{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ptflops import get_model_complexity_info\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_mod5(nn.Module):\n",
    "    # c1--c4是每条路径的输出通道数\n",
    "    def __init__(self, in_channels, c1, **kwargs):\n",
    "        super(Inception_mod5, self).__init__(**kwargs)\n",
    "        # 线路1，单1x1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # 线路2，1x1卷积层后接3x3卷积层\n",
    "        # self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "        # self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1x1卷积层后接5x5卷积层\n",
    "        # self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n",
    "        # self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3x3最大汇聚层后接1x1卷积层\n",
    "        # self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        # self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        # p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        # p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        # p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        # 在通道维度上连结输出\n",
    "        return torch.cat([p1], dim=1)\n",
    "    \n",
    "def Googlenet_mod5(img_channel, num_labels):\n",
    "    b1 = nn.Sequential(nn.Conv2d(img_channel, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b3 = nn.Sequential(Inception_mod5(192, 64),\n",
    "                   Inception_mod5(64, 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b4 = nn.Sequential(Inception_mod5(128, 192),\n",
    "                   Inception_mod5(192, 160),\n",
    "                   Inception_mod5(160, 128),\n",
    "                   Inception_mod5(128, 112),\n",
    "                   Inception_mod5(112, 256),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b5 = nn.Sequential(Inception_mod5(256, 256),\n",
    "                   Inception_mod5(256, 384),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   nn.Flatten())\n",
    "\n",
    "    net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(384, num_labels))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_mod6(nn.Module):\n",
    "    # c1--c4是每条路径的输出通道数\n",
    "    def __init__(self, in_channels, c1, **kwargs):\n",
    "        super(Inception_mod6, self).__init__(**kwargs)\n",
    "        # 线路1，单1x1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # 线路2，1x1卷积层后接3x3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1x1卷积层后接5x5卷积层\n",
    "        # self.p3_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "        # self.p3_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路4，3x3最大汇聚层后接1x1卷积层\n",
    "        # self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        # self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_1(x))\n",
    "        # p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        # p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        # p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        # 在通道维度上连结输出\n",
    "        return torch.cat((p1, p2), dim=1)\n",
    "    \n",
    "def Googlenet_mod6(img_channel, num_labels):\n",
    "    b1 = nn.Sequential(nn.Conv2d(img_channel, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b3 = nn.Sequential(Inception_mod6(192, 64),\n",
    "                   Inception_mod6(128, 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b4 = nn.Sequential(Inception_mod6(256, 192),\n",
    "                   Inception_mod6(384, 160),\n",
    "                   Inception_mod6(320, 128),\n",
    "                   Inception_mod6(256, 112),\n",
    "                   Inception_mod6(224, 256),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b5 = nn.Sequential(Inception_mod6(512, 256),\n",
    "                   Inception_mod6(512, 384),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   nn.Flatten())\n",
    "\n",
    "    net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(384*2, num_labels))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_mod7(nn.Module):\n",
    "    # c1--c4是每条路径的输出通道数\n",
    "    def __init__(self, in_channels, c1, **kwargs):\n",
    "        super(Inception_mod7, self).__init__(**kwargs)\n",
    "        # 线路1，单1x1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # 线路2，1x1卷积层后接3x3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1x1卷积层后接5x5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # self.p3_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路4，3x3最大汇聚层后接1x1卷积层\n",
    "        # self.p4_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "        # self.p4_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_1(x))\n",
    "        p3 = F.relu(self.p3_1(x))\n",
    "        # p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        # p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        # p4 = F.relu(self.p4_2(F.relu(self.p4_1(x))))\n",
    "        # 在通道维度上连结输出\n",
    "        return torch.cat((p1,p2, p3), dim=1)\n",
    "    \n",
    "def Googlenet_mod7(img_channel, num_labels):\n",
    "    b1 = nn.Sequential(nn.Conv2d(img_channel, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b3 = nn.Sequential(Inception_mod7(192, 64),\n",
    "                   Inception_mod7(64*3, 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b4 = nn.Sequential(Inception_mod7(128*3, 192),\n",
    "                   Inception_mod7(192*3, 160),\n",
    "                   Inception_mod7(160*3, 128),\n",
    "                   Inception_mod7(128*3, 112),\n",
    "                   Inception_mod7(112*3, 256),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b5 = nn.Sequential(Inception_mod7(256*3, 256),\n",
    "                   Inception_mod7(256*3, 384),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   nn.Flatten())\n",
    "\n",
    "    net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(384*3, num_labels))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_mod8(nn.Module):\n",
    "    # c1--c4是每条路径的输出通道数\n",
    "    def __init__(self, in_channels, c1, **kwargs):\n",
    "        super(Inception_mod8, self).__init__(**kwargs)\n",
    "        # 线路1，单1x1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # 线路2，1x1卷积层后接3x3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1x1卷积层后接5x5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # self.p3_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路4，3x3最大汇聚层后接1x1卷积层\n",
    "        self.p4_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # self.p4_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_1(x))\n",
    "        p3 = F.relu(self.p3_1(x))\n",
    "        p4 = F.relu(self.p4_1(x))\n",
    "        # 在通道维度上连结输出\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)\n",
    "    \n",
    "def Googlenet_mod8(img_channel, num_labels):\n",
    "    b1 = nn.Sequential(nn.Conv2d(img_channel, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b3 = nn.Sequential(Inception_mod8(192, 64),\n",
    "                   Inception_mod8(64*4, 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b4 = nn.Sequential(Inception_mod8(128*4, 192),\n",
    "                   Inception_mod8(192*4, 160),\n",
    "                   Inception_mod8(160*4, 128),\n",
    "                   Inception_mod8(128*4, 112),\n",
    "                   Inception_mod8(112*4, 256),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b5 = nn.Sequential(Inception_mod8(256*4, 256),\n",
    "                   Inception_mod8(256*4, 384),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   nn.Flatten())\n",
    "\n",
    "    net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(384*4, num_labels))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Inception_mod8(nn.Module):\n",
    "#     # c1--c4是每条路径的输出通道数\n",
    "#     def __init__(self, in_channels, c2, **kwargs):\n",
    "#         super(Inception_mod8, self).__init__(**kwargs)\n",
    "#         # 线路1，单1x1卷积层\n",
    "#         self.p1_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "#         self.p1_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "#         # 线路2，1x1卷积层后接3x3卷积层\n",
    "#         self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "#         self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "#         # 线路3，1x1卷积层后接5x5卷积层\n",
    "#         self.p3_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "#         self.p3_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "#         # 线路4，3x3最大汇聚层后接1x1卷积层\n",
    "#         self.p4_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "#         self.p4_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         p1 = F.relu(self.p1_2(F.relu(self.p1_1(x))))\n",
    "#         p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "#         p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "#         p4 = F.relu(self.p4_2(F.relu(self.p4_1(x))))\n",
    "#         # 在通道维度上连结输出\n",
    "#         return torch.cat((p1, p2, p3, p4), dim=1)\n",
    "    \n",
    "def Googlenet_mod9(img_channel, num_labels):\n",
    "    b1 = nn.Sequential(nn.Conv2d(img_channel, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    # b3 = nn.Sequential(Inception_mod8(192, (96, 128)),\n",
    "    #                Inception_mod8(128*4, (128, 192)),\n",
    "    #                nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    # b4 = nn.Sequential(Inception_mod8(192*4, (96, 208)),\n",
    "    #                Inception_mod8(208*4, (112, 224)),\n",
    "    #                Inception_mod8(224*4, (128, 256)),\n",
    "    #                Inception_mod8(256*4, (144, 288)),\n",
    "    #                Inception_mod8(288*4, (160, 320)),\n",
    "    #                nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    # b5 = nn.Sequential(Inception_mod8(320*4, (160, 320)),\n",
    "    #                Inception_mod8(320*4, (192, 384)),\n",
    "    #                nn.AdaptiveAvgPool2d((1,1)),\n",
    "    #                nn.Flatten())\n",
    "    \n",
    "    b5 = nn.Sequential(\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   nn.Flatten())\n",
    "\n",
    "    net = nn.Sequential(b1, b2, b5, nn.Linear(192, num_labels))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Sequential\n",
      "  0: Conv2d\n",
      "  1: ReLU\n",
      "  2: MaxPool2d\n",
      "1: Sequential\n",
      "  0: Conv2d\n",
      "  1: ReLU\n",
      "  2: Conv2d\n",
      "  3: ReLU\n",
      "  4: MaxPool2d\n",
      "2: Sequential\n",
      "  0: AdaptiveAvgPool2d\n",
      "  1: Flatten\n",
      "3: Linear\n",
      "The layer name is: ['S0_C0', 'S0_R1', 'S0_M2', 'S1_C0', 'S1_R1', 'S1_C2', 'S1_R3', 'S1_M4', 'S2_A0', 'S2_F1']\n",
      "The length of layer name is: 10\n",
      "The number of blocks is: 3\n",
      "The number of inception blocks is: 0\n"
     ]
    }
   ],
   "source": [
    "# net = Googlenet_mod5(1, 10) \n",
    "# net = Googlenet_mod6(1, 10) \n",
    "# net = Googlenet_mod7(1, 10) \n",
    "# net = Googlenet_mod8(1, 10) \n",
    "net = Googlenet_mod9(1, 10) \n",
    "LayerName = []\n",
    "block_num = 0\n",
    "incep_num = 0\n",
    "\n",
    "for num, layer in net.named_children():  # 使用 named_children 来获取层名和层\n",
    "    layername = layer.__class__.__name__\n",
    "    print(f\"{num}: {layername}\")  # 打印层名和层类名\n",
    "    \n",
    "    if layer.__class__.__name__ == 'Sequential':\n",
    "        block_num += 1\n",
    "        for sublayernum, sublayer in layer.named_children():  # 再次使用 named_children\n",
    "            sublayername = sublayer.__class__.__name__\n",
    "            if sublayername == 'Inception_mod5':\n",
    "                incep_num += 1\n",
    "            print(f\"  {sublayernum}: {sublayername}\")\n",
    "            layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}'\n",
    "            LayerName.append(layer_label)  # 收集子块的类型\n",
    "                        \n",
    "print('The layer name is:', LayerName)\n",
    "print(f'The length of layer name is: {len(LayerName)}')\n",
    "print('The number of blocks is:', block_num)\n",
    "print('The number of inception blocks is:', incep_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build different alexnet model for different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于不同的数据集，要设置不同的img_channel和num_labels\n",
    "# Fashion-MNIST中的图像通道数为1，类别数为10\n",
    "googlenet_fmod5 = Googlenet_mod5(1, 10)\n",
    "googlenet_fmod6 = Googlenet_mod6(1, 10)\n",
    "googlenet_fmod7 = Googlenet_mod7(1, 10)\n",
    "googlenet_fmod8 = Googlenet_mod8(1, 10)\n",
    "googlenet_fmod9 = Googlenet_mod9(1, 10)\n",
    "# CIFAR100中的图像通道数为3，类别数为100\n",
    "googlenet_cmod5 = Googlenet_mod5(3, 100)\n",
    "googlenet_cmod6 = Googlenet_mod6(3, 100)\n",
    "googlenet_cmod7 = Googlenet_mod7(3, 100)\n",
    "googlenet_cmod8 = Googlenet_mod8(3, 100)\n",
    "googlenet_cmod9 = Googlenet_mod9(3, 100)\n",
    "# CIFAR10中的图像通道数为3，类别数为10\n",
    "googlenet_c10mod5 = Googlenet_mod5(3, 10)\n",
    "googlenet_c10mod6 = Googlenet_mod6(3, 10)\n",
    "googlenet_c10mod7 = Googlenet_mod7(3, 10)\n",
    "googlenet_c10mod8 = Googlenet_mod8(3, 10)\n",
    "googlenet_c10mod9 = Googlenet_mod9(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model complexity of googlenet_fmod5:\n",
      "Warning: module Inception_mod5 is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  426.78 k, 100.000% Params, 451.5 MMac, 99.225% MACs, \n",
      "  (0): Sequential(\n",
      "    3.2 k, 0.750% Params, 41.75 MMac, 9.174% MACs, \n",
      "    (0): Conv2d(3.2 k, 0.750% Params, 40.14 MMac, 8.822% MACs, 1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.176% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.176% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 26.933% Params, 361.87 MMac, 79.526% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.975% Params, 13.05 MMac, 2.867% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.044% MACs, )\n",
      "    (2): Conv2d(110.78 k, 25.958% Params, 347.42 MMac, 76.351% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.132% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.132% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    20.67 k, 4.844% Params, 16.31 MMac, 3.584% MACs, \n",
      "    (0): Inception_mod5(\n",
      "      12.35 k, 2.894% Params, 9.68 MMac, 2.128% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 2.894% Params, 9.68 MMac, 2.128% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod5(\n",
      "      8.32 k, 1.949% Params, 6.52 MMac, 1.434% MACs, \n",
      "      (p1_1): Conv2d(8.32 k, 1.949% Params, 6.52 MMac, 1.434% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.022% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    119.63 k, 28.031% Params, 23.5 MMac, 5.164% MACs, \n",
      "    (0): Inception_mod5(\n",
      "      24.77 k, 5.803% Params, 4.85 MMac, 1.067% MACs, \n",
      "      (p1_1): Conv2d(24.77 k, 5.803% Params, 4.85 MMac, 1.067% MACs, 128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod5(\n",
      "      30.88 k, 7.236% Params, 6.05 MMac, 1.330% MACs, \n",
      "      (p1_1): Conv2d(30.88 k, 7.236% Params, 6.05 MMac, 1.330% MACs, 192, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception_mod5(\n",
      "      20.61 k, 4.829% Params, 4.04 MMac, 0.888% MACs, \n",
      "      (p1_1): Conv2d(20.61 k, 4.829% Params, 4.04 MMac, 0.888% MACs, 160, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception_mod5(\n",
      "      14.45 k, 3.385% Params, 2.83 MMac, 0.622% MACs, \n",
      "      (p1_1): Conv2d(14.45 k, 3.385% Params, 2.83 MMac, 0.622% MACs, 128, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception_mod5(\n",
      "      28.93 k, 6.778% Params, 5.67 MMac, 1.246% MACs, \n",
      "      (p1_1): Conv2d(28.93 k, 6.778% Params, 5.67 MMac, 1.246% MACs, 112, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 50.18 KMac, 0.011% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    164.48 k, 38.540% Params, 8.08 MMac, 1.775% MACs, \n",
      "    (0): Inception_mod5(\n",
      "      65.79 k, 15.416% Params, 3.22 MMac, 0.708% MACs, \n",
      "      (p1_1): Conv2d(65.79 k, 15.416% Params, 3.22 MMac, 0.708% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod5(\n",
      "      98.69 k, 23.124% Params, 4.84 MMac, 1.063% MACs, \n",
      "      (p1_1): Conv2d(98.69 k, 23.124% Params, 4.84 MMac, 1.063% MACs, 256, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 18.82 KMac, 0.004% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(3.85 k, 0.902% Params, 3.85 KMac, 0.001% MACs, in_features=384, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       455.03 MMac\n",
      "Number of parameters:           426.78 k\n",
      "**************************************************\n",
      "The model complexity of googlenet_fmod6:\n",
      "Warning: module Inception_mod6 is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  1.32 M, 100.000% Params, 574.86 MMac, 99.301% MACs, \n",
      "  (0): Sequential(\n",
      "    3.2 k, 0.243% Params, 41.75 MMac, 7.211% MACs, \n",
      "    (0): Conv2d(3.2 k, 0.243% Params, 40.14 MMac, 6.934% MACs, 1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.139% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.139% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 8.727% Params, 361.87 MMac, 62.510% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.316% Params, 13.05 MMac, 2.254% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.035% MACs, )\n",
      "    (2): Conv2d(110.78 k, 8.412% Params, 347.42 MMac, 60.014% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.104% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.104% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    57.73 k, 4.383% Params, 45.46 MMac, 7.853% MACs, \n",
      "    (0): Inception_mod6(\n",
      "      24.7 k, 1.876% Params, 19.37 MMac, 3.346% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.938% Params, 9.68 MMac, 1.673% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(12.35 k, 0.938% Params, 9.68 MMac, 1.673% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod6(\n",
      "      33.02 k, 2.507% Params, 25.89 MMac, 4.472% MACs, \n",
      "      (p1_1): Conv2d(16.51 k, 1.254% Params, 12.95 MMac, 2.236% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(16.51 k, 1.254% Params, 12.95 MMac, 2.236% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 200.7 KMac, 0.035% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    476.83 k, 36.205% Params, 93.56 MMac, 16.162% MACs, \n",
      "    (0): Inception_mod6(\n",
      "      98.69 k, 7.493% Params, 19.34 MMac, 3.341% MACs, \n",
      "      (p1_1): Conv2d(49.34 k, 3.747% Params, 9.67 MMac, 1.671% MACs, 256, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(49.34 k, 3.747% Params, 9.67 MMac, 1.671% MACs, 256, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod6(\n",
      "      123.2 k, 9.354% Params, 24.15 MMac, 4.171% MACs, \n",
      "      (p1_1): Conv2d(61.6 k, 4.677% Params, 12.07 MMac, 2.086% MACs, 384, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(61.6 k, 4.677% Params, 12.07 MMac, 2.086% MACs, 384, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception_mod6(\n",
      "      82.18 k, 6.239% Params, 16.11 MMac, 2.782% MACs, \n",
      "      (p1_1): Conv2d(41.09 k, 3.120% Params, 8.05 MMac, 1.391% MACs, 320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(41.09 k, 3.120% Params, 8.05 MMac, 1.391% MACs, 320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception_mod6(\n",
      "      57.57 k, 4.371% Params, 11.28 MMac, 1.949% MACs, \n",
      "      (p1_1): Conv2d(28.78 k, 2.186% Params, 5.64 MMac, 0.975% MACs, 256, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(28.78 k, 2.186% Params, 5.64 MMac, 0.975% MACs, 256, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception_mod6(\n",
      "      115.2 k, 8.747% Params, 22.58 MMac, 3.900% MACs, \n",
      "      (p1_1): Conv2d(57.6 k, 4.373% Params, 11.29 MMac, 1.950% MACs, 224, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(57.6 k, 4.373% Params, 11.29 MMac, 1.950% MACs, 224, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.017% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    656.64 k, 49.857% Params, 32.21 MMac, 5.565% MACs, \n",
      "    (0): Inception_mod6(\n",
      "      262.66 k, 19.943% Params, 12.87 MMac, 2.223% MACs, \n",
      "      (p1_1): Conv2d(131.33 k, 9.971% Params, 6.44 MMac, 1.112% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(131.33 k, 9.971% Params, 6.44 MMac, 1.112% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod6(\n",
      "      393.98 k, 29.914% Params, 19.31 MMac, 3.335% MACs, \n",
      "      (p1_1): Conv2d(196.99 k, 14.957% Params, 9.65 MMac, 1.667% MACs, 512, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(196.99 k, 14.957% Params, 9.65 MMac, 1.667% MACs, 512, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 37.63 KMac, 0.007% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(7.69 k, 0.584% Params, 7.69 KMac, 0.001% MACs, in_features=768, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       578.9 MMac\n",
      "Number of parameters:           1.32 M  \n",
      "**************************************************\n",
      "The model complexity of googlenet_fmod7:\n",
      "Warning: module Inception_mod7 is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  2.79 M, 100.000% Params, 773.67 MMac, 99.414% MACs, \n",
      "  (0): Sequential(\n",
      "    3.2 k, 0.115% Params, 41.75 MMac, 5.364% MACs, \n",
      "    (0): Conv2d(3.2 k, 0.115% Params, 40.14 MMac, 5.158% MACs, 1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.103% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.103% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 4.121% Params, 361.87 MMac, 46.499% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.149% Params, 13.05 MMac, 1.676% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.026% MACs, )\n",
      "    (2): Conv2d(110.78 k, 3.972% Params, 347.42 MMac, 44.642% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.077% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.077% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    111.17 k, 3.986% Params, 87.46 MMac, 11.238% MACs, \n",
      "    (0): Inception_mod7(\n",
      "      37.06 k, 1.329% Params, 29.05 MMac, 3.733% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.443% Params, 9.68 MMac, 1.244% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(12.35 k, 0.443% Params, 9.68 MMac, 1.244% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(12.35 k, 0.443% Params, 9.68 MMac, 1.244% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod7(\n",
      "      74.11 k, 2.657% Params, 58.1 MMac, 7.466% MACs, \n",
      "      (p1_1): Conv2d(24.7 k, 0.886% Params, 19.37 MMac, 2.489% MACs, 192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(24.7 k, 0.886% Params, 19.37 MMac, 2.489% MACs, 192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(24.7 k, 0.886% Params, 19.37 MMac, 2.489% MACs, 192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 301.06 KMac, 0.039% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    1.07 M, 38.423% Params, 210.18 MMac, 27.008% MACs, \n",
      "    (0): Inception_mod7(\n",
      "      221.76 k, 7.951% Params, 43.46 MMac, 5.585% MACs, \n",
      "      (p1_1): Conv2d(73.92 k, 2.650% Params, 14.49 MMac, 1.862% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(73.92 k, 2.650% Params, 14.49 MMac, 1.862% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(73.92 k, 2.650% Params, 14.49 MMac, 1.862% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod7(\n",
      "      276.96 k, 9.931% Params, 54.28 MMac, 6.975% MACs, \n",
      "      (p1_1): Conv2d(92.32 k, 3.310% Params, 18.09 MMac, 2.325% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(92.32 k, 3.310% Params, 18.09 MMac, 2.325% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(92.32 k, 3.310% Params, 18.09 MMac, 2.325% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception_mod7(\n",
      "      184.7 k, 6.623% Params, 36.2 MMac, 4.652% MACs, \n",
      "      (p1_1): Conv2d(61.57 k, 2.208% Params, 12.07 MMac, 1.551% MACs, 480, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(61.57 k, 2.208% Params, 12.07 MMac, 1.551% MACs, 480, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(61.57 k, 2.208% Params, 12.07 MMac, 1.551% MACs, 480, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception_mod7(\n",
      "      129.36 k, 4.638% Params, 25.35 MMac, 3.258% MACs, \n",
      "      (p1_1): Conv2d(43.12 k, 1.546% Params, 8.45 MMac, 1.086% MACs, 384, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(43.12 k, 1.546% Params, 8.45 MMac, 1.086% MACs, 384, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(43.12 k, 1.546% Params, 8.45 MMac, 1.086% MACs, 384, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception_mod7(\n",
      "      258.82 k, 9.280% Params, 50.73 MMac, 6.518% MACs, \n",
      "      (p1_1): Conv2d(86.27 k, 3.093% Params, 16.91 MMac, 2.173% MACs, 336, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(86.27 k, 3.093% Params, 16.91 MMac, 2.173% MACs, 336, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(86.27 k, 3.093% Params, 16.91 MMac, 2.173% MACs, 336, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 150.53 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    1.48 M, 52.941% Params, 72.4 MMac, 9.304% MACs, \n",
      "    (0): Inception_mod7(\n",
      "      590.59 k, 21.176% Params, 28.94 MMac, 3.719% MACs, \n",
      "      (p1_1): Conv2d(196.86 k, 7.059% Params, 9.65 MMac, 1.240% MACs, 768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(196.86 k, 7.059% Params, 9.65 MMac, 1.240% MACs, 768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(196.86 k, 7.059% Params, 9.65 MMac, 1.240% MACs, 768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod7(\n",
      "      885.89 k, 31.765% Params, 43.41 MMac, 5.578% MACs, \n",
      "      (p1_1): Conv2d(295.3 k, 10.588% Params, 14.47 MMac, 1.859% MACs, 768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(295.3 k, 10.588% Params, 14.47 MMac, 1.859% MACs, 768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(295.3 k, 10.588% Params, 14.47 MMac, 1.859% MACs, 768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 56.45 KMac, 0.007% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(11.53 k, 0.413% Params, 11.53 KMac, 0.001% MACs, in_features=1152, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       778.24 MMac\n",
      "Number of parameters:           2.79 M  \n",
      "**************************************************\n",
      "The model complexity of googlenet_fmod8:\n",
      "Warning: module Inception_mod8 is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  4.84 M, 100.000% Params, 1.05 GMac, 99.518% MACs, \n",
      "  (0): Sequential(\n",
      "    3.2 k, 0.066% Params, 41.75 MMac, 3.964% MACs, \n",
      "    (0): Conv2d(3.2 k, 0.066% Params, 40.14 MMac, 3.812% MACs, 1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.076% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.076% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 2.374% Params, 361.87 MMac, 34.364% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.086% Params, 13.05 MMac, 1.239% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.019% MACs, )\n",
      "    (2): Conv2d(110.78 k, 2.288% Params, 347.42 MMac, 32.992% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.057% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.057% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    180.99 k, 3.738% Params, 142.3 MMac, 13.513% MACs, \n",
      "    (0): Inception_mod8(\n",
      "      49.41 k, 1.020% Params, 38.74 MMac, 3.679% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.255% Params, 9.68 MMac, 0.920% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(12.35 k, 0.255% Params, 9.68 MMac, 0.920% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(12.35 k, 0.255% Params, 9.68 MMac, 0.920% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(12.35 k, 0.255% Params, 9.68 MMac, 0.920% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod8(\n",
      "      131.58 k, 2.717% Params, 103.16 MMac, 9.797% MACs, \n",
      "      (p1_1): Conv2d(32.9 k, 0.679% Params, 25.79 MMac, 2.449% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(32.9 k, 0.679% Params, 25.79 MMac, 2.449% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(32.9 k, 0.679% Params, 25.79 MMac, 2.449% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(32.9 k, 0.679% Params, 25.79 MMac, 2.449% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 401.41 KMac, 0.038% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    1.9 M, 39.318% Params, 373.37 MMac, 35.457% MACs, \n",
      "    (0): Inception_mod8(\n",
      "      393.98 k, 8.136% Params, 77.22 MMac, 7.333% MACs, \n",
      "      (p1_1): Conv2d(98.5 k, 2.034% Params, 19.31 MMac, 1.833% MACs, 512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(98.5 k, 2.034% Params, 19.31 MMac, 1.833% MACs, 512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(98.5 k, 2.034% Params, 19.31 MMac, 1.833% MACs, 512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(98.5 k, 2.034% Params, 19.31 MMac, 1.833% MACs, 512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod8(\n",
      "      492.16 k, 10.163% Params, 96.46 MMac, 9.161% MACs, \n",
      "      (p1_1): Conv2d(123.04 k, 2.541% Params, 24.12 MMac, 2.290% MACs, 768, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(123.04 k, 2.541% Params, 24.12 MMac, 2.290% MACs, 768, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(123.04 k, 2.541% Params, 24.12 MMac, 2.290% MACs, 768, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(123.04 k, 2.541% Params, 24.12 MMac, 2.290% MACs, 768, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception_mod8(\n",
      "      328.19 k, 6.777% Params, 64.33 MMac, 6.109% MACs, \n",
      "      (p1_1): Conv2d(82.05 k, 1.694% Params, 16.08 MMac, 1.527% MACs, 640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(82.05 k, 1.694% Params, 16.08 MMac, 1.527% MACs, 640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(82.05 k, 1.694% Params, 16.08 MMac, 1.527% MACs, 640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(82.05 k, 1.694% Params, 16.08 MMac, 1.527% MACs, 640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception_mod8(\n",
      "      229.82 k, 4.746% Params, 45.05 MMac, 4.278% MACs, \n",
      "      (p1_1): Conv2d(57.46 k, 1.187% Params, 11.26 MMac, 1.069% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(57.46 k, 1.187% Params, 11.26 MMac, 1.069% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(57.46 k, 1.187% Params, 11.26 MMac, 1.069% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(57.46 k, 1.187% Params, 11.26 MMac, 1.069% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception_mod8(\n",
      "      459.78 k, 9.495% Params, 90.12 MMac, 8.558% MACs, \n",
      "      (p1_1): Conv2d(114.94 k, 2.374% Params, 22.53 MMac, 2.139% MACs, 448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(114.94 k, 2.374% Params, 22.53 MMac, 2.139% MACs, 448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(114.94 k, 2.374% Params, 22.53 MMac, 2.139% MACs, 448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(114.94 k, 2.374% Params, 22.53 MMac, 2.139% MACs, 448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 200.7 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    2.62 M, 54.188% Params, 128.65 MMac, 12.217% MACs, \n",
      "    (0): Inception_mod8(\n",
      "      1.05 M, 21.675% Params, 51.43 MMac, 4.884% MACs, \n",
      "      (p1_1): Conv2d(262.4 k, 5.419% Params, 12.86 MMac, 1.221% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(262.4 k, 5.419% Params, 12.86 MMac, 1.221% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(262.4 k, 5.419% Params, 12.86 MMac, 1.221% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(262.4 k, 5.419% Params, 12.86 MMac, 1.221% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod8(\n",
      "      1.57 M, 32.513% Params, 77.15 MMac, 7.326% MACs, \n",
      "      (p1_1): Conv2d(393.6 k, 8.128% Params, 19.29 MMac, 1.832% MACs, 1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(393.6 k, 8.128% Params, 19.29 MMac, 1.832% MACs, 1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(393.6 k, 8.128% Params, 19.29 MMac, 1.832% MACs, 1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(393.6 k, 8.128% Params, 19.29 MMac, 1.832% MACs, 1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.007% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(15.37 k, 0.317% Params, 15.37 KMac, 0.001% MACs, in_features=1536, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       1.05 GMac\n",
      "Number of parameters:           4.84 M  \n",
      "**************************************************\n",
      "The model complexity of googlenet_fmod9:\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  120.07 k, 100.000% Params, 403.77 MMac, 99.223% MACs, \n",
      "  (0): Sequential(\n",
      "    3.2 k, 2.665% Params, 41.75 MMac, 10.259% MACs, \n",
      "    (0): Conv2d(3.2 k, 2.665% Params, 40.14 MMac, 9.864% MACs, 1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.197% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.197% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 95.728% Params, 361.87 MMac, 88.927% MACs, \n",
      "    (0): Conv2d(4.16 k, 3.465% Params, 13.05 MMac, 3.206% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.049% MACs, )\n",
      "    (2): Conv2d(110.78 k, 92.263% Params, 347.42 MMac, 85.376% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.148% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.148% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    0, 0.000% Params, 150.53 KMac, 0.037% MACs, \n",
      "    (0): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.037% MACs, output_size=(1, 1))\n",
      "    (1): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (3): Linear(1.93 k, 1.607% Params, 1.93 KMac, 0.000% MACs, in_features=192, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       406.93 MMac\n",
      "Number of parameters:           120.07 k\n",
      "********************************************************************************************************************************************************************************************************\n",
      "The model complexity of googlenet_cmod5:\n",
      "Warning: module Inception_mod5 is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  467.7 k, 100.000% Params, 530.21 MMac, 99.339% MACs, \n",
      "  (0): Sequential(\n",
      "    9.47 k, 2.025% Params, 120.42 MMac, 22.562% MACs, \n",
      "    (0): Conv2d(9.47 k, 2.025% Params, 118.82 MMac, 22.261% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.150% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.150% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 24.576% Params, 361.87 MMac, 67.799% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.889% Params, 13.05 MMac, 2.444% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.038% MACs, )\n",
      "    (2): Conv2d(110.78 k, 23.687% Params, 347.42 MMac, 65.091% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.113% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.113% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    20.67 k, 4.420% Params, 16.31 MMac, 3.055% MACs, \n",
      "    (0): Inception_mod5(\n",
      "      12.35 k, 2.641% Params, 9.68 MMac, 1.814% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 2.641% Params, 9.68 MMac, 1.814% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod5(\n",
      "      8.32 k, 1.779% Params, 6.52 MMac, 1.222% MACs, \n",
      "      (p1_1): Conv2d(8.32 k, 1.779% Params, 6.52 MMac, 1.222% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    119.63 k, 25.579% Params, 23.5 MMac, 4.403% MACs, \n",
      "    (0): Inception_mod5(\n",
      "      24.77 k, 5.296% Params, 4.85 MMac, 0.910% MACs, \n",
      "      (p1_1): Conv2d(24.77 k, 5.296% Params, 4.85 MMac, 0.910% MACs, 128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod5(\n",
      "      30.88 k, 6.603% Params, 6.05 MMac, 1.134% MACs, \n",
      "      (p1_1): Conv2d(30.88 k, 6.603% Params, 6.05 MMac, 1.134% MACs, 192, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception_mod5(\n",
      "      20.61 k, 4.406% Params, 4.04 MMac, 0.757% MACs, \n",
      "      (p1_1): Conv2d(20.61 k, 4.406% Params, 4.04 MMac, 0.757% MACs, 160, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception_mod5(\n",
      "      14.45 k, 3.089% Params, 2.83 MMac, 0.531% MACs, \n",
      "      (p1_1): Conv2d(14.45 k, 3.089% Params, 2.83 MMac, 0.531% MACs, 128, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception_mod5(\n",
      "      28.93 k, 6.185% Params, 5.67 MMac, 1.062% MACs, \n",
      "      (p1_1): Conv2d(28.93 k, 6.185% Params, 5.67 MMac, 1.062% MACs, 112, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 50.18 KMac, 0.009% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    164.48 k, 35.168% Params, 8.08 MMac, 1.514% MACs, \n",
      "    (0): Inception_mod5(\n",
      "      65.79 k, 14.067% Params, 3.22 MMac, 0.604% MACs, \n",
      "      (p1_1): Conv2d(65.79 k, 14.067% Params, 3.22 MMac, 0.604% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod5(\n",
      "      98.69 k, 21.101% Params, 4.84 MMac, 0.906% MACs, \n",
      "      (p1_1): Conv2d(98.69 k, 21.101% Params, 4.84 MMac, 0.906% MACs, 256, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 18.82 KMac, 0.004% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(38.5 k, 8.232% Params, 38.5 KMac, 0.007% MACs, in_features=384, out_features=100, bias=True)\n",
      ")\n",
      "Computational complexity:       533.74 MMac\n",
      "Number of parameters:           467.7 k \n",
      "**************************************************\n",
      "The model complexity of googlenet_cmod6:\n",
      "Warning: module Inception_mod6 is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  1.39 M, 100.000% Params, 653.6 MMac, 99.385% MACs, \n",
      "  (0): Sequential(\n",
      "    9.47 k, 0.680% Params, 120.42 MMac, 18.311% MACs, \n",
      "    (0): Conv2d(9.47 k, 0.680% Params, 118.82 MMac, 18.067% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.122% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.122% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 8.254% Params, 361.87 MMac, 55.025% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.299% Params, 13.05 MMac, 1.984% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.031% MACs, )\n",
      "    (2): Conv2d(110.78 k, 7.956% Params, 347.42 MMac, 52.828% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.092% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.092% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    57.73 k, 4.146% Params, 45.46 MMac, 6.912% MACs, \n",
      "    (0): Inception_mod6(\n",
      "      24.7 k, 1.774% Params, 19.37 MMac, 2.945% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.887% Params, 9.68 MMac, 1.473% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(12.35 k, 0.887% Params, 9.68 MMac, 1.473% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod6(\n",
      "      33.02 k, 2.372% Params, 25.89 MMac, 3.937% MACs, \n",
      "      (p1_1): Conv2d(16.51 k, 1.186% Params, 12.95 MMac, 1.968% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(16.51 k, 1.186% Params, 12.95 MMac, 1.968% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 200.7 KMac, 0.031% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    476.83 k, 34.242% Params, 93.56 MMac, 14.226% MACs, \n",
      "    (0): Inception_mod6(\n",
      "      98.69 k, 7.087% Params, 19.34 MMac, 2.941% MACs, \n",
      "      (p1_1): Conv2d(49.34 k, 3.544% Params, 9.67 MMac, 1.471% MACs, 256, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(49.34 k, 3.544% Params, 9.67 MMac, 1.471% MACs, 256, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod6(\n",
      "      123.2 k, 8.847% Params, 24.15 MMac, 3.672% MACs, \n",
      "      (p1_1): Conv2d(61.6 k, 4.424% Params, 12.07 MMac, 1.836% MACs, 384, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(61.6 k, 4.424% Params, 12.07 MMac, 1.836% MACs, 384, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception_mod6(\n",
      "      82.18 k, 5.901% Params, 16.11 MMac, 2.449% MACs, \n",
      "      (p1_1): Conv2d(41.09 k, 2.951% Params, 8.05 MMac, 1.225% MACs, 320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(41.09 k, 2.951% Params, 8.05 MMac, 1.225% MACs, 320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception_mod6(\n",
      "      57.57 k, 4.134% Params, 11.28 MMac, 1.716% MACs, \n",
      "      (p1_1): Conv2d(28.78 k, 2.067% Params, 5.64 MMac, 0.858% MACs, 256, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(28.78 k, 2.067% Params, 5.64 MMac, 0.858% MACs, 256, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception_mod6(\n",
      "      115.2 k, 8.273% Params, 22.58 MMac, 3.433% MACs, \n",
      "      (p1_1): Conv2d(57.6 k, 4.136% Params, 11.29 MMac, 1.717% MACs, 224, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(57.6 k, 4.136% Params, 11.29 MMac, 1.717% MACs, 224, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.015% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    656.64 k, 47.155% Params, 32.21 MMac, 4.898% MACs, \n",
      "    (0): Inception_mod6(\n",
      "      262.66 k, 18.862% Params, 12.87 MMac, 1.957% MACs, \n",
      "      (p1_1): Conv2d(131.33 k, 9.431% Params, 6.44 MMac, 0.979% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(131.33 k, 9.431% Params, 6.44 MMac, 0.979% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod6(\n",
      "      393.98 k, 28.293% Params, 19.31 MMac, 2.936% MACs, \n",
      "      (p1_1): Conv2d(196.99 k, 14.146% Params, 9.65 MMac, 1.468% MACs, 512, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(196.99 k, 14.146% Params, 9.65 MMac, 1.468% MACs, 512, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 37.63 KMac, 0.006% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(76.9 k, 5.522% Params, 76.9 KMac, 0.012% MACs, in_features=768, out_features=100, bias=True)\n",
      ")\n",
      "Computational complexity:       657.65 MMac\n",
      "Number of parameters:           1.39 M  \n",
      "**************************************************\n",
      "The model complexity of googlenet_cmod7:\n",
      "Warning: module Inception_mod7 is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  2.9 M, 100.000% Params, 852.45 MMac, 99.468% MACs, \n",
      "  (0): Sequential(\n",
      "    9.47 k, 0.327% Params, 120.42 MMac, 14.051% MACs, \n",
      "    (0): Conv2d(9.47 k, 0.327% Params, 118.82 MMac, 13.864% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.094% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.094% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 3.965% Params, 361.87 MMac, 42.224% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.143% Params, 13.05 MMac, 1.522% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.023% MACs, )\n",
      "    (2): Conv2d(110.78 k, 3.822% Params, 347.42 MMac, 40.538% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.070% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.070% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    111.17 k, 3.835% Params, 87.46 MMac, 10.205% MACs, \n",
      "    (0): Inception_mod7(\n",
      "      37.06 k, 1.278% Params, 29.05 MMac, 3.390% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.426% Params, 9.68 MMac, 1.130% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(12.35 k, 0.426% Params, 9.68 MMac, 1.130% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(12.35 k, 0.426% Params, 9.68 MMac, 1.130% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod7(\n",
      "      74.11 k, 2.556% Params, 58.1 MMac, 6.780% MACs, \n",
      "      (p1_1): Conv2d(24.7 k, 0.852% Params, 19.37 MMac, 2.260% MACs, 192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(24.7 k, 0.852% Params, 19.37 MMac, 2.260% MACs, 192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(24.7 k, 0.852% Params, 19.37 MMac, 2.260% MACs, 192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 301.06 KMac, 0.035% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    1.07 M, 36.965% Params, 210.18 MMac, 24.525% MACs, \n",
      "    (0): Inception_mod7(\n",
      "      221.76 k, 7.650% Params, 43.46 MMac, 5.072% MACs, \n",
      "      (p1_1): Conv2d(73.92 k, 2.550% Params, 14.49 MMac, 1.691% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(73.92 k, 2.550% Params, 14.49 MMac, 1.691% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(73.92 k, 2.550% Params, 14.49 MMac, 1.691% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod7(\n",
      "      276.96 k, 9.554% Params, 54.28 MMac, 6.334% MACs, \n",
      "      (p1_1): Conv2d(92.32 k, 3.185% Params, 18.09 MMac, 2.111% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(92.32 k, 3.185% Params, 18.09 MMac, 2.111% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(92.32 k, 3.185% Params, 18.09 MMac, 2.111% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception_mod7(\n",
      "      184.7 k, 6.371% Params, 36.2 MMac, 4.224% MACs, \n",
      "      (p1_1): Conv2d(61.57 k, 2.124% Params, 12.07 MMac, 1.408% MACs, 480, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(61.57 k, 2.124% Params, 12.07 MMac, 1.408% MACs, 480, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(61.57 k, 2.124% Params, 12.07 MMac, 1.408% MACs, 480, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception_mod7(\n",
      "      129.36 k, 4.462% Params, 25.35 MMac, 2.958% MACs, \n",
      "      (p1_1): Conv2d(43.12 k, 1.487% Params, 8.45 MMac, 0.986% MACs, 384, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(43.12 k, 1.487% Params, 8.45 MMac, 0.986% MACs, 384, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(43.12 k, 1.487% Params, 8.45 MMac, 0.986% MACs, 384, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception_mod7(\n",
      "      258.82 k, 8.928% Params, 50.73 MMac, 5.919% MACs, \n",
      "      (p1_1): Conv2d(86.27 k, 2.976% Params, 16.91 MMac, 1.973% MACs, 336, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(86.27 k, 2.976% Params, 16.91 MMac, 1.973% MACs, 336, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(86.27 k, 2.976% Params, 16.91 MMac, 1.973% MACs, 336, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 150.53 KMac, 0.018% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    1.48 M, 50.931% Params, 72.4 MMac, 8.448% MACs, \n",
      "    (0): Inception_mod7(\n",
      "      590.59 k, 20.373% Params, 28.94 MMac, 3.377% MACs, \n",
      "      (p1_1): Conv2d(196.86 k, 6.791% Params, 9.65 MMac, 1.126% MACs, 768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(196.86 k, 6.791% Params, 9.65 MMac, 1.126% MACs, 768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(196.86 k, 6.791% Params, 9.65 MMac, 1.126% MACs, 768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod7(\n",
      "      885.89 k, 30.559% Params, 43.41 MMac, 5.065% MACs, \n",
      "      (p1_1): Conv2d(295.3 k, 10.186% Params, 14.47 MMac, 1.688% MACs, 768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(295.3 k, 10.186% Params, 14.47 MMac, 1.688% MACs, 768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(295.3 k, 10.186% Params, 14.47 MMac, 1.688% MACs, 768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 56.45 KMac, 0.007% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(115.3 k, 3.977% Params, 115.3 KMac, 0.013% MACs, in_features=1152, out_features=100, bias=True)\n",
      ")\n",
      "Computational complexity:       857.01 MMac\n",
      "Number of parameters:           2.9 M   \n",
      "**************************************************\n",
      "The model complexity of googlenet_cmod8:\n",
      "Warning: module Inception_mod8 is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  4.99 M, 100.000% Params, 1.13 GMac, 99.551% MACs, \n",
      "  (0): Sequential(\n",
      "    9.47 k, 0.190% Params, 120.42 MMac, 10.639% MACs, \n",
      "    (0): Conv2d(9.47 k, 0.190% Params, 118.82 MMac, 10.498% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.071% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.071% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 2.305% Params, 361.87 MMac, 31.972% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.083% Params, 13.05 MMac, 1.153% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.018% MACs, )\n",
      "    (2): Conv2d(110.78 k, 2.221% Params, 347.42 MMac, 30.695% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.053% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.053% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    180.99 k, 3.629% Params, 142.3 MMac, 12.572% MACs, \n",
      "    (0): Inception_mod8(\n",
      "      49.41 k, 0.991% Params, 38.74 MMac, 3.422% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.248% Params, 9.68 MMac, 0.856% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(12.35 k, 0.248% Params, 9.68 MMac, 0.856% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(12.35 k, 0.248% Params, 9.68 MMac, 0.856% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(12.35 k, 0.248% Params, 9.68 MMac, 0.856% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod8(\n",
      "      131.58 k, 2.639% Params, 103.16 MMac, 9.114% MACs, \n",
      "      (p1_1): Conv2d(32.9 k, 0.660% Params, 25.79 MMac, 2.279% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(32.9 k, 0.660% Params, 25.79 MMac, 2.279% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(32.9 k, 0.660% Params, 25.79 MMac, 2.279% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(32.9 k, 0.660% Params, 25.79 MMac, 2.279% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 401.41 KMac, 0.035% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    1.9 M, 38.178% Params, 373.37 MMac, 32.988% MACs, \n",
      "    (0): Inception_mod8(\n",
      "      393.98 k, 7.900% Params, 77.22 MMac, 6.823% MACs, \n",
      "      (p1_1): Conv2d(98.5 k, 1.975% Params, 19.31 MMac, 1.706% MACs, 512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(98.5 k, 1.975% Params, 19.31 MMac, 1.706% MACs, 512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(98.5 k, 1.975% Params, 19.31 MMac, 1.706% MACs, 512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(98.5 k, 1.975% Params, 19.31 MMac, 1.706% MACs, 512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod8(\n",
      "      492.16 k, 9.869% Params, 96.46 MMac, 8.523% MACs, \n",
      "      (p1_1): Conv2d(123.04 k, 2.467% Params, 24.12 MMac, 2.131% MACs, 768, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(123.04 k, 2.467% Params, 24.12 MMac, 2.131% MACs, 768, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(123.04 k, 2.467% Params, 24.12 MMac, 2.131% MACs, 768, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(123.04 k, 2.467% Params, 24.12 MMac, 2.131% MACs, 768, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception_mod8(\n",
      "      328.19 k, 6.581% Params, 64.33 MMac, 5.683% MACs, \n",
      "      (p1_1): Conv2d(82.05 k, 1.645% Params, 16.08 MMac, 1.421% MACs, 640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(82.05 k, 1.645% Params, 16.08 MMac, 1.421% MACs, 640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(82.05 k, 1.645% Params, 16.08 MMac, 1.421% MACs, 640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(82.05 k, 1.645% Params, 16.08 MMac, 1.421% MACs, 640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception_mod8(\n",
      "      229.82 k, 4.608% Params, 45.05 MMac, 3.980% MACs, \n",
      "      (p1_1): Conv2d(57.46 k, 1.152% Params, 11.26 MMac, 0.995% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(57.46 k, 1.152% Params, 11.26 MMac, 0.995% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(57.46 k, 1.152% Params, 11.26 MMac, 0.995% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(57.46 k, 1.152% Params, 11.26 MMac, 0.995% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception_mod8(\n",
      "      459.78 k, 9.219% Params, 90.12 MMac, 7.962% MACs, \n",
      "      (p1_1): Conv2d(114.94 k, 2.305% Params, 22.53 MMac, 1.990% MACs, 448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(114.94 k, 2.305% Params, 22.53 MMac, 1.990% MACs, 448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(114.94 k, 2.305% Params, 22.53 MMac, 1.990% MACs, 448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(114.94 k, 2.305% Params, 22.53 MMac, 1.990% MACs, 448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 200.7 KMac, 0.018% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    2.62 M, 52.616% Params, 128.65 MMac, 11.366% MACs, \n",
      "    (0): Inception_mod8(\n",
      "      1.05 M, 21.047% Params, 51.43 MMac, 4.544% MACs, \n",
      "      (p1_1): Conv2d(262.4 k, 5.262% Params, 12.86 MMac, 1.136% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(262.4 k, 5.262% Params, 12.86 MMac, 1.136% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(262.4 k, 5.262% Params, 12.86 MMac, 1.136% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(262.4 k, 5.262% Params, 12.86 MMac, 1.136% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod8(\n",
      "      1.57 M, 31.570% Params, 77.15 MMac, 6.816% MACs, \n",
      "      (p1_1): Conv2d(393.6 k, 7.892% Params, 19.29 MMac, 1.704% MACs, 1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(393.6 k, 7.892% Params, 19.29 MMac, 1.704% MACs, 1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(393.6 k, 7.892% Params, 19.29 MMac, 1.704% MACs, 1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(393.6 k, 7.892% Params, 19.29 MMac, 1.704% MACs, 1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.007% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(153.7 k, 3.082% Params, 153.7 KMac, 0.014% MACs, in_features=1536, out_features=100, bias=True)\n",
      ")\n",
      "Computational complexity:       1.13 GMac\n",
      "Number of parameters:           4.99 M  \n",
      "**************************************************\n",
      "The model complexity of googlenet_cmod9:\n",
      "Warning: module Flatten is treated as a zero-op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  143.72 k, 100.000% Params, 482.46 MMac, 99.349% MACs, \n",
      "  (0): Sequential(\n",
      "    9.47 k, 6.591% Params, 120.42 MMac, 24.798% MACs, \n",
      "    (0): Conv2d(9.47 k, 6.591% Params, 118.82 MMac, 24.467% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.165% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.165% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 79.980% Params, 361.87 MMac, 74.517% MACs, \n",
      "    (0): Conv2d(4.16 k, 2.895% Params, 13.05 MMac, 2.686% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.041% MACs, )\n",
      "    (2): Conv2d(110.78 k, 77.085% Params, 347.42 MMac, 71.541% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.124% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.124% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    0, 0.000% Params, 150.53 KMac, 0.031% MACs, \n",
      "    (0): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.031% MACs, output_size=(1, 1))\n",
      "    (1): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (3): Linear(19.3 k, 13.429% Params, 19.3 KMac, 0.004% MACs, in_features=192, out_features=100, bias=True)\n",
      ")\n",
      "Computational complexity:       485.62 MMac\n",
      "Number of parameters:           143.72 k\n",
      "********************************************************************************************************************************************************************************************************\n",
      "The model complexity of googlenet_cmod5:\n",
      "Warning: module Inception_mod5 is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  433.05 k, 100.000% Params, 530.18 MMac, 99.339% MACs, \n",
      "  (0): Sequential(\n",
      "    9.47 k, 2.187% Params, 120.42 MMac, 22.563% MACs, \n",
      "    (0): Conv2d(9.47 k, 2.187% Params, 118.82 MMac, 22.263% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.150% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.150% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 26.543% Params, 361.87 MMac, 67.803% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.961% Params, 13.05 MMac, 2.444% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.038% MACs, )\n",
      "    (2): Conv2d(110.78 k, 25.582% Params, 347.42 MMac, 65.095% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.113% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.113% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    20.67 k, 4.774% Params, 16.31 MMac, 3.055% MACs, \n",
      "    (0): Inception_mod5(\n",
      "      12.35 k, 2.852% Params, 9.68 MMac, 1.814% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 2.852% Params, 9.68 MMac, 1.814% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod5(\n",
      "      8.32 k, 1.921% Params, 6.52 MMac, 1.222% MACs, \n",
      "      (p1_1): Conv2d(8.32 k, 1.921% Params, 6.52 MMac, 1.222% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    119.63 k, 27.625% Params, 23.5 MMac, 4.403% MACs, \n",
      "    (0): Inception_mod5(\n",
      "      24.77 k, 5.719% Params, 4.85 MMac, 0.910% MACs, \n",
      "      (p1_1): Conv2d(24.77 k, 5.719% Params, 4.85 MMac, 0.910% MACs, 128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod5(\n",
      "      30.88 k, 7.131% Params, 6.05 MMac, 1.134% MACs, \n",
      "      (p1_1): Conv2d(30.88 k, 7.131% Params, 6.05 MMac, 1.134% MACs, 192, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception_mod5(\n",
      "      20.61 k, 4.759% Params, 4.04 MMac, 0.757% MACs, \n",
      "      (p1_1): Conv2d(20.61 k, 4.759% Params, 4.04 MMac, 0.757% MACs, 160, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception_mod5(\n",
      "      14.45 k, 3.336% Params, 2.83 MMac, 0.531% MACs, \n",
      "      (p1_1): Conv2d(14.45 k, 3.336% Params, 2.83 MMac, 0.531% MACs, 128, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception_mod5(\n",
      "      28.93 k, 6.680% Params, 5.67 MMac, 1.062% MACs, \n",
      "      (p1_1): Conv2d(28.93 k, 6.680% Params, 5.67 MMac, 1.062% MACs, 112, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 50.18 KMac, 0.009% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    164.48 k, 37.982% Params, 8.08 MMac, 1.514% MACs, \n",
      "    (0): Inception_mod5(\n",
      "      65.79 k, 15.193% Params, 3.22 MMac, 0.604% MACs, \n",
      "      (p1_1): Conv2d(65.79 k, 15.193% Params, 3.22 MMac, 0.604% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod5(\n",
      "      98.69 k, 22.789% Params, 4.84 MMac, 0.906% MACs, \n",
      "      (p1_1): Conv2d(98.69 k, 22.789% Params, 4.84 MMac, 0.906% MACs, 256, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 18.82 KMac, 0.004% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(3.85 k, 0.889% Params, 3.85 KMac, 0.001% MACs, in_features=384, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       533.71 MMac\n",
      "Number of parameters:           433.05 k\n",
      "**************************************************\n",
      "The model complexity of googlenet_cmod6:\n",
      "Warning: module Inception_mod6 is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  1.32 M, 100.000% Params, 653.53 MMac, 99.385% MACs, \n",
      "  (0): Sequential(\n",
      "    9.47 k, 0.716% Params, 120.42 MMac, 18.313% MACs, \n",
      "    (0): Conv2d(9.47 k, 0.716% Params, 118.82 MMac, 18.069% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.122% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.122% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 8.686% Params, 361.87 MMac, 55.031% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.314% Params, 13.05 MMac, 1.984% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.031% MACs, )\n",
      "    (2): Conv2d(110.78 k, 8.372% Params, 347.42 MMac, 52.833% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.092% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.092% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    57.73 k, 4.362% Params, 45.46 MMac, 6.913% MACs, \n",
      "    (0): Inception_mod6(\n",
      "      24.7 k, 1.867% Params, 19.37 MMac, 2.945% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.933% Params, 9.68 MMac, 1.473% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(12.35 k, 0.933% Params, 9.68 MMac, 1.473% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod6(\n",
      "      33.02 k, 2.496% Params, 25.89 MMac, 3.937% MACs, \n",
      "      (p1_1): Conv2d(16.51 k, 1.248% Params, 12.95 MMac, 1.969% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(16.51 k, 1.248% Params, 12.95 MMac, 1.969% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 200.7 KMac, 0.031% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    476.83 k, 36.033% Params, 93.56 MMac, 14.228% MACs, \n",
      "    (0): Inception_mod6(\n",
      "      98.69 k, 7.458% Params, 19.34 MMac, 2.942% MACs, \n",
      "      (p1_1): Conv2d(49.34 k, 3.729% Params, 9.67 MMac, 1.471% MACs, 256, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(49.34 k, 3.729% Params, 9.67 MMac, 1.471% MACs, 256, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod6(\n",
      "      123.2 k, 9.310% Params, 24.15 MMac, 3.672% MACs, \n",
      "      (p1_1): Conv2d(61.6 k, 4.655% Params, 12.07 MMac, 1.836% MACs, 384, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(61.6 k, 4.655% Params, 12.07 MMac, 1.836% MACs, 384, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception_mod6(\n",
      "      82.18 k, 6.210% Params, 16.11 MMac, 2.449% MACs, \n",
      "      (p1_1): Conv2d(41.09 k, 3.105% Params, 8.05 MMac, 1.225% MACs, 320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(41.09 k, 3.105% Params, 8.05 MMac, 1.225% MACs, 320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception_mod6(\n",
      "      57.57 k, 4.350% Params, 11.28 MMac, 1.716% MACs, \n",
      "      (p1_1): Conv2d(28.78 k, 2.175% Params, 5.64 MMac, 0.858% MACs, 256, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(28.78 k, 2.175% Params, 5.64 MMac, 0.858% MACs, 256, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception_mod6(\n",
      "      115.2 k, 8.705% Params, 22.58 MMac, 3.434% MACs, \n",
      "      (p1_1): Conv2d(57.6 k, 4.353% Params, 11.29 MMac, 1.717% MACs, 224, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(57.6 k, 4.353% Params, 11.29 MMac, 1.717% MACs, 224, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.015% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    656.64 k, 49.621% Params, 32.21 MMac, 4.899% MACs, \n",
      "    (0): Inception_mod6(\n",
      "      262.66 k, 19.848% Params, 12.87 MMac, 1.957% MACs, \n",
      "      (p1_1): Conv2d(131.33 k, 9.924% Params, 6.44 MMac, 0.979% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(131.33 k, 9.924% Params, 6.44 MMac, 0.979% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod6(\n",
      "      393.98 k, 29.773% Params, 19.31 MMac, 2.936% MACs, \n",
      "      (p1_1): Conv2d(196.99 k, 14.886% Params, 9.65 MMac, 1.468% MACs, 512, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(196.99 k, 14.886% Params, 9.65 MMac, 1.468% MACs, 512, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 37.63 KMac, 0.006% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(7.69 k, 0.581% Params, 7.69 KMac, 0.001% MACs, in_features=768, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       657.58 MMac\n",
      "Number of parameters:           1.32 M  \n",
      "**************************************************\n",
      "The model complexity of googlenet_cmod7:\n",
      "Warning: module Inception_mod7 is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  2.8 M, 100.000% Params, 852.35 MMac, 99.468% MACs, \n",
      "  (0): Sequential(\n",
      "    9.47 k, 0.339% Params, 120.42 MMac, 14.053% MACs, \n",
      "    (0): Conv2d(9.47 k, 0.339% Params, 118.82 MMac, 13.866% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.094% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.094% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 4.112% Params, 361.87 MMac, 42.230% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.149% Params, 13.05 MMac, 1.522% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.023% MACs, )\n",
      "    (2): Conv2d(110.78 k, 3.963% Params, 347.42 MMac, 40.543% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.070% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.070% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    111.17 k, 3.977% Params, 87.46 MMac, 10.206% MACs, \n",
      "    (0): Inception_mod7(\n",
      "      37.06 k, 1.326% Params, 29.05 MMac, 3.390% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.442% Params, 9.68 MMac, 1.130% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(12.35 k, 0.442% Params, 9.68 MMac, 1.130% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(12.35 k, 0.442% Params, 9.68 MMac, 1.130% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod7(\n",
      "      74.11 k, 2.651% Params, 58.1 MMac, 6.781% MACs, \n",
      "      (p1_1): Conv2d(24.7 k, 0.884% Params, 19.37 MMac, 2.260% MACs, 192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(24.7 k, 0.884% Params, 19.37 MMac, 2.260% MACs, 192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(24.7 k, 0.884% Params, 19.37 MMac, 2.260% MACs, 192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 301.06 KMac, 0.035% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    1.07 M, 38.337% Params, 210.18 MMac, 24.528% MACs, \n",
      "    (0): Inception_mod7(\n",
      "      221.76 k, 7.934% Params, 43.46 MMac, 5.072% MACs, \n",
      "      (p1_1): Conv2d(73.92 k, 2.645% Params, 14.49 MMac, 1.691% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(73.92 k, 2.645% Params, 14.49 MMac, 1.691% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(73.92 k, 2.645% Params, 14.49 MMac, 1.691% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod7(\n",
      "      276.96 k, 9.908% Params, 54.28 MMac, 6.335% MACs, \n",
      "      (p1_1): Conv2d(92.32 k, 3.303% Params, 18.09 MMac, 2.112% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(92.32 k, 3.303% Params, 18.09 MMac, 2.112% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(92.32 k, 3.303% Params, 18.09 MMac, 2.112% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception_mod7(\n",
      "      184.7 k, 6.608% Params, 36.2 MMac, 4.225% MACs, \n",
      "      (p1_1): Conv2d(61.57 k, 2.203% Params, 12.07 MMac, 1.408% MACs, 480, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(61.57 k, 2.203% Params, 12.07 MMac, 1.408% MACs, 480, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(61.57 k, 2.203% Params, 12.07 MMac, 1.408% MACs, 480, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception_mod7(\n",
      "      129.36 k, 4.628% Params, 25.35 MMac, 2.959% MACs, \n",
      "      (p1_1): Conv2d(43.12 k, 1.543% Params, 8.45 MMac, 0.986% MACs, 384, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(43.12 k, 1.543% Params, 8.45 MMac, 0.986% MACs, 384, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(43.12 k, 1.543% Params, 8.45 MMac, 0.986% MACs, 384, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception_mod7(\n",
      "      258.82 k, 9.259% Params, 50.73 MMac, 5.920% MACs, \n",
      "      (p1_1): Conv2d(86.27 k, 3.086% Params, 16.91 MMac, 1.973% MACs, 336, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(86.27 k, 3.086% Params, 16.91 MMac, 1.973% MACs, 336, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(86.27 k, 3.086% Params, 16.91 MMac, 1.973% MACs, 336, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 150.53 KMac, 0.018% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    1.48 M, 52.822% Params, 72.4 MMac, 8.449% MACs, \n",
      "    (0): Inception_mod7(\n",
      "      590.59 k, 21.129% Params, 28.94 MMac, 3.377% MACs, \n",
      "      (p1_1): Conv2d(196.86 k, 7.043% Params, 9.65 MMac, 1.126% MACs, 768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(196.86 k, 7.043% Params, 9.65 MMac, 1.126% MACs, 768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(196.86 k, 7.043% Params, 9.65 MMac, 1.126% MACs, 768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod7(\n",
      "      885.89 k, 31.693% Params, 43.41 MMac, 5.066% MACs, \n",
      "      (p1_1): Conv2d(295.3 k, 10.564% Params, 14.47 MMac, 1.689% MACs, 768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(295.3 k, 10.564% Params, 14.47 MMac, 1.689% MACs, 768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(295.3 k, 10.564% Params, 14.47 MMac, 1.689% MACs, 768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 56.45 KMac, 0.007% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(11.53 k, 0.412% Params, 11.53 KMac, 0.001% MACs, in_features=1152, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       856.91 MMac\n",
      "Number of parameters:           2.8 M   \n",
      "**************************************************\n",
      "The model complexity of googlenet_cmod8:\n",
      "Warning: module Inception_mod8 is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  4.85 M, 100.000% Params, 1.13 GMac, 99.551% MACs, \n",
      "  (0): Sequential(\n",
      "    9.47 k, 0.195% Params, 120.42 MMac, 10.641% MACs, \n",
      "    (0): Conv2d(9.47 k, 0.195% Params, 118.82 MMac, 10.499% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.071% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.071% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 2.371% Params, 361.87 MMac, 31.975% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.086% Params, 13.05 MMac, 1.153% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.018% MACs, )\n",
      "    (2): Conv2d(110.78 k, 2.285% Params, 347.42 MMac, 30.699% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.053% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.053% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    180.99 k, 3.733% Params, 142.3 MMac, 12.574% MACs, \n",
      "    (0): Inception_mod8(\n",
      "      49.41 k, 1.019% Params, 38.74 MMac, 3.423% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.255% Params, 9.68 MMac, 0.856% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(12.35 k, 0.255% Params, 9.68 MMac, 0.856% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(12.35 k, 0.255% Params, 9.68 MMac, 0.856% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(12.35 k, 0.255% Params, 9.68 MMac, 0.856% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod8(\n",
      "      131.58 k, 2.714% Params, 103.16 MMac, 9.116% MACs, \n",
      "      (p1_1): Conv2d(32.9 k, 0.678% Params, 25.79 MMac, 2.279% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(32.9 k, 0.678% Params, 25.79 MMac, 2.279% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(32.9 k, 0.678% Params, 25.79 MMac, 2.279% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(32.9 k, 0.678% Params, 25.79 MMac, 2.279% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 401.41 KMac, 0.035% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    1.9 M, 39.267% Params, 373.37 MMac, 32.992% MACs, \n",
      "    (0): Inception_mod8(\n",
      "      393.98 k, 8.126% Params, 77.22 MMac, 6.823% MACs, \n",
      "      (p1_1): Conv2d(98.5 k, 2.031% Params, 19.31 MMac, 1.706% MACs, 512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(98.5 k, 2.031% Params, 19.31 MMac, 1.706% MACs, 512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(98.5 k, 2.031% Params, 19.31 MMac, 1.706% MACs, 512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(98.5 k, 2.031% Params, 19.31 MMac, 1.706% MACs, 512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod8(\n",
      "      492.16 k, 10.150% Params, 96.46 MMac, 8.524% MACs, \n",
      "      (p1_1): Conv2d(123.04 k, 2.538% Params, 24.12 MMac, 2.131% MACs, 768, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(123.04 k, 2.538% Params, 24.12 MMac, 2.131% MACs, 768, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(123.04 k, 2.538% Params, 24.12 MMac, 2.131% MACs, 768, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(123.04 k, 2.538% Params, 24.12 MMac, 2.131% MACs, 768, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception_mod8(\n",
      "      328.19 k, 6.769% Params, 64.33 MMac, 5.684% MACs, \n",
      "      (p1_1): Conv2d(82.05 k, 1.692% Params, 16.08 MMac, 1.421% MACs, 640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(82.05 k, 1.692% Params, 16.08 MMac, 1.421% MACs, 640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(82.05 k, 1.692% Params, 16.08 MMac, 1.421% MACs, 640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(82.05 k, 1.692% Params, 16.08 MMac, 1.421% MACs, 640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception_mod8(\n",
      "      229.82 k, 4.740% Params, 45.05 MMac, 3.980% MACs, \n",
      "      (p1_1): Conv2d(57.46 k, 1.185% Params, 11.26 MMac, 0.995% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(57.46 k, 1.185% Params, 11.26 MMac, 0.995% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(57.46 k, 1.185% Params, 11.26 MMac, 0.995% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(57.46 k, 1.185% Params, 11.26 MMac, 0.995% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception_mod8(\n",
      "      459.78 k, 9.482% Params, 90.12 MMac, 7.963% MACs, \n",
      "      (p1_1): Conv2d(114.94 k, 2.371% Params, 22.53 MMac, 1.991% MACs, 448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(114.94 k, 2.371% Params, 22.53 MMac, 1.991% MACs, 448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(114.94 k, 2.371% Params, 22.53 MMac, 1.991% MACs, 448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(114.94 k, 2.371% Params, 22.53 MMac, 1.991% MACs, 448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 200.7 KMac, 0.018% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    2.62 M, 54.117% Params, 128.65 MMac, 11.368% MACs, \n",
      "    (0): Inception_mod8(\n",
      "      1.05 M, 21.647% Params, 51.43 MMac, 4.544% MACs, \n",
      "      (p1_1): Conv2d(262.4 k, 5.412% Params, 12.86 MMac, 1.136% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(262.4 k, 5.412% Params, 12.86 MMac, 1.136% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(262.4 k, 5.412% Params, 12.86 MMac, 1.136% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(262.4 k, 5.412% Params, 12.86 MMac, 1.136% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception_mod8(\n",
      "      1.57 M, 32.470% Params, 77.15 MMac, 6.817% MACs, \n",
      "      (p1_1): Conv2d(393.6 k, 8.118% Params, 19.29 MMac, 1.704% MACs, 1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(393.6 k, 8.118% Params, 19.29 MMac, 1.704% MACs, 1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_1): Conv2d(393.6 k, 8.118% Params, 19.29 MMac, 1.704% MACs, 1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p4_1): Conv2d(393.6 k, 8.118% Params, 19.29 MMac, 1.704% MACs, 1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.007% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(15.37 k, 0.317% Params, 15.37 KMac, 0.001% MACs, in_features=1536, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       1.13 GMac\n",
      "Number of parameters:           4.85 M  \n",
      "**************************************************\n",
      "The model complexity of googlenet_cmod9:\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  126.35 k, 100.000% Params, 482.44 MMac, 99.349% MACs, \n",
      "  (0): Sequential(\n",
      "    9.47 k, 7.497% Params, 120.42 MMac, 24.798% MACs, \n",
      "    (0): Conv2d(9.47 k, 7.497% Params, 118.82 MMac, 24.468% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.165% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.165% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 90.976% Params, 361.87 MMac, 74.519% MACs, \n",
      "    (0): Conv2d(4.16 k, 3.293% Params, 13.05 MMac, 2.686% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.041% MACs, )\n",
      "    (2): Conv2d(110.78 k, 87.683% Params, 347.42 MMac, 71.543% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.124% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.124% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    0, 0.000% Params, 150.53 KMac, 0.031% MACs, \n",
      "    (0): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.031% MACs, output_size=(1, 1))\n",
      "    (1): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (3): Linear(1.93 k, 1.528% Params, 1.93 KMac, 0.000% MACs, in_features=192, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       485.61 MMac\n",
      "Number of parameters:           126.35 k\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fashion mnist\n",
    "print('The model complexity of googlenet_fmod5:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_f, params_f = get_model_complexity_info(googlenet_fmod5, (1, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_f))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_f))\n",
    "\n",
    "print('*'*50)\n",
    "print('The model complexity of googlenet_fmod6:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_f, params_f = get_model_complexity_info(googlenet_fmod6, (1, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_f))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_f))\n",
    "    \n",
    "print('*'*50)\n",
    "print('The model complexity of googlenet_fmod7:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_f, params_f = get_model_complexity_info(googlenet_fmod7, (1, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_f))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_f))\n",
    "    \n",
    "print('*'*50)\n",
    "print('The model complexity of googlenet_fmod8:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_f, params_f = get_model_complexity_info(googlenet_fmod8, (1, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_f))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_f))\n",
    "\n",
    "print('*'*50)\n",
    "print('The model complexity of googlenet_fmod9:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_f, params_f = get_model_complexity_info(googlenet_fmod9, (1, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_f))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_f))\n",
    "\n",
    "print('*'*200)\n",
    "# cifar100\n",
    "print('The model complexity of googlenet_cmod5:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_c, params_c = get_model_complexity_info(googlenet_cmod5, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_c))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_c))\n",
    "\n",
    "print('*'*50)\n",
    "print('The model complexity of googlenet_cmod6:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_c, params_c = get_model_complexity_info(googlenet_cmod6, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_c))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_c))\n",
    "    \n",
    "print('*'*50)\n",
    "print('The model complexity of googlenet_cmod7:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_c, params_c = get_model_complexity_info(googlenet_cmod7, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_c))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_c))\n",
    "    \n",
    "print('*'*50)\n",
    "print('The model complexity of googlenet_cmod8:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_c, params_c = get_model_complexity_info(googlenet_cmod8, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_c))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_c))\n",
    "    \n",
    "print('*'*50)\n",
    "print('The model complexity of googlenet_cmod9:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_c, params_c = get_model_complexity_info(googlenet_cmod9, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_c))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_c))\n",
    "    \n",
    "print('*'*200)\n",
    "# cifar100\n",
    "print('The model complexity of googlenet_cmod5:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_c10, params_c10 = get_model_complexity_info(googlenet_c10mod5, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_c10))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_c10))\n",
    "\n",
    "print('*'*50)\n",
    "print('The model complexity of googlenet_cmod6:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_c10, params_c10 = get_model_complexity_info(googlenet_c10mod6, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_c10))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_c10))\n",
    "    \n",
    "print('*'*50)\n",
    "print('The model complexity of googlenet_cmod7:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_c10, params_c10 = get_model_complexity_info(googlenet_c10mod7, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_c10))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_c10))\n",
    "    \n",
    "print('*'*50)\n",
    "print('The model complexity of googlenet_cmod8:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_c10, params_c10 = get_model_complexity_info(googlenet_c10mod8, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_c10))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_c10))\n",
    "    \n",
    "print('*'*50)\n",
    "print('The model complexity of googlenet_cmod9:')\n",
    "with torch.cuda.device(0):\n",
    "    macs_c10, params_c10 = get_model_complexity_info(googlenet_c10mod9, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_c10))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_c10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 192, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 256, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "Sequential output shape:\t torch.Size([1, 768])\n",
      "Linear output shape:\t torch.Size([1, 10])\n",
      "**************************************************\n",
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 192, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 256, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "Sequential output shape:\t torch.Size([1, 768])\n",
      "Linear output shape:\t torch.Size([1, 100])\n",
      "**************************************************\n",
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 192, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 256, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "Sequential output shape:\t torch.Size([1, 768])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X_f = torch.randn(size=(1, 1, 224, 224), dtype=torch.float32) # fashion mnist\n",
    "X_c = torch.randn(size=(1, 3, 224, 224), dtype=torch.float32) # cifar100\n",
    "X_c10 = torch.randn(size=(1, 3, 224, 224), dtype=torch.float32) # cifar100\n",
    "\n",
    "\n",
    "for layer in googlenet_fmod6:\n",
    "    X_f=layer(X_f)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X_f.shape)\n",
    "\n",
    "print('*'*50)\n",
    "\n",
    "for layer in googlenet_cmod6:\n",
    "    X_c=layer(X_c)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X_c.shape)\n",
    "    \n",
    "print('*'*50)\n",
    "\n",
    "for layer in googlenet_c10mod6:\n",
    "    X_c10=layer(X_c10)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X_c10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# fashion mnist\n",
    "def get_dataloader_workers():\n",
    "    \"\"\"Use 4 processes to read the data.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    return 4\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\n",
    "\n",
    "    Defined in :numref:`sec_fashion_mnist`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=get_dataloader_workers()))\n",
    "\n",
    "def load_data_cifar100(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    # import the cifar100 dataset\n",
    "    cifar_train = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    cifar_test = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(cifar_train, batch_size, shuffle=True,\n",
    "                                        num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(cifar_test, batch_size, shuffle=False,\n",
    "                                        num_workers=get_dataloader_workers()))\n",
    "    \n",
    "def load_data_cifar10(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    # import the cifar100 dataset\n",
    "    cifar_train = torchvision.datasets.CIFAR10(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    cifar_test = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(cifar_train, batch_size, shuffle=True,\n",
    "                                        num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(cifar_test, batch_size, shuffle=False,\n",
    "                                        num_workers=get_dataloader_workers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = [128, 256, 512]\n",
    "batch_size = [256]\n",
    "# epochs = [10, 20, 30, 40, 50]\n",
    "epochs = [20]\n",
    "rounds = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(net, train_iter, test_iter, LayerName, num_epochs, lr, device):\n",
    "    def init_weights(m): # 初始化权重\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    # record each block running time\n",
    "    Layers_time = np.zeros((len(LayerName), num_epochs)) # each row is a layer, each column is an epoch\n",
    "    Train_part_time = np.zeros((4, num_epochs)) # store the time to device, forward and backward time, and test time of each epoch\n",
    "    Train_acc = np.zeros(num_epochs) # store the training accuracy of each epoch\n",
    "    Test_acc = np.zeros(num_epochs) # store the test accuracy of each epoch\n",
    "    Epoch_time = np.zeros(num_epochs) # store the total time of each epoch\n",
    "    Epoch_energy = np.zeros((num_epochs,1), dtype='object') # store the total energy of each epoch\n",
    "    timer = d2l.Timer()\n",
    "    train_timer = d2l.Timer()\n",
    "    ttd_timer = d2l.Timer()\n",
    "    forward_timer = d2l.Timer()\n",
    "    backward_timer = d2l.Timer()\n",
    "    layer_timer = d2l.Timer()\n",
    "    test_timer = d2l.Timer()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    # start training\n",
    "    for epoch in range(num_epochs):\n",
    "        print('The epoch is:', epoch+1)\n",
    "        timer.start()\n",
    "        net.train()\n",
    "        ttd_epoch, forward_epoch, backward_epoch, testtime_epoch= 0.0, 0.0, 0.0, 0.0\n",
    "        layer_epoch = np.zeros((len(LayerName), 1)) # store the total running time of each layer in one epoch\n",
    "        metric = d2l.Accumulator(3)  # train_loss, train_acc, num_examples   \n",
    "        # start the nvidia-smi command\n",
    "        with open('gpu_power_usage.csv', 'w') as file:\n",
    "            # Start the nvidia-smi command\n",
    "            nvidia_smi_process = subprocess.Popen(\n",
    "                [\"nvidia-smi\", \"--query-gpu=power.draw\", \"--format=csv\", \"--loop-ms=1000\"],\n",
    "                stdout=file,  # Redirect the output directly to the file\n",
    "                stderr=subprocess.PIPE,\n",
    "                text=True)\n",
    "        train_timer.start()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            batch_block_num = 0\n",
    "            print('The batch is:', i+1)\n",
    "            optimizer.zero_grad()\n",
    "            # to device\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            ttd_timer.start()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            ttd_epoch += ttd_timer.stop()\n",
    "            # forward\n",
    "            forward_timer.start()\n",
    "            y_hat = X\n",
    "            for num, layer in net.named_children():\n",
    "                layername = layer.__class__.__name__\n",
    "                if layername == 'Sequential':\n",
    "                    for sublayernum, sublayer in layer.named_children():\n",
    "                        sublayername = sublayer.__class__.__name__\n",
    "                        Layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}'\n",
    "                        layer_index = LayerName.index(Layer_label)\n",
    "                        # print('The layer index is:', layer_index, 'The layer label is:', Layer_label)\n",
    "                        layer_timer.start()\n",
    "                        y_hat = sublayer(y_hat)\n",
    "                        torch.cuda.synchronize()\n",
    "                        layer_epoch[layer_index] += layer_timer.stop()\n",
    "            torch.cuda.synchronize()\n",
    "            forward_epoch += forward_timer.stop()\n",
    "            # loss\n",
    "            l = loss_fn(y_hat, y)\n",
    "            # backward\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            backward_timer.start()\n",
    "            l.backward()\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            backward_epoch += backward_timer.stop()\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            with torch.no_grad():\n",
    "                metric.add(l*X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            train_acc = metric[1] / metric[2]\n",
    "        train_epoch = train_timer.stop()\n",
    "        test_timer.start()\n",
    "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n",
    "        testtime_epoch = test_timer.stop()\n",
    "        print(f'train acc {train_acc:.3f}, test acc {test_acc:.3f}')\n",
    "        print('epoch %d, time %f sec' % (epoch+1, timer.sum()))\n",
    "        # store the time and acc data\n",
    "        Epoch_time[epoch] = timer.stop()\n",
    "        print(f'The total time of the {epoch} is:', Epoch_time[epoch])\n",
    "        Layers_time[:, epoch] = layer_epoch.flatten()\n",
    "        Train_part_time[:, epoch] = ttd_epoch, forward_epoch, backward_epoch, testtime_epoch\n",
    "        print(ttd_epoch, forward_epoch, backward_epoch, testtime_epoch)\n",
    "        Train_acc[epoch] = train_acc\n",
    "        Test_acc[epoch] = test_acc\n",
    "        # stop the nvidia-smi command\n",
    "        nvidia_smi_process.terminate()\n",
    "        # calculate the energy consumption of each epoch\n",
    "        GPU_df = pd.read_csv('gpu_power_usage.csv')\n",
    "        for row in range(len(GPU_df)):\n",
    "            GPU_df.iloc[row,0] = GPU_df.iloc[row,0].replace(' W','')\n",
    "        Consumption_df = GPU_df.astype(float)  \n",
    "        EnergyDatai = Consumption_df.iloc[:,0].values # 将数据转换为numpy数组\n",
    "        # store the energy data\n",
    "        Epoch_energy[epoch,0] = EnergyDatai\n",
    "    return Layers_time, Train_part_time, Train_acc, Test_acc, Epoch_time, Epoch_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_f(main_folder, batch_size, num_epochs, round, lr, device, LayerName, model_f):\n",
    "    print(f'The epoch is set: {num_epochs}, batch is set: {batch_size}, is in {round+1}th running')\n",
    "    # create the folder to store the data\n",
    "    epoch_batch_folder = main_folder/f'E{num_epochs}_B{batch_size}_R{round}'\n",
    "    # 判断文件是否存在\n",
    "    if epoch_batch_folder.exists():\n",
    "        print(\"文件存在。\")\n",
    "    else:\n",
    "        os.makedirs(epoch_batch_folder)\n",
    "        print(\"文件不存在，已创建。\")\n",
    "        print(\"文件创建于：\", epoch_batch_folder)\n",
    "    train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n",
    "    # show the shape of the data\n",
    "    list_of_i = []\n",
    "    for i, (X, y) in enumerate(train_iter):\n",
    "        if i < 3:\n",
    "            print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "        else:\n",
    "            pass\n",
    "        list_of_i.append(i)\n",
    "    print(f'The number of batches is: {np.array(list_of_i).shape}')\n",
    "    Layers_time, Train_part_time, Train_acc, Test_acc, \\\n",
    "        Epoch_time, Epoch_energy = train_func(model_f, train_iter, test_iter, LayerName, num_epochs, lr, device)\n",
    "    # save the data\n",
    "    np.save(epoch_batch_folder/'Layers_time.npy', Layers_time)\n",
    "    np.save(epoch_batch_folder/'Train_part_time.npy', Train_part_time)\n",
    "    np.save(epoch_batch_folder/'Train_acc.npy', Train_acc)\n",
    "    np.save(epoch_batch_folder/'Test_acc.npy', Test_acc)\n",
    "    np.save(epoch_batch_folder/'Epoch_time.npy', Epoch_time)\n",
    "    np.save(epoch_batch_folder/'Epoch_energy.npy', Epoch_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_c(main_folder, batch_size, num_epochs, round, lr, device, LayerName, model_c):\n",
    "    print(f'The epoch is set: {num_epochs}, batch is set: {batch_size}, is in {round+1}th running')\n",
    "    # create the folder to store the data\n",
    "    epoch_batch_folder = main_folder/f'E{num_epochs}_B{batch_size}_R{round}'\n",
    "    # 判断文件是否存在\n",
    "    if epoch_batch_folder.exists():\n",
    "        print(\"文件存在。\")\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(epoch_batch_folder)\n",
    "        print(\"文件不存在，已创建。\")\n",
    "        print(\"文件创建于：\", epoch_batch_folder)\n",
    "        train_iter, test_iter = load_data_cifar100(batch_size, resize=224)\n",
    "        # show the shape of the data\n",
    "        list_of_i = []\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            if i < 3:\n",
    "                print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "            else:\n",
    "                pass\n",
    "            list_of_i.append(i)\n",
    "        print(f'The number of batches is: {np.array(list_of_i).shape}')\n",
    "        Layers_time, Train_part_time, Train_acc, Test_acc, \\\n",
    "            Epoch_time, Epoch_energy = train_func(model_c, train_iter, test_iter, LayerName, num_epochs, lr, device)\n",
    "        # save the data\n",
    "        np.save(epoch_batch_folder/'Layers_time.npy', Layers_time)\n",
    "        np.save(epoch_batch_folder/'Train_part_time.npy', Train_part_time)\n",
    "        np.save(epoch_batch_folder/'Train_acc.npy', Train_acc)\n",
    "        np.save(epoch_batch_folder/'Test_acc.npy', Test_acc)\n",
    "        np.save(epoch_batch_folder/'Epoch_time.npy', Epoch_time)\n",
    "        np.save(epoch_batch_folder/'Epoch_energy.npy', Epoch_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_c10(main_folder, batch_size, num_epochs, round, lr, device, LayerName, model_c):\n",
    "    print(f'The epoch is set: {num_epochs}, batch is set: {batch_size}, is in {round+1}th running')\n",
    "    # create the folder to store the data\n",
    "    epoch_batch_folder = main_folder/f'E{num_epochs}_B{batch_size}_R{round}'\n",
    "    # 判断文件是否存在\n",
    "    if epoch_batch_folder.exists():\n",
    "        print(\"文件存在。\")\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(epoch_batch_folder)\n",
    "        print(\"文件不存在，已创建。\")\n",
    "        print(\"文件创建于：\", epoch_batch_folder)\n",
    "        train_iter, test_iter = load_data_cifar10(batch_size, resize=224)\n",
    "        # show the shape of the data\n",
    "        list_of_i = []\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            if i < 3:\n",
    "                print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "            else:\n",
    "                pass\n",
    "            list_of_i.append(i)\n",
    "        print(f'The number of batches is: {np.array(list_of_i).shape}')\n",
    "        Layers_time, Train_part_time, Train_acc, Test_acc, \\\n",
    "            Epoch_time, Epoch_energy = train_func(model_c, train_iter, test_iter, LayerName, num_epochs, lr, device)\n",
    "        # save the data\n",
    "        np.save(epoch_batch_folder/'Layers_time.npy', Layers_time)\n",
    "        np.save(epoch_batch_folder/'Train_part_time.npy', Train_part_time)\n",
    "        np.save(epoch_batch_folder/'Train_acc.npy', Train_acc)\n",
    "        np.save(epoch_batch_folder/'Test_acc.npy', Test_acc)\n",
    "        np.save(epoch_batch_folder/'Epoch_time.npy', Epoch_time)\n",
    "        np.save(epoch_batch_folder/'Epoch_energy.npy', Epoch_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is: cuda\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('The device is:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (3): Linear(in_features=192, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googlenet_fmod5\n",
    "googlenet_fmod6\n",
    "googlenet_fmod7\n",
    "googlenet_fmod8\n",
    "googlenet_fmod9\n",
    "# CIFAR100中的\n",
    "googlenet_cmod5\n",
    "googlenet_cmod6\n",
    "googlenet_cmod7\n",
    "googlenet_cmod8\n",
    "googlenet_cmod9\n",
    "# CIFAR10中的\n",
    "googlenet_c10mod5\n",
    "googlenet_c10mod6\n",
    "googlenet_c10mod7\n",
    "googlenet_c10mod8\n",
    "googlenet_c10mod9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current path is: /root/GreenAI/Cloud/4090/code\n",
      "The parent path is: /root/GreenAI/Cloud/4090\n",
      "The data path is: /root/GreenAI/Cloud/4090/Data/googlenet_mod9_mod1\n",
      "The folder is: /root/GreenAI/Cloud/4090/Data/googlenet_mod9_mod1/cifar10\n",
      "文件存在。\n",
      "The epoch is set: 20, batch is set: 256, is in 1th running\n",
      "文件不存在，已创建。\n",
      "文件创建于： /root/GreenAI/Cloud/4090/Data/googlenet_mod9_mod1/cifar10/E20_B256_R0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "the shape of the 0 batch of the train_iter is: torch.Size([256, 3, 224, 224])\n",
      "the shape of the 1 batch of the train_iter is: torch.Size([256, 3, 224, 224])\n",
      "the shape of the 2 batch of the train_iter is: torch.Size([256, 3, 224, 224])\n",
      "The number of batches is: (196,)\n",
      "training on cuda\n",
      "The epoch is: 1\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.105, test acc 0.010\n",
      "epoch 1, time 0.000000 sec\n",
      "The total time of the 0 is: 27.38161563873291\n",
      "5.243021488189697 3.0931284427642822 5.622734308242798 5.419660329818726\n",
      "The epoch is: 2\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.117, test acc 0.010\n",
      "epoch 2, time 27.381616 sec\n",
      "The total time of the 1 is: 27.487846851348877\n",
      "5.357106685638428 3.095659017562866 5.6138832569122314 5.359977960586548\n",
      "The epoch is: 3\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.144, test acc 0.010\n",
      "epoch 3, time 54.869462 sec\n",
      "The total time of the 2 is: 26.963761806488037\n",
      "5.360964059829712 3.100646734237671 5.629806280136108 4.90451979637146\n",
      "The epoch is: 4\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.172, test acc 0.010\n",
      "epoch 4, time 81.833224 sec\n",
      "The total time of the 3 is: 26.916113138198853\n",
      "5.218380451202393 3.0953712463378906 5.623104572296143 5.631039381027222\n",
      "The epoch is: 5\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.185, test acc 0.010\n",
      "epoch 5, time 108.749337 sec\n",
      "The total time of the 4 is: 26.458794116973877\n",
      "5.330309152603149 3.095231056213379 5.624558925628662 4.899638891220093\n",
      "The epoch is: 6\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.190, test acc 0.010\n",
      "epoch 6, time 135.208132 sec\n",
      "The total time of the 5 is: 27.263440132141113\n",
      "5.373773097991943 3.095404863357544 5.630882501602173 5.24117112159729\n",
      "The epoch is: 7\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.191, test acc 0.011\n",
      "epoch 7, time 162.471572 sec\n",
      "The total time of the 6 is: 27.55338740348816\n",
      "5.510261535644531 3.1085634231567383 5.619337558746338 5.19746732711792\n",
      "The epoch is: 8\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.198, test acc 0.010\n",
      "epoch 8, time 190.024959 sec\n",
      "The total time of the 7 is: 28.21015429496765\n",
      "5.641399621963501 3.1074564456939697 5.62543249130249 5.258725881576538\n",
      "The epoch is: 9\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.199, test acc 0.010\n",
      "epoch 9, time 218.235113 sec\n",
      "The total time of the 8 is: 27.994012594223022\n",
      "5.36580228805542 3.1015379428863525 5.627966403961182 5.282952070236206\n",
      "The epoch is: 10\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.202, test acc 0.010\n",
      "epoch 10, time 246.229126 sec\n",
      "The total time of the 9 is: 27.928972959518433\n",
      "5.433409690856934 3.102999210357666 5.6307594776153564 5.232658386230469\n",
      "The epoch is: 11\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.205, test acc 0.011\n",
      "epoch 11, time 274.158099 sec\n",
      "The total time of the 10 is: 28.25476336479187\n",
      "5.343551158905029 3.1057333946228027 5.622754335403442 5.372145175933838\n",
      "The epoch is: 12\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.206, test acc 0.010\n",
      "epoch 12, time 302.412862 sec\n",
      "The total time of the 11 is: 27.256262063980103\n",
      "5.285199880599976 3.0960447788238525 5.626611232757568 4.97835111618042\n",
      "The epoch is: 13\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.211, test acc 0.010\n",
      "epoch 13, time 329.669124 sec\n",
      "The total time of the 12 is: 28.062642812728882\n",
      "5.591884613037109 3.0959677696228027 5.612561941146851 5.317006826400757\n",
      "The epoch is: 14\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.212, test acc 0.010\n",
      "epoch 14, time 357.731767 sec\n",
      "The total time of the 13 is: 28.493659496307373\n",
      "5.808843612670898 3.1006743907928467 5.6279685497283936 5.420834064483643\n",
      "The epoch is: 15\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.216, test acc 0.010\n",
      "epoch 15, time 386.225427 sec\n",
      "The total time of the 14 is: 30.10857605934143\n",
      "6.3334784507751465 3.1102168560028076 5.641066789627075 5.738651275634766\n",
      "The epoch is: 16\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.217, test acc 0.010\n",
      "epoch 16, time 416.334003 sec\n",
      "The total time of the 15 is: 29.119324445724487\n",
      "6.319111585617065 3.109367847442627 5.636980056762695 5.339904546737671\n",
      "The epoch is: 17\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.220, test acc 0.010\n",
      "epoch 17, time 445.453327 sec\n",
      "The total time of the 16 is: 29.012147903442383\n",
      "6.177306652069092 3.113206386566162 5.616774320602417 5.15130877494812\n",
      "The epoch is: 18\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.223, test acc 0.011\n",
      "epoch 18, time 474.465475 sec\n",
      "The total time of the 17 is: 27.67248225212097\n",
      "5.722450494766235 3.1054270267486572 5.626835584640503 5.129143476486206\n",
      "The epoch is: 19\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.227, test acc 0.011\n",
      "epoch 19, time 502.137957 sec\n",
      "The total time of the 18 is: 28.358904123306274\n",
      "5.961118221282959 3.111464500427246 5.634087562561035 5.2453460693359375\n",
      "The epoch is: 20\n",
      "The batch is: 1\n",
      "The batch is: 2\n",
      "The batch is: 3\n",
      "The batch is: 4\n",
      "The batch is: 5\n",
      "The batch is: 6\n",
      "The batch is: 7\n",
      "The batch is: 8\n",
      "The batch is: 9\n",
      "The batch is: 10\n",
      "The batch is: 11\n",
      "The batch is: 12\n",
      "The batch is: 13\n",
      "The batch is: 14\n",
      "The batch is: 15\n",
      "The batch is: 16\n",
      "The batch is: 17\n",
      "The batch is: 18\n",
      "The batch is: 19\n",
      "The batch is: 20\n",
      "The batch is: 21\n",
      "The batch is: 22\n",
      "The batch is: 23\n",
      "The batch is: 24\n",
      "The batch is: 25\n",
      "The batch is: 26\n",
      "The batch is: 27\n",
      "The batch is: 28\n",
      "The batch is: 29\n",
      "The batch is: 30\n",
      "The batch is: 31\n",
      "The batch is: 32\n",
      "The batch is: 33\n",
      "The batch is: 34\n",
      "The batch is: 35\n",
      "The batch is: 36\n",
      "The batch is: 37\n",
      "The batch is: 38\n",
      "The batch is: 39\n",
      "The batch is: 40\n",
      "The batch is: 41\n",
      "The batch is: 42\n",
      "The batch is: 43\n",
      "The batch is: 44\n",
      "The batch is: 45\n",
      "The batch is: 46\n",
      "The batch is: 47\n",
      "The batch is: 48\n",
      "The batch is: 49\n",
      "The batch is: 50\n",
      "The batch is: 51\n",
      "The batch is: 52\n",
      "The batch is: 53\n",
      "The batch is: 54\n",
      "The batch is: 55\n",
      "The batch is: 56\n",
      "The batch is: 57\n",
      "The batch is: 58\n",
      "The batch is: 59\n",
      "The batch is: 60\n",
      "The batch is: 61\n",
      "The batch is: 62\n",
      "The batch is: 63\n",
      "The batch is: 64\n",
      "The batch is: 65\n",
      "The batch is: 66\n",
      "The batch is: 67\n",
      "The batch is: 68\n",
      "The batch is: 69\n",
      "The batch is: 70\n",
      "The batch is: 71\n",
      "The batch is: 72\n",
      "The batch is: 73\n",
      "The batch is: 74\n",
      "The batch is: 75\n",
      "The batch is: 76\n",
      "The batch is: 77\n",
      "The batch is: 78\n",
      "The batch is: 79\n",
      "The batch is: 80\n",
      "The batch is: 81\n",
      "The batch is: 82\n",
      "The batch is: 83\n",
      "The batch is: 84\n",
      "The batch is: 85\n",
      "The batch is: 86\n",
      "The batch is: 87\n",
      "The batch is: 88\n",
      "The batch is: 89\n",
      "The batch is: 90\n",
      "The batch is: 91\n",
      "The batch is: 92\n",
      "The batch is: 93\n",
      "The batch is: 94\n",
      "The batch is: 95\n",
      "The batch is: 96\n",
      "The batch is: 97\n",
      "The batch is: 98\n",
      "The batch is: 99\n",
      "The batch is: 100\n",
      "The batch is: 101\n",
      "The batch is: 102\n",
      "The batch is: 103\n",
      "The batch is: 104\n",
      "The batch is: 105\n",
      "The batch is: 106\n",
      "The batch is: 107\n",
      "The batch is: 108\n",
      "The batch is: 109\n",
      "The batch is: 110\n",
      "The batch is: 111\n",
      "The batch is: 112\n",
      "The batch is: 113\n",
      "The batch is: 114\n",
      "The batch is: 115\n",
      "The batch is: 116\n",
      "The batch is: 117\n",
      "The batch is: 118\n",
      "The batch is: 119\n",
      "The batch is: 120\n",
      "The batch is: 121\n",
      "The batch is: 122\n",
      "The batch is: 123\n",
      "The batch is: 124\n",
      "The batch is: 125\n",
      "The batch is: 126\n",
      "The batch is: 127\n",
      "The batch is: 128\n",
      "The batch is: 129\n",
      "The batch is: 130\n",
      "The batch is: 131\n",
      "The batch is: 132\n",
      "The batch is: 133\n",
      "The batch is: 134\n",
      "The batch is: 135\n",
      "The batch is: 136\n",
      "The batch is: 137\n",
      "The batch is: 138\n",
      "The batch is: 139\n",
      "The batch is: 140\n",
      "The batch is: 141\n",
      "The batch is: 142\n",
      "The batch is: 143\n",
      "The batch is: 144\n",
      "The batch is: 145\n",
      "The batch is: 146\n",
      "The batch is: 147\n",
      "The batch is: 148\n",
      "The batch is: 149\n",
      "The batch is: 150\n",
      "The batch is: 151\n",
      "The batch is: 152\n",
      "The batch is: 153\n",
      "The batch is: 154\n",
      "The batch is: 155\n",
      "The batch is: 156\n",
      "The batch is: 157\n",
      "The batch is: 158\n",
      "The batch is: 159\n",
      "The batch is: 160\n",
      "The batch is: 161\n",
      "The batch is: 162\n",
      "The batch is: 163\n",
      "The batch is: 164\n",
      "The batch is: 165\n",
      "The batch is: 166\n",
      "The batch is: 167\n",
      "The batch is: 168\n",
      "The batch is: 169\n",
      "The batch is: 170\n",
      "The batch is: 171\n",
      "The batch is: 172\n",
      "The batch is: 173\n",
      "The batch is: 174\n",
      "The batch is: 175\n",
      "The batch is: 176\n",
      "The batch is: 177\n",
      "The batch is: 178\n",
      "The batch is: 179\n",
      "The batch is: 180\n",
      "The batch is: 181\n",
      "The batch is: 182\n",
      "The batch is: 183\n",
      "The batch is: 184\n",
      "The batch is: 185\n",
      "The batch is: 186\n",
      "The batch is: 187\n",
      "The batch is: 188\n",
      "The batch is: 189\n",
      "The batch is: 190\n",
      "The batch is: 191\n",
      "The batch is: 192\n",
      "The batch is: 193\n",
      "The batch is: 194\n",
      "The batch is: 195\n",
      "The batch is: 196\n",
      "train acc 0.231, test acc 0.010\n",
      "epoch 20, time 530.496861 sec\n",
      "The total time of the 19 is: 28.40501117706299\n",
      "5.81327748298645 3.113684892654419 5.633807182312012 5.46147346496582\n"
     ]
    }
   ],
   "source": [
    "'''find the Model path'''\n",
    "# find the current path\n",
    "current_path = os.getcwd()\n",
    "print('The current path is:', current_path)\n",
    "\n",
    "# find the parent path\n",
    "parent_path = Path(current_path).parent\n",
    "print('The parent path is:', parent_path)\n",
    "\n",
    "pathnum = [9]\n",
    "# find the data path\n",
    "for i in pathnum:\n",
    "    data_path = parent_path / f'Data/googlenet_mod{i}_mod1'\n",
    "    print('The data path is:', data_path)\n",
    "    if i == 5:\n",
    "        # model_f = googlenet_fmod5\n",
    "        # model_c = googlenet_cmod5\n",
    "        model_c10 = googlenet_c10mod5\n",
    "    elif i == 6:\n",
    "        # model_f = googlenet_fmod6\n",
    "        # model_c = googlenet_cmod6\n",
    "        model_c10 = googlenet_c10mod6\n",
    "    elif i == 7:\n",
    "        # model_f = googlenet_fmod7\n",
    "        # model_c = googlenet_cmod7\n",
    "        model_c10 = googlenet_c10mod7\n",
    "    elif i == 8:\n",
    "        # model_f = googlenet_fmod8\n",
    "        # model_c = googlenet_cmod8\n",
    "        model_c10 = googlenet_c10mod8\n",
    "    elif i == 9:\n",
    "        # model_f = googlenet_fmod9\n",
    "        # model_c = googlenet_cmod9\n",
    "        model_c10 = googlenet_c10mod9\n",
    "    # train the model\n",
    "    ##########################################################\n",
    "    # # Fashion-MNIST\n",
    "    # # create the folder to store the data\n",
    "    # main_folder = data_path/'fashion_mnist'\n",
    "    # print('The folder is:', main_folder)\n",
    "    # # find out that if the folder exists in the data path\n",
    "    # # 判断文件是否存在\n",
    "    # if main_folder.exists():\n",
    "    #     print(\"文件存在。\")\n",
    "    # else:\n",
    "    #     os.makedirs(main_folder)\n",
    "    #     print(\"文件不存在，已创建。\")\n",
    "    #     print(\"文件创建于：\", main_folder)\n",
    "    # for epoch in epochs:\n",
    "    #     for batch in batch_size:\n",
    "    #         for round in range(rounds):\n",
    "    #             train_model_f(main_folder, batch, epoch, round, lr, device, LayerName, model_f)\n",
    "    # ##########################################################\n",
    "    # # CIFAR100\n",
    "    # # create the folder to store the data\n",
    "    # main_folder = data_path/'cifar100'\n",
    "    # print('The folder is:', main_folder)\n",
    "    # # find out that if the folder exists in the data path\n",
    "    # # 判断文件是否存在\n",
    "    # if main_folder.exists():\n",
    "    #     print(\"文件存在。\")\n",
    "    # else:\n",
    "    #     os.makedirs(main_folder)\n",
    "    #     print(\"文件不存在，已创建。\")\n",
    "    #     print(\"文件创建于：\", main_folder)\n",
    "    # for epoch in epochs:\n",
    "    #     for batch in batch_size:\n",
    "    #         for round in range(rounds):\n",
    "    #             train_model_c(main_folder, batch, epoch, round, lr, device, LayerName, model_c)\n",
    "    ##########################################################\n",
    "    # CIFAR10\n",
    "    # create the folder to store the data\n",
    "    main_folder = data_path/'cifar10'\n",
    "    print('The folder is:', main_folder)\n",
    "    # find out that if the folder exists in the data path\n",
    "    # 判断文件是否存在\n",
    "    if main_folder.exists():\n",
    "        print(\"文件存在。\")\n",
    "    else:\n",
    "        os.makedirs(main_folder)\n",
    "        print(\"文件不存在，已创建。\")\n",
    "        print(\"文件创建于：\", main_folder)\n",
    "    for epoch in epochs:\n",
    "        for batch in batch_size:\n",
    "            for round in range(rounds):\n",
    "                train_model_c10(main_folder, batch, epoch, round, lr, device, LayerName, model_c10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GreenAI",
   "language": "python",
   "name": "greenai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
