{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ptflops import get_model_complexity_info\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current path is: /root/GreenAI/Cloud/4090/code\n",
      "The parent path is: /root/GreenAI/Cloud/4090\n",
      "The data path is: /root/GreenAI/Cloud/4090/Data/googlenet\n"
     ]
    }
   ],
   "source": [
    "'''find the Model path'''\n",
    "# find the current path\n",
    "current_path = os.getcwd()\n",
    "print('The current path is:', current_path)\n",
    "\n",
    "# find the parent path\n",
    "parent_path = Path(current_path).parent\n",
    "print('The parent path is:', parent_path)\n",
    "\n",
    "# find the data path\n",
    "data_path = parent_path / 'Data/googlenet'\n",
    "print('The data path is:', data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    # c1--c4是每条路径的输出通道数\n",
    "    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        # 线路1，单1x1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # 线路2，1x1卷积层后接3x3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1x1卷积层后接5x5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3x3最大汇聚层后接1x1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        # 在通道维度上连结输出\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)\n",
    "    \n",
    "def Googlenet(img_channel, num_labels):\n",
    "    b1 = nn.Sequential(nn.Conv2d(img_channel, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   nn.Flatten())\n",
    "\n",
    "    net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, num_labels))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Sequential\n",
      "  0: Conv2d\n",
      "  1: ReLU\n",
      "  2: MaxPool2d\n",
      "1: Sequential\n",
      "  0: Conv2d\n",
      "  1: ReLU\n",
      "  2: Conv2d\n",
      "  3: ReLU\n",
      "  4: MaxPool2d\n",
      "2: Sequential\n",
      "  0: Inception\n",
      "  1: Inception\n",
      "  2: MaxPool2d\n",
      "3: Sequential\n",
      "  0: Inception\n",
      "  1: Inception\n",
      "  2: Inception\n",
      "  3: Inception\n",
      "  4: Inception\n",
      "  5: MaxPool2d\n",
      "4: Sequential\n",
      "  0: Inception\n",
      "  1: Inception\n",
      "  2: AdaptiveAvgPool2d\n",
      "  3: Flatten\n",
      "5: Linear\n",
      "The layer name is: ['S0_C0', 'S0_R1', 'S0_M2', 'S1_C0', 'S1_R1', 'S1_C2', 'S1_R3', 'S1_M4', 'S2_I0', 'S2_I1', 'S2_M2', 'S3_I0', 'S3_I1', 'S3_I2', 'S3_I3', 'S3_I4', 'S3_M5', 'S4_I0', 'S4_I1', 'S4_A2', 'S4_F3']\n",
      "The length of layer name is: 21\n",
      "The number of blocks is: 5\n",
      "The number of inception blocks is: 9\n"
     ]
    }
   ],
   "source": [
    "net = Googlenet(1, 10)    \n",
    "LayerName = []\n",
    "block_num = 0\n",
    "incep_num = 0\n",
    "\n",
    "for num, layer in net.named_children():  # 使用 named_children 来获取层名和层\n",
    "    layername = layer.__class__.__name__\n",
    "    print(f\"{num}: {layername}\")  # 打印层名和层类名\n",
    "    \n",
    "    if layer.__class__.__name__ == 'Sequential':\n",
    "        block_num += 1\n",
    "        for sublayernum, sublayer in layer.named_children():  # 再次使用 named_children\n",
    "            sublayername = sublayer.__class__.__name__\n",
    "            if sublayername == 'Inception':\n",
    "                incep_num += 1\n",
    "            print(f\"  {sublayernum}: {sublayername}\")\n",
    "            layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}'\n",
    "            LayerName.append(layer_label)  # 收集子块的类型\n",
    "            # if sublayername == 'Inception':\n",
    "            #     incep_num += 1\n",
    "            #     for incepblocknum, incepblock in sublayer.named_children():  # 继续使用 named_children\n",
    "            #         incepblockname = incepblock.__class__.__name__\n",
    "            #         print(f\"    {incepblocknum}: {incepblockname}\")\n",
    "                    \n",
    "            #         layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}_{incepblockname[0]}{incepblocknum}'\n",
    "            #         # print('The layer label is:', layer_label)\n",
    "            #         LayerName.append(layer_label)  # 收集子子块的类型\n",
    "            # else:\n",
    "            #     layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}'\n",
    "            #     LayerName.append(layer_label)  # 收集子块的类型\n",
    "                        \n",
    "print('The layer name is:', LayerName)\n",
    "print(f'The length of layer name is: {len(LayerName)}')\n",
    "print('The number of blocks is:', block_num)\n",
    "print('The number of inception blocks is:', incep_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build different alexnet model for different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于不同的数据集，要设置不同的img_channel和num_labels\n",
    "# Fashion-MNIST中的图像通道数为1，类别数为10\n",
    "googlenet_f = Googlenet(1, 10)\n",
    "# CIFAR100中的图像通道数为3，类别数为100\n",
    "googlenet_c = Googlenet(3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Inception is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  5.98 M, 100.000% Params, 1.51 GMac, 99.594% MACs, \n",
      "  (0): Sequential(\n",
      "    3.2 k, 0.054% Params, 41.75 MMac, 2.752% MACs, \n",
      "    (0): Conv2d(3.2 k, 0.054% Params, 40.14 MMac, 2.646% MACs, 1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.053% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.053% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 1.923% Params, 361.87 MMac, 23.856% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.070% Params, 13.05 MMac, 0.860% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.013% MACs, )\n",
      "    (2): Conv2d(110.78 k, 1.853% Params, 347.42 MMac, 22.903% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.040% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.040% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    552.43 k, 9.242% Params, 433.83 MMac, 28.600% MACs, \n",
      "    (0): Inception(\n",
      "      163.7 k, 2.739% Params, 128.49 MMac, 8.470% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.207% Params, 9.68 MMac, 0.638% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(18.53 k, 0.310% Params, 14.53 MMac, 0.958% MACs, 192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(110.72 k, 1.852% Params, 86.8 MMac, 5.723% MACs, 96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(3.09 k, 0.052% Params, 2.42 MMac, 0.160% MACs, 192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(12.83 k, 0.215% Params, 10.06 MMac, 0.663% MACs, 16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 150.53 KMac, 0.010% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(6.18 k, 0.103% Params, 4.84 MMac, 0.319% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      388.74 k, 6.503% Params, 304.97 MMac, 20.105% MACs, \n",
      "      (p1_1): Conv2d(32.9 k, 0.550% Params, 25.79 MMac, 1.700% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(32.9 k, 0.550% Params, 25.79 MMac, 1.700% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(221.38 k, 3.703% Params, 173.56 MMac, 11.442% MACs, 128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(8.22 k, 0.138% Params, 6.45 MMac, 0.425% MACs, 256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(76.9 k, 1.286% Params, 60.29 MMac, 3.974% MACs, 32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 200.7 KMac, 0.013% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(16.45 k, 0.275% Params, 12.9 MMac, 0.850% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 376.32 KMac, 0.025% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    2.81 M, 46.995% Params, 551.26 MMac, 36.341% MACs, \n",
      "    (0): Inception(\n",
      "      376.18 k, 6.293% Params, 73.82 MMac, 4.867% MACs, \n",
      "      (p1_1): Conv2d(92.35 k, 1.545% Params, 18.1 MMac, 1.193% MACs, 480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(46.18 k, 0.772% Params, 9.05 MMac, 0.597% MACs, 480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(179.92 k, 3.010% Params, 35.26 MMac, 2.325% MACs, 96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(7.7 k, 0.129% Params, 1.51 MMac, 0.099% MACs, 480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(19.25 k, 0.322% Params, 3.77 MMac, 0.249% MACs, 16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 94.08 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(30.78 k, 0.515% Params, 6.03 MMac, 0.398% MACs, 480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      449.16 k, 7.514% Params, 88.14 MMac, 5.810% MACs, \n",
      "      (p1_1): Conv2d(82.08 k, 1.373% Params, 16.09 MMac, 1.061% MACs, 512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(57.46 k, 0.961% Params, 11.26 MMac, 0.742% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(226.02 k, 3.781% Params, 44.3 MMac, 2.920% MACs, 112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.206% Params, 2.41 MMac, 0.159% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.643% Params, 7.54 MMac, 0.497% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.549% Params, 6.44 MMac, 0.424% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception(\n",
      "      510.1 k, 8.534% Params, 100.08 MMac, 6.598% MACs, \n",
      "      (p1_1): Conv2d(65.66 k, 1.099% Params, 12.87 MMac, 0.848% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(65.66 k, 1.099% Params, 12.87 MMac, 0.848% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(295.17 k, 4.938% Params, 57.85 MMac, 3.814% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.206% Params, 2.41 MMac, 0.159% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.643% Params, 7.54 MMac, 0.497% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.549% Params, 6.44 MMac, 0.424% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception(\n",
      "      605.38 k, 10.128% Params, 118.75 MMac, 7.829% MACs, \n",
      "      (p1_1): Conv2d(57.46 k, 0.961% Params, 11.26 MMac, 0.742% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(73.87 k, 1.236% Params, 14.48 MMac, 0.955% MACs, 512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(373.54 k, 6.249% Params, 73.21 MMac, 4.827% MACs, 144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.42 k, 0.275% Params, 3.22 MMac, 0.212% MACs, 512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(51.26 k, 0.858% Params, 10.05 MMac, 0.662% MACs, 32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.549% Params, 6.44 MMac, 0.424% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception(\n",
      "      868.35 k, 14.527% Params, 170.3 MMac, 11.227% MACs, \n",
      "      (p1_1): Conv2d(135.42 k, 2.266% Params, 26.54 MMac, 1.750% MACs, 528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(84.64 k, 1.416% Params, 16.59 MMac, 1.094% MACs, 528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.714% Params, 90.38 MMac, 5.958% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.93 k, 0.283% Params, 3.32 MMac, 0.219% MACs, 528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.715% Params, 20.1 MMac, 1.325% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 103.49 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(67.71 k, 1.133% Params, 13.27 MMac, 0.875% MACs, 528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 163.07 KMac, 0.011% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    2.49 M, 41.615% Params, 122.02 MMac, 8.044% MACs, \n",
      "    (0): Inception(\n",
      "      1.04 M, 17.456% Params, 51.17 MMac, 3.373% MACs, \n",
      "      (p1_1): Conv2d(213.25 k, 3.567% Params, 10.45 MMac, 0.689% MACs, 832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(133.28 k, 2.230% Params, 6.53 MMac, 0.431% MACs, 832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.714% Params, 22.59 MMac, 1.490% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(26.66 k, 0.446% Params, 1.31 MMac, 0.086% MACs, 832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.715% Params, 5.02 MMac, 0.331% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.784% Params, 5.22 MMac, 0.344% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      1.44 M, 24.158% Params, 70.8 MMac, 4.667% MACs, \n",
      "      (p1_1): Conv2d(319.87 k, 5.351% Params, 15.67 MMac, 1.033% MACs, 832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(159.94 k, 2.676% Params, 7.84 MMac, 0.517% MACs, 832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(663.94 k, 11.107% Params, 32.53 MMac, 2.145% MACs, 192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(39.98 k, 0.669% Params, 1.96 MMac, 0.129% MACs, 832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(153.73 k, 2.572% Params, 7.53 MMac, 0.497% MACs, 48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.784% Params, 5.22 MMac, 0.344% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 50.18 KMac, 0.003% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(10.25 k, 0.171% Params, 10.25 KMac, 0.001% MACs, in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       1.52 GMac\n",
      "Number of parameters:           5.98 M  \n",
      "**************************************************\n",
      "Warning: module Inception is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  6.08 M, 100.000% Params, 1.59 GMac, 99.614% MACs, \n",
      "  (0): Sequential(\n",
      "    9.47 k, 0.156% Params, 120.42 MMac, 7.547% MACs, \n",
      "    (0): Conv2d(9.47 k, 0.156% Params, 118.82 MMac, 7.446% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.050% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.050% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 1.892% Params, 361.87 MMac, 22.678% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.068% Params, 13.05 MMac, 0.818% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.013% MACs, )\n",
      "    (2): Conv2d(110.78 k, 1.823% Params, 347.42 MMac, 21.773% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.038% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.038% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    552.43 k, 9.092% Params, 433.83 MMac, 27.188% MACs, \n",
      "    (0): Inception(\n",
      "      163.7 k, 2.694% Params, 128.49 MMac, 8.052% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.203% Params, 9.68 MMac, 0.607% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(18.53 k, 0.305% Params, 14.53 MMac, 0.910% MACs, 192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(110.72 k, 1.822% Params, 86.8 MMac, 5.440% MACs, 96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(3.09 k, 0.051% Params, 2.42 MMac, 0.152% MACs, 192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(12.83 k, 0.211% Params, 10.06 MMac, 0.630% MACs, 16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 150.53 KMac, 0.009% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(6.18 k, 0.102% Params, 4.84 MMac, 0.303% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      388.74 k, 6.398% Params, 304.97 MMac, 19.112% MACs, \n",
      "      (p1_1): Conv2d(32.9 k, 0.541% Params, 25.79 MMac, 1.616% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(32.9 k, 0.541% Params, 25.79 MMac, 1.616% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(221.38 k, 3.643% Params, 173.56 MMac, 10.877% MACs, 128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(8.22 k, 0.135% Params, 6.45 MMac, 0.404% MACs, 256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(76.9 k, 1.266% Params, 60.29 MMac, 3.778% MACs, 32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 200.7 KMac, 0.013% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(16.45 k, 0.271% Params, 12.9 MMac, 0.808% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 376.32 KMac, 0.024% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    2.81 M, 46.233% Params, 551.26 MMac, 34.547% MACs, \n",
      "    (0): Inception(\n",
      "      376.18 k, 6.191% Params, 73.82 MMac, 4.627% MACs, \n",
      "      (p1_1): Conv2d(92.35 k, 1.520% Params, 18.1 MMac, 1.134% MACs, 480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(46.18 k, 0.760% Params, 9.05 MMac, 0.567% MACs, 480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(179.92 k, 2.961% Params, 35.26 MMac, 2.210% MACs, 96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(7.7 k, 0.127% Params, 1.51 MMac, 0.095% MACs, 480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(19.25 k, 0.317% Params, 3.77 MMac, 0.236% MACs, 16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 94.08 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(30.78 k, 0.507% Params, 6.03 MMac, 0.378% MACs, 480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      449.16 k, 7.392% Params, 88.14 MMac, 5.523% MACs, \n",
      "      (p1_1): Conv2d(82.08 k, 1.351% Params, 16.09 MMac, 1.008% MACs, 512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(57.46 k, 0.946% Params, 11.26 MMac, 0.706% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(226.02 k, 3.720% Params, 44.3 MMac, 2.776% MACs, 112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.203% Params, 2.41 MMac, 0.151% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.633% Params, 7.54 MMac, 0.472% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.540% Params, 6.44 MMac, 0.403% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception(\n",
      "      510.1 k, 8.395% Params, 100.08 MMac, 6.272% MACs, \n",
      "      (p1_1): Conv2d(65.66 k, 1.081% Params, 12.87 MMac, 0.807% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(65.66 k, 1.081% Params, 12.87 MMac, 0.807% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(295.17 k, 4.858% Params, 57.85 MMac, 3.626% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.203% Params, 2.41 MMac, 0.151% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.633% Params, 7.54 MMac, 0.472% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.540% Params, 6.44 MMac, 0.403% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception(\n",
      "      605.38 k, 9.963% Params, 118.75 MMac, 7.442% MACs, \n",
      "      (p1_1): Conv2d(57.46 k, 0.946% Params, 11.26 MMac, 0.706% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(73.87 k, 1.216% Params, 14.48 MMac, 0.907% MACs, 512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(373.54 k, 6.148% Params, 73.21 MMac, 4.588% MACs, 144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.42 k, 0.270% Params, 3.22 MMac, 0.202% MACs, 512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(51.26 k, 0.844% Params, 10.05 MMac, 0.630% MACs, 32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.540% Params, 6.44 MMac, 0.403% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception(\n",
      "      868.35 k, 14.291% Params, 170.3 MMac, 10.673% MACs, \n",
      "      (p1_1): Conv2d(135.42 k, 2.229% Params, 26.54 MMac, 1.663% MACs, 528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(84.64 k, 1.393% Params, 16.59 MMac, 1.040% MACs, 528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.589% Params, 90.38 MMac, 5.664% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.93 k, 0.279% Params, 3.32 MMac, 0.208% MACs, 528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.687% Params, 20.1 MMac, 1.259% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 103.49 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(67.71 k, 1.114% Params, 13.27 MMac, 0.832% MACs, 528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 163.07 KMac, 0.010% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    2.49 M, 40.940% Params, 122.02 MMac, 7.647% MACs, \n",
      "    (0): Inception(\n",
      "      1.04 M, 17.173% Params, 51.17 MMac, 3.207% MACs, \n",
      "      (p1_1): Conv2d(213.25 k, 3.510% Params, 10.45 MMac, 0.655% MACs, 832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(133.28 k, 2.194% Params, 6.53 MMac, 0.409% MACs, 832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.589% Params, 22.59 MMac, 1.416% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(26.66 k, 0.439% Params, 1.31 MMac, 0.082% MACs, 832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.687% Params, 5.02 MMac, 0.315% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.755% Params, 5.22 MMac, 0.327% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      1.44 M, 23.767% Params, 70.8 MMac, 4.437% MACs, \n",
      "      (p1_1): Conv2d(319.87 k, 5.264% Params, 15.67 MMac, 0.982% MACs, 832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(159.94 k, 2.632% Params, 7.84 MMac, 0.491% MACs, 832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(663.94 k, 10.927% Params, 32.53 MMac, 2.039% MACs, 192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(39.98 k, 0.658% Params, 1.96 MMac, 0.123% MACs, 832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(153.73 k, 2.530% Params, 7.53 MMac, 0.472% MACs, 48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.755% Params, 5.22 MMac, 0.327% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 50.18 KMac, 0.003% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(102.5 k, 1.687% Params, 102.5 KMac, 0.006% MACs, in_features=1024, out_features=100, bias=True)\n",
      ")\n",
      "Computational complexity:       1.6 GMac\n",
      "Number of parameters:           6.08 M  \n"
     ]
    }
   ],
   "source": [
    "# fashion mnist\n",
    "with torch.cuda.device(0):\n",
    "    macs_f, params_f = get_model_complexity_info(googlenet_f, (1, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_f))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_f))\n",
    "\n",
    "print('*'*50)\n",
    "\n",
    "# cifar100\n",
    "with torch.cuda.device(0):\n",
    "    macs_c, params_c = get_model_complexity_info(googlenet_c, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_c))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 192, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 480, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 832, 7, 7])\n",
      "Sequential output shape:\t torch.Size([1, 1024])\n",
      "Linear output shape:\t torch.Size([1, 10])\n",
      "**************************************************\n",
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 192, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 480, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 832, 7, 7])\n",
      "Sequential output shape:\t torch.Size([1, 1024])\n",
      "Linear output shape:\t torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "X_f = torch.randn(size=(1, 1, 224, 224), dtype=torch.float32) # fashion mnist\n",
    "X_c = torch.randn(size=(1, 3, 224, 224), dtype=torch.float32) # cifar100\n",
    "\n",
    "for layer in googlenet_f:\n",
    "    X_f=layer(X_f)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X_f.shape)\n",
    "\n",
    "print('*'*50)\n",
    "\n",
    "for layer in googlenet_c:\n",
    "    X_c=layer(X_c)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# fashion mnist\n",
    "def get_dataloader_workers():\n",
    "    \"\"\"Use 4 processes to read the data.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    return 4\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\n",
    "\n",
    "    Defined in :numref:`sec_fashion_mnist`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=get_dataloader_workers()))\n",
    "\n",
    "def load_data_cifar100(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    # import the cifar100 dataset\n",
    "    cifar_train = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    cifar_test = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(cifar_train, batch_size, shuffle=True,\n",
    "                                        num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(cifar_test, batch_size, shuffle=False,\n",
    "                                        num_workers=get_dataloader_workers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = [128, 256, 512]\n",
    "batch_size = [256]\n",
    "# epochs = [10, 20, 30, 40, 50]\n",
    "epochs = [20]\n",
    "rounds = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(net, train_iter, test_iter, LayerName, num_epochs, lr, device):\n",
    "    def init_weights(m): # 初始化权重\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    # record each block running time\n",
    "    Layers_time = np.zeros((len(LayerName), num_epochs)) # each row is a layer, each column is an epoch\n",
    "    Train_part_time = np.zeros((6, num_epochs)) # store the time to device, forward and backward time, and test time of each epoch\n",
    "    Train_acc = np.zeros(num_epochs) # store the training accuracy of each epoch\n",
    "    Test_acc = np.zeros(num_epochs) # store the test accuracy of each epoch\n",
    "    Epoch_time = np.zeros(num_epochs) # store the total time of each epoch\n",
    "    Epoch_energy = np.zeros((num_epochs,1), dtype='object') # store the total energy of each epoch\n",
    "    timer = d2l.Timer()\n",
    "    train_timer = d2l.Timer()\n",
    "    ttd_timer = d2l.Timer()\n",
    "    forward_timer = d2l.Timer()\n",
    "    loss_timer = d2l.Timer()\n",
    "    backward_timer = d2l.Timer()\n",
    "    optimizer_timer = d2l.Timer()\n",
    "    layer_timer = d2l.Timer()\n",
    "    test_timer = d2l.Timer()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    # start training\n",
    "    for epoch in range(num_epochs):\n",
    "        print('The epoch is:', epoch+1)\n",
    "        timer.start()\n",
    "        net.train()\n",
    "        ttd_epoch, forward_epoch, loss_epoch, backward_epoch, optimization_epoch, testtime_epoch= 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "        layer_epoch = np.zeros((len(LayerName), 1)) # store the total running time of each layer in one epoch\n",
    "        metric = d2l.Accumulator(3)  # train_loss, train_acc, num_examples   \n",
    "        # start the nvidia-smi command\n",
    "        with open('gpu_power_usage.csv', 'w') as file:\n",
    "            # Start the nvidia-smi command\n",
    "            nvidia_smi_process = subprocess.Popen(\n",
    "                [\"nvidia-smi\", \"--query-gpu=power.draw\", \"--format=csv\", \"--loop-ms=1000\"],\n",
    "                stdout=file,  # Redirect the output directly to the file\n",
    "                stderr=subprocess.PIPE,\n",
    "                text=True)\n",
    "        train_timer.start()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            batch_block_num = 0\n",
    "            # print('The batch is:', i+1)\n",
    "            optimizer.zero_grad()\n",
    "            # to device\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            ttd_timer.start()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            ttd_epoch += ttd_timer.stop()\n",
    "            # forward\n",
    "            forward_timer.start()\n",
    "            y_hat = X\n",
    "            for num, layer in net.named_children():\n",
    "                layername = layer.__class__.__name__\n",
    "                if layername == 'Sequential':\n",
    "                    for sublayernum, sublayer in layer.named_children():\n",
    "                        sublayername = sublayer.__class__.__name__\n",
    "                        Layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}'\n",
    "                        layer_index = LayerName.index(Layer_label)\n",
    "                        # print('The layer index is:', layer_index, 'The layer label is:', Layer_label)\n",
    "                        layer_timer.start()\n",
    "                        y_hat = sublayer(y_hat)\n",
    "                        torch.cuda.synchronize()\n",
    "                        layer_epoch[layer_index] += layer_timer.stop()\n",
    "            torch.cuda.synchronize()\n",
    "            forward_epoch += forward_timer.stop()\n",
    "            # loss\n",
    "            loss_timer.start()\n",
    "            l = loss_fn(y_hat, y)\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            loss_epoch += loss_timer.stop()\n",
    "            # backward\n",
    "            backward_timer.start()\n",
    "            l.backward()\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            backward_epoch += backward_timer.stop()\n",
    "            # optimize\n",
    "            optimizer_timer.start()\n",
    "            optimizer.step()\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            optimization_epoch += optimizer_timer.stop()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l*X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            train_acc = metric[1] / metric[2]\n",
    "        train_epoch = train_timer.stop()\n",
    "        test_timer.start()\n",
    "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n",
    "        testtime_epoch = test_timer.stop()\n",
    "        print(f'train acc {train_acc:.3f}, test acc {test_acc:.3f}')\n",
    "        print('epoch %d, time %f sec' % (epoch+1, timer.sum()))\n",
    "        # store the time and acc data\n",
    "        Epoch_time[epoch] = timer.stop()\n",
    "        print(f'The total time of the {epoch} is:', Epoch_time[epoch])\n",
    "        Layers_time[:, epoch] = layer_epoch.flatten()\n",
    "        Train_part_time[:, epoch] = ttd_epoch, forward_epoch, loss_epoch, backward_epoch, optimization_epoch, testtime_epoch\n",
    "        print(ttd_epoch, forward_epoch, loss_epoch, backward_epoch, optimization_epoch, testtime_epoch)\n",
    "        print('*'*50)\n",
    "        print(testtime_epoch)\n",
    "        Train_acc[epoch] = train_acc\n",
    "        Test_acc[epoch] = test_acc\n",
    "        # stop the nvidia-smi command\n",
    "        nvidia_smi_process.terminate()\n",
    "        # calculate the energy consumption of each epoch\n",
    "        GPU_df = pd.read_csv('gpu_power_usage.csv')\n",
    "        for row in range(len(GPU_df)):\n",
    "            GPU_df.iloc[row,0] = GPU_df.iloc[row,0].replace(' W','')\n",
    "        Consumption_df = GPU_df.astype(float)  \n",
    "        EnergyDatai = Consumption_df.iloc[:,0].values # 将数据转换为numpy数组\n",
    "        # store the energy data\n",
    "        Epoch_energy[epoch,0] = EnergyDatai\n",
    "    return Layers_time, Train_part_time, Train_acc, Test_acc, Epoch_time, Epoch_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_f(main_folder, batch_size, num_epochs, round, lr, device, LayerName):\n",
    "    print(f'The epoch is set: {num_epochs}, batch is set: {batch_size}, is in {round+1}th running')\n",
    "    # create the folder to store the data\n",
    "    epoch_batch_folder = main_folder/f'E{num_epochs}_B{batch_size}_R{round}'\n",
    "    # 判断文件是否存在\n",
    "    if epoch_batch_folder.exists():\n",
    "        print(\"文件存在。\")\n",
    "    else:\n",
    "        os.makedirs(epoch_batch_folder)\n",
    "        print(\"文件不存在，已创建。\")\n",
    "        print(\"文件创建于：\", epoch_batch_folder)\n",
    "    train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n",
    "    # show the shape of the data\n",
    "    list_of_i = []\n",
    "    for i, (X, y) in enumerate(train_iter):\n",
    "        if i < 3:\n",
    "            print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "        else:\n",
    "            pass\n",
    "        list_of_i.append(i)\n",
    "    print(f'The number of batches is: {np.array(list_of_i).shape}')\n",
    "    Layers_time, Train_part_time, Train_acc, Test_acc, \\\n",
    "        Epoch_time, Epoch_energy = train_func(googlenet_f, train_iter, test_iter, LayerName, num_epochs, lr, device)\n",
    "    # save the data\n",
    "    np.save(epoch_batch_folder/'Layers_time.npy', Layers_time)\n",
    "    np.save(epoch_batch_folder/'Train_part_time.npy', Train_part_time)\n",
    "    np.save(epoch_batch_folder/'Train_acc.npy', Train_acc)\n",
    "    np.save(epoch_batch_folder/'Test_acc.npy', Test_acc)\n",
    "    np.save(epoch_batch_folder/'Epoch_time.npy', Epoch_time)\n",
    "    np.save(epoch_batch_folder/'Epoch_energy.npy', Epoch_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_c(main_folder, batch_size, num_epochs, round, lr, device, LayerName):\n",
    "    print(f'The epoch is set: {num_epochs}, batch is set: {batch_size}, is in {round+1}th running')\n",
    "    # create the folder to store the data\n",
    "    epoch_batch_folder = main_folder/f'E{num_epochs}_B{batch_size}_R{round}'\n",
    "    # 判断文件是否存在\n",
    "    if epoch_batch_folder.exists():\n",
    "        print(\"文件存在。\")\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(epoch_batch_folder)\n",
    "        print(\"文件不存在，已创建。\")\n",
    "        print(\"文件创建于：\", epoch_batch_folder)\n",
    "        train_iter, test_iter = load_data_cifar100(batch_size, resize=224)\n",
    "        # show the shape of the data\n",
    "        list_of_i = []\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            if i < 3:\n",
    "                print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "            else:\n",
    "                pass\n",
    "            list_of_i.append(i)\n",
    "        print(f'The number of batches is: {np.array(list_of_i).shape}')\n",
    "        Layers_time, Train_part_time, Train_acc, Test_acc, \\\n",
    "            Epoch_time, Epoch_energy = train_func(googlenet_c, train_iter, test_iter, LayerName, num_epochs, lr, device)\n",
    "        # save the data\n",
    "        np.save(epoch_batch_folder/'Layers_time.npy', Layers_time)\n",
    "        np.save(epoch_batch_folder/'Train_part_time.npy', Train_part_time)\n",
    "        np.save(epoch_batch_folder/'Train_acc.npy', Train_acc)\n",
    "        np.save(epoch_batch_folder/'Test_acc.npy', Test_acc)\n",
    "        np.save(epoch_batch_folder/'Epoch_time.npy', Epoch_time)\n",
    "        np.save(epoch_batch_folder/'Epoch_energy.npy', Epoch_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is: cuda\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('The device is:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder is: /root/GreenAI/Cloud/4090/Data/googlenet/fashion_mnist\n",
      "文件存在。\n",
      "The epoch is set: 20, batch is set: 256, is in 1th running\n",
      "文件不存在，已创建。\n",
      "文件创建于： /root/GreenAI/Cloud/4090/Data/googlenet/fashion_mnist/E20_B256_R0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the 0 batch of the train_iter is: torch.Size([256, 1, 224, 224])\n",
      "the shape of the 1 batch of the train_iter is: torch.Size([256, 1, 224, 224])\n",
      "the shape of the 2 batch of the train_iter is: torch.Size([256, 1, 224, 224])\n",
      "The number of batches is: (235,)\n",
      "training on cuda\n",
      "The epoch is: 1\n",
      "train acc 0.099, test acc 0.100\n",
      "epoch 1, time 0.000000 sec\n",
      "The total time of the 0 is: 41.94174122810364\n",
      "2.6165931224823 10.444980382919312 0.10967445373535156 20.76690435409546 0.26568174362182617 3.344947338104248\n",
      "**************************************************\n",
      "3.344947338104248\n",
      "The epoch is: 2\n",
      "train acc 0.153, test acc 0.103\n",
      "epoch 2, time 41.941741 sec\n",
      "The total time of the 1 is: 40.155275106430054\n",
      "2.470069646835327 9.758726596832275 0.06763815879821777 20.261005640029907 0.2443385124206543 3.218003988265991\n",
      "**************************************************\n",
      "3.218003988265991\n",
      "The epoch is: 3\n",
      "train acc 0.233, test acc 0.100\n",
      "epoch 3, time 82.097016 sec\n",
      "The total time of the 2 is: 40.5233199596405\n",
      "2.542067050933838 9.769354343414307 0.07195472717285156 20.29957938194275 0.24978256225585938 3.1517465114593506\n",
      "**************************************************\n",
      "3.1517465114593506\n",
      "The epoch is: 4\n",
      "train acc 0.415, test acc 0.195\n",
      "epoch 4, time 122.620336 sec\n",
      "The total time of the 3 is: 40.51642870903015\n",
      "2.544461488723755 9.789055585861206 0.0700371265411377 20.305383443832397 0.25567054748535156 3.1848795413970947\n",
      "**************************************************\n",
      "3.1848795413970947\n",
      "The epoch is: 5\n",
      "train acc 0.522, test acc 0.100\n",
      "epoch 5, time 163.136765 sec\n",
      "The total time of the 4 is: 40.0808539390564\n",
      "2.4576354026794434 9.756094217300415 0.0667428970336914 20.313673496246338 0.24081778526306152 3.1597108840942383\n",
      "**************************************************\n",
      "3.1597108840942383\n",
      "The epoch is: 6\n",
      "train acc 0.616, test acc 0.102\n",
      "epoch 6, time 203.217619 sec\n",
      "The total time of the 5 is: 40.3730902671814\n",
      "2.473344564437866 9.755096673965454 0.06749415397644043 20.320324182510376 0.24221563339233398 3.111052989959717\n",
      "**************************************************\n",
      "3.111052989959717\n",
      "The epoch is: 7\n",
      "train acc 0.694, test acc 0.144\n",
      "epoch 7, time 243.590709 sec\n",
      "The total time of the 6 is: 40.4632933139801\n",
      "2.455655574798584 9.773581743240356 0.06721758842468262 20.319008350372314 0.2480154037475586 3.3327152729034424\n",
      "**************************************************\n",
      "3.3327152729034424\n",
      "The epoch is: 8\n",
      "train acc 0.739, test acc 0.116\n",
      "epoch 8, time 284.054003 sec\n",
      "The total time of the 7 is: 40.693044900894165\n",
      "2.527477502822876 9.76695990562439 0.06718802452087402 20.326848030090332 0.2478628158569336 3.3648688793182373\n",
      "**************************************************\n",
      "3.3648688793182373\n",
      "The epoch is: 9\n",
      "train acc 0.762, test acc 0.100\n",
      "epoch 9, time 324.747047 sec\n",
      "The total time of the 8 is: 40.39175844192505\n",
      "2.4393467903137207 9.762902021408081 0.06684541702270508 20.3207585811615 0.24682283401489258 3.214268684387207\n",
      "**************************************************\n",
      "3.214268684387207\n",
      "The epoch is: 10\n",
      "train acc 0.777, test acc 0.098\n",
      "epoch 10, time 365.138806 sec\n",
      "The total time of the 9 is: 40.19113731384277\n",
      "2.36089825630188 9.764397144317627 0.06670045852661133 20.322744369506836 0.24500083923339844 3.265587091445923\n",
      "**************************************************\n",
      "3.265587091445923\n",
      "The epoch is: 11\n",
      "train acc 0.787, test acc 0.142\n",
      "epoch 11, time 405.329943 sec\n",
      "The total time of the 10 is: 40.37067103385925\n",
      "2.4508330821990967 9.76077389717102 0.06578850746154785 20.308279514312744 0.2456364631652832 3.283433198928833\n",
      "**************************************************\n",
      "3.283433198928833\n",
      "The epoch is: 12\n",
      "train acc 0.803, test acc 0.126\n",
      "epoch 12, time 445.700614 sec\n",
      "The total time of the 11 is: 40.017021894454956\n",
      "2.3864126205444336 9.75364899635315 0.06680774688720703 20.304256677627563 0.24074029922485352 3.087608814239502\n",
      "**************************************************\n",
      "3.087608814239502\n",
      "The epoch is: 13\n",
      "train acc 0.817, test acc 0.088\n",
      "epoch 13, time 485.717636 sec\n",
      "The total time of the 12 is: 39.91611337661743\n",
      "2.317256212234497 9.775897979736328 0.06866097450256348 20.324695825576782 0.244154691696167 3.217717170715332\n",
      "**************************************************\n",
      "3.217717170715332\n",
      "The epoch is: 14\n",
      "train acc 0.822, test acc 0.096\n",
      "epoch 14, time 525.633749 sec\n",
      "The total time of the 13 is: 40.32597279548645\n",
      "2.405451774597168 9.747299909591675 0.06564617156982422 20.316138744354248 0.2423844337463379 3.270854949951172\n",
      "**************************************************\n",
      "3.270854949951172\n",
      "The epoch is: 15\n",
      "train acc 0.829, test acc 0.091\n",
      "epoch 15, time 565.959722 sec\n",
      "The total time of the 14 is: 40.171215772628784\n",
      "2.406507968902588 9.753844976425171 0.06672000885009766 20.321049451828003 0.24289417266845703 3.271831512451172\n",
      "**************************************************\n",
      "3.271831512451172\n",
      "The epoch is: 16\n",
      "train acc 0.836, test acc 0.095\n",
      "epoch 16, time 606.130938 sec\n",
      "The total time of the 15 is: 40.15452694892883\n",
      "2.4080986976623535 9.770555257797241 0.06737971305847168 20.320414304733276 0.24882745742797852 3.281428337097168\n",
      "**************************************************\n",
      "3.281428337097168\n",
      "The epoch is: 17\n",
      "train acc 0.843, test acc 0.073\n",
      "epoch 17, time 646.285465 sec\n",
      "The total time of the 16 is: 40.38220000267029\n",
      "2.4535973072052 9.774682760238647 0.06824469566345215 20.319111347198486 0.24948978424072266 3.169987201690674\n",
      "**************************************************\n",
      "3.169987201690674\n",
      "The epoch is: 18\n",
      "train acc 0.850, test acc 0.059\n",
      "epoch 18, time 686.667665 sec\n",
      "The total time of the 17 is: 40.63286638259888\n",
      "2.4913737773895264 9.76815390586853 0.06798291206359863 20.32957887649536 0.24692797660827637 3.3146209716796875\n",
      "**************************************************\n",
      "3.3146209716796875\n",
      "The epoch is: 19\n",
      "train acc 0.852, test acc 0.054\n",
      "epoch 19, time 727.300531 sec\n",
      "The total time of the 18 is: 40.140944719314575\n",
      "2.371670961380005 9.75525450706482 0.066009521484375 20.321834325790405 0.24004292488098145 3.171398162841797\n",
      "**************************************************\n",
      "3.171398162841797\n",
      "The epoch is: 20\n",
      "train acc 0.858, test acc 0.075\n",
      "epoch 20, time 767.441476 sec\n",
      "The total time of the 19 is: 39.850178718566895\n",
      "2.3675787448883057 9.769063472747803 0.06701397895812988 20.315174102783203 0.24394726753234863 3.126488208770752\n",
      "**************************************************\n",
      "3.126488208770752\n"
     ]
    }
   ],
   "source": [
    "# create the folder to store the data\n",
    "main_folder = data_path/'fashion_mnist'\n",
    "print('The folder is:', main_folder)\n",
    "# find out that if the folder exists in the data path\n",
    "# 判断文件是否存在\n",
    "if main_folder.exists():\n",
    "    print(\"文件存在。\")\n",
    "else:\n",
    "    os.makedirs(main_folder)\n",
    "    print(\"文件不存在，已创建。\")\n",
    "    print(\"文件创建于：\", main_folder)\n",
    "for epoch in epochs:\n",
    "    for batch in batch_size:\n",
    "        for round in range(rounds):\n",
    "            train_model_f(main_folder, batch, epoch, round, lr, device, LayerName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder is: /root/GreenAI/Cloud/4090/Data/googlenet/cifar100\n",
      "文件存在。\n",
      "The epoch is set: 20, batch is set: 256, is in 1th running\n",
      "文件不存在，已创建。\n",
      "文件创建于： /root/GreenAI/Cloud/4090/Data/googlenet/cifar100/E20_B256_R0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "the shape of the 0 batch of the train_iter is: torch.Size([256, 3, 224, 224])\n",
      "the shape of the 1 batch of the train_iter is: torch.Size([256, 3, 224, 224])\n",
      "the shape of the 2 batch of the train_iter is: torch.Size([256, 3, 224, 224])\n",
      "The number of batches is: (196,)\n",
      "training on cuda\n",
      "The epoch is: 1\n",
      "train acc 0.007, test acc 0.010\n",
      "epoch 1, time 0.000000 sec\n",
      "The total time of the 0 is: 47.11707162857056\n",
      "6.315913200378418 8.450315713882446 0.05543184280395508 17.584708213806152 0.21501779556274414 5.3950183391571045\n",
      "**************************************************\n",
      "5.3950183391571045\n",
      "The epoch is: 2\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 2, time 47.117072 sec\n",
      "The total time of the 1 is: 47.21440529823303\n",
      "6.475688219070435 8.307420253753662 0.061810970306396484 17.387306451797485 0.2267005443572998 5.713540554046631\n",
      "**************************************************\n",
      "5.713540554046631\n",
      "The epoch is: 3\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 3, time 94.331477 sec\n",
      "The total time of the 2 is: 46.688493490219116\n",
      "6.3001697063446045 8.311273574829102 0.06408381462097168 17.380187034606934 0.2235124111175537 5.4645020961761475\n",
      "**************************************************\n",
      "5.4645020961761475\n",
      "The epoch is: 4\n",
      "train acc 0.011, test acc 0.010\n",
      "epoch 4, time 141.019970 sec\n",
      "The total time of the 3 is: 45.617862939834595\n",
      "5.932706832885742 8.258816719055176 0.05906867980957031 17.384300470352173 0.20678329467773438 5.171349048614502\n",
      "**************************************************\n",
      "5.171349048614502\n",
      "The epoch is: 5\n",
      "train acc 0.011, test acc 0.010\n",
      "epoch 5, time 186.637833 sec\n",
      "The total time of the 4 is: 46.0950231552124\n",
      "6.116864442825317 8.267441987991333 0.05968880653381348 17.398107290267944 0.2063913345336914 5.590840578079224\n",
      "**************************************************\n",
      "5.590840578079224\n",
      "The epoch is: 6\n",
      "train acc 0.012, test acc 0.010\n",
      "epoch 6, time 232.732857 sec\n",
      "The total time of the 5 is: 47.116294384002686\n",
      "6.976588487625122 8.292705774307251 0.05854320526123047 17.332836866378784 0.21951079368591309 5.518819332122803\n",
      "**************************************************\n",
      "5.518819332122803\n",
      "The epoch is: 7\n",
      "train acc 0.011, test acc 0.010\n",
      "epoch 7, time 279.849151 sec\n",
      "The total time of the 6 is: 47.26203918457031\n",
      "7.107235670089722 8.292739629745483 0.057301998138427734 17.35415554046631 0.21740341186523438 5.390729904174805\n",
      "**************************************************\n",
      "5.390729904174805\n",
      "The epoch is: 8\n",
      "train acc 0.011, test acc 0.010\n",
      "epoch 8, time 327.111190 sec\n",
      "The total time of the 7 is: 47.588772773742676\n",
      "7.090618371963501 8.294238090515137 0.05726456642150879 17.353612422943115 0.2158360481262207 5.683796644210815\n",
      "**************************************************\n",
      "5.683796644210815\n",
      "The epoch is: 9\n",
      "train acc 0.011, test acc 0.010\n",
      "epoch 9, time 374.699963 sec\n",
      "The total time of the 8 is: 45.24108338356018\n",
      "6.013025522232056 8.306753158569336 0.05707859992980957 17.327327728271484 0.21002936363220215 5.177671909332275\n",
      "**************************************************\n",
      "5.177671909332275\n",
      "The epoch is: 10\n",
      "train acc 0.011, test acc 0.010\n",
      "epoch 10, time 419.941046 sec\n",
      "The total time of the 9 is: 44.17212200164795\n",
      "5.4376256465911865 8.287286281585693 0.05523109436035156 17.3236563205719 0.2029426097869873 5.121585845947266\n",
      "**************************************************\n",
      "5.121585845947266\n",
      "The epoch is: 11\n",
      "train acc 0.012, test acc 0.010\n",
      "epoch 11, time 464.113168 sec\n",
      "The total time of the 10 is: 43.71117377281189\n",
      "5.457565069198608 8.290293455123901 0.05577874183654785 17.332218885421753 0.20353007316589355 4.959036588668823\n",
      "**************************************************\n",
      "4.959036588668823\n",
      "The epoch is: 12\n",
      "train acc 0.011, test acc 0.010\n",
      "epoch 12, time 507.824342 sec\n",
      "The total time of the 11 is: 44.04889369010925\n",
      "5.415962219238281 8.292484283447266 0.057340145111083984 17.36033797264099 0.21170306205749512 4.954315900802612\n",
      "**************************************************\n",
      "4.954315900802612\n",
      "The epoch is: 13\n",
      "train acc 0.012, test acc 0.010\n",
      "epoch 13, time 551.873236 sec\n",
      "The total time of the 12 is: 42.814117670059204\n",
      "5.086345672607422 8.230535507202148 0.05071377754211426 17.332863807678223 0.17983675003051758 5.015992641448975\n",
      "**************************************************\n",
      "5.015992641448975\n",
      "The epoch is: 14\n",
      "train acc 0.013, test acc 0.010\n",
      "epoch 14, time 594.687353 sec\n",
      "The total time of the 13 is: 44.53561973571777\n",
      "5.6105523109436035 8.287277936935425 0.05539584159851074 17.345964193344116 0.20149660110473633 5.265284299850464\n",
      "**************************************************\n",
      "5.265284299850464\n",
      "The epoch is: 15\n",
      "train acc 0.012, test acc 0.010\n",
      "epoch 15, time 639.222973 sec\n",
      "The total time of the 14 is: 44.843055725097656\n",
      "5.621402978897095 8.30377459526062 0.056813955307006836 17.34964370727539 0.21075868606567383 5.503814220428467\n",
      "**************************************************\n",
      "5.503814220428467\n",
      "The epoch is: 16\n",
      "train acc 0.014, test acc 0.010\n",
      "epoch 16, time 684.066029 sec\n",
      "The total time of the 15 is: 44.65956401824951\n",
      "5.554864168167114 8.296570062637329 0.05632185935974121 17.34253430366516 0.21150541305541992 5.229986906051636\n",
      "**************************************************\n",
      "5.229986906051636\n",
      "The epoch is: 17\n",
      "train acc 0.017, test acc 0.010\n",
      "epoch 17, time 728.725593 sec\n",
      "The total time of the 16 is: 43.94621157646179\n",
      "5.409930467605591 8.287184953689575 0.0554807186126709 17.35239315032959 0.20909643173217773 4.990616321563721\n",
      "**************************************************\n",
      "4.990616321563721\n",
      "The epoch is: 18\n",
      "train acc 0.024, test acc 0.013\n",
      "epoch 18, time 772.671804 sec\n",
      "The total time of the 17 is: 43.846019983291626\n",
      "5.469009637832642 8.291095733642578 0.05561351776123047 17.34397792816162 0.20803427696228027 4.86571741104126\n",
      "**************************************************\n",
      "4.86571741104126\n",
      "The epoch is: 19\n",
      "train acc 0.028, test acc 0.014\n",
      "epoch 19, time 816.517824 sec\n",
      "The total time of the 18 is: 43.459651947021484\n",
      "5.2084105014801025 8.263403177261353 0.052381277084350586 17.34618306159973 0.19566059112548828 5.274330139160156\n",
      "**************************************************\n",
      "5.274330139160156\n",
      "The epoch is: 20\n",
      "train acc 0.028, test acc 0.010\n",
      "epoch 20, time 859.977476 sec\n",
      "The total time of the 19 is: 44.406617879867554\n",
      "5.708059549331665 8.292495012283325 0.05590248107910156 17.341960430145264 0.20892715454101562 4.974134206771851\n",
      "**************************************************\n",
      "4.974134206771851\n"
     ]
    }
   ],
   "source": [
    "# create the folder to store the data\n",
    "main_folder = data_path/'cifar100'\n",
    "print('The folder is:', main_folder)\n",
    "# find out that if the folder exists in the data path\n",
    "# 判断文件是否存在\n",
    "if main_folder.exists():\n",
    "    print(\"文件存在。\")\n",
    "else:\n",
    "    os.makedirs(main_folder)\n",
    "    print(\"文件不存在，已创建。\")\n",
    "    print(\"文件创建于：\", main_folder)\n",
    "for epoch in epochs:\n",
    "    for batch in batch_size:\n",
    "        for round in range(rounds):\n",
    "            train_model_c(main_folder, batch, epoch, round, lr, device, LayerName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GreenAI",
   "language": "python",
   "name": "greenai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
