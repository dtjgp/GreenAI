{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ptflops import get_model_complexity_info\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current path is: /root/GreenAI/Cloud/4090/code\n",
      "The parent path is: /root/GreenAI/Cloud/4090\n",
      "The data path is: /root/GreenAI/Cloud/4090/Data/googlenet\n"
     ]
    }
   ],
   "source": [
    "'''find the Model path'''\n",
    "# find the current path\n",
    "current_path = os.getcwd()\n",
    "print('The current path is:', current_path)\n",
    "\n",
    "# find the parent path\n",
    "parent_path = Path(current_path).parent\n",
    "print('The parent path is:', parent_path)\n",
    "\n",
    "# find the data path\n",
    "data_path = parent_path / 'Data/googlenet'\n",
    "print('The data path is:', data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    # c1--c4是每条路径的输出通道数\n",
    "    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        # 线路1，单1x1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # 线路2，1x1卷积层后接3x3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1x1卷积层后接5x5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3x3最大汇聚层后接1x1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        # 在通道维度上连结输出\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)\n",
    "    \n",
    "def Googlenet(img_channel, num_labels):\n",
    "    b1 = nn.Sequential(nn.Conv2d(img_channel, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   nn.Flatten())\n",
    "\n",
    "    net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, num_labels))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Sequential\n",
      "  0: Conv2d\n",
      "  1: ReLU\n",
      "  2: MaxPool2d\n",
      "1: Sequential\n",
      "  0: Conv2d\n",
      "  1: ReLU\n",
      "  2: Conv2d\n",
      "  3: ReLU\n",
      "  4: MaxPool2d\n",
      "2: Sequential\n",
      "  0: Inception\n",
      "  1: Inception\n",
      "  2: MaxPool2d\n",
      "3: Sequential\n",
      "  0: Inception\n",
      "  1: Inception\n",
      "  2: Inception\n",
      "  3: Inception\n",
      "  4: Inception\n",
      "  5: MaxPool2d\n",
      "4: Sequential\n",
      "  0: Inception\n",
      "  1: Inception\n",
      "  2: AdaptiveAvgPool2d\n",
      "  3: Flatten\n",
      "5: Linear\n",
      "The layer name is: ['S0_C0', 'S0_R1', 'S0_M2', 'S1_C0', 'S1_R1', 'S1_C2', 'S1_R3', 'S1_M4', 'S2_I0', 'S2_I1', 'S2_M2', 'S3_I0', 'S3_I1', 'S3_I2', 'S3_I3', 'S3_I4', 'S3_M5', 'S4_I0', 'S4_I1', 'S4_A2', 'S4_F3', 'L5']\n",
      "The length of layer name is: 22\n",
      "The number of blocks is: 5\n",
      "The number of inception blocks is: 9\n"
     ]
    }
   ],
   "source": [
    "net = Googlenet(1, 10)    \n",
    "LayerName = []\n",
    "block_num = 0\n",
    "incep_num = 0\n",
    "\n",
    "for num, layer in net.named_children():  # 使用 named_children 来获取层名和层\n",
    "    layername = layer.__class__.__name__\n",
    "    print(f\"{num}: {layername}\")  # 打印层名和层类名\n",
    "    \n",
    "    if layer.__class__.__name__ == 'Sequential':\n",
    "        block_num += 1\n",
    "        for sublayernum, sublayer in layer.named_children():  # 再次使用 named_children\n",
    "            sublayername = sublayer.__class__.__name__\n",
    "            if sublayername == 'Inception':\n",
    "                incep_num += 1\n",
    "            print(f\"  {sublayernum}: {sublayername}\")\n",
    "            layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}'\n",
    "            LayerName.append(layer_label)  # 收集子块的类型\n",
    "    else:\n",
    "        layer_label = f'{layername[0]}{num}'\n",
    "        LayerName.append(layer_label)  # 收集块的类型\n",
    "            # if sublayername == 'Inception':\n",
    "            #     incep_num += 1\n",
    "            #     for incepblocknum, incepblock in sublayer.named_children():  # 继续使用 named_children\n",
    "            #         incepblockname = incepblock.__class__.__name__\n",
    "            #         print(f\"    {incepblocknum}: {incepblockname}\")\n",
    "                    \n",
    "            #         layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}_{incepblockname[0]}{incepblocknum}'\n",
    "            #         # print('The layer label is:', layer_label)\n",
    "            #         LayerName.append(layer_label)  # 收集子子块的类型\n",
    "            # else:\n",
    "            #     layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}'\n",
    "            #     LayerName.append(layer_label)  # 收集子块的类型\n",
    "                        \n",
    "print('The layer name is:', LayerName)\n",
    "print(f'The length of layer name is: {len(LayerName)}')\n",
    "print('The number of blocks is:', block_num)\n",
    "print('The number of inception blocks is:', incep_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build different alexnet model for different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于不同的数据集，要设置不同的img_channel和num_labels\n",
    "# Fashion-MNIST中的图像通道数为1，类别数为10\n",
    "googlenet_f = Googlenet(1, 10)\n",
    "# CIFAR100中的图像通道数为3，类别数为100\n",
    "googlenet_c = Googlenet(3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Inception is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  5.98 M, 100.000% Params, 1.51 GMac, 99.594% MACs, \n",
      "  (0): Sequential(\n",
      "    3.2 k, 0.054% Params, 41.75 MMac, 2.752% MACs, \n",
      "    (0): Conv2d(3.2 k, 0.054% Params, 40.14 MMac, 2.646% MACs, 1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.053% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.053% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 1.923% Params, 361.87 MMac, 23.856% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.070% Params, 13.05 MMac, 0.860% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.013% MACs, )\n",
      "    (2): Conv2d(110.78 k, 1.853% Params, 347.42 MMac, 22.903% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.040% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.040% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    552.43 k, 9.242% Params, 433.83 MMac, 28.600% MACs, \n",
      "    (0): Inception(\n",
      "      163.7 k, 2.739% Params, 128.49 MMac, 8.470% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.207% Params, 9.68 MMac, 0.638% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(18.53 k, 0.310% Params, 14.53 MMac, 0.958% MACs, 192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(110.72 k, 1.852% Params, 86.8 MMac, 5.723% MACs, 96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(3.09 k, 0.052% Params, 2.42 MMac, 0.160% MACs, 192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(12.83 k, 0.215% Params, 10.06 MMac, 0.663% MACs, 16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 150.53 KMac, 0.010% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(6.18 k, 0.103% Params, 4.84 MMac, 0.319% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      388.74 k, 6.503% Params, 304.97 MMac, 20.105% MACs, \n",
      "      (p1_1): Conv2d(32.9 k, 0.550% Params, 25.79 MMac, 1.700% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(32.9 k, 0.550% Params, 25.79 MMac, 1.700% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(221.38 k, 3.703% Params, 173.56 MMac, 11.442% MACs, 128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(8.22 k, 0.138% Params, 6.45 MMac, 0.425% MACs, 256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(76.9 k, 1.286% Params, 60.29 MMac, 3.974% MACs, 32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 200.7 KMac, 0.013% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(16.45 k, 0.275% Params, 12.9 MMac, 0.850% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 376.32 KMac, 0.025% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    2.81 M, 46.995% Params, 551.26 MMac, 36.341% MACs, \n",
      "    (0): Inception(\n",
      "      376.18 k, 6.293% Params, 73.82 MMac, 4.867% MACs, \n",
      "      (p1_1): Conv2d(92.35 k, 1.545% Params, 18.1 MMac, 1.193% MACs, 480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(46.18 k, 0.772% Params, 9.05 MMac, 0.597% MACs, 480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(179.92 k, 3.010% Params, 35.26 MMac, 2.325% MACs, 96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(7.7 k, 0.129% Params, 1.51 MMac, 0.099% MACs, 480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(19.25 k, 0.322% Params, 3.77 MMac, 0.249% MACs, 16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 94.08 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(30.78 k, 0.515% Params, 6.03 MMac, 0.398% MACs, 480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      449.16 k, 7.514% Params, 88.14 MMac, 5.810% MACs, \n",
      "      (p1_1): Conv2d(82.08 k, 1.373% Params, 16.09 MMac, 1.061% MACs, 512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(57.46 k, 0.961% Params, 11.26 MMac, 0.742% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(226.02 k, 3.781% Params, 44.3 MMac, 2.920% MACs, 112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.206% Params, 2.41 MMac, 0.159% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.643% Params, 7.54 MMac, 0.497% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.549% Params, 6.44 MMac, 0.424% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception(\n",
      "      510.1 k, 8.534% Params, 100.08 MMac, 6.598% MACs, \n",
      "      (p1_1): Conv2d(65.66 k, 1.099% Params, 12.87 MMac, 0.848% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(65.66 k, 1.099% Params, 12.87 MMac, 0.848% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(295.17 k, 4.938% Params, 57.85 MMac, 3.814% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.206% Params, 2.41 MMac, 0.159% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.643% Params, 7.54 MMac, 0.497% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.549% Params, 6.44 MMac, 0.424% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception(\n",
      "      605.38 k, 10.128% Params, 118.75 MMac, 7.829% MACs, \n",
      "      (p1_1): Conv2d(57.46 k, 0.961% Params, 11.26 MMac, 0.742% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(73.87 k, 1.236% Params, 14.48 MMac, 0.955% MACs, 512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(373.54 k, 6.249% Params, 73.21 MMac, 4.827% MACs, 144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.42 k, 0.275% Params, 3.22 MMac, 0.212% MACs, 512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(51.26 k, 0.858% Params, 10.05 MMac, 0.662% MACs, 32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.549% Params, 6.44 MMac, 0.424% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception(\n",
      "      868.35 k, 14.527% Params, 170.3 MMac, 11.227% MACs, \n",
      "      (p1_1): Conv2d(135.42 k, 2.266% Params, 26.54 MMac, 1.750% MACs, 528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(84.64 k, 1.416% Params, 16.59 MMac, 1.094% MACs, 528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.714% Params, 90.38 MMac, 5.958% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.93 k, 0.283% Params, 3.32 MMac, 0.219% MACs, 528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.715% Params, 20.1 MMac, 1.325% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 103.49 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(67.71 k, 1.133% Params, 13.27 MMac, 0.875% MACs, 528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 163.07 KMac, 0.011% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    2.49 M, 41.615% Params, 122.02 MMac, 8.044% MACs, \n",
      "    (0): Inception(\n",
      "      1.04 M, 17.456% Params, 51.17 MMac, 3.373% MACs, \n",
      "      (p1_1): Conv2d(213.25 k, 3.567% Params, 10.45 MMac, 0.689% MACs, 832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(133.28 k, 2.230% Params, 6.53 MMac, 0.431% MACs, 832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.714% Params, 22.59 MMac, 1.490% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(26.66 k, 0.446% Params, 1.31 MMac, 0.086% MACs, 832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.715% Params, 5.02 MMac, 0.331% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.784% Params, 5.22 MMac, 0.344% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      1.44 M, 24.158% Params, 70.8 MMac, 4.667% MACs, \n",
      "      (p1_1): Conv2d(319.87 k, 5.351% Params, 15.67 MMac, 1.033% MACs, 832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(159.94 k, 2.676% Params, 7.84 MMac, 0.517% MACs, 832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(663.94 k, 11.107% Params, 32.53 MMac, 2.145% MACs, 192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(39.98 k, 0.669% Params, 1.96 MMac, 0.129% MACs, 832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(153.73 k, 2.572% Params, 7.53 MMac, 0.497% MACs, 48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.784% Params, 5.22 MMac, 0.344% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 50.18 KMac, 0.003% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(10.25 k, 0.171% Params, 10.25 KMac, 0.001% MACs, in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       1.52 GMac\n",
      "Number of parameters:           5.98 M  \n",
      "**************************************************\n",
      "Warning: module Inception is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  6.08 M, 100.000% Params, 1.59 GMac, 99.614% MACs, \n",
      "  (0): Sequential(\n",
      "    9.47 k, 0.156% Params, 120.42 MMac, 7.547% MACs, \n",
      "    (0): Conv2d(9.47 k, 0.156% Params, 118.82 MMac, 7.446% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.050% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.050% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 1.892% Params, 361.87 MMac, 22.678% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.068% Params, 13.05 MMac, 0.818% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.013% MACs, )\n",
      "    (2): Conv2d(110.78 k, 1.823% Params, 347.42 MMac, 21.773% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.038% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.038% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    552.43 k, 9.092% Params, 433.83 MMac, 27.188% MACs, \n",
      "    (0): Inception(\n",
      "      163.7 k, 2.694% Params, 128.49 MMac, 8.052% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.203% Params, 9.68 MMac, 0.607% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(18.53 k, 0.305% Params, 14.53 MMac, 0.910% MACs, 192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(110.72 k, 1.822% Params, 86.8 MMac, 5.440% MACs, 96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(3.09 k, 0.051% Params, 2.42 MMac, 0.152% MACs, 192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(12.83 k, 0.211% Params, 10.06 MMac, 0.630% MACs, 16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 150.53 KMac, 0.009% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(6.18 k, 0.102% Params, 4.84 MMac, 0.303% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      388.74 k, 6.398% Params, 304.97 MMac, 19.112% MACs, \n",
      "      (p1_1): Conv2d(32.9 k, 0.541% Params, 25.79 MMac, 1.616% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(32.9 k, 0.541% Params, 25.79 MMac, 1.616% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(221.38 k, 3.643% Params, 173.56 MMac, 10.877% MACs, 128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(8.22 k, 0.135% Params, 6.45 MMac, 0.404% MACs, 256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(76.9 k, 1.266% Params, 60.29 MMac, 3.778% MACs, 32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 200.7 KMac, 0.013% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(16.45 k, 0.271% Params, 12.9 MMac, 0.808% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 376.32 KMac, 0.024% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    2.81 M, 46.233% Params, 551.26 MMac, 34.547% MACs, \n",
      "    (0): Inception(\n",
      "      376.18 k, 6.191% Params, 73.82 MMac, 4.627% MACs, \n",
      "      (p1_1): Conv2d(92.35 k, 1.520% Params, 18.1 MMac, 1.134% MACs, 480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(46.18 k, 0.760% Params, 9.05 MMac, 0.567% MACs, 480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(179.92 k, 2.961% Params, 35.26 MMac, 2.210% MACs, 96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(7.7 k, 0.127% Params, 1.51 MMac, 0.095% MACs, 480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(19.25 k, 0.317% Params, 3.77 MMac, 0.236% MACs, 16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 94.08 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(30.78 k, 0.507% Params, 6.03 MMac, 0.378% MACs, 480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      449.16 k, 7.392% Params, 88.14 MMac, 5.523% MACs, \n",
      "      (p1_1): Conv2d(82.08 k, 1.351% Params, 16.09 MMac, 1.008% MACs, 512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(57.46 k, 0.946% Params, 11.26 MMac, 0.706% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(226.02 k, 3.720% Params, 44.3 MMac, 2.776% MACs, 112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.203% Params, 2.41 MMac, 0.151% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.633% Params, 7.54 MMac, 0.472% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.540% Params, 6.44 MMac, 0.403% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception(\n",
      "      510.1 k, 8.395% Params, 100.08 MMac, 6.272% MACs, \n",
      "      (p1_1): Conv2d(65.66 k, 1.081% Params, 12.87 MMac, 0.807% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(65.66 k, 1.081% Params, 12.87 MMac, 0.807% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(295.17 k, 4.858% Params, 57.85 MMac, 3.626% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.203% Params, 2.41 MMac, 0.151% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.633% Params, 7.54 MMac, 0.472% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.540% Params, 6.44 MMac, 0.403% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception(\n",
      "      605.38 k, 9.963% Params, 118.75 MMac, 7.442% MACs, \n",
      "      (p1_1): Conv2d(57.46 k, 0.946% Params, 11.26 MMac, 0.706% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(73.87 k, 1.216% Params, 14.48 MMac, 0.907% MACs, 512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(373.54 k, 6.148% Params, 73.21 MMac, 4.588% MACs, 144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.42 k, 0.270% Params, 3.22 MMac, 0.202% MACs, 512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(51.26 k, 0.844% Params, 10.05 MMac, 0.630% MACs, 32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.540% Params, 6.44 MMac, 0.403% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception(\n",
      "      868.35 k, 14.291% Params, 170.3 MMac, 10.673% MACs, \n",
      "      (p1_1): Conv2d(135.42 k, 2.229% Params, 26.54 MMac, 1.663% MACs, 528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(84.64 k, 1.393% Params, 16.59 MMac, 1.040% MACs, 528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.589% Params, 90.38 MMac, 5.664% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.93 k, 0.279% Params, 3.32 MMac, 0.208% MACs, 528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.687% Params, 20.1 MMac, 1.259% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 103.49 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(67.71 k, 1.114% Params, 13.27 MMac, 0.832% MACs, 528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 163.07 KMac, 0.010% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    2.49 M, 40.940% Params, 122.02 MMac, 7.647% MACs, \n",
      "    (0): Inception(\n",
      "      1.04 M, 17.173% Params, 51.17 MMac, 3.207% MACs, \n",
      "      (p1_1): Conv2d(213.25 k, 3.510% Params, 10.45 MMac, 0.655% MACs, 832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(133.28 k, 2.194% Params, 6.53 MMac, 0.409% MACs, 832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.589% Params, 22.59 MMac, 1.416% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(26.66 k, 0.439% Params, 1.31 MMac, 0.082% MACs, 832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.687% Params, 5.02 MMac, 0.315% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.755% Params, 5.22 MMac, 0.327% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      1.44 M, 23.767% Params, 70.8 MMac, 4.437% MACs, \n",
      "      (p1_1): Conv2d(319.87 k, 5.264% Params, 15.67 MMac, 0.982% MACs, 832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(159.94 k, 2.632% Params, 7.84 MMac, 0.491% MACs, 832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(663.94 k, 10.927% Params, 32.53 MMac, 2.039% MACs, 192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(39.98 k, 0.658% Params, 1.96 MMac, 0.123% MACs, 832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(153.73 k, 2.530% Params, 7.53 MMac, 0.472% MACs, 48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.755% Params, 5.22 MMac, 0.327% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 50.18 KMac, 0.003% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(102.5 k, 1.687% Params, 102.5 KMac, 0.006% MACs, in_features=1024, out_features=100, bias=True)\n",
      ")\n",
      "Computational complexity:       1.6 GMac\n",
      "Number of parameters:           6.08 M  \n"
     ]
    }
   ],
   "source": [
    "# fashion mnist\n",
    "with torch.cuda.device(0):\n",
    "    macs_f, params_f = get_model_complexity_info(googlenet_f, (1, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_f))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_f))\n",
    "\n",
    "print('*'*50)\n",
    "\n",
    "# cifar100\n",
    "with torch.cuda.device(0):\n",
    "    macs_c, params_c = get_model_complexity_info(googlenet_c, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_c))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 192, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 480, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 832, 7, 7])\n",
      "Sequential output shape:\t torch.Size([1, 1024])\n",
      "Linear output shape:\t torch.Size([1, 10])\n",
      "**************************************************\n",
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 192, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 480, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 832, 7, 7])\n",
      "Sequential output shape:\t torch.Size([1, 1024])\n",
      "Linear output shape:\t torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "X_f = torch.randn(size=(1, 1, 224, 224), dtype=torch.float32) # fashion mnist\n",
    "X_c = torch.randn(size=(1, 3, 224, 224), dtype=torch.float32) # cifar100\n",
    "\n",
    "for layer in googlenet_f:\n",
    "    X_f=layer(X_f)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X_f.shape)\n",
    "\n",
    "print('*'*50)\n",
    "\n",
    "for layer in googlenet_c:\n",
    "    X_c=layer(X_c)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# fashion mnist\n",
    "def get_dataloader_workers():\n",
    "    \"\"\"Use 4 processes to read the data.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    return 4\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\n",
    "\n",
    "    Defined in :numref:`sec_fashion_mnist`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=get_dataloader_workers()))\n",
    "\n",
    "def load_data_cifar100(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    # import the cifar100 dataset\n",
    "    cifar_train = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    cifar_test = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(cifar_train, batch_size, shuffle=True,\n",
    "                                        num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(cifar_test, batch_size, shuffle=False,\n",
    "                                        num_workers=get_dataloader_workers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = [128, 256, 512]\n",
    "batch_size = [256]\n",
    "# epochs = [10, 20, 30, 40, 50]\n",
    "epochs = [20]\n",
    "rounds = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(net, train_iter, test_iter, LayerName, num_epochs, lr, device):\n",
    "    def init_weights(m): # 初始化权重\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    # record each block running time\n",
    "    Layers_time = np.zeros((len(LayerName), num_epochs)) # each row is a layer, each column is an epoch\n",
    "    Train_part_time = np.zeros((6, num_epochs)) # store the time to device, forward and backward time, and test time of each epoch\n",
    "    Train_acc = np.zeros(num_epochs) # store the training accuracy of each epoch\n",
    "    Test_acc = np.zeros(num_epochs) # store the test accuracy of each epoch\n",
    "    Epoch_time = np.zeros(num_epochs) # store the total time of each epoch\n",
    "    Epoch_energy = np.zeros((num_epochs,1), dtype='object') # store the total energy of each epoch\n",
    "    timer = d2l.Timer()\n",
    "    train_timer = d2l.Timer()\n",
    "    ttd_timer = d2l.Timer()\n",
    "    forward_timer = d2l.Timer()\n",
    "    loss_timer = d2l.Timer()\n",
    "    backward_timer = d2l.Timer()\n",
    "    optimizer_timer = d2l.Timer()\n",
    "    layer_timer = d2l.Timer()\n",
    "    test_timer = d2l.Timer()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    # start training\n",
    "    for epoch in range(num_epochs):\n",
    "        print('The epoch is:', epoch+1)\n",
    "        timer.start()\n",
    "        net.train()\n",
    "        ttd_epoch, forward_epoch, loss_epoch, backward_epoch, optimization_epoch, testtime_epoch= 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "        layer_epoch = np.zeros((len(LayerName), 1)) # store the total running time of each layer in one epoch\n",
    "        metric = d2l.Accumulator(3)  # train_loss, train_acc, num_examples   \n",
    "        # start the nvidia-smi command\n",
    "        with open('gpu_power_usage.csv', 'w') as file:\n",
    "            # Start the nvidia-smi command\n",
    "            nvidia_smi_process = subprocess.Popen(\n",
    "                [\"nvidia-smi\", \"--query-gpu=power.draw\", \"--format=csv\", \"--loop-ms=1000\"],\n",
    "                stdout=file,  # Redirect the output directly to the file\n",
    "                stderr=subprocess.PIPE,\n",
    "                text=True)\n",
    "        train_timer.start()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            batch_block_num = 0\n",
    "            # print('The batch is:', i+1)\n",
    "            optimizer.zero_grad()\n",
    "            # to device\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            ttd_timer.start()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            ttd_epoch += ttd_timer.stop()\n",
    "            # forward\n",
    "            forward_timer.start()\n",
    "            y_hat = X\n",
    "            for num, layer in net.named_children():\n",
    "                layername = layer.__class__.__name__\n",
    "                if layername == 'Sequential':\n",
    "                    for sublayernum, sublayer in layer.named_children():\n",
    "                        sublayername = sublayer.__class__.__name__\n",
    "                        Layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}'\n",
    "                        layer_index = LayerName.index(Layer_label)\n",
    "                        # print('The layer index is:', layer_index, 'The layer label is:', Layer_label)\n",
    "                        layer_timer.start()\n",
    "                        y_hat = sublayer(y_hat)\n",
    "                        torch.cuda.synchronize()\n",
    "                        layer_epoch[layer_index] += layer_timer.stop()\n",
    "                else:\n",
    "                    Layer_label = f'{layername[0]}{num}'\n",
    "                    layer_index = LayerName.index(Layer_label)\n",
    "                    # print('The layer index is:', layer_index, 'The layer label is:', Layer_label)\n",
    "                    layer_timer.start()\n",
    "                    y_hat = layer(y_hat)\n",
    "                    torch.cuda.synchronize()\n",
    "                    layer_epoch[layer_index] += layer_timer.stop()\n",
    "            torch.cuda.synchronize()\n",
    "            forward_epoch += forward_timer.stop()\n",
    "            # loss\n",
    "            loss_timer.start()\n",
    "            l = loss_fn(y_hat, y)\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            loss_epoch += loss_timer.stop()\n",
    "            # backward\n",
    "            backward_timer.start()\n",
    "            l.backward()\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            backward_epoch += backward_timer.stop()\n",
    "            # optimize\n",
    "            optimizer_timer.start()\n",
    "            optimizer.step()\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            optimization_epoch += optimizer_timer.stop()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l*X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            train_acc = metric[1] / metric[2]\n",
    "        train_epoch = train_timer.stop()\n",
    "        test_timer.start()\n",
    "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n",
    "        testtime_epoch = test_timer.stop()\n",
    "        print(f'train acc {train_acc:.3f}, test acc {test_acc:.3f}')\n",
    "        print('epoch %d, time %f sec' % (epoch+1, timer.sum()))\n",
    "        # store the time and acc data\n",
    "        Epoch_time[epoch] = timer.stop()\n",
    "        print(f'The total time of the {epoch} is:', Epoch_time[epoch])\n",
    "        Layers_time[:, epoch] = layer_epoch.flatten()\n",
    "        Train_part_time[:, epoch] = ttd_epoch, forward_epoch, loss_epoch, backward_epoch, optimization_epoch, testtime_epoch\n",
    "        print(ttd_epoch, forward_epoch, loss_epoch, backward_epoch, optimization_epoch, testtime_epoch)\n",
    "        print('*'*50)\n",
    "        print(testtime_epoch)\n",
    "        Train_acc[epoch] = train_acc\n",
    "        Test_acc[epoch] = test_acc\n",
    "        # stop the nvidia-smi command\n",
    "        nvidia_smi_process.terminate()\n",
    "        # calculate the energy consumption of each epoch\n",
    "        GPU_df = pd.read_csv('gpu_power_usage.csv')\n",
    "        for row in range(len(GPU_df)):\n",
    "            GPU_df.iloc[row,0] = GPU_df.iloc[row,0].replace(' W','')\n",
    "        Consumption_df = GPU_df.astype(float)  \n",
    "        EnergyDatai = Consumption_df.iloc[:,0].values # 将数据转换为numpy数组\n",
    "        # store the energy data\n",
    "        Epoch_energy[epoch,0] = EnergyDatai\n",
    "    return Layers_time, Train_part_time, Train_acc, Test_acc, Epoch_time, Epoch_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_f(main_folder, batch_size, num_epochs, round, lr, device, LayerName):\n",
    "    print(f'The epoch is set: {num_epochs}, batch is set: {batch_size}, is in {round+1}th running')\n",
    "    # create the folder to store the data\n",
    "    epoch_batch_folder = main_folder/f'E{num_epochs}_B{batch_size}_R{round}'\n",
    "    # 判断文件是否存在\n",
    "    if epoch_batch_folder.exists():\n",
    "        print(\"文件存在。\")\n",
    "    else:\n",
    "        os.makedirs(epoch_batch_folder)\n",
    "        print(\"文件不存在，已创建。\")\n",
    "        print(\"文件创建于：\", epoch_batch_folder)\n",
    "    train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n",
    "    # show the shape of the data\n",
    "    list_of_i = []\n",
    "    for i, (X, y) in enumerate(train_iter):\n",
    "        if i < 3:\n",
    "            print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "        else:\n",
    "            pass\n",
    "        list_of_i.append(i)\n",
    "    print(f'The number of batches is: {np.array(list_of_i).shape}')\n",
    "    Layers_time, Train_part_time, Train_acc, Test_acc, \\\n",
    "        Epoch_time, Epoch_energy = train_func(googlenet_f, train_iter, test_iter, LayerName, num_epochs, lr, device)\n",
    "    # save the data\n",
    "    np.save(epoch_batch_folder/'Layers_time.npy', Layers_time)\n",
    "    np.save(epoch_batch_folder/'Train_part_time.npy', Train_part_time)\n",
    "    np.save(epoch_batch_folder/'Train_acc.npy', Train_acc)\n",
    "    np.save(epoch_batch_folder/'Test_acc.npy', Test_acc)\n",
    "    np.save(epoch_batch_folder/'Epoch_time.npy', Epoch_time)\n",
    "    np.save(epoch_batch_folder/'Epoch_energy.npy', Epoch_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_c(main_folder, batch_size, num_epochs, round, lr, device, LayerName):\n",
    "    print(f'The epoch is set: {num_epochs}, batch is set: {batch_size}, is in {round+1}th running')\n",
    "    # create the folder to store the data\n",
    "    epoch_batch_folder = main_folder/f'E{num_epochs}_B{batch_size}_R{round}'\n",
    "    # 判断文件是否存在\n",
    "    if epoch_batch_folder.exists():\n",
    "        print(\"文件存在。\")\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(epoch_batch_folder)\n",
    "        print(\"文件不存在，已创建。\")\n",
    "        print(\"文件创建于：\", epoch_batch_folder)\n",
    "        train_iter, test_iter = load_data_cifar100(batch_size, resize=224)\n",
    "        # show the shape of the data\n",
    "        list_of_i = []\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            if i < 3:\n",
    "                print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "            else:\n",
    "                pass\n",
    "            list_of_i.append(i)\n",
    "        print(f'The number of batches is: {np.array(list_of_i).shape}')\n",
    "        Layers_time, Train_part_time, Train_acc, Test_acc, \\\n",
    "            Epoch_time, Epoch_energy = train_func(googlenet_c, train_iter, test_iter, LayerName, num_epochs, lr, device)\n",
    "        # save the data\n",
    "        np.save(epoch_batch_folder/'Layers_time.npy', Layers_time)\n",
    "        np.save(epoch_batch_folder/'Train_part_time.npy', Train_part_time)\n",
    "        np.save(epoch_batch_folder/'Train_acc.npy', Train_acc)\n",
    "        np.save(epoch_batch_folder/'Test_acc.npy', Test_acc)\n",
    "        np.save(epoch_batch_folder/'Epoch_time.npy', Epoch_time)\n",
    "        np.save(epoch_batch_folder/'Epoch_energy.npy', Epoch_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is: cuda\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('The device is:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder is: /root/GreenAI/Cloud/4090/Data/googlenet/fashion_mnist\n",
      "文件存在。\n",
      "The epoch is set: 20, batch is set: 256, is in 1th running\n",
      "文件不存在，已创建。\n",
      "文件创建于： /root/GreenAI/Cloud/4090/Data/googlenet/fashion_mnist/E20_B256_R0\n",
      "the shape of the 0 batch of the train_iter is: torch.Size([256, 1, 224, 224])\n",
      "the shape of the 1 batch of the train_iter is: torch.Size([256, 1, 224, 224])\n",
      "the shape of the 2 batch of the train_iter is: torch.Size([256, 1, 224, 224])\n",
      "The number of batches is: (235,)\n",
      "training on cuda\n",
      "The epoch is: 1\n",
      "train acc 0.101, test acc 0.100\n",
      "epoch 1, time 0.000000 sec\n",
      "The total time of the 0 is: 42.916255950927734\n",
      "2.749173641204834 10.58615255355835 0.1134791374206543 20.821338415145874 0.33318328857421875 3.2338147163391113\n",
      "**************************************************\n",
      "3.2338147163391113\n",
      "The epoch is: 2\n",
      "train acc 0.115, test acc 0.100\n",
      "epoch 2, time 42.916256 sec\n",
      "The total time of the 1 is: 41.20322895050049\n",
      "2.621412992477417 9.813942432403564 0.0744771957397461 20.25243854522705 0.2799339294433594 3.3297080993652344\n",
      "**************************************************\n",
      "3.3297080993652344\n",
      "The epoch is: 3\n",
      "train acc 0.131, test acc 0.206\n",
      "epoch 3, time 84.119485 sec\n",
      "The total time of the 2 is: 41.016690731048584\n",
      "2.5185718536376953 9.845067977905273 0.07361364364624023 20.2532639503479 0.2980985641479492 3.1670284271240234\n",
      "**************************************************\n",
      "3.1670284271240234\n",
      "The epoch is: 4\n",
      "train acc 0.143, test acc 0.123\n",
      "epoch 4, time 125.136176 sec\n",
      "The total time of the 3 is: 40.72942495346069\n",
      "2.4980220794677734 9.802775859832764 0.0698699951171875 20.227755546569824 0.276813268661499 3.3240280151367188\n",
      "**************************************************\n",
      "3.3240280151367188\n",
      "The epoch is: 5\n",
      "train acc 0.193, test acc 0.247\n",
      "epoch 5, time 165.865601 sec\n",
      "The total time of the 4 is: 40.69494867324829\n",
      "2.332285165786743 9.813026428222656 0.06959843635559082 20.220710277557373 0.28209519386291504 3.4524271488189697\n",
      "**************************************************\n",
      "3.4524271488189697\n",
      "The epoch is: 6\n",
      "train acc 0.238, test acc 0.320\n",
      "epoch 6, time 206.560549 sec\n",
      "The total time of the 5 is: 40.638243436813354\n",
      "2.4582273960113525 9.809192895889282 0.06988954544067383 20.228623390197754 0.27709507942199707 3.2573366165161133\n",
      "**************************************************\n",
      "3.2573366165161133\n",
      "The epoch is: 7\n",
      "train acc 0.257, test acc 0.348\n",
      "epoch 7, time 247.198793 sec\n",
      "The total time of the 6 is: 40.853323459625244\n",
      "2.527137041091919 9.821940898895264 0.07083415985107422 20.211817264556885 0.28562164306640625 3.2578132152557373\n",
      "**************************************************\n",
      "3.2578132152557373\n",
      "The epoch is: 8\n",
      "train acc 0.299, test acc 0.219\n",
      "epoch 8, time 288.052116 sec\n",
      "The total time of the 7 is: 42.048460483551025\n",
      "2.845599889755249 9.922324895858765 0.08701753616333008 20.264448404312134 0.33478856086730957 3.2585012912750244\n",
      "**************************************************\n",
      "3.2585012912750244\n",
      "The epoch is: 9\n",
      "train acc 0.232, test acc 0.243\n",
      "epoch 9, time 330.100577 sec\n",
      "The total time of the 8 is: 41.03649187088013\n",
      "2.5429768562316895 9.846874713897705 0.0809025764465332 20.32543683052063 0.3002142906188965 3.079723358154297\n",
      "**************************************************\n",
      "3.079723358154297\n",
      "The epoch is: 10\n",
      "train acc 0.359, test acc 0.470\n",
      "epoch 10, time 371.137069 sec\n",
      "The total time of the 9 is: 41.55695462226868\n",
      "2.6069672107696533 9.908844232559204 0.08527779579162598 20.32944345474243 0.3302168846130371 3.325845956802368\n",
      "**************************************************\n",
      "3.325845956802368\n",
      "The epoch is: 11\n",
      "train acc 0.522, test acc 0.515\n",
      "epoch 11, time 412.694023 sec\n",
      "The total time of the 10 is: 41.28294062614441\n",
      "2.561189889907837 9.828609943389893 0.07942962646484375 20.3256094455719 0.2932248115539551 3.4460651874542236\n",
      "**************************************************\n",
      "3.4460651874542236\n",
      "The epoch is: 12\n",
      "train acc 0.592, test acc 0.599\n",
      "epoch 12, time 453.976964 sec\n",
      "The total time of the 11 is: 41.17637872695923\n",
      "2.5437121391296387 9.86486530303955 0.08430981636047363 20.32570767402649 0.30857205390930176 3.366523504257202\n",
      "**************************************************\n",
      "3.366523504257202\n",
      "The epoch is: 13\n",
      "train acc 0.649, test acc 0.627\n",
      "epoch 13, time 495.153342 sec\n",
      "The total time of the 12 is: 43.718637466430664\n",
      "3.2436463832855225 9.937808752059937 0.09139513969421387 20.386287689208984 0.33244800567626953 3.277013063430786\n",
      "**************************************************\n",
      "3.277013063430786\n",
      "The epoch is: 14\n",
      "train acc 0.682, test acc 0.701\n",
      "epoch 14, time 538.871980 sec\n",
      "The total time of the 13 is: 41.9009907245636\n",
      "2.86950945854187 9.864322900772095 0.0790259838104248 20.26870107650757 0.3076605796813965 3.351344108581543\n",
      "**************************************************\n",
      "3.351344108581543\n",
      "The epoch is: 15\n",
      "train acc 0.714, test acc 0.627\n",
      "epoch 15, time 580.772971 sec\n",
      "The total time of the 14 is: 41.161078214645386\n",
      "2.613861083984375 9.819210767745972 0.07205486297607422 20.282224416732788 0.2791104316711426 3.2629289627075195\n",
      "**************************************************\n",
      "3.2629289627075195\n",
      "The epoch is: 16\n",
      "train acc 0.739, test acc 0.758\n",
      "epoch 16, time 621.934049 sec\n",
      "The total time of the 15 is: 40.93644976615906\n",
      "2.5100839138031006 9.797741413116455 0.07030415534973145 20.2603497505188 0.2717010974884033 3.2577202320098877\n",
      "**************************************************\n",
      "3.2577202320098877\n",
      "The epoch is: 17\n",
      "train acc 0.764, test acc 0.628\n",
      "epoch 17, time 662.870499 sec\n",
      "The total time of the 16 is: 42.15779232978821\n",
      "2.8567464351654053 9.938035726547241 0.08223843574523926 20.297949075698853 0.3233654499053955 3.5635948181152344\n",
      "**************************************************\n",
      "3.5635948181152344\n",
      "The epoch is: 18\n",
      "train acc 0.781, test acc 0.753\n",
      "epoch 18, time 705.028291 sec\n",
      "The total time of the 17 is: 41.03719615936279\n",
      "2.476087808609009 9.80979061126709 0.07009720802307129 20.26045298576355 0.27224206924438477 3.4892492294311523\n",
      "**************************************************\n",
      "3.4892492294311523\n",
      "The epoch is: 19\n",
      "train acc 0.793, test acc 0.777\n",
      "epoch 19, time 746.065487 sec\n",
      "The total time of the 18 is: 41.17293977737427\n",
      "2.664982557296753 9.86329960823059 0.07313966751098633 20.24390959739685 0.28772854804992676 3.302471876144409\n",
      "**************************************************\n",
      "3.302471876144409\n",
      "The epoch is: 20\n",
      "train acc 0.806, test acc 0.812\n",
      "epoch 20, time 787.238427 sec\n",
      "The total time of the 19 is: 41.389437437057495\n",
      "2.66731595993042 9.849269390106201 0.0735936164855957 20.27367854118347 0.2886934280395508 3.3210222721099854\n",
      "**************************************************\n",
      "3.3210222721099854\n"
     ]
    }
   ],
   "source": [
    "# create the folder to store the data\n",
    "main_folder = data_path/'fashion_mnist'\n",
    "print('The folder is:', main_folder)\n",
    "# find out that if the folder exists in the data path\n",
    "# 判断文件是否存在\n",
    "if main_folder.exists():\n",
    "    print(\"文件存在。\")\n",
    "else:\n",
    "    os.makedirs(main_folder)\n",
    "    print(\"文件不存在，已创建。\")\n",
    "    print(\"文件创建于：\", main_folder)\n",
    "for epoch in epochs:\n",
    "    for batch in batch_size:\n",
    "        for round in range(rounds):\n",
    "            train_model_f(main_folder, batch, epoch, round, lr, device, LayerName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder is: /root/GreenAI/Cloud/4090/Data/googlenet/cifar100\n",
      "文件存在。\n",
      "The epoch is set: 20, batch is set: 256, is in 1th running\n",
      "文件不存在，已创建。\n",
      "文件创建于： /root/GreenAI/Cloud/4090/Data/googlenet/cifar100/E20_B256_R0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "the shape of the 0 batch of the train_iter is: torch.Size([256, 3, 224, 224])\n",
      "the shape of the 1 batch of the train_iter is: torch.Size([256, 3, 224, 224])\n",
      "the shape of the 2 batch of the train_iter is: torch.Size([256, 3, 224, 224])\n",
      "The number of batches is: (196,)\n",
      "training on cuda\n",
      "The epoch is: 1\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 1, time 0.000000 sec\n",
      "The total time of the 0 is: 46.869489431381226\n",
      "5.738188982009888 8.450026035308838 0.05538773536682129 17.523057460784912 0.22110795974731445 5.544356822967529\n",
      "**************************************************\n",
      "5.544356822967529\n",
      "The epoch is: 2\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 2, time 46.869489 sec\n",
      "The total time of the 1 is: 47.60784649848938\n",
      "6.211095333099365 8.315213441848755 0.06212115287780762 17.338401317596436 0.23215961456298828 5.547494888305664\n",
      "**************************************************\n",
      "5.547494888305664\n",
      "The epoch is: 3\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 3, time 94.477336 sec\n",
      "The total time of the 2 is: 47.05847716331482\n",
      "6.031219959259033 8.319075107574463 0.0602724552154541 17.324689865112305 0.22232961654663086 5.583171129226685\n",
      "**************************************************\n",
      "5.583171129226685\n",
      "The epoch is: 4\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 4, time 141.535813 sec\n",
      "The total time of the 3 is: 47.867008447647095\n",
      "6.422108888626099 8.305735111236572 0.060457468032836914 17.34335708618164 0.22571563720703125 5.684279203414917\n",
      "**************************************************\n",
      "5.684279203414917\n",
      "The epoch is: 5\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 5, time 189.402822 sec\n",
      "The total time of the 4 is: 47.72994542121887\n",
      "6.201880693435669 8.32585334777832 0.06124734878540039 17.34066915512085 0.22550702095031738 5.7738871574401855\n",
      "**************************************************\n",
      "5.7738871574401855\n",
      "The epoch is: 6\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 6, time 237.132767 sec\n",
      "The total time of the 5 is: 48.2895712852478\n",
      "6.614770889282227 8.323081970214844 0.06245279312133789 17.346962690353394 0.2299206256866455 5.513441324234009\n",
      "**************************************************\n",
      "5.513441324234009\n",
      "The epoch is: 7\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 7, time 285.422338 sec\n",
      "The total time of the 6 is: 46.76926589012146\n",
      "5.875466346740723 8.295085668563843 0.0578916072845459 17.30062222480774 0.22366023063659668 5.669566869735718\n",
      "**************************************************\n",
      "5.669566869735718\n",
      "The epoch is: 8\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 8, time 332.191604 sec\n",
      "The total time of the 7 is: 46.86226987838745\n",
      "5.880934715270996 8.284310102462769 0.059310197830200195 17.34207248687744 0.22086596488952637 5.626314163208008\n",
      "**************************************************\n",
      "5.626314163208008\n",
      "The epoch is: 9\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 9, time 379.053874 sec\n",
      "The total time of the 8 is: 48.98064351081848\n",
      "7.129108428955078 8.332176446914673 0.06305861473083496 17.37206745147705 0.24085736274719238 5.775350332260132\n",
      "**************************************************\n",
      "5.775350332260132\n",
      "The epoch is: 10\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 10, time 428.034518 sec\n",
      "The total time of the 9 is: 46.552762508392334\n",
      "5.6360883712768555 8.286635398864746 0.058476924896240234 17.332021951675415 0.22042536735534668 5.592027902603149\n",
      "**************************************************\n",
      "5.592027902603149\n",
      "The epoch is: 11\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 11, time 474.587280 sec\n",
      "The total time of the 10 is: 46.49115443229675\n",
      "5.768638610839844 8.319044828414917 0.05995774269104004 17.31914520263672 0.22569561004638672 5.334305286407471\n",
      "**************************************************\n",
      "5.334305286407471\n",
      "The epoch is: 12\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 12, time 521.078434 sec\n",
      "The total time of the 11 is: 47.135905265808105\n",
      "5.913585662841797 8.289759874343872 0.0585017204284668 17.323169231414795 0.21533679962158203 5.71106743812561\n",
      "**************************************************\n",
      "5.71106743812561\n",
      "The epoch is: 13\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 13, time 568.214340 sec\n",
      "The total time of the 12 is: 47.87404465675354\n",
      "6.356010675430298 8.317206382751465 0.0608820915222168 17.320488929748535 0.2335047721862793 5.642795562744141\n",
      "**************************************************\n",
      "5.642795562744141\n",
      "The epoch is: 14\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 14, time 616.088384 sec\n",
      "The total time of the 13 is: 46.780359745025635\n",
      "6.1101062297821045 8.28972315788269 0.059647321701049805 17.31707525253296 0.21822071075439453 5.240921497344971\n",
      "**************************************************\n",
      "5.240921497344971\n",
      "The epoch is: 15\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 15, time 662.868744 sec\n",
      "The total time of the 14 is: 46.66379928588867\n",
      "5.910441875457764 8.320347547531128 0.05932140350341797 17.31743550300598 0.22196435928344727 5.418346166610718\n",
      "**************************************************\n",
      "5.418346166610718\n",
      "The epoch is: 16\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 16, time 709.532543 sec\n",
      "The total time of the 15 is: 46.5027494430542\n",
      "5.77855372428894 8.28927755355835 0.05964851379394531 17.320292472839355 0.21892166137695312 5.5749571323394775\n",
      "**************************************************\n",
      "5.5749571323394775\n",
      "The epoch is: 17\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 17, time 756.035293 sec\n",
      "The total time of the 16 is: 48.23037910461426\n",
      "6.461384057998657 8.327760457992554 0.06255173683166504 17.34575128555298 0.22847723960876465 5.6638970375061035\n",
      "**************************************************\n",
      "5.6638970375061035\n",
      "The epoch is: 18\n",
      "train acc 0.010, test acc 0.010\n",
      "epoch 18, time 804.265672 sec\n",
      "The total time of the 17 is: 46.79837131500244\n",
      "6.039863348007202 8.293956518173218 0.05797982215881348 17.320834159851074 0.21809077262878418 5.249520540237427\n",
      "**************************************************\n",
      "5.249520540237427\n",
      "The epoch is: 19\n",
      "train acc 0.010, test acc 0.011\n",
      "epoch 19, time 851.064043 sec\n",
      "The total time of the 18 is: 46.93475604057312\n",
      "6.112359046936035 8.298252582550049 0.05831575393676758 17.321664810180664 0.21878480911254883 5.190396070480347\n",
      "**************************************************\n",
      "5.190396070480347\n",
      "The epoch is: 20\n",
      "train acc 0.011, test acc 0.011\n",
      "epoch 20, time 897.998799 sec\n",
      "The total time of the 19 is: 44.779162645339966\n",
      "5.445372819900513 8.233527421951294 0.052388668060302734 17.297284364700317 0.19101405143737793 5.184930086135864\n",
      "**************************************************\n",
      "5.184930086135864\n"
     ]
    }
   ],
   "source": [
    "# create the folder to store the data\n",
    "main_folder = data_path/'cifar100'\n",
    "print('The folder is:', main_folder)\n",
    "# find out that if the folder exists in the data path\n",
    "# 判断文件是否存在\n",
    "if main_folder.exists():\n",
    "    print(\"文件存在。\")\n",
    "else:\n",
    "    os.makedirs(main_folder)\n",
    "    print(\"文件不存在，已创建。\")\n",
    "    print(\"文件创建于：\", main_folder)\n",
    "for epoch in epochs:\n",
    "    for batch in batch_size:\n",
    "        for round in range(rounds):\n",
    "            train_model_c(main_folder, batch, epoch, round, lr, device, LayerName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GreenAI",
   "language": "python",
   "name": "greenai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
