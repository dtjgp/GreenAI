{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ae34b7",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from d2l import torch as d2l\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ptflops import get_model_complexity_info\n",
    "from train import train_func\n",
    "from train_nosync import train_func_nosync\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d4bd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current path is: /home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/code\n",
      "The parent path is: /home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel\n",
      "The model path is: /home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Model\n"
     ]
    }
   ],
   "source": [
    "'''find the Model path'''\n",
    "# find the current path\n",
    "current_path = os.getcwd()\n",
    "print('The current path is:', current_path)\n",
    "\n",
    "# find the parent path\n",
    "parent_path = Path(current_path).parent\n",
    "print('The parent path is:', parent_path)\n",
    "\n",
    "# find the model path\n",
    "model_folder_path = os.path.join(parent_path, 'Model')\n",
    "print('The model path is:', model_folder_path)\n",
    "\n",
    "# find the model that for FashionMNIST\n",
    "model_fashion_path = os.path.join(model_folder_path, 'FashionMNIST')\n",
    "# find the model that for CIFAR100\n",
    "model_cifar_path = os.path.join(model_folder_path, 'CIFAR100')\n",
    "\n",
    "# add the model path to the system path\n",
    "sys.path.append(model_fashion_path)\n",
    "sys.path.append(model_cifar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561c3ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AlexNet_F import alexnet_f\n",
    "from GoogLeNet_F import googlenet_f\n",
    "from ResNet_F import resnet_f\n",
    "from VGG_F import vgg_f\n",
    "from AlexNet_C import alexnet_c\n",
    "from ResNet_C import resnet_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87db6b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n",
    "alexnet_fashion = alexnet_f()\n",
    "googlenet_fashion = googlenet_f()\n",
    "resnet_fashion = resnet_f()\n",
    "vgg_fashion = vgg_f(conv_arch)\n",
    "alexnet_cifar = alexnet_c()\n",
    "resnet_cifar = resnet_c()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa461034",
   "metadata": {},
   "source": [
    "##### using ptflops to calculate the number of the flops in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d86d58f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Residual is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  11.23 M, 100.000% Params, 1.82 GMac, 99.828% MACs, \n",
      "  (0): Sequential(\n",
      "    9.6 k, 0.085% Params, 122.03 MMac, 6.685% MACs, \n",
      "    (0): Conv2d(9.47 k, 0.084% Params, 118.82 MMac, 6.509% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.088% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(0, 0.000% Params, 802.82 KMac, 0.044% MACs, )\n",
      "    (3): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.044% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    148.22 k, 1.320% Params, 464.83 MMac, 25.463% MACs, \n",
      "    (0): Residual(\n",
      "      74.11 k, 0.660% Params, 232.42 MMac, 12.732% MACs, \n",
      "      (conv1): Conv2d(36.93 k, 0.329% Params, 115.81 MMac, 6.344% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(36.93 k, 0.329% Params, 115.81 MMac, 6.344% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.022% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.022% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Residual(\n",
      "      74.11 k, 0.660% Params, 232.42 MMac, 12.732% MACs, \n",
      "      (conv1): Conv2d(36.93 k, 0.329% Params, 115.81 MMac, 6.344% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(36.93 k, 0.329% Params, 115.81 MMac, 6.344% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.022% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.022% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    525.95 k, 4.683% Params, 412.35 MMac, 22.588% MACs, \n",
      "    (0): Residual(\n",
      "      230.27 k, 2.050% Params, 180.53 MMac, 9.890% MACs, \n",
      "      (conv1): Conv2d(73.86 k, 0.658% Params, 57.9 MMac, 3.172% MACs, 64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(147.58 k, 1.314% Params, 115.71 MMac, 6.338% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8.32 k, 0.074% Params, 6.52 MMac, 0.357% MACs, 64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (bn1): BatchNorm2d(256, 0.002% Params, 200.7 KMac, 0.011% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, 0.002% Params, 200.7 KMac, 0.011% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Residual(\n",
      "      295.68 k, 2.633% Params, 231.81 MMac, 12.699% MACs, \n",
      "      (conv1): Conv2d(147.58 k, 1.314% Params, 115.71 MMac, 6.338% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(147.58 k, 1.314% Params, 115.71 MMac, 6.338% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, 0.002% Params, 200.7 KMac, 0.011% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, 0.002% Params, 200.7 KMac, 0.011% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    2.1 M, 18.703% Params, 411.69 MMac, 22.553% MACs, \n",
      "    (0): Residual(\n",
      "      919.3 k, 8.185% Params, 180.18 MMac, 9.870% MACs, \n",
      "      (conv1): Conv2d(295.17 k, 2.628% Params, 57.85 MMac, 3.169% MACs, 128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 5.254% Params, 115.66 MMac, 6.336% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(33.02 k, 0.294% Params, 6.47 MMac, 0.355% MACs, 128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (bn1): BatchNorm2d(512, 0.005% Params, 100.35 KMac, 0.005% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, 0.005% Params, 100.35 KMac, 0.005% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Residual(\n",
      "      1.18 M, 10.517% Params, 231.51 MMac, 12.682% MACs, \n",
      "      (conv1): Conv2d(590.08 k, 5.254% Params, 115.66 MMac, 6.336% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(590.08 k, 5.254% Params, 115.66 MMac, 6.336% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, 0.005% Params, 100.35 KMac, 0.005% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, 0.005% Params, 100.35 KMac, 0.005% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    8.4 M, 74.752% Params, 411.37 MMac, 22.535% MACs, \n",
      "    (0): Residual(\n",
      "      3.67 M, 32.710% Params, 180.01 MMac, 9.861% MACs, \n",
      "      (conv1): Conv2d(1.18 M, 10.508% Params, 57.83 MMac, 3.168% MACs, 256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(2.36 M, 21.012% Params, 115.63 MMac, 6.334% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(131.58 k, 1.172% Params, 6.45 MMac, 0.353% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.009% Params, 50.18 KMac, 0.003% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.009% Params, 50.18 KMac, 0.003% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Residual(\n",
      "      4.72 M, 42.042% Params, 231.36 MMac, 12.674% MACs, \n",
      "      (conv1): Conv2d(2.36 M, 21.012% Params, 115.63 MMac, 6.334% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(2.36 M, 21.012% Params, 115.63 MMac, 6.334% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.009% Params, 50.18 KMac, 0.003% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.009% Params, 50.18 KMac, 0.003% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): AdaptiveAvgPool2d(0, 0.000% Params, 25.09 KMac, 0.001% MACs, output_size=(1, 1))\n",
      "  (6): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  (7): Linear(51.3 k, 0.457% Params, 51.3 KMac, 0.003% MACs, in_features=512, out_features=100, bias=True)\n",
      ")\n",
      "False\n",
      "False\n",
      "Computational complexity:       1.83 GMac\n",
      "Number of parameters:           11.23 M \n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    # net = alexnet_fashion\n",
    "    # macs, params = get_model_complexity_info(net, (1, 224, 224), as_strings=True,\n",
    "    #                                         print_per_layer_stat=True, verbose=True)\n",
    "    \n",
    "    # net = resnet_fashion\n",
    "    # macs, params = get_model_complexity_info(net, (1, 224, 224), as_strings=True,\n",
    "    #                                         print_per_layer_stat=True, verbose=True)\n",
    "    \n",
    "    # net = vgg_fashion\n",
    "    # macs, params = get_model_complexity_info(net, (1, 224, 224), as_strings=True,\n",
    "    #                                         print_per_layer_stat=True, verbose=True)\n",
    "    \n",
    "    # net = googlenet_fashion\n",
    "    # macs, params = get_model_complexity_info(net, (1, 224, 224), as_strings=True,\n",
    "    #                                         print_per_layer_stat=True, verbose=True)\n",
    "    \n",
    "    # net = alexnet_cifar\n",
    "    # macs, params = get_model_complexity_info(net, (3, 224, 224), as_strings=True,\n",
    "    #                                         print_per_layer_stat=True, verbose=True)\n",
    "    \n",
    "    net = resnet_cifar\n",
    "    macs, params = get_model_complexity_info(net, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    \n",
    "    \n",
    "    if net == resnet_cifar:\n",
    "        print(torch.backends.mps.is_built())\n",
    "        print(torch.backends.mps.is_available())\n",
    "    \n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d97a07",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "[**我们构造一个**]高度和宽度都为224的(**单通道数据，来观察每一层输出的形状**)。\n",
    "它与 :numref:`fig_alexnet`中的AlexNet架构相匹配。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37a7ec36",
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 128, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 256, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 512, 1, 1])\n",
      "Flatten output shape:\t torch.Size([1, 512])\n",
      "Linear output shape:\t torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "# X = torch.randn(1, 1, 224, 224) # FashionMNIST\n",
    "\n",
    "X = torch.randn(1, 3, 224, 224) # CIFAR100\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c79a7",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "## 读取数据集\n",
    "\n",
    "尽管原文中AlexNet是在ImageNet上进行训练的，但本书在这里使用的是Fashion-MNIST数据集。因为即使在现代GPU上，训练ImageNet模型，同时使其收敛可能需要数小时或数天的时间。\n",
    "将AlexNet直接应用于Fashion-MNIST的一个问题是，[**Fashion-MNIST图像的分辨率**]（$28 \\times 28$像素）(**低于ImageNet图像。**)\n",
    "为了解决这个问题，(**我们将它们增加到$224 \\times 224$**)（通常来讲这不是一个明智的做法，但在这里这样做是为了有效使用AlexNet架构）。\n",
    "这里需要使用`d2l.load_data_fashion_mnist`函数中的`resize`参数执行此调整。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32a33f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_workers():\n",
    "    \"\"\"Use 4 processes to read the data.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    return 4\n",
    "def load_data_cifar100(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    # import the cifar100 dataset\n",
    "    cifar_train = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    cifar_test = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(cifar_train, batch_size, shuffle=True,\n",
    "                                        num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(cifar_test, batch_size, shuffle=False,\n",
    "                                        num_workers=get_dataloader_workers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c1552a8",
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ../data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/cifar-100-python.tar.gz to ../data\n",
      "Files already downloaded and verified\n",
      "the shape of the train_iter is: (391,)\n",
      "the shape of the 0 batch of the train_iter is: torch.Size([128, 3, 224, 224])\n",
      "the shape of the 1 batch of the train_iter is: torch.Size([128, 3, 224, 224])\n",
      "the shape of the 2 batch of the train_iter is: torch.Size([128, 3, 224, 224])\n",
      "the shape of the 3 batch of the train_iter is: torch.Size([128, 3, 224, 224])\n",
      "the shape of the 4 batch of the train_iter is: torch.Size([128, 3, 224, 224])\n",
      "the shape of the 5 batch of the train_iter is: torch.Size([128, 3, 224, 224])\n",
      "the shape of the 6 batch of the train_iter is: torch.Size([128, 3, 224, 224])\n",
      "the shape of the 7 batch of the train_iter is: torch.Size([128, 3, 224, 224])\n",
      "the shape of the 8 batch of the train_iter is: torch.Size([128, 3, 224, 224])\n",
      "the shape of the 9 batch of the train_iter is: torch.Size([128, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "\n",
    "# train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224) # FashionMNIST\n",
    "train_iter, test_iter = load_data_cifar100(batch_size, resize=224) # CIFAR100\n",
    "# print the shape of the train_iter\n",
    "list_of_i = []\n",
    "for i, (X, y) in enumerate(train_iter):\n",
    "    list_of_i.append(i)\n",
    "\n",
    "print('the shape of the train_iter is:', np.array(list_of_i).shape)\n",
    "# print(list_of_i)\n",
    "# print the first 10 batch of the train_iter\n",
    "for i, (X, y) in enumerate(train_iter):\n",
    "    if i < 10:\n",
    "        print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcd56c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data folder path is: /home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data\n",
      "The FashionMNIST train_data dir is: /home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/FashionMNIST\n",
      "The CIFAR100 train_data dir is: /home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100\n"
     ]
    }
   ],
   "source": [
    "# save the data to data folder\n",
    "data_folder_path = os.path.join(parent_path, 'Data')\n",
    "print('The data folder path is:', data_folder_path)\n",
    "\n",
    "# find out the train_data path\n",
    "fashion_data_path = os.path.join(data_folder_path, 'FashionMNIST')\n",
    "cifar_data_data = os.path.join(data_folder_path, 'CIFAR100')\n",
    "print('The FashionMNIST train_data dir is:', fashion_data_path)\n",
    "print('The CIFAR100 train_data dir is:', cifar_data_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c288e4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current using model data path is: /home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100\n",
      "The current using model path is: /home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet\n",
      "The current using pattern path is: /home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet/sync\n"
     ]
    }
   ],
   "source": [
    "# find the current using data path\n",
    "current_dataset_path = cifar_data_data\n",
    "# current_dataset = cifar_train_data\n",
    "print('The current using model data path is:', current_dataset_path)\n",
    "\n",
    "# find the current using model\n",
    "current_model_path = os.path.join(current_dataset_path, 'resnet')\n",
    "print('The current using model path is:', current_model_path)\n",
    "\n",
    "# find the train pattern, sync or nosync\n",
    "pattern_path = os.path.join(current_model_path, 'sync')\n",
    "# pattern_path = os.path.join(current_model_path, 'nosync')\n",
    "print('The current using pattern path is:', pattern_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0222ef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train_data_str is:  /home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet/sync\n"
     ]
    }
   ],
   "source": [
    "train_data_str = str(pattern_path)\n",
    "print('The train_data_str is: ', train_data_str)\n",
    "train_data_path = Path(train_data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folders in the train_data are:  ['/home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet/sync/round_1', '/home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet/sync/round_2', '/home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet/sync/round_9', '/home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet/sync/round_4', '/home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet/sync/round_5', '/home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet/sync/round_8', '/home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet/sync/round_3', '/home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet/sync/round_7', '/home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet/sync/round_6', '/home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet/sync/round_10']\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    dir_path = train_data_path / f'round_{i}'\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# find out all the subfolders in the train_data\n",
    "subfolders = [f.path for f in os.scandir(train_data_path) if f.is_dir()]\n",
    "print('The folders in the train_data are: ', subfolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35ebe8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sub_folder dir is:  /home/yj/FinalThesis/GreenAI/Cloud/4090_detailmodel/Data/CIFAR100/resnet/sync/round_1\n",
      "training on cuda:0\n",
      "epoch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe sub_folder dir is: \u001b[39m\u001b[38;5;124m'\u001b[39m, working_diri)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(alexnet_fashion, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for Alexnet\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(resnet_fashion, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for Resnet\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(vgg_fashion, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for VGG\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func_nosync(googlenet_fashion, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for Googlenet\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(alexnet_cifar, train_iter, test_iter, num_epochs, lr, device) # CIFAR100 for Alexnet\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet_cifar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# CIFAR100 for ResNet\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# save the Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss to the sub_folder dir as .npy file\u001b[39;00m\n\u001b[1;32m     18\u001b[0m np\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(working_diri, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_AllEpochs.npy\u001b[39m\u001b[38;5;124m'\u001b[39m), Time_AllEpochs)\n",
      "File \u001b[0;32m~/FinalThesis/GreenAI/Cloud/4090_detailmodel/code/train.py:68\u001b[0m, in \u001b[0;36mtrain_func\u001b[0;34m(net, train_iter, test_iter, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m     66\u001b[0m Tbatch_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;66;03m# time batch start\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Ttesti = time.time()\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m X,y \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     69\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize()  \u001b[38;5;66;03m# 等待数据传输完成\u001b[39;00m\n\u001b[1;32m     70\u001b[0m TtD_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 10\n",
    "device = d2l.try_gpu()\n",
    "for subfolder in subfolders:\n",
    "    working_diri = subfolder\n",
    "    print('The sub_folder dir is: ', working_diri)\n",
    "    # Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(alexnet_fashion, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for Alexnet\n",
    "    # Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(resnet_fashion, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for Resnet\n",
    "    # Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(vgg_fashion, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for VGG\n",
    "    # Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(googlenet_fashion, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for Googlenet\n",
    "    # Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func_nosync(alexnet_fashion, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for alexnet\n",
    "    # Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func_nosync(resnet_fashion, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for resnet\n",
    "    # Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func_nosync(vgg_fashion, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for vgg\n",
    "    # Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func_nosync(googlenet_fashion, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for Googlenet\n",
    "    # Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(alexnet_cifar, train_iter, test_iter, num_epochs, lr, device) # CIFAR100 for Alexnet\n",
    "    Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(resnet_cifar, train_iter, test_iter, num_epochs, lr, device) # CIFAR100 for ResNet\n",
    "\n",
    "    # save the Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss to the sub_folder dir as .npy file\n",
    "    np.save(os.path.join(working_diri, 'Time_AllEpochs.npy'), Time_AllEpochs)\n",
    "    np.save(os.path.join(working_diri, 'TestAcc.npy'), TestAcc)\n",
    "    np.save(os.path.join(working_diri, 'TrainLoss.npy'), TrainLoss)\n",
    "    np.save(os.path.join(working_diri, 'TrainAcc.npy'), TrainAcc)\n",
    "    np.save(os.path.join(working_diri, 'TimeEpoch.npy'), TimeEpoch)\n",
    "    np.save(os.path.join(working_diri, 'Energy_AllEpochs.npy'), Energy_AllEpochs)\n",
    "    np.save(os.path.join(working_diri, 'TrainTime.npy'), TrainTime)\n",
    "    np.save(os.path.join(working_diri, 'TTrainAccLoss.npy'), TTrainAccLoss)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4ad45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345446cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GreenAI",
   "language": "python",
   "name": "greenai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
