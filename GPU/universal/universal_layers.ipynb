{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ae34b7",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from alexnet import AlexNet\n",
    "from d2l import torch as d2l\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "from ptflops import get_model_complexity_info\n",
    "from train_layers import train_layers\n",
    "# from train import train_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9533381",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = AlexNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa461034",
   "metadata": {},
   "source": [
    "##### using ptflops to calculate the number of the flops in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86d58f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Flatten is treated as a zero-op.\n",
      "Warning: module Dropout is treated as a zero-op.\n",
      "Sequential(\n",
      "  46.76 M, 100.000% Params, 939.85 MMac, 99.883% MACs, \n",
      "  (0): Conv2d(11.71 k, 0.025% Params, 34.15 MMac, 3.630% MACs, 1, 96, kernel_size=(11, 11), stride=(4, 4), padding=(1, 1))\n",
      "  (1): ReLU(0, 0.000% Params, 279.94 KMac, 0.030% MACs, )\n",
      "  (2): MaxPool2d(0, 0.000% Params, 279.94 KMac, 0.030% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(614.66 k, 1.314% Params, 415.51 MMac, 44.158% MACs, 96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (4): ReLU(0, 0.000% Params, 173.06 KMac, 0.018% MACs, )\n",
      "  (5): MaxPool2d(0, 0.000% Params, 173.06 KMac, 0.018% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(885.12 k, 1.893% Params, 127.46 MMac, 13.546% MACs, 256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU(0, 0.000% Params, 55.3 KMac, 0.006% MACs, )\n",
      "  (8): Conv2d(1.33 M, 2.839% Params, 191.16 MMac, 20.315% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU(0, 0.000% Params, 55.3 KMac, 0.006% MACs, )\n",
      "  (10): Conv2d(884.99 k, 1.892% Params, 127.44 MMac, 13.544% MACs, 384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(0, 0.000% Params, 36.86 KMac, 0.004% MACs, )\n",
      "  (12): MaxPool2d(0, 0.000% Params, 36.86 KMac, 0.004% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  (14): Linear(26.22 M, 56.065% Params, 26.22 MMac, 2.786% MACs, in_features=6400, out_features=4096, bias=True)\n",
      "  (15): ReLU(0, 0.000% Params, 4.1 KMac, 0.000% MACs, )\n",
      "  (16): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
      "  (17): Linear(16.78 M, 35.885% Params, 16.78 MMac, 1.783% MACs, in_features=4096, out_features=4096, bias=True)\n",
      "  (18): ReLU(0, 0.000% Params, 4.1 KMac, 0.000% MACs, )\n",
      "  (19): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
      "  (20): Linear(40.97 k, 0.088% Params, 40.97 KMac, 0.004% MACs, in_features=4096, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       940.95 MMac\n",
      "Number of parameters:           46.76 M \n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    net = alexnet\n",
    "    macs, params = get_model_complexity_info(net, (1, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "    alexnet_para_num = params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d97a07",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "[**我们构造一个**]高度和宽度都为224的(**单通道数据，来观察每一层输出的形状**)。\n",
    "它与 :numref:`fig_alexnet`中的AlexNet架构相匹配。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a7ec36",
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 96, 54, 54])\n",
      "ReLU output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 26, 26])\n",
      "ReLU output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 256, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 5, 5])\n",
      "Flatten output shape:\t torch.Size([1, 6400])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1, 1, 224, 224)\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c79a7",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "## 读取数据集\n",
    "\n",
    "尽管原文中AlexNet是在ImageNet上进行训练的，但本书在这里使用的是Fashion-MNIST数据集。因为即使在现代GPU上，训练ImageNet模型，同时使其收敛可能需要数小时或数天的时间。\n",
    "将AlexNet直接应用于Fashion-MNIST的一个问题是，[**Fashion-MNIST图像的分辨率**]（$28 \\times 28$像素）(**低于ImageNet图像。**)\n",
    "为了解决这个问题，(**我们将它们增加到$224 \\times 224$**)（通常来讲这不是一个明智的做法，但在这里这样做是为了有效使用AlexNet架构）。\n",
    "这里需要使用`d2l.load_data_fashion_mnist`函数中的`resize`参数执行此调整。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c1552a8",
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the train_iter is: (469,)\n",
      "the shape of the 0 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 1 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 2 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 3 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 4 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 5 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 6 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 7 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 8 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 9 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "# print the shape of the train_iter\n",
    "list_of_i = []\n",
    "for i, (X, y) in enumerate(train_iter):\n",
    "    list_of_i.append(i)\n",
    "\n",
    "print('the shape of the train_iter is:', np.array(list_of_i).shape)\n",
    "# print(list_of_i)\n",
    "# print the first 10 batch of the train_iter\n",
    "for i, (X, y) in enumerate(train_iter):\n",
    "    if i < 10:\n",
    "        print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d484d7f3",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "## [**训练AlexNet**]\n",
    "\n",
    "现在AlexNet可以开始被训练了。与 :numref:`sec_lenet`中的LeNet相比，这里的主要变化是使用更小的学习速率训练，这是因为网络更深更广、图像分辨率更高，训练卷积神经网络就更昂贵。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ebe8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n",
      "epoch 1\n",
      "round 0\n",
      "time to device 0.005736 sec\n",
      "time forward 0.164138 sec\n",
      "loss time 0.018266 sec\n",
      "backward time 0.108599 sec\n",
      "optimizer time 0.007306 sec\n",
      "training time in batch 0 cost 0.30516529083251953 sec\n",
      "loss 2.297448, train acc 0.132812\n",
      "round 1\n",
      "time to device 0.004025 sec\n",
      "time forward 0.000880 sec\n",
      "loss time 0.000080 sec\n",
      "backward time 0.001153 sec\n",
      "optimizer time 0.000223 sec\n",
      "training time in batch 1 cost 0.006602287292480469 sec\n",
      "loss 2.299442, train acc 0.105469\n",
      "round 2\n",
      "time to device 0.003998 sec\n",
      "time forward 0.000804 sec\n",
      "loss time 0.000071 sec\n",
      "backward time 0.001695 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 2 cost 0.007006645202636719 sec\n",
      "loss 2.300937, train acc 0.098958\n",
      "round 3\n",
      "time to device 0.004010 sec\n",
      "time forward 0.000935 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001257 sec\n",
      "optimizer time 0.000223 sec\n",
      "training time in batch 3 cost 0.006720781326293945 sec\n",
      "loss 2.302328, train acc 0.091797\n",
      "round 4\n",
      "time to device 0.003973 sec\n",
      "time forward 0.000892 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001127 sec\n",
      "optimizer time 0.000217 sec\n",
      "training time in batch 4 cost 0.006504535675048828 sec\n",
      "loss 2.302604, train acc 0.092188\n",
      "round 5\n",
      "time to device 0.004027 sec\n",
      "time forward 0.000825 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001995 sec\n",
      "optimizer time 0.000212 sec\n",
      "training time in batch 5 cost 0.007340908050537109 sec\n",
      "loss 2.302949, train acc 0.096354\n",
      "round 6\n",
      "time to device 0.004036 sec\n",
      "time forward 0.000816 sec\n",
      "loss time 0.000088 sec\n",
      "backward time 0.001476 sec\n",
      "optimizer time 0.000217 sec\n",
      "training time in batch 6 cost 0.006862163543701172 sec\n",
      "loss 2.302363, train acc 0.095982\n",
      "round 7\n",
      "time to device 0.004002 sec\n",
      "time forward 0.000831 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001215 sec\n",
      "optimizer time 0.000223 sec\n",
      "training time in batch 7 cost 0.006562232971191406 sec\n",
      "loss 2.302022, train acc 0.094727\n",
      "round 8\n",
      "time to device 0.003996 sec\n",
      "time forward 0.000817 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001527 sec\n",
      "optimizer time 0.000222 sec\n",
      "training time in batch 8 cost 0.006833553314208984 sec\n",
      "loss 2.301493, train acc 0.104167\n",
      "round 9\n",
      "time to device 0.004039 sec\n",
      "time forward 0.000835 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001612 sec\n",
      "optimizer time 0.000236 sec\n",
      "training time in batch 9 cost 0.007002592086791992 sec\n",
      "loss 2.301533, train acc 0.103125\n",
      "round 10\n",
      "time to device 0.004003 sec\n",
      "time forward 0.000866 sec\n",
      "loss time 0.000083 sec\n",
      "backward time 0.001161 sec\n",
      "optimizer time 0.000210 sec\n",
      "training time in batch 10 cost 0.0065212249755859375 sec\n",
      "loss 2.301142, train acc 0.102983\n",
      "round 11\n",
      "time to device 0.004043 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000083 sec\n",
      "backward time 0.001164 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 11 cost 0.006539821624755859 sec\n",
      "loss 2.300971, train acc 0.107422\n",
      "round 12\n",
      "time to device 0.004046 sec\n",
      "time forward 0.000989 sec\n",
      "loss time 0.000102 sec\n",
      "backward time 0.001084 sec\n",
      "optimizer time 0.000237 sec\n",
      "training time in batch 12 cost 0.00667572021484375 sec\n",
      "loss 2.300610, train acc 0.109976\n",
      "round 13\n",
      "time to device 0.003978 sec\n",
      "time forward 0.000871 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001172 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 13 cost 0.006482124328613281 sec\n",
      "loss 2.300246, train acc 0.112165\n",
      "round 14\n",
      "time to device 0.004138 sec\n",
      "time forward 0.000834 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001183 sec\n",
      "optimizer time 0.000248 sec\n",
      "training time in batch 14 cost 0.006669044494628906 sec\n",
      "loss 2.300054, train acc 0.112500\n",
      "round 15\n",
      "time to device 0.004204 sec\n",
      "time forward 0.000905 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001186 sec\n",
      "optimizer time 0.000211 sec\n",
      "training time in batch 15 cost 0.0068302154541015625 sec\n",
      "loss 2.299908, train acc 0.111328\n",
      "round 16\n",
      "time to device 0.003992 sec\n",
      "time forward 0.000825 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001555 sec\n",
      "optimizer time 0.000211 sec\n",
      "training time in batch 16 cost 0.006856441497802734 sec\n",
      "loss 2.299833, train acc 0.112132\n",
      "round 17\n",
      "time to device 0.004068 sec\n",
      "time forward 0.000819 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001578 sec\n",
      "optimizer time 0.000239 sec\n",
      "training time in batch 17 cost 0.006982088088989258 sec\n",
      "loss 2.299416, train acc 0.114583\n",
      "round 18\n",
      "time to device 0.004025 sec\n",
      "time forward 0.000837 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001171 sec\n",
      "optimizer time 0.000203 sec\n",
      "training time in batch 18 cost 0.006544589996337891 sec\n",
      "loss 2.299470, train acc 0.114309\n",
      "round 19\n",
      "time to device 0.004035 sec\n",
      "time forward 0.000903 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001161 sec\n",
      "optimizer time 0.000218 sec\n",
      "training time in batch 19 cost 0.006598949432373047 sec\n",
      "loss 2.299320, train acc 0.117188\n",
      "round 20\n",
      "time to device 0.004036 sec\n",
      "time forward 0.000832 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001692 sec\n",
      "optimizer time 0.000213 sec\n",
      "training time in batch 20 cost 0.007058620452880859 sec\n",
      "loss 2.299118, train acc 0.121652\n",
      "round 21\n",
      "time to device 0.004024 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001589 sec\n",
      "optimizer time 0.000232 sec\n",
      "training time in batch 21 cost 0.006950855255126953 sec\n",
      "loss 2.299041, train acc 0.122869\n",
      "round 22\n",
      "time to device 0.004011 sec\n",
      "time forward 0.000832 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001213 sec\n",
      "optimizer time 0.000201 sec\n",
      "training time in batch 22 cost 0.006543874740600586 sec\n",
      "loss 2.298826, train acc 0.124321\n",
      "round 23\n",
      "time to device 0.004060 sec\n",
      "time forward 0.000829 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001953 sec\n",
      "optimizer time 0.000211 sec\n",
      "training time in batch 23 cost 0.007322072982788086 sec\n",
      "loss 2.298611, train acc 0.125651\n",
      "round 24\n",
      "time to device 0.004038 sec\n",
      "time forward 0.000859 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001200 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 24 cost 0.0065686702728271484 sec\n",
      "loss 2.298525, train acc 0.128125\n",
      "round 25\n",
      "time to device 0.003973 sec\n",
      "time forward 0.000832 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001174 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 25 cost 0.006448984146118164 sec\n",
      "loss 2.298538, train acc 0.128005\n",
      "round 26\n",
      "time to device 0.004028 sec\n",
      "time forward 0.000815 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001811 sec\n",
      "optimizer time 0.000215 sec\n",
      "training time in batch 26 cost 0.0071566104888916016 sec\n",
      "loss 2.298223, train acc 0.129919\n",
      "round 27\n",
      "time to device 0.004050 sec\n",
      "time forward 0.000867 sec\n",
      "loss time 0.000092 sec\n",
      "backward time 0.001092 sec\n",
      "optimizer time 0.000217 sec\n",
      "training time in batch 27 cost 0.006524324417114258 sec\n",
      "loss 2.298218, train acc 0.129464\n",
      "round 28\n",
      "time to device 0.004002 sec\n",
      "time forward 0.000826 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001192 sec\n",
      "optimizer time 0.000210 sec\n",
      "training time in batch 28 cost 0.006498813629150391 sec\n",
      "loss 2.298136, train acc 0.129580\n",
      "round 29\n",
      "time to device 0.004076 sec\n",
      "time forward 0.000905 sec\n",
      "loss time 0.000118 sec\n",
      "backward time 0.001156 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 29 cost 0.006688833236694336 sec\n",
      "loss 2.298023, train acc 0.129688\n",
      "round 30\n",
      "time to device 0.004045 sec\n",
      "time forward 0.000844 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001597 sec\n",
      "optimizer time 0.000209 sec\n",
      "training time in batch 30 cost 0.0069730281829833984 sec\n",
      "loss 2.297925, train acc 0.129536\n",
      "round 31\n",
      "time to device 0.004003 sec\n",
      "time forward 0.000828 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001606 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 31 cost 0.006926536560058594 sec\n",
      "loss 2.297750, train acc 0.129639\n",
      "round 32\n",
      "time to device 0.003992 sec\n",
      "time forward 0.000824 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001658 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 32 cost 0.006946086883544922 sec\n",
      "loss 2.297428, train acc 0.130919\n",
      "round 33\n",
      "time to device 0.004036 sec\n",
      "time forward 0.000827 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001629 sec\n",
      "optimizer time 0.000211 sec\n",
      "training time in batch 33 cost 0.0069963932037353516 sec\n",
      "loss 2.297292, train acc 0.130974\n",
      "round 34\n",
      "time to device 0.004004 sec\n",
      "time forward 0.000848 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001178 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 34 cost 0.00653076171875 sec\n",
      "loss 2.297375, train acc 0.130580\n",
      "round 35\n",
      "time to device 0.003982 sec\n",
      "time forward 0.000824 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001174 sec\n",
      "optimizer time 0.000208 sec\n",
      "training time in batch 35 cost 0.006465911865234375 sec\n",
      "loss 2.297099, train acc 0.131944\n",
      "round 36\n",
      "time to device 0.004016 sec\n",
      "time forward 0.000859 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001464 sec\n",
      "optimizer time 0.000212 sec\n",
      "training time in batch 36 cost 0.006827116012573242 sec\n",
      "loss 2.297043, train acc 0.131546\n",
      "round 37\n",
      "time to device 0.004033 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001230 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 37 cost 0.0065784454345703125 sec\n",
      "loss 2.296855, train acc 0.131579\n",
      "round 38\n",
      "time to device 0.003979 sec\n",
      "time forward 0.000875 sec\n",
      "loss time 0.000080 sec\n",
      "backward time 0.001178 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 38 cost 0.0064983367919921875 sec\n",
      "loss 2.296730, train acc 0.133013\n",
      "round 39\n",
      "time to device 0.004025 sec\n",
      "time forward 0.000814 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001862 sec\n",
      "optimizer time 0.000232 sec\n",
      "training time in batch 39 cost 0.007203340530395508 sec\n",
      "loss 2.296361, train acc 0.133789\n",
      "round 40\n",
      "time to device 0.003985 sec\n",
      "time forward 0.000868 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001076 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 40 cost 0.006398200988769531 sec\n",
      "loss 2.296040, train acc 0.135671\n",
      "round 41\n",
      "time to device 0.003985 sec\n",
      "time forward 0.000940 sec\n",
      "loss time 0.000091 sec\n",
      "backward time 0.001180 sec\n",
      "optimizer time 0.000228 sec\n",
      "training time in batch 41 cost 0.0066356658935546875 sec\n",
      "loss 2.295877, train acc 0.136347\n",
      "round 42\n",
      "time to device 0.004328 sec\n",
      "time forward 0.001159 sec\n",
      "loss time 0.000118 sec\n",
      "backward time 0.001221 sec\n",
      "optimizer time 0.000271 sec\n",
      "training time in batch 42 cost 0.00734710693359375 sec\n",
      "loss 2.295670, train acc 0.137536\n",
      "round 43\n",
      "time to device 0.004029 sec\n",
      "time forward 0.000842 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001172 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 43 cost 0.0065152645111083984 sec\n",
      "loss 2.295585, train acc 0.139205\n",
      "round 44\n",
      "time to device 0.004011 sec\n",
      "time forward 0.000875 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001170 sec\n",
      "optimizer time 0.000209 sec\n",
      "training time in batch 44 cost 0.006532907485961914 sec\n",
      "loss 2.295488, train acc 0.140972\n",
      "round 45\n",
      "time to device 0.003972 sec\n",
      "time forward 0.000820 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001226 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 45 cost 0.0064771175384521484 sec\n",
      "loss 2.295404, train acc 0.141135\n",
      "round 46\n",
      "time to device 0.003979 sec\n",
      "time forward 0.000819 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001892 sec\n",
      "optimizer time 0.000209 sec\n",
      "training time in batch 46 cost 0.007170915603637695 sec\n",
      "loss 2.295229, train acc 0.141789\n",
      "round 47\n",
      "time to device 0.003999 sec\n",
      "time forward 0.000827 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001167 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 47 cost 0.006453752517700195 sec\n",
      "loss 2.294967, train acc 0.143066\n",
      "round 48\n",
      "time to device 0.003975 sec\n",
      "time forward 0.000817 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001601 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 48 cost 0.006872415542602539 sec\n",
      "loss 2.294673, train acc 0.144930\n",
      "round 49\n",
      "time to device 0.004002 sec\n",
      "time forward 0.000848 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001184 sec\n",
      "optimizer time 0.000203 sec\n",
      "training time in batch 49 cost 0.006501197814941406 sec\n",
      "loss 2.294482, train acc 0.146094\n",
      "round 50\n",
      "time to device 0.003994 sec\n",
      "time forward 0.000818 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001604 sec\n",
      "optimizer time 0.000230 sec\n",
      "training time in batch 50 cost 0.00691533088684082 sec\n",
      "loss 2.294226, train acc 0.146906\n",
      "round 51\n",
      "time to device 0.004019 sec\n",
      "time forward 0.000834 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001107 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 51 cost 0.006439685821533203 sec\n",
      "loss 2.294004, train acc 0.147987\n",
      "round 52\n",
      "time to device 0.003993 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001192 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 52 cost 0.0064737796783447266 sec\n",
      "loss 2.293800, train acc 0.148585\n",
      "round 53\n",
      "time to device 0.003992 sec\n",
      "time forward 0.000855 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001169 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 53 cost 0.00648951530456543 sec\n",
      "loss 2.293544, train acc 0.150029\n",
      "round 54\n",
      "time to device 0.003991 sec\n",
      "time forward 0.000844 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001930 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 54 cost 0.0072460174560546875 sec\n",
      "loss 2.293202, train acc 0.150994\n",
      "round 55\n",
      "time to device 0.003993 sec\n",
      "time forward 0.000823 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001597 sec\n",
      "optimizer time 0.000233 sec\n",
      "training time in batch 55 cost 0.006932973861694336 sec\n",
      "loss 2.292964, train acc 0.151088\n",
      "round 56\n",
      "time to device 0.003997 sec\n",
      "time forward 0.000855 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001176 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 56 cost 0.0064890384674072266 sec\n",
      "loss 2.292668, train acc 0.151864\n",
      "round 57\n",
      "time to device 0.003999 sec\n",
      "time forward 0.000849 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001179 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 57 cost 0.0064847469329833984 sec\n",
      "loss 2.292394, train acc 0.152613\n",
      "round 58\n",
      "time to device 0.004002 sec\n",
      "time forward 0.000876 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001181 sec\n",
      "optimizer time 0.000211 sec\n",
      "training time in batch 58 cost 0.0065460205078125 sec\n",
      "loss 2.292207, train acc 0.153072\n",
      "round 59\n",
      "time to device 0.004038 sec\n",
      "time forward 0.000824 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001601 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 59 cost 0.006934165954589844 sec\n",
      "loss 2.292054, train acc 0.153255\n",
      "round 60\n",
      "time to device 0.004011 sec\n",
      "time forward 0.000814 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001665 sec\n",
      "optimizer time 0.000233 sec\n",
      "training time in batch 60 cost 0.006986141204833984 sec\n",
      "loss 2.291858, train acc 0.153432\n",
      "round 61\n",
      "time to device 0.003989 sec\n",
      "time forward 0.000829 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001853 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 61 cost 0.007131338119506836 sec\n",
      "loss 2.291605, train acc 0.154108\n",
      "round 62\n",
      "time to device 0.003980 sec\n",
      "time forward 0.000858 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001159 sec\n",
      "optimizer time 0.000201 sec\n",
      "training time in batch 62 cost 0.006467103958129883 sec\n",
      "loss 2.291367, train acc 0.154762\n",
      "round 63\n",
      "time to device 0.004011 sec\n",
      "time forward 0.000901 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001156 sec\n",
      "optimizer time 0.000208 sec\n",
      "training time in batch 63 cost 0.006554603576660156 sec\n",
      "loss 2.291145, train acc 0.155273\n",
      "round 64\n",
      "time to device 0.003997 sec\n",
      "time forward 0.000822 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001580 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 64 cost 0.0068700313568115234 sec\n",
      "loss 2.290926, train acc 0.155649\n",
      "round 65\n",
      "time to device 0.003962 sec\n",
      "time forward 0.000832 sec\n",
      "loss time 0.000091 sec\n",
      "backward time 0.001177 sec\n",
      "optimizer time 0.000208 sec\n",
      "training time in batch 65 cost 0.006479740142822266 sec\n",
      "loss 2.290704, train acc 0.156013\n",
      "round 66\n",
      "time to device 0.003989 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001141 sec\n",
      "optimizer time 0.000203 sec\n",
      "training time in batch 66 cost 0.006443977355957031 sec\n",
      "loss 2.290429, train acc 0.156133\n",
      "round 67\n",
      "time to device 0.004005 sec\n",
      "time forward 0.000847 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001198 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 67 cost 0.006525516510009766 sec\n",
      "loss 2.290109, train acc 0.155790\n",
      "round 68\n",
      "time to device 0.004010 sec\n",
      "time forward 0.000841 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001207 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 68 cost 0.006537437438964844 sec\n",
      "loss 2.289843, train acc 0.156476\n",
      "round 69\n",
      "time to device 0.003999 sec\n",
      "time forward 0.000831 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001784 sec\n",
      "optimizer time 0.000198 sec\n",
      "training time in batch 69 cost 0.00707697868347168 sec\n",
      "loss 2.289495, train acc 0.157143\n",
      "round 70\n",
      "time to device 0.003982 sec\n",
      "time forward 0.000826 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001676 sec\n",
      "optimizer time 0.000215 sec\n",
      "training time in batch 70 cost 0.0069620609283447266 sec\n",
      "loss 2.289131, train acc 0.158231\n",
      "round 71\n",
      "time to device 0.003993 sec\n",
      "time forward 0.000828 sec\n",
      "loss time 0.000084 sec\n",
      "backward time 0.001128 sec\n",
      "optimizer time 0.000203 sec\n",
      "training time in batch 71 cost 0.006421327590942383 sec\n",
      "loss 2.288916, train acc 0.159180\n",
      "round 72\n",
      "time to device 0.003996 sec\n",
      "time forward 0.000847 sec\n",
      "loss time 0.000086 sec\n",
      "backward time 0.001158 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 72 cost 0.006491899490356445 sec\n",
      "loss 2.288542, train acc 0.160317\n",
      "round 73\n",
      "time to device 0.004011 sec\n",
      "time forward 0.000813 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001516 sec\n",
      "optimizer time 0.000189 sec\n",
      "training time in batch 73 cost 0.0067901611328125 sec\n",
      "loss 2.288391, train acc 0.160367\n",
      "round 74\n",
      "time to device 0.003998 sec\n",
      "time forward 0.000825 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001944 sec\n",
      "optimizer time 0.000201 sec\n",
      "training time in batch 74 cost 0.00724339485168457 sec\n",
      "loss 2.288219, train acc 0.160625\n",
      "round 75\n",
      "time to device 0.004012 sec\n",
      "time forward 0.000828 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001167 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 75 cost 0.006474971771240234 sec\n",
      "loss 2.287771, train acc 0.162315\n",
      "round 76\n",
      "time to device 0.004001 sec\n",
      "time forward 0.000849 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001202 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 76 cost 0.00652623176574707 sec\n",
      "loss 2.287298, train acc 0.164468\n",
      "round 77\n",
      "time to device 0.003996 sec\n",
      "time forward 0.000838 sec\n",
      "loss time 0.000078 sec\n",
      "backward time 0.001165 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 77 cost 0.00648951530456543 sec\n",
      "loss 2.286924, train acc 0.165665\n",
      "round 78\n",
      "time to device 0.004025 sec\n",
      "time forward 0.000821 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001667 sec\n",
      "optimizer time 0.000213 sec\n",
      "training time in batch 78 cost 0.006998538970947266 sec\n",
      "loss 2.286566, train acc 0.167029\n",
      "round 79\n",
      "time to device 0.003996 sec\n",
      "time forward 0.000841 sec\n",
      "loss time 0.000083 sec\n",
      "backward time 0.001140 sec\n",
      "optimizer time 0.000190 sec\n",
      "training time in batch 79 cost 0.006439208984375 sec\n",
      "loss 2.286172, train acc 0.167969\n",
      "round 80\n",
      "time to device 0.003998 sec\n",
      "time forward 0.000839 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001701 sec\n",
      "optimizer time 0.000200 sec\n",
      "training time in batch 80 cost 0.007002592086791992 sec\n",
      "loss 2.285848, train acc 0.168789\n",
      "round 81\n",
      "time to device 0.003981 sec\n",
      "time forward 0.000842 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001115 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 81 cost 0.006405830383300781 sec\n",
      "loss 2.285381, train acc 0.169874\n",
      "round 82\n",
      "time to device 0.003977 sec\n",
      "time forward 0.000824 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001169 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 82 cost 0.0064449310302734375 sec\n",
      "loss 2.285023, train acc 0.170463\n",
      "round 83\n",
      "time to device 0.003996 sec\n",
      "time forward 0.000842 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001179 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 83 cost 0.0064961910247802734 sec\n",
      "loss 2.284563, train acc 0.171503\n",
      "round 84\n",
      "time to device 0.004010 sec\n",
      "time forward 0.000826 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001615 sec\n",
      "optimizer time 0.000225 sec\n",
      "training time in batch 84 cost 0.006937742233276367 sec\n",
      "loss 2.284109, train acc 0.172151\n",
      "round 85\n",
      "time to device 0.003992 sec\n",
      "time forward 0.000821 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001618 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 85 cost 0.006916999816894531 sec\n",
      "loss 2.283450, train acc 0.173964\n",
      "round 86\n",
      "time to device 0.004017 sec\n",
      "time forward 0.000934 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001191 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 86 cost 0.0066013336181640625 sec\n",
      "loss 2.283125, train acc 0.174210\n",
      "round 87\n",
      "time to device 0.004006 sec\n",
      "time forward 0.000841 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001141 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 87 cost 0.0064907073974609375 sec\n",
      "loss 2.282589, train acc 0.174893\n",
      "round 88\n",
      "time to device 0.003979 sec\n",
      "time forward 0.000837 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001129 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 88 cost 0.006426095962524414 sec\n",
      "loss 2.282057, train acc 0.175474\n",
      "round 89\n",
      "time to device 0.003985 sec\n",
      "time forward 0.000845 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001538 sec\n",
      "optimizer time 0.000210 sec\n",
      "training time in batch 89 cost 0.00684809684753418 sec\n",
      "loss 2.281558, train acc 0.176215\n",
      "round 90\n",
      "time to device 0.003994 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001186 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 90 cost 0.006475210189819336 sec\n",
      "loss 2.280922, train acc 0.176854\n",
      "round 91\n",
      "time to device 0.003989 sec\n",
      "time forward 0.000827 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001573 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 91 cost 0.006848812103271484 sec\n",
      "loss 2.280437, train acc 0.177734\n",
      "round 92\n",
      "time to device 0.004014 sec\n",
      "time forward 0.000854 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001174 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 92 cost 0.006500720977783203 sec\n",
      "loss 2.279866, train acc 0.178595\n",
      "round 93\n",
      "time to device 0.003982 sec\n",
      "time forward 0.000889 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001171 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 93 cost 0.006506204605102539 sec\n",
      "loss 2.279181, train acc 0.179771\n",
      "round 94\n",
      "time to device 0.003966 sec\n",
      "time forward 0.000839 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001242 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 94 cost 0.006519317626953125 sec\n",
      "loss 2.278394, train acc 0.180345\n",
      "round 95\n",
      "time to device 0.003999 sec\n",
      "time forward 0.000823 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001556 sec\n",
      "optimizer time 0.000210 sec\n",
      "training time in batch 95 cost 0.006856679916381836 sec\n",
      "loss 2.277657, train acc 0.181152\n",
      "round 96\n",
      "time to device 0.004016 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001961 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 96 cost 0.007277965545654297 sec\n",
      "loss 2.276777, train acc 0.181782\n",
      "round 97\n",
      "time to device 0.003956 sec\n",
      "time forward 0.000850 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001197 sec\n",
      "optimizer time 0.000211 sec\n",
      "training time in batch 97 cost 0.00648188591003418 sec\n",
      "loss 2.276053, train acc 0.182159\n",
      "round 98\n",
      "time to device 0.003999 sec\n",
      "time forward 0.000866 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001174 sec\n",
      "optimizer time 0.000188 sec\n",
      "training time in batch 98 cost 0.006486415863037109 sec\n",
      "loss 2.275217, train acc 0.183160\n",
      "round 99\n",
      "time to device 0.004027 sec\n",
      "time forward 0.000819 sec\n",
      "loss time 0.000085 sec\n",
      "backward time 0.001440 sec\n",
      "optimizer time 0.000218 sec\n",
      "training time in batch 99 cost 0.006778240203857422 sec\n",
      "loss 2.274287, train acc 0.183594\n",
      "round 100\n",
      "time to device 0.003996 sec\n",
      "time forward 0.000850 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001327 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 100 cost 0.006628274917602539 sec\n",
      "loss 2.273263, train acc 0.184638\n",
      "round 101\n",
      "time to device 0.003974 sec\n",
      "time forward 0.000865 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001219 sec\n",
      "optimizer time 0.000208 sec\n",
      "training time in batch 101 cost 0.006547451019287109 sec\n",
      "loss 2.272378, train acc 0.185202\n",
      "round 102\n",
      "time to device 0.004093 sec\n",
      "time forward 0.000844 sec\n",
      "loss time 0.000080 sec\n",
      "backward time 0.001126 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 102 cost 0.0065343379974365234 sec\n",
      "loss 2.271431, train acc 0.185680\n",
      "round 103\n",
      "time to device 0.004018 sec\n",
      "time forward 0.000865 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001192 sec\n",
      "optimizer time 0.000229 sec\n",
      "training time in batch 103 cost 0.006577968597412109 sec\n",
      "loss 2.270470, train acc 0.186298\n",
      "round 104\n",
      "time to device 0.004036 sec\n",
      "time forward 0.000820 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001626 sec\n",
      "optimizer time 0.000221 sec\n",
      "training time in batch 104 cost 0.0069735050201416016 sec\n",
      "loss 2.269309, train acc 0.186830\n",
      "round 105\n",
      "time to device 0.004022 sec\n",
      "time forward 0.000837 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001173 sec\n",
      "optimizer time 0.000189 sec\n",
      "training time in batch 105 cost 0.0065021514892578125 sec\n",
      "loss 2.268431, train acc 0.187279\n",
      "round 106\n",
      "time to device 0.003974 sec\n",
      "time forward 0.000836 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001174 sec\n",
      "optimizer time 0.000211 sec\n",
      "training time in batch 106 cost 0.006460905075073242 sec\n",
      "loss 2.267379, train acc 0.187719\n",
      "round 107\n",
      "time to device 0.004009 sec\n",
      "time forward 0.000860 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001147 sec\n",
      "optimizer time 0.000203 sec\n",
      "training time in batch 107 cost 0.006493806838989258 sec\n",
      "loss 2.265978, train acc 0.189091\n",
      "round 108\n",
      "time to device 0.004037 sec\n",
      "time forward 0.000854 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001546 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 108 cost 0.006897449493408203 sec\n",
      "loss 2.264290, train acc 0.189937\n",
      "round 109\n",
      "time to device 0.003983 sec\n",
      "time forward 0.000820 sec\n",
      "loss time 0.000095 sec\n",
      "backward time 0.001194 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 109 cost 0.006498575210571289 sec\n",
      "loss 2.262997, train acc 0.190767\n",
      "round 110\n",
      "time to device 0.003998 sec\n",
      "time forward 0.000817 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001139 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 110 cost 0.006427288055419922 sec\n",
      "loss 2.261625, train acc 0.191441\n",
      "round 111\n",
      "time to device 0.003987 sec\n",
      "time forward 0.000818 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001933 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 111 cost 0.007203817367553711 sec\n",
      "loss 2.259364, train acc 0.193220\n",
      "round 112\n",
      "time to device 0.004016 sec\n",
      "time forward 0.000816 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001614 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 112 cost 0.00691986083984375 sec\n",
      "loss 2.256854, train acc 0.195036\n",
      "round 113\n",
      "time to device 0.003997 sec\n",
      "time forward 0.000825 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001576 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 113 cost 0.006868600845336914 sec\n",
      "loss 2.255208, train acc 0.195792\n",
      "round 114\n",
      "time to device 0.003977 sec\n",
      "time forward 0.000866 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001132 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 114 cost 0.006429433822631836 sec\n",
      "loss 2.252804, train acc 0.197011\n",
      "round 115\n",
      "time to device 0.004017 sec\n",
      "time forward 0.000831 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001214 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 115 cost 0.006527423858642578 sec\n",
      "loss 2.250520, train acc 0.197804\n",
      "round 116\n",
      "time to device 0.004027 sec\n",
      "time forward 0.000837 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001194 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 116 cost 0.006509304046630859 sec\n",
      "loss 2.248531, train acc 0.198451\n",
      "round 117\n",
      "time to device 0.003997 sec\n",
      "time forward 0.000835 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001197 sec\n",
      "optimizer time 0.000205 sec\n",
      "training time in batch 117 cost 0.006506204605102539 sec\n",
      "loss 2.245755, train acc 0.199682\n",
      "round 118\n",
      "time to device 0.003980 sec\n",
      "time forward 0.000863 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001136 sec\n",
      "optimizer time 0.000222 sec\n",
      "training time in batch 118 cost 0.00647425651550293 sec\n",
      "loss 2.243072, train acc 0.200302\n",
      "round 119\n",
      "time to device 0.004009 sec\n",
      "time forward 0.000829 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001158 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 119 cost 0.006467580795288086 sec\n",
      "loss 2.240408, train acc 0.200977\n",
      "round 120\n",
      "time to device 0.004002 sec\n",
      "time forward 0.000853 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001154 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 120 cost 0.006485462188720703 sec\n",
      "loss 2.237567, train acc 0.201834\n",
      "round 121\n",
      "time to device 0.003974 sec\n",
      "time forward 0.000821 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001227 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 121 cost 0.0064983367919921875 sec\n",
      "loss 2.234350, train acc 0.202997\n",
      "round 122\n",
      "time to device 0.004003 sec\n",
      "time forward 0.000832 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001724 sec\n",
      "optimizer time 0.000201 sec\n",
      "training time in batch 122 cost 0.007032155990600586 sec\n",
      "loss 2.231027, train acc 0.203951\n",
      "round 123\n",
      "time to device 0.004007 sec\n",
      "time forward 0.000831 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001193 sec\n",
      "optimizer time 0.000203 sec\n",
      "training time in batch 123 cost 0.006500720977783203 sec\n",
      "loss 2.227731, train acc 0.204700\n",
      "round 124\n",
      "time to device 0.003988 sec\n",
      "time forward 0.000836 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001572 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 124 cost 0.0068891048431396484 sec\n",
      "loss 2.224346, train acc 0.205750\n",
      "round 125\n",
      "time to device 0.003983 sec\n",
      "time forward 0.000855 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001170 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 125 cost 0.006470918655395508 sec\n",
      "loss 2.221185, train acc 0.206225\n",
      "round 126\n",
      "time to device 0.003985 sec\n",
      "time forward 0.000856 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001186 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 126 cost 0.006484270095825195 sec\n",
      "loss 2.217499, train acc 0.207493\n",
      "round 127\n",
      "time to device 0.004029 sec\n",
      "time forward 0.000824 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001942 sec\n",
      "optimizer time 0.000220 sec\n",
      "training time in batch 127 cost 0.007282733917236328 sec\n",
      "loss 2.213161, train acc 0.208984\n",
      "round 128\n",
      "time to device 0.003994 sec\n",
      "time forward 0.000827 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001194 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 128 cost 0.006482362747192383 sec\n",
      "loss 2.208643, train acc 0.210938\n",
      "round 129\n",
      "time to device 0.004013 sec\n",
      "time forward 0.000887 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001271 sec\n",
      "optimizer time 0.000190 sec\n",
      "training time in batch 129 cost 0.006643056869506836 sec\n",
      "loss 2.204802, train acc 0.212139\n",
      "round 130\n",
      "time to device 0.003999 sec\n",
      "time forward 0.000839 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001211 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 130 cost 0.0065212249755859375 sec\n",
      "loss 2.200442, train acc 0.213621\n",
      "round 131\n",
      "time to device 0.004005 sec\n",
      "time forward 0.000822 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001590 sec\n",
      "optimizer time 0.000210 sec\n",
      "training time in batch 131 cost 0.006908893585205078 sec\n",
      "loss 2.195607, train acc 0.215495\n",
      "round 132\n",
      "time to device 0.004055 sec\n",
      "time forward 0.000836 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001199 sec\n",
      "optimizer time 0.000222 sec\n",
      "training time in batch 132 cost 0.006579160690307617 sec\n",
      "loss 2.191521, train acc 0.216577\n",
      "round 133\n",
      "time to device 0.004031 sec\n",
      "time forward 0.000859 sec\n",
      "loss time 0.000085 sec\n",
      "backward time 0.001115 sec\n",
      "optimizer time 0.000208 sec\n",
      "training time in batch 133 cost 0.006503105163574219 sec\n",
      "loss 2.186468, train acc 0.218342\n",
      "round 134\n",
      "time to device 0.003978 sec\n",
      "time forward 0.000868 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001173 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 134 cost 0.006488323211669922 sec\n",
      "loss 2.181933, train acc 0.219850\n",
      "round 135\n",
      "time to device 0.004013 sec\n",
      "time forward 0.000825 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001562 sec\n",
      "optimizer time 0.000212 sec\n",
      "training time in batch 135 cost 0.00687718391418457 sec\n",
      "loss 2.177874, train acc 0.221278\n",
      "round 136\n",
      "time to device 0.003988 sec\n",
      "time forward 0.000859 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001172 sec\n",
      "optimizer time 0.000189 sec\n",
      "training time in batch 136 cost 0.006512641906738281 sec\n",
      "loss 2.173316, train acc 0.222970\n",
      "round 137\n",
      "time to device 0.004022 sec\n",
      "time forward 0.000912 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001248 sec\n",
      "optimizer time 0.000208 sec\n",
      "training time in batch 137 cost 0.006669282913208008 sec\n",
      "loss 2.168312, train acc 0.224524\n",
      "round 138\n",
      "time to device 0.003974 sec\n",
      "time forward 0.000863 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001199 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 138 cost 0.00652623176574707 sec\n",
      "loss 2.163106, train acc 0.225776\n",
      "round 139\n",
      "time to device 0.004028 sec\n",
      "time forward 0.000818 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001630 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 139 cost 0.006958723068237305 sec\n",
      "loss 2.157947, train acc 0.227232\n",
      "round 140\n",
      "time to device 0.004017 sec\n",
      "time forward 0.000838 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001553 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 140 cost 0.006891965866088867 sec\n",
      "loss 2.154384, train acc 0.228557\n",
      "round 141\n",
      "time to device 0.003987 sec\n",
      "time forward 0.000842 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001188 sec\n",
      "optimizer time 0.000217 sec\n",
      "training time in batch 141 cost 0.006497859954833984 sec\n",
      "loss 2.150903, train acc 0.229423\n",
      "round 142\n",
      "time to device 0.004050 sec\n",
      "time forward 0.000841 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001178 sec\n",
      "optimizer time 0.000201 sec\n",
      "training time in batch 142 cost 0.006555318832397461 sec\n",
      "loss 2.148069, train acc 0.230168\n",
      "round 143\n",
      "time to device 0.004076 sec\n",
      "time forward 0.000890 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001229 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 143 cost 0.006692409515380859 sec\n",
      "loss 2.144071, train acc 0.231066\n",
      "round 144\n",
      "time to device 0.004007 sec\n",
      "time forward 0.000858 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001212 sec\n",
      "optimizer time 0.000209 sec\n",
      "training time in batch 144 cost 0.006546735763549805 sec\n",
      "loss 2.140228, train acc 0.232058\n",
      "round 145\n",
      "time to device 0.003988 sec\n",
      "time forward 0.000828 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001610 sec\n",
      "optimizer time 0.000203 sec\n",
      "training time in batch 145 cost 0.006899833679199219 sec\n",
      "loss 2.135101, train acc 0.233840\n",
      "round 146\n",
      "time to device 0.003966 sec\n",
      "time forward 0.000848 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001154 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 146 cost 0.006441831588745117 sec\n",
      "loss 2.129446, train acc 0.235597\n",
      "round 147\n",
      "time to device 0.003989 sec\n",
      "time forward 0.000816 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001200 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 147 cost 0.006461381912231445 sec\n",
      "loss 2.124871, train acc 0.237226\n",
      "round 148\n",
      "time to device 0.004026 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001217 sec\n",
      "optimizer time 0.000210 sec\n",
      "training time in batch 148 cost 0.006579160690307617 sec\n",
      "loss 2.119638, train acc 0.238884\n",
      "round 149\n",
      "time to device 0.004102 sec\n",
      "time forward 0.000872 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001369 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 149 cost 0.006819963455200195 sec\n",
      "loss 2.114935, train acc 0.240313\n",
      "round 150\n",
      "time to device 0.004032 sec\n",
      "time forward 0.000849 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001245 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 150 cost 0.0066013336181640625 sec\n",
      "loss 2.110128, train acc 0.241618\n",
      "round 151\n",
      "time to device 0.004016 sec\n",
      "time forward 0.000838 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001152 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 151 cost 0.006490945816040039 sec\n",
      "loss 2.104366, train acc 0.243524\n",
      "round 152\n",
      "time to device 0.003980 sec\n",
      "time forward 0.000849 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001162 sec\n",
      "optimizer time 0.000199 sec\n",
      "training time in batch 152 cost 0.006449460983276367 sec\n",
      "loss 2.099485, train acc 0.245098\n",
      "round 153\n",
      "time to device 0.004005 sec\n",
      "time forward 0.000823 sec\n",
      "loss time 0.000085 sec\n",
      "backward time 0.001480 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 153 cost 0.00678253173828125 sec\n",
      "loss 2.094572, train acc 0.246246\n",
      "round 154\n",
      "time to device 0.004000 sec\n",
      "time forward 0.000855 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001203 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 154 cost 0.006540775299072266 sec\n",
      "loss 2.090069, train acc 0.247984\n",
      "round 155\n",
      "time to device 0.004002 sec\n",
      "time forward 0.000887 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001173 sec\n",
      "optimizer time 0.000199 sec\n",
      "training time in batch 155 cost 0.006545305252075195 sec\n",
      "loss 2.085318, train acc 0.249149\n",
      "round 156\n",
      "time to device 0.004012 sec\n",
      "time forward 0.000828 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001547 sec\n",
      "optimizer time 0.000247 sec\n",
      "training time in batch 156 cost 0.0069179534912109375 sec\n",
      "loss 2.080489, train acc 0.250398\n",
      "round 157\n",
      "time to device 0.004038 sec\n",
      "time forward 0.000826 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001378 sec\n",
      "optimizer time 0.000208 sec\n",
      "training time in batch 157 cost 0.006733894348144531 sec\n",
      "loss 2.076307, train acc 0.251533\n",
      "round 158\n",
      "time to device 0.003999 sec\n",
      "time forward 0.000831 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001582 sec\n",
      "optimizer time 0.000230 sec\n",
      "training time in batch 158 cost 0.006922483444213867 sec\n",
      "loss 2.072569, train acc 0.252408\n",
      "round 159\n",
      "time to device 0.004008 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001119 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 159 cost 0.006433010101318359 sec\n",
      "loss 2.068478, train acc 0.253613\n",
      "round 160\n",
      "time to device 0.004006 sec\n",
      "time forward 0.000844 sec\n",
      "loss time 0.000096 sec\n",
      "backward time 0.001172 sec\n",
      "optimizer time 0.000212 sec\n",
      "training time in batch 160 cost 0.006548643112182617 sec\n",
      "loss 2.063762, train acc 0.255192\n",
      "round 161\n",
      "time to device 0.004009 sec\n",
      "time forward 0.000835 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001595 sec\n",
      "optimizer time 0.000205 sec\n",
      "training time in batch 161 cost 0.006915092468261719 sec\n",
      "loss 2.059313, train acc 0.256269\n",
      "round 162\n",
      "time to device 0.004029 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001891 sec\n",
      "optimizer time 0.000210 sec\n",
      "training time in batch 162 cost 0.0072481632232666016 sec\n",
      "loss 2.053740, train acc 0.258388\n",
      "round 163\n",
      "time to device 0.004013 sec\n",
      "time forward 0.000880 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001189 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 163 cost 0.006571292877197266 sec\n",
      "loss 2.049133, train acc 0.260051\n",
      "round 164\n",
      "time to device 0.004066 sec\n",
      "time forward 0.000926 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001202 sec\n",
      "optimizer time 0.000227 sec\n",
      "training time in batch 164 cost 0.006749153137207031 sec\n",
      "loss 2.044840, train acc 0.261269\n",
      "round 165\n",
      "time to device 0.003988 sec\n",
      "time forward 0.000828 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001557 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 165 cost 0.006834983825683594 sec\n",
      "loss 2.040006, train acc 0.262754\n",
      "round 166\n",
      "time to device 0.004045 sec\n",
      "time forward 0.000853 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001217 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 166 cost 0.00660395622253418 sec\n",
      "loss 2.035743, train acc 0.264222\n",
      "round 167\n",
      "time to device 0.004081 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001176 sec\n",
      "optimizer time 0.000201 sec\n",
      "training time in batch 167 cost 0.006590604782104492 sec\n",
      "loss 2.030630, train acc 0.265811\n",
      "round 168\n",
      "time to device 0.003989 sec\n",
      "time forward 0.000859 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001879 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 168 cost 0.007196187973022461 sec\n",
      "loss 2.026582, train acc 0.267289\n",
      "round 169\n",
      "time to device 0.003984 sec\n",
      "time forward 0.000842 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001153 sec\n",
      "optimizer time 0.000200 sec\n",
      "training time in batch 169 cost 0.006463766098022461 sec\n",
      "loss 2.021449, train acc 0.269026\n",
      "round 170\n",
      "time to device 0.003990 sec\n",
      "time forward 0.000840 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001340 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 170 cost 0.0066432952880859375 sec\n",
      "loss 2.016601, train acc 0.270239\n",
      "round 171\n",
      "time to device 0.003988 sec\n",
      "time forward 0.000860 sec\n",
      "loss time 0.000088 sec\n",
      "backward time 0.001219 sec\n",
      "optimizer time 0.000224 sec\n",
      "training time in batch 171 cost 0.006568193435668945 sec\n",
      "loss 2.011873, train acc 0.271984\n",
      "round 172\n",
      "time to device 0.004068 sec\n",
      "time forward 0.000852 sec\n",
      "loss time 0.000084 sec\n",
      "backward time 0.001178 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 172 cost 0.006589412689208984 sec\n",
      "loss 2.007302, train acc 0.273483\n",
      "round 173\n",
      "time to device 0.004037 sec\n",
      "time forward 0.000822 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001908 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 173 cost 0.00728297233581543 sec\n",
      "loss 2.002441, train acc 0.275009\n",
      "round 174\n",
      "time to device 0.004045 sec\n",
      "time forward 0.000826 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001760 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 174 cost 0.007101774215698242 sec\n",
      "loss 1.998184, train acc 0.276518\n",
      "round 175\n",
      "time to device 0.004025 sec\n",
      "time forward 0.000835 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001561 sec\n",
      "optimizer time 0.000228 sec\n",
      "training time in batch 175 cost 0.00691986083984375 sec\n",
      "loss 1.993357, train acc 0.278232\n",
      "round 176\n",
      "time to device 0.003977 sec\n",
      "time forward 0.000863 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001115 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 176 cost 0.006431102752685547 sec\n",
      "loss 1.987943, train acc 0.279749\n",
      "round 177\n",
      "time to device 0.003992 sec\n",
      "time forward 0.000908 sec\n",
      "loss time 0.000098 sec\n",
      "backward time 0.001157 sec\n",
      "optimizer time 0.000216 sec\n",
      "training time in batch 177 cost 0.006581783294677734 sec\n",
      "loss 1.983441, train acc 0.281382\n",
      "round 178\n",
      "time to device 0.004016 sec\n",
      "time forward 0.000831 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001206 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 178 cost 0.0065190792083740234 sec\n",
      "loss 1.978871, train acc 0.282952\n",
      "round 179\n",
      "time to device 0.004167 sec\n",
      "time forward 0.000868 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001153 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 179 cost 0.006668806076049805 sec\n",
      "loss 1.974368, train acc 0.284418\n",
      "round 180\n",
      "time to device 0.004159 sec\n",
      "time forward 0.000858 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001070 sec\n",
      "optimizer time 0.000201 sec\n",
      "training time in batch 180 cost 0.006580352783203125 sec\n",
      "loss 1.970836, train acc 0.285221\n",
      "round 181\n",
      "time to device 0.004105 sec\n",
      "time forward 0.000871 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001176 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 181 cost 0.0066373348236083984 sec\n",
      "loss 1.967488, train acc 0.286358\n",
      "round 182\n",
      "time to device 0.004045 sec\n",
      "time forward 0.000876 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001274 sec\n",
      "optimizer time 0.000212 sec\n",
      "training time in batch 182 cost 0.0066852569580078125 sec\n",
      "loss 1.964207, train acc 0.287398\n",
      "round 183\n",
      "time to device 0.004130 sec\n",
      "time forward 0.000845 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001202 sec\n",
      "optimizer time 0.000217 sec\n",
      "training time in batch 183 cost 0.00667119026184082 sec\n",
      "loss 1.960291, train acc 0.288765\n",
      "round 184\n",
      "time to device 0.004042 sec\n",
      "time forward 0.000902 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001089 sec\n",
      "optimizer time 0.000227 sec\n",
      "training time in batch 184 cost 0.00653386116027832 sec\n",
      "loss 1.955633, train acc 0.290118\n",
      "round 185\n",
      "time to device 0.003999 sec\n",
      "time forward 0.000816 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001632 sec\n",
      "optimizer time 0.000213 sec\n",
      "training time in batch 185 cost 0.006935596466064453 sec\n",
      "loss 1.951416, train acc 0.291289\n",
      "round 186\n",
      "time to device 0.004069 sec\n",
      "time forward 0.000852 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001154 sec\n",
      "optimizer time 0.000248 sec\n",
      "training time in batch 186 cost 0.006622314453125 sec\n",
      "loss 1.947174, train acc 0.292655\n",
      "round 187\n",
      "time to device 0.003973 sec\n",
      "time forward 0.000846 sec\n",
      "loss time 0.000082 sec\n",
      "backward time 0.001358 sec\n",
      "optimizer time 0.000220 sec\n",
      "training time in batch 187 cost 0.006684780120849609 sec\n",
      "loss 1.942713, train acc 0.293966\n",
      "round 188\n",
      "time to device 0.004023 sec\n",
      "time forward 0.000839 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001124 sec\n",
      "optimizer time 0.000209 sec\n",
      "training time in batch 188 cost 0.0064580440521240234 sec\n",
      "loss 1.938043, train acc 0.295263\n",
      "round 189\n",
      "time to device 0.004088 sec\n",
      "time forward 0.000843 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001067 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 189 cost 0.006481170654296875 sec\n",
      "loss 1.933452, train acc 0.296711\n",
      "round 190\n",
      "time to device 0.004008 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001114 sec\n",
      "optimizer time 0.000213 sec\n",
      "training time in batch 190 cost 0.006436586380004883 sec\n",
      "loss 1.929665, train acc 0.298143\n",
      "round 191\n",
      "time to device 0.004034 sec\n",
      "time forward 0.000842 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001871 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 191 cost 0.0072057247161865234 sec\n",
      "loss 1.925972, train acc 0.299113\n",
      "round 192\n",
      "time to device 0.004027 sec\n",
      "time forward 0.000850 sec\n",
      "loss time 0.000086 sec\n",
      "backward time 0.001192 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 192 cost 0.006557941436767578 sec\n",
      "loss 1.921874, train acc 0.300721\n",
      "round 193\n",
      "time to device 0.004061 sec\n",
      "time forward 0.000858 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001076 sec\n",
      "optimizer time 0.000208 sec\n",
      "training time in batch 193 cost 0.0064775943756103516 sec\n",
      "loss 1.917961, train acc 0.301828\n",
      "round 194\n",
      "time to device 0.004034 sec\n",
      "time forward 0.000835 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001178 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 194 cost 0.0065195560455322266 sec\n",
      "loss 1.914679, train acc 0.303085\n",
      "round 195\n",
      "time to device 0.004032 sec\n",
      "time forward 0.000836 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001237 sec\n",
      "optimizer time 0.000199 sec\n",
      "training time in batch 195 cost 0.006604909896850586 sec\n",
      "loss 1.910504, train acc 0.304767\n",
      "round 196\n",
      "time to device 0.004057 sec\n",
      "time forward 0.000837 sec\n",
      "loss time 0.000079 sec\n",
      "backward time 0.001156 sec\n",
      "optimizer time 0.000201 sec\n",
      "training time in batch 196 cost 0.006571531295776367 sec\n",
      "loss 1.906559, train acc 0.305996\n",
      "round 197\n",
      "time to device 0.004063 sec\n",
      "time forward 0.000863 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001278 sec\n",
      "optimizer time 0.000226 sec\n",
      "training time in batch 197 cost 0.0068929195404052734 sec\n",
      "loss 1.902178, train acc 0.307568\n",
      "round 198\n",
      "time to device 0.004114 sec\n",
      "time forward 0.000834 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001111 sec\n",
      "optimizer time 0.000223 sec\n",
      "training time in batch 198 cost 0.0065610408782958984 sec\n",
      "loss 1.898359, train acc 0.308849\n",
      "round 199\n",
      "time to device 0.004066 sec\n",
      "time forward 0.000949 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001104 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 199 cost 0.00659632682800293 sec\n",
      "loss 1.894691, train acc 0.310391\n",
      "round 200\n",
      "time to device 0.004132 sec\n",
      "time forward 0.000903 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001178 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 200 cost 0.006682634353637695 sec\n",
      "loss 1.891295, train acc 0.311451\n",
      "round 201\n",
      "time to device 0.004138 sec\n",
      "time forward 0.000852 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001141 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 201 cost 0.006598234176635742 sec\n",
      "loss 1.888689, train acc 0.312345\n",
      "round 202\n",
      "time to device 0.003993 sec\n",
      "time forward 0.000841 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001162 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 202 cost 0.00646519660949707 sec\n",
      "loss 1.884782, train acc 0.313655\n",
      "round 203\n",
      "time to device 0.004115 sec\n",
      "time forward 0.000857 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001112 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 203 cost 0.006537675857543945 sec\n",
      "loss 1.880381, train acc 0.315181\n",
      "round 204\n",
      "time to device 0.004081 sec\n",
      "time forward 0.000951 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001220 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 204 cost 0.006706953048706055 sec\n",
      "loss 1.876380, train acc 0.316692\n",
      "round 205\n",
      "time to device 0.004099 sec\n",
      "time forward 0.000912 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001414 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 205 cost 0.00690007209777832 sec\n",
      "loss 1.871844, train acc 0.318530\n",
      "round 206\n",
      "time to device 0.004013 sec\n",
      "time forward 0.000920 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001248 sec\n",
      "optimizer time 0.000216 sec\n",
      "training time in batch 206 cost 0.006673336029052734 sec\n",
      "loss 1.867591, train acc 0.319897\n",
      "round 207\n",
      "time to device 0.004156 sec\n",
      "time forward 0.000853 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001177 sec\n",
      "optimizer time 0.000216 sec\n",
      "training time in batch 207 cost 0.006765842437744141 sec\n",
      "loss 1.863801, train acc 0.321214\n",
      "round 208\n",
      "time to device 0.004071 sec\n",
      "time forward 0.000838 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001179 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 208 cost 0.006571769714355469 sec\n",
      "loss 1.859710, train acc 0.322555\n",
      "round 209\n",
      "time to device 0.004104 sec\n",
      "time forward 0.000890 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001177 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 209 cost 0.006636381149291992 sec\n",
      "loss 1.856630, train acc 0.323735\n",
      "round 210\n",
      "time to device 0.004118 sec\n",
      "time forward 0.000840 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001751 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 210 cost 0.0072863101959228516 sec\n",
      "loss 1.852597, train acc 0.325274\n",
      "round 211\n",
      "time to device 0.004180 sec\n",
      "time forward 0.000854 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001153 sec\n",
      "optimizer time 0.000269 sec\n",
      "training time in batch 211 cost 0.006720542907714844 sec\n",
      "loss 1.848929, train acc 0.326393\n",
      "round 212\n",
      "time to device 0.004232 sec\n",
      "time forward 0.000839 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001179 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 212 cost 0.006711006164550781 sec\n",
      "loss 1.845981, train acc 0.327171\n",
      "round 213\n",
      "time to device 0.004086 sec\n",
      "time forward 0.000839 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001174 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 213 cost 0.006573200225830078 sec\n",
      "loss 1.842410, train acc 0.328198\n",
      "round 214\n",
      "time to device 0.004103 sec\n",
      "time forward 0.000839 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001572 sec\n",
      "optimizer time 0.000203 sec\n",
      "training time in batch 214 cost 0.007004261016845703 sec\n",
      "loss 1.839146, train acc 0.329215\n",
      "round 215\n",
      "time to device 0.003986 sec\n",
      "time forward 0.000960 sec\n",
      "loss time 0.000087 sec\n",
      "backward time 0.001279 sec\n",
      "optimizer time 0.000198 sec\n",
      "training time in batch 215 cost 0.0067942142486572266 sec\n",
      "loss 1.836349, train acc 0.330187\n",
      "round 216\n",
      "time to device 0.004180 sec\n",
      "time forward 0.000828 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001704 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 216 cost 0.00717473030090332 sec\n",
      "loss 1.832385, train acc 0.331689\n",
      "round 217\n",
      "time to device 0.004091 sec\n",
      "time forward 0.000902 sec\n",
      "loss time 0.000086 sec\n",
      "backward time 0.001244 sec\n",
      "optimizer time 0.000205 sec\n",
      "training time in batch 217 cost 0.006718873977661133 sec\n",
      "loss 1.829572, train acc 0.332425\n",
      "round 218\n",
      "time to device 0.004131 sec\n",
      "time forward 0.000949 sec\n",
      "loss time 0.000087 sec\n",
      "backward time 0.001110 sec\n",
      "optimizer time 0.000200 sec\n",
      "training time in batch 218 cost 0.0066814422607421875 sec\n",
      "loss 1.825773, train acc 0.333726\n",
      "round 219\n",
      "time to device 0.004187 sec\n",
      "time forward 0.000853 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001217 sec\n",
      "optimizer time 0.000211 sec\n",
      "training time in batch 219 cost 0.006768465042114258 sec\n",
      "loss 1.822949, train acc 0.334553\n",
      "round 220\n",
      "time to device 0.003986 sec\n",
      "time forward 0.000962 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001200 sec\n",
      "optimizer time 0.000230 sec\n",
      "training time in batch 220 cost 0.006652116775512695 sec\n",
      "loss 1.819457, train acc 0.335831\n",
      "round 221\n",
      "time to device 0.004038 sec\n",
      "time forward 0.000837 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001190 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 221 cost 0.006537437438964844 sec\n",
      "loss 1.815806, train acc 0.336888\n",
      "round 222\n",
      "time to device 0.003983 sec\n",
      "time forward 0.000823 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001596 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 222 cost 0.00685882568359375 sec\n",
      "loss 1.812520, train acc 0.337899\n",
      "round 223\n",
      "time to device 0.004019 sec\n",
      "time forward 0.000853 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001188 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 223 cost 0.006532907485961914 sec\n",
      "loss 1.808501, train acc 0.339286\n",
      "round 224\n",
      "time to device 0.004050 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001583 sec\n",
      "optimizer time 0.000248 sec\n",
      "training time in batch 224 cost 0.00697636604309082 sec\n",
      "loss 1.805735, train acc 0.340139\n",
      "round 225\n",
      "time to device 0.004076 sec\n",
      "time forward 0.000856 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001194 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 225 cost 0.00665283203125 sec\n",
      "loss 1.802615, train acc 0.341261\n",
      "round 226\n",
      "time to device 0.004011 sec\n",
      "time forward 0.000853 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001151 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 226 cost 0.006495475769042969 sec\n",
      "loss 1.799265, train acc 0.342305\n",
      "round 227\n",
      "time to device 0.004011 sec\n",
      "time forward 0.000860 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001159 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 227 cost 0.006518363952636719 sec\n",
      "loss 1.795977, train acc 0.343544\n",
      "round 228\n",
      "time to device 0.004029 sec\n",
      "time forward 0.000874 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001112 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 228 cost 0.0064852237701416016 sec\n",
      "loss 1.792793, train acc 0.344842\n",
      "round 229\n",
      "time to device 0.003996 sec\n",
      "time forward 0.000867 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001145 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 229 cost 0.006460428237915039 sec\n",
      "loss 1.789469, train acc 0.345822\n",
      "round 230\n",
      "time to device 0.004019 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001317 sec\n",
      "optimizer time 0.000200 sec\n",
      "training time in batch 230 cost 0.006673097610473633 sec\n",
      "loss 1.786266, train acc 0.346828\n",
      "round 231\n",
      "time to device 0.004015 sec\n",
      "time forward 0.000825 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001241 sec\n",
      "optimizer time 0.000216 sec\n",
      "training time in batch 231 cost 0.006580829620361328 sec\n",
      "loss 1.782262, train acc 0.348229\n",
      "round 232\n",
      "time to device 0.003984 sec\n",
      "time forward 0.000835 sec\n",
      "loss time 0.000085 sec\n",
      "backward time 0.001188 sec\n",
      "optimizer time 0.000235 sec\n",
      "training time in batch 232 cost 0.006518840789794922 sec\n",
      "loss 1.779009, train acc 0.349249\n",
      "round 233\n",
      "time to device 0.004009 sec\n",
      "time forward 0.000826 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001664 sec\n",
      "optimizer time 0.000221 sec\n",
      "training time in batch 233 cost 0.006987094879150391 sec\n",
      "loss 1.775873, train acc 0.350361\n",
      "round 234\n",
      "time to device 0.004096 sec\n",
      "time forward 0.000838 sec\n",
      "loss time 0.000090 sec\n",
      "backward time 0.001195 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 234 cost 0.0066089630126953125 sec\n",
      "loss 1.773184, train acc 0.351263\n",
      "round 235\n",
      "time to device 0.004056 sec\n",
      "time forward 0.001000 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001196 sec\n",
      "optimizer time 0.000212 sec\n",
      "training time in batch 235 cost 0.006729841232299805 sec\n",
      "loss 1.770250, train acc 0.352225\n",
      "round 236\n",
      "time to device 0.004190 sec\n",
      "time forward 0.000870 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001070 sec\n",
      "optimizer time 0.000201 sec\n",
      "training time in batch 236 cost 0.006669759750366211 sec\n",
      "loss 1.767140, train acc 0.353376\n",
      "round 237\n",
      "time to device 0.004184 sec\n",
      "time forward 0.000842 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001168 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 237 cost 0.006661415100097656 sec\n",
      "loss 1.764196, train acc 0.354320\n",
      "round 238\n",
      "time to device 0.004134 sec\n",
      "time forward 0.000827 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001665 sec\n",
      "optimizer time 0.000198 sec\n",
      "training time in batch 238 cost 0.007109403610229492 sec\n",
      "loss 1.760492, train acc 0.355681\n",
      "round 239\n",
      "time to device 0.004120 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001198 sec\n",
      "optimizer time 0.000203 sec\n",
      "training time in batch 239 cost 0.006616115570068359 sec\n",
      "loss 1.756695, train acc 0.357064\n",
      "round 240\n",
      "time to device 0.004094 sec\n",
      "time forward 0.000898 sec\n",
      "loss time 0.000085 sec\n",
      "backward time 0.001176 sec\n",
      "optimizer time 0.000224 sec\n",
      "training time in batch 240 cost 0.0066721439361572266 sec\n",
      "loss 1.754358, train acc 0.357787\n",
      "round 241\n",
      "time to device 0.004055 sec\n",
      "time forward 0.000930 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001185 sec\n",
      "optimizer time 0.000208 sec\n",
      "training time in batch 241 cost 0.00664067268371582 sec\n",
      "loss 1.751712, train acc 0.358697\n",
      "round 242\n",
      "time to device 0.004108 sec\n",
      "time forward 0.000955 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001201 sec\n",
      "optimizer time 0.000200 sec\n",
      "training time in batch 242 cost 0.006728410720825195 sec\n",
      "loss 1.748817, train acc 0.359536\n",
      "round 243\n",
      "time to device 0.004013 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001588 sec\n",
      "optimizer time 0.000250 sec\n",
      "training time in batch 243 cost 0.006959438323974609 sec\n",
      "loss 1.745557, train acc 0.360624\n",
      "round 244\n",
      "time to device 0.004010 sec\n",
      "time forward 0.000822 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001970 sec\n",
      "optimizer time 0.000231 sec\n",
      "training time in batch 244 cost 0.007297039031982422 sec\n",
      "loss 1.742454, train acc 0.361639\n",
      "round 245\n",
      "time to device 0.004008 sec\n",
      "time forward 0.000824 sec\n",
      "loss time 0.000087 sec\n",
      "backward time 0.001149 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 245 cost 0.006478548049926758 sec\n",
      "loss 1.739496, train acc 0.362583\n",
      "round 246\n",
      "time to device 0.004031 sec\n",
      "time forward 0.000840 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001170 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 246 cost 0.0065271854400634766 sec\n",
      "loss 1.736188, train acc 0.363708\n",
      "round 247\n",
      "time to device 0.004128 sec\n",
      "time forward 0.000925 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001163 sec\n",
      "optimizer time 0.000201 sec\n",
      "training time in batch 247 cost 0.006698131561279297 sec\n",
      "loss 1.733407, train acc 0.364604\n",
      "round 248\n",
      "time to device 0.004062 sec\n",
      "time forward 0.000856 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001195 sec\n",
      "optimizer time 0.000211 sec\n",
      "training time in batch 248 cost 0.006608247756958008 sec\n",
      "loss 1.731187, train acc 0.365556\n",
      "round 249\n",
      "time to device 0.004022 sec\n",
      "time forward 0.000836 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001948 sec\n",
      "optimizer time 0.000233 sec\n",
      "training time in batch 249 cost 0.007313251495361328 sec\n",
      "loss 1.728952, train acc 0.366375\n",
      "round 250\n",
      "time to device 0.004004 sec\n",
      "time forward 0.000841 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001180 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 250 cost 0.006523609161376953 sec\n",
      "loss 1.725628, train acc 0.367499\n",
      "round 251\n",
      "time to device 0.004059 sec\n",
      "time forward 0.000968 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001258 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 251 cost 0.00678706169128418 sec\n",
      "loss 1.722522, train acc 0.368707\n",
      "round 252\n",
      "time to device 0.004004 sec\n",
      "time forward 0.000842 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001191 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 252 cost 0.00650787353515625 sec\n",
      "loss 1.719056, train acc 0.369967\n",
      "round 253\n",
      "time to device 0.004023 sec\n",
      "time forward 0.000826 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001589 sec\n",
      "optimizer time 0.000212 sec\n",
      "training time in batch 253 cost 0.00692296028137207 sec\n",
      "loss 1.716056, train acc 0.371155\n",
      "round 254\n",
      "time to device 0.004038 sec\n",
      "time forward 0.000823 sec\n",
      "loss time 0.000092 sec\n",
      "backward time 0.001443 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 254 cost 0.006808280944824219 sec\n",
      "loss 1.712521, train acc 0.372243\n",
      "round 255\n",
      "time to device 0.004112 sec\n",
      "time forward 0.000993 sec\n",
      "loss time 0.000104 sec\n",
      "backward time 0.001182 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 255 cost 0.006815433502197266 sec\n",
      "loss 1.709906, train acc 0.373260\n",
      "round 256\n",
      "time to device 0.004013 sec\n",
      "time forward 0.000825 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001611 sec\n",
      "optimizer time 0.000228 sec\n",
      "training time in batch 256 cost 0.006957054138183594 sec\n",
      "loss 1.707191, train acc 0.374179\n",
      "round 257\n",
      "time to device 0.004020 sec\n",
      "time forward 0.000940 sec\n",
      "loss time 0.000090 sec\n",
      "backward time 0.001229 sec\n",
      "optimizer time 0.000224 sec\n",
      "training time in batch 257 cost 0.006712198257446289 sec\n",
      "loss 1.703972, train acc 0.375091\n",
      "round 258\n",
      "time to device 0.004035 sec\n",
      "time forward 0.000867 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001180 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 258 cost 0.00656437873840332 sec\n",
      "loss 1.700857, train acc 0.376207\n",
      "round 259\n",
      "time to device 0.004009 sec\n",
      "time forward 0.000868 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001164 sec\n",
      "optimizer time 0.000208 sec\n",
      "training time in batch 259 cost 0.006518840789794922 sec\n",
      "loss 1.697660, train acc 0.377554\n",
      "round 260\n",
      "time to device 0.004060 sec\n",
      "time forward 0.000831 sec\n",
      "loss time 0.000082 sec\n",
      "backward time 0.001216 sec\n",
      "optimizer time 0.000199 sec\n",
      "training time in batch 260 cost 0.0066072940826416016 sec\n",
      "loss 1.694303, train acc 0.378682\n",
      "round 261\n",
      "time to device 0.004022 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001562 sec\n",
      "optimizer time 0.000236 sec\n",
      "training time in batch 261 cost 0.006922245025634766 sec\n",
      "loss 1.691433, train acc 0.379592\n",
      "round 262\n",
      "time to device 0.003986 sec\n",
      "time forward 0.000861 sec\n",
      "loss time 0.000095 sec\n",
      "backward time 0.001989 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 262 cost 0.007329463958740234 sec\n",
      "loss 1.688891, train acc 0.380466\n",
      "round 263\n",
      "time to device 0.004075 sec\n",
      "time forward 0.000916 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001191 sec\n",
      "optimizer time 0.000198 sec\n",
      "training time in batch 263 cost 0.006658077239990234 sec\n",
      "loss 1.686926, train acc 0.380919\n",
      "round 264\n",
      "time to device 0.004033 sec\n",
      "time forward 0.000832 sec\n",
      "loss time 0.000089 sec\n",
      "backward time 0.001213 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 264 cost 0.0065670013427734375 sec\n",
      "loss 1.684420, train acc 0.381781\n",
      "round 265\n",
      "time to device 0.004008 sec\n",
      "time forward 0.000854 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001149 sec\n",
      "optimizer time 0.000205 sec\n",
      "training time in batch 265 cost 0.006493091583251953 sec\n",
      "loss 1.681700, train acc 0.382578\n",
      "round 266\n",
      "time to device 0.004076 sec\n",
      "time forward 0.000865 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001133 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 266 cost 0.006554126739501953 sec\n",
      "loss 1.678929, train acc 0.383427\n",
      "round 267\n",
      "time to device 0.003979 sec\n",
      "time forward 0.000992 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001128 sec\n",
      "optimizer time 0.000198 sec\n",
      "training time in batch 267 cost 0.006577730178833008 sec\n",
      "loss 1.676184, train acc 0.384445\n",
      "round 268\n",
      "time to device 0.004204 sec\n",
      "time forward 0.000909 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001097 sec\n",
      "optimizer time 0.000277 sec\n",
      "training time in batch 268 cost 0.006760358810424805 sec\n",
      "loss 1.673305, train acc 0.385688\n",
      "round 269\n",
      "time to device 0.004137 sec\n",
      "time forward 0.000824 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001794 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 269 cost 0.007227420806884766 sec\n",
      "loss 1.670309, train acc 0.386892\n",
      "round 270\n",
      "time to device 0.004029 sec\n",
      "time forward 0.000846 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001465 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 270 cost 0.006793022155761719 sec\n",
      "loss 1.668054, train acc 0.387598\n",
      "round 271\n",
      "time to device 0.004007 sec\n",
      "time forward 0.000887 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001209 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 271 cost 0.006568431854248047 sec\n",
      "loss 1.665866, train acc 0.388557\n",
      "round 272\n",
      "time to device 0.004020 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000085 sec\n",
      "backward time 0.001163 sec\n",
      "optimizer time 0.000203 sec\n",
      "training time in batch 272 cost 0.006505489349365234 sec\n",
      "loss 1.663045, train acc 0.389652\n",
      "round 273\n",
      "time to device 0.004019 sec\n",
      "time forward 0.000832 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001640 sec\n",
      "optimizer time 0.000220 sec\n",
      "training time in batch 273 cost 0.006996870040893555 sec\n",
      "loss 1.660303, train acc 0.390340\n",
      "round 274\n",
      "time to device 0.004038 sec\n",
      "time forward 0.000835 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001825 sec\n",
      "optimizer time 0.000201 sec\n",
      "training time in batch 274 cost 0.007166147232055664 sec\n",
      "loss 1.657984, train acc 0.391193\n",
      "round 275\n",
      "time to device 0.004045 sec\n",
      "time forward 0.000821 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001594 sec\n",
      "optimizer time 0.000214 sec\n",
      "training time in batch 275 cost 0.006949901580810547 sec\n",
      "loss 1.655367, train acc 0.392182\n",
      "round 276\n",
      "time to device 0.003992 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001235 sec\n",
      "optimizer time 0.000198 sec\n",
      "training time in batch 276 cost 0.0065310001373291016 sec\n",
      "loss 1.652954, train acc 0.393163\n",
      "round 277\n",
      "time to device 0.004001 sec\n",
      "time forward 0.000837 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001141 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 277 cost 0.0064411163330078125 sec\n",
      "loss 1.649864, train acc 0.394306\n",
      "round 278\n",
      "time to device 0.004011 sec\n",
      "time forward 0.000892 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001040 sec\n",
      "optimizer time 0.000200 sec\n",
      "training time in batch 278 cost 0.0064258575439453125 sec\n",
      "loss 1.647188, train acc 0.395245\n",
      "round 279\n",
      "time to device 0.004018 sec\n",
      "time forward 0.000842 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001186 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 279 cost 0.006519794464111328 sec\n",
      "loss 1.644210, train acc 0.396317\n",
      "round 280\n",
      "time to device 0.004027 sec\n",
      "time forward 0.000834 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001180 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 280 cost 0.006506919860839844 sec\n",
      "loss 1.641385, train acc 0.397409\n",
      "round 281\n",
      "time to device 0.004013 sec\n",
      "time forward 0.000837 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001183 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 281 cost 0.006502866744995117 sec\n",
      "loss 1.638286, train acc 0.398548\n",
      "round 282\n",
      "time to device 0.004002 sec\n",
      "time forward 0.000852 sec\n",
      "loss time 0.000085 sec\n",
      "backward time 0.001179 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 282 cost 0.006522655487060547 sec\n",
      "loss 1.635552, train acc 0.399625\n",
      "round 283\n",
      "time to device 0.004014 sec\n",
      "time forward 0.000818 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001667 sec\n",
      "optimizer time 0.000227 sec\n",
      "training time in batch 283 cost 0.007002592086791992 sec\n",
      "loss 1.632607, train acc 0.400666\n",
      "round 284\n",
      "time to device 0.004020 sec\n",
      "time forward 0.000842 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001209 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 284 cost 0.006567478179931641 sec\n",
      "loss 1.630176, train acc 0.401590\n",
      "round 285\n",
      "time to device 0.003997 sec\n",
      "time forward 0.000843 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001632 sec\n",
      "optimizer time 0.000205 sec\n",
      "training time in batch 285 cost 0.006961822509765625 sec\n",
      "loss 1.628397, train acc 0.402043\n",
      "round 286\n",
      "time to device 0.004064 sec\n",
      "time forward 0.000877 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001187 sec\n",
      "optimizer time 0.000208 sec\n",
      "training time in batch 286 cost 0.00664830207824707 sec\n",
      "loss 1.626565, train acc 0.402466\n",
      "round 287\n",
      "time to device 0.003999 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001585 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 287 cost 0.0068776607513427734 sec\n",
      "loss 1.624548, train acc 0.403103\n",
      "round 288\n",
      "time to device 0.004020 sec\n",
      "time forward 0.000852 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001170 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 288 cost 0.006532907485961914 sec\n",
      "loss 1.622086, train acc 0.403817\n",
      "round 289\n",
      "time to device 0.004006 sec\n",
      "time forward 0.000854 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001333 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 289 cost 0.006665945053100586 sec\n",
      "loss 1.619419, train acc 0.404714\n",
      "round 290\n",
      "time to device 0.004070 sec\n",
      "time forward 0.000886 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001180 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 290 cost 0.006609678268432617 sec\n",
      "loss 1.616862, train acc 0.405579\n",
      "round 291\n",
      "time to device 0.003996 sec\n",
      "time forward 0.000824 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001777 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 291 cost 0.007055521011352539 sec\n",
      "loss 1.614241, train acc 0.406464\n",
      "round 292\n",
      "time to device 0.004026 sec\n",
      "time forward 0.000829 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001225 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 292 cost 0.006539344787597656 sec\n",
      "loss 1.611318, train acc 0.407557\n",
      "round 293\n",
      "time to device 0.004074 sec\n",
      "time forward 0.000831 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001298 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 293 cost 0.0066792964935302734 sec\n",
      "loss 1.608958, train acc 0.408323\n",
      "round 294\n",
      "time to device 0.004018 sec\n",
      "time forward 0.000832 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001188 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 294 cost 0.006493568420410156 sec\n",
      "loss 1.606737, train acc 0.409216\n",
      "round 295\n",
      "time to device 0.003955 sec\n",
      "time forward 0.000854 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001132 sec\n",
      "optimizer time 0.000190 sec\n",
      "training time in batch 295 cost 0.00640106201171875 sec\n",
      "loss 1.604278, train acc 0.410051\n",
      "round 296\n",
      "time to device 0.004028 sec\n",
      "time forward 0.000840 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001168 sec\n",
      "optimizer time 0.000201 sec\n",
      "training time in batch 296 cost 0.006505250930786133 sec\n",
      "loss 1.601906, train acc 0.410748\n",
      "round 297\n",
      "time to device 0.003994 sec\n",
      "time forward 0.000853 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001174 sec\n",
      "optimizer time 0.000203 sec\n",
      "training time in batch 297 cost 0.006519794464111328 sec\n",
      "loss 1.599579, train acc 0.411572\n",
      "round 298\n",
      "time to device 0.003993 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000082 sec\n",
      "backward time 0.001192 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 298 cost 0.0064852237701416016 sec\n",
      "loss 1.596966, train acc 0.412625\n",
      "round 299\n",
      "time to device 0.004003 sec\n",
      "time forward 0.000846 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001171 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 299 cost 0.006482601165771484 sec\n",
      "loss 1.594358, train acc 0.413620\n",
      "round 300\n",
      "time to device 0.004013 sec\n",
      "time forward 0.000870 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001202 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 300 cost 0.0065495967864990234 sec\n",
      "loss 1.592078, train acc 0.414348\n",
      "round 301\n",
      "time to device 0.004029 sec\n",
      "time forward 0.000826 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001608 sec\n",
      "optimizer time 0.000190 sec\n",
      "training time in batch 301 cost 0.006934165954589844 sec\n",
      "loss 1.590179, train acc 0.415020\n",
      "round 302\n",
      "time to device 0.004030 sec\n",
      "time forward 0.000827 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001567 sec\n",
      "optimizer time 0.000219 sec\n",
      "training time in batch 302 cost 0.0069124698638916016 sec\n",
      "loss 1.587824, train acc 0.415816\n",
      "round 303\n",
      "time to device 0.004008 sec\n",
      "time forward 0.000829 sec\n",
      "loss time 0.000087 sec\n",
      "backward time 0.001546 sec\n",
      "optimizer time 0.000216 sec\n",
      "training time in batch 303 cost 0.006875038146972656 sec\n",
      "loss 1.585357, train acc 0.416709\n",
      "round 304\n",
      "time to device 0.003987 sec\n",
      "time forward 0.000845 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001209 sec\n",
      "optimizer time 0.000208 sec\n",
      "training time in batch 304 cost 0.006516695022583008 sec\n",
      "loss 1.583156, train acc 0.417444\n",
      "round 305\n",
      "time to device 0.004030 sec\n",
      "time forward 0.000827 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001366 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 305 cost 0.0067064762115478516 sec\n",
      "loss 1.581132, train acc 0.418147\n",
      "round 306\n",
      "time to device 0.004012 sec\n",
      "time forward 0.000840 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001955 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 306 cost 0.0072841644287109375 sec\n",
      "loss 1.578582, train acc 0.418898\n",
      "round 307\n",
      "time to device 0.003996 sec\n",
      "time forward 0.000818 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001926 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 307 cost 0.007210969924926758 sec\n",
      "loss 1.576020, train acc 0.419871\n",
      "round 308\n",
      "time to device 0.004021 sec\n",
      "time forward 0.000822 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001859 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 308 cost 0.00717616081237793 sec\n",
      "loss 1.573723, train acc 0.420788\n",
      "round 309\n",
      "time to device 0.004000 sec\n",
      "time forward 0.000834 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001606 sec\n",
      "optimizer time 0.000208 sec\n",
      "training time in batch 309 cost 0.006930351257324219 sec\n",
      "loss 1.571216, train acc 0.421799\n",
      "round 310\n",
      "time to device 0.003981 sec\n",
      "time forward 0.000819 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001198 sec\n",
      "optimizer time 0.000198 sec\n",
      "training time in batch 310 cost 0.00646209716796875 sec\n",
      "loss 1.569085, train acc 0.422679\n",
      "round 311\n",
      "time to device 0.004000 sec\n",
      "time forward 0.000873 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001184 sec\n",
      "optimizer time 0.000187 sec\n",
      "training time in batch 311 cost 0.006510019302368164 sec\n",
      "loss 1.567359, train acc 0.423302\n",
      "round 312\n",
      "time to device 0.004024 sec\n",
      "time forward 0.000865 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001147 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 312 cost 0.006510496139526367 sec\n",
      "loss 1.564998, train acc 0.424071\n",
      "round 313\n",
      "time to device 0.004031 sec\n",
      "time forward 0.000839 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001166 sec\n",
      "optimizer time 0.000187 sec\n",
      "training time in batch 313 cost 0.006505012512207031 sec\n",
      "loss 1.562377, train acc 0.424861\n",
      "round 314\n",
      "time to device 0.003993 sec\n",
      "time forward 0.000873 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001168 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 314 cost 0.006502628326416016 sec\n",
      "loss 1.560107, train acc 0.425744\n",
      "round 315\n",
      "time to device 0.004005 sec\n",
      "time forward 0.000862 sec\n",
      "loss time 0.000083 sec\n",
      "backward time 0.001136 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 315 cost 0.006485700607299805 sec\n",
      "loss 1.557707, train acc 0.426523\n",
      "round 316\n",
      "time to device 0.003995 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001592 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 316 cost 0.006884098052978516 sec\n",
      "loss 1.555302, train acc 0.427469\n",
      "round 317\n",
      "time to device 0.004005 sec\n",
      "time forward 0.000870 sec\n",
      "loss time 0.000085 sec\n",
      "backward time 0.001209 sec\n",
      "optimizer time 0.000219 sec\n",
      "training time in batch 317 cost 0.006574869155883789 sec\n",
      "loss 1.553777, train acc 0.427968\n",
      "round 318\n",
      "time to device 0.004007 sec\n",
      "time forward 0.000835 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001179 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 318 cost 0.006493330001831055 sec\n",
      "loss 1.552041, train acc 0.428610\n",
      "round 319\n",
      "time to device 0.003986 sec\n",
      "time forward 0.000828 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001897 sec\n",
      "optimizer time 0.000210 sec\n",
      "training time in batch 319 cost 0.007190227508544922 sec\n",
      "loss 1.550312, train acc 0.429150\n",
      "round 320\n",
      "time to device 0.004004 sec\n",
      "time forward 0.000828 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001168 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 320 cost 0.006459474563598633 sec\n",
      "loss 1.548296, train acc 0.429980\n",
      "round 321\n",
      "time to device 0.004011 sec\n",
      "time forward 0.000854 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001178 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 321 cost 0.006495475769042969 sec\n",
      "loss 1.545877, train acc 0.430852\n",
      "round 322\n",
      "time to device 0.003971 sec\n",
      "time forward 0.000855 sec\n",
      "loss time 0.000086 sec\n",
      "backward time 0.001176 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 322 cost 0.006487131118774414 sec\n",
      "loss 1.543335, train acc 0.431719\n",
      "round 323\n",
      "time to device 0.003990 sec\n",
      "time forward 0.000815 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001813 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 323 cost 0.007097005844116211 sec\n",
      "loss 1.541585, train acc 0.432412\n",
      "round 324\n",
      "time to device 0.004014 sec\n",
      "time forward 0.000882 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001254 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 324 cost 0.0066220760345458984 sec\n",
      "loss 1.539823, train acc 0.433101\n",
      "round 325\n",
      "time to device 0.004012 sec\n",
      "time forward 0.000835 sec\n",
      "loss time 0.000084 sec\n",
      "backward time 0.001165 sec\n",
      "optimizer time 0.000211 sec\n",
      "training time in batch 325 cost 0.006502628326416016 sec\n",
      "loss 1.538195, train acc 0.433618\n",
      "round 326\n",
      "time to device 0.004039 sec\n",
      "time forward 0.000817 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001549 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 326 cost 0.006878852844238281 sec\n",
      "loss 1.536337, train acc 0.434179\n",
      "round 327\n",
      "time to device 0.004006 sec\n",
      "time forward 0.000835 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001668 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 327 cost 0.006970882415771484 sec\n",
      "loss 1.534109, train acc 0.434975\n",
      "round 328\n",
      "time to device 0.004058 sec\n",
      "time forward 0.000835 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001182 sec\n",
      "optimizer time 0.000217 sec\n",
      "training time in batch 328 cost 0.006589412689208984 sec\n",
      "loss 1.531849, train acc 0.435719\n",
      "round 329\n",
      "time to device 0.003997 sec\n",
      "time forward 0.000829 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001604 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 329 cost 0.006910562515258789 sec\n",
      "loss 1.529503, train acc 0.436458\n",
      "round 330\n",
      "time to device 0.004019 sec\n",
      "time forward 0.000822 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001693 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 330 cost 0.007008075714111328 sec\n",
      "loss 1.527436, train acc 0.437170\n",
      "round 331\n",
      "time to device 0.003980 sec\n",
      "time forward 0.000836 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001581 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 331 cost 0.0068645477294921875 sec\n",
      "loss 1.525210, train acc 0.438018\n",
      "round 332\n",
      "time to device 0.003997 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001564 sec\n",
      "optimizer time 0.000215 sec\n",
      "training time in batch 332 cost 0.00689697265625 sec\n",
      "loss 1.523030, train acc 0.438790\n",
      "round 333\n",
      "time to device 0.004016 sec\n",
      "time forward 0.000849 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001146 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 333 cost 0.006484508514404297 sec\n",
      "loss 1.521282, train acc 0.439395\n",
      "round 334\n",
      "time to device 0.003994 sec\n",
      "time forward 0.000851 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001096 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 334 cost 0.006441354751586914 sec\n",
      "loss 1.519690, train acc 0.439949\n",
      "round 335\n",
      "time to device 0.004042 sec\n",
      "time forward 0.000857 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001201 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 335 cost 0.006579399108886719 sec\n",
      "loss 1.518293, train acc 0.440499\n",
      "round 336\n",
      "time to device 0.003989 sec\n",
      "time forward 0.000831 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001182 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 336 cost 0.006464958190917969 sec\n",
      "loss 1.516390, train acc 0.441256\n",
      "round 337\n",
      "time to device 0.003998 sec\n",
      "time forward 0.000869 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001173 sec\n",
      "optimizer time 0.000190 sec\n",
      "training time in batch 337 cost 0.006509065628051758 sec\n",
      "loss 1.514390, train acc 0.441915\n",
      "round 338\n",
      "time to device 0.003988 sec\n",
      "time forward 0.000822 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001565 sec\n",
      "optimizer time 0.000213 sec\n",
      "training time in batch 338 cost 0.006856203079223633 sec\n",
      "loss 1.512336, train acc 0.442708\n",
      "round 339\n",
      "time to device 0.004006 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001622 sec\n",
      "optimizer time 0.000213 sec\n",
      "training time in batch 339 cost 0.0069429874420166016 sec\n",
      "loss 1.510264, train acc 0.443681\n",
      "round 340\n",
      "time to device 0.003999 sec\n",
      "time forward 0.000857 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001139 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 340 cost 0.0064618587493896484 sec\n",
      "loss 1.508389, train acc 0.444373\n",
      "round 341\n",
      "time to device 0.004026 sec\n",
      "time forward 0.000849 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001240 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 341 cost 0.00658726692199707 sec\n",
      "loss 1.506584, train acc 0.445061\n",
      "round 342\n",
      "time to device 0.003969 sec\n",
      "time forward 0.000855 sec\n",
      "loss time 0.000081 sec\n",
      "backward time 0.001188 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 342 cost 0.0064945220947265625 sec\n",
      "loss 1.504329, train acc 0.445814\n",
      "round 343\n",
      "time to device 0.003981 sec\n",
      "time forward 0.000846 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001239 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 343 cost 0.006534576416015625 sec\n",
      "loss 1.503023, train acc 0.446334\n",
      "round 344\n",
      "time to device 0.003994 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001592 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 344 cost 0.006875276565551758 sec\n",
      "loss 1.501190, train acc 0.447011\n",
      "round 345\n",
      "time to device 0.003976 sec\n",
      "time forward 0.000860 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001273 sec\n",
      "optimizer time 0.000216 sec\n",
      "training time in batch 345 cost 0.006626605987548828 sec\n",
      "loss 1.499188, train acc 0.447729\n",
      "round 346\n",
      "time to device 0.004019 sec\n",
      "time forward 0.000858 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001135 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 346 cost 0.006474971771240234 sec\n",
      "loss 1.497248, train acc 0.448397\n",
      "round 347\n",
      "time to device 0.004099 sec\n",
      "time forward 0.000858 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001271 sec\n",
      "optimizer time 0.000233 sec\n",
      "training time in batch 347 cost 0.00679326057434082 sec\n",
      "loss 1.495556, train acc 0.448904\n",
      "round 348\n",
      "time to device 0.004023 sec\n",
      "time forward 0.000838 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001589 sec\n",
      "optimizer time 0.000203 sec\n",
      "training time in batch 348 cost 0.0069239139556884766 sec\n",
      "loss 1.493605, train acc 0.449655\n",
      "round 349\n",
      "time to device 0.003979 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001174 sec\n",
      "optimizer time 0.000190 sec\n",
      "training time in batch 349 cost 0.0064542293548583984 sec\n",
      "loss 1.491756, train acc 0.450201\n",
      "round 350\n",
      "time to device 0.003993 sec\n",
      "time forward 0.000850 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001114 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 350 cost 0.006438493728637695 sec\n",
      "loss 1.489702, train acc 0.450877\n",
      "round 351\n",
      "time to device 0.004058 sec\n",
      "time forward 0.000857 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001179 sec\n",
      "optimizer time 0.000203 sec\n",
      "training time in batch 351 cost 0.0065767765045166016 sec\n",
      "loss 1.488012, train acc 0.451483\n",
      "round 352\n",
      "time to device 0.003992 sec\n",
      "time forward 0.000981 sec\n",
      "loss time 0.000111 sec\n",
      "backward time 0.001185 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 352 cost 0.006670475006103516 sec\n",
      "loss 1.486739, train acc 0.451974\n",
      "round 353\n",
      "time to device 0.004012 sec\n",
      "time forward 0.000841 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001171 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 353 cost 0.006505250930786133 sec\n",
      "loss 1.484952, train acc 0.452728\n",
      "round 354\n",
      "time to device 0.003992 sec\n",
      "time forward 0.000861 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001149 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 354 cost 0.0064661502838134766 sec\n",
      "loss 1.483327, train acc 0.453213\n",
      "round 355\n",
      "time to device 0.003980 sec\n",
      "time forward 0.000846 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001229 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 355 cost 0.006514549255371094 sec\n",
      "loss 1.481592, train acc 0.453849\n",
      "round 356\n",
      "time to device 0.004049 sec\n",
      "time forward 0.000818 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001681 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 356 cost 0.007028102874755859 sec\n",
      "loss 1.479805, train acc 0.454460\n",
      "round 357\n",
      "time to device 0.003997 sec\n",
      "time forward 0.000827 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001626 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 357 cost 0.006911277770996094 sec\n",
      "loss 1.477777, train acc 0.455176\n",
      "round 358\n",
      "time to device 0.003984 sec\n",
      "time forward 0.000826 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001721 sec\n",
      "optimizer time 0.000217 sec\n",
      "training time in batch 358 cost 0.007019758224487305 sec\n",
      "loss 1.476047, train acc 0.455780\n",
      "round 359\n",
      "time to device 0.003987 sec\n",
      "time forward 0.000843 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001175 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 359 cost 0.0064694881439208984 sec\n",
      "loss 1.474154, train acc 0.456510\n",
      "round 360\n",
      "time to device 0.004014 sec\n",
      "time forward 0.000846 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001169 sec\n",
      "optimizer time 0.000230 sec\n",
      "training time in batch 360 cost 0.006538867950439453 sec\n",
      "loss 1.472341, train acc 0.457129\n",
      "round 361\n",
      "time to device 0.004017 sec\n",
      "time forward 0.000832 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001151 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 361 cost 0.0064737796783447266 sec\n",
      "loss 1.470820, train acc 0.457700\n",
      "round 362\n",
      "time to device 0.004004 sec\n",
      "time forward 0.000832 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001569 sec\n",
      "optimizer time 0.000244 sec\n",
      "training time in batch 362 cost 0.006936788558959961 sec\n",
      "loss 1.469345, train acc 0.458376\n",
      "round 363\n",
      "time to device 0.004002 sec\n",
      "time forward 0.000823 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001576 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 363 cost 0.006861686706542969 sec\n",
      "loss 1.467496, train acc 0.459049\n",
      "round 364\n",
      "time to device 0.004052 sec\n",
      "time forward 0.000840 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001123 sec\n",
      "optimizer time 0.000190 sec\n",
      "training time in batch 364 cost 0.006470441818237305 sec\n",
      "loss 1.466170, train acc 0.459717\n",
      "round 365\n",
      "time to device 0.004043 sec\n",
      "time forward 0.000835 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001198 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 365 cost 0.0065538883209228516 sec\n",
      "loss 1.464350, train acc 0.460489\n",
      "round 366\n",
      "time to device 0.004012 sec\n",
      "time forward 0.000853 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001175 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 366 cost 0.006506919860839844 sec\n",
      "loss 1.462503, train acc 0.461023\n",
      "round 367\n",
      "time to device 0.003998 sec\n",
      "time forward 0.000825 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001167 sec\n",
      "optimizer time 0.000211 sec\n",
      "training time in batch 367 cost 0.006475925445556641 sec\n",
      "loss 1.460911, train acc 0.461596\n",
      "round 368\n",
      "time to device 0.004029 sec\n",
      "time forward 0.000838 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001592 sec\n",
      "optimizer time 0.000232 sec\n",
      "training time in batch 368 cost 0.006963491439819336 sec\n",
      "loss 1.459400, train acc 0.462123\n",
      "round 369\n",
      "time to device 0.004003 sec\n",
      "time forward 0.000837 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001742 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 369 cost 0.007053375244140625 sec\n",
      "loss 1.457846, train acc 0.462648\n",
      "round 370\n",
      "time to device 0.004003 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001051 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 370 cost 0.006343841552734375 sec\n",
      "loss 1.455912, train acc 0.463317\n",
      "round 371\n",
      "time to device 0.003984 sec\n",
      "time forward 0.000877 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001188 sec\n",
      "optimizer time 0.000198 sec\n",
      "training time in batch 371 cost 0.00652003288269043 sec\n",
      "loss 1.454146, train acc 0.463899\n",
      "round 372\n",
      "time to device 0.004006 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001578 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 372 cost 0.006891727447509766 sec\n",
      "loss 1.451938, train acc 0.464749\n",
      "round 373\n",
      "time to device 0.004041 sec\n",
      "time forward 0.000871 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001137 sec\n",
      "optimizer time 0.000214 sec\n",
      "training time in batch 373 cost 0.006536722183227539 sec\n",
      "loss 1.450198, train acc 0.465345\n",
      "round 374\n",
      "time to device 0.003996 sec\n",
      "time forward 0.000846 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001127 sec\n",
      "optimizer time 0.000209 sec\n",
      "training time in batch 374 cost 0.0064656734466552734 sec\n",
      "loss 1.448638, train acc 0.465958\n",
      "round 375\n",
      "time to device 0.004014 sec\n",
      "time forward 0.000870 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001187 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 375 cost 0.006541728973388672 sec\n",
      "loss 1.447040, train acc 0.466631\n",
      "round 376\n",
      "time to device 0.003995 sec\n",
      "time forward 0.000895 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001281 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 376 cost 0.006635427474975586 sec\n",
      "loss 1.445386, train acc 0.467279\n",
      "round 377\n",
      "time to device 0.003996 sec\n",
      "time forward 0.000837 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001214 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 377 cost 0.006522178649902344 sec\n",
      "loss 1.443679, train acc 0.467861\n",
      "round 378\n",
      "time to device 0.004007 sec\n",
      "time forward 0.000832 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001852 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 378 cost 0.007153511047363281 sec\n",
      "loss 1.442199, train acc 0.468317\n",
      "round 379\n",
      "time to device 0.003985 sec\n",
      "time forward 0.000821 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001684 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 379 cost 0.006946563720703125 sec\n",
      "loss 1.440834, train acc 0.468791\n",
      "round 380\n",
      "time to device 0.004009 sec\n",
      "time forward 0.000839 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001233 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 380 cost 0.006543159484863281 sec\n",
      "loss 1.439520, train acc 0.469283\n",
      "round 381\n",
      "time to device 0.003972 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001198 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 381 cost 0.006489276885986328 sec\n",
      "loss 1.438586, train acc 0.469589\n",
      "round 382\n",
      "time to device 0.003993 sec\n",
      "time forward 0.000830 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001148 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 382 cost 0.006444454193115234 sec\n",
      "loss 1.436813, train acc 0.470157\n",
      "round 383\n",
      "time to device 0.004014 sec\n",
      "time forward 0.000841 sec\n",
      "loss time 0.000086 sec\n",
      "backward time 0.001146 sec\n",
      "optimizer time 0.000205 sec\n",
      "training time in batch 383 cost 0.006490468978881836 sec\n",
      "loss 1.435516, train acc 0.470520\n",
      "round 384\n",
      "time to device 0.004021 sec\n",
      "time forward 0.000836 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001583 sec\n",
      "optimizer time 0.000226 sec\n",
      "training time in batch 384 cost 0.006937742233276367 sec\n",
      "loss 1.434385, train acc 0.470921\n",
      "round 385\n",
      "time to device 0.004036 sec\n",
      "time forward 0.000836 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001733 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 385 cost 0.007079124450683594 sec\n",
      "loss 1.432505, train acc 0.471665\n",
      "round 386\n",
      "time to device 0.003966 sec\n",
      "time forward 0.000862 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001140 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 386 cost 0.006454944610595703 sec\n",
      "loss 1.430904, train acc 0.472222\n",
      "round 387\n",
      "time to device 0.004021 sec\n",
      "time forward 0.000892 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001145 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 387 cost 0.006523609161376953 sec\n",
      "loss 1.429282, train acc 0.472777\n",
      "round 388\n",
      "time to device 0.004018 sec\n",
      "time forward 0.000819 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001795 sec\n",
      "optimizer time 0.000188 sec\n",
      "training time in batch 388 cost 0.00710749626159668 sec\n",
      "loss 1.427632, train acc 0.473429\n",
      "round 389\n",
      "time to device 0.003995 sec\n",
      "time forward 0.000923 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001229 sec\n",
      "optimizer time 0.000214 sec\n",
      "training time in batch 389 cost 0.0066297054290771484 sec\n",
      "loss 1.426421, train acc 0.473818\n",
      "round 390\n",
      "time to device 0.004019 sec\n",
      "time forward 0.000883 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001179 sec\n",
      "optimizer time 0.000190 sec\n",
      "training time in batch 390 cost 0.0065500736236572266 sec\n",
      "loss 1.424905, train acc 0.474465\n",
      "round 391\n",
      "time to device 0.003973 sec\n",
      "time forward 0.000850 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001199 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 391 cost 0.006494045257568359 sec\n",
      "loss 1.423312, train acc 0.475088\n",
      "round 392\n",
      "time to device 0.004002 sec\n",
      "time forward 0.000826 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001615 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 392 cost 0.0069043636322021484 sec\n",
      "loss 1.421580, train acc 0.475767\n",
      "round 393\n",
      "time to device 0.003996 sec\n",
      "time forward 0.000834 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001561 sec\n",
      "optimizer time 0.000230 sec\n",
      "training time in batch 393 cost 0.006899595260620117 sec\n",
      "loss 1.420349, train acc 0.476225\n",
      "round 394\n",
      "time to device 0.004009 sec\n",
      "time forward 0.000828 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001595 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 394 cost 0.006896257400512695 sec\n",
      "loss 1.418922, train acc 0.476701\n",
      "round 395\n",
      "time to device 0.004002 sec\n",
      "time forward 0.000847 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001202 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 395 cost 0.0065174102783203125 sec\n",
      "loss 1.417268, train acc 0.477115\n",
      "round 396\n",
      "time to device 0.004036 sec\n",
      "time forward 0.000838 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001195 sec\n",
      "optimizer time 0.000198 sec\n",
      "training time in batch 396 cost 0.006550788879394531 sec\n",
      "loss 1.415755, train acc 0.477763\n",
      "round 397\n",
      "time to device 0.003975 sec\n",
      "time forward 0.000869 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001152 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 397 cost 0.006471872329711914 sec\n",
      "loss 1.413928, train acc 0.478447\n",
      "round 398\n",
      "time to device 0.003995 sec\n",
      "time forward 0.000829 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001578 sec\n",
      "optimizer time 0.000242 sec\n",
      "training time in batch 398 cost 0.0069086551666259766 sec\n",
      "loss 1.412566, train acc 0.478893\n",
      "round 399\n",
      "time to device 0.004051 sec\n",
      "time forward 0.000827 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001219 sec\n",
      "optimizer time 0.000231 sec\n",
      "training time in batch 399 cost 0.006594657897949219 sec\n",
      "loss 1.411180, train acc 0.479355\n",
      "round 400\n",
      "time to device 0.004000 sec\n",
      "time forward 0.000826 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001719 sec\n",
      "optimizer time 0.000212 sec\n",
      "training time in batch 400 cost 0.007075309753417969 sec\n",
      "loss 1.409487, train acc 0.479933\n",
      "round 401\n",
      "time to device 0.004019 sec\n",
      "time forward 0.000849 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001184 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 401 cost 0.006521940231323242 sec\n",
      "loss 1.407657, train acc 0.480663\n",
      "round 402\n",
      "time to device 0.003985 sec\n",
      "time forward 0.000840 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001175 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 402 cost 0.00647735595703125 sec\n",
      "loss 1.405623, train acc 0.481370\n",
      "round 403\n",
      "time to device 0.004025 sec\n",
      "time forward 0.000866 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001149 sec\n",
      "optimizer time 0.000218 sec\n",
      "training time in batch 403 cost 0.0065310001373291016 sec\n",
      "loss 1.404183, train acc 0.481900\n",
      "round 404\n",
      "time to device 0.004018 sec\n",
      "time forward 0.000851 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001122 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 404 cost 0.006468772888183594 sec\n",
      "loss 1.402608, train acc 0.482350\n",
      "round 405\n",
      "time to device 0.004005 sec\n",
      "time forward 0.000843 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001121 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 405 cost 0.006430625915527344 sec\n",
      "loss 1.401109, train acc 0.482951\n",
      "round 406\n",
      "time to device 0.004011 sec\n",
      "time forward 0.000862 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001186 sec\n",
      "optimizer time 0.000190 sec\n",
      "training time in batch 406 cost 0.006516456604003906 sec\n",
      "loss 1.399605, train acc 0.483454\n",
      "round 407\n",
      "time to device 0.004004 sec\n",
      "time forward 0.000894 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001140 sec\n",
      "optimizer time 0.000205 sec\n",
      "training time in batch 407 cost 0.006505250930786133 sec\n",
      "loss 1.397849, train acc 0.484030\n",
      "round 408\n",
      "time to device 0.004169 sec\n",
      "time forward 0.000938 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001201 sec\n",
      "optimizer time 0.000221 sec\n",
      "training time in batch 408 cost 0.006855487823486328 sec\n",
      "loss 1.396487, train acc 0.484642\n",
      "round 409\n",
      "time to device 0.004022 sec\n",
      "time forward 0.000827 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001603 sec\n",
      "optimizer time 0.000213 sec\n",
      "training time in batch 409 cost 0.006953239440917969 sec\n",
      "loss 1.395006, train acc 0.485061\n",
      "round 410\n",
      "time to device 0.004031 sec\n",
      "time forward 0.000871 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001166 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 410 cost 0.006540060043334961 sec\n",
      "loss 1.393255, train acc 0.485706\n",
      "round 411\n",
      "time to device 0.004012 sec\n",
      "time forward 0.000836 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001134 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 411 cost 0.006441831588745117 sec\n",
      "loss 1.391798, train acc 0.486252\n",
      "round 412\n",
      "time to device 0.003988 sec\n",
      "time forward 0.000851 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001264 sec\n",
      "optimizer time 0.000226 sec\n",
      "training time in batch 412 cost 0.006608724594116211 sec\n",
      "loss 1.390347, train acc 0.486777\n",
      "round 413\n",
      "time to device 0.004032 sec\n",
      "time forward 0.000860 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001260 sec\n",
      "optimizer time 0.000207 sec\n",
      "training time in batch 413 cost 0.0066280364990234375 sec\n",
      "loss 1.388917, train acc 0.487262\n",
      "round 414\n",
      "time to device 0.004028 sec\n",
      "time forward 0.000845 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001085 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 414 cost 0.00642704963684082 sec\n",
      "loss 1.387458, train acc 0.487669\n",
      "round 415\n",
      "time to device 0.004027 sec\n",
      "time forward 0.000819 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001618 sec\n",
      "optimizer time 0.000209 sec\n",
      "training time in batch 415 cost 0.0069501399993896484 sec\n",
      "loss 1.386302, train acc 0.488093\n",
      "round 416\n",
      "time to device 0.003990 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001766 sec\n",
      "optimizer time 0.000205 sec\n",
      "training time in batch 416 cost 0.007062435150146484 sec\n",
      "loss 1.384965, train acc 0.488515\n",
      "round 417\n",
      "time to device 0.003989 sec\n",
      "time forward 0.000826 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001901 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 417 cost 0.007174491882324219 sec\n",
      "loss 1.383806, train acc 0.488954\n",
      "round 418\n",
      "time to device 0.004009 sec\n",
      "time forward 0.000854 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001204 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 418 cost 0.006534099578857422 sec\n",
      "loss 1.382136, train acc 0.489484\n",
      "round 419\n",
      "time to device 0.004051 sec\n",
      "time forward 0.000851 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001045 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 419 cost 0.006405830383300781 sec\n",
      "loss 1.380896, train acc 0.489825\n",
      "round 420\n",
      "time to device 0.004047 sec\n",
      "time forward 0.000844 sec\n",
      "loss time 0.000084 sec\n",
      "backward time 0.001124 sec\n",
      "optimizer time 0.000199 sec\n",
      "training time in batch 420 cost 0.0065152645111083984 sec\n",
      "loss 1.379384, train acc 0.490350\n",
      "round 421\n",
      "time to device 0.004003 sec\n",
      "time forward 0.000822 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001600 sec\n",
      "optimizer time 0.000198 sec\n",
      "training time in batch 421 cost 0.00690150260925293 sec\n",
      "loss 1.378192, train acc 0.490855\n",
      "round 422\n",
      "time to device 0.003993 sec\n",
      "time forward 0.000834 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001576 sec\n",
      "optimizer time 0.000215 sec\n",
      "training time in batch 422 cost 0.006897926330566406 sec\n",
      "loss 1.376740, train acc 0.491430\n",
      "round 423\n",
      "time to device 0.004031 sec\n",
      "time forward 0.000839 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001801 sec\n",
      "optimizer time 0.000220 sec\n",
      "training time in batch 423 cost 0.007169961929321289 sec\n",
      "loss 1.375260, train acc 0.491966\n",
      "round 424\n",
      "time to device 0.004033 sec\n",
      "time forward 0.000844 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001226 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 424 cost 0.006564617156982422 sec\n",
      "loss 1.374307, train acc 0.492390\n",
      "round 425\n",
      "time to device 0.004045 sec\n",
      "time forward 0.000902 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001178 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 425 cost 0.006608009338378906 sec\n",
      "loss 1.373201, train acc 0.492884\n",
      "round 426\n",
      "time to device 0.004040 sec\n",
      "time forward 0.000833 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001138 sec\n",
      "optimizer time 0.000193 sec\n",
      "training time in batch 426 cost 0.006476402282714844 sec\n",
      "loss 1.371829, train acc 0.493340\n",
      "round 427\n",
      "time to device 0.004048 sec\n",
      "time forward 0.000863 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001140 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 427 cost 0.0065059661865234375 sec\n",
      "loss 1.370452, train acc 0.493830\n",
      "round 428\n",
      "time to device 0.004022 sec\n",
      "time forward 0.000889 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001181 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 428 cost 0.006550788879394531 sec\n",
      "loss 1.369345, train acc 0.494172\n",
      "round 429\n",
      "time to device 0.003980 sec\n",
      "time forward 0.000859 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001172 sec\n",
      "optimizer time 0.000200 sec\n",
      "training time in batch 429 cost 0.006484270095825195 sec\n",
      "loss 1.368098, train acc 0.494531\n",
      "round 430\n",
      "time to device 0.004030 sec\n",
      "time forward 0.000814 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001559 sec\n",
      "optimizer time 0.000200 sec\n",
      "training time in batch 430 cost 0.006857633590698242 sec\n",
      "loss 1.366626, train acc 0.495106\n",
      "round 431\n",
      "time to device 0.004007 sec\n",
      "time forward 0.000887 sec\n",
      "loss time 0.000085 sec\n",
      "backward time 0.001165 sec\n",
      "optimizer time 0.000209 sec\n",
      "training time in batch 431 cost 0.006552219390869141 sec\n",
      "loss 1.365949, train acc 0.495461\n",
      "round 432\n",
      "time to device 0.004028 sec\n",
      "time forward 0.000836 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001208 sec\n",
      "optimizer time 0.000199 sec\n",
      "training time in batch 432 cost 0.006533145904541016 sec\n",
      "loss 1.364446, train acc 0.496067\n",
      "round 433\n",
      "time to device 0.004033 sec\n",
      "time forward 0.000831 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001710 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 433 cost 0.0070531368255615234 sec\n",
      "loss 1.363104, train acc 0.496508\n",
      "round 434\n",
      "time to device 0.003976 sec\n",
      "time forward 0.000853 sec\n",
      "loss time 0.000085 sec\n",
      "backward time 0.001158 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 434 cost 0.006475925445556641 sec\n",
      "loss 1.361581, train acc 0.497073\n",
      "round 435\n",
      "time to device 0.004008 sec\n",
      "time forward 0.000829 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001762 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 435 cost 0.007089376449584961 sec\n",
      "loss 1.359966, train acc 0.497706\n",
      "round 436\n",
      "time to device 0.004031 sec\n",
      "time forward 0.000818 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001755 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 436 cost 0.007074832916259766 sec\n",
      "loss 1.358673, train acc 0.498105\n",
      "round 437\n",
      "time to device 0.004105 sec\n",
      "time forward 0.000841 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001163 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 437 cost 0.006585597991943359 sec\n",
      "loss 1.357137, train acc 0.498716\n",
      "round 438\n",
      "time to device 0.004008 sec\n",
      "time forward 0.000825 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001618 sec\n",
      "optimizer time 0.000206 sec\n",
      "training time in batch 438 cost 0.00691676139831543 sec\n",
      "loss 1.356240, train acc 0.499092\n",
      "round 439\n",
      "time to device 0.003998 sec\n",
      "time forward 0.000859 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001181 sec\n",
      "optimizer time 0.000188 sec\n",
      "training time in batch 439 cost 0.006506681442260742 sec\n",
      "loss 1.354813, train acc 0.499680\n",
      "round 440\n",
      "time to device 0.003973 sec\n",
      "time forward 0.000870 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001196 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 440 cost 0.006501913070678711 sec\n",
      "loss 1.353297, train acc 0.500266\n",
      "round 441\n",
      "time to device 0.004003 sec\n",
      "time forward 0.000839 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001833 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 441 cost 0.007169961929321289 sec\n",
      "loss 1.352023, train acc 0.500725\n",
      "round 442\n",
      "time to device 0.003991 sec\n",
      "time forward 0.000837 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001790 sec\n",
      "optimizer time 0.000204 sec\n",
      "training time in batch 442 cost 0.00710606575012207 sec\n",
      "loss 1.350684, train acc 0.501146\n",
      "round 443\n",
      "time to device 0.003997 sec\n",
      "time forward 0.000849 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001145 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 443 cost 0.0064585208892822266 sec\n",
      "loss 1.349543, train acc 0.501548\n",
      "round 444\n",
      "time to device 0.004005 sec\n",
      "time forward 0.000861 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001195 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 444 cost 0.006557941436767578 sec\n",
      "loss 1.348361, train acc 0.502019\n",
      "round 445\n",
      "time to device 0.004017 sec\n",
      "time forward 0.000935 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001179 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 445 cost 0.0066089630126953125 sec\n",
      "loss 1.347292, train acc 0.502382\n",
      "round 446\n",
      "time to device 0.004040 sec\n",
      "time forward 0.000841 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001195 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 446 cost 0.006560802459716797 sec\n",
      "loss 1.345665, train acc 0.502936\n",
      "round 447\n",
      "time to device 0.004000 sec\n",
      "time forward 0.000828 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001801 sec\n",
      "optimizer time 0.000211 sec\n",
      "training time in batch 447 cost 0.007112026214599609 sec\n",
      "loss 1.344437, train acc 0.503401\n",
      "round 448\n",
      "time to device 0.004015 sec\n",
      "time forward 0.000839 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001141 sec\n",
      "optimizer time 0.000196 sec\n",
      "training time in batch 448 cost 0.006455421447753906 sec\n",
      "loss 1.343264, train acc 0.503724\n",
      "round 449\n",
      "time to device 0.004038 sec\n",
      "time forward 0.000848 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001168 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 449 cost 0.006523609161376953 sec\n",
      "loss 1.341784, train acc 0.504132\n",
      "round 450\n",
      "time to device 0.004039 sec\n",
      "time forward 0.000903 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001120 sec\n",
      "optimizer time 0.000199 sec\n",
      "training time in batch 450 cost 0.006541252136230469 sec\n",
      "loss 1.340443, train acc 0.504642\n",
      "round 451\n",
      "time to device 0.004030 sec\n",
      "time forward 0.000937 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001103 sec\n",
      "optimizer time 0.000195 sec\n",
      "training time in batch 451 cost 0.006539583206176758 sec\n",
      "loss 1.339224, train acc 0.505133\n",
      "round 452\n",
      "time to device 0.004014 sec\n",
      "time forward 0.000852 sec\n",
      "loss time 0.000089 sec\n",
      "backward time 0.001183 sec\n",
      "optimizer time 0.000191 sec\n",
      "training time in batch 452 cost 0.0065233707427978516 sec\n",
      "loss 1.338044, train acc 0.505622\n",
      "round 453\n",
      "time to device 0.004011 sec\n",
      "time forward 0.000851 sec\n",
      "loss time 0.000077 sec\n",
      "backward time 0.001197 sec\n",
      "optimizer time 0.000202 sec\n",
      "training time in batch 453 cost 0.006528377532958984 sec\n",
      "loss 1.336744, train acc 0.506109\n",
      "round 454\n",
      "time to device 0.004026 sec\n",
      "time forward 0.000831 sec\n",
      "loss time 0.000075 sec\n",
      "backward time 0.001213 sec\n",
      "optimizer time 0.000189 sec\n",
      "training time in batch 454 cost 0.006552934646606445 sec\n",
      "loss 1.335436, train acc 0.506542\n",
      "round 455\n",
      "time to device 0.004010 sec\n",
      "time forward 0.000864 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001194 sec\n",
      "optimizer time 0.000228 sec\n",
      "training time in batch 455 cost 0.006580829620361328 sec\n",
      "loss 1.334091, train acc 0.507024\n",
      "round 456\n",
      "time to device 0.004024 sec\n",
      "time forward 0.000853 sec\n",
      "loss time 0.000093 sec\n",
      "backward time 0.001225 sec\n",
      "optimizer time 0.000219 sec\n",
      "training time in batch 456 cost 0.006604671478271484 sec\n",
      "loss 1.332712, train acc 0.507505\n",
      "round 457\n",
      "time to device 0.003984 sec\n",
      "time forward 0.000869 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001190 sec\n",
      "optimizer time 0.000236 sec\n",
      "training time in batch 457 cost 0.006542205810546875 sec\n",
      "loss 1.331486, train acc 0.507898\n",
      "round 458\n",
      "time to device 0.003988 sec\n",
      "time forward 0.000835 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001129 sec\n",
      "optimizer time 0.000213 sec\n",
      "training time in batch 458 cost 0.006435871124267578 sec\n",
      "loss 1.330084, train acc 0.508493\n",
      "round 459\n",
      "time to device 0.004071 sec\n",
      "time forward 0.000834 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001635 sec\n",
      "optimizer time 0.000197 sec\n",
      "training time in batch 459 cost 0.007021665573120117 sec\n",
      "loss 1.328820, train acc 0.508882\n",
      "round 460\n",
      "time to device 0.004005 sec\n",
      "time forward 0.000843 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001604 sec\n",
      "optimizer time 0.000199 sec\n",
      "training time in batch 460 cost 0.006928443908691406 sec\n",
      "loss 1.327928, train acc 0.509100\n",
      "round 461\n",
      "time to device 0.003976 sec\n",
      "time forward 0.000885 sec\n",
      "loss time 0.000076 sec\n",
      "backward time 0.001188 sec\n",
      "optimizer time 0.000194 sec\n",
      "training time in batch 461 cost 0.0065004825592041016 sec\n",
      "loss 1.326892, train acc 0.509402\n",
      "round 462\n",
      "time to device 0.003946 sec\n",
      "time forward 0.000862 sec\n",
      "loss time 0.000081 sec\n",
      "backward time 0.001568 sec\n",
      "optimizer time 0.000213 sec\n",
      "training time in batch 462 cost 0.006846189498901367 sec\n",
      "loss 1.325772, train acc 0.509837\n",
      "round 463\n",
      "time to device 0.003948 sec\n",
      "time forward 0.000826 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001125 sec\n",
      "optimizer time 0.000185 sec\n",
      "training time in batch 463 cost 0.00634002685546875 sec\n",
      "loss 1.324746, train acc 0.510288\n",
      "round 464\n",
      "time to device 0.003978 sec\n",
      "time forward 0.000824 sec\n",
      "loss time 0.000072 sec\n",
      "backward time 0.001151 sec\n",
      "optimizer time 0.000184 sec\n",
      "training time in batch 464 cost 0.006357669830322266 sec\n",
      "loss 1.323362, train acc 0.510769\n",
      "round 465\n",
      "time to device 0.003956 sec\n",
      "time forward 0.000882 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001029 sec\n",
      "optimizer time 0.000185 sec\n",
      "training time in batch 465 cost 0.0062847137451171875 sec\n",
      "loss 1.322036, train acc 0.511233\n",
      "round 466\n",
      "time to device 0.003935 sec\n",
      "time forward 0.000819 sec\n",
      "loss time 0.000073 sec\n",
      "backward time 0.001211 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 466 cost 0.006394147872924805 sec\n",
      "loss 1.320839, train acc 0.511677\n",
      "round 467\n",
      "time to device 0.003946 sec\n",
      "time forward 0.000842 sec\n",
      "loss time 0.000074 sec\n",
      "backward time 0.001213 sec\n",
      "optimizer time 0.000192 sec\n",
      "training time in batch 467 cost 0.0064318180084228516 sec\n",
      "loss 1.319641, train acc 0.512203\n",
      "round 468\n",
      "time to device 0.003064 sec\n",
      "time forward 0.010723 sec\n",
      "loss time 0.000081 sec\n",
      "backward time 0.012917 sec\n",
      "optimizer time 0.000281 sec\n",
      "training time in batch 468 cost 0.027287721633911133 sec\n",
      "loss 1.318729, train acc 0.512600\n",
      "test acc is 0.747700\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 1\n",
    "device = d2l.try_gpu()\n",
    "Time_Layers, Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, Timport= train_layers(alexnet, train_iter, test_iter, num_epochs, lr, device)\n",
    "# Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, Timport= train_func(alexnet, train_iter, test_iter, num_epochs, lr, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2203111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time_AllEpochs: \n",
      " Time to Device time:  [1.88681507] \n",
      " Forward time:  [0.57212591] \n",
      " Calculate Loss time:  [0.05389261] \n",
      " Backward time:  [0.74353361] \n",
      " Optimize time:  [0.10294962] \n",
      " Test time:  [2.78524184]\n",
      "**************************************************\n",
      "Train Time of each epoch: [3.4555859565734863]\n",
      "**************************************************\n",
      "Import data to ndarray time: [0]\n",
      "**************************************************\n",
      "TestAcc: [0.7477]\n",
      "**************************************************\n",
      "TrainLoss: [[2.297447681427002, 2.299442410469055, 2.3009370962778726, 2.30232834815979, 2.302603816986084, 2.3029493490854898, 2.302363395690918, 2.302022308111191, 2.3014929029676647, 2.301532769203186, 2.301142454147339, 2.3009710709253945, 2.3006096803225002, 2.3002463238579884, 2.3000536918640138, 2.299908086657524, 2.29983291906469, 2.299415535397, 2.2994698599765173, 2.299320328235626, 2.299118405296689, 2.2990413145585493, 2.298825678618058, 2.2986112336317697, 2.2985249614715575, 2.2985376578110914, 2.2982232217435485, 2.2982179692813327, 2.2981363740460625, 2.2980229457219443, 2.2979247339310183, 2.297750413417816, 2.297428340622873, 2.297291594393113, 2.2973750250680105, 2.2970986564954123, 2.297043001329577, 2.2968550167585673, 2.296730432754908, 2.29636127948761, 2.2960396685251374, 2.2958774339585077, 2.295670376267544, 2.295585122975436, 2.2954881032307943, 2.2954036826672763, 2.2952289479844112, 2.2949672092994056, 2.294673423377835, 2.2944819498062134, 2.2942255151038076, 2.294004133114448, 2.2937998681698204, 2.2935441732406616, 2.2932016025890003, 2.2929644073758806, 2.29266797868829, 2.29239350351794, 2.292206885450977, 2.2920540452003477, 2.2918582197095527, 2.2916046304087483, 2.2913674740564254, 2.2911446392536163, 2.2909262657165526, 2.2907038349093813, 2.2904288982277485, 2.2901088700574985, 2.289842660876288, 2.2894947256360734, 2.289130627269476, 2.288915640778012, 2.288542087763956, 2.288391081062523, 2.2882193311055503, 2.287770606969532, 2.287297555378505, 2.286923763079521, 2.286566034148011, 2.2861723780632017, 2.2858475814630954, 2.285381433440418, 2.285023086042289, 2.2845633654367354, 2.284108793034273, 2.2834502735803293, 2.2831247894243263, 2.282589151100679, 2.282057218337327, 2.281558052698771, 2.280922103714157, 2.28043669462204, 2.2798658673481276, 2.279181277498286, 2.2783943126076145, 2.277657262980938, 2.276776714423268, 2.2760534627096995, 2.2752172152201333, 2.2742874312400816, 2.2732632514273767, 2.2723784306470085, 2.2714312377485255, 2.2704703624431906, 2.2693086760384698, 2.268431121448301, 2.2673787558190175, 2.265977645361865, 2.2642900725023463, 2.262997289137407, 2.261624529555037, 2.2593644836119244, 2.256854048872416, 2.2552079736140738, 2.2528037745019662, 2.2505201923436133, 2.248530893244295, 2.2457549652810824, 2.2430717804852653, 2.240408472220103, 2.2375671242879442, 2.2343499035131735, 2.2310267551158502, 2.227730592412333, 2.2243459005355835, 2.2211848109487504, 2.217498890058262, 2.213161451742053, 2.2086430898932523, 2.2048023361426132, 2.200442297768047, 2.195607180848266, 2.191521367632357, 2.186467633318545, 2.1819329535519634, 2.17787405147272, 2.1733162516224995, 2.1683124951694324, 2.163106282837957, 2.1579466462135315, 2.1543841116817286, 2.1509025869235185, 2.14806941922728, 2.144071433279249, 2.1402283594526095, 2.135101407358091, 2.1294455641791936, 2.1248710985119277, 2.1196382477779516, 2.1149352685610454, 2.110128484024907, 2.1043657323247507, 2.0994849189434177, 2.0945722174334835, 2.0900694485633604, 2.0853178065556746, 2.0804890789044133, 2.076307307315778, 2.0725685125626856, 2.068478301167488, 2.063762450810545, 2.059313223685747, 2.0537398000436324, 2.0491334846833857, 2.044839893687855, 2.0400059675595847, 2.0357432579565904, 2.030630262834685, 2.026582257282099, 2.021448596084819, 2.0166008834950406, 2.011873191179231, 2.0073017371183184, 2.002441459003536, 1.9981844179970878, 1.993357466025786, 1.9879426249003007, 1.9834410621878806, 1.9788705383599137, 1.9743679443995157, 1.970835818770182, 1.9674876030984816, 1.9642069613347288, 1.9602909943331843, 1.955632751052444, 1.9514164898985176, 1.9471744866294658, 1.9427125764654039, 1.9380430443577035, 1.9334519944692914, 1.9296647915665393, 1.9259721556057532, 1.9218738264370459, 1.9179607617486383, 1.9146790308830066, 1.9105036465489134, 1.9065590733804074, 1.9021775885061785, 1.8983593819728448, 1.8946907705068587, 1.8912949888267327, 1.8886892718843895, 1.8847823465986204, 1.8803812236178155, 1.876379568983869, 1.8718438813987288, 1.8675905754024855, 1.8638006460208159, 1.859710128683793, 1.856630489939735, 1.8525969027342954, 1.84892886033598, 1.8459808809656493, 1.8424103427156109, 1.8391459814337796, 1.8363491048415501, 1.8323846788999671, 1.8295716974166556, 1.8257731980384757, 1.8229492780837147, 1.8194570846147666, 1.815805764080168, 1.8125202428599645, 1.808500655793718, 1.8057349997096592, 1.8026153912058973, 1.7992647726105173, 1.7959772758839423, 1.7927934438901176, 1.7894690754620926, 1.7862659076075533, 1.7822619453072548, 1.779008787333198, 1.7758726704324412, 1.773183537797725, 1.7702499953872066, 1.7671400049567725, 1.7641960214666959, 1.760491989147713, 1.7566948376595974, 1.7543579639240914, 1.751712221990932, 1.7488174288851734, 1.7455566486374277, 1.7424539471159175, 1.7394961140504697, 1.7361875934156812, 1.7334073207551433, 1.7311866065584511, 1.7289522740840912, 1.725628466007719, 1.7225218838642513, 1.7190560229682168, 1.7160557679773316, 1.7125208422249438, 1.709905825322494, 1.7071906177450247, 1.7039719838504643, 1.7008570764055584, 1.6976597015674297, 1.6943027747088466, 1.691433387858267, 1.6888910876480798, 1.686926057844451, 1.6844202711897076, 1.6817003750711454, 1.6789293146312014, 1.6761837990871116, 1.6733046169617805, 1.6703085320967215, 1.6680543559063845, 1.6658661681063034, 1.6630450022089613, 1.6603025291522924, 1.657983768419786, 1.6553665637106136, 1.6529542517575977, 1.6498637394510585, 1.647187572226302, 1.6442097502095359, 1.6413854046648508, 1.6382859858638006, 1.6355522026442808, 1.6326069384813309, 1.630176317691803, 1.6283971385939138, 1.6265646952369903, 1.624548193274273, 1.6220857212287745, 1.6194193548169629, 1.6168617851955374, 1.6142406839213959, 1.6113176311242297, 1.6089577557278327, 1.6067373021174285, 1.6042783373111003, 1.6019056485558198, 1.5995789934324738, 1.5969659201676232, 1.594358304341634, 1.5920778752561424, 1.5901790350083485, 1.587824004908206, 1.5853571985897266, 1.5831562945100128, 1.5811321182188645, 1.5785819018314249, 1.5760204331441359, 1.5737228206446257, 1.571216493268167, 1.5690845987037831, 1.5673585048852823, 1.56499816491581, 1.562376563526263, 1.5601067138096643, 1.5577067532871343, 1.555301706873656, 1.553776593703144, 1.5520412043717962, 1.5503123888745904, 1.5482957342703394, 1.5458769776065897, 1.5433350314296805, 1.541585307430338, 1.5398231207407438, 1.5381950566008047, 1.536337179692878, 1.5341089151617957, 1.5318493344863497, 1.5295028307221152, 1.527436249565862, 1.525209745908358, 1.5230297499948793, 1.5212824842530097, 1.519689645518118, 1.5182933841078055, 1.51638978861206, 1.5143903922399826, 1.5123359807121366, 1.510264435936423, 1.508389209722144, 1.5065835381460468, 1.5043289134870812, 1.5030227918611017, 1.5011895373247672, 1.499188247099088, 1.4972484673478075, 1.4955564220061248, 1.4936047982008205, 1.4917564172404154, 1.489701623081142, 1.4880122344263575, 1.4867389305117449, 1.4849522841178764, 1.483327117100568, 1.4815923695483904, 1.4798049811555558, 1.4777768161043774, 1.4760470888408779, 1.4741539037889904, 1.4723407089545126, 1.4708200635501694, 1.46934474975938, 1.4674959277713693, 1.4661700970506015, 1.464350252529311, 1.4625025081374665, 1.460911428960769, 1.4594001327426775, 1.457846397966952, 1.4559119992821685, 1.4541463271905017, 1.4519377246938505, 1.4501979797281683, 1.4486377952893574, 1.4470396270143224, 1.445386263040396, 1.4436788174210402, 1.4421991993695262, 1.4408343468841753, 1.4395198696867375, 1.4385862550186237, 1.4368131176298655, 1.4355159892390172, 1.434384941125845, 1.4325047033438412, 1.4309037688166597, 1.4292820367923718, 1.4276320984860007, 1.4264213682749332, 1.4249049414454213, 1.4233116434544932, 1.421579732391367, 1.4203487521198195, 1.4189218183107013, 1.417268450964581, 1.41575490932921, 1.4139275112044272, 1.4125656645399587, 1.4111798897385597, 1.4094866988367571, 1.4076574303914065, 1.4056227214578956, 1.4041830074078967, 1.402608295870416, 1.4011089643234103, 1.399605110617176, 1.397848603041733, 1.3964871694231382, 1.395005525030741, 1.393254723572093, 1.3917978339403578, 1.3903469118598586, 1.3889172051263892, 1.3874576901815023, 1.386301536972706, 1.384965298844756, 1.383806142082625, 1.3821363379391964, 1.3808963310150872, 1.3793837062819836, 1.3781922098019677, 1.376740311336292, 1.3752599368399043, 1.3743069647340214, 1.3732009699367023, 1.3718292978385014, 1.370451887634313, 1.369344826483782, 1.3680984394494877, 1.3666261054246995, 1.3659494465423956, 1.3644461039858107, 1.3631039248084142, 1.3615810703957218, 1.3599656211947082, 1.3586725162968756, 1.3571366177846307, 1.3562404203795084, 1.3548126709732142, 1.3532968886585193, 1.3520230030581961, 1.3506836654370311, 1.3495433372151744, 1.3483610666200017, 1.3472923926441125, 1.3456652356474192, 1.344437194056809, 1.3432641191312624, 1.341784062915378, 1.3404426683079114, 1.3392237039793908, 1.3380436601228272, 1.3367443124103127, 1.335436211837517, 1.3340906886416568, 1.3327120800769563, 1.3314855787171027, 1.3300840700114216, 1.3288203900275024, 1.3279278505908694, 1.326891545480464, 1.3257724274569402, 1.324746175958165, 1.3233617300628333, 1.3220360325129759, 1.3208386729565116, 1.3196408567775009, 1.3187289115905763]]\n",
      "**************************************************\n",
      "TrainAcc: [[0.1328125, 0.10546875, 0.09895833333333333, 0.091796875, 0.0921875, 0.09635416666666667, 0.09598214285714286, 0.0947265625, 0.10416666666666667, 0.103125, 0.10298295454545454, 0.107421875, 0.10997596153846154, 0.11216517857142858, 0.1125, 0.111328125, 0.11213235294117647, 0.11458333333333333, 0.11430921052631579, 0.1171875, 0.12165178571428571, 0.12286931818181818, 0.12432065217391304, 0.12565104166666666, 0.128125, 0.12800480769230768, 0.12991898148148148, 0.12946428571428573, 0.12957974137931033, 0.1296875, 0.12953629032258066, 0.129638671875, 0.1309185606060606, 0.13097426470588236, 0.13058035714285715, 0.13194444444444445, 0.13154560810810811, 0.13157894736842105, 0.1330128205128205, 0.1337890625, 0.13567073170731708, 0.1363467261904762, 0.13753633720930233, 0.13920454545454544, 0.14097222222222222, 0.14113451086956522, 0.14178856382978725, 0.14306640625, 0.1449298469387755, 0.14609375, 0.14690563725490197, 0.14798677884615385, 0.14858490566037735, 0.15002893518518517, 0.1509943181818182, 0.15108816964285715, 0.15186403508771928, 0.15261314655172414, 0.1530720338983051, 0.15325520833333334, 0.15343237704918034, 0.1541078629032258, 0.15476190476190477, 0.1552734375, 0.15564903846153846, 0.15601325757575757, 0.15613339552238806, 0.1557904411764706, 0.1564764492753623, 0.15714285714285714, 0.1582306338028169, 0.1591796875, 0.1603167808219178, 0.16036739864864866, 0.160625, 0.16231496710526316, 0.16446834415584416, 0.1656650641025641, 0.16702927215189872, 0.16796875, 0.16878858024691357, 0.16987423780487804, 0.17046310240963855, 0.1715029761904762, 0.17215073529411765, 0.17396438953488372, 0.17420977011494254, 0.1748934659090909, 0.17547401685393257, 0.1762152777777778, 0.17685439560439561, 0.177734375, 0.17859543010752688, 0.17977061170212766, 0.1803453947368421, 0.18115234375, 0.18178157216494845, 0.18215880102040816, 0.1831597222222222, 0.18359375, 0.18463799504950495, 0.18520220588235295, 0.18567961165048544, 0.18629807692307693, 0.18683035714285715, 0.18727889150943397, 0.18771904205607476, 0.18909143518518517, 0.1899369266055046, 0.19076704545454545, 0.19144144144144143, 0.19321986607142858, 0.19503595132743362, 0.19579221491228072, 0.19701086956521738, 0.1978044181034483, 0.1984508547008547, 0.1996822033898305, 0.20030199579831934, 0.2009765625, 0.20183367768595042, 0.20299692622950818, 0.20395071138211382, 0.20470010080645162, 0.20575, 0.2062251984126984, 0.20749261811023623, 0.208984375, 0.2109375, 0.21213942307692307, 0.21362118320610687, 0.21549479166666666, 0.21657659774436092, 0.21834188432835822, 0.21984953703703702, 0.22127757352941177, 0.2229698905109489, 0.22452445652173914, 0.22577562949640287, 0.22723214285714285, 0.22855718085106383, 0.22942341549295775, 0.23016826923076922, 0.23106553819444445, 0.23205818965517241, 0.23383989726027396, 0.23559736394557823, 0.23722550675675674, 0.23888422818791946, 0.2403125, 0.2416183774834437, 0.24352384868421054, 0.24509803921568626, 0.24624594155844157, 0.24798387096774194, 0.24914863782051283, 0.25039808917197454, 0.251532832278481, 0.25240762578616355, 0.25361328125, 0.2551921583850932, 0.2562692901234568, 0.25838765337423314, 0.2600514481707317, 0.2612689393939394, 0.2627541415662651, 0.26422155688622756, 0.2658110119047619, 0.26728920118343197, 0.26902573529411766, 0.27023940058479534, 0.271984011627907, 0.27348265895953755, 0.27500897988505746, 0.27651785714285715, 0.2782315340909091, 0.2797492937853107, 0.2813816713483146, 0.2829521648044693, 0.2844184027777778, 0.2852209944751381, 0.2863581730769231, 0.28739754098360654, 0.288765285326087, 0.29011824324324326, 0.29128864247311825, 0.2926554144385027, 0.2939660904255319, 0.2952628968253968, 0.2967105263157895, 0.29814299738219896, 0.2991129557291667, 0.3007205310880829, 0.30182828608247425, 0.3030849358974359, 0.3047672193877551, 0.305996192893401, 0.3075678661616162, 0.308848932160804, 0.310390625, 0.31145055970149255, 0.312345297029703, 0.31365455665024633, 0.3151807598039216, 0.3166920731707317, 0.318530036407767, 0.3198973429951691, 0.3212139423076923, 0.3225553229665072, 0.32373511904761904, 0.32527399289099523, 0.32639298349056606, 0.32717136150234744, 0.3281980140186916, 0.32921511627906974, 0.3301866319444444, 0.3316892281105991, 0.3324254587155963, 0.3337257420091324, 0.3345525568181818, 0.3358314479638009, 0.3368876689189189, 0.33789938340807174, 0.3392857142857143, 0.3401388888888889, 0.34126106194690264, 0.3423045154185022, 0.34354440789473684, 0.34484170305676853, 0.3458220108695652, 0.3468276515151515, 0.3482287176724138, 0.3492489270386266, 0.3503605769230769, 0.35126329787234045, 0.3522245762711864, 0.35337552742616035, 0.35431985294117646, 0.3556812238493724, 0.3570638020833333, 0.35778656639004147, 0.35869705578512395, 0.3595357510288066, 0.3606237192622951, 0.3616390306122449, 0.3625825711382114, 0.36370824898785425, 0.3646043346774194, 0.3655559738955823, 0.366375, 0.36749875498007967, 0.3687065972222222, 0.3699666501976285, 0.3711552657480315, 0.37224264705882354, 0.373260498046875, 0.3741792315175097, 0.3750908430232558, 0.3762065637065637, 0.37755408653846156, 0.3786817528735632, 0.37959208015267176, 0.3804657794676806, 0.3809185606060606, 0.38178066037735847, 0.38257753759398494, 0.38342696629213485, 0.38444496268656714, 0.3856877323420074, 0.38689236111111114, 0.3875980166051661, 0.38855698529411764, 0.38965201465201466, 0.3903398722627737, 0.3911931818181818, 0.39218183876811596, 0.393163357400722, 0.3943064298561151, 0.39524529569892475, 0.3963169642857143, 0.3974088078291815, 0.3985483156028369, 0.39962455830388693, 0.400665713028169, 0.40158991228070173, 0.4020432692307692, 0.4024662456445993, 0.4031032986111111, 0.40381704152249137, 0.4047144396551724, 0.40557882302405496, 0.4064640410958904, 0.40755652730375425, 0.4083227040816326, 0.40921610169491524, 0.41005067567567566, 0.4107481060606061, 0.41157193791946306, 0.41262541806020064, 0.4136197916666667, 0.41434800664451826, 0.41501966059602646, 0.415815800330033, 0.41670949835526316, 0.4174436475409836, 0.4181474673202614, 0.41889759771986973, 0.4198711444805195, 0.4207878236245955, 0.42179939516129034, 0.4226788585209003, 0.42330228365384615, 0.4240714856230032, 0.42486066878980894, 0.4257440476190476, 0.42652294303797467, 0.4274694400630915, 0.4279677672955975, 0.4286099137931034, 0.429150390625, 0.42997955607476634, 0.4308520962732919, 0.43171923374613, 0.4324122299382716, 0.43310096153846156, 0.4336177147239264, 0.43417909021406725, 0.4349752286585366, 0.4357190349544073, 0.43645833333333334, 0.43716956193353473, 0.43801769578313254, 0.43879035285285284, 0.4393946482035928, 0.43994869402985076, 0.4404994419642857, 0.44125556379821956, 0.4419147559171598, 0.4427083333333333, 0.4436810661764706, 0.44437316715542524, 0.4450612207602339, 0.44581359329446063, 0.4463344840116279, 0.4470108695652174, 0.4477285043352601, 0.44839697406340057, 0.4489044540229885, 0.4496552650429799, 0.4502008928571429, 0.4508769586894587, 0.4514825994318182, 0.45197415014164305, 0.4527277542372881, 0.4532130281690141, 0.45384919241573035, 0.45445990896358546, 0.45517632681564246, 0.4557799442896936, 0.45651041666666664, 0.45712863573407203, 0.4577002762430939, 0.4583763774104683, 0.45904876373626374, 0.45971746575342465, 0.4604892418032787, 0.46102264986376024, 0.46159561820652173, 0.4621231368563686, 0.46264780405405403, 0.4633170485175202, 0.46389868951612906, 0.46474949731903487, 0.4653450868983957, 0.4659583333333333, 0.4666306515957447, 0.4672786803713528, 0.46786127645502645, 0.46831711741424803, 0.46879111842105264, 0.4692831364829396, 0.4695885143979058, 0.4701574738903394, 0.47052001953125, 0.47092126623376623, 0.47166450777202074, 0.4722222222222222, 0.4727770618556701, 0.47342946658097684, 0.473818108974359, 0.47446451406649615, 0.4750876913265306, 0.47576733460559795, 0.4762254124365482, 0.4767009493670886, 0.477114898989899, 0.47776290931989923, 0.4784469221105528, 0.47889254385964913, 0.47935546875, 0.47993298004987534, 0.4806630907960199, 0.4813701923076923, 0.4818997524752475, 0.48234953703703703, 0.4829510467980296, 0.4834536240786241, 0.4840303308823529, 0.4846424205378973, 0.4850609756097561, 0.48570559610705594, 0.48625227548543687, 0.48677739104116224, 0.48726222826086957, 0.4876694277108434, 0.4880934495192308, 0.4885154376498801, 0.48895409688995217, 0.48948389021479716, 0.4898251488095238, 0.4903503562945368, 0.4908545616113744, 0.4914302600472813, 0.49196639150943394, 0.4923897058823529, 0.4928843896713615, 0.49334016393442626, 0.4938303154205608, 0.49417249417249415, 0.49453125, 0.4951058584686775, 0.49546079282407407, 0.4960666859122402, 0.49650777649769584, 0.4970725574712644, 0.49770642201834864, 0.4981049771167048, 0.4987157534246575, 0.49909239749430523, 0.49968039772727274, 0.5002657312925171, 0.5007246889140271, 0.5011463036117382, 0.5015484234234234, 0.5020189606741573, 0.5023822869955157, 0.5029362416107382, 0.5034005301339286, 0.5037235523385301, 0.5041319444444444, 0.5046424611973392, 0.5051334347345132, 0.5056222406181016, 0.5061088931718062, 0.5065418956043956, 0.5070243969298246, 0.5075047866520788, 0.50789778930131, 0.5084933278867102, 0.508882472826087, 0.5091004609544468, 0.5094020562770563, 0.5098373380129589, 0.5102875808189655, 0.5107694892473118, 0.5112325643776824, 0.5116769271948608, 0.5122028579059829, 0.5126]]\n",
      "**************************************************\n",
      "TimeEpoch: [42.39790225028992]\n",
      "**************************************************\n",
      "Energy_AllEpochs: [[array([24.83, 44.13, 78.85, 79.  , 79.15, 78.94, 79.02, 78.78, 78.8 ,\n",
      "         78.68, 78.81, 78.88, 78.76, 78.87, 79.1 , 79.13, 79.12, 79.07,\n",
      "         79.13, 79.03, 78.75, 78.87, 78.74, 79.11, 78.68, 78.95, 78.97,\n",
      "         79.06, 78.85, 78.65, 79.  , 79.  , 78.86, 79.18, 79.38, 79.13,\n",
      "         79.17, 79.03, 78.81, 78.88, 73.33, 77.68, 77.8 ])             ]] \n",
      " Total Energy: 3297.9599999999996 \n",
      " The time of the first epoch: 43\n"
     ]
    }
   ],
   "source": [
    "print('Forward Layers Time: \\n', \n",
    "      'Conv2d time: ', Time_Layers[0,0], '\\n',\n",
    "      'ReLU time: ', Time_Layers[0,1], '\\n',\n",
    "      'MaxPool2d time: ', Time_Layers[0,2], '\\n',\n",
    "      'Linear time: ', Time_Layers[0,3], '\\n',\n",
    "      'Dropout time: ', Time_Layers[0,4], '\\n',\n",
    "      'Flatten time: ', Time_Layers[0,5])\n",
    "print('*'*50)\n",
    "print('Time_AllEpochs: \\n', \n",
    "      'Time to Device time: ', Time_AllEpochs[0,0], '\\n',\n",
    "      'Forward time: ', Time_AllEpochs[0,1], '\\n',\n",
    "      'Calculate Loss time: ', Time_AllEpochs[0,2], '\\n',\n",
    "      'Backward time: ', Time_AllEpochs[0,3], '\\n',\n",
    "      'Optimize time: ', Time_AllEpochs[0,4], '\\n',\n",
    "      'Test time: ', Time_AllEpochs[0,5])\n",
    "print('*'*50)\n",
    "print('Train Time of each epoch:', TrainTime)\n",
    "print('*'*50)\n",
    "print('Import data to ndarray time:', Timport)\n",
    "print('*'*50)\n",
    "print('TestAcc:', TestAcc)\n",
    "print('*'*50)\n",
    "print('TrainLoss:', TrainLoss)\n",
    "print('*'*50)\n",
    "print('TrainAcc:', TrainAcc)\n",
    "print('*'*50)\n",
    "print('TimeEpoch:', TimeEpoch)\n",
    "print('*'*50)\n",
    "print('Energy_AllEpochs:', Energy_AllEpochs, '\\n',\n",
    "      'Total Energy:',np.sum(Energy_AllEpochs[0,0]), '\\n',\n",
    "      'The time of the first epoch:', len(Energy_AllEpochs[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5882db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# working_dir = os.getcwd()\n",
    "# working_dir\n",
    "\n",
    "# # find out the parent directory\n",
    "# parent_dir1 = os.path.dirname(working_dir)\n",
    "# print(parent_dir1)\n",
    "\n",
    "# parent_dir2 = os.path.dirname(parent_dir1)\n",
    "# print(parent_dir2)\n",
    "\n",
    "# parent_dir3 = os.path.dirname(parent_dir2)\n",
    "# print(parent_dir3)\n",
    "\n",
    "# data_folder = os.path.join(parent_dir3, 'data')\n",
    "# print(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86646f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the second_part folder\n",
    "# second_part_dir = os.path.join(data_folder, 'epoch_20SGD_GPU')\n",
    "# second_part_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce4ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the data as .npy file\n",
    "# np.save(os.path.join(second_part_dir, 'time_forward.npy'), time_forward)\n",
    "# np.save(os.path.join(second_part_dir, 'time_round.npy'), time_round)\n",
    "# np.save(os.path.join(second_part_dir, 'test_acc.npy'), test_acc)\n",
    "# np.save(os.path.join(second_part_dir, 'train_acc.npy'), train_acc)\n",
    "# np.save(os.path.join(second_part_dir, 'train_l.npy'), train_l)\n",
    "# np.save(os.path.join(second_part_dir, 'time_epoch.npy'), time_epoch)\n",
    "# np.save(os.path.join(second_part_dir, 'energy_epoch.npy'), energy_data_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
