{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7ae34b7",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from alexnet_FashionMnist import FashionMnist\n",
    "from alexnet_CIFAR100 import CIFAR100\n",
    "from resnet_FashionMnist import resnet_FashionMnist\n",
    "from googlenet_FashionMnist import Googlenet\n",
    "from vgg_FashionMnist import vgg\n",
    "from d2l import torch as d2l\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ptflops import get_model_complexity_info\n",
    "from train_layers import train_layers\n",
    "from train import train_func\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9533381",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n",
    "alexnet_fashionmnist = FashionMnist()\n",
    "alexnet_cifar100 = CIFAR100()\n",
    "resnet_fashionmnist = resnet_FashionMnist()\n",
    "vgg_fashionmnist = vgg(conv_arch)\n",
    "googlenet_fashionmnist = Googlenet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa461034",
   "metadata": {},
   "source": [
    "##### using ptflops to calculate the number of the flops in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86d58f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Inception is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  5.98 M, 100.000% Params, 1.51 GMac, 99.594% MACs, \n",
      "  (0): Sequential(\n",
      "    3.2 k, 0.054% Params, 41.75 MMac, 2.752% MACs, \n",
      "    (0): Conv2d(3.2 k, 0.054% Params, 40.14 MMac, 2.646% MACs, 1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.053% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.053% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 1.923% Params, 361.87 MMac, 23.856% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.070% Params, 13.05 MMac, 0.860% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.013% MACs, )\n",
      "    (2): Conv2d(110.78 k, 1.853% Params, 347.42 MMac, 22.903% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.040% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.040% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    552.43 k, 9.242% Params, 433.83 MMac, 28.600% MACs, \n",
      "    (0): Inception(\n",
      "      163.7 k, 2.739% Params, 128.49 MMac, 8.470% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.207% Params, 9.68 MMac, 0.638% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(18.53 k, 0.310% Params, 14.53 MMac, 0.958% MACs, 192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(110.72 k, 1.852% Params, 86.8 MMac, 5.723% MACs, 96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(3.09 k, 0.052% Params, 2.42 MMac, 0.160% MACs, 192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(12.83 k, 0.215% Params, 10.06 MMac, 0.663% MACs, 16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 150.53 KMac, 0.010% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(6.18 k, 0.103% Params, 4.84 MMac, 0.319% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      388.74 k, 6.503% Params, 304.97 MMac, 20.105% MACs, \n",
      "      (p1_1): Conv2d(32.9 k, 0.550% Params, 25.79 MMac, 1.700% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(32.9 k, 0.550% Params, 25.79 MMac, 1.700% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(221.38 k, 3.703% Params, 173.56 MMac, 11.442% MACs, 128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(8.22 k, 0.138% Params, 6.45 MMac, 0.425% MACs, 256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(76.9 k, 1.286% Params, 60.29 MMac, 3.974% MACs, 32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 200.7 KMac, 0.013% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(16.45 k, 0.275% Params, 12.9 MMac, 0.850% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 376.32 KMac, 0.025% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    2.81 M, 46.995% Params, 551.26 MMac, 36.341% MACs, \n",
      "    (0): Inception(\n",
      "      376.18 k, 6.293% Params, 73.82 MMac, 4.867% MACs, \n",
      "      (p1_1): Conv2d(92.35 k, 1.545% Params, 18.1 MMac, 1.193% MACs, 480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(46.18 k, 0.772% Params, 9.05 MMac, 0.597% MACs, 480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(179.92 k, 3.010% Params, 35.26 MMac, 2.325% MACs, 96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(7.7 k, 0.129% Params, 1.51 MMac, 0.099% MACs, 480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(19.25 k, 0.322% Params, 3.77 MMac, 0.249% MACs, 16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 94.08 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(30.78 k, 0.515% Params, 6.03 MMac, 0.398% MACs, 480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      449.16 k, 7.514% Params, 88.14 MMac, 5.810% MACs, \n",
      "      (p1_1): Conv2d(82.08 k, 1.373% Params, 16.09 MMac, 1.061% MACs, 512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(57.46 k, 0.961% Params, 11.26 MMac, 0.742% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(226.02 k, 3.781% Params, 44.3 MMac, 2.920% MACs, 112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.206% Params, 2.41 MMac, 0.159% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.643% Params, 7.54 MMac, 0.497% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.549% Params, 6.44 MMac, 0.424% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception(\n",
      "      510.1 k, 8.534% Params, 100.08 MMac, 6.598% MACs, \n",
      "      (p1_1): Conv2d(65.66 k, 1.099% Params, 12.87 MMac, 0.848% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(65.66 k, 1.099% Params, 12.87 MMac, 0.848% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(295.17 k, 4.938% Params, 57.85 MMac, 3.814% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.206% Params, 2.41 MMac, 0.159% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.643% Params, 7.54 MMac, 0.497% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.549% Params, 6.44 MMac, 0.424% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception(\n",
      "      605.38 k, 10.128% Params, 118.75 MMac, 7.829% MACs, \n",
      "      (p1_1): Conv2d(57.46 k, 0.961% Params, 11.26 MMac, 0.742% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(73.87 k, 1.236% Params, 14.48 MMac, 0.955% MACs, 512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(373.54 k, 6.249% Params, 73.21 MMac, 4.827% MACs, 144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.42 k, 0.275% Params, 3.22 MMac, 0.212% MACs, 512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(51.26 k, 0.858% Params, 10.05 MMac, 0.662% MACs, 32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.549% Params, 6.44 MMac, 0.424% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception(\n",
      "      868.35 k, 14.527% Params, 170.3 MMac, 11.227% MACs, \n",
      "      (p1_1): Conv2d(135.42 k, 2.266% Params, 26.54 MMac, 1.750% MACs, 528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(84.64 k, 1.416% Params, 16.59 MMac, 1.094% MACs, 528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.714% Params, 90.38 MMac, 5.958% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.93 k, 0.283% Params, 3.32 MMac, 0.219% MACs, 528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.715% Params, 20.1 MMac, 1.325% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 103.49 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(67.71 k, 1.133% Params, 13.27 MMac, 0.875% MACs, 528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 163.07 KMac, 0.011% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    2.49 M, 41.615% Params, 122.02 MMac, 8.044% MACs, \n",
      "    (0): Inception(\n",
      "      1.04 M, 17.456% Params, 51.17 MMac, 3.373% MACs, \n",
      "      (p1_1): Conv2d(213.25 k, 3.567% Params, 10.45 MMac, 0.689% MACs, 832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(133.28 k, 2.230% Params, 6.53 MMac, 0.431% MACs, 832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.714% Params, 22.59 MMac, 1.490% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(26.66 k, 0.446% Params, 1.31 MMac, 0.086% MACs, 832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.715% Params, 5.02 MMac, 0.331% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.784% Params, 5.22 MMac, 0.344% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      1.44 M, 24.158% Params, 70.8 MMac, 4.667% MACs, \n",
      "      (p1_1): Conv2d(319.87 k, 5.351% Params, 15.67 MMac, 1.033% MACs, 832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(159.94 k, 2.676% Params, 7.84 MMac, 0.517% MACs, 832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(663.94 k, 11.107% Params, 32.53 MMac, 2.145% MACs, 192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(39.98 k, 0.669% Params, 1.96 MMac, 0.129% MACs, 832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(153.73 k, 2.572% Params, 7.53 MMac, 0.497% MACs, 48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.784% Params, 5.22 MMac, 0.344% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 50.18 KMac, 0.003% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(10.25 k, 0.171% Params, 10.25 KMac, 0.001% MACs, in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       1.52 GMac\n",
      "Number of parameters:           5.98 M  \n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "#     net = alexnet_fashionmnist\n",
    "#     macs, params = get_model_complexity_info(net, (1, 224, 224), as_strings=True,\n",
    "#                                             print_per_layer_stat=True, verbose=True)\n",
    "    \n",
    "    # net = alexnet_cifar100\n",
    "    # macs, params = get_model_complexity_info(net, (3, 224, 224), as_strings=True,\n",
    "    #                                         print_per_layer_stat=True, verbose=True)\n",
    "    \n",
    "    # net = resnet_fashionmnist\n",
    "    # macs, params = get_model_complexity_info(net, (1, 224, 224), as_strings=True,\n",
    "    #                                         print_per_layer_stat=True, verbose=True)\n",
    "    \n",
    "    # net = vgg_fashionmnist\n",
    "    # macs, params = get_model_complexity_info(net, (1, 224, 224), as_strings=True,\n",
    "    #                                         print_per_layer_stat=True, verbose=True)\n",
    "    \n",
    "    net = googlenet_fashionmnist\n",
    "    macs, params = get_model_complexity_info(net, (1, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    \n",
    "    if net == resnet_fashionmnist:\n",
    "        print(torch.backends.mps.is_built())\n",
    "        print(torch.backends.mps.is_available())\n",
    "    \n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d97a07",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "[**我们构造一个**]高度和宽度都为224的(**单通道数据，来观察每一层输出的形状**)。\n",
    "它与 :numref:`fig_alexnet`中的AlexNet架构相匹配。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a7ec36",
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 192, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 480, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 832, 7, 7])\n",
      "Sequential output shape:\t torch.Size([1, 1024])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1, 1, 224, 224) # FashionMNIST\n",
    "\n",
    "# X = torch.randn(1, 3, 224, 224) # CIFAR100\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c79a7",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "## 读取数据集\n",
    "\n",
    "尽管原文中AlexNet是在ImageNet上进行训练的，但本书在这里使用的是Fashion-MNIST数据集。因为即使在现代GPU上，训练ImageNet模型，同时使其收敛可能需要数小时或数天的时间。\n",
    "将AlexNet直接应用于Fashion-MNIST的一个问题是，[**Fashion-MNIST图像的分辨率**]（$28 \\times 28$像素）(**低于ImageNet图像。**)\n",
    "为了解决这个问题，(**我们将它们增加到$224 \\times 224$**)（通常来讲这不是一个明智的做法，但在这里这样做是为了有效使用AlexNet架构）。\n",
    "这里需要使用`d2l.load_data_fashion_mnist`函数中的`resize`参数执行此调整。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32a33f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_workers():\n",
    "    \"\"\"Use 4 processes to read the data.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    return 4\n",
    "def load_data_cifar100(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    # import the cifar100 dataset\n",
    "    cifar_train = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    cifar_test = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(cifar_train, batch_size, shuffle=True,\n",
    "                                        num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(cifar_test, batch_size, shuffle=False,\n",
    "                                        num_workers=get_dataloader_workers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c1552a8",
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the train_iter is: (469,)\n",
      "the shape of the 0 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 1 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 2 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 3 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 4 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 5 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 6 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 7 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 8 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 9 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224) # FashionMNIST\n",
    "\n",
    "# train_iter, test_iter = load_data_cifar100(batch_size, resize=224) # CIFAR100\n",
    "# print the shape of the train_iter\n",
    "list_of_i = []\n",
    "for i, (X, y) in enumerate(train_iter):\n",
    "    list_of_i.append(i)\n",
    "\n",
    "print('the shape of the train_iter is:', np.array(list_of_i).shape)\n",
    "# print(list_of_i)\n",
    "# print the first 10 batch of the train_iter\n",
    "for i, (X, y) in enumerate(train_iter):\n",
    "    if i < 10:\n",
    "        print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcd56c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working dir is:  /root/GreenAI/GPU/universal\n",
      "The train_data dir is:  /root/GreenAI/GPU/universal/Data/Googlenet_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "working_dir = os.getcwd()\n",
    "print('The working dir is: ', working_dir)\n",
    "\n",
    "# find out the parent directory\n",
    "train_data = os.path.join(working_dir, 'Data/Googlenet_data')\n",
    "# train_data = os.path.join(working_dir, 'Googlenet_train_data')\n",
    "print('The train_data dir is: ', train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0222ef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train_data_str is:  /root/GreenAI/GPU/universal/Data/Googlenet_data\n"
     ]
    }
   ],
   "source": [
    "train_data_str = str(train_data)\n",
    "print('The train_data_str is: ', train_data_str)\n",
    "train_data_path = Path(train_data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folders in the train_data are:  ['/root/GreenAI/GPU/universal/Data/Googlenet_data/round_1', '/root/GreenAI/GPU/universal/Data/Googlenet_data/round_2', '/root/GreenAI/GPU/universal/Data/Googlenet_data/round_3', '/root/GreenAI/GPU/universal/Data/Googlenet_data/round_4', '/root/GreenAI/GPU/universal/Data/Googlenet_data/round_5', '/root/GreenAI/GPU/universal/Data/Googlenet_data/round_6', '/root/GreenAI/GPU/universal/Data/Googlenet_data/round_7', '/root/GreenAI/GPU/universal/Data/Googlenet_data/round_8', '/root/GreenAI/GPU/universal/Data/Googlenet_data/round_9', '/root/GreenAI/GPU/universal/Data/Googlenet_data/round_10']\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dir_path = train_data_path / f'round_{i}'\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# find out all the subfolders in the train_data\n",
    "subfolders = [f.path for f in os.scandir(train_data) if f.is_dir()]\n",
    "print('The folders in the train_data are: ', subfolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35ebe8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sub_folder dir is:  /root/GreenAI/GPU/universal/Data/Googlenet_data/round_1\n",
      "training on cuda:0\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed: Avg Loss: 2.30251149520874, Avg Accuracy: 0.10098333333333333\n",
      "test acc is 0.100000\n",
      "epoch 1, time 41.895674 sec\n",
      "epoch 2\n",
      "Epoch 2 completed: Avg Loss: 2.3018104578653973, Avg Accuracy: 0.12276666666666666\n",
      "test acc is 0.189800\n",
      "epoch 2, time 81.375071 sec\n",
      "epoch 3\n",
      "Epoch 3 completed: Avg Loss: 2.3003796063741047, Avg Accuracy: 0.13778333333333334\n",
      "test acc is 0.100000\n",
      "epoch 3, time 122.830104 sec\n",
      "epoch 4\n",
      "Epoch 4 completed: Avg Loss: 2.2952255165100097, Avg Accuracy: 0.19881666666666667\n",
      "test acc is 0.346400\n",
      "epoch 4, time 163.206377 sec\n",
      "epoch 5\n",
      "Epoch 5 completed: Avg Loss: 2.247052219136556, Avg Accuracy: 0.26005\n",
      "test acc is 0.225100\n",
      "epoch 5, time 202.995350 sec\n",
      "epoch 6\n",
      "Epoch 6 completed: Avg Loss: 1.559759793217977, Avg Accuracy: 0.41685\n",
      "test acc is 0.512900\n",
      "epoch 6, time 242.442717 sec\n",
      "epoch 7\n",
      "Epoch 7 completed: Avg Loss: 1.02395247408549, Avg Accuracy: 0.5913333333333334\n",
      "test acc is 0.667700\n",
      "epoch 7, time 282.471200 sec\n",
      "epoch 8\n",
      "Epoch 8 completed: Avg Loss: 0.8589798470815023, Avg Accuracy: 0.66705\n",
      "test acc is 0.740700\n",
      "epoch 8, time 323.519897 sec\n",
      "epoch 9\n",
      "Epoch 9 completed: Avg Loss: 0.716501349957784, Avg Accuracy: 0.7265833333333334\n",
      "test acc is 0.751000\n",
      "epoch 9, time 364.206729 sec\n",
      "epoch 10\n",
      "Epoch 10 completed: Avg Loss: 0.6269467436472574, Avg Accuracy: 0.7584833333333333\n",
      "test acc is 0.763500\n",
      "epoch 10, time 403.754785 sec\n",
      "The sub_folder dir is:  /root/GreenAI/GPU/universal/Data/Googlenet_data/round_2\n",
      "training on cuda:0\n",
      "epoch 1\n",
      "Epoch 1 completed: Avg Loss: 2.302758083597819, Avg Accuracy: 0.10023333333333333\n",
      "test acc is 0.192900\n",
      "epoch 1, time 39.317724 sec\n",
      "epoch 2\n",
      "Epoch 2 completed: Avg Loss: 2.3003175605773927, Avg Accuracy: 0.13146666666666668\n",
      "test acc is 0.115700\n",
      "epoch 2, time 80.300813 sec\n",
      "epoch 3\n",
      "Epoch 3 completed: Avg Loss: 2.2911259806315103, Avg Accuracy: 0.22495\n",
      "test acc is 0.258400\n",
      "epoch 3, time 119.686079 sec\n",
      "epoch 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe sub_folder dir is: \u001b[39m\u001b[38;5;124m'\u001b[39m, working_diri)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(alexnet_fashionmnist, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for Alexnet\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(resnet_fashionmnist, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for Resnet\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(alexnet_cifar100, train_iter, test_iter, num_epochs, lr, device) # CIFAR100 for Alexnet\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(vgg_fashionmnist, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for VGG\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgooglenet_fashionmnist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# FashionMNIST for Googlenet\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# # print('Forward Layers Time: \\n', \u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# #       'Conv2d time: ', Time_Layers[0,0], '\\n',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# save the Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss to the sub_folder dir as .npy file\u001b[39;00m\n\u001b[1;32m     46\u001b[0m np\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(working_diri, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_AllEpochs.npy\u001b[39m\u001b[38;5;124m'\u001b[39m), Time_AllEpochs)\n",
      "File \u001b[0;32m~/GreenAI/GPU/universal/train.py:94\u001b[0m, in \u001b[0;36mtrain_func\u001b[0;34m(net, train_iter, test_iter, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m##################################################################################\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 94\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 等待数据传输完成\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     Tbi_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     96\u001b[0m     Tback_batch \u001b[38;5;241m=\u001b[39m Tbi_end \u001b[38;5;241m-\u001b[39m Tli_end\n",
      "File \u001b[0;32m~/miniconda3/envs/GreenAI/lib/python3.11/site-packages/torch/cuda/__init__.py:801\u001b[0m, in \u001b[0;36msynchronize\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    799\u001b[0m _lazy_init()\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[0;32m--> 801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 10\n",
    "device = d2l.try_gpu()\n",
    "for subfolder in subfolders:\n",
    "    working_diri = os.path.join(train_data, subfolder)\n",
    "    print('The sub_folder dir is: ', working_diri)\n",
    "    # Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(alexnet_fashionmnist, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for Alexnet\n",
    "    # Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(resnet_fashionmnist, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for Resnet\n",
    "    # Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(alexnet_cifar100, train_iter, test_iter, num_epochs, lr, device) # CIFAR100 for Alexnet\n",
    "    # Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(vgg_fashionmnist, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for VGG\n",
    "    Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss = train_func(googlenet_fashionmnist, train_iter, test_iter, num_epochs, lr, device) # FashionMNIST for Googlenet\n",
    "\n",
    "    # # print('Forward Layers Time: \\n', \n",
    "    \n",
    "    # #       'Conv2d time: ', Time_Layers[0,0], '\\n',\n",
    "    # #       'ReLU time: ', Time_Layers[0,1], '\\n',\n",
    "    # #       'MaxPool2d time: ', Time_Layers[0,2], '\\n',\n",
    "    # #       'Linear time: ', Time_Layers[0,3], '\\n',\n",
    "    # #       'Dropout time: ', Time_Layers[0,4], '\\n',\n",
    "    # #       'Flatten time: ', Time_Layers[0,5])\n",
    "    # # print('*'*50)\n",
    "    # print('Time_AllEpochs: \\n', \n",
    "    #     'Time to Device time: ', Time_AllEpochs[0,0], '\\n',\n",
    "    #     'Forward time: ', Time_AllEpochs[0,1], '\\n',\n",
    "    #     'Calculate Loss time: ', Time_AllEpochs[0,2], '\\n',\n",
    "    #     'Backward time: ', Time_AllEpochs[0,3], '\\n',\n",
    "    #     'Optimize time: ', Time_AllEpochs[0,4], '\\n',\n",
    "    #     'Test time: ', Time_AllEpochs[0,5])\n",
    "    # print('*'*50)\n",
    "    # print('Train Time of each epoch:', TrainTime[0])\n",
    "    # print('*'*50)\n",
    "    # print('Evaluation time: ', TTrainAccLoss[0])\n",
    "    # print('*'*50)\n",
    "    # print('TestAcc:', TestAcc)\n",
    "    # print('*'*50)\n",
    "    # print('TrainLoss:', TrainLoss)\n",
    "    # print('*'*50)\n",
    "    # print('TrainAcc:', TrainAcc)\n",
    "    # print('*'*50)\n",
    "    # print('TimeEpoch:', TimeEpoch[0])\n",
    "    # print('*'*50)\n",
    "    # print('Energy_AllEpochs:', Energy_AllEpochs[0], '\\n',\n",
    "    #     'Total Energy:',np.sum(Energy_AllEpochs[0,0]), '\\n',\n",
    "    #     'The time of the first epoch:', len(Energy_AllEpochs[0,0]))\n",
    "    \n",
    "    # save the Time_AllEpochs, TestAcc, TrainLoss, TrainAcc, TimeEpoch, Energy_AllEpochs, TrainTime, TTrainAccLoss to the sub_folder dir as .npy file\n",
    "    np.save(os.path.join(working_diri, 'Time_AllEpochs.npy'), Time_AllEpochs)\n",
    "    np.save(os.path.join(working_diri, 'TestAcc.npy'), TestAcc)\n",
    "    np.save(os.path.join(working_diri, 'TrainLoss.npy'), TrainLoss)\n",
    "    np.save(os.path.join(working_diri, 'TrainAcc.npy'), TrainAcc)\n",
    "    np.save(os.path.join(working_diri, 'TimeEpoch.npy'), TimeEpoch)\n",
    "    np.save(os.path.join(working_diri, 'Energy_AllEpochs.npy'), Energy_AllEpochs)\n",
    "    np.save(os.path.join(working_diri, 'TrainTime.npy'), TrainTime)\n",
    "    np.save(os.path.join(working_diri, 'TTrainAccLoss.npy'), TTrainAccLoss)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4ad45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GreenAI",
   "language": "python",
   "name": "greenai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
