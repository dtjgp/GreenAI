{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is to gather the information of the energy consumption of the whole training process of different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from d2l import torch as d2l\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ptflops import get_model_complexity_info\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import pynvml\n",
    "import threading\n",
    "import queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current path is: /root/autodl-tmp/GreenAI/3080\n",
      "The data path is: /root/autodl-tmp/GreenAI/3080/ModelsData\n"
     ]
    }
   ],
   "source": [
    "'''find the Model path'''\n",
    "# find the current path\n",
    "from pathlib import Path\n",
    "\n",
    "# find the current path\n",
    "current_path = Path.cwd()\n",
    "print('The current path is:', current_path)\n",
    "\n",
    "# find the data path\n",
    "data_path = Path(current_path / 'ModelsData')\n",
    "print('The data path is:', data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate the data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name = ['resnet18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/root/autodl-tmp/GreenAI/3080/ModelsData/resnet18')]\n"
     ]
    }
   ],
   "source": [
    "DataList = [Path(f\"{data_path}/{i}\") for i in models_name]\n",
    "print(DataList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ResNet18 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual18(nn.Module):  #@save\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels, kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Dictionary to record time for each sub-layer\n",
    "        self.layer_time = {}\n",
    "\n",
    "    def forward(self, X):\n",
    "        start_t = time.time()\n",
    "        out = self.conv1(X)\n",
    "        torch.cuda.synchronize()\n",
    "        end_t = time.time()\n",
    "        self.layer_time['conv1'] = end_t - start_t\n",
    "\n",
    "        start_t = time.time()\n",
    "        out = self.bn1(out)\n",
    "        torch.cuda.synchronize()\n",
    "        end_t = time.time()\n",
    "        self.layer_time['bn1'] = end_t - start_t\n",
    "\n",
    "        start_t = time.time()\n",
    "        out = self.relu1(out)\n",
    "        torch.cuda.synchronize()\n",
    "        end_t = time.time()\n",
    "        self.layer_time['relu1'] = end_t - start_t\n",
    "\n",
    "        start_t = time.time()\n",
    "        out = self.conv2(out)\n",
    "        torch.cuda.synchronize()\n",
    "        end_t = time.time()\n",
    "        self.layer_time['conv2'] = end_t - start_t\n",
    "\n",
    "        start_t = time.time()\n",
    "        out = self.bn2(out)\n",
    "        torch.cuda.synchronize()\n",
    "        end_t = time.time()\n",
    "        self.layer_time['bn2'] = end_t - start_t\n",
    "\n",
    "        if self.conv3:\n",
    "            start_t = time.time()\n",
    "            X = self.conv3(X)\n",
    "            torch.cuda.synchronize()\n",
    "            end_t = time.time()\n",
    "            self.layer_time['conv3'] = end_t - start_t\n",
    "\n",
    "        start_t = time.time()\n",
    "        out = out + X\n",
    "        out = self.relu2(out)\n",
    "        torch.cuda.synchronize()\n",
    "        end_t = time.time()\n",
    "        self.layer_time['residual_add_relu2'] = end_t - start_t\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "def resnet18(img_channel, num_labels):\n",
    "    b1 = nn.Sequential(\n",
    "        nn.Conv2d(img_channel, 64, kernel_size=7, stride=2, padding=3),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    )\n",
    "\n",
    "    def resnet_block(input_channels, num_channels, num_residuals, first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(Residual18(input_channels, num_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(Residual18(num_channels, num_channels))\n",
    "        return blk\n",
    "\n",
    "    b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
    "    b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
    "    b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "    b5 = nn.Sequential(*resnet_block(256, 512, 2))\n",
    "\n",
    "    net = nn.Sequential(\n",
    "                        b1, b2, b3, b4, b5,\n",
    "                        nn.AdaptiveAvgPool2d((1,1)),\n",
    "                        nn.Flatten(),\n",
    "                        nn.Linear(512, num_labels)\n",
    "                    )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n",
    "print('The device is:', device)\n",
    "\n",
    "# check if mps on macbook is availabel\n",
    "# print(torch.backends.mps.is_available())  # 检查 MPS 是否可用\n",
    "# print(torch.backends.mps.is_built())      # 检查 MPS 是否已编译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to store all the parameters and the number of MACs, be careful of the different datasets\n",
    "# to avoid the error of the number of input channels and any other mistake, try to use different dictionaries to store each dataset\n",
    "# create different empty dictionary\n",
    "macs_f = {}\n",
    "paras_f = {}\n",
    "macs_c100 = {}\n",
    "paras_c100 = {}\n",
    "macs_c10 = {}\n",
    "paras_c10 = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### usea function to call the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for all the models to run\n",
    "# image channel for fashion mnist \n",
    "channel_f = 1\n",
    "# image channel for cifar100 and cifar10\n",
    "channel_c = 3\n",
    "\n",
    "# number of labels for fashion mnist\n",
    "num_labels_f = 10\n",
    "# number of labels for cifar100 \n",
    "num_labels_c100 = 100\n",
    "# number of labels for cifar10\n",
    "num_labels_c10 = 10\n",
    "\n",
    "def get_model_info(model, img_channel, num_labels):\n",
    "    model_ini = model.__name__\n",
    "    print(f'The model name is {model_ini}')\n",
    "\n",
    "    net = model(img_channel, num_labels)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model name is resnet18\n",
      "The model name is resnet18\n",
      "The model name is resnet18\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m resnet18_f \u001b[38;5;241m=\u001b[39m get_model_info(resnet18, channel_f, num_labels_f)\n\u001b[1;32m      4\u001b[0m resnet18_c100 \u001b[38;5;241m=\u001b[39m get_model_info(resnet18, channel_c, num_labels_c100)\n\u001b[0;32m----> 5\u001b[0m resnet18_c10 \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet18\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels_c10\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m, in \u001b[0;36mget_model_info\u001b[0;34m(model, img_channel, num_labels)\u001b[0m\n\u001b[1;32m     15\u001b[0m model_ini \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe model name is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_ini\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_channel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m net\n",
      "Cell \u001b[0;32mIn[5], line 84\u001b[0m, in \u001b[0;36mresnet18\u001b[0;34m(img_channel, num_labels)\u001b[0m\n\u001b[1;32m     81\u001b[0m             blk\u001b[38;5;241m.\u001b[39mappend(Residual18(num_channels, num_channels))\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m blk\n\u001b[0;32m---> 84\u001b[0m b2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39m\u001b[43mresnet_block\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_block\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m     85\u001b[0m b3 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39mresnet_block(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     86\u001b[0m b4 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39mresnet_block(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[0;32mIn[5], line 81\u001b[0m, in \u001b[0;36mresnet18.<locals>.resnet_block\u001b[0;34m(input_channels, num_channels, num_residuals, first_block)\u001b[0m\n\u001b[1;32m     79\u001b[0m         blk\u001b[38;5;241m.\u001b[39mappend(Residual18(input_channels, num_channels, use_1x1conv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         blk\u001b[38;5;241m.\u001b[39mappend(\u001b[43mResidual18\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blk\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36mResidual18.__init__\u001b[0;34m(self, input_channels, num_channels, use_1x1conv, strides)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(input_channels, num_channels, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, stride\u001b[38;5;241m=\u001b[39mstrides)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_1x1conv:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(input_channels, num_channels, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, stride\u001b[38;5;241m=\u001b[39mstrides)\n",
      "File \u001b[0;32m~/miniconda3/envs/greenai/lib/python3.10/site-packages/torch/nn/modules/conv.py:521\u001b[0m, in \u001b[0;36mConv2d.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    519\u001b[0m padding_ \u001b[38;5;241m=\u001b[39m padding \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(padding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m _pair(padding)\n\u001b[1;32m    520\u001b[0m dilation_ \u001b[38;5;241m=\u001b[39m _pair(dilation)\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_size_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdilation_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/greenai/lib/python3.10/site-packages/torch/nn/modules/conv.py:176\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/greenai/lib/python3.10/site-packages/torch/nn/modules/conv.py:182\u001b[0m, in \u001b[0;36m_ConvNd.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*kernel_size)\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m         fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n",
      "File \u001b[0;32m~/miniconda3/envs/greenai/lib/python3.10/site-packages/torch/nn/init.py:518\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity, generator)\u001b[0m\n\u001b[1;32m    516\u001b[0m bound \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ResNet\n",
    "# resnet18\n",
    "resnet18_f = get_model_info(resnet18, channel_f, num_labels_f)\n",
    "resnet18_c100 = get_model_info(resnet18, channel_c, num_labels_c100)\n",
    "resnet18_c10 = get_model_info(resnet18, channel_c, num_labels_c10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Datasets for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet18']\n"
     ]
    }
   ],
   "source": [
    "print(models_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model list according to models_name order\n",
    "models_f_list = [resnet18_f]\n",
    "\n",
    "models_c100_list = [resnet18_c100]\n",
    "\n",
    "models_c10_list = [resnet18_c10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show the output size of each layers after the picture is passed through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layerlist_resnet18: ['Conv2d', 'BatchNorm2d', 'ReLU', 'MaxPool2d', 'residual_Conv2d_1', 'residual_BatchNorm2d_1', 'residual_ReLU_1', 'residual_Conv2d_2', 'residual_BatchNorm2d_2', 'residual_ReLU_2', 'residual_Conv2d_1', 'residual_BatchNorm2d_1', 'residual_ReLU_1', 'residual_Conv2d_2', 'residual_BatchNorm2d_2', 'residual_ReLU_2', 'residual_Conv2d_1', 'residual_BatchNorm2d_1', 'residual_ReLU_1', 'residual_Conv2d_2', 'residual_BatchNorm2d_2', 'residual_Conv2d_3', 'residual_ReLU_2', 'residual_Conv2d_1', 'residual_BatchNorm2d_1', 'residual_ReLU_1', 'residual_Conv2d_2', 'residual_BatchNorm2d_2', 'residual_ReLU_2', 'residual_Conv2d_1', 'residual_BatchNorm2d_1', 'residual_ReLU_1', 'residual_Conv2d_2', 'residual_BatchNorm2d_2', 'residual_Conv2d_3', 'residual_ReLU_2', 'residual_Conv2d_1', 'residual_BatchNorm2d_1', 'residual_ReLU_1', 'residual_Conv2d_2', 'residual_BatchNorm2d_2', 'residual_ReLU_2', 'residual_Conv2d_1', 'residual_BatchNorm2d_1', 'residual_ReLU_1', 'residual_Conv2d_2', 'residual_BatchNorm2d_2', 'residual_Conv2d_3', 'residual_ReLU_2', 'residual_Conv2d_1', 'residual_BatchNorm2d_1', 'residual_ReLU_1', 'residual_Conv2d_2', 'residual_BatchNorm2d_2', 'residual_ReLU_2', 'AdaptiveAvgPool2d', 'Flatten', 'Linear']\n"
     ]
    }
   ],
   "source": [
    "X_f = torch.randn(size=(1, 1, 224, 224), dtype=torch.float32) # fashion mnist\n",
    "\n",
    "layerlist_resnet18 = []\n",
    "for layer in resnet18_f:\n",
    "    name = layer.__class__.__name__\n",
    "    if name == 'Sequential':\n",
    "        for l in layer:\n",
    "            inner_name = l.__class__.__name__\n",
    "            if inner_name == 'Residual18':\n",
    "                layerlist_resnet18.append('residual_'+l.conv1.__class__.__name__+'_1')\n",
    "                layerlist_resnet18.append('residual_'+l.bn1.__class__.__name__+'_1')\n",
    "                layerlist_resnet18.append('residual_'+l.relu1.__class__.__name__+'_1')\n",
    "                layerlist_resnet18.append('residual_'+l.conv2.__class__.__name__+'_2')   \n",
    "                layerlist_resnet18.append('residual_'+l.bn2.__class__.__name__+'_2')\n",
    "                if l.conv3 is not None:  # 确保 conv3 存在\n",
    "                    layerlist_resnet18.append('residual_' + l.conv3.__class__.__name__+'_3')      \n",
    "                layerlist_resnet18.append('residual_'+l.relu2.__class__.__name__+'_2')\n",
    "            else:\n",
    "                layerlist_resnet18.append(inner_name)\n",
    "    else:\n",
    "        layerlist_resnet18.append(name)\n",
    "\n",
    "print(f'layerlist_resnet18: {layerlist_resnet18}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "layer_count = 0\n",
    "for layer in resnet18_f:\n",
    "    name = layer.__class__.__name__\n",
    "    if name == 'Sequential':\n",
    "        residual_block = 0\n",
    "        for l in layer:\n",
    "            inner_name = l.__class__.__name__\n",
    "            if inner_name == 'Residual18':\n",
    "                print(l.conv1)\n",
    "                \n",
    "                \n",
    "                \n",
    "    else:\n",
    "        name = name + '_' + str(layer_count)\n",
    "        layer_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load all the datas:  \n",
    "    1. FashionMNIST\n",
    "    2. CIFAR100\n",
    "    3. CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# fashion mnist\n",
    "def get_dataloader_workers():\n",
    "    \"\"\"Use 4 processes to read the data.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    return 4\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \"\"\"下载Fashion-MNIST数据集, 然后将其加载到内存中\n",
    "\n",
    "    Defined in :numref:`sec_fashion_mnist`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=get_dataloader_workers()))\n",
    "\n",
    "def load_data_cifar100(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    # import the cifar100 dataset\n",
    "    cifar_train = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    cifar_test = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(cifar_train, batch_size, shuffle=True,\n",
    "                                        num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(cifar_test, batch_size, shuffle=False,\n",
    "                                        num_workers=get_dataloader_workers()))\n",
    "    \n",
    "def load_data_cifar10(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    # import the cifar100 dataset\n",
    "    cifar_train = torchvision.datasets.CIFAR10(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    cifar_test = torchvision.datasets.CIFAR10(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(cifar_train, batch_size, shuffle=True,\n",
    "                                        num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(cifar_test, batch_size, shuffle=False,\n",
    "                                        num_workers=get_dataloader_workers()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [128]\n",
    "epochs = [5]\n",
    "rounds = 1\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using pynvml to get the GPU power consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nvml_sampling_thread(handle, filename, stop_event, sampling_interval):\n",
    "    \"\"\"\n",
    "    在单独的线程中定期调用 NVML, 获取功耗数据并存储到 data_queue 中。\n",
    "    参数：\n",
    "    - handle: nvmlDeviceGetHandleByIndex(0) 得到的 GPU 句柄\n",
    "    - data_queue: 用于存放 (timestamp, power_in_watts) 数据的队列\n",
    "    - stop_event: 当此事件被设置时，线程应结束循环\n",
    "    - sampling_interval: 采样间隔（秒）\n",
    "    \"\"\"\n",
    "    with open(filename/'energy_consumption_file.csv', 'a') as f:  # 追加模式\n",
    "        # 写入列名\n",
    "        f.write(\"timestamp,power_in_watts\\n\")\n",
    "        while not stop_event.is_set():\n",
    "            try:\n",
    "                # 采集功率和时间戳\n",
    "                current_time = time.time()\n",
    "                current_power = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # 转换 mW -> W\n",
    "                # 写入文件\n",
    "                f.write(f\"{current_time},{current_power}\\n\")\n",
    "                # 等待下一次采样\n",
    "                time.sleep(sampling_interval)\n",
    "            except pynvml.NVMLError as e:\n",
    "                print(f\"NVML Error: {e}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set the interval of the power consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_power_over_interval(samples, start_time, end_time):\n",
    "    # 假定 samples是按时间升序排序的 (t, p)\n",
    "    # 若未排序，请先排序:\n",
    "    # samples = sorted(samples, key=lambda x: x[0])\n",
    "    \n",
    "    def interpolate(samples, target_time):\n",
    "        # 在 samples 中找到 target_time 左右最近的两个点，并进行线性插值\n",
    "        # 若 target_time 恰好等于某个样本点时间，直接返回该点功率\n",
    "        # 若无法找到两侧点（如 target_time在样本时间轴外），根据情况返回None或边界点\n",
    "        n = len(samples)\n",
    "        if n == 0:\n",
    "            return None\n",
    "        # 若 target_time 小于第一个样本点时间，无法向左插值，这里直接返回第一个点的功率值(或None)\n",
    "        if target_time <= samples[0][0]:\n",
    "            # 简化处理：返回最早样本点的功率（或None）\n",
    "            return samples[0][1]\n",
    "        # 若 target_time 大于最后一个样本点时间，无法向右插值，返回最后一个点的功率（或None）\n",
    "        if target_time >= samples[-1][0]:\n",
    "            return samples[-1][1]\n",
    "\n",
    "        # 否则，在中间插值\n",
    "        # 使用二分查找快速定位\n",
    "        import bisect\n",
    "        times = [t for t, _ in samples]\n",
    "        pos = bisect.bisect_left(times, target_time)\n",
    "        # pos是使times保持有序插入target_time的位置\n",
    "        # 因为target_time不在已有样本点中，pos不会越界且pos>0且pos<n\n",
    "        t1, p1 = samples[pos-1]\n",
    "        t2, p2 = samples[pos]\n",
    "        # 线性插值： p = p1 + (p2 - p1)*((target_time - t1)/(t2 - t1))\n",
    "        ratio = (target_time - t1) / (t2 - t1)\n",
    "        p = p1 + (p2 - p1)*ratio\n",
    "        return p\n",
    "\n",
    "    # 从原始 samples 中筛选出位于[start_time, end_time]内的点\n",
    "    filtered = [(t, p) for t, p in samples if start_time <= t <= end_time]\n",
    "\n",
    "    # 如果不足2个点，则尝试使用插值\n",
    "    if len(filtered) < 2:\n",
    "        # 无论如何都需要在边界处插值出两个点(起码start和end)\n",
    "        start_power = interpolate(samples, start_time)\n",
    "        end_power = interpolate(samples, end_time)\n",
    "\n",
    "        # 如果从样本中无法插值出任何有意义的点（比如samples为空或无法插值），返回0.0\n",
    "        if start_power is None or end_power is None:\n",
    "            return 0.0\n",
    "\n",
    "        # 将插值的边界点加入到 filtered\n",
    "        # 注意：如果filtered中有一个点在区间内，我们也需要确保边界有两点以上\n",
    "        # 例如filtered只有一个点在中间，则需要在start和end插值点全部加入。\n",
    "        # 若filtered为空，则只用start/end两点插值点求积分\n",
    "        new_filtered = [(start_time, start_power)] + filtered + [(end_time, end_power)]\n",
    "        # 确保按时间排序\n",
    "        new_filtered.sort(key=lambda x: x[0])\n",
    "        filtered = new_filtered\n",
    "\n",
    "    # 正常积分计算\n",
    "    if len(filtered) < 2:\n",
    "        # 经过插值仍不够，返回0\n",
    "        return 0.0\n",
    "\n",
    "    total_energy = 0.0\n",
    "    for i in range(len(filtered)-1):\n",
    "        t1, p1 = filtered[i]\n",
    "        t2, p2 = filtered[i+1]\n",
    "        dt = t2 - t1\n",
    "        avg_p = (p1 + p2)/2.0\n",
    "        total_energy += avg_p * dt\n",
    "\n",
    "    return total_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(net, train_iter, test_iter, num_epochs, lr, device, filename, sampling_interval):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    # print(f'The name of the layers are: {alexlayer}')\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # save all epochs time data using list\n",
    "    to_device_intervals_total = []\n",
    "    forward_intervals_total = []\n",
    "    loss_intervals_total = []\n",
    "    backward_intervals_total = []\n",
    "    optimize_intervals_total = []\n",
    "    test_intervals_total = []\n",
    "\n",
    "    # create a dictionary to store each layer time period data in each batch\n",
    "    layer_time = {}\n",
    "\n",
    "    # create a list to store the epoch time data\n",
    "    epoch_intervals_total = []\n",
    "    \n",
    "    # 初始化NVML和采样线程\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    power_data_queue = queue.Queue()\n",
    "    stop_event = threading.Event()\n",
    "    sampler_thread = threading.Thread(target=nvml_sampling_thread, args=(handle, filename, stop_event, sampling_interval))\n",
    "    sampler_thread.start()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        layer_time[str(epoch)] = {}\n",
    "\n",
    "        print('The epoch is:', epoch+1)\n",
    "        metric = d2l.Accumulator(3)  # train_loss, train_acc, num_examples\n",
    "        to_device_intervals_epoch = []  # 用来记录本epoch每个batch的to_device时间段\n",
    "        forward_intervals_epoch = []  # 用来记录本epoch每个batch的forward时间段\n",
    "        loss_intervals_epoch = []  # 用来记录本epoch每个batch的loss时间段\n",
    "        backward_intervals_epoch = [] \n",
    "        optimize_intervals_epoch = []\n",
    "        test_intervals_epoch = []   \n",
    "        epoch_intervals_epoch = []  # 用来记录本epoch的时间段\n",
    "\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            print('The batch is:', i+1)\n",
    "\n",
    "            layer_time[str(epoch)][str(i)] = {}\n",
    "            optimizer.zero_grad()\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "            # 记录to_device前后的时间戳\n",
    "            start_ttd_time = time.time()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            torch.cuda.synchronize()\n",
    "            end_ttd_time = time.time()\n",
    "            to_device_intervals_epoch.append((start_ttd_time, end_ttd_time))\n",
    "\n",
    "            # forward\n",
    "            start_forward_time = time.time()\n",
    "            y_hat = X\n",
    "\n",
    "            '''alexnet'''\n",
    "            # layer_count = 0\n",
    "\n",
    "            '''resnet18'''\n",
    "            block_count = 0\n",
    "\n",
    "            for block in net:\n",
    "                name = block.__class__.__name__ # get the name of the layer\n",
    "                name_show = name + '_' + str(block_count)\n",
    "                print(f'The name of the layer is: {name_show}')\n",
    "                layer_time[str(epoch)][str(i)][name_show] = {}\n",
    "                '''alexnet'''\n",
    "                # name = name + '_' + str(layer_count)\n",
    "                # layer_count += 1\n",
    "                # if name in layerlist_alexnet:\n",
    "                #     start_layer_time = time.time()\n",
    "                #     y_hat = layer(y_hat)\n",
    "                #     torch.cuda.synchronize()\n",
    "                #     end_layer_time = time.time()\n",
    "                #     layer_time[str(epoch)][str(i)][name] = (start_layer_time, end_layer_time)\n",
    "                '''resnet18'''\n",
    "                if name == 'Sequential':\n",
    "                    resblock_num = 0\n",
    "                    # iterate the subblock in the block\n",
    "                    for subblock in block:\n",
    "                        subblock_name = subblock.__class__.__name__\n",
    "                        # determine if the layer is Residual18\n",
    "                        if subblock_name == 'Residual18':\n",
    "                            # clear the layer_time\n",
    "                            subblock.layer_time = {}\n",
    "                            y_hat = subblock(y_hat)\n",
    "                            torch.cuda.synchronize()\n",
    "                            print(subblock.layer_time)\n",
    "                            subblock_name = subblock_name + '_' + str(resblock_num)\n",
    "                            layer_time[str(epoch)][str(i)][name_show][subblock_name] = subblock.layer_time\n",
    "                        # if the inner layer is not Residual18\n",
    "                        else:\n",
    "                            # print the current layer name\n",
    "                            print(subblock_name)\n",
    "                            start_layer_time = time.time()\n",
    "                            y_hat = subblock(y_hat)\n",
    "                            torch.cuda.synchronize()\n",
    "                            end_layer_time = time.time()\n",
    "                            layer_time[str(epoch)][str(i)][name_show][subblock_name] = (start_layer_time, end_layer_time)\n",
    "                        resblock_num += 1\n",
    "                    block_count += 1\n",
    "                else:\n",
    "                    start_layer_time = time.time()\n",
    "                    y_hat = block(y_hat)\n",
    "                    torch.cuda.synchronize()\n",
    "                    end_layer_time = time.time()\n",
    "                    layer_time[str(epoch)][str(i)][name_show] = (start_layer_time, end_layer_time)\n",
    "\n",
    "            # y_hat = net(X)\n",
    "            # torch.cuda.synchronize()\n",
    "            end_forward_time = time.time()\n",
    "            forward_intervals_epoch.append((start_forward_time, end_forward_time))\n",
    "\n",
    "            # loss\n",
    "            start_loss_time = time.time()\n",
    "            l = loss_fn(y_hat, y)\n",
    "            torch.cuda.synchronize()\n",
    "            end_loss_time = time.time()\n",
    "            loss_intervals_epoch.append((start_loss_time, end_loss_time))\n",
    "\n",
    "            # backward\n",
    "            start_backward_time = time.time()\n",
    "            l.backward()\n",
    "            torch.cuda.synchronize()\n",
    "            end_backward_time = time.time()\n",
    "            backward_intervals_epoch.append((start_backward_time, end_backward_time))\n",
    "\n",
    "            # optimize\n",
    "            start_optimize_time = time.time()\n",
    "            optimizer.step()\n",
    "            torch.cuda.synchronize()\n",
    "            end_optimize_time = time.time()\n",
    "            optimize_intervals_epoch.append((start_optimize_time, end_optimize_time))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                metric.add(l*X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            train_acc = metric[1] / metric[2]\n",
    "\n",
    "        start_test_time = time.time()\n",
    "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n",
    "        end_test_time = time.time()\n",
    "        print(f'train acc {train_acc:.3f}, test acc {test_acc:.3f}')\n",
    "        test_intervals_epoch.append((start_test_time, end_test_time))\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_intervals_epoch.append((epoch_start_time, epoch_end_time))\n",
    "\n",
    "        # data need to be saved\n",
    "        # add the intervals_epoch to intervals_total\n",
    "        to_device_intervals_total.append(to_device_intervals_epoch)\n",
    "        forward_intervals_total.append(forward_intervals_epoch)\n",
    "        loss_intervals_total.append(loss_intervals_epoch)\n",
    "        backward_intervals_total.append(backward_intervals_epoch)\n",
    "        optimize_intervals_total.append(optimize_intervals_epoch)\n",
    "        test_intervals_total.append(test_intervals_epoch)\n",
    "        epoch_intervals_total.append(epoch_intervals_epoch)\n",
    "\n",
    "\n",
    "    # 训练结束后关闭线程\n",
    "    stop_event.set()\n",
    "    sampler_thread.join()\n",
    "\n",
    "    pynvml.nvmlShutdown()\n",
    "\n",
    "    return to_device_intervals_total, forward_intervals_total, loss_intervals_total, backward_intervals_total, optimize_intervals_total, test_intervals_total, epoch_intervals_total, layer_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set a function to train the model with FashionMNIST datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(main_folder, batch_size, num_epochs, round, lr, device, sample_interval, net):\n",
    "    print(f'The epoch is set: {num_epochs}, batch is set: {batch_size}, is in {round+1}th running')\n",
    "    # create the folder to store the data\n",
    "    # epoch_batch_folder = main_folder/f'E{num_epochs}_B{batch_size}_R{round}'\n",
    "    sr_number = int(sample_interval*1000)\n",
    "    epoch_batch_folder = f'E{num_epochs}_B{batch_size}_R{round}_SR{sr_number}_layer'\n",
    "\n",
    "    data_dir = 'fashion_mnist'\n",
    "    # data_dir = 'cifar100'\n",
    "    # data_dir = 'cifar10'\n",
    "\n",
    "    # the folder path is main_folder/epoch_batch_folder\n",
    "    folder_path = main_folder/epoch_batch_folder/data_dir\n",
    "    print(f'The folder path is: {folder_path}')\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n",
    "    # show the shape of the data\n",
    "    list_of_i = []\n",
    "    for i, (X, y) in enumerate(train_iter):\n",
    "        if i < 3:\n",
    "            print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "        else:\n",
    "            pass\n",
    "        list_of_i.append(i)\n",
    "    print(f'The number of batches is: {np.array(list_of_i).shape}')\n",
    "    to_device_intervals_total, forward_intervals_total, loss_intervals_total,\\\n",
    "          backward_intervals_total, optimize_intervals_total, test_intervals_total, epoch_intervals_total, layer_time_alexnet = train_func(net, train_iter, test_iter, num_epochs, lr, device, folder_path, sample_interval)\n",
    "\n",
    "    # transfer the data to the numpy array\n",
    "    to_device_data = np.array(to_device_intervals_total)\n",
    "    forward_time = np.array(forward_intervals_total)\n",
    "    loss_time = np.array(loss_intervals_total)\n",
    "    backward_time = np.array(backward_intervals_total)\n",
    "    optimize_time = np.array(optimize_intervals_total)\n",
    "    test_time = np.array(test_intervals_total)\n",
    "    epoch_time = np.array(epoch_intervals_total)\n",
    "\n",
    "    # save the layer_time_alexnet, the type is a dictionary, need to be saved as a csv file\n",
    "    # the first column is the epoch, the second column is the batch, the third column is the layer name, the fourth column is the start time, the fifth column is the end time\n",
    "    layer_time_alexnet_df = pd.DataFrame.from_dict(layer_time_alexnet)\n",
    "    \n",
    "\n",
    "\n",
    "    # print(layer_time_alexnet_df)\n",
    "\n",
    "    # save the data\n",
    "    np.save(folder_path/'to_device.npy', to_device_data, allow_pickle=True)\n",
    "    np.save(folder_path/'forward.npy', forward_time, allow_pickle=True)\n",
    "    np.save(folder_path/'loss.npy', loss_time, allow_pickle=True)\n",
    "    np.save(folder_path/'backward.npy', backward_time, allow_pickle=True)\n",
    "    np.save(folder_path/'optimize.npy', optimize_time, allow_pickle=True)\n",
    "    np.save(folder_path/'test.npy', test_time, allow_pickle=True)\n",
    "    np.save(folder_path/'epoch.npy', epoch_time, allow_pickle=True)\n",
    "    layer_time_alexnet_df.to_csv(folder_path/'layer_time.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder is: /root/autodl-tmp/GreenAI/3080/ModelsData/resnet18\n",
      "文件存在。\n",
      "The epoch is set: 1, batch is set: 128, is in 1th running\n",
      "The folder path is: /root/autodl-tmp/GreenAI/3080/ModelsData/resnet18/E1_B128_R0_SR2_layer_test/fashion_mnist\n",
      "the shape of the 0 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 1 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 2 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "The number of batches is: (469,)\n",
      "training on cuda\n",
      "The epoch is: 1\n",
      "The batch is: 1\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001895904541015625, 'bn1': 0.0007023811340332031, 'relu1': 0.0003638267517089844, 'conv2': 0.0017926692962646484, 'bn2': 0.0006170272827148438, 'residual_add_relu2': 0.0008046627044677734}\n",
      "{'conv1': 0.0018231868743896484, 'bn1': 0.0006580352783203125, 'relu1': 0.00035500526428222656, 'conv2': 0.0017852783203125, 'bn2': 0.0006132125854492188, 'residual_add_relu2': 0.0007784366607666016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0011663436889648438, 'bn1': 0.00039839744567871094, 'relu1': 0.00020432472229003906, 'conv2': 0.0014767646789550781, 'bn2': 0.0003631114959716797, 'conv3': 0.0004963874816894531, 'residual_add_relu2': 0.0004017353057861328}\n",
      "{'conv1': 0.0014672279357910156, 'bn1': 0.00035953521728515625, 'relu1': 0.0002193450927734375, 'conv2': 0.0014514923095703125, 'bn2': 0.0003662109375, 'residual_add_relu2': 0.0004057884216308594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0012929439544677734, 'bn1': 0.0004787445068359375, 'relu1': 0.00014591217041015625, 'conv2': 0.0013968944549560547, 'bn2': 0.0002892017364501953, 'conv3': 0.00045943260192871094, 'residual_add_relu2': 0.00022983551025390625}\n",
      "{'conv1': 0.0013289451599121094, 'bn1': 0.00026798248291015625, 'relu1': 0.0001239776611328125, 'conv2': 0.00130462646484375, 'bn2': 0.0002510547637939453, 'residual_add_relu2': 0.0002129077911376953}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0007753372192382812, 'bn1': 0.00019311904907226562, 'relu1': 0.00011587142944335938, 'conv2': 0.0013241767883300781, 'bn2': 0.00019311904907226562, 'conv3': 0.00040030479431152344, 'residual_add_relu2': 0.00011706352233886719}\n",
      "{'conv1': 0.00130462646484375, 'bn1': 0.00017309188842773438, 'relu1': 7.390975952148438e-05, 'conv2': 0.0012822151184082031, 'bn2': 0.00017762184143066406, 'residual_add_relu2': 0.00011801719665527344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 2\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0017924308776855469, 'bn1': 0.0006082057952880859, 'relu1': 0.0003376007080078125, 'conv2': 0.0017580986022949219, 'bn2': 0.0005850791931152344, 'residual_add_relu2': 0.0007753372192382812}\n",
      "{'conv1': 0.001764535903930664, 'bn1': 0.0005934238433837891, 'relu1': 0.00033402442932128906, 'conv2': 0.001758575439453125, 'bn2': 0.0005903244018554688, 'residual_add_relu2': 0.000774383544921875}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001129150390625, 'bn1': 0.0003616809844970703, 'relu1': 0.00018262863159179688, 'conv2': 0.0014345645904541016, 'bn2': 0.00033974647521972656, 'conv3': 0.0004322528839111328, 'residual_add_relu2': 0.0003972053527832031}\n",
      "{'conv1': 0.0014393329620361328, 'bn1': 0.0003573894500732422, 'relu1': 0.00018143653869628906, 'conv2': 0.001439809799194336, 'bn2': 0.00035858154296875, 'residual_add_relu2': 0.0003993511199951172}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008730888366699219, 'bn1': 0.0002396106719970703, 'relu1': 0.00010728836059570312, 'conv2': 0.001283884048461914, 'bn2': 0.00022840499877929688, 'conv3': 0.0003726482391357422, 'residual_add_relu2': 0.00021076202392578125}\n",
      "{'conv1': 0.0012857913970947266, 'bn1': 0.00023031234741210938, 'relu1': 0.00010514259338378906, 'conv2': 0.0012743473052978516, 'bn2': 0.00023245811462402344, 'residual_add_relu2': 0.00021028518676757812}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0007307529449462891, 'bn1': 0.00015473365783691406, 'relu1': 6.67572021484375e-05, 'conv2': 0.0012786388397216797, 'bn2': 0.00015783309936523438, 'conv3': 0.00033593177795410156, 'residual_add_relu2': 0.00011706352233886719}\n",
      "{'conv1': 0.0012812614440917969, 'bn1': 0.0001633167266845703, 'relu1': 6.699562072753906e-05, 'conv2': 0.0012698173522949219, 'bn2': 0.00016641616821289062, 'residual_add_relu2': 0.00011610984802246094}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 3\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016531944274902344, 'bn1': 0.0005977153778076172, 'relu1': 0.0003330707550048828, 'conv2': 0.0016295909881591797, 'bn2': 0.0005686283111572266, 'residual_add_relu2': 0.0007765293121337891}\n",
      "{'conv1': 0.0016396045684814453, 'bn1': 0.00057220458984375, 'relu1': 0.0003304481506347656, 'conv2': 0.0016422271728515625, 'bn2': 0.0005726814270019531, 'residual_add_relu2': 0.0007681846618652344}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001058340072631836, 'bn1': 0.00034356117248535156, 'relu1': 0.00018215179443359375, 'conv2': 0.001310110092163086, 'bn2': 0.00036334991455078125, 'conv3': 0.0004150867462158203, 'residual_add_relu2': 0.000396728515625}\n",
      "{'conv1': 0.0013108253479003906, 'bn1': 0.00034546852111816406, 'relu1': 0.00018095970153808594, 'conv2': 0.001306295394897461, 'bn2': 0.0003628730773925781, 'residual_add_relu2': 0.0003952980041503906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007944107055664062, 'bn1': 0.00023102760314941406, 'relu1': 0.00017523765563964844, 'conv2': 0.0011603832244873047, 'bn2': 0.0002238750457763672, 'conv3': 0.00036597251892089844, 'residual_add_relu2': 0.00020885467529296875}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.00022363662719726562, 'relu1': 0.00010538101196289062, 'conv2': 0.001165628433227539, 'bn2': 0.00022411346435546875, 'residual_add_relu2': 0.0002086162567138672}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006763935089111328, 'bn1': 0.00014638900756835938, 'relu1': 6.747245788574219e-05, 'conv2': 0.001149892807006836, 'bn2': 0.00014138221740722656, 'conv3': 0.0003085136413574219, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.0011684894561767578, 'bn1': 0.00016450881958007812, 'relu1': 6.747245788574219e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.00013947486877441406, 'residual_add_relu2': 0.00011467933654785156}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 4\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0017025470733642578, 'bn1': 0.0006361007690429688, 'relu1': 0.0003345012664794922, 'conv2': 0.0016601085662841797, 'bn2': 0.0005884170532226562, 'residual_add_relu2': 0.0007746219635009766}\n",
      "{'conv1': 0.0016551017761230469, 'bn1': 0.0005824565887451172, 'relu1': 0.00033164024353027344, 'conv2': 0.001659393310546875, 'bn2': 0.0006039142608642578, 'residual_add_relu2': 0.0007703304290771484}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010673999786376953, 'bn1': 0.0003552436828613281, 'relu1': 0.00018215179443359375, 'conv2': 0.0013222694396972656, 'bn2': 0.0003426074981689453, 'conv3': 0.0004210472106933594, 'residual_add_relu2': 0.0003979206085205078}\n",
      "{'conv1': 0.0013251304626464844, 'bn1': 0.00038623809814453125, 'relu1': 0.0001876354217529297, 'conv2': 0.0013210773468017578, 'bn2': 0.0003409385681152344, 'residual_add_relu2': 0.0003952980041503906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008080005645751953, 'bn1': 0.00024056434631347656, 'relu1': 0.0001068115234375, 'conv2': 0.0011746883392333984, 'bn2': 0.00024175643920898438, 'conv3': 0.00037217140197753906, 'residual_add_relu2': 0.000209808349609375}\n",
      "{'conv1': 0.0011625289916992188, 'bn1': 0.00022530555725097656, 'relu1': 0.00010609626770019531, 'conv2': 0.0011594295501708984, 'bn2': 0.0002503395080566406, 'residual_add_relu2': 0.00021076202392578125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006730556488037109, 'bn1': 0.00015592575073242188, 'relu1': 6.67572021484375e-05, 'conv2': 0.0011544227600097656, 'bn2': 0.0001456737518310547, 'conv3': 0.0003101825714111328, 'residual_add_relu2': 0.00013208389282226562}\n",
      "{'conv1': 0.0011589527130126953, 'bn1': 0.0001747608184814453, 'relu1': 6.914138793945312e-05, 'conv2': 0.0011539459228515625, 'bn2': 0.000152587890625, 'residual_add_relu2': 0.00011992454528808594}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 5\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016663074493408203, 'bn1': 0.0005807876586914062, 'relu1': 0.00033783912658691406, 'conv2': 0.0016400814056396484, 'bn2': 0.0005996227264404297, 'residual_add_relu2': 0.0007755756378173828}\n",
      "{'conv1': 0.0016469955444335938, 'bn1': 0.0005776882171630859, 'relu1': 0.00033092498779296875, 'conv2': 0.0016369819641113281, 'bn2': 0.0005776882171630859, 'residual_add_relu2': 0.0007681846618652344}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010559558868408203, 'bn1': 0.00033926963806152344, 'relu1': 0.000179290771484375, 'conv2': 0.0013203620910644531, 'bn2': 0.0003597736358642578, 'conv3': 0.0004184246063232422, 'residual_add_relu2': 0.00040411949157714844}\n",
      "{'conv1': 0.0013191699981689453, 'bn1': 0.0003399848937988281, 'relu1': 0.0001811981201171875, 'conv2': 0.0013124942779541016, 'bn2': 0.0003502368927001953, 'residual_add_relu2': 0.0003952980041503906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008018016815185547, 'bn1': 0.000225067138671875, 'relu1': 0.00010514259338378906, 'conv2': 0.0011601448059082031, 'bn2': 0.00022149085998535156, 'conv3': 0.00038361549377441406, 'residual_add_relu2': 0.00021195411682128906}\n",
      "{'conv1': 0.001165151596069336, 'bn1': 0.00022745132446289062, 'relu1': 0.00010943412780761719, 'conv2': 0.0011632442474365234, 'bn2': 0.0002300739288330078, 'residual_add_relu2': 0.00021004676818847656}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006732940673828125, 'bn1': 0.0001678466796875, 'relu1': 6.794929504394531e-05, 'conv2': 0.0011529922485351562, 'bn2': 0.00014138221740722656, 'conv3': 0.0003066062927246094, 'residual_add_relu2': 0.00012111663818359375}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00014901161193847656, 'relu1': 6.556510925292969e-05, 'conv2': 0.0011644363403320312, 'bn2': 0.00014472007751464844, 'residual_add_relu2': 0.00011467933654785156}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 6\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016756057739257812, 'bn1': 0.000598907470703125, 'relu1': 0.0003333091735839844, 'conv2': 0.0016396045684814453, 'bn2': 0.0005655288696289062, 'residual_add_relu2': 0.0007719993591308594}\n",
      "{'conv1': 0.0016515254974365234, 'bn1': 0.0005805492401123047, 'relu1': 0.0003361701965332031, 'conv2': 0.0016407966613769531, 'bn2': 0.0005810260772705078, 'residual_add_relu2': 0.0007703304290771484}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.00106048583984375, 'bn1': 0.00034737586975097656, 'relu1': 0.0001842975616455078, 'conv2': 0.0013175010681152344, 'bn2': 0.0003573894500732422, 'conv3': 0.00041961669921875, 'residual_add_relu2': 0.00039649009704589844}\n",
      "{'conv1': 0.0013179779052734375, 'bn1': 0.00036025047302246094, 'relu1': 0.00019431114196777344, 'conv2': 0.0013234615325927734, 'bn2': 0.00034546852111816406, 'residual_add_relu2': 0.00039649009704589844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008022785186767578, 'bn1': 0.0002257823944091797, 'relu1': 0.00010538101196289062, 'conv2': 0.001161336898803711, 'bn2': 0.00022649765014648438, 'conv3': 0.0003662109375, 'residual_add_relu2': 0.00020885467529296875}\n",
      "{'conv1': 0.0011682510375976562, 'bn1': 0.0002243518829345703, 'relu1': 0.00010585784912109375, 'conv2': 0.0011601448059082031, 'bn2': 0.00023436546325683594, 'residual_add_relu2': 0.00021076202392578125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006763935089111328, 'bn1': 0.0001621246337890625, 'relu1': 6.866455078125e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00015401840209960938, 'conv3': 0.00031185150146484375, 'residual_add_relu2': 0.00011539459228515625}\n",
      "{'conv1': 0.0011560916900634766, 'bn1': 0.0001647472381591797, 'relu1': 6.747245788574219e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.0001685619354248047, 'residual_add_relu2': 0.00011658668518066406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 7\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016748905181884766, 'bn1': 0.0005936622619628906, 'relu1': 0.0003330707550048828, 'conv2': 0.001661062240600586, 'bn2': 0.0006070137023925781, 'residual_add_relu2': 0.0007719993591308594}\n",
      "{'conv1': 0.0016436576843261719, 'bn1': 0.0005927085876464844, 'relu1': 0.00033974647521972656, 'conv2': 0.0016541481018066406, 'bn2': 0.0005800724029541016, 'residual_add_relu2': 0.0007688999176025391}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010631084442138672, 'bn1': 0.0003426074981689453, 'relu1': 0.00018095970153808594, 'conv2': 0.00131988525390625, 'bn2': 0.00033354759216308594, 'conv3': 0.00043845176696777344, 'residual_add_relu2': 0.0003986358642578125}\n",
      "{'conv1': 0.0013294219970703125, 'bn1': 0.0003542900085449219, 'relu1': 0.00018262863159179688, 'conv2': 0.0013229846954345703, 'bn2': 0.00035643577575683594, 'residual_add_relu2': 0.0003962516784667969}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008094310760498047, 'bn1': 0.00022745132446289062, 'relu1': 0.00010561943054199219, 'conv2': 0.0011646747589111328, 'bn2': 0.00022792816162109375, 'conv3': 0.00036716461181640625, 'residual_add_relu2': 0.0002117156982421875}\n",
      "{'conv1': 0.0011894702911376953, 'bn1': 0.0002338886260986328, 'relu1': 0.00010514259338378906, 'conv2': 0.0011615753173828125, 'bn2': 0.0002181529998779297, 'residual_add_relu2': 0.00021123886108398438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006754398345947266, 'bn1': 0.00019598007202148438, 'relu1': 7.319450378417969e-05, 'conv2': 0.001163482666015625, 'bn2': 0.00015401840209960938, 'conv3': 0.000308990478515625, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.0001468658447265625, 'relu1': 6.628036499023438e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00016880035400390625, 'residual_add_relu2': 0.00011539459228515625}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 8\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016601085662841797, 'bn1': 0.0005910396575927734, 'relu1': 0.00033545494079589844, 'conv2': 0.0016448497772216797, 'bn2': 0.0005676746368408203, 'residual_add_relu2': 0.0007722377777099609}\n",
      "{'conv1': 0.0016450881958007812, 'bn1': 0.0005781650543212891, 'relu1': 0.0003314018249511719, 'conv2': 0.0016374588012695312, 'bn2': 0.0005786418914794922, 'residual_add_relu2': 0.0007736682891845703}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010619163513183594, 'bn1': 0.0003428459167480469, 'relu1': 0.00018072128295898438, 'conv2': 0.0013179779052734375, 'bn2': 0.0003380775451660156, 'conv3': 0.000415802001953125, 'residual_add_relu2': 0.0003955364227294922}\n",
      "{'conv1': 0.0013191699981689453, 'bn1': 0.0003466606140136719, 'relu1': 0.00018072128295898438, 'conv2': 0.0013163089752197266, 'bn2': 0.0003521442413330078, 'residual_add_relu2': 0.00039768218994140625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008013248443603516, 'bn1': 0.0002486705780029297, 'relu1': 0.00010776519775390625, 'conv2': 0.0011646747589111328, 'bn2': 0.0002238750457763672, 'conv3': 0.0003681182861328125, 'residual_add_relu2': 0.0002110004425048828}\n",
      "{'conv1': 0.0011687278747558594, 'bn1': 0.0002269744873046875, 'relu1': 0.0001049041748046875, 'conv2': 0.0011615753173828125, 'bn2': 0.0002186298370361328, 'residual_add_relu2': 0.0002086162567138672}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006816387176513672, 'bn1': 0.0001766681671142578, 'relu1': 6.961822509765625e-05, 'conv2': 0.0011637210845947266, 'bn2': 0.0001423358917236328, 'conv3': 0.0003046989440917969, 'residual_add_relu2': 0.00011539459228515625}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00016880035400390625, 'relu1': 6.794929504394531e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.0001621246337890625, 'residual_add_relu2': 0.00011587142944335938}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 9\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016789436340332031, 'bn1': 0.0005936622619628906, 'relu1': 0.0003306865692138672, 'conv2': 0.0016415119171142578, 'bn2': 0.0005903244018554688, 'residual_add_relu2': 0.00077056884765625}\n",
      "{'conv1': 0.001650094985961914, 'bn1': 0.0005738735198974609, 'relu1': 0.00033211708068847656, 'conv2': 0.001641988754272461, 'bn2': 0.000568389892578125, 'residual_add_relu2': 0.0007677078247070312}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010704994201660156, 'bn1': 0.0003578662872314453, 'relu1': 0.00018095970153808594, 'conv2': 0.001317739486694336, 'bn2': 0.0003466606140136719, 'conv3': 0.0004184246063232422, 'residual_add_relu2': 0.0003979206085205078}\n",
      "{'conv1': 0.001321554183959961, 'bn1': 0.00036215782165527344, 'relu1': 0.00018095970153808594, 'conv2': 0.0013141632080078125, 'bn2': 0.0003459453582763672, 'residual_add_relu2': 0.00039696693420410156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008053779602050781, 'bn1': 0.0002465248107910156, 'relu1': 0.00010800361633300781, 'conv2': 0.001173257827758789, 'bn2': 0.00022268295288085938, 'conv3': 0.0003674030303955078, 'residual_add_relu2': 0.0002090930938720703}\n",
      "{'conv1': 0.0011684894561767578, 'bn1': 0.0002570152282714844, 'relu1': 0.0001087188720703125, 'conv2': 0.0011675357818603516, 'bn2': 0.00023221969604492188, 'residual_add_relu2': 0.00021004676818847656}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006725788116455078, 'bn1': 0.000148773193359375, 'relu1': 6.723403930664062e-05, 'conv2': 0.0011529922485351562, 'bn2': 0.0001468658447265625, 'conv3': 0.00030350685119628906, 'residual_add_relu2': 0.00011467933654785156}\n",
      "{'conv1': 0.0011553764343261719, 'bn1': 0.00014662742614746094, 'relu1': 6.771087646484375e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00014925003051757812, 'residual_add_relu2': 0.00011467933654785156}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 10\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016753673553466797, 'bn1': 0.0005958080291748047, 'relu1': 0.0003490447998046875, 'conv2': 0.0016596317291259766, 'bn2': 0.0005772113800048828, 'residual_add_relu2': 0.0007760524749755859}\n",
      "{'conv1': 0.0016477108001708984, 'bn1': 0.0005898475646972656, 'relu1': 0.0003337860107421875, 'conv2': 0.0016551017761230469, 'bn2': 0.0005669593811035156, 'residual_add_relu2': 0.0007712841033935547}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010807514190673828, 'bn1': 0.00035190582275390625, 'relu1': 0.00018072128295898438, 'conv2': 0.0013189315795898438, 'bn2': 0.0003631114959716797, 'conv3': 0.0004239082336425781, 'residual_add_relu2': 0.0003952980041503906}\n",
      "{'conv1': 0.0013303756713867188, 'bn1': 0.0003559589385986328, 'relu1': 0.00018405914306640625, 'conv2': 0.0013213157653808594, 'bn2': 0.0003418922424316406, 'residual_add_relu2': 0.0003960132598876953}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008032321929931641, 'bn1': 0.00023102760314941406, 'relu1': 0.00010728836059570312, 'conv2': 0.0011644363403320312, 'bn2': 0.00022029876708984375, 'conv3': 0.0003871917724609375, 'residual_add_relu2': 0.00021219253540039062}\n",
      "{'conv1': 0.0011720657348632812, 'bn1': 0.00022840499877929688, 'relu1': 0.0001049041748046875, 'conv2': 0.0011615753173828125, 'bn2': 0.0002224445343017578, 'residual_add_relu2': 0.0002143383026123047}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0007112026214599609, 'bn1': 0.00017261505126953125, 'relu1': 6.866455078125e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.00014209747314453125, 'conv3': 0.0003037452697753906, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.0011751651763916016, 'bn1': 0.00015306472778320312, 'relu1': 6.890296936035156e-05, 'conv2': 0.0011699199676513672, 'bn2': 0.00014710426330566406, 'residual_add_relu2': 0.00011467933654785156}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 11\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016627311706542969, 'bn1': 0.0005853176116943359, 'relu1': 0.0003325939178466797, 'conv2': 0.001645803451538086, 'bn2': 0.0005700588226318359, 'residual_add_relu2': 0.0007739067077636719}\n",
      "{'conv1': 0.0016570091247558594, 'bn1': 0.0005733966827392578, 'relu1': 0.0003371238708496094, 'conv2': 0.0016460418701171875, 'bn2': 0.0005717277526855469, 'residual_add_relu2': 0.0007693767547607422}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010623931884765625, 'bn1': 0.0003390312194824219, 'relu1': 0.00017905235290527344, 'conv2': 0.0013153553009033203, 'bn2': 0.0003662109375, 'conv3': 0.0004189014434814453, 'residual_add_relu2': 0.000396728515625}\n",
      "{'conv1': 0.0013203620910644531, 'bn1': 0.0003421306610107422, 'relu1': 0.0001823902130126953, 'conv2': 0.0013375282287597656, 'bn2': 0.0003497600555419922, 'residual_add_relu2': 0.0003974437713623047}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008008480072021484, 'bn1': 0.00022721290588378906, 'relu1': 0.00010538101196289062, 'conv2': 0.001163482666015625, 'bn2': 0.0002231597900390625, 'conv3': 0.0003685951232910156, 'residual_add_relu2': 0.0002090930938720703}\n",
      "{'conv1': 0.001165151596069336, 'bn1': 0.00022459030151367188, 'relu1': 0.00010538101196289062, 'conv2': 0.0011632442474365234, 'bn2': 0.0002570152282714844, 'residual_add_relu2': 0.0002105236053466797}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006730556488037109, 'bn1': 0.0001456737518310547, 'relu1': 6.580352783203125e-05, 'conv2': 0.001154184341430664, 'bn2': 0.00014853477478027344, 'conv3': 0.0003113746643066406, 'residual_add_relu2': 0.00011849403381347656}\n",
      "{'conv1': 0.0011594295501708984, 'bn1': 0.00015091896057128906, 'relu1': 6.747245788574219e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.0001392364501953125, 'residual_add_relu2': 0.00011467933654785156}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 12\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016679763793945312, 'bn1': 0.0006268024444580078, 'relu1': 0.00033783912658691406, 'conv2': 0.0016498565673828125, 'bn2': 0.0005753040313720703, 'residual_add_relu2': 0.00077056884765625}\n",
      "{'conv1': 0.0016546249389648438, 'bn1': 0.0005786418914794922, 'relu1': 0.0003292560577392578, 'conv2': 0.0016450881958007812, 'bn2': 0.0006029605865478516, 'residual_add_relu2': 0.0007700920104980469}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001070261001586914, 'bn1': 0.0003540515899658203, 'relu1': 0.0001804828643798828, 'conv2': 0.0013213157653808594, 'bn2': 0.0003376007080078125, 'conv3': 0.0004162788391113281, 'residual_add_relu2': 0.0003933906555175781}\n",
      "{'conv1': 0.0013170242309570312, 'bn1': 0.00033855438232421875, 'relu1': 0.0001800060272216797, 'conv2': 0.0013127326965332031, 'bn2': 0.0003590583801269531, 'residual_add_relu2': 0.0003986358642578125}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008099079132080078, 'bn1': 0.00022864341735839844, 'relu1': 0.00010514259338378906, 'conv2': 0.0011835098266601562, 'bn2': 0.00023436546325683594, 'conv3': 0.0003705024719238281, 'residual_add_relu2': 0.00021004676818847656}\n",
      "{'conv1': 0.0011637210845947266, 'bn1': 0.0002269744873046875, 'relu1': 0.00010442733764648438, 'conv2': 0.0011594295501708984, 'bn2': 0.0002181529998779297, 'residual_add_relu2': 0.000209808349609375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006754398345947266, 'bn1': 0.00016736984252929688, 'relu1': 6.699562072753906e-05, 'conv2': 0.001153707504272461, 'bn2': 0.00014162063598632812, 'conv3': 0.00030517578125, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.0011591911315917969, 'bn1': 0.00019097328186035156, 'relu1': 7.414817810058594e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.00015425682067871094, 'residual_add_relu2': 0.00011682510375976562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 13\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016574859619140625, 'bn1': 0.0005872249603271484, 'relu1': 0.0003345012664794922, 'conv2': 0.0016524791717529297, 'bn2': 0.0005781650543212891, 'residual_add_relu2': 0.0007734298706054688}\n",
      "{'conv1': 0.0016481876373291016, 'bn1': 0.0005834102630615234, 'relu1': 0.00033092498779296875, 'conv2': 0.00164031982421875, 'bn2': 0.0005693435668945312, 'residual_add_relu2': 0.0007846355438232422}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010633468627929688, 'bn1': 0.00034427642822265625, 'relu1': 0.00018024444580078125, 'conv2': 0.0013163089752197266, 'bn2': 0.00038433074951171875, 'conv3': 0.0004410743713378906, 'residual_add_relu2': 0.00040030479431152344}\n",
      "{'conv1': 0.001323699951171875, 'bn1': 0.00034809112548828125, 'relu1': 0.0001811981201171875, 'conv2': 0.001313924789428711, 'bn2': 0.0003383159637451172, 'residual_add_relu2': 0.0003948211669921875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007996559143066406, 'bn1': 0.000225067138671875, 'relu1': 0.00010561943054199219, 'conv2': 0.0011632442474365234, 'bn2': 0.0002484321594238281, 'conv3': 0.00036978721618652344, 'residual_add_relu2': 0.00021076202392578125}\n",
      "{'conv1': 0.001180887222290039, 'bn1': 0.00023317337036132812, 'relu1': 0.00010609626770019531, 'conv2': 0.0011620521545410156, 'bn2': 0.00024127960205078125, 'residual_add_relu2': 0.00020956993103027344}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006754398345947266, 'bn1': 0.00017452239990234375, 'relu1': 6.818771362304688e-05, 'conv2': 0.0011589527130126953, 'bn2': 0.00014781951904296875, 'conv3': 0.000308990478515625, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.0011589527130126953, 'bn1': 0.0001468658447265625, 'relu1': 6.651878356933594e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.0001533031463623047, 'residual_add_relu2': 0.00011563301086425781}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 14\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016703605651855469, 'bn1': 0.0006279945373535156, 'relu1': 0.000335693359375, 'conv2': 0.0016405582427978516, 'bn2': 0.0005793571472167969, 'residual_add_relu2': 0.0007734298706054688}\n",
      "{'conv1': 0.0016646385192871094, 'bn1': 0.0005903244018554688, 'relu1': 0.0003352165222167969, 'conv2': 0.001636505126953125, 'bn2': 0.0005900859832763672, 'residual_add_relu2': 0.0007710456848144531}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010619163513183594, 'bn1': 0.00034308433532714844, 'relu1': 0.0001842975616455078, 'conv2': 0.0013229846954345703, 'bn2': 0.00034928321838378906, 'conv3': 0.0004208087921142578, 'residual_add_relu2': 0.00039505958557128906}\n",
      "{'conv1': 0.0013206005096435547, 'bn1': 0.0003478527069091797, 'relu1': 0.0001881122589111328, 'conv2': 0.0013265609741210938, 'bn2': 0.0003561973571777344, 'residual_add_relu2': 0.00039505958557128906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008037090301513672, 'bn1': 0.00023055076599121094, 'relu1': 0.00010514259338378906, 'conv2': 0.0011682510375976562, 'bn2': 0.00024437904357910156, 'conv3': 0.0003781318664550781, 'residual_add_relu2': 0.000209808349609375}\n",
      "{'conv1': 0.0011749267578125, 'bn1': 0.00022864341735839844, 'relu1': 0.00010514259338378906, 'conv2': 0.0011601448059082031, 'bn2': 0.00022411346435546875, 'residual_add_relu2': 0.00021767616271972656}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006885528564453125, 'bn1': 0.00016069412231445312, 'relu1': 6.771087646484375e-05, 'conv2': 0.0011587142944335938, 'bn2': 0.00015425682067871094, 'conv3': 0.0003147125244140625, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.0011661052703857422, 'bn1': 0.0001621246337890625, 'relu1': 6.67572021484375e-05, 'conv2': 0.001154184341430664, 'bn2': 0.00014352798461914062, 'residual_add_relu2': 0.00011491775512695312}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 15\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016632080078125, 'bn1': 0.0005941390991210938, 'relu1': 0.0003345012664794922, 'conv2': 0.0016341209411621094, 'bn2': 0.000576019287109375, 'residual_add_relu2': 0.0007717609405517578}\n",
      "{'conv1': 0.0016474723815917969, 'bn1': 0.0005743503570556641, 'relu1': 0.00033092498779296875, 'conv2': 0.001636505126953125, 'bn2': 0.0005886554718017578, 'residual_add_relu2': 0.0007669925689697266}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010633468627929688, 'bn1': 0.0003399848937988281, 'relu1': 0.00018024444580078125, 'conv2': 0.0013165473937988281, 'bn2': 0.00036978721618652344, 'conv3': 0.00041675567626953125, 'residual_add_relu2': 0.0003955364227294922}\n",
      "{'conv1': 0.0013251304626464844, 'bn1': 0.00035262107849121094, 'relu1': 0.00019168853759765625, 'conv2': 0.0013318061828613281, 'bn2': 0.0003407001495361328, 'residual_add_relu2': 0.00039577484130859375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008118152618408203, 'bn1': 0.0002353191375732422, 'relu1': 0.00010752677917480469, 'conv2': 0.001955747604370117, 'bn2': 0.0002906322479248047, 'conv3': 0.00038170814514160156, 'residual_add_relu2': 0.0002117156982421875}\n",
      "{'conv1': 0.0011692047119140625, 'bn1': 0.0002384185791015625, 'relu1': 0.00010943412780761719, 'conv2': 0.0011925697326660156, 'bn2': 0.00023698806762695312, 'residual_add_relu2': 0.00021147727966308594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006747245788574219, 'bn1': 0.00015401840209960938, 'relu1': 7.081031799316406e-05, 'conv2': 0.001154184341430664, 'bn2': 0.00014591217041015625, 'conv3': 0.000308990478515625, 'residual_add_relu2': 0.000125885009765625}\n",
      "{'conv1': 0.0011730194091796875, 'bn1': 0.00015878677368164062, 'relu1': 6.67572021484375e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.0001418590545654297, 'residual_add_relu2': 0.00011444091796875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 16\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001657247543334961, 'bn1': 0.0005881786346435547, 'relu1': 0.0003337860107421875, 'conv2': 0.0016443729400634766, 'bn2': 0.0005784034729003906, 'residual_add_relu2': 0.0007715225219726562}\n",
      "{'conv1': 0.0016477108001708984, 'bn1': 0.0005781650543212891, 'relu1': 0.0003311634063720703, 'conv2': 0.001641988754272461, 'bn2': 0.0005733966827392578, 'residual_add_relu2': 0.0007703304290771484}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010616779327392578, 'bn1': 0.00034236907958984375, 'relu1': 0.00018477439880371094, 'conv2': 0.0013265609741210938, 'bn2': 0.00034356117248535156, 'conv3': 0.0004360675811767578, 'residual_add_relu2': 0.00039696693420410156}\n",
      "{'conv1': 0.001321554183959961, 'bn1': 0.0003414154052734375, 'relu1': 0.00019025802612304688, 'conv2': 0.0013203620910644531, 'bn2': 0.00034546852111816406, 'residual_add_relu2': 0.0003962516784667969}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007989406585693359, 'bn1': 0.0002257823944091797, 'relu1': 0.00010609626770019531, 'conv2': 0.001165151596069336, 'bn2': 0.0002353191375732422, 'conv3': 0.0003705024719238281, 'residual_add_relu2': 0.00020933151245117188}\n",
      "{'conv1': 0.0011692047119140625, 'bn1': 0.0002346038818359375, 'relu1': 0.00010609626770019531, 'conv2': 0.0011637210845947266, 'bn2': 0.00022530555725097656, 'residual_add_relu2': 0.00020956993103027344}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006704330444335938, 'bn1': 0.00014734268188476562, 'relu1': 6.556510925292969e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00015044212341308594, 'conv3': 0.00030612945556640625, 'residual_add_relu2': 0.00011992454528808594}\n",
      "{'conv1': 0.001163482666015625, 'bn1': 0.00015974044799804688, 'relu1': 6.628036499023438e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00014090538024902344, 'residual_add_relu2': 0.00011444091796875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 17\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001688241958618164, 'bn1': 0.0005970001220703125, 'relu1': 0.00033354759216308594, 'conv2': 0.0016376972198486328, 'bn2': 0.0005669593811035156, 'residual_add_relu2': 0.0007734298706054688}\n",
      "{'conv1': 0.0016474723815917969, 'bn1': 0.0005812644958496094, 'relu1': 0.0003342628479003906, 'conv2': 0.0016486644744873047, 'bn2': 0.0005726814270019531, 'residual_add_relu2': 0.00077056884765625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010683536529541016, 'bn1': 0.0003509521484375, 'relu1': 0.0001811981201171875, 'conv2': 0.0013179779052734375, 'bn2': 0.000339508056640625, 'conv3': 0.00041604042053222656, 'residual_add_relu2': 0.0003993511199951172}\n",
      "{'conv1': 0.001329183578491211, 'bn1': 0.0003528594970703125, 'relu1': 0.0001857280731201172, 'conv2': 0.0013203620910644531, 'bn2': 0.0003514289855957031, 'residual_add_relu2': 0.00039649009704589844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008032321929931641, 'bn1': 0.00024008750915527344, 'relu1': 0.00010585784912109375, 'conv2': 0.0011641979217529297, 'bn2': 0.00023293495178222656, 'conv3': 0.0003705024719238281, 'residual_add_relu2': 0.0002090930938720703}\n",
      "{'conv1': 0.0011644363403320312, 'bn1': 0.00022482872009277344, 'relu1': 0.00010538101196289062, 'conv2': 0.0011625289916992188, 'bn2': 0.0002231597900390625, 'residual_add_relu2': 0.000209808349609375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006916522979736328, 'bn1': 0.00016069412231445312, 'relu1': 7.104873657226562e-05, 'conv2': 0.0011632442474365234, 'bn2': 0.00015473365783691406, 'conv3': 0.00031065940856933594, 'residual_add_relu2': 0.00011658668518066406}\n",
      "{'conv1': 0.0011746883392333984, 'bn1': 0.0001537799835205078, 'relu1': 6.67572021484375e-05, 'conv2': 0.0011539459228515625, 'bn2': 0.0001518726348876953, 'residual_add_relu2': 0.00011587142944335938}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 18\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016341209411621094, 'bn1': 0.0005571842193603516, 'relu1': 0.0003218650817871094, 'conv2': 0.001611948013305664, 'bn2': 0.0005283355712890625, 'residual_add_relu2': 0.0007622241973876953}\n",
      "{'conv1': 0.0016255378723144531, 'bn1': 0.0005319118499755859, 'relu1': 0.0003211498260498047, 'conv2': 0.0016145706176757812, 'bn2': 0.0005261898040771484, 'residual_add_relu2': 0.0007665157318115234}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010416507720947266, 'bn1': 0.0003046989440917969, 'relu1': 0.00017023086547851562, 'conv2': 0.0012960433959960938, 'bn2': 0.00029921531677246094, 'conv3': 0.000392913818359375, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0012962818145751953, 'bn1': 0.0003056526184082031, 'relu1': 0.00017023086547851562, 'conv2': 0.0012955665588378906, 'bn2': 0.0003018379211425781, 'residual_add_relu2': 0.00038814544677734375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007917881011962891, 'bn1': 0.00020766258239746094, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011501312255859375, 'bn2': 0.0001938343048095703, 'conv3': 0.00035071372985839844, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011501312255859375, 'bn1': 0.0002002716064453125, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006549358367919922, 'bn1': 0.00011897087097167969, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011382102966308594, 'bn2': 0.00011277198791503906, 'conv3': 0.00028967857360839844, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.00115203857421875, 'bn1': 0.00012159347534179688, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011363029479980469, 'bn2': 0.00011420249938964844, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 19\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016465187072753906, 'bn1': 0.0005519390106201172, 'relu1': 0.0003237724304199219, 'conv2': 0.001630544662475586, 'bn2': 0.0005450248718261719, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016372203826904297, 'bn1': 0.0005345344543457031, 'relu1': 0.0003218650817871094, 'conv2': 0.0016264915466308594, 'bn2': 0.0005280971527099609, 'residual_add_relu2': 0.0007610321044921875}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010399818420410156, 'bn1': 0.0003132820129394531, 'relu1': 0.0001728534698486328, 'conv2': 0.0012996196746826172, 'bn2': 0.000301361083984375, 'conv3': 0.0003936290740966797, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0012981891632080078, 'bn1': 0.0003142356872558594, 'relu1': 0.0001728534698486328, 'conv2': 0.001300811767578125, 'bn2': 0.0003070831298828125, 'residual_add_relu2': 0.00039267539978027344}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007841587066650391, 'bn1': 0.00019788742065429688, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.0001952648162841797, 'conv3': 0.00035119056701660156, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.001150369644165039, 'bn1': 0.00019812583923339844, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.00020313262939453125, 'residual_add_relu2': 0.00020575523376464844}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006589889526367188, 'bn1': 0.00012040138244628906, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011391639709472656, 'bn2': 0.00011372566223144531, 'conv3': 0.0002925395965576172, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011446475982666016, 'bn1': 0.00012111663818359375, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011382102966308594, 'bn2': 0.00011396408081054688, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 20\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016388893127441406, 'bn1': 0.0005552768707275391, 'relu1': 0.0003235340118408203, 'conv2': 0.0016298294067382812, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016231536865234375, 'bn1': 0.0005414485931396484, 'relu1': 0.00032210350036621094, 'conv2': 0.0016171932220458984, 'bn2': 0.0005283355712890625, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010426044464111328, 'bn1': 0.00030493736267089844, 'relu1': 0.0001704692840576172, 'conv2': 0.0012967586517333984, 'bn2': 0.0003101825714111328, 'conv3': 0.00039887428283691406, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013012886047363281, 'bn1': 0.0003108978271484375, 'relu1': 0.0001723766326904297, 'conv2': 0.001298666000366211, 'bn2': 0.00031065940856933594, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007841587066650391, 'bn1': 0.00019669532775878906, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.0001926422119140625, 'conv3': 0.0003504753112792969, 'residual_add_relu2': 0.00020766258239746094}\n",
      "{'conv1': 0.0011548995971679688, 'bn1': 0.00020003318786621094, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011472702026367188, 'bn2': 0.00019240379333496094, 'residual_add_relu2': 0.00020813941955566406}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006577968597412109, 'bn1': 0.00012373924255371094, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011398792266845703, 'bn2': 0.00011372566223144531, 'conv3': 0.0002911090850830078, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011439323425292969, 'bn1': 0.00014781951904296875, 'relu1': 6.270408630371094e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.0001289844512939453, 'residual_add_relu2': 0.00011229515075683594}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 21\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016326904296875, 'bn1': 0.0005538463592529297, 'relu1': 0.0003235340118408203, 'conv2': 0.001626729965209961, 'bn2': 0.0005445480346679688, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016262531280517578, 'bn1': 0.0005452632904052734, 'relu1': 0.00032329559326171875, 'conv2': 0.0016257762908935547, 'bn2': 0.0005376338958740234, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010437965393066406, 'bn1': 0.0003161430358886719, 'relu1': 0.000171661376953125, 'conv2': 0.0013020038604736328, 'bn2': 0.0003066062927246094, 'conv3': 0.0003998279571533203, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013072490692138672, 'bn1': 0.0003173351287841797, 'relu1': 0.0001735687255859375, 'conv2': 0.0013132095336914062, 'bn2': 0.00031495094299316406, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007867813110351562, 'bn1': 0.00019860267639160156, 'relu1': 9.894371032714844e-05, 'conv2': 0.001149892807006836, 'bn2': 0.00019431114196777344, 'conv3': 0.0003504753112792969, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0011506080627441406, 'bn1': 0.0002009868621826172, 'relu1': 9.775161743164062e-05, 'conv2': 0.001146078109741211, 'bn2': 0.00021314620971679688, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006558895111083984, 'bn1': 0.00012135505676269531, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011408329010009766, 'bn2': 0.00012111663818359375, 'conv3': 0.00029206275939941406, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011394023895263672, 'bn1': 0.00011849403381347656, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011360645294189453, 'bn2': 0.00011467933654785156, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 22\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001657724380493164, 'bn1': 0.0005795955657958984, 'relu1': 0.0003314018249511719, 'conv2': 0.001638174057006836, 'bn2': 0.0005574226379394531, 'residual_add_relu2': 0.0007700920104980469}\n",
      "{'conv1': 0.0016374588012695312, 'bn1': 0.0005688667297363281, 'relu1': 0.0003273487091064453, 'conv2': 0.0016331672668457031, 'bn2': 0.0005505084991455078, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010540485382080078, 'bn1': 0.00032973289489746094, 'relu1': 0.00017547607421875, 'conv2': 0.0013074874877929688, 'bn2': 0.0003287792205810547, 'conv3': 0.0004096031188964844, 'residual_add_relu2': 0.0003936290740966797}\n",
      "{'conv1': 0.001312255859375, 'bn1': 0.0003311634063720703, 'relu1': 0.000179290771484375, 'conv2': 0.0013115406036376953, 'bn2': 0.0003218650817871094, 'residual_add_relu2': 0.00039315223693847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007951259613037109, 'bn1': 0.00021004676818847656, 'relu1': 0.00010466575622558594, 'conv2': 0.001157999038696289, 'bn2': 0.00020933151245117188, 'conv3': 0.0003600120544433594, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.001157999038696289, 'bn1': 0.00021123886108398438, 'relu1': 0.0001010894775390625, 'conv2': 0.0011510848999023438, 'bn2': 0.0002086162567138672, 'residual_add_relu2': 0.00020647048950195312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006663799285888672, 'bn1': 0.00013947486877441406, 'relu1': 6.318092346191406e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.00012540817260742188, 'conv3': 0.0003018379211425781, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.0011510848999023438, 'bn1': 0.00014162063598632812, 'relu1': 6.604194641113281e-05, 'conv2': 0.0011470317840576172, 'bn2': 0.000125885009765625, 'residual_add_relu2': 0.00011205673217773438}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 23\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016429424285888672, 'bn1': 0.000560760498046875, 'relu1': 0.0003266334533691406, 'conv2': 0.0016248226165771484, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016300678253173828, 'bn1': 0.0005483627319335938, 'relu1': 0.0003228187561035156, 'conv2': 0.001619577407836914, 'bn2': 0.0005464553833007812, 'residual_add_relu2': 0.0007703304290771484}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010485649108886719, 'bn1': 0.00032329559326171875, 'relu1': 0.0001747608184814453, 'conv2': 0.0013060569763183594, 'bn2': 0.0003170967102050781, 'conv3': 0.0004029273986816406, 'residual_add_relu2': 0.00039315223693847656}\n",
      "{'conv1': 0.0013108253479003906, 'bn1': 0.0003216266632080078, 'relu1': 0.00017595291137695312, 'conv2': 0.0013039112091064453, 'bn2': 0.0003151893615722656, 'residual_add_relu2': 0.00039196014404296875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007925033569335938, 'bn1': 0.00021123886108398438, 'relu1': 0.00010132789611816406, 'conv2': 0.0011525154113769531, 'bn2': 0.00020170211791992188, 'conv3': 0.0003573894500732422, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00021028518676757812, 'relu1': 0.00010132789611816406, 'conv2': 0.0011518001556396484, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006537437438964844, 'bn1': 0.00012040138244628906, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011394023895263672, 'bn2': 0.00011706352233886719, 'conv3': 0.00029206275939941406, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011417865753173828, 'bn1': 0.0001316070556640625, 'relu1': 6.198883056640625e-05, 'conv2': 0.0011425018310546875, 'bn2': 0.00012302398681640625, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 24\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016417503356933594, 'bn1': 0.0005588531494140625, 'relu1': 0.0003247261047363281, 'conv2': 0.0016200542449951172, 'bn2': 0.0005435943603515625, 'residual_add_relu2': 0.0007681846618652344}\n",
      "{'conv1': 0.0016317367553710938, 'bn1': 0.0005574226379394531, 'relu1': 0.0003249645233154297, 'conv2': 0.0016193389892578125, 'bn2': 0.000545501708984375, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010418891906738281, 'bn1': 0.0003376007080078125, 'relu1': 0.00017452239990234375, 'conv2': 0.0013093948364257812, 'bn2': 0.00031757354736328125, 'conv3': 0.000408172607421875, 'residual_add_relu2': 0.000392913818359375}\n",
      "{'conv1': 0.001306295394897461, 'bn1': 0.00031828880310058594, 'relu1': 0.00017309188842773438, 'conv2': 0.0013022422790527344, 'bn2': 0.0003147125244140625, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007863044738769531, 'bn1': 0.0001995563507080078, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.00019788742065429688, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011506080627441406, 'bn1': 0.00020456314086914062, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011470317840576172, 'bn2': 0.00019407272338867188, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006606578826904297, 'bn1': 0.00012254714965820312, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011396408081054688, 'bn2': 0.00011944770812988281, 'conv3': 0.00029659271240234375, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011410713195800781, 'bn1': 0.00012135505676269531, 'relu1': 5.8650970458984375e-05, 'conv2': 0.00113677978515625, 'bn2': 0.0001289844512939453, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 25\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016355514526367188, 'bn1': 0.0005540847778320312, 'relu1': 0.00032520294189453125, 'conv2': 0.0016245841979980469, 'bn2': 0.0005409717559814453, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016255378723144531, 'bn1': 0.0005431175231933594, 'relu1': 0.00032329559326171875, 'conv2': 0.001617431640625, 'bn2': 0.0005328655242919922, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010607242584228516, 'bn1': 0.0003104209899902344, 'relu1': 0.00017142295837402344, 'conv2': 0.0012974739074707031, 'bn2': 0.000301361083984375, 'conv3': 0.0003955364227294922, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013036727905273438, 'bn1': 0.00038814544677734375, 'relu1': 0.00018334388732910156, 'conv2': 0.001317739486694336, 'bn2': 0.0003192424774169922, 'residual_add_relu2': 0.0003924369812011719}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007948875427246094, 'bn1': 0.0002155303955078125, 'relu1': 0.00010061264038085938, 'conv2': 0.0011546611785888672, 'bn2': 0.0001926422119140625, 'conv3': 0.00035381317138671875, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011489391326904297, 'bn1': 0.0002446174621582031, 'relu1': 0.00010037422180175781, 'conv2': 0.0011525154113769531, 'bn2': 0.00020599365234375, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006597042083740234, 'bn1': 0.00012803077697753906, 'relu1': 5.936622619628906e-05, 'conv2': 0.001142740249633789, 'bn2': 0.00011968612670898438, 'conv3': 0.0002949237823486328, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011396408081054688, 'bn1': 0.00012493133544921875, 'relu1': 5.91278076171875e-05, 'conv2': 0.001138448715209961, 'bn2': 0.000118255615234375, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 26\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016505718231201172, 'bn1': 0.0005524158477783203, 'relu1': 0.00032448768615722656, 'conv2': 0.0016279220581054688, 'bn2': 0.0005464553833007812, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016276836395263672, 'bn1': 0.0005424022674560547, 'relu1': 0.00032329559326171875, 'conv2': 0.0016231536865234375, 'bn2': 0.0005354881286621094, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001039743423461914, 'bn1': 0.0003147125244140625, 'relu1': 0.00017261505126953125, 'conv2': 0.0013020038604736328, 'bn2': 0.0003077983856201172, 'conv3': 0.0004012584686279297, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.001300811767578125, 'bn1': 0.0003135204315185547, 'relu1': 0.0001742839813232422, 'conv2': 0.0012989044189453125, 'bn2': 0.000308990478515625, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007894039154052734, 'bn1': 0.00020265579223632812, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00019431114196777344, 'conv3': 0.00035452842712402344, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.0011508464813232422, 'bn1': 0.0002624988555908203, 'relu1': 0.00010156631469726562, 'conv2': 0.0011496543884277344, 'bn2': 0.0001976490020751953, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.00067138671875, 'bn1': 0.0001251697540283203, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011417865753173828, 'bn2': 0.00012063980102539062, 'conv3': 0.0002999305725097656, 'residual_add_relu2': 0.00011348724365234375}\n",
      "{'conv1': 0.0011458396911621094, 'bn1': 0.00012922286987304688, 'relu1': 6.175041198730469e-05, 'conv2': 0.001142263412475586, 'bn2': 0.00012636184692382812, 'residual_add_relu2': 0.00011229515075683594}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 27\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016856193542480469, 'bn1': 0.0005602836608886719, 'relu1': 0.00032639503479003906, 'conv2': 0.0016422271728515625, 'bn2': 0.0005426406860351562, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.001638174057006836, 'bn1': 0.0005497932434082031, 'relu1': 0.00032711029052734375, 'conv2': 0.001631021499633789, 'bn2': 0.0005388259887695312, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010535717010498047, 'bn1': 0.0003139972686767578, 'relu1': 0.0001766681671142578, 'conv2': 0.0013098716735839844, 'bn2': 0.0003104209899902344, 'conv3': 0.000400543212890625, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013039112091064453, 'bn1': 0.00031304359436035156, 'relu1': 0.0001742839813232422, 'conv2': 0.0013005733489990234, 'bn2': 0.0003108978271484375, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007874965667724609, 'bn1': 0.00020074844360351562, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.00019693374633789062, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.001150369644165039, 'bn1': 0.00020170211791992188, 'relu1': 0.00010323524475097656, 'conv2': 0.0011463165283203125, 'bn2': 0.0001971721649169922, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006601810455322266, 'bn1': 0.0001232624053955078, 'relu1': 6.246566772460938e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00012373924255371094, 'conv3': 0.0002968311309814453, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011429786682128906, 'bn1': 0.00011873245239257812, 'relu1': 5.888938903808594e-05, 'conv2': 0.00113677978515625, 'bn2': 0.00011610984802246094, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 28\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016541481018066406, 'bn1': 0.0005505084991455078, 'relu1': 0.0003230571746826172, 'conv2': 0.001644134521484375, 'bn2': 0.0005393028259277344, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016531944274902344, 'bn1': 0.0005488395690917969, 'relu1': 0.0003235340118408203, 'conv2': 0.0016398429870605469, 'bn2': 0.0005445480346679688, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010447502136230469, 'bn1': 0.0003139972686767578, 'relu1': 0.0001723766326904297, 'conv2': 0.0013072490692138672, 'bn2': 0.00030040740966796875, 'conv3': 0.00039505958557128906, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013055801391601562, 'bn1': 0.0003097057342529297, 'relu1': 0.00017213821411132812, 'conv2': 0.001302480697631836, 'bn2': 0.0003020763397216797, 'residual_add_relu2': 0.0003886222839355469}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007987022399902344, 'bn1': 0.00020074844360351562, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00018930435180664062, 'conv3': 0.00034809112548828125, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011532306671142578, 'bn1': 0.00019884109497070312, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00019669532775878906, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.00066375732421875, 'bn1': 0.0001227855682373047, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011491775512695312, 'bn2': 0.00011587142944335938, 'conv3': 0.0002918243408203125, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.00012040138244628906, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011446475982666016, 'bn2': 0.0001163482666015625, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 29\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016422271728515625, 'bn1': 0.00054931640625, 'relu1': 0.0003209114074707031, 'conv2': 0.0016183853149414062, 'bn2': 0.0005409717559814453, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016341209411621094, 'bn1': 0.0005428791046142578, 'relu1': 0.0003237724304199219, 'conv2': 0.0016162395477294922, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007653236389160156}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010395050048828125, 'bn1': 0.0003132820129394531, 'relu1': 0.0001723766326904297, 'conv2': 0.0012941360473632812, 'bn2': 0.00033855438232421875, 'conv3': 0.0004057884216308594, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013010501861572266, 'bn1': 0.0003230571746826172, 'relu1': 0.00017642974853515625, 'conv2': 0.0012972354888916016, 'bn2': 0.0003199577331542969, 'residual_add_relu2': 0.0003941059112548828}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007863044738769531, 'bn1': 0.00020694732666015625, 'relu1': 0.00010156631469726562, 'conv2': 0.0011470317840576172, 'bn2': 0.00020456314086914062, 'conv3': 0.0004146099090576172, 'residual_add_relu2': 0.0002079010009765625}\n",
      "{'conv1': 0.0011501312255859375, 'bn1': 0.0002090930938720703, 'relu1': 0.00010037422180175781, 'conv2': 0.0011444091796875, 'bn2': 0.0002014636993408203, 'residual_add_relu2': 0.00020647048950195312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006551742553710938, 'bn1': 0.0001304149627685547, 'relu1': 6.151199340820312e-05, 'conv2': 0.0011360645294189453, 'bn2': 0.0001220703125, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.0011377334594726562, 'bn1': 0.00012946128845214844, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011370182037353516, 'bn2': 0.0001323223114013672, 'residual_add_relu2': 0.00011205673217773438}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 30\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016350746154785156, 'bn1': 0.0005652904510498047, 'relu1': 0.0003268718719482422, 'conv2': 0.0016357898712158203, 'bn2': 0.000553131103515625, 'residual_add_relu2': 0.0007684230804443359}\n",
      "{'conv1': 0.0016300678253173828, 'bn1': 0.0005540847778320312, 'relu1': 0.0003237724304199219, 'conv2': 0.0016322135925292969, 'bn2': 0.0005466938018798828, 'residual_add_relu2': 0.0007655620574951172}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010440349578857422, 'bn1': 0.0003230571746826172, 'relu1': 0.0001766681671142578, 'conv2': 0.0012993812561035156, 'bn2': 0.0003192424774169922, 'conv3': 0.00040411949157714844, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.001308441162109375, 'bn1': 0.0003228187561035156, 'relu1': 0.0001728534698486328, 'conv2': 0.001293182373046875, 'bn2': 0.0003159046173095703, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007851123809814453, 'bn1': 0.0002067089080810547, 'relu1': 0.00010228157043457031, 'conv2': 0.0011467933654785156, 'bn2': 0.0002033710479736328, 'conv3': 0.0003571510314941406, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.00115203857421875, 'bn1': 0.00020766258239746094, 'relu1': 0.00010013580322265625, 'conv2': 0.0011434555053710938, 'bn2': 0.00020503997802734375, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006573200225830078, 'bn1': 0.00013017654418945312, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011363029479980469, 'bn2': 0.0001239776611328125, 'conv3': 0.0002989768981933594, 'residual_add_relu2': 0.00011372566223144531}\n",
      "{'conv1': 0.001138448715209961, 'bn1': 0.00013256072998046875, 'relu1': 6.29425048828125e-05, 'conv2': 0.001134634017944336, 'bn2': 0.00012183189392089844, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 31\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016314983367919922, 'bn1': 0.0005550384521484375, 'relu1': 0.00032210350036621094, 'conv2': 0.0016260147094726562, 'bn2': 0.0005388259887695312, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016207695007324219, 'bn1': 0.0005459785461425781, 'relu1': 0.00032401084899902344, 'conv2': 0.0016167163848876953, 'bn2': 0.0005373954772949219, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.00103759765625, 'bn1': 0.00031256675720214844, 'relu1': 0.00017189979553222656, 'conv2': 0.0012946128845214844, 'bn2': 0.0003108978271484375, 'conv3': 0.00039887428283691406, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0012941360473632812, 'bn1': 0.00031185150146484375, 'relu1': 0.0001747608184814453, 'conv2': 0.0012922286987304688, 'bn2': 0.00030875205993652344, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007798671722412109, 'bn1': 0.0001983642578125, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011413097381591797, 'bn2': 0.0001964569091796875, 'conv3': 0.0003516674041748047, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011439323425292969, 'bn1': 0.0002033710479736328, 'relu1': 9.894371032714844e-05, 'conv2': 0.001138925552368164, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006530284881591797, 'bn1': 0.00012183189392089844, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011310577392578125, 'bn2': 0.00011301040649414062, 'conv3': 0.0002918243408203125, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011379718780517578, 'bn1': 0.0001270771026611328, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011315345764160156, 'bn2': 0.00011420249938964844, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 32\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016281604766845703, 'bn1': 0.0005552768707275391, 'relu1': 0.0003249645233154297, 'conv2': 0.001621246337890625, 'bn2': 0.0005435943603515625, 'residual_add_relu2': 0.0007638931274414062}\n",
      "{'conv1': 0.0016472339630126953, 'bn1': 0.0011115074157714844, 'relu1': 0.00039887428283691406, 'conv2': 0.0016613006591796875, 'bn2': 0.0007507801055908203, 'residual_add_relu2': 0.0007755756378173828}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001055002212524414, 'bn1': 0.0003304481506347656, 'relu1': 0.00017642974853515625, 'conv2': 0.0013015270233154297, 'bn2': 0.0003237724304199219, 'conv3': 0.00040602684020996094, 'residual_add_relu2': 0.0003921985626220703}\n",
      "{'conv1': 0.0013003349304199219, 'bn1': 0.00032258033752441406, 'relu1': 0.00017595291137695312, 'conv2': 0.0012967586517333984, 'bn2': 0.00032973289489746094, 'residual_add_relu2': 0.000392913818359375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007879734039306641, 'bn1': 0.00020742416381835938, 'relu1': 0.00010132789611816406, 'conv2': 0.0011453628540039062, 'bn2': 0.00019407272338867188, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011441707611083984, 'bn1': 0.0001976490020751953, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011394023895263672, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006518363952636719, 'bn1': 0.00012254714965820312, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011324882507324219, 'bn2': 0.00011944770812988281, 'conv3': 0.00028824806213378906, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011343955993652344, 'bn1': 0.00011920928955078125, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011289119720458984, 'bn2': 0.0001163482666015625, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 33\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016379356384277344, 'bn1': 0.0005598068237304688, 'relu1': 0.0003256797790527344, 'conv2': 0.0016293525695800781, 'bn2': 0.0005457401275634766, 'residual_add_relu2': 0.0007636547088623047}\n",
      "{'conv1': 0.0016167163848876953, 'bn1': 0.0005400180816650391, 'relu1': 0.0003218650817871094, 'conv2': 0.001611471176147461, 'bn2': 0.000537872314453125, 'residual_add_relu2': 0.0007681846618652344}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010457038879394531, 'bn1': 0.0003170967102050781, 'relu1': 0.0001728534698486328, 'conv2': 0.0012950897216796875, 'bn2': 0.00030803680419921875, 'conv3': 0.0004031658172607422, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0012974739074707031, 'bn1': 0.00031495094299316406, 'relu1': 0.0001747608184814453, 'conv2': 0.0012955665588378906, 'bn2': 0.00030922889709472656, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007832050323486328, 'bn1': 0.0002009868621826172, 'relu1': 0.00010013580322265625, 'conv2': 0.0011432170867919922, 'bn2': 0.0001938343048095703, 'conv3': 0.000354766845703125, 'residual_add_relu2': 0.0002028942108154297}\n",
      "{'conv1': 0.0011413097381591797, 'bn1': 0.00019478797912597656, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011372566223144531, 'bn2': 0.00018644332885742188, 'residual_add_relu2': 0.0002028942108154297}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006513595581054688, 'bn1': 0.00012636184692382812, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011343955993652344, 'bn2': 0.0001232624053955078, 'conv3': 0.00029349327087402344, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011374950408935547, 'bn1': 0.00011944770812988281, 'relu1': 6.103515625e-05, 'conv2': 0.0011315345764160156, 'bn2': 0.00011491775512695312, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 34\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016319751739501953, 'bn1': 0.0005524158477783203, 'relu1': 0.0003237724304199219, 'conv2': 0.0016179084777832031, 'bn2': 0.0005428791046142578, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.0016186237335205078, 'bn1': 0.0005519390106201172, 'relu1': 0.00032258033752441406, 'conv2': 0.001619100570678711, 'bn2': 0.0005376338958740234, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010399818420410156, 'bn1': 0.0003132820129394531, 'relu1': 0.000171661376953125, 'conv2': 0.001295328140258789, 'bn2': 0.0003075599670410156, 'conv3': 0.0003974437713623047, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.001294851303100586, 'bn1': 0.00031495094299316406, 'relu1': 0.0001735687255859375, 'conv2': 0.0012938976287841797, 'bn2': 0.00030803680419921875, 'residual_add_relu2': 0.00038886070251464844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007801055908203125, 'bn1': 0.0001983642578125, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011415481567382812, 'bn2': 0.00019407272338867188, 'conv3': 0.0003502368927001953, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011410713195800781, 'bn1': 0.00025153160095214844, 'relu1': 0.00010228157043457031, 'conv2': 0.0011439323425292969, 'bn2': 0.00019693374633789062, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006535053253173828, 'bn1': 0.00012135505676269531, 'relu1': 5.888938903808594e-05, 'conv2': 0.001132965087890625, 'bn2': 0.00011396408081054688, 'conv3': 0.0002918243408203125, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011348724365234375, 'bn1': 0.00012040138244628906, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011289119720458984, 'bn2': 0.00011420249938964844, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 35\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016350746154785156, 'bn1': 0.0005495548248291016, 'relu1': 0.00032401084899902344, 'conv2': 0.0016167163848876953, 'bn2': 0.0005347728729248047, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016155242919921875, 'bn1': 0.00054168701171875, 'relu1': 0.0003223419189453125, 'conv2': 0.0016143321990966797, 'bn2': 0.0005342960357666016, 'residual_add_relu2': 0.0007612705230712891}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010368824005126953, 'bn1': 0.0003190040588378906, 'relu1': 0.0001723766326904297, 'conv2': 0.0012960433959960938, 'bn2': 0.0003097057342529297, 'conv3': 0.00040149688720703125, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.001295328140258789, 'bn1': 0.0003209114074707031, 'relu1': 0.00017380714416503906, 'conv2': 0.001295328140258789, 'bn2': 0.0003082752227783203, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007808208465576172, 'bn1': 0.00020003318786621094, 'relu1': 0.00010061264038085938, 'conv2': 0.0011410713195800781, 'bn2': 0.0001900196075439453, 'conv3': 0.0003495216369628906, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011420249938964844, 'bn1': 0.00019288063049316406, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011358261108398438, 'bn2': 0.0002155303955078125, 'residual_add_relu2': 0.00020575523376464844}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006575584411621094, 'bn1': 0.00012445449829101562, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011332035064697266, 'bn2': 0.00011467933654785156, 'conv3': 0.00029397010803222656, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011353492736816406, 'bn1': 0.00012111663818359375, 'relu1': 5.984306335449219e-05, 'conv2': 0.001129150390625, 'bn2': 0.00011801719665527344, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 36\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016367435455322266, 'bn1': 0.0005505084991455078, 'relu1': 0.00032258033752441406, 'conv2': 0.0016238689422607422, 'bn2': 0.0005438327789306641, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.0016214847564697266, 'bn1': 0.0005440711975097656, 'relu1': 0.00032401084899902344, 'conv2': 0.0016133785247802734, 'bn2': 0.0005393028259277344, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001039743423461914, 'bn1': 0.00031304359436035156, 'relu1': 0.00017261505126953125, 'conv2': 0.001293182373046875, 'bn2': 0.0003094673156738281, 'conv3': 0.0003986358642578125, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.001295328140258789, 'bn1': 0.00031113624572753906, 'relu1': 0.00017261505126953125, 'conv2': 0.0012929439544677734, 'bn2': 0.0003132820129394531, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007815361022949219, 'bn1': 0.00019693374633789062, 'relu1': 9.846687316894531e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00019407272338867188, 'conv3': 0.00035190582275390625, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011463165283203125, 'bn1': 0.00020313262939453125, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011398792266845703, 'bn2': 0.00019407272338867188, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006515979766845703, 'bn1': 0.00012254714965820312, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00011968612670898438, 'conv3': 0.00028824806213378906, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011332035064697266, 'bn1': 0.0001227855682373047, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011298656463623047, 'bn2': 0.00012373924255371094, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 37\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016629695892333984, 'bn1': 0.0005583763122558594, 'relu1': 0.0003237724304199219, 'conv2': 0.0016300678253173828, 'bn2': 0.0005424022674560547, 'residual_add_relu2': 0.0007693767547607422}\n",
      "{'conv1': 0.001619100570678711, 'bn1': 0.0005397796630859375, 'relu1': 0.0003216266632080078, 'conv2': 0.0016121864318847656, 'bn2': 0.0005335807800292969, 'residual_add_relu2': 0.0007617473602294922}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010356903076171875, 'bn1': 0.0003077983856201172, 'relu1': 0.00017023086547851562, 'conv2': 0.0012934207916259766, 'bn2': 0.00030303001403808594, 'conv3': 0.000396728515625, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0012927055358886719, 'bn1': 0.0003123283386230469, 'relu1': 0.00017309188842773438, 'conv2': 0.0012884140014648438, 'bn2': 0.00030541419982910156, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007784366607666016, 'bn1': 0.00020051002502441406, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011432170867919922, 'bn2': 0.00019812583923339844, 'conv3': 0.0003533363342285156, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011436939239501953, 'bn1': 0.00019669532775878906, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011382102966308594, 'bn2': 0.00019741058349609375, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006518363952636719, 'bn1': 0.00011944770812988281, 'relu1': 5.817413330078125e-05, 'conv2': 0.001130819320678711, 'bn2': 0.00011897087097167969, 'conv3': 0.00029087066650390625, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011396408081054688, 'bn1': 0.0001246929168701172, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011305809020996094, 'bn2': 0.00011587142944335938, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 38\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016317367553710938, 'bn1': 0.0005509853363037109, 'relu1': 0.0003235340118408203, 'conv2': 0.0016100406646728516, 'bn2': 0.0005366802215576172, 'residual_add_relu2': 0.0007646083831787109}\n",
      "{'conv1': 0.0016214847564697266, 'bn1': 0.0005452632904052734, 'relu1': 0.0003228187561035156, 'conv2': 0.0016112327575683594, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.0007658004760742188}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001039743423461914, 'bn1': 0.0003161430358886719, 'relu1': 0.00017213821411132812, 'conv2': 0.0012946128845214844, 'bn2': 0.0003082752227783203, 'conv3': 0.0003972053527832031, 'residual_add_relu2': 0.00038886070251464844}\n",
      "{'conv1': 0.001294851303100586, 'bn1': 0.0003147125244140625, 'relu1': 0.00017333030700683594, 'conv2': 0.0012934207916259766, 'bn2': 0.00029921531677246094, 'residual_add_relu2': 0.0003886222839355469}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007770061492919922, 'bn1': 0.00020933151245117188, 'relu1': 9.989738464355469e-05, 'conv2': 0.001142263412475586, 'bn2': 0.00019621849060058594, 'conv3': 0.0003514289855957031, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011472702026367188, 'bn1': 0.00020003318786621094, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011396408081054688, 'bn2': 0.00020313262939453125, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006542205810546875, 'bn1': 0.00012159347534179688, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011324882507324219, 'bn2': 0.00011491775512695312, 'conv3': 0.00029087066650390625, 'residual_add_relu2': 0.00011229515075683594}\n",
      "{'conv1': 0.0011394023895263672, 'bn1': 0.00012421607971191406, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011298656463623047, 'bn2': 0.00011563301086425781, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 39\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016374588012695312, 'bn1': 0.0005578994750976562, 'relu1': 0.0003223419189453125, 'conv2': 0.001621246337890625, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.0007638931274414062}\n",
      "{'conv1': 0.0016169548034667969, 'bn1': 0.0005438327789306641, 'relu1': 0.0003235340118408203, 'conv2': 0.0016133785247802734, 'bn2': 0.0005576610565185547, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.00103759765625, 'bn1': 0.0003132820129394531, 'relu1': 0.00017309188842773438, 'conv2': 0.0012955665588378906, 'bn2': 0.0003108978271484375, 'conv3': 0.0003986358642578125, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0012912750244140625, 'bn1': 0.0016655921936035156, 'relu1': 0.00020623207092285156, 'conv2': 0.0013070106506347656, 'bn2': 0.00031280517578125, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007798671722412109, 'bn1': 0.0001971721649169922, 'relu1': 9.632110595703125e-05, 'conv2': 0.001138925552368164, 'bn2': 0.0001995563507080078, 'conv3': 0.0003509521484375, 'residual_add_relu2': 0.00020813941955566406}\n",
      "{'conv1': 0.0011444091796875, 'bn1': 0.0002033710479736328, 'relu1': 9.965896606445312e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00019598007202148438, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006518363952636719, 'bn1': 0.00012159347534179688, 'relu1': 6.29425048828125e-05, 'conv2': 0.0011320114135742188, 'bn2': 0.00011539459228515625, 'conv3': 0.0002894401550292969, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011370182037353516, 'bn1': 0.0001201629638671875, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011317729949951172, 'bn2': 0.0001163482666015625, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 40\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016186237335205078, 'bn1': 0.0005528926849365234, 'relu1': 0.0003237724304199219, 'conv2': 0.0016155242919921875, 'bn2': 0.0005362033843994141, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016143321990966797, 'bn1': 0.0005419254302978516, 'relu1': 0.0003230571746826172, 'conv2': 0.0016138553619384766, 'bn2': 0.0005509853363037109, 'residual_add_relu2': 0.0007655620574951172}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010399818420410156, 'bn1': 0.0003142356872558594, 'relu1': 0.00017261505126953125, 'conv2': 0.0012929439544677734, 'bn2': 0.0003108978271484375, 'conv3': 0.00040268898010253906, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0012969970703125, 'bn1': 0.0003056526184082031, 'relu1': 0.00017523765563964844, 'conv2': 0.0012884140014648438, 'bn2': 0.0003094673156738281, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007827281951904297, 'bn1': 0.00019121170043945312, 'relu1': 9.560585021972656e-05, 'conv2': 0.0011382102966308594, 'bn2': 0.00018906593322753906, 'conv3': 0.00034809112548828125, 'residual_add_relu2': 0.00020265579223632812}\n",
      "{'conv1': 0.001138925552368164, 'bn1': 0.0001900196075439453, 'relu1': 9.703636169433594e-05, 'conv2': 0.001135110855102539, 'bn2': 0.00018858909606933594, 'residual_add_relu2': 0.00020265579223632812}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0007102489471435547, 'bn1': 0.000125885009765625, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011358261108398438, 'bn2': 0.0001347064971923828, 'conv3': 0.0003018379211425781, 'residual_add_relu2': 0.00011348724365234375}\n",
      "{'conv1': 0.0011391639709472656, 'bn1': 0.0001316070556640625, 'relu1': 6.198883056640625e-05, 'conv2': 0.001134634017944336, 'bn2': 0.00012683868408203125, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 41\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001634836196899414, 'bn1': 0.0005524158477783203, 'relu1': 0.0003237724304199219, 'conv2': 0.001621246337890625, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016226768493652344, 'bn1': 0.0005443096160888672, 'relu1': 0.0003247261047363281, 'conv2': 0.0016200542449951172, 'bn2': 0.0005397796630859375, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001039266586303711, 'bn1': 0.00031280517578125, 'relu1': 0.00017547607421875, 'conv2': 0.0012946128845214844, 'bn2': 0.000308990478515625, 'conv3': 0.0003962516784667969, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013005733489990234, 'bn1': 0.0003151893615722656, 'relu1': 0.0001747608184814453, 'conv2': 0.0012912750244140625, 'bn2': 0.0003075599670410156, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007808208465576172, 'bn1': 0.00019979476928710938, 'relu1': 9.870529174804688e-05, 'conv2': 0.001142263412475586, 'bn2': 0.00020694732666015625, 'conv3': 0.0003552436828613281, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011436939239501953, 'bn1': 0.00019931793212890625, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011401176452636719, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006508827209472656, 'bn1': 0.00012230873107910156, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011324882507324219, 'bn2': 0.0001266002655029297, 'conv3': 0.00029087066650390625, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011327266693115234, 'bn1': 0.00011992454528808594, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011289119720458984, 'bn2': 0.00011515617370605469, 'residual_add_relu2': 0.00012803077697753906}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 42\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.00164031982421875, 'bn1': 0.0005459785461425781, 'relu1': 0.00032258033752441406, 'conv2': 0.0016188621520996094, 'bn2': 0.0005393028259277344, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016160011291503906, 'bn1': 0.0005359649658203125, 'relu1': 0.0003218650817871094, 'conv2': 0.0016124248504638672, 'bn2': 0.0005321502685546875, 'residual_add_relu2': 0.0007600784301757812}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010330677032470703, 'bn1': 0.00030303001403808594, 'relu1': 0.00017070770263671875, 'conv2': 0.0012898445129394531, 'bn2': 0.0003032684326171875, 'conv3': 0.0003943443298339844, 'residual_add_relu2': 0.0003883838653564453}\n",
      "{'conv1': 0.0012905597686767578, 'bn1': 0.0003070831298828125, 'relu1': 0.0001723766326904297, 'conv2': 0.001291513442993164, 'bn2': 0.0003135204315185547, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000782012939453125, 'bn1': 0.0002307891845703125, 'relu1': 0.00010013580322265625, 'conv2': 0.0011439323425292969, 'bn2': 0.00019788742065429688, 'conv3': 0.0003535747528076172, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.0011420249938964844, 'bn1': 0.00019741058349609375, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011391639709472656, 'bn2': 0.00019311904907226562, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006513595581054688, 'bn1': 0.00012040138244628906, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011320114135742188, 'bn2': 0.00010824203491210938, 'conv3': 0.0002841949462890625, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011293888092041016, 'bn1': 0.00011301040649414062, 'relu1': 5.745887756347656e-05, 'conv2': 0.001125335693359375, 'bn2': 0.00011730194091796875, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 43\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016477108001708984, 'bn1': 0.0005481243133544922, 'relu1': 0.0003223419189453125, 'conv2': 0.0016243457794189453, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007634162902832031}\n",
      "{'conv1': 0.0016193389892578125, 'bn1': 0.000545501708984375, 'relu1': 0.00032329559326171875, 'conv2': 0.0016186237335205078, 'bn2': 0.0005481243133544922, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010385513305664062, 'bn1': 0.0003123283386230469, 'relu1': 0.00017213821411132812, 'conv2': 0.0012905597686767578, 'bn2': 0.00030541419982910156, 'conv3': 0.0003955364227294922, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0012998580932617188, 'bn1': 0.0003123283386230469, 'relu1': 0.00017261505126953125, 'conv2': 0.001291513442993164, 'bn2': 0.00030732154846191406, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007796287536621094, 'bn1': 0.0001983642578125, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011420249938964844, 'bn2': 0.00019788742065429688, 'conv3': 0.0003516674041748047, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011417865753173828, 'bn1': 0.0002512931823730469, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011417865753173828, 'bn2': 0.00019407272338867188, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006513595581054688, 'bn1': 0.00011944770812988281, 'relu1': 5.936622619628906e-05, 'conv2': 0.001130819320678711, 'bn2': 0.00011301040649414062, 'conv3': 0.0002899169921875, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011317729949951172, 'bn1': 0.00011968612670898438, 'relu1': 6.389617919921875e-05, 'conv2': 0.0011303424835205078, 'bn2': 0.00011467933654785156, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 44\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016407966613769531, 'bn1': 0.0005524158477783203, 'relu1': 0.0003235340118408203, 'conv2': 0.001619100570678711, 'bn2': 0.0005426406860351562, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016205310821533203, 'bn1': 0.0005428791046142578, 'relu1': 0.00033020973205566406, 'conv2': 0.0016124248504638672, 'bn2': 0.0005364418029785156, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.00103759765625, 'bn1': 0.0003159046173095703, 'relu1': 0.00017380714416503906, 'conv2': 0.0012936592102050781, 'bn2': 0.00030541419982910156, 'conv3': 0.0003979206085205078, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0012929439544677734, 'bn1': 0.00031447410583496094, 'relu1': 0.00017404556274414062, 'conv2': 0.0012962818145751953, 'bn2': 0.0003077983856201172, 'residual_add_relu2': 0.00038886070251464844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007803440093994141, 'bn1': 0.00019812583923339844, 'relu1': 0.00010204315185546875, 'conv2': 0.0011548995971679688, 'bn2': 0.00020122528076171875, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011425018310546875, 'bn1': 0.00019788742065429688, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011386871337890625, 'bn2': 0.0002033710479736328, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006532669067382812, 'bn1': 0.00012040138244628906, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011327266693115234, 'bn2': 0.00011444091796875, 'conv3': 0.0002865791320800781, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.0011360645294189453, 'bn1': 0.00012183189392089844, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011296272277832031, 'bn2': 0.00011515617370605469, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 45\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001630544662475586, 'bn1': 0.0005517005920410156, 'relu1': 0.00032591819763183594, 'conv2': 0.0016183853149414062, 'bn2': 0.0005390644073486328, 'residual_add_relu2': 0.0007691383361816406}\n",
      "{'conv1': 0.0016138553619384766, 'bn1': 0.0005440711975097656, 'relu1': 0.00032329559326171875, 'conv2': 0.0016198158264160156, 'bn2': 0.0005366802215576172, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010406970977783203, 'bn1': 0.00032329559326171875, 'relu1': 0.00017380714416503906, 'conv2': 0.0012960433959960938, 'bn2': 0.0003180503845214844, 'conv3': 0.0004017353057861328, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0012943744659423828, 'bn1': 0.00031256675720214844, 'relu1': 0.0001728534698486328, 'conv2': 0.001291513442993164, 'bn2': 0.0003108978271484375, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007829666137695312, 'bn1': 0.0002014636993408203, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011415481567382812, 'bn2': 0.0001933574676513672, 'conv3': 0.0003509521484375, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011475086212158203, 'bn1': 0.0002002716064453125, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011379718780517578, 'bn2': 0.00019240379333496094, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006513595581054688, 'bn1': 0.00011920928955078125, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011341571807861328, 'bn2': 0.00012373924255371094, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011317729949951172, 'bn1': 0.00011992454528808594, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011289119720458984, 'bn2': 0.00011658668518066406, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 46\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001646280288696289, 'bn1': 0.0005664825439453125, 'relu1': 0.0003268718719482422, 'conv2': 0.001628875732421875, 'bn2': 0.0005459785461425781, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.00162506103515625, 'bn1': 0.0005481243133544922, 'relu1': 0.0003407001495361328, 'conv2': 0.0016207695007324219, 'bn2': 0.0005528926849365234, 'residual_add_relu2': 0.0007688999176025391}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010492801666259766, 'bn1': 0.0003192424774169922, 'relu1': 0.0001742839813232422, 'conv2': 0.0012955665588378906, 'bn2': 0.0003173351287841797, 'conv3': 0.00040340423583984375, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0012967586517333984, 'bn1': 0.0003185272216796875, 'relu1': 0.00017499923706054688, 'conv2': 0.0012993812561035156, 'bn2': 0.0003135204315185547, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007994174957275391, 'bn1': 0.00020694732666015625, 'relu1': 0.00010132789611816406, 'conv2': 0.001146554946899414, 'bn2': 0.0002028942108154297, 'conv3': 0.00035572052001953125, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.001146554946899414, 'bn1': 0.00021195411682128906, 'relu1': 0.00010180473327636719, 'conv2': 0.0011425018310546875, 'bn2': 0.0001971721649169922, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006630420684814453, 'bn1': 0.00012731552124023438, 'relu1': 9.512901306152344e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00012087821960449219, 'conv3': 0.00029587745666503906, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011513233184814453, 'bn1': 0.0001239776611328125, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011305809020996094, 'bn2': 0.00012135505676269531, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 47\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001628875732421875, 'bn1': 0.0005440711975097656, 'relu1': 0.00032401084899902344, 'conv2': 0.001622915267944336, 'bn2': 0.0005481243133544922, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016167163848876953, 'bn1': 0.0005514621734619141, 'relu1': 0.00032520294189453125, 'conv2': 0.0016171932220458984, 'bn2': 0.0005476474761962891, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010402202606201172, 'bn1': 0.00031447410583496094, 'relu1': 0.00017261505126953125, 'conv2': 0.0013108253479003906, 'bn2': 0.0003142356872558594, 'conv3': 0.00040435791015625, 'residual_add_relu2': 0.00039267539978027344}\n",
      "{'conv1': 0.0012993812561035156, 'bn1': 0.00031375885009765625, 'relu1': 0.00017309188842773438, 'conv2': 0.0012919902801513672, 'bn2': 0.0003769397735595703, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007815361022949219, 'bn1': 0.0001983642578125, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011417865753173828, 'bn2': 0.000194549560546875, 'conv3': 0.00035119056701660156, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011441707611083984, 'bn1': 0.0001983642578125, 'relu1': 9.846687316894531e-05, 'conv2': 0.001138448715209961, 'bn2': 0.0001952648162841797, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006506443023681641, 'bn1': 0.00011897087097167969, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011320114135742188, 'bn2': 0.00011849403381347656, 'conv3': 0.00028896331787109375, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011324882507324219, 'bn1': 0.000118255615234375, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011286735534667969, 'bn2': 0.00011396408081054688, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 48\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016412734985351562, 'bn1': 0.0005800724029541016, 'relu1': 0.000324249267578125, 'conv2': 0.0016133785247802734, 'bn2': 0.0005435943603515625, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.0016255378723144531, 'bn1': 0.0005574226379394531, 'relu1': 0.00032711029052734375, 'conv2': 0.0016202926635742188, 'bn2': 0.0005581378936767578, 'residual_add_relu2': 0.0007696151733398438}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010471343994140625, 'bn1': 0.0003299713134765625, 'relu1': 0.0001773834228515625, 'conv2': 0.0013043880462646484, 'bn2': 0.0003199577331542969, 'conv3': 0.0004057884216308594, 'residual_add_relu2': 0.0003933906555175781}\n",
      "{'conv1': 0.0013163089752197266, 'bn1': 0.0003247261047363281, 'relu1': 0.00017499923706054688, 'conv2': 0.0012972354888916016, 'bn2': 0.0003085136413574219, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007803440093994141, 'bn1': 0.00019741058349609375, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.00021076202392578125, 'conv3': 0.00035452842712402344, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.001142740249633789, 'bn1': 0.00020003318786621094, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011394023895263672, 'bn2': 0.0001964569091796875, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006475448608398438, 'bn1': 0.00012493133544921875, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011341571807861328, 'bn2': 0.00011181831359863281, 'conv3': 0.0002880096435546875, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011301040649414062, 'bn1': 0.00012063980102539062, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011296272277832031, 'bn2': 0.00011610984802246094, 'residual_add_relu2': 0.00011205673217773438}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 49\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016417503356933594, 'bn1': 0.0005540847778320312, 'relu1': 0.000324249267578125, 'conv2': 0.0016214847564697266, 'bn2': 0.0005388259887695312, 'residual_add_relu2': 0.0007781982421875}\n",
      "{'conv1': 0.0016398429870605469, 'bn1': 0.0005419254302978516, 'relu1': 0.00032138824462890625, 'conv2': 0.0016140937805175781, 'bn2': 0.0005350112915039062, 'residual_add_relu2': 0.0007619857788085938}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001033782958984375, 'bn1': 0.0003180503845214844, 'relu1': 0.00017380714416503906, 'conv2': 0.0012943744659423828, 'bn2': 0.00031065940856933594, 'conv3': 0.0003991127014160156, 'residual_add_relu2': 0.00038933753967285156}\n",
      "{'conv1': 0.0012938976287841797, 'bn1': 0.0003135204315185547, 'relu1': 0.00017404556274414062, 'conv2': 0.0012924671173095703, 'bn2': 0.00031113624572753906, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000782012939453125, 'bn1': 0.00020003318786621094, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011420249938964844, 'bn2': 0.00019502639770507812, 'conv3': 0.00038242340087890625, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.00020074844360351562, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011391639709472656, 'bn2': 0.00019311904907226562, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006537437438964844, 'bn1': 0.00012350082397460938, 'relu1': 5.936622619628906e-05, 'conv2': 0.001131296157836914, 'bn2': 0.00011444091796875, 'conv3': 0.0002880096435546875, 'residual_add_relu2': 0.00011324882507324219}\n",
      "{'conv1': 0.0011374950408935547, 'bn1': 0.00012922286987304688, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011305809020996094, 'bn2': 0.00011801719665527344, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 50\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016379356384277344, 'bn1': 0.0005598068237304688, 'relu1': 0.0003247261047363281, 'conv2': 0.0016210079193115234, 'bn2': 0.0005433559417724609, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016329288482666016, 'bn1': 0.0005426406860351562, 'relu1': 0.00032329559326171875, 'conv2': 0.0016210079193115234, 'bn2': 0.0005321502685546875, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010383129119873047, 'bn1': 0.0003142356872558594, 'relu1': 0.00017189979553222656, 'conv2': 0.0012960433959960938, 'bn2': 0.00030303001403808594, 'conv3': 0.00039887428283691406, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0012903213500976562, 'bn1': 0.00030684471130371094, 'relu1': 0.00017333030700683594, 'conv2': 0.0012905597686767578, 'bn2': 0.0003039836883544922, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007753372192382812, 'bn1': 0.000194549560546875, 'relu1': 9.703636169433594e-05, 'conv2': 0.0011401176452636719, 'bn2': 0.00018477439880371094, 'conv3': 0.0003485679626464844, 'residual_add_relu2': 0.0002033710479736328}\n",
      "{'conv1': 0.0011382102966308594, 'bn1': 0.00019478797912597656, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011355876922607422, 'bn2': 0.0001876354217529297, 'residual_add_relu2': 0.00020313262939453125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006482601165771484, 'bn1': 0.00011491775512695312, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011298656463623047, 'bn2': 0.00010967254638671875, 'conv3': 0.0002906322479248047, 'residual_add_relu2': 0.00010967254638671875}\n",
      "{'conv1': 0.001129150390625, 'bn1': 0.00011086463928222656, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011279582977294922, 'bn2': 0.00010919570922851562, 'residual_add_relu2': 0.00010824203491210938}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 51\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016448497772216797, 'bn1': 0.0005526542663574219, 'relu1': 0.0003228187561035156, 'conv2': 0.0016236305236816406, 'bn2': 0.0005409717559814453, 'residual_add_relu2': 0.0007636547088623047}\n",
      "{'conv1': 0.0016143321990966797, 'bn1': 0.0005443096160888672, 'relu1': 0.00033783912658691406, 'conv2': 0.0016202926635742188, 'bn2': 0.0005316734313964844, 'residual_add_relu2': 0.000759124755859375}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010344982147216797, 'bn1': 0.0003082752227783203, 'relu1': 0.00017118453979492188, 'conv2': 0.0012907981872558594, 'bn2': 0.0003094673156738281, 'conv3': 0.0003933906555175781, 'residual_add_relu2': 0.0003883838653564453}\n",
      "{'conv1': 0.00128936767578125, 'bn1': 0.0003032684326171875, 'relu1': 0.0001704692840576172, 'conv2': 0.001287698745727539, 'bn2': 0.0002968311309814453, 'residual_add_relu2': 0.0003879070281982422}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007750988006591797, 'bn1': 0.00018858909606933594, 'relu1': 9.512901306152344e-05, 'conv2': 0.001135110855102539, 'bn2': 0.00018739700317382812, 'conv3': 0.00035381317138671875, 'residual_add_relu2': 0.0002028942108154297}\n",
      "{'conv1': 0.0011401176452636719, 'bn1': 0.00019812583923339844, 'relu1': 0.0001583099365234375, 'conv2': 0.001142263412475586, 'bn2': 0.00019669532775878906, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006518363952636719, 'bn1': 0.0001354217529296875, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011315345764160156, 'bn2': 0.00011396408081054688, 'conv3': 0.00028586387634277344, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011339187622070312, 'bn1': 0.00012135505676269531, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011281967163085938, 'bn2': 0.00011467933654785156, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 52\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016329288482666016, 'bn1': 0.0005550384521484375, 'relu1': 0.0003235340118408203, 'conv2': 0.0016231536865234375, 'bn2': 0.0005383491516113281, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.0016124248504638672, 'bn1': 0.0005359649658203125, 'relu1': 0.0003223419189453125, 'conv2': 0.0016238689422607422, 'bn2': 0.0005328655242919922, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010383129119873047, 'bn1': 0.0003056526184082031, 'relu1': 0.00016999244689941406, 'conv2': 0.0012900829315185547, 'bn2': 0.0003025531768798828, 'conv3': 0.0003972053527832031, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.001293182373046875, 'bn1': 0.0003066062927246094, 'relu1': 0.0001709461212158203, 'conv2': 0.0012884140014648438, 'bn2': 0.00030159950256347656, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007765293121337891, 'bn1': 0.0001952648162841797, 'relu1': 0.00010061264038085938, 'conv2': 0.001142740249633789, 'bn2': 0.00019598007202148438, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.001148223876953125, 'bn1': 0.0001933574676513672, 'relu1': 9.5367431640625e-05, 'conv2': 0.0011353492736816406, 'bn2': 0.00018906593322753906, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006477832794189453, 'bn1': 0.00012540817260742188, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011317729949951172, 'bn2': 0.00011491775512695312, 'conv3': 0.00029015541076660156, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.001132965087890625, 'bn1': 0.00011801719665527344, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011281967163085938, 'bn2': 0.00011444091796875, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 53\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016260147094726562, 'bn1': 0.0005457401275634766, 'relu1': 0.0003199577331542969, 'conv2': 0.0016124248504638672, 'bn2': 0.0005657672882080078, 'residual_add_relu2': 0.0007696151733398438}\n",
      "{'conv1': 0.001630544662475586, 'bn1': 0.0005741119384765625, 'relu1': 0.00033092498779296875, 'conv2': 0.0016210079193115234, 'bn2': 0.0005500316619873047, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010442733764648438, 'bn1': 0.0003249645233154297, 'relu1': 0.00017571449279785156, 'conv2': 0.0012984275817871094, 'bn2': 0.00031757354736328125, 'conv3': 0.00040459632873535156, 'residual_add_relu2': 0.00038933753967285156}\n",
      "{'conv1': 0.0012958049774169922, 'bn1': 0.00031280517578125, 'relu1': 0.00017309188842773438, 'conv2': 0.0012922286987304688, 'bn2': 0.00032448768615722656, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007817745208740234, 'bn1': 0.00019979476928710938, 'relu1': 9.751319885253906e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00019359588623046875, 'conv3': 0.00034999847412109375, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011432170867919922, 'bn1': 0.00019669532775878906, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011386871337890625, 'bn2': 0.00019693374633789062, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006508827209472656, 'bn1': 0.000118255615234375, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011324882507324219, 'bn2': 0.00011324882507324219, 'conv3': 0.0002894401550292969, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011403560638427734, 'bn1': 0.00011897087097167969, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011301040649414062, 'bn2': 0.00012493133544921875, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 54\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016760826110839844, 'bn1': 0.0005896091461181641, 'relu1': 0.00033283233642578125, 'conv2': 0.001641988754272461, 'bn2': 0.0005731582641601562, 'residual_add_relu2': 0.0007715225219726562}\n",
      "{'conv1': 0.0016608238220214844, 'bn1': 0.0005815029144287109, 'relu1': 0.0003311634063720703, 'conv2': 0.001634836196899414, 'bn2': 0.0005636215209960938, 'residual_add_relu2': 0.0007691383361816406}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010721683502197266, 'bn1': 0.0003452301025390625, 'relu1': 0.00018024444580078125, 'conv2': 0.0013103485107421875, 'bn2': 0.0003330707550048828, 'conv3': 0.00041413307189941406, 'residual_add_relu2': 0.0003962516784667969}\n",
      "{'conv1': 0.0013186931610107422, 'bn1': 0.0003509521484375, 'relu1': 0.00018143653869628906, 'conv2': 0.0013077259063720703, 'bn2': 0.0003371238708496094, 'residual_add_relu2': 0.0003952980041503906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007979869842529297, 'bn1': 0.00022840499877929688, 'relu1': 0.00010633468627929688, 'conv2': 0.0011556148529052734, 'bn2': 0.00022101402282714844, 'conv3': 0.00036597251892089844, 'residual_add_relu2': 0.0002090930938720703}\n",
      "{'conv1': 0.001157999038696289, 'bn1': 0.00022864341735839844, 'relu1': 0.00010466575622558594, 'conv2': 0.0011529922485351562, 'bn2': 0.0002472400665283203, 'residual_add_relu2': 0.0002117156982421875}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006692409515380859, 'bn1': 0.00015783309936523438, 'relu1': 6.67572021484375e-05, 'conv2': 0.0011472702026367188, 'bn2': 0.00015044212341308594, 'conv3': 0.00030517578125, 'residual_add_relu2': 0.00011587142944335938}\n",
      "{'conv1': 0.0011475086212158203, 'bn1': 0.00014972686767578125, 'relu1': 6.747245788574219e-05, 'conv2': 0.0011420249938964844, 'bn2': 0.0001423358917236328, 'residual_add_relu2': 0.00011515617370605469}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 55\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016520023345947266, 'bn1': 0.0005815029144287109, 'relu1': 0.00033211708068847656, 'conv2': 0.001634359359741211, 'bn2': 0.0005719661712646484, 'residual_add_relu2': 0.0007688999176025391}\n",
      "{'conv1': 0.0016322135925292969, 'bn1': 0.0005712509155273438, 'relu1': 0.00033092498779296875, 'conv2': 0.0016295909881591797, 'bn2': 0.0005764961242675781, 'residual_add_relu2': 0.0007693767547607422}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010542869567871094, 'bn1': 0.0003390312194824219, 'relu1': 0.00017952919006347656, 'conv2': 0.001308441162109375, 'bn2': 0.00033354759216308594, 'conv3': 0.00041174888610839844, 'residual_add_relu2': 0.0003952980041503906}\n",
      "{'conv1': 0.0013103485107421875, 'bn1': 0.0003390312194824219, 'relu1': 0.00018024444580078125, 'conv2': 0.0013043880462646484, 'bn2': 0.0003345012664794922, 'residual_add_relu2': 0.0004875659942626953}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008029937744140625, 'bn1': 0.00022912025451660156, 'relu1': 0.00010538101196289062, 'conv2': 0.001155853271484375, 'bn2': 0.0002429485321044922, 'conv3': 0.0003688335418701172, 'residual_add_relu2': 0.00020813941955566406}\n",
      "{'conv1': 0.0011577606201171875, 'bn1': 0.00022935867309570312, 'relu1': 0.0001049041748046875, 'conv2': 0.0011529922485351562, 'bn2': 0.00021886825561523438, 'residual_add_relu2': 0.0002105236053466797}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006656646728515625, 'bn1': 0.0001456737518310547, 'relu1': 6.651878356933594e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.0001418590545654297, 'conv3': 0.00030517578125, 'residual_add_relu2': 0.00011491775512695312}\n",
      "{'conv1': 0.0011479854583740234, 'bn1': 0.00015473365783691406, 'relu1': 6.771087646484375e-05, 'conv2': 0.001146554946899414, 'bn2': 0.0001430511474609375, 'residual_add_relu2': 0.00011491775512695312}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 56\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016503334045410156, 'bn1': 0.0005800724029541016, 'relu1': 0.00033211708068847656, 'conv2': 0.0016317367553710938, 'bn2': 0.0005850791931152344, 'residual_add_relu2': 0.0007719993591308594}\n",
      "{'conv1': 0.001634836196899414, 'bn1': 0.0005695819854736328, 'relu1': 0.000331878662109375, 'conv2': 0.001626729965209961, 'bn2': 0.0005631446838378906, 'residual_add_relu2': 0.0007681846618652344}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010526180267333984, 'bn1': 0.00033783912658691406, 'relu1': 0.00018024444580078125, 'conv2': 0.0013065338134765625, 'bn2': 0.00034618377685546875, 'conv3': 0.0004150867462158203, 'residual_add_relu2': 0.0003955364227294922}\n",
      "{'conv1': 0.0013086795806884766, 'bn1': 0.0003383159637451172, 'relu1': 0.00018072128295898438, 'conv2': 0.0013060569763183594, 'bn2': 0.00033402442932128906, 'residual_add_relu2': 0.0003941059112548828}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007977485656738281, 'bn1': 0.0002281665802001953, 'relu1': 0.00010609626770019531, 'conv2': 0.001155853271484375, 'bn2': 0.0002295970916748047, 'conv3': 0.0003685951232910156, 'residual_add_relu2': 0.000209808349609375}\n",
      "{'conv1': 0.0011608600616455078, 'bn1': 0.00022268295288085938, 'relu1': 0.00010466575622558594, 'conv2': 0.001153707504272461, 'bn2': 0.0002288818359375, 'residual_add_relu2': 0.00020933151245117188}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006680488586425781, 'bn1': 0.0001461505889892578, 'relu1': 6.651878356933594e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.00013947486877441406, 'conv3': 0.00030303001403808594, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.0011477470397949219, 'bn1': 0.000148773193359375, 'relu1': 6.723403930664062e-05, 'conv2': 0.0011425018310546875, 'bn2': 0.00013637542724609375, 'residual_add_relu2': 0.00011491775512695312}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 57\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016608238220214844, 'bn1': 0.0005862712860107422, 'relu1': 0.000331878662109375, 'conv2': 0.001644134521484375, 'bn2': 0.0005688667297363281, 'residual_add_relu2': 0.0007722377777099609}\n",
      "{'conv1': 0.0016443729400634766, 'bn1': 0.0005705356597900391, 'relu1': 0.0003287792205810547, 'conv2': 0.0016407966613769531, 'bn2': 0.0005767345428466797, 'residual_add_relu2': 0.0007691383361816406}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010592937469482422, 'bn1': 0.00034046173095703125, 'relu1': 0.00017952919006347656, 'conv2': 0.0013082027435302734, 'bn2': 0.0003323554992675781, 'conv3': 0.0004134178161621094, 'residual_add_relu2': 0.0003981590270996094}\n",
      "{'conv1': 0.0013146400451660156, 'bn1': 0.0003428459167480469, 'relu1': 0.00018024444580078125, 'conv2': 0.0013055801391601562, 'bn2': 0.0003352165222167969, 'residual_add_relu2': 0.00039958953857421875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008001327514648438, 'bn1': 0.0002384185791015625, 'relu1': 0.00010776519775390625, 'conv2': 0.0011587142944335938, 'bn2': 0.00022292137145996094, 'conv3': 0.00036716461181640625, 'residual_add_relu2': 0.0002086162567138672}\n",
      "{'conv1': 0.0011572837829589844, 'bn1': 0.0002269744873046875, 'relu1': 0.00010466575622558594, 'conv2': 0.0011529922485351562, 'bn2': 0.0002186298370361328, 'residual_add_relu2': 0.00020813941955566406}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006661415100097656, 'bn1': 0.00014638900756835938, 'relu1': 6.604194641113281e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00014400482177734375, 'conv3': 0.00030422210693359375, 'residual_add_relu2': 0.00011515617370605469}\n",
      "{'conv1': 0.0011489391326904297, 'bn1': 0.00015401840209960938, 'relu1': 6.604194641113281e-05, 'conv2': 0.001153707504272461, 'bn2': 0.00015497207641601562, 'residual_add_relu2': 0.00011563301086425781}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 58\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016560554504394531, 'bn1': 0.0005996227264404297, 'relu1': 0.0003390312194824219, 'conv2': 0.0016379356384277344, 'bn2': 0.0005688667297363281, 'residual_add_relu2': 0.0007710456848144531}\n",
      "{'conv1': 0.0016398429870605469, 'bn1': 0.0005712509155273438, 'relu1': 0.0003299713134765625, 'conv2': 0.001634359359741211, 'bn2': 0.0005633831024169922, 'residual_add_relu2': 0.0007722377777099609}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010669231414794922, 'bn1': 0.0003561973571777344, 'relu1': 0.00018024444580078125, 'conv2': 0.0013115406036376953, 'bn2': 0.00033664703369140625, 'conv3': 0.0004191398620605469, 'residual_add_relu2': 0.00039649009704589844}\n",
      "{'conv1': 0.0013096332550048828, 'bn1': 0.00034046173095703125, 'relu1': 0.0001823902130126953, 'conv2': 0.0013070106506347656, 'bn2': 0.00034499168395996094, 'residual_add_relu2': 0.0003952980041503906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007991790771484375, 'bn1': 0.00022864341735839844, 'relu1': 0.00010704994201660156, 'conv2': 0.0011627674102783203, 'bn2': 0.00023412704467773438, 'conv3': 0.00037384033203125, 'residual_add_relu2': 0.00021266937255859375}\n",
      "{'conv1': 0.0011639595031738281, 'bn1': 0.0002288818359375, 'relu1': 0.00010538101196289062, 'conv2': 0.0011551380157470703, 'bn2': 0.00022149085998535156, 'residual_add_relu2': 0.0002231597900390625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006706714630126953, 'bn1': 0.0001513957977294922, 'relu1': 6.747245788574219e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.0001423358917236328, 'conv3': 0.0003018379211425781, 'residual_add_relu2': 0.00011587142944335938}\n",
      "{'conv1': 0.0011518001556396484, 'bn1': 0.00014662742614746094, 'relu1': 6.890296936035156e-05, 'conv2': 0.0011446475982666016, 'bn2': 0.00015115737915039062, 'residual_add_relu2': 0.00011491775512695312}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 59\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016503334045410156, 'bn1': 0.0005803108215332031, 'relu1': 0.0003304481506347656, 'conv2': 0.001631021499633789, 'bn2': 0.0005736351013183594, 'residual_add_relu2': 0.0007750988006591797}\n",
      "{'conv1': 0.0016455650329589844, 'bn1': 0.0005731582641601562, 'relu1': 0.0003314018249511719, 'conv2': 0.001626729965209961, 'bn2': 0.0005676746368408203, 'residual_add_relu2': 0.0007688999176025391}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010554790496826172, 'bn1': 0.00033926963806152344, 'relu1': 0.00017976760864257812, 'conv2': 0.0013058185577392578, 'bn2': 0.00034046173095703125, 'conv3': 0.0004134178161621094, 'residual_add_relu2': 0.0003974437713623047}\n",
      "{'conv1': 0.0013120174407958984, 'bn1': 0.00034809112548828125, 'relu1': 0.0001800060272216797, 'conv2': 0.0013079643249511719, 'bn2': 0.0003590583801269531, 'residual_add_relu2': 0.0003986358642578125}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008003711700439453, 'bn1': 0.00023365020751953125, 'relu1': 0.00010538101196289062, 'conv2': 0.0011572837829589844, 'bn2': 0.00022602081298828125, 'conv3': 0.0003669261932373047, 'residual_add_relu2': 0.00021004676818847656}\n",
      "{'conv1': 0.0011572837829589844, 'bn1': 0.00022411346435546875, 'relu1': 0.00010514259338378906, 'conv2': 0.0011527538299560547, 'bn2': 0.00022912025451660156, 'residual_add_relu2': 0.00021004676818847656}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006711483001708984, 'bn1': 0.00015616416931152344, 'relu1': 6.699562072753906e-05, 'conv2': 0.0011463165283203125, 'bn2': 0.00013971328735351562, 'conv3': 0.00030541419982910156, 'residual_add_relu2': 0.00011587142944335938}\n",
      "{'conv1': 0.0011477470397949219, 'bn1': 0.0001480579376220703, 'relu1': 6.67572021484375e-05, 'conv2': 0.001142263412475586, 'bn2': 0.0001399517059326172, 'residual_add_relu2': 0.00011444091796875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 60\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001653432846069336, 'bn1': 0.0005948543548583984, 'relu1': 0.0003325939178466797, 'conv2': 0.0016357898712158203, 'bn2': 0.0005741119384765625, 'residual_add_relu2': 0.0007729530334472656}\n",
      "{'conv1': 0.0016360282897949219, 'bn1': 0.0005984306335449219, 'relu1': 0.00033593177795410156, 'conv2': 0.0016434192657470703, 'bn2': 0.0005848407745361328, 'residual_add_relu2': 0.0007715225219726562}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001062631607055664, 'bn1': 0.00034928321838378906, 'relu1': 0.0001800060272216797, 'conv2': 0.0013117790222167969, 'bn2': 0.00033664703369140625, 'conv3': 0.0004184246063232422, 'residual_add_relu2': 0.0003936290740966797}\n",
      "{'conv1': 0.0013098716735839844, 'bn1': 0.00034117698669433594, 'relu1': 0.0001804828643798828, 'conv2': 0.0013370513916015625, 'bn2': 0.0003533363342285156, 'residual_add_relu2': 0.00039887428283691406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008015632629394531, 'bn1': 0.00024175643920898438, 'relu1': 0.00010800361633300781, 'conv2': 0.0011603832244873047, 'bn2': 0.00023221969604492188, 'conv3': 0.0003695487976074219, 'residual_add_relu2': 0.00021004676818847656}\n",
      "{'conv1': 0.001163482666015625, 'bn1': 0.00022840499877929688, 'relu1': 0.00010538101196289062, 'conv2': 0.001153707504272461, 'bn2': 0.0002200603485107422, 'residual_add_relu2': 0.00020956993103027344}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006663799285888672, 'bn1': 0.0001614093780517578, 'relu1': 6.67572021484375e-05, 'conv2': 0.0011472702026367188, 'bn2': 0.00014162063598632812, 'conv3': 0.00030684471130371094, 'residual_add_relu2': 0.00011897087097167969}\n",
      "{'conv1': 0.0011522769927978516, 'bn1': 0.000156402587890625, 'relu1': 6.747245788574219e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.00015664100646972656, 'residual_add_relu2': 0.00011610984802246094}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 61\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016558170318603516, 'bn1': 0.0005817413330078125, 'relu1': 0.0003330707550048828, 'conv2': 0.0016376972198486328, 'bn2': 0.0005810260772705078, 'residual_add_relu2': 0.0007729530334472656}\n",
      "{'conv1': 0.0016398429870605469, 'bn1': 0.0005781650543212891, 'relu1': 0.00034046173095703125, 'conv2': 0.0016388893127441406, 'bn2': 0.0005648136138916016, 'residual_add_relu2': 0.0007672309875488281}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010614395141601562, 'bn1': 0.00034546852111816406, 'relu1': 0.0001838207244873047, 'conv2': 0.0013120174407958984, 'bn2': 0.0003409385681152344, 'conv3': 0.00041556358337402344, 'residual_add_relu2': 0.0003955364227294922}\n",
      "{'conv1': 0.0013163089752197266, 'bn1': 0.0003497600555419922, 'relu1': 0.00018143653869628906, 'conv2': 0.0013091564178466797, 'bn2': 0.0003364086151123047, 'residual_add_relu2': 0.0003952980041503906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007965564727783203, 'bn1': 0.00023508071899414062, 'relu1': 0.00010728836059570312, 'conv2': 0.0011591911315917969, 'bn2': 0.00022101402282714844, 'conv3': 0.0003643035888671875, 'residual_add_relu2': 0.00021004676818847656}\n",
      "{'conv1': 0.0011670589447021484, 'bn1': 0.00023317337036132812, 'relu1': 0.00010824203491210938, 'conv2': 0.001157522201538086, 'bn2': 0.0002224445343017578, 'residual_add_relu2': 0.00021409988403320312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006706714630126953, 'bn1': 0.0001506805419921875, 'relu1': 7.271766662597656e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.00014257431030273438, 'conv3': 0.00030517578125, 'residual_add_relu2': 0.00011658668518066406}\n",
      "{'conv1': 0.0011475086212158203, 'bn1': 0.00014638900756835938, 'relu1': 6.67572021484375e-05, 'conv2': 0.001146554946899414, 'bn2': 0.00014090538024902344, 'residual_add_relu2': 0.00011754035949707031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 62\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016682147979736328, 'bn1': 0.0005886554718017578, 'relu1': 0.000331878662109375, 'conv2': 0.0016312599182128906, 'bn2': 0.000579833984375, 'residual_add_relu2': 0.0007734298706054688}\n",
      "{'conv1': 0.0016407966613769531, 'bn1': 0.0005853176116943359, 'relu1': 0.0003342628479003906, 'conv2': 0.0016357898712158203, 'bn2': 0.0005817413330078125, 'residual_add_relu2': 0.0007698535919189453}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010612010955810547, 'bn1': 0.0003466606140136719, 'relu1': 0.00018095970153808594, 'conv2': 0.0013108253479003906, 'bn2': 0.00033593177795410156, 'conv3': 0.00041675567626953125, 'residual_add_relu2': 0.0003960132598876953}\n",
      "{'conv1': 0.0013134479522705078, 'bn1': 0.00035381317138671875, 'relu1': 0.00018095970153808594, 'conv2': 0.0013155937194824219, 'bn2': 0.0003371238708496094, 'residual_add_relu2': 0.0003948211669921875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008072853088378906, 'bn1': 0.0002429485321044922, 'relu1': 0.00010752677917480469, 'conv2': 0.0011622905731201172, 'bn2': 0.0002243518829345703, 'conv3': 0.0003693103790283203, 'residual_add_relu2': 0.0002105236053466797}\n",
      "{'conv1': 0.0011584758758544922, 'bn1': 0.00023317337036132812, 'relu1': 0.00010776519775390625, 'conv2': 0.0011570453643798828, 'bn2': 0.0002498626708984375, 'residual_add_relu2': 0.00021147727966308594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006768703460693359, 'bn1': 0.00017261505126953125, 'relu1': 6.818771362304688e-05, 'conv2': 0.001161813735961914, 'bn2': 0.00015878677368164062, 'conv3': 0.0003190040588378906, 'residual_add_relu2': 0.00011897087097167969}\n",
      "{'conv1': 0.0011534690856933594, 'bn1': 0.00018715858459472656, 'relu1': 6.961822509765625e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.00014972686767578125, 'residual_add_relu2': 0.00011539459228515625}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 63\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016400814056396484, 'bn1': 0.0005612373352050781, 'relu1': 0.0003261566162109375, 'conv2': 0.0016269683837890625, 'bn2': 0.0005466938018798828, 'residual_add_relu2': 0.0007677078247070312}\n",
      "{'conv1': 0.0016269683837890625, 'bn1': 0.0005474090576171875, 'relu1': 0.0003237724304199219, 'conv2': 0.0016207695007324219, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.0007669925689697266}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010404586791992188, 'bn1': 0.0003180503845214844, 'relu1': 0.0001728534698486328, 'conv2': 0.0012979507446289062, 'bn2': 0.00032329559326171875, 'conv3': 0.0004048347473144531, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0012955665588378906, 'bn1': 0.0003151893615722656, 'relu1': 0.00017333030700683594, 'conv2': 0.0018355846405029297, 'bn2': 0.0003616809844970703, 'residual_add_relu2': 0.0003986358642578125}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007946491241455078, 'bn1': 0.00020623207092285156, 'relu1': 9.918212890625e-05, 'conv2': 0.0011472702026367188, 'bn2': 0.00020885467529296875, 'conv3': 0.0003561973571777344, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.0011494159698486328, 'bn1': 0.0002503395080566406, 'relu1': 0.00011682510375976562, 'conv2': 0.0011527538299560547, 'bn2': 0.00021314620971679688, 'residual_add_relu2': 0.00020766258239746094}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006587505340576172, 'bn1': 0.0001366138458251953, 'relu1': 7.390975952148438e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.00012969970703125, 'conv3': 0.0002994537353515625, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.001140594482421875, 'bn1': 0.00013327598571777344, 'relu1': 6.246566772460938e-05, 'conv2': 0.0011341571807861328, 'bn2': 0.0001266002655029297, 'residual_add_relu2': 0.00011610984802246094}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 64\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016398429870605469, 'bn1': 0.0005555152893066406, 'relu1': 0.0003237724304199219, 'conv2': 0.0016169548034667969, 'bn2': 0.0005469322204589844, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016181468963623047, 'bn1': 0.0005428791046142578, 'relu1': 0.0003228187561035156, 'conv2': 0.0016090869903564453, 'bn2': 0.0005459785461425781, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010390281677246094, 'bn1': 0.0003151893615722656, 'relu1': 0.0001747608184814453, 'conv2': 0.0012943744659423828, 'bn2': 0.0003104209899902344, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0012965202331542969, 'bn1': 0.0003135204315185547, 'relu1': 0.00017380714416503906, 'conv2': 0.0012984275817871094, 'bn2': 0.0003173351287841797, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007860660552978516, 'bn1': 0.00020837783813476562, 'relu1': 0.00010037422180175781, 'conv2': 0.001146078109741211, 'bn2': 0.0002124309539794922, 'conv3': 0.0003523826599121094, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0011434555053710938, 'bn1': 0.00019788742065429688, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011377334594726562, 'bn2': 0.00019359588623046875, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006539821624755859, 'bn1': 0.00012087821960449219, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011317729949951172, 'bn2': 0.00011444091796875, 'conv3': 0.0002925395965576172, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.001135110855102539, 'bn1': 0.00011968612670898438, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011372566223144531, 'bn2': 0.00011539459228515625, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 65\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.002028942108154297, 'bn1': 0.0006005764007568359, 'relu1': 0.00033164024353027344, 'conv2': 0.001623392105102539, 'bn2': 0.0005450248718261719, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.00162506103515625, 'bn1': 0.0005466938018798828, 'relu1': 0.0003235340118408203, 'conv2': 0.0016162395477294922, 'bn2': 0.0005419254302978516, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010406970977783203, 'bn1': 0.0003147125244140625, 'relu1': 0.00017309188842773438, 'conv2': 0.0012941360473632812, 'bn2': 0.00031304359436035156, 'conv3': 0.0004000663757324219, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0012955665588378906, 'bn1': 0.0003135204315185547, 'relu1': 0.00017333030700683594, 'conv2': 0.0012903213500976562, 'bn2': 0.00031065940856933594, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007801055908203125, 'bn1': 0.00019860267639160156, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011415481567382812, 'bn2': 0.0001952648162841797, 'conv3': 0.0003521442413330078, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011432170867919922, 'bn1': 0.00019812583923339844, 'relu1': 9.751319885253906e-05, 'conv2': 0.001138448715209961, 'bn2': 0.00018668174743652344, 'residual_add_relu2': 0.00020265579223632812}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006480216979980469, 'bn1': 0.00012159347534179688, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011298656463623047, 'bn2': 0.00010800361633300781, 'conv3': 0.0003039836883544922, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011305809020996094, 'bn1': 0.0001125335693359375, 'relu1': 5.6743621826171875e-05, 'conv2': 0.0011248588562011719, 'bn2': 0.00010728836059570312, 'residual_add_relu2': 0.00010800361633300781}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 66\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001664876937866211, 'bn1': 0.0005784034729003906, 'relu1': 0.0003311634063720703, 'conv2': 0.0016264915466308594, 'bn2': 0.0005686283111572266, 'residual_add_relu2': 0.0007731914520263672}\n",
      "{'conv1': 0.0016362667083740234, 'bn1': 0.0005700588226318359, 'relu1': 0.0003304481506347656, 'conv2': 0.0016341209411621094, 'bn2': 0.0005664825439453125, 'residual_add_relu2': 0.0007691383361816406}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010528564453125, 'bn1': 0.0003383159637451172, 'relu1': 0.00017881393432617188, 'conv2': 0.0013060569763183594, 'bn2': 0.00033473968505859375, 'conv3': 0.00041222572326660156, 'residual_add_relu2': 0.0003933906555175781}\n",
      "{'conv1': 0.0013091564178466797, 'bn1': 0.000347137451171875, 'relu1': 0.00017976760864257812, 'conv2': 0.0013051033020019531, 'bn2': 0.0003399848937988281, 'residual_add_relu2': 0.0003943443298339844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007960796356201172, 'bn1': 0.00022077560424804688, 'relu1': 0.00010657310485839844, 'conv2': 0.0011548995971679688, 'bn2': 0.0002181529998779297, 'conv3': 0.0003635883331298828, 'residual_add_relu2': 0.0002269744873046875}\n",
      "{'conv1': 0.0011601448059082031, 'bn1': 0.00022459030151367188, 'relu1': 0.0001049041748046875, 'conv2': 0.0011518001556396484, 'bn2': 0.0002162456512451172, 'residual_add_relu2': 0.00020837783813476562}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006659030914306641, 'bn1': 0.0001475811004638672, 'relu1': 6.651878356933594e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00013971328735351562, 'conv3': 0.00030541419982910156, 'residual_add_relu2': 0.00011563301086425781}\n",
      "{'conv1': 0.0011487007141113281, 'bn1': 0.00014495849609375, 'relu1': 6.532669067382812e-05, 'conv2': 0.0011420249938964844, 'bn2': 0.00013947486877441406, 'residual_add_relu2': 0.00011444091796875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 67\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016472339630126953, 'bn1': 0.0005736351013183594, 'relu1': 0.00033473968505859375, 'conv2': 0.0016417503356933594, 'bn2': 0.0005674362182617188, 'residual_add_relu2': 0.0007693767547607422}\n",
      "{'conv1': 0.0016338825225830078, 'bn1': 0.0005712509155273438, 'relu1': 0.00033020973205566406, 'conv2': 0.0016269683837890625, 'bn2': 0.0005612373352050781, 'residual_add_relu2': 0.0007669925689697266}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010526180267333984, 'bn1': 0.00033664703369140625, 'relu1': 0.00017905235290527344, 'conv2': 0.0013051033020019531, 'bn2': 0.00033211708068847656, 'conv3': 0.0004107952117919922, 'residual_add_relu2': 0.0003960132598876953}\n",
      "{'conv1': 0.0013127326965332031, 'bn1': 0.00034308433532714844, 'relu1': 0.00017976760864257812, 'conv2': 0.00130462646484375, 'bn2': 0.00033283233642578125, 'residual_add_relu2': 0.00039386749267578125}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007944107055664062, 'bn1': 0.0002231597900390625, 'relu1': 0.00010514259338378906, 'conv2': 0.0011529922485351562, 'bn2': 0.00021719932556152344, 'conv3': 0.00036454200744628906, 'residual_add_relu2': 0.00020813941955566406}\n",
      "{'conv1': 0.0011563301086425781, 'bn1': 0.00022268295288085938, 'relu1': 0.0001049041748046875, 'conv2': 0.0011518001556396484, 'bn2': 0.00021576881408691406, 'residual_add_relu2': 0.0002086162567138672}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006647109985351562, 'bn1': 0.00016927719116210938, 'relu1': 6.699562072753906e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.00014901161193847656, 'conv3': 0.00030517578125, 'residual_add_relu2': 0.00011658668518066406}\n",
      "{'conv1': 0.0011470317840576172, 'bn1': 0.00014519691467285156, 'relu1': 6.4849853515625e-05, 'conv2': 0.001142740249633789, 'bn2': 0.00015163421630859375, 'residual_add_relu2': 0.00011539459228515625}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 68\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016551017761230469, 'bn1': 0.0005824565887451172, 'relu1': 0.0003311634063720703, 'conv2': 0.001630544662475586, 'bn2': 0.0005669593811035156, 'residual_add_relu2': 0.0007724761962890625}\n",
      "{'conv1': 0.0016367435455322266, 'bn1': 0.0005660057067871094, 'relu1': 0.0003287792205810547, 'conv2': 0.0016322135925292969, 'bn2': 0.0005640983581542969, 'residual_add_relu2': 0.0007722377777099609}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010523796081542969, 'bn1': 0.0003383159637451172, 'relu1': 0.00017905235290527344, 'conv2': 0.0013043880462646484, 'bn2': 0.00033164024353027344, 'conv3': 0.0004127025604248047, 'residual_add_relu2': 0.0003948211669921875}\n",
      "{'conv1': 0.001308441162109375, 'bn1': 0.0003376007080078125, 'relu1': 0.00018024444580078125, 'conv2': 0.0013055801391601562, 'bn2': 0.0003325939178466797, 'residual_add_relu2': 0.00039458274841308594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007948875427246094, 'bn1': 0.00022482872009277344, 'relu1': 0.00010895729064941406, 'conv2': 0.0011577606201171875, 'bn2': 0.00022864341735839844, 'conv3': 0.00036597251892089844, 'residual_add_relu2': 0.00020956993103027344}\n",
      "{'conv1': 0.0011610984802246094, 'bn1': 0.00022268295288085938, 'relu1': 0.00010442733764648438, 'conv2': 0.0011532306671142578, 'bn2': 0.00022125244140625, 'residual_add_relu2': 0.00020885467529296875}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006666183471679688, 'bn1': 0.0001442432403564453, 'relu1': 6.628036499023438e-05, 'conv2': 0.0011444091796875, 'bn2': 0.00013875961303710938, 'conv3': 0.0002999305725097656, 'residual_add_relu2': 0.00011515617370605469}\n",
      "{'conv1': 0.0011463165283203125, 'bn1': 0.00014638900756835938, 'relu1': 6.580352783203125e-05, 'conv2': 0.0011420249938964844, 'bn2': 0.00013709068298339844, 'residual_add_relu2': 0.00011372566223144531}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 69\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016562938690185547, 'bn1': 0.0005774497985839844, 'relu1': 0.00033164024353027344, 'conv2': 0.0016350746154785156, 'bn2': 0.0005714893341064453, 'residual_add_relu2': 0.0007710456848144531}\n",
      "{'conv1': 0.0016405582427978516, 'bn1': 0.0005693435668945312, 'relu1': 0.00033211708068847656, 'conv2': 0.0016336441040039062, 'bn2': 0.0005640983581542969, 'residual_add_relu2': 0.0007686614990234375}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001062154769897461, 'bn1': 0.0003402233123779297, 'relu1': 0.0001804828643798828, 'conv2': 0.001306295394897461, 'bn2': 0.0003314018249511719, 'conv3': 0.00041103363037109375, 'residual_add_relu2': 0.00039577484130859375}\n",
      "{'conv1': 0.0013265609741210938, 'bn1': 0.00034499168395996094, 'relu1': 0.00018072128295898438, 'conv2': 0.0013060569763183594, 'bn2': 0.0003323554992675781, 'residual_add_relu2': 0.00039505958557128906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007944107055664062, 'bn1': 0.00022220611572265625, 'relu1': 0.00010442733764648438, 'conv2': 0.001154184341430664, 'bn2': 0.00021767616271972656, 'conv3': 0.00036263465881347656, 'residual_add_relu2': 0.00020885467529296875}\n",
      "{'conv1': 0.0011565685272216797, 'bn1': 0.0002243518829345703, 'relu1': 0.00010514259338378906, 'conv2': 0.0011510848999023438, 'bn2': 0.00021696090698242188, 'residual_add_relu2': 0.000209808349609375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006632804870605469, 'bn1': 0.00014328956604003906, 'relu1': 6.604194641113281e-05, 'conv2': 0.0011444091796875, 'bn2': 0.00013899803161621094, 'conv3': 0.0003056526184082031, 'residual_add_relu2': 0.00011467933654785156}\n",
      "{'conv1': 0.0011448860168457031, 'bn1': 0.00014519691467285156, 'relu1': 6.4849853515625e-05, 'conv2': 0.0011408329010009766, 'bn2': 0.00014925003051757812, 'residual_add_relu2': 0.00011491775512695312}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 70\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016548633575439453, 'bn1': 0.0005848407745361328, 'relu1': 0.0003330707550048828, 'conv2': 0.0016355514526367188, 'bn2': 0.0005667209625244141, 'residual_add_relu2': 0.0007708072662353516}\n",
      "{'conv1': 0.0016405582427978516, 'bn1': 0.0005738735198974609, 'relu1': 0.00032973289489746094, 'conv2': 0.0016498565673828125, 'bn2': 0.0005660057067871094, 'residual_add_relu2': 0.0007693767547607422}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001056671142578125, 'bn1': 0.00034236907958984375, 'relu1': 0.000179290771484375, 'conv2': 0.0013055801391601562, 'bn2': 0.0003364086151123047, 'conv3': 0.00041604042053222656, 'residual_add_relu2': 0.0003974437713623047}\n",
      "{'conv1': 0.0013120174407958984, 'bn1': 0.0003418922424316406, 'relu1': 0.0001823902130126953, 'conv2': 0.0013077259063720703, 'bn2': 0.00033855438232421875, 'residual_add_relu2': 0.00039577484130859375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007946491241455078, 'bn1': 0.00022530555725097656, 'relu1': 0.00010609626770019531, 'conv2': 0.0011553764343261719, 'bn2': 0.0002186298370361328, 'conv3': 0.00036907196044921875, 'residual_add_relu2': 0.0002086162567138672}\n",
      "{'conv1': 0.0011582374572753906, 'bn1': 0.00022602081298828125, 'relu1': 0.00010585784912109375, 'conv2': 0.00115203857421875, 'bn2': 0.0002167224884033203, 'residual_add_relu2': 0.00020885467529296875}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000667572021484375, 'bn1': 0.00015997886657714844, 'relu1': 6.794929504394531e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00014281272888183594, 'conv3': 0.00030422210693359375, 'residual_add_relu2': 0.0001163482666015625}\n",
      "{'conv1': 0.001149892807006836, 'bn1': 0.00017213821411132812, 'relu1': 6.937980651855469e-05, 'conv2': 0.0011539459228515625, 'bn2': 0.00014257431030273438, 'residual_add_relu2': 0.00011515617370605469}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 71\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016980171203613281, 'bn1': 0.0006546974182128906, 'relu1': 0.0003571510314941406, 'conv2': 0.0016856193542480469, 'bn2': 0.0006320476531982422, 'residual_add_relu2': 0.000789642333984375}\n",
      "{'conv1': 0.0016808509826660156, 'bn1': 0.0006427764892578125, 'relu1': 0.00034689903259277344, 'conv2': 0.0016782283782958984, 'bn2': 0.000629425048828125, 'residual_add_relu2': 0.0007946491241455078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010912418365478516, 'bn1': 0.00039577484130859375, 'relu1': 0.00020551681518554688, 'conv2': 0.0013439655303955078, 'bn2': 0.0004570484161376953, 'conv3': 0.0004508495330810547, 'residual_add_relu2': 0.0004112720489501953}\n",
      "{'conv1': 0.0013461112976074219, 'bn1': 0.0003986358642578125, 'relu1': 0.0001900196075439453, 'conv2': 0.001737833023071289, 'bn2': 0.0005884170532226562, 'residual_add_relu2': 0.0004208087921142578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008668899536132812, 'bn1': 0.0003082752227783203, 'relu1': 0.0001366138458251953, 'conv2': 0.0012252330780029297, 'bn2': 0.0002994537353515625, 'conv3': 0.00042057037353515625, 'residual_add_relu2': 0.00022602081298828125}\n",
      "{'conv1': 0.0011947154998779297, 'bn1': 0.0003027915954589844, 'relu1': 0.00012826919555664062, 'conv2': 0.0011909008026123047, 'bn2': 0.00029397010803222656, 'residual_add_relu2': 0.00021886825561523438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0007121562957763672, 'bn1': 0.000232696533203125, 'relu1': 0.000102996826171875, 'conv2': 0.0011827945709228516, 'bn2': 0.00022363662719726562, 'conv3': 0.0003464221954345703, 'residual_add_relu2': 0.0001342296600341797}\n",
      "{'conv1': 0.001186370849609375, 'bn1': 0.0002377033233642578, 'relu1': 7.939338684082031e-05, 'conv2': 0.00116729736328125, 'bn2': 0.0002486705780029297, 'residual_add_relu2': 0.0001354217529296875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 72\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016512870788574219, 'bn1': 0.0005822181701660156, 'relu1': 0.0003311634063720703, 'conv2': 0.0016281604766845703, 'bn2': 0.0005619525909423828, 'residual_add_relu2': 0.0007698535919189453}\n",
      "{'conv1': 0.0016450881958007812, 'bn1': 0.0005762577056884766, 'relu1': 0.00032830238342285156, 'conv2': 0.0016298294067382812, 'bn2': 0.0005643367767333984, 'residual_add_relu2': 0.0007672309875488281}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010883808135986328, 'bn1': 0.0003376007080078125, 'relu1': 0.00017833709716796875, 'conv2': 0.0013079643249511719, 'bn2': 0.0003345012664794922, 'conv3': 0.0004177093505859375, 'residual_add_relu2': 0.0003936290740966797}\n",
      "{'conv1': 0.0013086795806884766, 'bn1': 0.0003364086151123047, 'relu1': 0.00017905235290527344, 'conv2': 0.0013048648834228516, 'bn2': 0.00034165382385253906, 'residual_add_relu2': 0.00039458274841308594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007963180541992188, 'bn1': 0.00022339820861816406, 'relu1': 0.00010752677917480469, 'conv2': 0.001155853271484375, 'bn2': 0.00023031234741210938, 'conv3': 0.0003647804260253906, 'residual_add_relu2': 0.0002090930938720703}\n",
      "{'conv1': 0.0011560916900634766, 'bn1': 0.00022459030151367188, 'relu1': 0.00010442733764648438, 'conv2': 0.0011510848999023438, 'bn2': 0.00021839141845703125, 'residual_add_relu2': 0.00020933151245117188}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.00067138671875, 'bn1': 0.00014472007751464844, 'relu1': 6.556510925292969e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.00013875961303710938, 'conv3': 0.0003025531768798828, 'residual_add_relu2': 0.0001163482666015625}\n",
      "{'conv1': 0.0011479854583740234, 'bn1': 0.00014472007751464844, 'relu1': 6.556510925292969e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00014281272888183594, 'residual_add_relu2': 0.00011515617370605469}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 73\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016775131225585938, 'bn1': 0.0005915164947509766, 'relu1': 0.0003333091735839844, 'conv2': 0.0016436576843261719, 'bn2': 0.0005817413330078125, 'residual_add_relu2': 0.0007739067077636719}\n",
      "{'conv1': 0.0016465187072753906, 'bn1': 0.000576019287109375, 'relu1': 0.0003311634063720703, 'conv2': 0.0016336441040039062, 'bn2': 0.0005648136138916016, 'residual_add_relu2': 0.0007708072662353516}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001056671142578125, 'bn1': 0.0003466606140136719, 'relu1': 0.0001804828643798828, 'conv2': 0.0013115406036376953, 'bn2': 0.0003349781036376953, 'conv3': 0.00041794776916503906, 'residual_add_relu2': 0.0003974437713623047}\n",
      "{'conv1': 0.0013141632080078125, 'bn1': 0.0003383159637451172, 'relu1': 0.00017976760864257812, 'conv2': 0.001306772232055664, 'bn2': 0.00033736228942871094, 'residual_add_relu2': 0.0004069805145263672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008039474487304688, 'bn1': 0.00023102760314941406, 'relu1': 0.00010657310485839844, 'conv2': 0.0011568069458007812, 'bn2': 0.00022339820861816406, 'conv3': 0.0003674030303955078, 'residual_add_relu2': 0.00020933151245117188}\n",
      "{'conv1': 0.0011591911315917969, 'bn1': 0.0002269744873046875, 'relu1': 0.00010538101196289062, 'conv2': 0.0011525154113769531, 'bn2': 0.0002224445343017578, 'residual_add_relu2': 0.00020956993103027344}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006642341613769531, 'bn1': 0.0001506805419921875, 'relu1': 6.604194641113281e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.0001461505889892578, 'conv3': 0.0003075599670410156, 'residual_add_relu2': 0.00011491775512695312}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.00014710426330566406, 'relu1': 6.556510925292969e-05, 'conv2': 0.0011408329010009766, 'bn2': 0.0001373291015625, 'residual_add_relu2': 0.00012922286987304688}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 74\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016493797302246094, 'bn1': 0.0005824565887451172, 'relu1': 0.0003294944763183594, 'conv2': 0.0016260147094726562, 'bn2': 0.0005664825439453125, 'residual_add_relu2': 0.0007691383361816406}\n",
      "{'conv1': 0.001634836196899414, 'bn1': 0.0005676746368408203, 'relu1': 0.00033164024353027344, 'conv2': 0.001630544662475586, 'bn2': 0.0005612373352050781, 'residual_add_relu2': 0.0007665157318115234}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010492801666259766, 'bn1': 0.00034236907958984375, 'relu1': 0.0001804828643798828, 'conv2': 0.0013055801391601562, 'bn2': 0.0003294944763183594, 'conv3': 0.0004112720489501953, 'residual_add_relu2': 0.0003941059112548828}\n",
      "{'conv1': 0.001306772232055664, 'bn1': 0.0003380775451660156, 'relu1': 0.00018405914306640625, 'conv2': 0.0013039112091064453, 'bn2': 0.0003333091735839844, 'residual_add_relu2': 0.00039505958557128906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007987022399902344, 'bn1': 0.00023126602172851562, 'relu1': 0.00010585784912109375, 'conv2': 0.001155853271484375, 'bn2': 0.00021696090698242188, 'conv3': 0.00036334991455078125, 'residual_add_relu2': 0.00020885467529296875}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00022268295288085938, 'relu1': 0.00010538101196289062, 'conv2': 0.0011522769927978516, 'bn2': 0.0002167224884033203, 'residual_add_relu2': 0.00020885467529296875}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006639957427978516, 'bn1': 0.00014328956604003906, 'relu1': 6.651878356933594e-05, 'conv2': 0.0011444091796875, 'bn2': 0.00013828277587890625, 'conv3': 0.0003066062927246094, 'residual_add_relu2': 0.0001201629638671875}\n",
      "{'conv1': 0.0011508464813232422, 'bn1': 0.00014638900756835938, 'relu1': 6.604194641113281e-05, 'conv2': 0.0011434555053710938, 'bn2': 0.00013971328735351562, 'residual_add_relu2': 0.00011372566223144531}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 75\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016834735870361328, 'bn1': 0.0006403923034667969, 'relu1': 0.00035834312438964844, 'conv2': 0.0016703605651855469, 'bn2': 0.0006303787231445312, 'residual_add_relu2': 0.0007963180541992188}\n",
      "{'conv1': 0.0016782283782958984, 'bn1': 0.0006372928619384766, 'relu1': 0.00040721893310546875, 'conv2': 0.001689910888671875, 'bn2': 0.0006306171417236328, 'residual_add_relu2': 0.0007956027984619141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010900497436523438, 'bn1': 0.00039768218994140625, 'relu1': 0.00019860267639160156, 'conv2': 0.001352071762084961, 'bn2': 0.0003981590270996094, 'conv3': 0.0004596710205078125, 'residual_add_relu2': 0.00040841102600097656}\n",
      "{'conv1': 0.0013566017150878906, 'bn1': 0.0003991127014160156, 'relu1': 0.00020885467529296875, 'conv2': 0.0013456344604492188, 'bn2': 0.0004107952117919922, 'residual_add_relu2': 0.00041556358337402344}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008273124694824219, 'bn1': 0.0002980232238769531, 'relu1': 0.00013136863708496094, 'conv2': 0.0011937618255615234, 'bn2': 0.0002796649932861328, 'conv3': 0.00039577484130859375, 'residual_add_relu2': 0.00023126602172851562}\n",
      "{'conv1': 0.001186370849609375, 'bn1': 0.0002963542938232422, 'relu1': 0.00012564659118652344, 'conv2': 0.0011796951293945312, 'bn2': 0.00028586387634277344, 'residual_add_relu2': 0.00022935867309570312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006971359252929688, 'bn1': 0.00022029876708984375, 'relu1': 7.581710815429688e-05, 'conv2': 0.0011663436889648438, 'bn2': 0.00022268295288085938, 'conv3': 0.00034809112548828125, 'residual_add_relu2': 0.00012826919555664062}\n",
      "{'conv1': 0.0011823177337646484, 'bn1': 0.0002243518829345703, 'relu1': 8.7738037109375e-05, 'conv2': 0.0011706352233886719, 'bn2': 0.0002033710479736328, 'residual_add_relu2': 0.00012087821960449219}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 76\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001646280288696289, 'bn1': 0.0005784034729003906, 'relu1': 0.0003294944763183594, 'conv2': 0.001628875732421875, 'bn2': 0.0005650520324707031, 'residual_add_relu2': 0.0007708072662353516}\n",
      "{'conv1': 0.001631021499633789, 'bn1': 0.0005679130554199219, 'relu1': 0.00033783912658691406, 'conv2': 0.0016295909881591797, 'bn2': 0.0005595684051513672, 'residual_add_relu2': 0.0007681846618652344}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010497570037841797, 'bn1': 0.0003380775451660156, 'relu1': 0.00017976760864257812, 'conv2': 0.0013096332550048828, 'bn2': 0.00033211708068847656, 'conv3': 0.0004127025604248047, 'residual_add_relu2': 0.0003952980041503906}\n",
      "{'conv1': 0.0013077259063720703, 'bn1': 0.0003383159637451172, 'relu1': 0.00018024444580078125, 'conv2': 0.0013053417205810547, 'bn2': 0.0003330707550048828, 'residual_add_relu2': 0.0003955364227294922}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007977485656738281, 'bn1': 0.0002243518829345703, 'relu1': 0.00010466575622558594, 'conv2': 0.0011539459228515625, 'bn2': 0.00022172927856445312, 'conv3': 0.0003650188446044922, 'residual_add_relu2': 0.00020837783813476562}\n",
      "{'conv1': 0.0011548995971679688, 'bn1': 0.00022149085998535156, 'relu1': 0.0001533031463623047, 'conv2': 0.001157522201538086, 'bn2': 0.00021982192993164062, 'residual_add_relu2': 0.00020837783813476562}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006649494171142578, 'bn1': 0.00014638900756835938, 'relu1': 6.556510925292969e-05, 'conv2': 0.0011446475982666016, 'bn2': 0.00013756752014160156, 'conv3': 0.00030493736267089844, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.0011487007141113281, 'bn1': 0.00014519691467285156, 'relu1': 6.532669067382812e-05, 'conv2': 0.001142263412475586, 'bn2': 0.0001392364501953125, 'residual_add_relu2': 0.00011587142944335938}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 77\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016529560089111328, 'bn1': 0.0005865097045898438, 'relu1': 0.0003330707550048828, 'conv2': 0.0016338825225830078, 'bn2': 0.0005662441253662109, 'residual_add_relu2': 0.00077056884765625}\n",
      "{'conv1': 0.001638174057006836, 'bn1': 0.0005712509155273438, 'relu1': 0.0003287792205810547, 'conv2': 0.0016236305236816406, 'bn2': 0.0005624294281005859, 'residual_add_relu2': 0.0007677078247070312}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010519027709960938, 'bn1': 0.0003387928009033203, 'relu1': 0.000179290771484375, 'conv2': 0.0013074874877929688, 'bn2': 0.0003333091735839844, 'conv3': 0.0004127025604248047, 'residual_add_relu2': 0.0003955364227294922}\n",
      "{'conv1': 0.0013070106506347656, 'bn1': 0.00033736228942871094, 'relu1': 0.00017976760864257812, 'conv2': 0.0013048648834228516, 'bn2': 0.00033473968505859375, 'residual_add_relu2': 0.0003943443298339844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007951259613037109, 'bn1': 0.0002472400665283203, 'relu1': 0.00010585784912109375, 'conv2': 0.0011556148529052734, 'bn2': 0.0002522468566894531, 'conv3': 0.000370025634765625, 'residual_add_relu2': 0.00020813941955566406}\n",
      "{'conv1': 0.0011546611785888672, 'bn1': 0.00022125244140625, 'relu1': 0.00010418891906738281, 'conv2': 0.0011527538299560547, 'bn2': 0.00021791458129882812, 'residual_add_relu2': 0.00020933151245117188}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006670951843261719, 'bn1': 0.00014519691467285156, 'relu1': 6.651878356933594e-05, 'conv2': 0.0011439323425292969, 'bn2': 0.00013709068298339844, 'conv3': 0.0003039836883544922, 'residual_add_relu2': 0.00011467933654785156}\n",
      "{'conv1': 0.001146078109741211, 'bn1': 0.00014400482177734375, 'relu1': 6.604194641113281e-05, 'conv2': 0.0011410713195800781, 'bn2': 0.0001423358917236328, 'residual_add_relu2': 0.00011563301086425781}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 78\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016472339630126953, 'bn1': 0.0005791187286376953, 'relu1': 0.00033092498779296875, 'conv2': 0.0016295909881591797, 'bn2': 0.0005660057067871094, 'residual_add_relu2': 0.0007688999176025391}\n",
      "{'conv1': 0.0016369819641113281, 'bn1': 0.0005733966827392578, 'relu1': 0.0003294944763183594, 'conv2': 0.0016307830810546875, 'bn2': 0.000560760498046875, 'residual_add_relu2': 0.0007696151733398438}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010516643524169922, 'bn1': 0.0003612041473388672, 'relu1': 0.00017976760864257812, 'conv2': 0.0013077259063720703, 'bn2': 0.0003345012664794922, 'conv3': 0.0004138946533203125, 'residual_add_relu2': 0.0003941059112548828}\n",
      "{'conv1': 0.0013070106506347656, 'bn1': 0.00033593177795410156, 'relu1': 0.0001800060272216797, 'conv2': 0.0013031959533691406, 'bn2': 0.00034117698669433594, 'residual_add_relu2': 0.0003948211669921875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000797271728515625, 'bn1': 0.0002231597900390625, 'relu1': 0.0001049041748046875, 'conv2': 0.001154184341430664, 'bn2': 0.00021886825561523438, 'conv3': 0.0003616809844970703, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011448860168457031, 'bn1': 0.00019741058349609375, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011370182037353516, 'bn2': 0.0001838207244873047, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006504058837890625, 'bn1': 0.00011324882507324219, 'relu1': 5.6743621826171875e-05, 'conv2': 0.0011262893676757812, 'bn2': 0.00011515617370605469, 'conv3': 0.00028133392333984375, 'residual_add_relu2': 0.00010895729064941406}\n",
      "{'conv1': 0.0011272430419921875, 'bn1': 0.00011110305786132812, 'relu1': 5.626678466796875e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.0001266002655029297, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 79\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016591548919677734, 'bn1': 0.0006029605865478516, 'relu1': 0.00034880638122558594, 'conv2': 0.0016498565673828125, 'bn2': 0.000591278076171875, 'residual_add_relu2': 0.0007855892181396484}\n",
      "{'conv1': 0.0016522407531738281, 'bn1': 0.0005984306335449219, 'relu1': 0.00034737586975097656, 'conv2': 0.0016407966613769531, 'bn2': 0.0005931854248046875, 'residual_add_relu2': 0.0007863044738769531}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010721683502197266, 'bn1': 0.0003719329833984375, 'relu1': 0.00018310546875, 'conv2': 0.0013308525085449219, 'bn2': 0.00035834312438964844, 'conv3': 0.0004258155822753906, 'residual_add_relu2': 0.0004088878631591797}\n",
      "{'conv1': 0.0013265609741210938, 'bn1': 0.0003631114959716797, 'relu1': 0.00019407272338867188, 'conv2': 0.0013148784637451172, 'bn2': 0.0003685951232910156, 'residual_add_relu2': 0.0004069805145263672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008101463317871094, 'bn1': 0.0002529621124267578, 'relu1': 0.0001163482666015625, 'conv2': 0.0011653900146484375, 'bn2': 0.0002422332763671875, 'conv3': 0.0003769397735595703, 'residual_add_relu2': 0.0002162456512451172}\n",
      "{'conv1': 0.001190185546875, 'bn1': 0.0002560615539550781, 'relu1': 0.00010633468627929688, 'conv2': 0.0011572837829589844, 'bn2': 0.00024509429931640625, 'residual_add_relu2': 0.00022077560424804688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006725788116455078, 'bn1': 0.00016832351684570312, 'relu1': 7.939338684082031e-05, 'conv2': 0.0011658668518066406, 'bn2': 0.00016808509826660156, 'conv3': 0.000308990478515625, 'residual_add_relu2': 0.000125885009765625}\n",
      "{'conv1': 0.0011594295501708984, 'bn1': 0.00018310546875, 'relu1': 6.628036499023438e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00017309188842773438, 'residual_add_relu2': 0.00012683868408203125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 80\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016322135925292969, 'bn1': 0.0005550384521484375, 'relu1': 0.0003230571746826172, 'conv2': 0.0016207695007324219, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0008060932159423828}\n",
      "{'conv1': 0.001623392105102539, 'bn1': 0.0006711483001708984, 'relu1': 0.00037550926208496094, 'conv2': 0.0016489028930664062, 'bn2': 0.0005686283111572266, 'residual_add_relu2': 0.0007839202880859375}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001047372817993164, 'bn1': 0.0003256797790527344, 'relu1': 0.00017333030700683594, 'conv2': 0.0012934207916259766, 'bn2': 0.00030684471130371094, 'conv3': 0.00040268898010253906, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.0012979507446289062, 'bn1': 0.00031876564025878906, 'relu1': 0.0001747608184814453, 'conv2': 0.0012941360473632812, 'bn2': 0.000308990478515625, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007817745208740234, 'bn1': 0.000202178955078125, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011434555053710938, 'bn2': 0.00019407272338867188, 'conv3': 0.0003542900085449219, 'residual_add_relu2': 0.0002503395080566406}\n",
      "{'conv1': 0.0011510848999023438, 'bn1': 0.0002067089080810547, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011403560638427734, 'bn2': 0.00019502639770507812, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006785392761230469, 'bn1': 0.00012636184692382812, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011341571807861328, 'bn2': 0.00011754035949707031, 'conv3': 0.0002913475036621094, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011363029479980469, 'bn1': 0.00012183189392089844, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011310577392578125, 'bn2': 0.00011372566223144531, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 81\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016527175903320312, 'bn1': 0.0005562305450439453, 'relu1': 0.0003247261047363281, 'conv2': 0.001691579818725586, 'bn2': 0.0005521774291992188, 'residual_add_relu2': 0.0007679462432861328}\n",
      "{'conv1': 0.0016188621520996094, 'bn1': 0.0005440711975097656, 'relu1': 0.00032258033752441406, 'conv2': 0.0016164779663085938, 'bn2': 0.000537872314453125, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010402202606201172, 'bn1': 0.0003116130828857422, 'relu1': 0.00017213821411132812, 'conv2': 0.0012934207916259766, 'bn2': 0.0003075599670410156, 'conv3': 0.0003979206085205078, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.0012938976287841797, 'bn1': 0.00031304359436035156, 'relu1': 0.00017380714416503906, 'conv2': 0.0012917518615722656, 'bn2': 0.00030875205993652344, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007784366607666016, 'bn1': 0.0001957416534423828, 'relu1': 9.846687316894531e-05, 'conv2': 0.001140594482421875, 'bn2': 0.0002014636993408203, 'conv3': 0.0003552436828613281, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011458396911621094, 'bn1': 0.0001964569091796875, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011379718780517578, 'bn2': 0.00019216537475585938, 'residual_add_relu2': 0.00020575523376464844}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006551742553710938, 'bn1': 0.00011992454528808594, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011317729949951172, 'bn2': 0.00011301040649414062, 'conv3': 0.0002868175506591797, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011320114135742188, 'bn1': 0.00011849403381347656, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011301040649414062, 'bn2': 0.00011372566223144531, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 82\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016868114471435547, 'bn1': 0.0005970001220703125, 'relu1': 0.00033926963806152344, 'conv2': 0.0016434192657470703, 'bn2': 0.0005772113800048828, 'residual_add_relu2': 0.0007736682891845703}\n",
      "{'conv1': 0.0016586780548095703, 'bn1': 0.0005896091461181641, 'relu1': 0.00033926963806152344, 'conv2': 0.001653432846069336, 'bn2': 0.0005769729614257812, 'residual_add_relu2': 0.0007865428924560547}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001071929931640625, 'bn1': 0.0003476142883300781, 'relu1': 0.0001900196075439453, 'conv2': 0.0013196468353271484, 'bn2': 0.00034165382385253906, 'conv3': 0.0004322528839111328, 'residual_add_relu2': 0.0003952980041503906}\n",
      "{'conv1': 0.001323699951171875, 'bn1': 0.0003426074981689453, 'relu1': 0.0001971721649169922, 'conv2': 0.0013222694396972656, 'bn2': 0.00035858154296875, 'residual_add_relu2': 0.0003972053527832031}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008046627044677734, 'bn1': 0.00023126602172851562, 'relu1': 0.00011491775512695312, 'conv2': 0.0011615753173828125, 'bn2': 0.00023031234741210938, 'conv3': 0.0003783702850341797, 'residual_add_relu2': 0.00020956993103027344}\n",
      "{'conv1': 0.0011577606201171875, 'bn1': 0.00023126602172851562, 'relu1': 0.00010561943054199219, 'conv2': 0.0011560916900634766, 'bn2': 0.00022673606872558594, 'residual_add_relu2': 0.000209808349609375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006685256958007812, 'bn1': 0.00015282630920410156, 'relu1': 6.818771362304688e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.00015497207641601562, 'conv3': 0.00031638145446777344, 'residual_add_relu2': 0.00012159347534179688}\n",
      "{'conv1': 0.0011572837829589844, 'bn1': 0.0001575946807861328, 'relu1': 6.842613220214844e-05, 'conv2': 0.001146554946899414, 'bn2': 0.00014925003051757812, 'residual_add_relu2': 0.00011563301086425781}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 83\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016531944274902344, 'bn1': 0.0005898475646972656, 'relu1': 0.0003325939178466797, 'conv2': 0.0016453266143798828, 'bn2': 0.000568389892578125, 'residual_add_relu2': 0.0007698535919189453}\n",
      "{'conv1': 0.00164031982421875, 'bn1': 0.0005726814270019531, 'relu1': 0.0003299713134765625, 'conv2': 0.001631021499633789, 'bn2': 0.0005781650543212891, 'residual_add_relu2': 0.0007724761962890625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010607242584228516, 'bn1': 0.0003440380096435547, 'relu1': 0.0001819133758544922, 'conv2': 0.0013096332550048828, 'bn2': 0.00033354759216308594, 'conv3': 0.0004124641418457031, 'residual_add_relu2': 0.0003960132598876953}\n",
      "{'conv1': 0.0013096332550048828, 'bn1': 0.0003407001495361328, 'relu1': 0.00018024444580078125, 'conv2': 0.0013058185577392578, 'bn2': 0.0003345012664794922, 'residual_add_relu2': 0.00039696693420410156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008027553558349609, 'bn1': 0.00023555755615234375, 'relu1': 0.00010967254638671875, 'conv2': 0.0011594295501708984, 'bn2': 0.00023126602172851562, 'conv3': 0.0003695487976074219, 'residual_add_relu2': 0.00021004676818847656}\n",
      "{'conv1': 0.00115966796875, 'bn1': 0.0002396106719970703, 'relu1': 0.00010609626770019531, 'conv2': 0.001153707504272461, 'bn2': 0.00022220611572265625, 'residual_add_relu2': 0.00021004676818847656}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006697177886962891, 'bn1': 0.00014710426330566406, 'relu1': 6.651878356933594e-05, 'conv2': 0.001146078109741211, 'bn2': 0.00014019012451171875, 'conv3': 0.00030541419982910156, 'residual_add_relu2': 0.00011515617370605469}\n",
      "{'conv1': 0.001149892807006836, 'bn1': 0.0001621246337890625, 'relu1': 6.699562072753906e-05, 'conv2': 0.001146554946899414, 'bn2': 0.00015616416931152344, 'residual_add_relu2': 0.00013136863708496094}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 84\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016551017761230469, 'bn1': 0.0005800724029541016, 'relu1': 0.00033020973205566406, 'conv2': 0.0016388893127441406, 'bn2': 0.0005884170532226562, 'residual_add_relu2': 0.000774383544921875}\n",
      "{'conv1': 0.0016379356384277344, 'bn1': 0.0005826950073242188, 'relu1': 0.0003299713134765625, 'conv2': 0.0016314983367919922, 'bn2': 0.0005652904510498047, 'residual_add_relu2': 0.0007688999176025391}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010528564453125, 'bn1': 0.0003457069396972656, 'relu1': 0.00017905235290527344, 'conv2': 0.001306295394897461, 'bn2': 0.0003361701965332031, 'conv3': 0.0004165172576904297, 'residual_add_relu2': 0.0003972053527832031}\n",
      "{'conv1': 0.0013165473937988281, 'bn1': 0.0003466606140136719, 'relu1': 0.00018167495727539062, 'conv2': 0.0013070106506347656, 'bn2': 0.00035071372985839844, 'residual_add_relu2': 0.0003962516784667969}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007982254028320312, 'bn1': 0.00022649765014648438, 'relu1': 0.00010585784912109375, 'conv2': 0.0011572837829589844, 'bn2': 0.00021767616271972656, 'conv3': 0.00036644935607910156, 'residual_add_relu2': 0.0002086162567138672}\n",
      "{'conv1': 0.0011577606201171875, 'bn1': 0.00022530555725097656, 'relu1': 0.00010561943054199219, 'conv2': 0.0011539459228515625, 'bn2': 0.0002315044403076172, 'residual_add_relu2': 0.0002124309539794922}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006699562072753906, 'bn1': 0.0001499652862548828, 'relu1': 0.0001366138458251953, 'conv2': 0.0011556148529052734, 'bn2': 0.00014853477478027344, 'conv3': 0.00030422210693359375, 'residual_add_relu2': 0.00011515617370605469}\n",
      "{'conv1': 0.0011472702026367188, 'bn1': 0.00014662742614746094, 'relu1': 6.556510925292969e-05, 'conv2': 0.0011417865753173828, 'bn2': 0.00014352798461914062, 'residual_add_relu2': 0.00011491775512695312}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 85\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001672983169555664, 'bn1': 0.0006055831909179688, 'relu1': 0.000331878662109375, 'conv2': 0.0016396045684814453, 'bn2': 0.0005719661712646484, 'residual_add_relu2': 0.0007729530334472656}\n",
      "{'conv1': 0.0016384124755859375, 'bn1': 0.0005724430084228516, 'relu1': 0.000331878662109375, 'conv2': 0.0016379356384277344, 'bn2': 0.0005810260772705078, 'residual_add_relu2': 0.0007696151733398438}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010676383972167969, 'bn1': 0.00034689903259277344, 'relu1': 0.0001804828643798828, 'conv2': 0.0013179779052734375, 'bn2': 0.0003337860107421875, 'conv3': 0.0004203319549560547, 'residual_add_relu2': 0.00039577484130859375}\n",
      "{'conv1': 0.001308441162109375, 'bn1': 0.00033974647521972656, 'relu1': 0.0001804828643798828, 'conv2': 0.0013110637664794922, 'bn2': 0.00034737586975097656, 'residual_add_relu2': 0.00039958953857421875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008003711700439453, 'bn1': 0.0002474784851074219, 'relu1': 0.00010657310485839844, 'conv2': 0.0011639595031738281, 'bn2': 0.00023055076599121094, 'conv3': 0.0003726482391357422, 'residual_add_relu2': 0.00020956993103027344}\n",
      "{'conv1': 0.001157522201538086, 'bn1': 0.00022530555725097656, 'relu1': 0.00010609626770019531, 'conv2': 0.0011532306671142578, 'bn2': 0.0002224445343017578, 'residual_add_relu2': 0.000209808349609375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006656646728515625, 'bn1': 0.00015091896057128906, 'relu1': 6.604194641113281e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.0001590251922607422, 'conv3': 0.0003104209899902344, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.0011491775512695312, 'bn1': 0.00016427040100097656, 'relu1': 6.747245788574219e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.00014281272888183594, 'residual_add_relu2': 0.00011467933654785156}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 86\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0017178058624267578, 'bn1': 0.0005993843078613281, 'relu1': 0.00033593177795410156, 'conv2': 0.00164794921875, 'bn2': 0.0005786418914794922, 'residual_add_relu2': 0.0007755756378173828}\n",
      "{'conv1': 0.0016393661499023438, 'bn1': 0.0005795955657958984, 'relu1': 0.00033783912658691406, 'conv2': 0.0016314983367919922, 'bn2': 0.0005705356597900391, 'residual_add_relu2': 0.0007758140563964844}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010671615600585938, 'bn1': 0.00034737586975097656, 'relu1': 0.0001842975616455078, 'conv2': 0.001310586929321289, 'bn2': 0.0003371238708496094, 'conv3': 0.00041675567626953125, 'residual_add_relu2': 0.0003941059112548828}\n",
      "{'conv1': 0.0013127326965332031, 'bn1': 0.00034165382385253906, 'relu1': 0.00018262863159179688, 'conv2': 0.0013079643249511719, 'bn2': 0.0003445148468017578, 'residual_add_relu2': 0.00039505958557128906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007987022399902344, 'bn1': 0.0002627372741699219, 'relu1': 0.00011205673217773438, 'conv2': 0.0011608600616455078, 'bn2': 0.00023221969604492188, 'conv3': 0.0003693103790283203, 'residual_add_relu2': 0.00021409988403320312}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.00023746490478515625, 'relu1': 0.00010800361633300781, 'conv2': 0.0011568069458007812, 'bn2': 0.00022149085998535156, 'residual_add_relu2': 0.00020956993103027344}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006682872772216797, 'bn1': 0.00016736984252929688, 'relu1': 7.033348083496094e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00014138221740722656, 'conv3': 0.0003032684326171875, 'residual_add_relu2': 0.00011467933654785156}\n",
      "{'conv1': 0.0011479854583740234, 'bn1': 0.00014829635620117188, 'relu1': 6.532669067382812e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.00018668174743652344, 'residual_add_relu2': 0.00011849403381347656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 87\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016515254974365234, 'bn1': 0.0005877017974853516, 'relu1': 0.0003345012664794922, 'conv2': 0.001626729965209961, 'bn2': 0.0005781650543212891, 'residual_add_relu2': 0.0007724761962890625}\n",
      "{'conv1': 0.0016443729400634766, 'bn1': 0.0005815029144287109, 'relu1': 0.00033092498779296875, 'conv2': 0.0016276836395263672, 'bn2': 0.0005655288696289062, 'residual_add_relu2': 0.0007688999176025391}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001054525375366211, 'bn1': 0.0003414154052734375, 'relu1': 0.00018215179443359375, 'conv2': 0.0013170242309570312, 'bn2': 0.00034880638122558594, 'conv3': 0.0004143714904785156, 'residual_add_relu2': 0.00039577484130859375}\n",
      "{'conv1': 0.001310586929321289, 'bn1': 0.0003497600555419922, 'relu1': 0.00018525123596191406, 'conv2': 0.0013115406036376953, 'bn2': 0.0003459453582763672, 'residual_add_relu2': 0.00039649009704589844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007975101470947266, 'bn1': 0.00022649765014648438, 'relu1': 0.0001049041748046875, 'conv2': 0.0011553764343261719, 'bn2': 0.00022029876708984375, 'conv3': 0.00036454200744628906, 'residual_add_relu2': 0.0002105236053466797}\n",
      "{'conv1': 0.0011577606201171875, 'bn1': 0.00023365020751953125, 'relu1': 0.00011348724365234375, 'conv2': 0.001157522201538086, 'bn2': 0.00022268295288085938, 'residual_add_relu2': 0.0002090930938720703}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006728172302246094, 'bn1': 0.00015807151794433594, 'relu1': 6.771087646484375e-05, 'conv2': 0.0011491775512695312, 'bn2': 0.00015115737915039062, 'conv3': 0.0003135204315185547, 'residual_add_relu2': 0.00011563301086425781}\n",
      "{'conv1': 0.0011522769927978516, 'bn1': 0.00014901161193847656, 'relu1': 6.651878356933594e-05, 'conv2': 0.0011444091796875, 'bn2': 0.00014591217041015625, 'residual_add_relu2': 0.00011467933654785156}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 88\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016520023345947266, 'bn1': 0.0005931854248046875, 'relu1': 0.0003349781036376953, 'conv2': 0.0016355514526367188, 'bn2': 0.0005784034729003906, 'residual_add_relu2': 0.0007696151733398438}\n",
      "{'conv1': 0.0016388893127441406, 'bn1': 0.0005903244018554688, 'relu1': 0.0003376007080078125, 'conv2': 0.0016391277313232422, 'bn2': 0.0005667209625244141, 'residual_add_relu2': 0.0007693767547607422}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010585784912109375, 'bn1': 0.0003490447998046875, 'relu1': 0.0001811981201171875, 'conv2': 0.0013091564178466797, 'bn2': 0.0003337860107421875, 'conv3': 0.00041294097900390625, 'residual_add_relu2': 0.0003941059112548828}\n",
      "{'conv1': 0.001312255859375, 'bn1': 0.0003516674041748047, 'relu1': 0.00018167495727539062, 'conv2': 0.0013158321380615234, 'bn2': 0.0003457069396972656, 'residual_add_relu2': 0.0003952980041503906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008075237274169922, 'bn1': 0.00023031234741210938, 'relu1': 0.00010657310485839844, 'conv2': 0.001157999038696289, 'bn2': 0.00024890899658203125, 'conv3': 0.0003714561462402344, 'residual_add_relu2': 0.00021338462829589844}\n",
      "{'conv1': 0.0011615753173828125, 'bn1': 0.0002346038818359375, 'relu1': 0.0001068115234375, 'conv2': 0.001155853271484375, 'bn2': 0.00022077560424804688, 'residual_add_relu2': 0.00020933151245117188}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006663799285888672, 'bn1': 0.0001475811004638672, 'relu1': 6.699562072753906e-05, 'conv2': 0.0011467933654785156, 'bn2': 0.00015282630920410156, 'conv3': 0.0003197193145751953, 'residual_add_relu2': 0.00012135505676269531}\n",
      "{'conv1': 0.0011508464813232422, 'bn1': 0.00014925003051757812, 'relu1': 6.604194641113281e-05, 'conv2': 0.001142740249633789, 'bn2': 0.00014090538024902344, 'residual_add_relu2': 0.00011491775512695312}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 89\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016596317291259766, 'bn1': 0.0006008148193359375, 'relu1': 0.0003352165222167969, 'conv2': 0.0016427040100097656, 'bn2': 0.0005857944488525391, 'residual_add_relu2': 0.0007719993591308594}\n",
      "{'conv1': 0.0016438961029052734, 'bn1': 0.0005793571472167969, 'relu1': 0.00033020973205566406, 'conv2': 0.0016372203826904297, 'bn2': 0.0005719661712646484, 'residual_add_relu2': 0.0007693767547607422}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010631084442138672, 'bn1': 0.0003528594970703125, 'relu1': 0.0001800060272216797, 'conv2': 0.0013120174407958984, 'bn2': 0.00033402442932128906, 'conv3': 0.00041222572326660156, 'residual_add_relu2': 0.000396728515625}\n",
      "{'conv1': 0.0013141632080078125, 'bn1': 0.0003476142883300781, 'relu1': 0.00018072128295898438, 'conv2': 0.0013072490692138672, 'bn2': 0.00033974647521972656, 'residual_add_relu2': 0.00039505958557128906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007977485656738281, 'bn1': 0.00022554397583007812, 'relu1': 0.00010967254638671875, 'conv2': 0.0011582374572753906, 'bn2': 0.00024700164794921875, 'conv3': 0.0003781318664550781, 'residual_add_relu2': 0.000209808349609375}\n",
      "{'conv1': 0.0011570453643798828, 'bn1': 0.00022649765014648438, 'relu1': 0.00010609626770019531, 'conv2': 0.0011551380157470703, 'bn2': 0.00022459030151367188, 'residual_add_relu2': 0.00021314620971679688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006709098815917969, 'bn1': 0.0001652240753173828, 'relu1': 6.890296936035156e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.00014257431030273438, 'conv3': 0.00030517578125, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.0011544227600097656, 'bn1': 0.0001480579376220703, 'relu1': 6.747245788574219e-05, 'conv2': 0.0011420249938964844, 'bn2': 0.00013899803161621094, 'residual_add_relu2': 0.0001163482666015625}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 90\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016579627990722656, 'bn1': 0.0005922317504882812, 'relu1': 0.00033283233642578125, 'conv2': 0.0016298294067382812, 'bn2': 0.0005819797515869141, 'residual_add_relu2': 0.0007786750793457031}\n",
      "{'conv1': 0.0016427040100097656, 'bn1': 0.0005757808685302734, 'relu1': 0.0003314018249511719, 'conv2': 0.001644134521484375, 'bn2': 0.0005753040313720703, 'residual_add_relu2': 0.00077056884765625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001056671142578125, 'bn1': 0.00035572052001953125, 'relu1': 0.00018095970153808594, 'conv2': 0.0013089179992675781, 'bn2': 0.0003459453582763672, 'conv3': 0.00041961669921875, 'residual_add_relu2': 0.00039696693420410156}\n",
      "{'conv1': 0.001316070556640625, 'bn1': 0.0003495216369628906, 'relu1': 0.0001804828643798828, 'conv2': 0.001308441162109375, 'bn2': 0.0003345012664794922, 'residual_add_relu2': 0.0003955364227294922}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007967948913574219, 'bn1': 0.0002396106719970703, 'relu1': 0.00010895729064941406, 'conv2': 0.0011718273162841797, 'bn2': 0.00022673606872558594, 'conv3': 0.0003676414489746094, 'residual_add_relu2': 0.00020885467529296875}\n",
      "{'conv1': 0.0011572837829589844, 'bn1': 0.0002288818359375, 'relu1': 0.00010585784912109375, 'conv2': 0.001155853271484375, 'bn2': 0.000240325927734375, 'residual_add_relu2': 0.00021076202392578125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006690025329589844, 'bn1': 0.00014925003051757812, 'relu1': 6.699562072753906e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00013971328735351562, 'conv3': 0.0003032684326171875, 'residual_add_relu2': 0.00011563301086425781}\n",
      "{'conv1': 0.0011510848999023438, 'bn1': 0.00016188621520996094, 'relu1': 6.866455078125e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.0001513957977294922, 'residual_add_relu2': 0.00011539459228515625}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 91\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016524791717529297, 'bn1': 0.0006034374237060547, 'relu1': 0.0003352165222167969, 'conv2': 0.0016324520111083984, 'bn2': 0.0005784034729003906, 'residual_add_relu2': 0.0007693767547607422}\n",
      "{'conv1': 0.0016520023345947266, 'bn1': 0.0006003379821777344, 'relu1': 0.0003311634063720703, 'conv2': 0.0016336441040039062, 'bn2': 0.0005652904510498047, 'residual_add_relu2': 0.0007691383361816406}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010669231414794922, 'bn1': 0.00035262107849121094, 'relu1': 0.00018143653869628906, 'conv2': 0.0013096332550048828, 'bn2': 0.0003337860107421875, 'conv3': 0.00041961669921875, 'residual_add_relu2': 0.0003962516784667969}\n",
      "{'conv1': 0.0013153553009033203, 'bn1': 0.0003597736358642578, 'relu1': 0.0001850128173828125, 'conv2': 0.0013110637664794922, 'bn2': 0.00034356117248535156, 'residual_add_relu2': 0.00039768218994140625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007991790771484375, 'bn1': 0.0002295970916748047, 'relu1': 0.00010776519775390625, 'conv2': 0.0011587142944335938, 'bn2': 0.0002300739288330078, 'conv3': 0.00037407875061035156, 'residual_add_relu2': 0.00021266937255859375}\n",
      "{'conv1': 0.0011641979217529297, 'bn1': 0.0002410411834716797, 'relu1': 0.0001068115234375, 'conv2': 0.001157999038696289, 'bn2': 0.00023674964904785156, 'residual_add_relu2': 0.0002110004425048828}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006840229034423828, 'bn1': 0.00015783309936523438, 'relu1': 6.747245788574219e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00015234947204589844, 'conv3': 0.00030732154846191406, 'residual_add_relu2': 0.0001163482666015625}\n",
      "{'conv1': 0.0011534690856933594, 'bn1': 0.00017142295837402344, 'relu1': 7.05718994140625e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.0001475811004638672, 'residual_add_relu2': 0.000118255615234375}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 92\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016560554504394531, 'bn1': 0.0005900859832763672, 'relu1': 0.00033164024353027344, 'conv2': 0.0016298294067382812, 'bn2': 0.0005707740783691406, 'residual_add_relu2': 0.0007715225219726562}\n",
      "{'conv1': 0.0016467571258544922, 'bn1': 0.0005793571472167969, 'relu1': 0.00033402442932128906, 'conv2': 0.0016283988952636719, 'bn2': 0.0005726814270019531, 'residual_add_relu2': 0.0007710456848144531}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.00106048583984375, 'bn1': 0.00035119056701660156, 'relu1': 0.00018167495727539062, 'conv2': 0.0013089179992675781, 'bn2': 0.000335693359375, 'conv3': 0.0004138946533203125, 'residual_add_relu2': 0.00039458274841308594}\n",
      "{'conv1': 0.0013120174407958984, 'bn1': 0.0003502368927001953, 'relu1': 0.00018358230590820312, 'conv2': 0.0013091564178466797, 'bn2': 0.0003380775451660156, 'residual_add_relu2': 0.0003948211669921875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007970333099365234, 'bn1': 0.00025916099548339844, 'relu1': 0.00010776519775390625, 'conv2': 0.0011582374572753906, 'bn2': 0.00023031234741210938, 'conv3': 0.0003695487976074219, 'residual_add_relu2': 0.0002110004425048828}\n",
      "{'conv1': 0.001157522201538086, 'bn1': 0.00022459030151367188, 'relu1': 0.00010609626770019531, 'conv2': 0.0011539459228515625, 'bn2': 0.00022220611572265625, 'residual_add_relu2': 0.0002105236053466797}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006668567657470703, 'bn1': 0.00015616416931152344, 'relu1': 6.771087646484375e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.0007767677307128906, 'conv3': 0.00037169456481933594, 'residual_add_relu2': 0.0001289844512939453}\n",
      "{'conv1': 0.0011668205261230469, 'bn1': 0.00017786026000976562, 'relu1': 7.534027099609375e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.0001823902130126953, 'residual_add_relu2': 0.00011897087097167969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 93\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016565322875976562, 'bn1': 0.0005936622619628906, 'relu1': 0.00033354759216308594, 'conv2': 0.0016341209411621094, 'bn2': 0.0005784034729003906, 'residual_add_relu2': 0.0007729530334472656}\n",
      "{'conv1': 0.00164031982421875, 'bn1': 0.0005853176116943359, 'relu1': 0.00033092498779296875, 'conv2': 0.0016314983367919922, 'bn2': 0.0005776882171630859, 'residual_add_relu2': 0.00077056884765625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010581016540527344, 'bn1': 0.0003514289855957031, 'relu1': 0.0001857280731201172, 'conv2': 0.0013163089752197266, 'bn2': 0.0003421306610107422, 'conv3': 0.00041937828063964844, 'residual_add_relu2': 0.0003952980041503906}\n",
      "{'conv1': 0.0013103485107421875, 'bn1': 0.00034117698669433594, 'relu1': 0.00018072128295898438, 'conv2': 0.0013098716735839844, 'bn2': 0.00033473968505859375, 'residual_add_relu2': 0.00039458274841308594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008008480072021484, 'bn1': 0.00024390220642089844, 'relu1': 0.00010752677917480469, 'conv2': 0.0011751651763916016, 'bn2': 0.00023436546325683594, 'conv3': 0.00036787986755371094, 'residual_add_relu2': 0.00020933151245117188}\n",
      "{'conv1': 0.001194000244140625, 'bn1': 0.00023865699768066406, 'relu1': 0.0001068115234375, 'conv2': 0.001155853271484375, 'bn2': 0.00022101402282714844, 'residual_add_relu2': 0.0002090930938720703}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006682872772216797, 'bn1': 0.0001480579376220703, 'relu1': 6.651878356933594e-05, 'conv2': 0.0011463165283203125, 'bn2': 0.00014328956604003906, 'conv3': 0.0003046989440917969, 'residual_add_relu2': 0.00011539459228515625}\n",
      "{'conv1': 0.001148223876953125, 'bn1': 0.00014734268188476562, 'relu1': 6.604194641113281e-05, 'conv2': 0.0011434555053710938, 'bn2': 0.00015282630920410156, 'residual_add_relu2': 0.00011491775512695312}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 94\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016627311706542969, 'bn1': 0.0005841255187988281, 'relu1': 0.0003361701965332031, 'conv2': 0.0016353130340576172, 'bn2': 0.0006535053253173828, 'residual_add_relu2': 0.00078582763671875}\n",
      "{'conv1': 0.0016558170318603516, 'bn1': 0.0005922317504882812, 'relu1': 0.00033402442932128906, 'conv2': 0.0016319751739501953, 'bn2': 0.0005819797515869141, 'residual_add_relu2': 0.0007688999176025391}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010609626770019531, 'bn1': 0.0003571510314941406, 'relu1': 0.00018835067749023438, 'conv2': 0.0013203620910644531, 'bn2': 0.0003502368927001953, 'conv3': 0.0004208087921142578, 'residual_add_relu2': 0.0003998279571533203}\n",
      "{'conv1': 0.0013298988342285156, 'bn1': 0.0003597736358642578, 'relu1': 0.00018262863159179688, 'conv2': 0.0013129711151123047, 'bn2': 0.0003383159637451172, 'residual_add_relu2': 0.00039505958557128906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007998943328857422, 'bn1': 0.0002357959747314453, 'relu1': 0.00010633468627929688, 'conv2': 0.0011606216430664062, 'bn2': 0.0002262592315673828, 'conv3': 0.0003693103790283203, 'residual_add_relu2': 0.00021147727966308594}\n",
      "{'conv1': 0.0011582374572753906, 'bn1': 0.000240325927734375, 'relu1': 0.00010967254638671875, 'conv2': 0.0011591911315917969, 'bn2': 0.00022530555725097656, 'residual_add_relu2': 0.0002124309539794922}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006716251373291016, 'bn1': 0.000164031982421875, 'relu1': 6.699562072753906e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.00014734268188476562, 'conv3': 0.0003116130828857422, 'residual_add_relu2': 0.00011706352233886719}\n",
      "{'conv1': 0.0011513233184814453, 'bn1': 0.00015163421630859375, 'relu1': 6.556510925292969e-05, 'conv2': 0.0011425018310546875, 'bn2': 0.00013875961303710938, 'residual_add_relu2': 0.00011539459228515625}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 95\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016651153564453125, 'bn1': 0.0005800724029541016, 'relu1': 0.00033092498779296875, 'conv2': 0.0016314983367919922, 'bn2': 0.0005714893341064453, 'residual_add_relu2': 0.0007693767547607422}\n",
      "{'conv1': 0.0016336441040039062, 'bn1': 0.0005743503570556641, 'relu1': 0.0003306865692138672, 'conv2': 0.0016396045684814453, 'bn2': 0.0005741119384765625, 'residual_add_relu2': 0.0007696151733398438}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010540485382080078, 'bn1': 0.0003426074981689453, 'relu1': 0.00018095970153808594, 'conv2': 0.0013077259063720703, 'bn2': 0.0003352165222167969, 'conv3': 0.0004124641418457031, 'residual_add_relu2': 0.0003948211669921875}\n",
      "{'conv1': 0.0013079643249511719, 'bn1': 0.00033926963806152344, 'relu1': 0.0001811981201171875, 'conv2': 0.0013058185577392578, 'bn2': 0.0003466606140136719, 'residual_add_relu2': 0.00039958953857421875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008380413055419922, 'bn1': 0.00024199485778808594, 'relu1': 0.0001068115234375, 'conv2': 0.0011582374572753906, 'bn2': 0.00022029876708984375, 'conv3': 0.00036406517028808594, 'residual_add_relu2': 0.0002086162567138672}\n",
      "{'conv1': 0.0011577606201171875, 'bn1': 0.00023221969604492188, 'relu1': 0.00010514259338378906, 'conv2': 0.0011532306671142578, 'bn2': 0.00021982192993164062, 'residual_add_relu2': 0.00021028518676757812}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006668567657470703, 'bn1': 0.00014662742614746094, 'relu1': 6.67572021484375e-05, 'conv2': 0.0011458396911621094, 'bn2': 0.00015115737915039062, 'conv3': 0.0003046989440917969, 'residual_add_relu2': 0.00011730194091796875}\n",
      "{'conv1': 0.0011506080627441406, 'bn1': 0.00015783309936523438, 'relu1': 6.651878356933594e-05, 'conv2': 0.0011470317840576172, 'bn2': 0.000148773193359375, 'residual_add_relu2': 0.00011515617370605469}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 96\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016677379608154297, 'bn1': 0.0005869865417480469, 'relu1': 0.0003311634063720703, 'conv2': 0.0016427040100097656, 'bn2': 0.0005991458892822266, 'residual_add_relu2': 0.0007729530334472656}\n",
      "{'conv1': 0.0016412734985351562, 'bn1': 0.0005714893341064453, 'relu1': 0.00033593177795410156, 'conv2': 0.0016355514526367188, 'bn2': 0.0005655288696289062, 'residual_add_relu2': 0.0007681846618652344}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010535717010498047, 'bn1': 0.0003371238708496094, 'relu1': 0.0001785755157470703, 'conv2': 0.0013251304626464844, 'bn2': 0.0003497600555419922, 'conv3': 0.000415802001953125, 'residual_add_relu2': 0.0003955364227294922}\n",
      "{'conv1': 0.0013146400451660156, 'bn1': 0.000339508056640625, 'relu1': 0.00019693374633789062, 'conv2': 0.0013089179992675781, 'bn2': 0.0003428459167480469, 'residual_add_relu2': 0.00039649009704589844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007982254028320312, 'bn1': 0.00023484230041503906, 'relu1': 0.00010704994201660156, 'conv2': 0.0011565685272216797, 'bn2': 0.0002396106719970703, 'conv3': 0.0003676414489746094, 'residual_add_relu2': 0.0002090930938720703}\n",
      "{'conv1': 0.0011568069458007812, 'bn1': 0.00023293495178222656, 'relu1': 0.00010585784912109375, 'conv2': 0.0011601448059082031, 'bn2': 0.00022339820861816406, 'residual_add_relu2': 0.00021004676818847656}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006699562072753906, 'bn1': 0.00015306472778320312, 'relu1': 6.67572021484375e-05, 'conv2': 0.0011467933654785156, 'bn2': 0.000141143798828125, 'conv3': 0.00030612945556640625, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.001146554946899414, 'bn1': 0.00015473365783691406, 'relu1': 6.628036499023438e-05, 'conv2': 0.0011434555053710938, 'bn2': 0.00013875961303710938, 'residual_add_relu2': 0.00011491775512695312}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 97\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016481876373291016, 'bn1': 0.0005872249603271484, 'relu1': 0.000331878662109375, 'conv2': 0.0016469955444335938, 'bn2': 0.0005970001220703125, 'residual_add_relu2': 0.0007700920104980469}\n",
      "{'conv1': 0.001636505126953125, 'bn1': 0.000579833984375, 'relu1': 0.00033545494079589844, 'conv2': 0.0016384124755859375, 'bn2': 0.0005738735198974609, 'residual_add_relu2': 0.0007681846618652344}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010585784912109375, 'bn1': 0.0003447532653808594, 'relu1': 0.00018095970153808594, 'conv2': 0.0013079643249511719, 'bn2': 0.00033545494079589844, 'conv3': 0.0004134178161621094, 'residual_add_relu2': 0.0003955364227294922}\n",
      "{'conv1': 0.0013096332550048828, 'bn1': 0.00033926963806152344, 'relu1': 0.00017952919006347656, 'conv2': 0.0013091564178466797, 'bn2': 0.00041103363037109375, 'residual_add_relu2': 0.0003998279571533203}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008046627044677734, 'bn1': 0.00022840499877929688, 'relu1': 0.00010609626770019531, 'conv2': 0.0011565685272216797, 'bn2': 0.0002446174621582031, 'conv3': 0.00036644935607910156, 'residual_add_relu2': 0.0002086162567138672}\n",
      "{'conv1': 0.0011606216430664062, 'bn1': 0.0002295970916748047, 'relu1': 0.00010538101196289062, 'conv2': 0.0011525154113769531, 'bn2': 0.00021767616271972656, 'residual_add_relu2': 0.0002090930938720703}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006663799285888672, 'bn1': 0.0001468658447265625, 'relu1': 7.534027099609375e-05, 'conv2': 0.0011467933654785156, 'bn2': 0.000141143798828125, 'conv3': 0.00030803680419921875, 'residual_add_relu2': 0.00011873245239257812}\n",
      "{'conv1': 0.0011527538299560547, 'bn1': 0.00015616416931152344, 'relu1': 6.723403930664062e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00014472007751464844, 'residual_add_relu2': 0.00011563301086425781}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 98\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016613006591796875, 'bn1': 0.0005967617034912109, 'relu1': 0.0003337860107421875, 'conv2': 0.0016443729400634766, 'bn2': 0.0005688667297363281, 'residual_add_relu2': 0.0007722377777099609}\n",
      "{'conv1': 0.0016400814056396484, 'bn1': 0.0005748271942138672, 'relu1': 0.00032973289489746094, 'conv2': 0.0016417503356933594, 'bn2': 0.0005621910095214844, 'residual_add_relu2': 0.0007686614990234375}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010614395141601562, 'bn1': 0.0003497600555419922, 'relu1': 0.00018095970153808594, 'conv2': 0.0013093948364257812, 'bn2': 0.0003323554992675781, 'conv3': 0.00048804283142089844, 'residual_add_relu2': 0.0003962516784667969}\n",
      "{'conv1': 0.0013129711151123047, 'bn1': 0.00034356117248535156, 'relu1': 0.00017976760864257812, 'conv2': 0.001306295394897461, 'bn2': 0.0003376007080078125, 'residual_add_relu2': 0.0003952980041503906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007956027984619141, 'bn1': 0.000225067138671875, 'relu1': 0.00010633468627929688, 'conv2': 0.001155853271484375, 'bn2': 0.0002288818359375, 'conv3': 0.0003681182861328125, 'residual_add_relu2': 0.00021028518676757812}\n",
      "{'conv1': 0.0011606216430664062, 'bn1': 0.0002276897430419922, 'relu1': 0.00010585784912109375, 'conv2': 0.001153707504272461, 'bn2': 0.00022101402282714844, 'residual_add_relu2': 0.0002086162567138672}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006666183471679688, 'bn1': 0.0001461505889892578, 'relu1': 6.794929504394531e-05, 'conv2': 0.0011463165283203125, 'bn2': 0.00014209747314453125, 'conv3': 0.00030303001403808594, 'residual_add_relu2': 0.00011563301086425781}\n",
      "{'conv1': 0.0011477470397949219, 'bn1': 0.0001480579376220703, 'relu1': 6.67572021484375e-05, 'conv2': 0.0011425018310546875, 'bn2': 0.00014209747314453125, 'residual_add_relu2': 0.00011730194091796875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 99\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016396045684814453, 'bn1': 0.0005619525909423828, 'relu1': 0.0003230571746826172, 'conv2': 0.0016202926635742188, 'bn2': 0.0005371570587158203, 'residual_add_relu2': 0.0007638931274414062}\n",
      "{'conv1': 0.0016238689422607422, 'bn1': 0.0005426406860351562, 'relu1': 0.0003218650817871094, 'conv2': 0.0016143321990966797, 'bn2': 0.0005435943603515625, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001039743423461914, 'bn1': 0.0003161430358886719, 'relu1': 0.00017213821411132812, 'conv2': 0.0012929439544677734, 'bn2': 0.00030922889709472656, 'conv3': 0.0003986358642578125, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0012967586517333984, 'bn1': 0.0003135204315185547, 'relu1': 0.00017213821411132812, 'conv2': 0.0012919902801513672, 'bn2': 0.00031113624572753906, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007808208465576172, 'bn1': 0.00019788742065429688, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.0001952648162841797, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011446475982666016, 'bn1': 0.00020003318786621094, 'relu1': 9.846687316894531e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00019431114196777344, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006542205810546875, 'bn1': 0.00012993812561035156, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011336803436279297, 'bn2': 0.00012755393981933594, 'conv3': 0.0002887248992919922, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011355876922607422, 'bn1': 0.0001506805419921875, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011320114135742188, 'bn2': 0.00012063980102539062, 'residual_add_relu2': 0.00011205673217773438}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 100\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016522407531738281, 'bn1': 0.0005741119384765625, 'relu1': 0.00032591819763183594, 'conv2': 0.0016193389892578125, 'bn2': 0.0005490779876708984, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016338825225830078, 'bn1': 0.0005469322204589844, 'relu1': 0.0003230571746826172, 'conv2': 0.0016121864318847656, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001039266586303711, 'bn1': 0.0003151893615722656, 'relu1': 0.0001876354217529297, 'conv2': 0.001298666000366211, 'bn2': 0.00031757354736328125, 'conv3': 0.00041222572326660156, 'residual_add_relu2': 0.00039196014404296875}\n",
      "{'conv1': 0.0013012886047363281, 'bn1': 0.0003170967102050781, 'relu1': 0.0001735687255859375, 'conv2': 0.0012934207916259766, 'bn2': 0.0003261566162109375, 'residual_add_relu2': 0.00039196014404296875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007860660552978516, 'bn1': 0.0002086162567138672, 'relu1': 0.00010132789611816406, 'conv2': 0.0011458396911621094, 'bn2': 0.0001952648162841797, 'conv3': 0.0003516674041748047, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011408329010009766, 'bn1': 0.00020694732666015625, 'relu1': 9.918212890625e-05, 'conv2': 0.0011420249938964844, 'bn2': 0.00020384788513183594, 'residual_add_relu2': 0.00020623207092285156}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006718635559082031, 'bn1': 0.00012922286987304688, 'relu1': 5.9604644775390625e-05, 'conv2': 0.001135110855102539, 'bn2': 0.00012040138244628906, 'conv3': 0.00029587745666503906, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011343955993652344, 'bn1': 0.00012183189392089844, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011289119720458984, 'bn2': 0.00011467933654785156, 'residual_add_relu2': 0.000118255615234375}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 101\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016264915466308594, 'bn1': 0.0005609989166259766, 'relu1': 0.00032806396484375, 'conv2': 0.0016283988952636719, 'bn2': 0.0005574226379394531, 'residual_add_relu2': 0.0007688999176025391}\n",
      "{'conv1': 0.0016207695007324219, 'bn1': 0.0005466938018798828, 'relu1': 0.0003235340118408203, 'conv2': 0.0016214847564697266, 'bn2': 0.0005397796630859375, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010426044464111328, 'bn1': 0.0003352165222167969, 'relu1': 0.0001747608184814453, 'conv2': 0.0012967586517333984, 'bn2': 0.0003190040588378906, 'conv3': 0.0004017353057861328, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0012955665588378906, 'bn1': 0.0003237724304199219, 'relu1': 0.00017523765563964844, 'conv2': 0.0012960433959960938, 'bn2': 0.0003211498260498047, 'residual_add_relu2': 0.00039267539978027344}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000789642333984375, 'bn1': 0.00021386146545410156, 'relu1': 0.00010228157043457031, 'conv2': 0.0011515617370605469, 'bn2': 0.00021028518676757812, 'conv3': 0.0003604888916015625, 'residual_add_relu2': 0.00020933151245117188}\n",
      "{'conv1': 0.0011563301086425781, 'bn1': 0.00022220611572265625, 'relu1': 0.00010752677917480469, 'conv2': 0.0011522769927978516, 'bn2': 0.00021004676818847656, 'residual_add_relu2': 0.00020647048950195312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006606578826904297, 'bn1': 0.00013327598571777344, 'relu1': 6.198883056640625e-05, 'conv2': 0.0011749267578125, 'bn2': 0.0002834796905517578, 'conv3': 0.0003268718719482422, 'residual_add_relu2': 0.00011444091796875}\n",
      "{'conv1': 0.001149892807006836, 'bn1': 0.00012969970703125, 'relu1': 6.0558319091796875e-05, 'conv2': 0.001131296157836914, 'bn2': 0.00012040138244628906, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 102\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016574859619140625, 'bn1': 0.0005762577056884766, 'relu1': 0.0003299713134765625, 'conv2': 0.0016360282897949219, 'bn2': 0.0005638599395751953, 'residual_add_relu2': 0.0007741451263427734}\n",
      "{'conv1': 0.0016446113586425781, 'bn1': 0.0005910396575927734, 'relu1': 0.0003371238708496094, 'conv2': 0.001691579818725586, 'bn2': 0.000568389892578125, 'residual_add_relu2': 0.0007717609405517578}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010631084442138672, 'bn1': 0.00034737586975097656, 'relu1': 0.00018477439880371094, 'conv2': 0.0013113021850585938, 'bn2': 0.0003521442413330078, 'conv3': 0.00043082237243652344, 'residual_add_relu2': 0.0004010200500488281}\n",
      "{'conv1': 0.0013153553009033203, 'bn1': 0.0003781318664550781, 'relu1': 0.00018715858459472656, 'conv2': 0.0013082027435302734, 'bn2': 0.00034356117248535156, 'residual_add_relu2': 0.0003952980041503906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008020401000976562, 'bn1': 0.00022149085998535156, 'relu1': 0.00010728836059570312, 'conv2': 0.001168966293334961, 'bn2': 0.00023794174194335938, 'conv3': 0.0003719329833984375, 'residual_add_relu2': 0.00020885467529296875}\n",
      "{'conv1': 0.0011713504791259766, 'bn1': 0.00022339820861816406, 'relu1': 0.00010180473327636719, 'conv2': 0.0011484622955322266, 'bn2': 0.00022864341735839844, 'residual_add_relu2': 0.00021076202392578125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006775856018066406, 'bn1': 0.00014710426330566406, 'relu1': 7.104873657226562e-05, 'conv2': 0.0011615753173828125, 'bn2': 0.00014162063598632812, 'conv3': 0.00030231475830078125, 'residual_add_relu2': 0.00011301040649414062}\n",
      "{'conv1': 0.0011415481567382812, 'bn1': 0.00015282630920410156, 'relu1': 6.794929504394531e-05, 'conv2': 0.0011396408081054688, 'bn2': 0.00013875961303710938, 'residual_add_relu2': 0.00011277198791503906}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 103\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016369819641113281, 'bn1': 0.0005533695220947266, 'relu1': 0.0003256797790527344, 'conv2': 0.0016262531280517578, 'bn2': 0.0005457401275634766, 'residual_add_relu2': 0.0007624626159667969}\n",
      "{'conv1': 0.0016257762908935547, 'bn1': 0.0005488395690917969, 'relu1': 0.0003228187561035156, 'conv2': 0.001617431640625, 'bn2': 0.0005373954772949219, 'residual_add_relu2': 0.0007698535919189453}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010387897491455078, 'bn1': 0.0003085136413574219, 'relu1': 0.00017142295837402344, 'conv2': 0.0012907981872558594, 'bn2': 0.0003077983856201172, 'conv3': 0.0003979206085205078, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0012962818145751953, 'bn1': 0.0003120899200439453, 'relu1': 0.00017404556274414062, 'conv2': 0.0012917518615722656, 'bn2': 0.0003063678741455078, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007855892181396484, 'bn1': 0.0002014636993408203, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011401176452636719, 'bn2': 0.0001926422119140625, 'conv3': 0.0003495216369628906, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011436939239501953, 'bn1': 0.0002009868621826172, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011403560638427734, 'bn2': 0.00018858909606933594, 'residual_add_relu2': 0.00020265579223632812}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006513595581054688, 'bn1': 0.00012040138244628906, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011303424835205078, 'bn2': 0.00010943412780761719, 'conv3': 0.0002884864807128906, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011289119720458984, 'bn1': 0.00011348724365234375, 'relu1': 5.698204040527344e-05, 'conv2': 0.0011243820190429688, 'bn2': 0.00010824203491210938, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 104\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016398429870605469, 'bn1': 0.0005557537078857422, 'relu1': 0.00032401084899902344, 'conv2': 0.0016274452209472656, 'bn2': 0.0005476474761962891, 'residual_add_relu2': 0.0007686614990234375}\n",
      "{'conv1': 0.0016164779663085938, 'bn1': 0.0005514621734619141, 'relu1': 0.0003230571746826172, 'conv2': 0.0016281604766845703, 'bn2': 0.0005462169647216797, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010402202606201172, 'bn1': 0.0003192424774169922, 'relu1': 0.00017309188842773438, 'conv2': 0.0012969970703125, 'bn2': 0.0003085136413574219, 'conv3': 0.00040221214294433594, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0012958049774169922, 'bn1': 0.0003151893615722656, 'relu1': 0.00017333030700683594, 'conv2': 0.0012922286987304688, 'bn2': 0.00030875205993652344, 'residual_add_relu2': 0.00039196014404296875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007812976837158203, 'bn1': 0.00020003318786621094, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.000213623046875, 'conv3': 0.000354766845703125, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011451244354248047, 'bn1': 0.0002453327178955078, 'relu1': 9.965896606445312e-05, 'conv2': 0.001140594482421875, 'bn2': 0.0001952648162841797, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006544589996337891, 'bn1': 0.00012445449829101562, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011322498321533203, 'bn2': 0.00011563301086425781, 'conv3': 0.0003020763397216797, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.001134634017944336, 'bn1': 0.00012350082397460938, 'relu1': 5.8650970458984375e-05, 'conv2': 0.001130819320678711, 'bn2': 0.00011992454528808594, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 105\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001645803451538086, 'bn1': 0.0005655288696289062, 'relu1': 0.00032639503479003906, 'conv2': 0.0016298294067382812, 'bn2': 0.0005428791046142578, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.0016326904296875, 'bn1': 0.0005371570587158203, 'relu1': 0.00032401084899902344, 'conv2': 0.0016293525695800781, 'bn2': 0.0005490779876708984, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010454654693603516, 'bn1': 0.0003108978271484375, 'relu1': 0.00017213821411132812, 'conv2': 0.0013041496276855469, 'bn2': 0.0003097057342529297, 'conv3': 0.0003986358642578125, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.001302957534790039, 'bn1': 0.00031375885009765625, 'relu1': 0.00017404556274414062, 'conv2': 0.001300811767578125, 'bn2': 0.00031065940856933594, 'residual_add_relu2': 0.00038814544677734375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007810592651367188, 'bn1': 0.00019931793212890625, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.00020265579223632812, 'conv3': 0.00035500526428222656, 'residual_add_relu2': 0.0002033710479736328}\n",
      "{'conv1': 0.0011477470397949219, 'bn1': 0.0001926422119140625, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011439323425292969, 'bn2': 0.00018739700317382812, 'residual_add_relu2': 0.0002028942108154297}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006535053253173828, 'bn1': 0.00011277198791503906, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011353492736816406, 'bn2': 0.00010633468627929688, 'conv3': 0.00028395652770996094, 'residual_add_relu2': 0.00010919570922851562}\n",
      "{'conv1': 0.0011377334594726562, 'bn1': 0.00012254714965820312, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011394023895263672, 'bn2': 0.0001239776611328125, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 106\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016520023345947266, 'bn1': 0.0005514621734619141, 'relu1': 0.00032138824462890625, 'conv2': 0.0016241073608398438, 'bn2': 0.0005478858947753906, 'residual_add_relu2': 0.0007681846618652344}\n",
      "{'conv1': 0.001627206802368164, 'bn1': 0.0005464553833007812, 'relu1': 0.0003237724304199219, 'conv2': 0.0016236305236816406, 'bn2': 0.0005409717559814453, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010442733764648438, 'bn1': 0.0003178119659423828, 'relu1': 0.0001728534698486328, 'conv2': 0.0013041496276855469, 'bn2': 0.0003039836883544922, 'conv3': 0.0003981590270996094, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013027191162109375, 'bn1': 0.00030732154846191406, 'relu1': 0.0001709461212158203, 'conv2': 0.0012969970703125, 'bn2': 0.00030303001403808594, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007836818695068359, 'bn1': 0.0001976490020751953, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011472702026367188, 'bn2': 0.0001900196075439453, 'conv3': 0.0003514289855957031, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011487007141113281, 'bn1': 0.00019621849060058594, 'relu1': 9.679794311523438e-05, 'conv2': 0.001142263412475586, 'bn2': 0.00019979476928710938, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006530284881591797, 'bn1': 0.00011777877807617188, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011372566223144531, 'bn2': 0.00011539459228515625, 'conv3': 0.00028634071350097656, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011391639709472656, 'bn1': 0.00011277198791503906, 'relu1': 5.650520324707031e-05, 'conv2': 0.001132965087890625, 'bn2': 0.00010967254638671875, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 107\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001630544662475586, 'bn1': 0.0005595684051513672, 'relu1': 0.00032448768615722656, 'conv2': 0.0016210079193115234, 'bn2': 0.0005438327789306641, 'residual_add_relu2': 0.0007677078247070312}\n",
      "{'conv1': 0.0016241073608398438, 'bn1': 0.0005347728729248047, 'relu1': 0.0003223419189453125, 'conv2': 0.0016205310821533203, 'bn2': 0.0005409717559814453, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001043558120727539, 'bn1': 0.000316619873046875, 'relu1': 0.0001723766326904297, 'conv2': 0.0013015270233154297, 'bn2': 0.0003077983856201172, 'conv3': 0.0003991127014160156, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.00130462646484375, 'bn1': 0.0003077983856201172, 'relu1': 0.00017142295837402344, 'conv2': 0.0012962818145751953, 'bn2': 0.00029850006103515625, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007803440093994141, 'bn1': 0.00019288063049316406, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.0001957416534423828, 'conv3': 0.0003540515899658203, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0011513233184814453, 'bn1': 0.0001976490020751953, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011470317840576172, 'bn2': 0.00019931793212890625, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006570816040039062, 'bn1': 0.00012159347534179688, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011396408081054688, 'bn2': 0.00011420249938964844, 'conv3': 0.00029015541076660156, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011425018310546875, 'bn1': 0.00012421607971191406, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011377334594726562, 'bn2': 0.00012612342834472656, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 108\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016334056854248047, 'bn1': 0.0005524158477783203, 'relu1': 0.0003237724304199219, 'conv2': 0.0016245841979980469, 'bn2': 0.0005385875701904297, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016298294067382812, 'bn1': 0.0005445480346679688, 'relu1': 0.0003218650817871094, 'conv2': 0.0016193389892578125, 'bn2': 0.0005421638488769531, 'residual_add_relu2': 0.0007691383361816406}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.00104522705078125, 'bn1': 0.0003147125244140625, 'relu1': 0.00017189979553222656, 'conv2': 0.001302480697631836, 'bn2': 0.00031447410583496094, 'conv3': 0.00039887428283691406, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013017654418945312, 'bn1': 0.00031185150146484375, 'relu1': 0.0001723766326904297, 'conv2': 0.0013003349304199219, 'bn2': 0.0003120899200439453, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007846355438232422, 'bn1': 0.0002186298370361328, 'relu1': 9.846687316894531e-05, 'conv2': 0.001149892807006836, 'bn2': 0.0001976490020751953, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011494159698486328, 'bn1': 0.00019884109497070312, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00019431114196777344, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006551742553710938, 'bn1': 0.00012230873107910156, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011398792266845703, 'bn2': 0.00011372566223144531, 'conv3': 0.0002918243408203125, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011403560638427734, 'bn1': 0.00011873245239257812, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011360645294189453, 'bn2': 0.000118255615234375, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 109\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001634359359741211, 'bn1': 0.0005519390106201172, 'relu1': 0.00032258033752441406, 'conv2': 0.001619100570678711, 'bn2': 0.0005345344543457031, 'residual_add_relu2': 0.0007638931274414062}\n",
      "{'conv1': 0.0016293525695800781, 'bn1': 0.0005471706390380859, 'relu1': 0.0003266334533691406, 'conv2': 0.0016226768493652344, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010502338409423828, 'bn1': 0.00031447410583496094, 'relu1': 0.00017380714416503906, 'conv2': 0.0013027191162109375, 'bn2': 0.00031280517578125, 'conv3': 0.0004029273986816406, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013086795806884766, 'bn1': 0.00031566619873046875, 'relu1': 0.0001742839813232422, 'conv2': 0.0013000965118408203, 'bn2': 0.0003123283386230469, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007953643798828125, 'bn1': 0.00020194053649902344, 'relu1': 9.918212890625e-05, 'conv2': 0.001149892807006836, 'bn2': 0.0001876354217529297, 'conv3': 0.0003514289855957031, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011532306671142578, 'bn1': 0.00019240379333496094, 'relu1': 9.512901306152344e-05, 'conv2': 0.0011425018310546875, 'bn2': 0.00018405914306640625, 'residual_add_relu2': 0.0002033710479736328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006525516510009766, 'bn1': 0.00011849403381347656, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011355876922607422, 'bn2': 0.00010585784912109375, 'conv3': 0.00028824806213378906, 'residual_add_relu2': 0.00010967254638671875}\n",
      "{'conv1': 0.0011379718780517578, 'bn1': 0.00011944770812988281, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011386871337890625, 'bn2': 0.00012755393981933594, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 110\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016455650329589844, 'bn1': 0.0005869865417480469, 'relu1': 0.00032806396484375, 'conv2': 0.00164031982421875, 'bn2': 0.0005488395690917969, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016298294067382812, 'bn1': 0.0005440711975097656, 'relu1': 0.0003249645233154297, 'conv2': 0.0016245841979980469, 'bn2': 0.0005409717559814453, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010449886322021484, 'bn1': 0.0003368854522705078, 'relu1': 0.00017499923706054688, 'conv2': 0.0013048648834228516, 'bn2': 0.0003120899200439453, 'conv3': 0.00039958953857421875, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0015544891357421875, 'bn1': 0.0003685951232910156, 'relu1': 0.00018143653869628906, 'conv2': 0.001310586929321289, 'bn2': 0.00031304359436035156, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007920265197753906, 'bn1': 0.0002262592315673828, 'relu1': 0.00010132789611816406, 'conv2': 0.0011529922485351562, 'bn2': 0.0001983642578125, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011527538299560547, 'bn1': 0.00020360946655273438, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.0002110004425048828, 'residual_add_relu2': 0.0002071857452392578}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006601810455322266, 'bn1': 0.00012636184692382812, 'relu1': 6.318092346191406e-05, 'conv2': 0.0011408329010009766, 'bn2': 0.00011515617370605469, 'conv3': 0.0002906322479248047, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011470317840576172, 'bn1': 0.00012254714965820312, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011386871337890625, 'bn2': 0.00011491775512695312, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 111\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016543865203857422, 'bn1': 0.0005476474761962891, 'relu1': 0.00032210350036621094, 'conv2': 0.00162506103515625, 'bn2': 0.0005574226379394531, 'residual_add_relu2': 0.0007679462432861328}\n",
      "{'conv1': 0.0016291141510009766, 'bn1': 0.0005571842193603516, 'relu1': 0.0003211498260498047, 'conv2': 0.0016257762908935547, 'bn2': 0.0005316734313964844, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001041412353515625, 'bn1': 0.00031948089599609375, 'relu1': 0.00017452239990234375, 'conv2': 0.001302480697631836, 'bn2': 0.0003094673156738281, 'conv3': 0.00040078163146972656, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013058185577392578, 'bn1': 0.0003173351287841797, 'relu1': 0.0001747608184814453, 'conv2': 0.0013017654418945312, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007860660552978516, 'bn1': 0.00021076202392578125, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.00020122528076171875, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.00115203857421875, 'bn1': 0.0002009868621826172, 'relu1': 0.00010704994201660156, 'conv2': 0.0011565685272216797, 'bn2': 0.0001888275146484375, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006515979766845703, 'bn1': 0.00011110305786132812, 'relu1': 5.698204040527344e-05, 'conv2': 0.0011358261108398438, 'bn2': 0.0001049041748046875, 'conv3': 0.00028705596923828125, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011374950408935547, 'bn1': 0.00011420249938964844, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011470317840576172, 'bn2': 0.00011420249938964844, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 112\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001646280288696289, 'bn1': 0.0005557537078857422, 'relu1': 0.0003218650817871094, 'conv2': 0.0016238689422607422, 'bn2': 0.0005595684051513672, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.001638650894165039, 'bn1': 0.0005438327789306641, 'relu1': 0.0003337860107421875, 'conv2': 0.0016262531280517578, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001041412353515625, 'bn1': 0.00031757354736328125, 'relu1': 0.00017189979553222656, 'conv2': 0.0013003349304199219, 'bn2': 0.000301361083984375, 'conv3': 0.00039505958557128906, 'residual_add_relu2': 0.00038886070251464844}\n",
      "{'conv1': 0.0012989044189453125, 'bn1': 0.00030612945556640625, 'relu1': 0.0001704692840576172, 'conv2': 0.001295328140258789, 'bn2': 0.0003008842468261719, 'residual_add_relu2': 0.00038743019104003906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007810592651367188, 'bn1': 0.00019240379333496094, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011458396911621094, 'bn2': 0.0001919269561767578, 'conv3': 0.00034928321838378906, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.00019359588623046875, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011444091796875, 'bn2': 0.0002243518829345703, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006556510925292969, 'bn1': 0.00011587142944335938, 'relu1': 5.841255187988281e-05, 'conv2': 0.001138448715209961, 'bn2': 0.00011467933654785156, 'conv3': 0.0002930164337158203, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.001142740249633789, 'bn1': 0.00013303756713867188, 'relu1': 6.103515625e-05, 'conv2': 0.0011415481567382812, 'bn2': 0.00011444091796875, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 113\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016384124755859375, 'bn1': 0.00055694580078125, 'relu1': 0.0003230571746826172, 'conv2': 0.0016231536865234375, 'bn2': 0.0005424022674560547, 'residual_add_relu2': 0.0007710456848144531}\n",
      "{'conv1': 0.0016314983367919922, 'bn1': 0.0005459785461425781, 'relu1': 0.0003249645233154297, 'conv2': 0.0016245841979980469, 'bn2': 0.0005435943603515625, 'residual_add_relu2': 0.0007658004760742188}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010416507720947266, 'bn1': 0.0003330707550048828, 'relu1': 0.00017452239990234375, 'conv2': 0.0013186931610107422, 'bn2': 0.0003142356872558594, 'conv3': 0.0004012584686279297, 'residual_add_relu2': 0.00039196014404296875}\n",
      "{'conv1': 0.0013039112091064453, 'bn1': 0.00031495094299316406, 'relu1': 0.0001766681671142578, 'conv2': 0.0013005733489990234, 'bn2': 0.00031113624572753906, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007865428924560547, 'bn1': 0.0002002716064453125, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00020933151245117188, 'conv3': 0.0003573894500732422, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011506080627441406, 'bn1': 0.00019884109497070312, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011467933654785156, 'bn2': 0.0008471012115478516, 'residual_add_relu2': 0.00021457672119140625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006806850433349609, 'bn1': 0.00013637542724609375, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011425018310546875, 'bn2': 0.00011014938354492188, 'conv3': 0.0002951622009277344, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.0011401176452636719, 'bn1': 0.00012302398681640625, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011360645294189453, 'bn2': 0.00010800361633300781, 'residual_add_relu2': 0.00010848045349121094}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 114\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016469955444335938, 'bn1': 0.0005812644958496094, 'relu1': 0.0003268718719482422, 'conv2': 0.0016243457794189453, 'bn2': 0.0005395412445068359, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016274452209472656, 'bn1': 0.0005483627319335938, 'relu1': 0.0003228187561035156, 'conv2': 0.0016264915466308594, 'bn2': 0.0005421638488769531, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010495185852050781, 'bn1': 0.00031876564025878906, 'relu1': 0.00017452239990234375, 'conv2': 0.0013048648834228516, 'bn2': 0.0003139972686767578, 'conv3': 0.0004019737243652344, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013041496276855469, 'bn1': 0.0003180503845214844, 'relu1': 0.0001766681671142578, 'conv2': 0.0012996196746826172, 'bn2': 0.0003056526184082031, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007853507995605469, 'bn1': 0.00020003318786621094, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011599063873291016, 'bn2': 0.00020813941955566406, 'conv3': 0.0003597736358642578, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.00115203857421875, 'bn1': 0.0002148151397705078, 'relu1': 0.00011157989501953125, 'conv2': 0.0011491775512695312, 'bn2': 0.00021886825561523438, 'residual_add_relu2': 0.00020742416381835938}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000659942626953125, 'bn1': 0.00012373924255371094, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011398792266845703, 'bn2': 0.00011491775512695312, 'conv3': 0.0002925395965576172, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011401176452636719, 'bn1': 0.00012373924255371094, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011363029479980469, 'bn2': 0.00011420249938964844, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 115\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016450881958007812, 'bn1': 0.0005435943603515625, 'relu1': 0.000324249267578125, 'conv2': 0.0016295909881591797, 'bn2': 0.0005424022674560547, 'residual_add_relu2': 0.0007643699645996094}\n",
      "{'conv1': 0.001623392105102539, 'bn1': 0.0005552768707275391, 'relu1': 0.0003216266632080078, 'conv2': 0.0016186237335205078, 'bn2': 0.0007071495056152344, 'residual_add_relu2': 0.0008165836334228516}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.00107574462890625, 'bn1': 0.0003464221954345703, 'relu1': 0.00018143653869628906, 'conv2': 0.0013120174407958984, 'bn2': 0.0003256797790527344, 'conv3': 0.00041556358337402344, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013134479522705078, 'bn1': 0.0003197193145751953, 'relu1': 0.0001785755157470703, 'conv2': 0.0013120174407958984, 'bn2': 0.00032520294189453125, 'residual_add_relu2': 0.0003941059112548828}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.00080108642578125, 'bn1': 0.00020837783813476562, 'relu1': 0.00010395050048828125, 'conv2': 0.0011570453643798828, 'bn2': 0.00020503997802734375, 'conv3': 0.00036525726318359375, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.001157999038696289, 'bn1': 0.00020599365234375, 'relu1': 0.00010275840759277344, 'conv2': 0.0011539459228515625, 'bn2': 0.0002071857452392578, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006580352783203125, 'bn1': 0.00013303756713867188, 'relu1': 6.151199340820312e-05, 'conv2': 0.0011444091796875, 'bn2': 0.0001251697540283203, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011229515075683594}\n",
      "{'conv1': 0.0011441707611083984, 'bn1': 0.00012040138244628906, 'relu1': 5.745887756347656e-05, 'conv2': 0.001134634017944336, 'bn2': 0.00012063980102539062, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 116\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016396045684814453, 'bn1': 0.00055694580078125, 'relu1': 0.00032401084899902344, 'conv2': 0.0016210079193115234, 'bn2': 0.0005450248718261719, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016264915466308594, 'bn1': 0.000545501708984375, 'relu1': 0.0003254413604736328, 'conv2': 0.00162506103515625, 'bn2': 0.0005400180816650391, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010488033294677734, 'bn1': 0.0003161430358886719, 'relu1': 0.00017380714416503906, 'conv2': 0.0013005733489990234, 'bn2': 0.0003070831298828125, 'conv3': 0.0003981590270996094, 'residual_add_relu2': 0.0003921985626220703}\n",
      "{'conv1': 0.0013039112091064453, 'bn1': 0.0003132820129394531, 'relu1': 0.0001735687255859375, 'conv2': 0.0012996196746826172, 'bn2': 0.0003075599670410156, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007979869842529297, 'bn1': 0.0002014636993408203, 'relu1': 9.870529174804688e-05, 'conv2': 0.001149892807006836, 'bn2': 0.00019669532775878906, 'conv3': 0.0003840923309326172, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0011570453643798828, 'bn1': 0.00021338462829589844, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00019431114196777344, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006568431854248047, 'bn1': 0.00012254714965820312, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011401176452636719, 'bn2': 0.000118255615234375, 'conv3': 0.00029349327087402344, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.001142263412475586, 'bn1': 0.00012111663818359375, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011370182037353516, 'bn2': 0.00012350082397460938, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 117\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016543865203857422, 'bn1': 0.0005600452423095703, 'relu1': 0.0003249645233154297, 'conv2': 0.0016329288482666016, 'bn2': 0.0005452632904052734, 'residual_add_relu2': 0.0007703304290771484}\n",
      "{'conv1': 0.0016400814056396484, 'bn1': 0.0005497932434082031, 'relu1': 0.0003230571746826172, 'conv2': 0.00164031982421875, 'bn2': 0.0005462169647216797, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010480880737304688, 'bn1': 0.00031757354736328125, 'relu1': 0.00017333030700683594, 'conv2': 0.0013136863708496094, 'bn2': 0.00031280517578125, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013079643249511719, 'bn1': 0.0003116130828857422, 'relu1': 0.000171661376953125, 'conv2': 0.0013020038604736328, 'bn2': 0.00031685829162597656, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007867813110351562, 'bn1': 0.0002028942108154297, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011513233184814453, 'bn2': 0.00020265579223632812, 'conv3': 0.0003561973571777344, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011532306671142578, 'bn1': 0.00020003318786621094, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011472702026367188, 'bn2': 0.0001995563507080078, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006566047668457031, 'bn1': 0.000125885009765625, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.00011754035949707031, 'conv3': 0.0002911090850830078, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011396408081054688, 'bn1': 0.00011992454528808594, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011339187622070312, 'bn2': 0.00010919570922851562, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 118\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016486644744873047, 'bn1': 0.0005638599395751953, 'relu1': 0.0003268718719482422, 'conv2': 0.0016243457794189453, 'bn2': 0.0005509853363037109, 'residual_add_relu2': 0.0007696151733398438}\n",
      "{'conv1': 0.0016300678253173828, 'bn1': 0.0005509853363037109, 'relu1': 0.0003261566162109375, 'conv2': 0.0016231536865234375, 'bn2': 0.0005478858947753906, 'residual_add_relu2': 0.0007672309875488281}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010528564453125, 'bn1': 0.0003228187561035156, 'relu1': 0.00017547607421875, 'conv2': 0.0013077259063720703, 'bn2': 0.0003173351287841797, 'conv3': 0.0004055500030517578, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013093948364257812, 'bn1': 0.00031876564025878906, 'relu1': 0.00017571449279785156, 'conv2': 0.0013022422790527344, 'bn2': 0.00033402442932128906, 'residual_add_relu2': 0.0003924369812011719}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0009739398956298828, 'bn1': 0.0004284381866455078, 'relu1': 0.00015497207641601562, 'conv2': 0.0012447834014892578, 'bn2': 0.00035953521728515625, 'conv3': 0.00043845176696777344, 'residual_add_relu2': 0.00023865699768066406}\n",
      "{'conv1': 0.0011539459228515625, 'bn1': 0.0002028942108154297, 'relu1': 9.918212890625e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.0001983642578125, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006589889526367188, 'bn1': 0.0001304149627685547, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011410713195800781, 'bn2': 0.00011038780212402344, 'conv3': 0.0002894401550292969, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011386871337890625, 'bn1': 0.0001163482666015625, 'relu1': 5.650520324707031e-05, 'conv2': 0.0011341571807861328, 'bn2': 0.00011301040649414062, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 119\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016460418701171875, 'bn1': 0.0005681514739990234, 'relu1': 0.00032639503479003906, 'conv2': 0.0016274452209472656, 'bn2': 0.0005476474761962891, 'residual_add_relu2': 0.0007648468017578125}\n",
      "{'conv1': 0.0016334056854248047, 'bn1': 0.0005519390106201172, 'relu1': 0.00032520294189453125, 'conv2': 0.001623392105102539, 'bn2': 0.0005519390106201172, 'residual_add_relu2': 0.0007643699645996094}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001051187515258789, 'bn1': 0.0003266334533691406, 'relu1': 0.00019288063049316406, 'conv2': 0.0013115406036376953, 'bn2': 0.0003261566162109375, 'conv3': 0.0004074573516845703, 'residual_add_relu2': 0.00039196014404296875}\n",
      "{'conv1': 0.0013074874877929688, 'bn1': 0.0003237724304199219, 'relu1': 0.0001766681671142578, 'conv2': 0.0013039112091064453, 'bn2': 0.0003116130828857422, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007851123809814453, 'bn1': 0.00019979476928710938, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.0002033710479736328, 'conv3': 0.0003600120544433594, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.0011556148529052734, 'bn1': 0.0002071857452392578, 'relu1': 0.00010085105895996094, 'conv2': 0.0011510848999023438, 'bn2': 0.0002033710479736328, 'residual_add_relu2': 0.00020599365234375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006608963012695312, 'bn1': 0.0001316070556640625, 'relu1': 6.246566772460938e-05, 'conv2': 0.0011448860168457031, 'bn2': 0.00012159347534179688, 'conv3': 0.0002963542938232422, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011456012725830078, 'bn1': 0.00012063980102539062, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011372566223144531, 'bn2': 0.00012421607971191406, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 120\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016450881958007812, 'bn1': 0.0005612373352050781, 'relu1': 0.00032639503479003906, 'conv2': 0.001636505126953125, 'bn2': 0.0005514621734619141, 'residual_add_relu2': 0.0007700920104980469}\n",
      "{'conv1': 0.0016307830810546875, 'bn1': 0.0005452632904052734, 'relu1': 0.00033092498779296875, 'conv2': 0.0016260147094726562, 'bn2': 0.000576019287109375, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010542869567871094, 'bn1': 0.0003209114074707031, 'relu1': 0.00017881393432617188, 'conv2': 0.0013184547424316406, 'bn2': 0.00034546852111816406, 'conv3': 0.00041031837463378906, 'residual_add_relu2': 0.00039315223693847656}\n",
      "{'conv1': 0.0013115406036376953, 'bn1': 0.00033164024353027344, 'relu1': 0.00017762184143066406, 'conv2': 0.0013072490692138672, 'bn2': 0.0003190040588378906, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007865428924560547, 'bn1': 0.00020241737365722656, 'relu1': 0.00010156631469726562, 'conv2': 0.0011565685272216797, 'bn2': 0.0002052783966064453, 'conv3': 0.00035762786865234375, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.001186370849609375, 'bn1': 0.00021123886108398438, 'relu1': 0.00010228157043457031, 'conv2': 0.0011494159698486328, 'bn2': 0.0001971721649169922, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006573200225830078, 'bn1': 0.00012421607971191406, 'relu1': 6.222724914550781e-05, 'conv2': 0.0011410713195800781, 'bn2': 0.0001239776611328125, 'conv3': 0.0002911090850830078, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011408329010009766, 'bn1': 0.00012254714965820312, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011379718780517578, 'bn2': 0.00011563301086425781, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 121\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016515254974365234, 'bn1': 0.0005612373352050781, 'relu1': 0.00032520294189453125, 'conv2': 0.0016324520111083984, 'bn2': 0.0005428791046142578, 'residual_add_relu2': 0.0007691383361816406}\n",
      "{'conv1': 0.0016369819641113281, 'bn1': 0.0005445480346679688, 'relu1': 0.000324249267578125, 'conv2': 0.0016312599182128906, 'bn2': 0.0005466938018798828, 'residual_add_relu2': 0.0007665157318115234}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010449886322021484, 'bn1': 0.0003104209899902344, 'relu1': 0.00017213821411132812, 'conv2': 0.0013074874877929688, 'bn2': 0.00030493736267089844, 'conv3': 0.0003960132598876953, 'residual_add_relu2': 0.00038886070251464844}\n",
      "{'conv1': 0.0013053417205810547, 'bn1': 0.00030684471130371094, 'relu1': 0.00017189979553222656, 'conv2': 0.001298666000366211, 'bn2': 0.00031065940856933594, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007843971252441406, 'bn1': 0.00019812583923339844, 'relu1': 9.822845458984375e-05, 'conv2': 0.001146554946899414, 'bn2': 0.0002269744873046875, 'conv3': 0.000354766845703125, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.00115203857421875, 'bn1': 0.00019931793212890625, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011491775512695312, 'bn2': 0.00019669532775878906, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006566047668457031, 'bn1': 0.00012183189392089844, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011398792266845703, 'bn2': 0.00011491775512695312, 'conv3': 0.0002906322479248047, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011420249938964844, 'bn1': 0.00012230873107910156, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011382102966308594, 'bn2': 0.00011539459228515625, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 122\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016436576843261719, 'bn1': 0.0005538463592529297, 'relu1': 0.0003254413604736328, 'conv2': 0.00162506103515625, 'bn2': 0.0005512237548828125, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.0016486644744873047, 'bn1': 0.0005657672882080078, 'relu1': 0.000335693359375, 'conv2': 0.001630544662475586, 'bn2': 0.0005497932434082031, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010509490966796875, 'bn1': 0.00031685829162597656, 'relu1': 0.00017547607421875, 'conv2': 0.0013027191162109375, 'bn2': 0.0003082752227783203, 'conv3': 0.0003948211669921875, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013027191162109375, 'bn1': 0.00031757354736328125, 'relu1': 0.00017452239990234375, 'conv2': 0.0013010501861572266, 'bn2': 0.0003116130828857422, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007851123809814453, 'bn1': 0.0002048015594482422, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011470317840576172, 'bn2': 0.0001895427703857422, 'conv3': 0.00034880638122558594, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.001149892807006836, 'bn1': 0.00019073486328125, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011432170867919922, 'bn2': 0.00019288063049316406, 'residual_add_relu2': 0.00020313262939453125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006618499755859375, 'bn1': 0.0001201629638671875, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011391639709472656, 'bn2': 0.00011920928955078125, 'conv3': 0.00028824806213378906, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011403560638427734, 'bn1': 0.00011682510375976562, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011343955993652344, 'bn2': 0.00011110305786132812, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 123\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016803741455078125, 'bn1': 0.0005652904510498047, 'relu1': 0.0003266334533691406, 'conv2': 0.0016345977783203125, 'bn2': 0.0005559921264648438, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016322135925292969, 'bn1': 0.0005404949188232422, 'relu1': 0.00032258033752441406, 'conv2': 0.0016279220581054688, 'bn2': 0.0005366802215576172, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010530948638916016, 'bn1': 0.0003235340118408203, 'relu1': 0.00017404556274414062, 'conv2': 0.0013079643249511719, 'bn2': 0.0003190040588378906, 'conv3': 0.00040149688720703125, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013036727905273438, 'bn1': 0.0003154277801513672, 'relu1': 0.0001735687255859375, 'conv2': 0.001302957534790039, 'bn2': 0.00030922889709472656, 'residual_add_relu2': 0.0003886222839355469}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007846355438232422, 'bn1': 0.00020432472229003906, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011491775512695312, 'bn2': 0.00019478797912597656, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011522769927978516, 'bn1': 0.0002071857452392578, 'relu1': 0.00010061264038085938, 'conv2': 0.0011513233184814453, 'bn2': 0.0002040863037109375, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006577968597412109, 'bn1': 0.00014138221740722656, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011394023895263672, 'bn2': 0.00011730194091796875, 'conv3': 0.0002899169921875, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011439323425292969, 'bn1': 0.00012087821960449219, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011374950408935547, 'bn2': 0.00011420249938964844, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 124\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016312599182128906, 'bn1': 0.0005578994750976562, 'relu1': 0.0003209114074707031, 'conv2': 0.0016241073608398438, 'bn2': 0.0005328655242919922, 'residual_add_relu2': 0.0007677078247070312}\n",
      "{'conv1': 0.0016214847564697266, 'bn1': 0.0005328655242919922, 'relu1': 0.00032067298889160156, 'conv2': 0.001619577407836914, 'bn2': 0.0005340576171875, 'residual_add_relu2': 0.0007615089416503906}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010387897491455078, 'bn1': 0.00030875205993652344, 'relu1': 0.0001704692840576172, 'conv2': 0.001298666000366211, 'bn2': 0.0003237724304199219, 'conv3': 0.00040030479431152344, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013031959533691406, 'bn1': 0.0003135204315185547, 'relu1': 0.0001735687255859375, 'conv2': 0.0013151168823242188, 'bn2': 0.00031256675720214844, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007827281951904297, 'bn1': 0.0001933574676513672, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00019884109497070312, 'conv3': 0.0003535747528076172, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011510848999023438, 'bn1': 0.00019431114196777344, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011432170867919922, 'bn2': 0.0001876354217529297, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006551742553710938, 'bn1': 0.00011610984802246094, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011358261108398438, 'bn2': 0.00011181831359863281, 'conv3': 0.00029087066650390625, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011372566223144531, 'bn1': 0.00011301040649414062, 'relu1': 5.793571472167969e-05, 'conv2': 0.0012235641479492188, 'bn2': 0.0001308917999267578, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 125\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001657724380493164, 'bn1': 0.0005633831024169922, 'relu1': 0.00032520294189453125, 'conv2': 0.0016326904296875, 'bn2': 0.0005424022674560547, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016293525695800781, 'bn1': 0.0005450248718261719, 'relu1': 0.0003230571746826172, 'conv2': 0.0016269683837890625, 'bn2': 0.0005517005920410156, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001046895980834961, 'bn1': 0.00031828880310058594, 'relu1': 0.00017333030700683594, 'conv2': 0.0013022422790527344, 'bn2': 0.0003120899200439453, 'conv3': 0.00040459632873535156, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013065338134765625, 'bn1': 0.0003085136413574219, 'relu1': 0.00017118453979492188, 'conv2': 0.0012977123260498047, 'bn2': 0.0003058910369873047, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007810592651367188, 'bn1': 0.0001914501190185547, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.00019407272338867188, 'conv3': 0.0003635883331298828, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011489391326904297, 'bn1': 0.0001952648162841797, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011439323425292969, 'bn2': 0.00018858909606933594, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006561279296875, 'bn1': 0.00012946128845214844, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011436939239501953, 'bn2': 0.00011658668518066406, 'conv3': 0.0002892017364501953, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011441707611083984, 'bn1': 0.00012087821960449219, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011394023895263672, 'bn2': 0.00011849403381347656, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 126\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016374588012695312, 'bn1': 0.0005550384521484375, 'relu1': 0.0003216266632080078, 'conv2': 0.0016186237335205078, 'bn2': 0.0005297660827636719, 'residual_add_relu2': 0.0007638931274414062}\n",
      "{'conv1': 0.0016300678253173828, 'bn1': 0.0005395412445068359, 'relu1': 0.00032138824462890625, 'conv2': 0.0016231536865234375, 'bn2': 0.0005373954772949219, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010423660278320312, 'bn1': 0.0003075599670410156, 'relu1': 0.0001704692840576172, 'conv2': 0.0012984275817871094, 'bn2': 0.00031638145446777344, 'conv3': 0.00039577484130859375, 'residual_add_relu2': 0.0003883838653564453}\n",
      "{'conv1': 0.0012967586517333984, 'bn1': 0.0003032684326171875, 'relu1': 0.00017070770263671875, 'conv2': 0.0012969970703125, 'bn2': 0.00031375885009765625, 'residual_add_relu2': 0.0003876686096191406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007827281951904297, 'bn1': 0.00019240379333496094, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011472702026367188, 'bn2': 0.00018644332885742188, 'conv3': 0.0003502368927001953, 'residual_add_relu2': 0.00020837783813476562}\n",
      "{'conv1': 0.0011532306671142578, 'bn1': 0.00019478797912597656, 'relu1': 9.584426879882812e-05, 'conv2': 0.0011436939239501953, 'bn2': 0.00019288063049316406, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006573200225830078, 'bn1': 0.0001437664031982422, 'relu1': 6.151199340820312e-05, 'conv2': 0.0011432170867919922, 'bn2': 0.00011587142944335938, 'conv3': 0.0002930164337158203, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.001140594482421875, 'bn1': 0.0001232624053955078, 'relu1': 5.984306335449219e-05, 'conv2': 0.00113677978515625, 'bn2': 0.00011920928955078125, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 127\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016486644744873047, 'bn1': 0.0005629062652587891, 'relu1': 0.000324249267578125, 'conv2': 0.0016207695007324219, 'bn2': 0.0005469322204589844, 'residual_add_relu2': 0.0007691383361816406}\n",
      "{'conv1': 0.0016260147094726562, 'bn1': 0.0005483627319335938, 'relu1': 0.00032329559326171875, 'conv2': 0.0016202926635742188, 'bn2': 0.0005457401275634766, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010416507720947266, 'bn1': 0.00031685829162597656, 'relu1': 0.00018167495727539062, 'conv2': 0.0013065338134765625, 'bn2': 0.0003123283386230469, 'conv3': 0.0004029273986816406, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013031959533691406, 'bn1': 0.000316619873046875, 'relu1': 0.0001785755157470703, 'conv2': 0.0013017654418945312, 'bn2': 0.00029969215393066406, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007798671722412109, 'bn1': 0.00019216537475585938, 'relu1': 9.5367431640625e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00019931793212890625, 'conv3': 0.0003540515899658203, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011568069458007812, 'bn1': 0.0002028942108154297, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011472702026367188, 'bn2': 0.000202178955078125, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006568431854248047, 'bn1': 0.00012302398681640625, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011398792266845703, 'bn2': 0.00011467933654785156, 'conv3': 0.0002913475036621094, 'residual_add_relu2': 0.00011324882507324219}\n",
      "{'conv1': 0.0011467933654785156, 'bn1': 0.0001385211944580078, 'relu1': 6.29425048828125e-05, 'conv2': 0.0011439323425292969, 'bn2': 0.00012731552124023438, 'residual_add_relu2': 0.00011181831359863281}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 128\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016589164733886719, 'bn1': 0.0005667209625244141, 'relu1': 0.00032520294189453125, 'conv2': 0.0016300678253173828, 'bn2': 0.0005576610565185547, 'residual_add_relu2': 0.0007688999176025391}\n",
      "{'conv1': 0.0016357898712158203, 'bn1': 0.0005481243133544922, 'relu1': 0.000324249267578125, 'conv2': 0.0016243457794189453, 'bn2': 0.000560760498046875, 'residual_add_relu2': 0.0007669925689697266}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010480880737304688, 'bn1': 0.00032711029052734375, 'relu1': 0.00017404556274414062, 'conv2': 0.00130462646484375, 'bn2': 0.0003135204315185547, 'conv3': 0.0004057884216308594, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013153553009033203, 'bn1': 0.0003330707550048828, 'relu1': 0.0001766681671142578, 'conv2': 0.0013048648834228516, 'bn2': 0.0003147125244140625, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007884502410888672, 'bn1': 0.00020503997802734375, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.000202178955078125, 'conv3': 0.0003578662872314453, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011548995971679688, 'bn1': 0.00020265579223632812, 'relu1': 9.870529174804688e-05, 'conv2': 0.001155853271484375, 'bn2': 0.00026345252990722656, 'residual_add_relu2': 0.00021266937255859375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006830692291259766, 'bn1': 0.00014209747314453125, 'relu1': 6.556510925292969e-05, 'conv2': 0.0011582374572753906, 'bn2': 0.00013637542724609375, 'conv3': 0.0003070831298828125, 'residual_add_relu2': 0.00011467933654785156}\n",
      "{'conv1': 0.0011529922485351562, 'bn1': 0.000156402587890625, 'relu1': 6.341934204101562e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.00013399124145507812, 'residual_add_relu2': 0.00011277198791503906}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 129\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016560554504394531, 'bn1': 0.0005590915679931641, 'relu1': 0.0003247261047363281, 'conv2': 0.0016336441040039062, 'bn2': 0.0005459785461425781, 'residual_add_relu2': 0.0007698535919189453}\n",
      "{'conv1': 0.0016341209411621094, 'bn1': 0.0005497932434082031, 'relu1': 0.0003256797790527344, 'conv2': 0.0016248226165771484, 'bn2': 0.0005497932434082031, 'residual_add_relu2': 0.0007655620574951172}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010476112365722656, 'bn1': 0.00032210350036621094, 'relu1': 0.00017714500427246094, 'conv2': 0.0013093948364257812, 'bn2': 0.000316619873046875, 'conv3': 0.00040435791015625, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013058185577392578, 'bn1': 0.00033473968505859375, 'relu1': 0.0001773834228515625, 'conv2': 0.0013051033020019531, 'bn2': 0.00031185150146484375, 'residual_add_relu2': 0.0003886222839355469}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007841587066650391, 'bn1': 0.000194549560546875, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011491775512695312, 'bn2': 0.00019598007202148438, 'conv3': 0.00035262107849121094, 'residual_add_relu2': 0.00020313262939453125}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.0002014636993408203, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.00019979476928710938, 'residual_add_relu2': 0.00020575523376464844}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006592273712158203, 'bn1': 0.0001266002655029297, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011432170867919922, 'bn2': 0.00011658668518066406, 'conv3': 0.0002925395965576172, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011415481567382812, 'bn1': 0.000125885009765625, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011436939239501953, 'bn2': 0.00012111663818359375, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 130\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016393661499023438, 'bn1': 0.0005526542663574219, 'relu1': 0.00034165382385253906, 'conv2': 0.0017287731170654297, 'bn2': 0.0007131099700927734, 'residual_add_relu2': 0.0007915496826171875}\n",
      "{'conv1': 0.0016283988952636719, 'bn1': 0.0005517005920410156, 'relu1': 0.00033092498779296875, 'conv2': 0.0016307830810546875, 'bn2': 0.0005440711975097656, 'residual_add_relu2': 0.0007610321044921875}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001050710678100586, 'bn1': 0.00031113624572753906, 'relu1': 0.00017118453979492188, 'conv2': 0.001299142837524414, 'bn2': 0.0003097057342529297, 'conv3': 0.0004038810729980469, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013077259063720703, 'bn1': 0.00030422210693359375, 'relu1': 0.00016999244689941406, 'conv2': 0.0012965202331542969, 'bn2': 0.0003077983856201172, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007827281951904297, 'bn1': 0.00019121170043945312, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011472702026367188, 'bn2': 0.0001938343048095703, 'conv3': 0.00035834312438964844, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011491775512695312, 'bn1': 0.00019550323486328125, 'relu1': 9.5367431640625e-05, 'conv2': 0.001142740249633789, 'bn2': 0.0001888275146484375, 'residual_add_relu2': 0.00020313262939453125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006508827209472656, 'bn1': 0.0001373291015625, 'relu1': 6.29425048828125e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00011396408081054688, 'conv3': 0.00029087066650390625, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.001140594482421875, 'bn1': 0.0001246929168701172, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011415481567382812, 'bn2': 0.00012159347534179688, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 131\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016396045684814453, 'bn1': 0.0005526542663574219, 'relu1': 0.0003249645233154297, 'conv2': 0.0016252994537353516, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016243457794189453, 'bn1': 0.0005402565002441406, 'relu1': 0.0003218650817871094, 'conv2': 0.0016188621520996094, 'bn2': 0.0005528926849365234, 'residual_add_relu2': 0.0007669925689697266}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010437965393066406, 'bn1': 0.0003159046173095703, 'relu1': 0.0001728534698486328, 'conv2': 0.0013012886047363281, 'bn2': 0.0003082752227783203, 'conv3': 0.0003986358642578125, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013048648834228516, 'bn1': 0.00031375885009765625, 'relu1': 0.00017309188842773438, 'conv2': 0.001299142837524414, 'bn2': 0.0003075599670410156, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007851123809814453, 'bn1': 0.0002002716064453125, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.000194549560546875, 'conv3': 0.00035071372985839844, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011515617370605469, 'bn1': 0.00020813941955566406, 'relu1': 0.00010156631469726562, 'conv2': 0.0011518001556396484, 'bn2': 0.00019669532775878906, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006566047668457031, 'bn1': 0.00011992454528808594, 'relu1': 5.984306335449219e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00011849403381347656, 'conv3': 0.0002944469451904297, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011408329010009766, 'bn1': 0.00011920928955078125, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011365413665771484, 'bn2': 0.00011277198791503906, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 132\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016412734985351562, 'bn1': 0.0005519390106201172, 'relu1': 0.00032401084899902344, 'conv2': 0.001621246337890625, 'bn2': 0.0005428791046142578, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016260147094726562, 'bn1': 0.000545501708984375, 'relu1': 0.0003235340118408203, 'conv2': 0.0016226768493652344, 'bn2': 0.0005388259887695312, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001047372817993164, 'bn1': 0.0003101825714111328, 'relu1': 0.00017118453979492188, 'conv2': 0.0012996196746826172, 'bn2': 0.0003075599670410156, 'conv3': 0.00039768218994140625, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013115406036376953, 'bn1': 0.0003097057342529297, 'relu1': 0.0001728534698486328, 'conv2': 0.0013003349304199219, 'bn2': 0.0003097057342529297, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007853507995605469, 'bn1': 0.00019979476928710938, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00019478797912597656, 'conv3': 0.0003533363342285156, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011515617370605469, 'bn1': 0.00020122528076171875, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.0001933574676513672, 'residual_add_relu2': 0.00020575523376464844}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006551742553710938, 'bn1': 0.00012135505676269531, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011425018310546875, 'bn2': 0.000141143798828125, 'conv3': 0.0002961158752441406, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.0011415481567382812, 'bn1': 0.00012183189392089844, 'relu1': 5.8650970458984375e-05, 'conv2': 0.001132965087890625, 'bn2': 0.00010800361633300781, 'residual_add_relu2': 0.0001087188720703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 133\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001651763916015625, 'bn1': 0.0005505084991455078, 'relu1': 0.00032138824462890625, 'conv2': 0.0016336441040039062, 'bn2': 0.0005357265472412109, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016367435455322266, 'bn1': 0.0005476474761962891, 'relu1': 0.00032448768615722656, 'conv2': 0.0016214847564697266, 'bn2': 0.0005383491516113281, 'residual_add_relu2': 0.000766754150390625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010449886322021484, 'bn1': 0.00032520294189453125, 'relu1': 0.00017452239990234375, 'conv2': 0.001302957534790039, 'bn2': 0.0003085136413574219, 'conv3': 0.0003993511199951172, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013012886047363281, 'bn1': 0.0003180503845214844, 'relu1': 0.0001742839813232422, 'conv2': 0.0013017654418945312, 'bn2': 0.000316619873046875, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007889270782470703, 'bn1': 0.0002372264862060547, 'relu1': 0.0001068115234375, 'conv2': 0.001154184341430664, 'bn2': 0.00019788742065429688, 'conv3': 0.00035262107849121094, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011506080627441406, 'bn1': 0.00021529197692871094, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00019884109497070312, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006570816040039062, 'bn1': 0.00012111663818359375, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011391639709472656, 'bn2': 0.00011396408081054688, 'conv3': 0.0002932548522949219, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011425018310546875, 'bn1': 0.000125885009765625, 'relu1': 5.817413330078125e-05, 'conv2': 0.00113677978515625, 'bn2': 0.00011610984802246094, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 134\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001668691635131836, 'bn1': 0.0005662441253662109, 'relu1': 0.0003273487091064453, 'conv2': 0.0016295909881591797, 'bn2': 0.0005483627319335938, 'residual_add_relu2': 0.0007722377777099609}\n",
      "{'conv1': 0.0016331672668457031, 'bn1': 0.000553131103515625, 'relu1': 0.0003266334533691406, 'conv2': 0.0016291141510009766, 'bn2': 0.0005447864532470703, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001051187515258789, 'bn1': 0.00032401084899902344, 'relu1': 0.00017571449279785156, 'conv2': 0.0013093948364257812, 'bn2': 0.00031685829162597656, 'conv3': 0.00041031837463378906, 'residual_add_relu2': 0.000392913818359375}\n",
      "{'conv1': 0.0013096332550048828, 'bn1': 0.0003211498260498047, 'relu1': 0.0001761913299560547, 'conv2': 0.00130462646484375, 'bn2': 0.0003154277801513672, 'residual_add_relu2': 0.00039267539978027344}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007905960083007812, 'bn1': 0.00020766258239746094, 'relu1': 0.00010228157043457031, 'conv2': 0.0011570453643798828, 'bn2': 0.00020456314086914062, 'conv3': 0.0003581047058105469, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011556148529052734, 'bn1': 0.00020885467529296875, 'relu1': 0.00010132789611816406, 'conv2': 0.00115203857421875, 'bn2': 0.00020241737365722656, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006964206695556641, 'bn1': 0.0001342296600341797, 'relu1': 6.270408630371094e-05, 'conv2': 0.001146554946899414, 'bn2': 0.0001266002655029297, 'conv3': 0.0003006458282470703, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.0011546611785888672, 'bn1': 0.0001285076141357422, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011394023895263672, 'bn2': 0.00011610984802246094, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 135\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016567707061767578, 'bn1': 0.0005595684051513672, 'relu1': 0.0003273487091064453, 'conv2': 0.0016281604766845703, 'bn2': 0.0005466938018798828, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016350746154785156, 'bn1': 0.0005424022674560547, 'relu1': 0.0003211498260498047, 'conv2': 0.0016205310821533203, 'bn2': 0.0005383491516113281, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010521411895751953, 'bn1': 0.0003199577331542969, 'relu1': 0.0001723766326904297, 'conv2': 0.001302480697631836, 'bn2': 0.00031495094299316406, 'conv3': 0.0004062652587890625, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.001308441162109375, 'bn1': 0.0003299713134765625, 'relu1': 0.00017881393432617188, 'conv2': 0.0013756752014160156, 'bn2': 0.0003299713134765625, 'residual_add_relu2': 0.0003936290740966797}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007951259613037109, 'bn1': 0.0002148151397705078, 'relu1': 0.00010323524475097656, 'conv2': 0.0011584758758544922, 'bn2': 0.00020074844360351562, 'conv3': 0.0003581047058105469, 'residual_add_relu2': 0.00020766258239746094}\n",
      "{'conv1': 0.0011622905731201172, 'bn1': 0.00020313262939453125, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.0002155303955078125, 'residual_add_relu2': 0.00020813941955566406}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006694793701171875, 'bn1': 0.00014138221740722656, 'relu1': 6.246566772460938e-05, 'conv2': 0.001149892807006836, 'bn2': 0.00012683868408203125, 'conv3': 0.00030517578125, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.0011496543884277344, 'bn1': 0.0001347064971923828, 'relu1': 6.413459777832031e-05, 'conv2': 0.0011458396911621094, 'bn2': 0.00012636184692382812, 'residual_add_relu2': 0.00011205673217773438}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 136\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016582012176513672, 'bn1': 0.0005660057067871094, 'relu1': 0.00032711029052734375, 'conv2': 0.001630544662475586, 'bn2': 0.0005483627319335938, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.001627206802368164, 'bn1': 0.0005528926849365234, 'relu1': 0.000324249267578125, 'conv2': 0.0016407966613769531, 'bn2': 0.0005421638488769531, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010459423065185547, 'bn1': 0.00031447410583496094, 'relu1': 0.00017309188842773438, 'conv2': 0.001302957534790039, 'bn2': 0.00031375885009765625, 'conv3': 0.00040149688720703125, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013036727905273438, 'bn1': 0.0003120899200439453, 'relu1': 0.0001723766326904297, 'conv2': 0.0013282299041748047, 'bn2': 0.00043392181396484375, 'residual_add_relu2': 0.0004031658172607422}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008103847503662109, 'bn1': 0.0002186298370361328, 'relu1': 0.0001068115234375, 'conv2': 0.0011665821075439453, 'bn2': 0.00021028518676757812, 'conv3': 0.0003647804260253906, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.001157999038696289, 'bn1': 0.00021123886108398438, 'relu1': 0.00010538101196289062, 'conv2': 0.0011534690856933594, 'bn2': 0.0002086162567138672, 'residual_add_relu2': 0.00020766258239746094}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006625652313232422, 'bn1': 0.00013136863708496094, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011446475982666016, 'bn2': 0.0001399517059326172, 'conv3': 0.0003037452697753906, 'residual_add_relu2': 0.00011539459228515625}\n",
      "{'conv1': 0.0011494159698486328, 'bn1': 0.00017881393432617188, 'relu1': 7.128715515136719e-05, 'conv2': 0.001148223876953125, 'bn2': 0.00013446807861328125, 'residual_add_relu2': 0.00011181831359863281}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 137\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016407966613769531, 'bn1': 0.0005583763122558594, 'relu1': 0.0003249645233154297, 'conv2': 0.0016362667083740234, 'bn2': 0.0005619525909423828, 'residual_add_relu2': 0.0007698535919189453}\n",
      "{'conv1': 0.0016388893127441406, 'bn1': 0.0005447864532470703, 'relu1': 0.0003247261047363281, 'conv2': 0.0016269683837890625, 'bn2': 0.0005509853363037109, 'residual_add_relu2': 0.0007655620574951172}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010519027709960938, 'bn1': 0.00032329559326171875, 'relu1': 0.00017547607421875, 'conv2': 0.0013129711151123047, 'bn2': 0.0003285408020019531, 'conv3': 0.0004096031188964844, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013031959533691406, 'bn1': 0.0003209114074707031, 'relu1': 0.00017523765563964844, 'conv2': 0.0013020038604736328, 'bn2': 0.0003094673156738281, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007855892181396484, 'bn1': 0.00021767616271972656, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00019693374633789062, 'conv3': 0.0003535747528076172, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011506080627441406, 'bn1': 0.00020003318786621094, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.00020456314086914062, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006585121154785156, 'bn1': 0.00012302398681640625, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011410713195800781, 'bn2': 0.00011396408081054688, 'conv3': 0.00029158592224121094, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011420249938964844, 'bn1': 0.00012302398681640625, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011374950408935547, 'bn2': 0.00012493133544921875, 'residual_add_relu2': 0.00011229515075683594}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 138\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016710758209228516, 'bn1': 0.0005719661712646484, 'relu1': 0.0003275871276855469, 'conv2': 0.0016362667083740234, 'bn2': 0.0005552768707275391, 'residual_add_relu2': 0.0007684230804443359}\n",
      "{'conv1': 0.0016341209411621094, 'bn1': 0.000553131103515625, 'relu1': 0.0003273487091064453, 'conv2': 0.0016269683837890625, 'bn2': 0.0005545616149902344, 'residual_add_relu2': 0.0007739067077636719}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010488033294677734, 'bn1': 0.0003228187561035156, 'relu1': 0.00017380714416503906, 'conv2': 0.0013055801391601562, 'bn2': 0.00032329559326171875, 'conv3': 0.0004096031188964844, 'residual_add_relu2': 0.0003921985626220703}\n",
      "{'conv1': 0.0013079643249511719, 'bn1': 0.0003161430358886719, 'relu1': 0.00017452239990234375, 'conv2': 0.001300811767578125, 'bn2': 0.000316619873046875, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007939338684082031, 'bn1': 0.0002117156982421875, 'relu1': 0.00010085105895996094, 'conv2': 0.001153707504272461, 'bn2': 0.00020742416381835938, 'conv3': 0.0003604888916015625, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0011525154113769531, 'bn1': 0.00020432472229003906, 'relu1': 9.846687316894531e-05, 'conv2': 0.001148223876953125, 'bn2': 0.00019860267639160156, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006577968597412109, 'bn1': 0.00012683868408203125, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011432170867919922, 'bn2': 0.0001304149627685547, 'conv3': 0.00029969215393066406, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.001142263412475586, 'bn1': 0.00012493133544921875, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011382102966308594, 'bn2': 0.0001232624053955078, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 139\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016384124755859375, 'bn1': 0.0005645751953125, 'relu1': 0.00032711029052734375, 'conv2': 0.0016393661499023438, 'bn2': 0.0005500316619873047, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016298294067382812, 'bn1': 0.0005655288696289062, 'relu1': 0.00032901763916015625, 'conv2': 0.001626729965209961, 'bn2': 0.0005512237548828125, 'residual_add_relu2': 0.0007658004760742188}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010509490966796875, 'bn1': 0.00033354759216308594, 'relu1': 0.0001766681671142578, 'conv2': 0.0013074874877929688, 'bn2': 0.0003306865692138672, 'conv3': 0.0004050731658935547, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013086795806884766, 'bn1': 0.0003342628479003906, 'relu1': 0.00017833709716796875, 'conv2': 0.0013089179992675781, 'bn2': 0.00032711029052734375, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007879734039306641, 'bn1': 0.00020170211791992188, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00021266937255859375, 'conv3': 0.0003609657287597656, 'residual_add_relu2': 0.00020742416381835938}\n",
      "{'conv1': 0.0011599063873291016, 'bn1': 0.00021219253540039062, 'relu1': 0.00010228157043457031, 'conv2': 0.0011534690856933594, 'bn2': 0.0002110004425048828, 'residual_add_relu2': 0.00020647048950195312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006632804870605469, 'bn1': 0.00014257431030273438, 'relu1': 6.341934204101562e-05, 'conv2': 0.0011491775512695312, 'bn2': 0.00013780593872070312, 'conv3': 0.0003046989440917969, 'residual_add_relu2': 0.00011372566223144531}\n",
      "{'conv1': 0.0011513233184814453, 'bn1': 0.00013875961303710938, 'relu1': 7.510185241699219e-05, 'conv2': 0.001150369644165039, 'bn2': 0.00013375282287597656, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 140\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016541481018066406, 'bn1': 0.0005593299865722656, 'relu1': 0.0003266334533691406, 'conv2': 0.0016319751739501953, 'bn2': 0.0005927085876464844, 'residual_add_relu2': 0.0007696151733398438}\n",
      "{'conv1': 0.0016252994537353516, 'bn1': 0.0005486011505126953, 'relu1': 0.0003287792205810547, 'conv2': 0.0016295909881591797, 'bn2': 0.000545501708984375, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010445117950439453, 'bn1': 0.0003094673156738281, 'relu1': 0.00017452239990234375, 'conv2': 0.0013053417205810547, 'bn2': 0.0003108978271484375, 'conv3': 0.0004017353057861328, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013022422790527344, 'bn1': 0.00030922889709472656, 'relu1': 0.00017380714416503906, 'conv2': 0.0012984275817871094, 'bn2': 0.0003063678741455078, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007843971252441406, 'bn1': 0.00019788742065429688, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011458396911621094, 'bn2': 0.00019311904907226562, 'conv3': 0.0003521442413330078, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011487007141113281, 'bn1': 0.00019860267639160156, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.00018668174743652344, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006537437438964844, 'bn1': 0.00011920928955078125, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011396408081054688, 'bn2': 0.00011157989501953125, 'conv3': 0.0002911090850830078, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011372566223144531, 'bn1': 0.00017976760864257812, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011360645294189453, 'bn2': 0.00011181831359863281, 'residual_add_relu2': 0.0001087188720703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 141\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016455650329589844, 'bn1': 0.0005586147308349609, 'relu1': 0.0003247261047363281, 'conv2': 0.0016307830810546875, 'bn2': 0.0005407333374023438, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016329288482666016, 'bn1': 0.0005359649658203125, 'relu1': 0.0003223419189453125, 'conv2': 0.0016238689422607422, 'bn2': 0.0005550384521484375, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010416507720947266, 'bn1': 0.00030684471130371094, 'relu1': 0.00016999244689941406, 'conv2': 0.0012981891632080078, 'bn2': 0.0003037452697753906, 'conv3': 0.00039577484130859375, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013053417205810547, 'bn1': 0.000316619873046875, 'relu1': 0.00017380714416503906, 'conv2': 0.0013022422790527344, 'bn2': 0.00031113624572753906, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.00078582763671875, 'bn1': 0.0002002716064453125, 'relu1': 0.00010347366333007812, 'conv2': 0.0011551380157470703, 'bn2': 0.0002002716064453125, 'conv3': 0.0003540515899658203, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011544227600097656, 'bn1': 0.00019311904907226562, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.00019621849060058594, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006647109985351562, 'bn1': 0.00011610984802246094, 'relu1': 5.745887756347656e-05, 'conv2': 0.00113677978515625, 'bn2': 0.00010752677917480469, 'conv3': 0.00028777122497558594, 'residual_add_relu2': 0.00010895729064941406}\n",
      "{'conv1': 0.001138925552368164, 'bn1': 0.00011420249938964844, 'relu1': 5.698204040527344e-05, 'conv2': 0.0011339187622070312, 'bn2': 0.00011563301086425781, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 142\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001674652099609375, 'bn1': 0.0005731582641601562, 'relu1': 0.00032806396484375, 'conv2': 0.0016317367553710938, 'bn2': 0.000560760498046875, 'residual_add_relu2': 0.00077056884765625}\n",
      "{'conv1': 0.0016374588012695312, 'bn1': 0.0005624294281005859, 'relu1': 0.00032591819763183594, 'conv2': 0.0016293525695800781, 'bn2': 0.0005509853363037109, 'residual_add_relu2': 0.000766754150390625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010540485382080078, 'bn1': 0.0003256797790527344, 'relu1': 0.0001766681671142578, 'conv2': 0.0013089179992675781, 'bn2': 0.00033211708068847656, 'conv3': 0.00040984153747558594, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013048648834228516, 'bn1': 0.00031566619873046875, 'relu1': 0.00017547607421875, 'conv2': 0.0013031959533691406, 'bn2': 0.00032210350036621094, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007915496826171875, 'bn1': 0.000209808349609375, 'relu1': 0.00010132789611816406, 'conv2': 0.0011563301086425781, 'bn2': 0.00020742416381835938, 'conv3': 0.0003592967987060547, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011568069458007812, 'bn1': 0.0002155303955078125, 'relu1': 0.00010204315185546875, 'conv2': 0.001153707504272461, 'bn2': 0.000213623046875, 'residual_add_relu2': 0.0002079010009765625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006740093231201172, 'bn1': 0.0001366138458251953, 'relu1': 6.270408630371094e-05, 'conv2': 0.0011463165283203125, 'bn2': 0.0001270771026611328, 'conv3': 0.0003006458282470703, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.0011560916900634766, 'bn1': 0.0001373291015625, 'relu1': 6.318092346191406e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.0001285076141357422, 'residual_add_relu2': 0.00011229515075683594}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 143\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001650094985961914, 'bn1': 0.0005657672882080078, 'relu1': 0.0003237724304199219, 'conv2': 0.0016396045684814453, 'bn2': 0.0005731582641601562, 'residual_add_relu2': 0.0007677078247070312}\n",
      "{'conv1': 0.0016391277313232422, 'bn1': 0.0005478858947753906, 'relu1': 0.00032258033752441406, 'conv2': 0.0016355514526367188, 'bn2': 0.0005366802215576172, 'residual_add_relu2': 0.0007681846618652344}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010478496551513672, 'bn1': 0.0003185272216796875, 'relu1': 0.00017261505126953125, 'conv2': 0.001310110092163086, 'bn2': 0.0003123283386230469, 'conv3': 0.00040268898010253906, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013065338134765625, 'bn1': 0.0003170967102050781, 'relu1': 0.00017380714416503906, 'conv2': 0.0013010501861572266, 'bn2': 0.0003204345703125, 'residual_add_relu2': 0.00039267539978027344}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007965564727783203, 'bn1': 0.00021982192993164062, 'relu1': 0.00010180473327636719, 'conv2': 0.0011568069458007812, 'bn2': 0.00020456314086914062, 'conv3': 0.00035762786865234375, 'residual_add_relu2': 0.0002079010009765625}\n",
      "{'conv1': 0.0011563301086425781, 'bn1': 0.00021219253540039062, 'relu1': 0.0001010894775390625, 'conv2': 0.00115203857421875, 'bn2': 0.00020384788513183594, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006585121154785156, 'bn1': 0.00012087821960449219, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011432170867919922, 'bn2': 0.00014543533325195312, 'conv3': 0.00029921531677246094, 'residual_add_relu2': 0.00011372566223144531}\n",
      "{'conv1': 0.0011491775512695312, 'bn1': 0.00013947486877441406, 'relu1': 6.198883056640625e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.00012493133544921875, 'residual_add_relu2': 0.00011301040649414062}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 144\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016493797302246094, 'bn1': 0.0005571842193603516, 'relu1': 0.0003254413604736328, 'conv2': 0.0016300678253173828, 'bn2': 0.0005440711975097656, 'residual_add_relu2': 0.0007643699645996094}\n",
      "{'conv1': 0.0016341209411621094, 'bn1': 0.0005457401275634766, 'relu1': 0.0003218650817871094, 'conv2': 0.0016362667083740234, 'bn2': 0.0005342960357666016, 'residual_add_relu2': 0.0007598400115966797}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010371208190917969, 'bn1': 0.0003142356872558594, 'relu1': 0.00017118453979492188, 'conv2': 0.0013012886047363281, 'bn2': 0.0003101825714111328, 'conv3': 0.00039839744567871094, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013020038604736328, 'bn1': 0.00033092498779296875, 'relu1': 0.00017547607421875, 'conv2': 0.001302480697631836, 'bn2': 0.0003108978271484375, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007932186126708984, 'bn1': 0.00020051002502441406, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00019216537475585938, 'conv3': 0.00035262107849121094, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011489391326904297, 'bn1': 0.00020742416381835938, 'relu1': 9.918212890625e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00019788742065429688, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006558895111083984, 'bn1': 0.0001220703125, 'relu1': 5.984306335449219e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00012373924255371094, 'conv3': 0.00029277801513671875, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011441707611083984, 'bn1': 0.00015878677368164062, 'relu1': 6.222724914550781e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00012493133544921875, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 145\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016660690307617188, 'bn1': 0.0005605220794677734, 'relu1': 0.0003249645233154297, 'conv2': 0.0016336441040039062, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016357898712158203, 'bn1': 0.0005483627319335938, 'relu1': 0.00032401084899902344, 'conv2': 0.0016291141510009766, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010459423065185547, 'bn1': 0.0003192424774169922, 'relu1': 0.00017333030700683594, 'conv2': 0.0013034343719482422, 'bn2': 0.000308990478515625, 'conv3': 0.00039887428283691406, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.0013020038604736328, 'bn1': 0.00031495094299316406, 'relu1': 0.0001747608184814453, 'conv2': 0.0013005733489990234, 'bn2': 0.0003075599670410156, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007851123809814453, 'bn1': 0.0001926422119140625, 'relu1': 0.00010561943054199219, 'conv2': 0.0011494159698486328, 'bn2': 0.00018906593322753906, 'conv3': 0.00034999847412109375, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011534690856933594, 'bn1': 0.000202178955078125, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.0002071857452392578, 'residual_add_relu2': 0.00020623207092285156}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006585121154785156, 'bn1': 0.00012445449829101562, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011408329010009766, 'bn2': 0.00011610984802246094, 'conv3': 0.0002951622009277344, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011432170867919922, 'bn1': 0.00012350082397460938, 'relu1': 5.91278076171875e-05, 'conv2': 0.00113677978515625, 'bn2': 0.00011515617370605469, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 146\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016469955444335938, 'bn1': 0.0005466938018798828, 'relu1': 0.0003223419189453125, 'conv2': 0.0016176700592041016, 'bn2': 0.0005354881286621094, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.001631021499633789, 'bn1': 0.000553131103515625, 'relu1': 0.0003249645233154297, 'conv2': 0.0016224384307861328, 'bn2': 0.0005404949188232422, 'residual_add_relu2': 0.0007653236389160156}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010457038879394531, 'bn1': 0.00031948089599609375, 'relu1': 0.00017309188842773438, 'conv2': 0.0012981891632080078, 'bn2': 0.00030159950256347656, 'conv3': 0.0003952980041503906, 'residual_add_relu2': 0.0008394718170166016}\n",
      "{'conv1': 0.0013539791107177734, 'bn1': 0.00034880638122558594, 'relu1': 0.00018334388732910156, 'conv2': 0.001318216323852539, 'bn2': 0.0003237724304199219, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007905960083007812, 'bn1': 0.00020694732666015625, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00019073486328125, 'conv3': 0.00035262107849121094, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011553764343261719, 'bn1': 0.00022125244140625, 'relu1': 0.0001010894775390625, 'conv2': 0.0011577606201171875, 'bn2': 0.00020599365234375, 'residual_add_relu2': 0.00020623207092285156}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006642341613769531, 'bn1': 0.00013589859008789062, 'relu1': 6.270408630371094e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00013566017150878906, 'conv3': 0.00030112266540527344, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.0011489391326904297, 'bn1': 0.00013375282287597656, 'relu1': 6.413459777832031e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.0001366138458251953, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 147\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016469955444335938, 'bn1': 0.0005588531494140625, 'relu1': 0.0003261566162109375, 'conv2': 0.0016312599182128906, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016393661499023438, 'bn1': 0.0005524158477783203, 'relu1': 0.0003249645233154297, 'conv2': 0.0016224384307861328, 'bn2': 0.0005407333374023438, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010488033294677734, 'bn1': 0.0003349781036376953, 'relu1': 0.00017452239990234375, 'conv2': 0.0013077259063720703, 'bn2': 0.0003154277801513672, 'conv3': 0.0004050731658935547, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013034343719482422, 'bn1': 0.00031256675720214844, 'relu1': 0.000171661376953125, 'conv2': 0.0012979507446289062, 'bn2': 0.0003037452697753906, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007810592651367188, 'bn1': 0.0001895427703857422, 'relu1': 9.5367431640625e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00022292137145996094, 'conv3': 0.00035262107849121094, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011475086212158203, 'bn1': 0.00022840499877929688, 'relu1': 9.846687316894531e-05, 'conv2': 0.001149892807006836, 'bn2': 0.0001971721649169922, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006575584411621094, 'bn1': 0.00012445449829101562, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011403560638427734, 'bn2': 0.00011491775512695312, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011425018310546875, 'bn1': 0.00012159347534179688, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011386871337890625, 'bn2': 0.00011801719665527344, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 148\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016520023345947266, 'bn1': 0.0005745887756347656, 'relu1': 0.00033283233642578125, 'conv2': 0.0016360282897949219, 'bn2': 0.0005528926849365234, 'residual_add_relu2': 0.0007712841033935547}\n",
      "{'conv1': 0.0016434192657470703, 'bn1': 0.0005509853363037109, 'relu1': 0.00033020973205566406, 'conv2': 0.0016281604766845703, 'bn2': 0.0005488395690917969, 'residual_add_relu2': 0.0007760524749755859}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010514259338378906, 'bn1': 0.00032830238342285156, 'relu1': 0.00018143653869628906, 'conv2': 0.0013196468353271484, 'bn2': 0.00031495094299316406, 'conv3': 0.0004134178161621094, 'residual_add_relu2': 0.0003921985626220703}\n",
      "{'conv1': 0.0013098716735839844, 'bn1': 0.00032258033752441406, 'relu1': 0.00017833709716796875, 'conv2': 0.0013074874877929688, 'bn2': 0.00030803680419921875, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007860660552978516, 'bn1': 0.0002009868621826172, 'relu1': 0.00011372566223144531, 'conv2': 0.001157999038696289, 'bn2': 0.0002052783966064453, 'conv3': 0.0003566741943359375, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.0011518001556396484, 'bn1': 0.0002028942108154297, 'relu1': 9.799003601074219e-05, 'conv2': 0.001146078109741211, 'bn2': 0.000202178955078125, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006570816040039062, 'bn1': 0.00012683868408203125, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.00011730194091796875, 'conv3': 0.00029397010803222656, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.001142740249633789, 'bn1': 0.00013494491577148438, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011394023895263672, 'bn2': 0.00012087821960449219, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 149\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.00164031982421875, 'bn1': 0.0005571842193603516, 'relu1': 0.0003228187561035156, 'conv2': 0.0016219615936279297, 'bn2': 0.0005300045013427734, 'residual_add_relu2': 0.0007710456848144531}\n",
      "{'conv1': 0.0016214847564697266, 'bn1': 0.0005362033843994141, 'relu1': 0.00031948089599609375, 'conv2': 0.0016231536865234375, 'bn2': 0.0005395412445068359, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010418891906738281, 'bn1': 0.0003116130828857422, 'relu1': 0.0001709461212158203, 'conv2': 0.0012989044189453125, 'bn2': 0.00030517578125, 'conv3': 0.00039577484130859375, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0012974739074707031, 'bn1': 0.00030541419982910156, 'relu1': 0.00021338462829589844, 'conv2': 0.0013015270233154297, 'bn2': 0.0003039836883544922, 'residual_add_relu2': 0.00038886070251464844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007812976837158203, 'bn1': 0.0001971721649169922, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011491775512695312, 'bn2': 0.0001971721649169922, 'conv3': 0.0003533363342285156, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011487007141113281, 'bn1': 0.0001933574676513672, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011444091796875, 'bn2': 0.0001881122589111328, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006582736968994141, 'bn1': 0.00011515617370605469, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011365413665771484, 'bn2': 0.00010585784912109375, 'conv3': 0.0002868175506591797, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.0011377334594726562, 'bn1': 0.00011396408081054688, 'relu1': 5.626678466796875e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.00011730194091796875, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 150\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016617774963378906, 'bn1': 0.00057220458984375, 'relu1': 0.00032830238342285156, 'conv2': 0.0016314983367919922, 'bn2': 0.0005588531494140625, 'residual_add_relu2': 0.0007715225219726562}\n",
      "{'conv1': 0.0016314983367919922, 'bn1': 0.000560760498046875, 'relu1': 0.0003273487091064453, 'conv2': 0.0016391277313232422, 'bn2': 0.0005524158477783203, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010480880737304688, 'bn1': 0.0003254413604736328, 'relu1': 0.0001761913299560547, 'conv2': 0.001310586929321289, 'bn2': 0.00032067298889160156, 'conv3': 0.0004067420959472656, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.001310586929321289, 'bn1': 0.0003349781036376953, 'relu1': 0.00017642974853515625, 'conv2': 0.0013055801391601562, 'bn2': 0.0003123283386230469, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007867813110351562, 'bn1': 0.0002028942108154297, 'relu1': 0.00012946128845214844, 'conv2': 0.0011572837829589844, 'bn2': 0.00019979476928710938, 'conv3': 0.00035643577575683594, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011518001556396484, 'bn1': 0.0002002716064453125, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.00019979476928710938, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006654262542724609, 'bn1': 0.00012636184692382812, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011446475982666016, 'bn2': 0.00012612342834472656, 'conv3': 0.0002930164337158203, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011601448059082031, 'bn1': 0.00012946128845214844, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011408329010009766, 'bn2': 0.00011777877807617188, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 151\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016374588012695312, 'bn1': 0.0005557537078857422, 'relu1': 0.00032401084899902344, 'conv2': 0.0016226768493652344, 'bn2': 0.0005397796630859375, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016269683837890625, 'bn1': 0.0005564689636230469, 'relu1': 0.00032329559326171875, 'conv2': 0.0016252994537353516, 'bn2': 0.0005583763122558594, 'residual_add_relu2': 0.0007662773132324219}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010442733764648438, 'bn1': 0.0003154277801513672, 'relu1': 0.0001742839813232422, 'conv2': 0.0013036727905273438, 'bn2': 0.00030875205993652344, 'conv3': 0.00039839744567871094, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013058185577392578, 'bn1': 0.0003154277801513672, 'relu1': 0.00017213821411132812, 'conv2': 0.0012972354888916016, 'bn2': 0.0003018379211425781, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007808208465576172, 'bn1': 0.00019240379333496094, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.00019502639770507812, 'conv3': 0.00035071372985839844, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011510848999023438, 'bn1': 0.00020742416381835938, 'relu1': 9.989738464355469e-05, 'conv2': 0.0011513233184814453, 'bn2': 0.00020194053649902344, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006740093231201172, 'bn1': 0.00012755393981933594, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011410713195800781, 'bn2': 0.00011563301086425781, 'conv3': 0.0002942085266113281, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011458396911621094, 'bn1': 0.00012874603271484375, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011432170867919922, 'bn2': 0.00011587142944335938, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 152\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001653432846069336, 'bn1': 0.0005602836608886719, 'relu1': 0.0003256797790527344, 'conv2': 0.0016350746154785156, 'bn2': 0.0005457401275634766, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016329288482666016, 'bn1': 0.0005443096160888672, 'relu1': 0.00032448768615722656, 'conv2': 0.0016291141510009766, 'bn2': 0.0005490779876708984, 'residual_add_relu2': 0.0007643699645996094}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010514259338378906, 'bn1': 0.0003180503845214844, 'relu1': 0.00017333030700683594, 'conv2': 0.0013175010681152344, 'bn2': 0.0003368854522705078, 'conv3': 0.0004093647003173828, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013113021850585938, 'bn1': 0.0003159046173095703, 'relu1': 0.0001723766326904297, 'conv2': 0.0012998580932617188, 'bn2': 0.00031065940856933594, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007891654968261719, 'bn1': 0.00020003318786621094, 'relu1': 0.00010275840759277344, 'conv2': 0.0011529922485351562, 'bn2': 0.00020503997802734375, 'conv3': 0.0003540515899658203, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.0011556148529052734, 'bn1': 0.00020766258239746094, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011491775512695312, 'bn2': 0.00019860267639160156, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006558895111083984, 'bn1': 0.00011944770812988281, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011377334594726562, 'bn2': 0.00010991096496582031, 'conv3': 0.00028634071350097656, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011396408081054688, 'bn1': 0.00011396408081054688, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011324882507324219, 'bn2': 0.00011515617370605469, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 153\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016396045684814453, 'bn1': 0.0005471706390380859, 'relu1': 0.0003228187561035156, 'conv2': 0.0016169548034667969, 'bn2': 0.0005345344543457031, 'residual_add_relu2': 0.0007646083831787109}\n",
      "{'conv1': 0.00162506103515625, 'bn1': 0.0005352497100830078, 'relu1': 0.0003211498260498047, 'conv2': 0.0016162395477294922, 'bn2': 0.0005407333374023438, 'residual_add_relu2': 0.0007672309875488281}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010476112365722656, 'bn1': 0.0003170967102050781, 'relu1': 0.0001728534698486328, 'conv2': 0.0013010501861572266, 'bn2': 0.0003046989440917969, 'conv3': 0.0003962516784667969, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013031959533691406, 'bn1': 0.00030922889709472656, 'relu1': 0.00017380714416503906, 'conv2': 0.001295328140258789, 'bn2': 0.0003008842468261719, 'residual_add_relu2': 0.0003886222839355469}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007822513580322266, 'bn1': 0.00019884109497070312, 'relu1': 9.608268737792969e-05, 'conv2': 0.001146554946899414, 'bn2': 0.00019311904907226562, 'conv3': 0.0003514289855957031, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.0011544227600097656, 'bn1': 0.00020194053649902344, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.00019311904907226562, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006573200225830078, 'bn1': 0.00013709068298339844, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011420249938964844, 'bn2': 0.00011944770812988281, 'conv3': 0.00029540061950683594, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011420249938964844, 'bn1': 0.00012135505676269531, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011370182037353516, 'bn2': 0.00012755393981933594, 'residual_add_relu2': 0.00011205673217773438}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 154\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001644134521484375, 'bn1': 0.0005545616149902344, 'relu1': 0.0003249645233154297, 'conv2': 0.00162506103515625, 'bn2': 0.0005404949188232422, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.0016276836395263672, 'bn1': 0.0005452632904052734, 'relu1': 0.0003249645233154297, 'conv2': 0.0016186237335205078, 'bn2': 0.0005340576171875, 'residual_add_relu2': 0.0007615089416503906}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010395050048828125, 'bn1': 0.0003032684326171875, 'relu1': 0.000171661376953125, 'conv2': 0.0012967586517333984, 'bn2': 0.000301361083984375, 'conv3': 0.0003955364227294922, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0012996196746826172, 'bn1': 0.0003101825714111328, 'relu1': 0.00017380714416503906, 'conv2': 0.0013098716735839844, 'bn2': 0.00031375885009765625, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007839202880859375, 'bn1': 0.0001938343048095703, 'relu1': 9.751319885253906e-05, 'conv2': 0.0012135505676269531, 'bn2': 0.00020265579223632812, 'conv3': 0.00035381317138671875, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011515617370605469, 'bn1': 0.00019884109497070312, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00019550323486328125, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000659942626953125, 'bn1': 0.0001227855682373047, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.00013494491577148438, 'conv3': 0.0002999305725097656, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.001142740249633789, 'bn1': 0.00012755393981933594, 'relu1': 6.031990051269531e-05, 'conv2': 0.001138925552368164, 'bn2': 0.00011849403381347656, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 155\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016460418701171875, 'bn1': 0.0005564689636230469, 'relu1': 0.00032329559326171875, 'conv2': 0.0016245841979980469, 'bn2': 0.0005528926849365234, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.0016286373138427734, 'bn1': 0.0005450248718261719, 'relu1': 0.00032448768615722656, 'conv2': 0.001623392105102539, 'bn2': 0.0005407333374023438, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010428428649902344, 'bn1': 0.0003223419189453125, 'relu1': 0.00017404556274414062, 'conv2': 0.0013048648834228516, 'bn2': 0.0003256797790527344, 'conv3': 0.0004038810729980469, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013082027435302734, 'bn1': 0.0003185272216796875, 'relu1': 0.00017380714416503906, 'conv2': 0.001300811767578125, 'bn2': 0.00033545494079589844, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007867813110351562, 'bn1': 0.00020051002502441406, 'relu1': 9.942054748535156e-05, 'conv2': 0.00115203857421875, 'bn2': 0.00019884109497070312, 'conv3': 0.0003523826599121094, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011532306671142578, 'bn1': 0.00020122528076171875, 'relu1': 0.00010204315185546875, 'conv2': 0.0011532306671142578, 'bn2': 0.00021886825561523438, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006606578826904297, 'bn1': 0.00012087821960449219, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011413097381591797, 'bn2': 0.00010895729064941406, 'conv3': 0.0002880096435546875, 'residual_add_relu2': 0.00010943412780761719}\n",
      "{'conv1': 0.0011372566223144531, 'bn1': 0.00011491775512695312, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011336803436279297, 'bn2': 0.000110626220703125, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 156\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016362667083740234, 'bn1': 0.0005731582641601562, 'relu1': 0.00032639503479003906, 'conv2': 0.0016238689422607422, 'bn2': 0.0005474090576171875, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016298294067382812, 'bn1': 0.0005450248718261719, 'relu1': 0.0003228187561035156, 'conv2': 0.0016183853149414062, 'bn2': 0.0005357265472412109, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010457038879394531, 'bn1': 0.00032329559326171875, 'relu1': 0.00017380714416503906, 'conv2': 0.00130462646484375, 'bn2': 0.0003180503845214844, 'conv3': 0.00040149688720703125, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.001300811767578125, 'bn1': 0.00031280517578125, 'relu1': 0.00017309188842773438, 'conv2': 0.0013005733489990234, 'bn2': 0.0003104209899902344, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007843971252441406, 'bn1': 0.0001990795135498047, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.0002028942108154297, 'conv3': 0.0003540515899658203, 'residual_add_relu2': 0.0002071857452392578}\n",
      "{'conv1': 0.001157522201538086, 'bn1': 0.00020384788513183594, 'relu1': 9.751319885253906e-05, 'conv2': 0.001146078109741211, 'bn2': 0.00019073486328125, 'residual_add_relu2': 0.0002033710479736328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006539821624755859, 'bn1': 0.00014781951904296875, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011417865753173828, 'bn2': 0.00011229515075683594, 'conv3': 0.00028514862060546875, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.001140594482421875, 'bn1': 0.00012230873107910156, 'relu1': 5.8650970458984375e-05, 'conv2': 0.00113677978515625, 'bn2': 0.00012254714965820312, 'residual_add_relu2': 0.00011181831359863281}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 157\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016412734985351562, 'bn1': 0.0005736351013183594, 'relu1': 0.0003285408020019531, 'conv2': 0.0016460418701171875, 'bn2': 0.0005693435668945312, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.0016329288482666016, 'bn1': 0.0005517005920410156, 'relu1': 0.00032520294189453125, 'conv2': 0.0016322135925292969, 'bn2': 0.0005512237548828125, 'residual_add_relu2': 0.0007655620574951172}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010476112365722656, 'bn1': 0.0003101825714111328, 'relu1': 0.00017142295837402344, 'conv2': 0.0013015270233154297, 'bn2': 0.00031304359436035156, 'conv3': 0.00039958953857421875, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013113021850585938, 'bn1': 0.00031566619873046875, 'relu1': 0.00017380714416503906, 'conv2': 0.0013065338134765625, 'bn2': 0.0003197193145751953, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007901191711425781, 'bn1': 0.00021791458129882812, 'relu1': 0.00010180473327636719, 'conv2': 0.0011572837829589844, 'bn2': 0.00022149085998535156, 'conv3': 0.00036025047302246094, 'residual_add_relu2': 0.00020647048950195312}\n",
      "{'conv1': 0.0011565685272216797, 'bn1': 0.00021004676818847656, 'relu1': 0.0001010894775390625, 'conv2': 0.001153707504272461, 'bn2': 0.0002033710479736328, 'residual_add_relu2': 0.00020647048950195312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006697177886962891, 'bn1': 0.00013399124145507812, 'relu1': 6.29425048828125e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00014710426330566406, 'conv3': 0.0003020763397216797, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.0011472702026367188, 'bn1': 0.0001361370086669922, 'relu1': 6.246566772460938e-05, 'conv2': 0.0011446475982666016, 'bn2': 0.00015354156494140625, 'residual_add_relu2': 0.00011539459228515625}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 158\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.00167083740234375, 'bn1': 0.0005960464477539062, 'relu1': 0.0003292560577392578, 'conv2': 0.0016338825225830078, 'bn2': 0.0005650520324707031, 'residual_add_relu2': 0.0007703304290771484}\n",
      "{'conv1': 0.0016412734985351562, 'bn1': 0.0005664825439453125, 'relu1': 0.00032806396484375, 'conv2': 0.0016274452209472656, 'bn2': 0.0005388259887695312, 'residual_add_relu2': 0.0007684230804443359}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010542869567871094, 'bn1': 0.0003287792205810547, 'relu1': 0.00017642974853515625, 'conv2': 0.0013155937194824219, 'bn2': 0.0003218650817871094, 'conv3': 0.00041413307189941406, 'residual_add_relu2': 0.0003943443298339844}\n",
      "{'conv1': 0.0013117790222167969, 'bn1': 0.0003478527069091797, 'relu1': 0.00017952919006347656, 'conv2': 0.0013134479522705078, 'bn2': 0.0003204345703125, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007920265197753906, 'bn1': 0.00020742416381835938, 'relu1': 0.00010228157043457031, 'conv2': 0.0011589527130126953, 'bn2': 0.00020432472229003906, 'conv3': 0.0003604888916015625, 'residual_add_relu2': 0.0002067089080810547}\n",
      "{'conv1': 0.0011591911315917969, 'bn1': 0.00021767616271972656, 'relu1': 0.00010347366333007812, 'conv2': 0.001157522201538086, 'bn2': 0.00021314620971679688, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006699562072753906, 'bn1': 0.0001480579376220703, 'relu1': 6.365776062011719e-05, 'conv2': 0.001148223876953125, 'bn2': 0.00012683868408203125, 'conv3': 0.0003027915954589844, 'residual_add_relu2': 0.00011420249938964844}\n",
      "{'conv1': 0.0011501312255859375, 'bn1': 0.00013303756713867188, 'relu1': 6.365776062011719e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.0001289844512939453, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 159\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016391277313232422, 'bn1': 0.0005626678466796875, 'relu1': 0.0003333091735839844, 'conv2': 0.0016322135925292969, 'bn2': 0.0005445480346679688, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016262531280517578, 'bn1': 0.0005495548248291016, 'relu1': 0.00032258033752441406, 'conv2': 0.0016176700592041016, 'bn2': 0.0005497932434082031, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010483264923095703, 'bn1': 0.00032329559326171875, 'relu1': 0.0001735687255859375, 'conv2': 0.0013039112091064453, 'bn2': 0.0003108978271484375, 'conv3': 0.0003998279571533203, 'residual_add_relu2': 0.00039196014404296875}\n",
      "{'conv1': 0.0013041496276855469, 'bn1': 0.00031447410583496094, 'relu1': 0.0001735687255859375, 'conv2': 0.0013020038604736328, 'bn2': 0.0003066062927246094, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007915496826171875, 'bn1': 0.00020313262939453125, 'relu1': 0.00010037422180175781, 'conv2': 0.0011510848999023438, 'bn2': 0.0001895427703857422, 'conv3': 0.0003502368927001953, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011544227600097656, 'bn1': 0.0002028942108154297, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.00019407272338867188, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006566047668457031, 'bn1': 0.00012159347534179688, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011403560638427734, 'bn2': 0.0001342296600341797, 'conv3': 0.000301361083984375, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011413097381591797, 'bn1': 0.00012159347534179688, 'relu1': 5.9604644775390625e-05, 'conv2': 0.001142263412475586, 'bn2': 0.00011873245239257812, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 160\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016505718231201172, 'bn1': 0.0005469322204589844, 'relu1': 0.00032138824462890625, 'conv2': 0.0016252994537353516, 'bn2': 0.0005426406860351562, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016269683837890625, 'bn1': 0.0005519390106201172, 'relu1': 0.00032401084899902344, 'conv2': 0.0016245841979980469, 'bn2': 0.0005445480346679688, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010466575622558594, 'bn1': 0.00031375885009765625, 'relu1': 0.000171661376953125, 'conv2': 0.0013003349304199219, 'bn2': 0.0003001689910888672, 'conv3': 0.0003936290740966797, 'residual_add_relu2': 0.00038886070251464844}\n",
      "{'conv1': 0.0012969970703125, 'bn1': 0.0003066062927246094, 'relu1': 0.00017070770263671875, 'conv2': 0.0013010501861572266, 'bn2': 0.0003056526184082031, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007836818695068359, 'bn1': 0.00020122528076171875, 'relu1': 9.751319885253906e-05, 'conv2': 0.001148223876953125, 'bn2': 0.00018906593322753906, 'conv3': 0.0003464221954345703, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011453628540039062, 'bn1': 0.0001919269561767578, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.0001919269561767578, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006520748138427734, 'bn1': 0.00011467933654785156, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011360645294189453, 'bn2': 0.00011372566223144531, 'conv3': 0.00029087066650390625, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011370182037353516, 'bn1': 0.00011348724365234375, 'relu1': 5.626678466796875e-05, 'conv2': 0.0011358261108398438, 'bn2': 0.00012183189392089844, 'residual_add_relu2': 0.00011229515075683594}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 161\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016372203826904297, 'bn1': 0.0005500316619873047, 'relu1': 0.0003223419189453125, 'conv2': 0.0016322135925292969, 'bn2': 0.0005366802215576172, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016241073608398438, 'bn1': 0.0005519390106201172, 'relu1': 0.00032520294189453125, 'conv2': 0.0016279220581054688, 'bn2': 0.0005393028259277344, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001043081283569336, 'bn1': 0.00031638145446777344, 'relu1': 0.0001735687255859375, 'conv2': 0.0013055801391601562, 'bn2': 0.00030922889709472656, 'conv3': 0.00040030479431152344, 'residual_add_relu2': 0.0003960132598876953}\n",
      "{'conv1': 0.0013117790222167969, 'bn1': 0.0003256797790527344, 'relu1': 0.00017690658569335938, 'conv2': 0.0013060569763183594, 'bn2': 0.00031566619873046875, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007865428924560547, 'bn1': 0.0002067089080810547, 'relu1': 9.918212890625e-05, 'conv2': 0.001150369644165039, 'bn2': 0.00019598007202148438, 'conv3': 0.00035452842712402344, 'residual_add_relu2': 0.0002067089080810547}\n",
      "{'conv1': 0.0011513233184814453, 'bn1': 0.0001995563507080078, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00021338462829589844, 'residual_add_relu2': 0.00020575523376464844}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006589889526367188, 'bn1': 0.00012230873107910156, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011408329010009766, 'bn2': 0.000118255615234375, 'conv3': 0.00029206275939941406, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.001142263412475586, 'bn1': 0.00012445449829101562, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011386871337890625, 'bn2': 0.00011610984802246094, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 162\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016512870788574219, 'bn1': 0.0005807876586914062, 'relu1': 0.00032401084899902344, 'conv2': 0.0016298294067382812, 'bn2': 0.0005466938018798828, 'residual_add_relu2': 0.0007686614990234375}\n",
      "{'conv1': 0.0016303062438964844, 'bn1': 0.0005490779876708984, 'relu1': 0.00032401084899902344, 'conv2': 0.0016260147094726562, 'bn2': 0.0005438327789306641, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010499954223632812, 'bn1': 0.0003223419189453125, 'relu1': 0.0001735687255859375, 'conv2': 0.0013072490692138672, 'bn2': 0.00031876564025878906, 'conv3': 0.0004105567932128906, 'residual_add_relu2': 0.00039267539978027344}\n",
      "{'conv1': 0.0013031959533691406, 'bn1': 0.0003139972686767578, 'relu1': 0.00017333030700683594, 'conv2': 0.001302957534790039, 'bn2': 0.00030994415283203125, 'residual_add_relu2': 0.0003952980041503906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007929801940917969, 'bn1': 0.0002148151397705078, 'relu1': 0.00010132789611816406, 'conv2': 0.0011587142944335938, 'bn2': 0.0002155303955078125, 'conv3': 0.0003647804260253906, 'residual_add_relu2': 0.0002067089080810547}\n",
      "{'conv1': 0.0011608600616455078, 'bn1': 0.00021791458129882812, 'relu1': 0.00010228157043457031, 'conv2': 0.0011539459228515625, 'bn2': 0.0002090930938720703, 'residual_add_relu2': 0.0002071857452392578}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006630420684814453, 'bn1': 0.0001366138458251953, 'relu1': 6.198883056640625e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00013113021850585938, 'conv3': 0.0003044605255126953, 'residual_add_relu2': 0.00011301040649414062}\n",
      "{'conv1': 0.0011501312255859375, 'bn1': 0.00012183189392089844, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011370182037353516, 'bn2': 0.00011849403381347656, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 163\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016450881958007812, 'bn1': 0.0005621910095214844, 'relu1': 0.000324249267578125, 'conv2': 0.0016345977783203125, 'bn2': 0.0005450248718261719, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.001636505126953125, 'bn1': 0.0005388259887695312, 'relu1': 0.0003216266632080078, 'conv2': 0.0016324520111083984, 'bn2': 0.0005371570587158203, 'residual_add_relu2': 0.0007665157318115234}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010442733764648438, 'bn1': 0.0003116130828857422, 'relu1': 0.00017070770263671875, 'conv2': 0.0012989044189453125, 'bn2': 0.0003018379211425781, 'conv3': 0.0003952980041503906, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0012974739074707031, 'bn1': 0.00030684471130371094, 'relu1': 0.00017118453979492188, 'conv2': 0.0012962818145751953, 'bn2': 0.000316619873046875, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007867813110351562, 'bn1': 0.00020170211791992188, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00020265579223632812, 'conv3': 0.00035572052001953125, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0011515617370605469, 'bn1': 0.00020074844360351562, 'relu1': 0.00010228157043457031, 'conv2': 0.001150369644165039, 'bn2': 0.0001971721649169922, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006544589996337891, 'bn1': 0.00012135505676269531, 'relu1': 5.91278076171875e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00011515617370605469, 'conv3': 0.00029277801513671875, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.001142263412475586, 'bn1': 0.00012230873107910156, 'relu1': 5.7697296142578125e-05, 'conv2': 0.00113677978515625, 'bn2': 0.00011110305786132812, 'residual_add_relu2': 0.00010848045349121094}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 164\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016438961029052734, 'bn1': 0.0005650520324707031, 'relu1': 0.0003237724304199219, 'conv2': 0.001622915267944336, 'bn2': 0.0005359649658203125, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.001628875732421875, 'bn1': 0.0005419254302978516, 'relu1': 0.0003218650817871094, 'conv2': 0.0016164779663085938, 'bn2': 0.0005397796630859375, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010387897491455078, 'bn1': 0.00030493736267089844, 'relu1': 0.0001704692840576172, 'conv2': 0.0012972354888916016, 'bn2': 0.0002982616424560547, 'conv3': 0.0003924369812011719, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.001298666000366211, 'bn1': 0.0003142356872558594, 'relu1': 0.0001723766326904297, 'conv2': 0.0013027191162109375, 'bn2': 0.00030994415283203125, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007832050323486328, 'bn1': 0.00019979476928710938, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011470317840576172, 'bn2': 0.00019216537475585938, 'conv3': 0.0003495216369628906, 'residual_add_relu2': 0.0002033710479736328}\n",
      "{'conv1': 0.001150369644165039, 'bn1': 0.00018978118896484375, 'relu1': 9.5367431640625e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.0001881122589111328, 'residual_add_relu2': 0.00020313262939453125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006504058837890625, 'bn1': 0.00011396408081054688, 'relu1': 5.698204040527344e-05, 'conv2': 0.0011363029479980469, 'bn2': 0.00011348724365234375, 'conv3': 0.00028777122497558594, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011413097381591797, 'bn1': 0.00011301040649414062, 'relu1': 5.7220458984375e-05, 'conv2': 0.0011324882507324219, 'bn2': 0.0001125335693359375, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 165\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016412734985351562, 'bn1': 0.0005440711975097656, 'relu1': 0.00033020973205566406, 'conv2': 0.001623392105102539, 'bn2': 0.0005383491516113281, 'residual_add_relu2': 0.0007681846618652344}\n",
      "{'conv1': 0.001627206802368164, 'bn1': 0.0005371570587158203, 'relu1': 0.00032258033752441406, 'conv2': 0.0016150474548339844, 'bn2': 0.0005331039428710938, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010406970977783203, 'bn1': 0.00030875205993652344, 'relu1': 0.000171661376953125, 'conv2': 0.001300811767578125, 'bn2': 0.00029850006103515625, 'conv3': 0.0003960132598876953, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013034343719482422, 'bn1': 0.0003123283386230469, 'relu1': 0.00017189979553222656, 'conv2': 0.0012960433959960938, 'bn2': 0.0003020763397216797, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007827281951904297, 'bn1': 0.0001926422119140625, 'relu1': 9.703636169433594e-05, 'conv2': 0.0011448860168457031, 'bn2': 0.0001862049102783203, 'conv3': 0.0003478527069091797, 'residual_add_relu2': 0.000202178955078125}\n",
      "{'conv1': 0.0011458396911621094, 'bn1': 0.0001952648162841797, 'relu1': 9.584426879882812e-05, 'conv2': 0.0011446475982666016, 'bn2': 0.00018596649169921875, 'residual_add_relu2': 0.00020766258239746094}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006537437438964844, 'bn1': 0.00011658668518066406, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011413097381591797, 'bn2': 0.0001125335693359375, 'conv3': 0.0002925395965576172, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011365413665771484, 'bn1': 0.0001239776611328125, 'relu1': 5.7220458984375e-05, 'conv2': 0.0011370182037353516, 'bn2': 0.0001068115234375, 'residual_add_relu2': 0.00010800361633300781}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 166\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016474723815917969, 'bn1': 0.0005536079406738281, 'relu1': 0.0003237724304199219, 'conv2': 0.001622915267944336, 'bn2': 0.0005469322204589844, 'residual_add_relu2': 0.000762939453125}\n",
      "{'conv1': 0.0016245841979980469, 'bn1': 0.0005621910095214844, 'relu1': 0.0003218650817871094, 'conv2': 0.001617431640625, 'bn2': 0.0005297660827636719, 'residual_add_relu2': 0.0007607936859130859}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010426044464111328, 'bn1': 0.0003097057342529297, 'relu1': 0.00017070770263671875, 'conv2': 0.0012998580932617188, 'bn2': 0.00030922889709472656, 'conv3': 0.0003955364227294922, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013027191162109375, 'bn1': 0.00031375885009765625, 'relu1': 0.0001747608184814453, 'conv2': 0.0012996196746826172, 'bn2': 0.00030231475830078125, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007824897766113281, 'bn1': 0.0001952648162841797, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011472702026367188, 'bn2': 0.0001938343048095703, 'conv3': 0.00035119056701660156, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.0011477470397949219, 'bn1': 0.00019216537475585938, 'relu1': 0.0006692409515380859, 'conv2': 0.0011837482452392578, 'bn2': 0.00021886825561523438, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006573200225830078, 'bn1': 0.0001239776611328125, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011391639709472656, 'bn2': 0.00011658668518066406, 'conv3': 0.00028824806213378906, 'residual_add_relu2': 0.00010943412780761719}\n",
      "{'conv1': 0.0011379718780517578, 'bn1': 0.00011348724365234375, 'relu1': 5.626678466796875e-05, 'conv2': 0.001132965087890625, 'bn2': 0.0001049041748046875, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 167\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016562938690185547, 'bn1': 0.0005612373352050781, 'relu1': 0.00032520294189453125, 'conv2': 0.0016372203826904297, 'bn2': 0.0005450248718261719, 'residual_add_relu2': 0.0007696151733398438}\n",
      "{'conv1': 0.0016260147094726562, 'bn1': 0.0005452632904052734, 'relu1': 0.0003256797790527344, 'conv2': 0.0016314983367919922, 'bn2': 0.0005609989166259766, 'residual_add_relu2': 0.0007658004760742188}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010647773742675781, 'bn1': 0.0003323554992675781, 'relu1': 0.00018143653869628906, 'conv2': 0.001310586929321289, 'bn2': 0.00032019615173339844, 'conv3': 0.00040149688720703125, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013108253479003906, 'bn1': 0.0003230571746826172, 'relu1': 0.00017690658569335938, 'conv2': 0.0013079643249511719, 'bn2': 0.0003294944763183594, 'residual_add_relu2': 0.00039386749267578125}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007946491241455078, 'bn1': 0.00021219253540039062, 'relu1': 0.00010180473327636719, 'conv2': 0.0011563301086425781, 'bn2': 0.0002148151397705078, 'conv3': 0.0003616809844970703, 'residual_add_relu2': 0.00021147727966308594}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.00021123886108398438, 'relu1': 0.00010085105895996094, 'conv2': 0.0011532306671142578, 'bn2': 0.00021147727966308594, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006616115570068359, 'bn1': 0.00012159347534179688, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011408329010009766, 'bn2': 0.00011491775512695312, 'conv3': 0.00028824806213378906, 'residual_add_relu2': 0.00011324882507324219}\n",
      "{'conv1': 0.001146078109741211, 'bn1': 0.00013065338134765625, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011396408081054688, 'bn2': 0.00011563301086425781, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 168\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016524791717529297, 'bn1': 0.0005624294281005859, 'relu1': 0.00032520294189453125, 'conv2': 0.0016283988952636719, 'bn2': 0.0005342960357666016, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016374588012695312, 'bn1': 0.0005459785461425781, 'relu1': 0.00032401084899902344, 'conv2': 0.0016334056854248047, 'bn2': 0.0005438327789306641, 'residual_add_relu2': 0.0007653236389160156}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010445117950439453, 'bn1': 0.0003085136413574219, 'relu1': 0.000171661376953125, 'conv2': 0.0013022422790527344, 'bn2': 0.00031065940856933594, 'conv3': 0.0004029273986816406, 'residual_add_relu2': 0.0003883838653564453}\n",
      "{'conv1': 0.0012989044189453125, 'bn1': 0.0003135204315185547, 'relu1': 0.0001735687255859375, 'conv2': 0.0012996196746826172, 'bn2': 0.00032019615173339844, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007872581481933594, 'bn1': 0.0002014636993408203, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00020313262939453125, 'conv3': 0.00035691261291503906, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011518001556396484, 'bn1': 0.00019478797912597656, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011444091796875, 'bn2': 0.000194549560546875, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006577968597412109, 'bn1': 0.00012445449829101562, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011415481567382812, 'bn2': 0.0001239776611328125, 'conv3': 0.0002963542938232422, 'residual_add_relu2': 0.00011396408081054688}\n",
      "{'conv1': 0.0011439323425292969, 'bn1': 0.00012135505676269531, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011382102966308594, 'bn2': 0.00011944770812988281, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 169\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016400814056396484, 'bn1': 0.0005483627319335938, 'relu1': 0.00032019615173339844, 'conv2': 0.0016283988952636719, 'bn2': 0.0005407333374023438, 'residual_add_relu2': 0.0007638931274414062}\n",
      "{'conv1': 0.0016298294067382812, 'bn1': 0.0005385875701904297, 'relu1': 0.000324249267578125, 'conv2': 0.0016222000122070312, 'bn2': 0.0005376338958740234, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010423660278320312, 'bn1': 0.0003104209899902344, 'relu1': 0.00017142295837402344, 'conv2': 0.0013000965118408203, 'bn2': 0.0003018379211425781, 'conv3': 0.0004012584686279297, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.0013036727905273438, 'bn1': 0.00031185150146484375, 'relu1': 0.00017189979553222656, 'conv2': 0.0012981891632080078, 'bn2': 0.00031185150146484375, 'residual_add_relu2': 0.000392913818359375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007860660552978516, 'bn1': 0.00019621849060058594, 'relu1': 9.72747802734375e-05, 'conv2': 0.001146554946899414, 'bn2': 0.0001900196075439453, 'conv3': 0.0003478527069091797, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011487007141113281, 'bn1': 0.00019168853759765625, 'relu1': 9.584426879882812e-05, 'conv2': 0.001142740249633789, 'bn2': 0.0001926422119140625, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006554126739501953, 'bn1': 0.00012230873107910156, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011386871337890625, 'bn2': 0.00011968612670898438, 'conv3': 0.0002906322479248047, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.001140594482421875, 'bn1': 0.00012683868408203125, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011398792266845703, 'bn2': 0.00011610984802246094, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 170\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016422271728515625, 'bn1': 0.0005638599395751953, 'relu1': 0.0003261566162109375, 'conv2': 0.001627206802368164, 'bn2': 0.0005497932434082031, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.0016262531280517578, 'bn1': 0.0005550384521484375, 'relu1': 0.0003235340118408203, 'conv2': 0.0016283988952636719, 'bn2': 0.0005440711975097656, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010426044464111328, 'bn1': 0.0003077983856201172, 'relu1': 0.00017023086547851562, 'conv2': 0.0013010501861572266, 'bn2': 0.0003101825714111328, 'conv3': 0.0003998279571533203, 'residual_add_relu2': 0.00038814544677734375}\n",
      "{'conv1': 0.0013058185577392578, 'bn1': 0.0003108978271484375, 'relu1': 0.00017261505126953125, 'conv2': 0.0013005733489990234, 'bn2': 0.00031065940856933594, 'residual_add_relu2': 0.00038814544677734375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000782012939453125, 'bn1': 0.00019288063049316406, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011463165283203125, 'bn2': 0.0001876354217529297, 'conv3': 0.0003490447998046875, 'residual_add_relu2': 0.00020265579223632812}\n",
      "{'conv1': 0.0011463165283203125, 'bn1': 0.00019025802612304688, 'relu1': 9.560585021972656e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.00020503997802734375, 'residual_add_relu2': 0.0002796649932861328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006630420684814453, 'bn1': 0.00012350082397460938, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011396408081054688, 'bn2': 0.00011801719665527344, 'conv3': 0.0002880096435546875, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011420249938964844, 'bn1': 0.00011515617370605469, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011343955993652344, 'bn2': 0.00011110305786132812, 'residual_add_relu2': 0.0001087188720703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 171\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001651763916015625, 'bn1': 0.0005528926849365234, 'relu1': 0.00032639503479003906, 'conv2': 0.0016417503356933594, 'bn2': 0.0005500316619873047, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016276836395263672, 'bn1': 0.0005655288696289062, 'relu1': 0.00032329559326171875, 'conv2': 0.0016188621520996094, 'bn2': 0.0005316734313964844, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010399818420410156, 'bn1': 0.0003056526184082031, 'relu1': 0.00017023086547851562, 'conv2': 0.0016751289367675781, 'bn2': 0.00040650367736816406, 'conv3': 0.0004248619079589844, 'residual_add_relu2': 0.000392913818359375}\n",
      "{'conv1': 0.0013098716735839844, 'bn1': 0.0003209114074707031, 'relu1': 0.00017690658569335938, 'conv2': 0.00130462646484375, 'bn2': 0.00031685829162597656, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007903575897216797, 'bn1': 0.00020384788513183594, 'relu1': 0.00010347366333007812, 'conv2': 0.001155853271484375, 'bn2': 0.00020194053649902344, 'conv3': 0.0003600120544433594, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.0011570453643798828, 'bn1': 0.00021338462829589844, 'relu1': 0.00010538101196289062, 'conv2': 0.0011527538299560547, 'bn2': 0.00020170211791992188, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006544589996337891, 'bn1': 0.00013899803161621094, 'relu1': 6.341934204101562e-05, 'conv2': 0.0011472702026367188, 'bn2': 0.0001251697540283203, 'conv3': 0.0002956390380859375, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011446475982666016, 'bn1': 0.0001227855682373047, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011353492736816406, 'bn2': 0.00012755393981933594, 'residual_add_relu2': 0.00011277198791503906}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 172\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016379356384277344, 'bn1': 0.0005583763122558594, 'relu1': 0.00032401084899902344, 'conv2': 0.001621246337890625, 'bn2': 0.0005514621734619141, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016489028930664062, 'bn1': 0.0005469322204589844, 'relu1': 0.00032448768615722656, 'conv2': 0.0016222000122070312, 'bn2': 0.0005447864532470703, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010428428649902344, 'bn1': 0.000331878662109375, 'relu1': 0.00017213821411132812, 'conv2': 0.0012984275817871094, 'bn2': 0.00031065940856933594, 'conv3': 0.00040030479431152344, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.001302957534790039, 'bn1': 0.00034236907958984375, 'relu1': 0.0001761913299560547, 'conv2': 0.0013005733489990234, 'bn2': 0.00031495094299316406, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007846355438232422, 'bn1': 0.00019860267639160156, 'relu1': 9.822845458984375e-05, 'conv2': 0.001148223876953125, 'bn2': 0.0001888275146484375, 'conv3': 0.00034809112548828125, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.0001971721649169922, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.00018739700317382812, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006530284881591797, 'bn1': 0.00011467933654785156, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011374950408935547, 'bn2': 0.00011134147644042969, 'conv3': 0.0003020763397216797, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.001140594482421875, 'bn1': 0.00011539459228515625, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011377334594726562, 'bn2': 0.00012683868408203125, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 173\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001676321029663086, 'bn1': 0.0005686283111572266, 'relu1': 0.00032973289489746094, 'conv2': 0.0016336441040039062, 'bn2': 0.0005481243133544922, 'residual_add_relu2': 0.0007696151733398438}\n",
      "{'conv1': 0.0016329288482666016, 'bn1': 0.0005557537078857422, 'relu1': 0.0003273487091064453, 'conv2': 0.001630544662475586, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007662773132324219}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001051187515258789, 'bn1': 0.0003306865692138672, 'relu1': 0.0001735687255859375, 'conv2': 0.0013110637664794922, 'bn2': 0.0003192424774169922, 'conv3': 0.0004069805145263672, 'residual_add_relu2': 0.00039196014404296875}\n",
      "{'conv1': 0.001306772232055664, 'bn1': 0.0003197193145751953, 'relu1': 0.0001735687255859375, 'conv2': 0.0013036727905273438, 'bn2': 0.0003292560577392578, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007925033569335938, 'bn1': 0.00020647048950195312, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.0001919269561767578, 'conv3': 0.0003509521484375, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011506080627441406, 'bn1': 0.00019502639770507812, 'relu1': 9.560585021972656e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.0001888275146484375, 'residual_add_relu2': 0.0002028942108154297}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006513595581054688, 'bn1': 0.00011658668518066406, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011386871337890625, 'bn2': 0.00011444091796875, 'conv3': 0.0002923011779785156, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011386871337890625, 'bn1': 0.00012350082397460938, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011372566223144531, 'bn2': 0.00011944770812988281, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 174\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016436576843261719, 'bn1': 0.0005548000335693359, 'relu1': 0.00032401084899902344, 'conv2': 0.0016214847564697266, 'bn2': 0.0005426406860351562, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016298294067382812, 'bn1': 0.0005481243133544922, 'relu1': 0.0003228187561035156, 'conv2': 0.0016200542449951172, 'bn2': 0.0005471706390380859, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010514259338378906, 'bn1': 0.0003228187561035156, 'relu1': 0.0001735687255859375, 'conv2': 0.0013022422790527344, 'bn2': 0.00031065940856933594, 'conv3': 0.00039839744567871094, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013051033020019531, 'bn1': 0.00032067298889160156, 'relu1': 0.00017380714416503906, 'conv2': 0.0013022422790527344, 'bn2': 0.00030875205993652344, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007877349853515625, 'bn1': 0.00020575523376464844, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011501312255859375, 'bn2': 0.00019598007202148438, 'conv3': 0.0003497600555419922, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011527538299560547, 'bn1': 0.00020742416381835938, 'relu1': 9.989738464355469e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.000194549560546875, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006601810455322266, 'bn1': 0.0001304149627685547, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011394023895263672, 'bn2': 0.00011205673217773438, 'conv3': 0.00029349327087402344, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011377334594726562, 'bn1': 0.0001201629638671875, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011370182037353516, 'bn2': 0.0001239776611328125, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 175\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016489028930664062, 'bn1': 0.0005750656127929688, 'relu1': 0.0003266334533691406, 'conv2': 0.001641988754272461, 'bn2': 0.0005550384521484375, 'residual_add_relu2': 0.0007698535919189453}\n",
      "{'conv1': 0.0016481876373291016, 'bn1': 0.0005486011505126953, 'relu1': 0.0003294944763183594, 'conv2': 0.0016281604766845703, 'bn2': 0.0005490779876708984, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010504722595214844, 'bn1': 0.000324249267578125, 'relu1': 0.00017571449279785156, 'conv2': 0.0013082027435302734, 'bn2': 0.0003218650817871094, 'conv3': 0.00041222572326660156, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013098716735839844, 'bn1': 0.0003325939178466797, 'relu1': 0.0001766681671142578, 'conv2': 0.0013093948364257812, 'bn2': 0.0003325939178466797, 'residual_add_relu2': 0.00039386749267578125}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007936954498291016, 'bn1': 0.0002105236053466797, 'relu1': 0.00010251998901367188, 'conv2': 0.0011603832244873047, 'bn2': 0.00021910667419433594, 'conv3': 0.0003628730773925781, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.0011568069458007812, 'bn1': 0.0002090930938720703, 'relu1': 0.00010085105895996094, 'conv2': 0.0011510848999023438, 'bn2': 0.0002033710479736328, 'residual_add_relu2': 0.0002071857452392578}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006639957427978516, 'bn1': 0.0001456737518310547, 'relu1': 6.4849853515625e-05, 'conv2': 0.0011496543884277344, 'bn2': 0.00012826919555664062, 'conv3': 0.000301361083984375, 'residual_add_relu2': 0.00011348724365234375}\n",
      "{'conv1': 0.0011472702026367188, 'bn1': 0.00016736984252929688, 'relu1': 6.365776062011719e-05, 'conv2': 0.0011463165283203125, 'bn2': 0.00012612342834472656, 'residual_add_relu2': 0.00011181831359863281}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 176\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016410350799560547, 'bn1': 0.0005502700805664062, 'relu1': 0.00032401084899902344, 'conv2': 0.0016350746154785156, 'bn2': 0.0005438327789306641, 'residual_add_relu2': 0.0007679462432861328}\n",
      "{'conv1': 0.0016312599182128906, 'bn1': 0.0005564689636230469, 'relu1': 0.00032806396484375, 'conv2': 0.0016276836395263672, 'bn2': 0.0005595684051513672, 'residual_add_relu2': 0.0007672309875488281}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010535717010498047, 'bn1': 0.00032591819763183594, 'relu1': 0.0001761913299560547, 'conv2': 0.0013213157653808594, 'bn2': 0.000324249267578125, 'conv3': 0.0004086494445800781, 'residual_add_relu2': 0.00039315223693847656}\n",
      "{'conv1': 0.0013070106506347656, 'bn1': 0.0003135204315185547, 'relu1': 0.0001742839813232422, 'conv2': 0.001299142837524414, 'bn2': 0.0003235340118408203, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007872581481933594, 'bn1': 0.00020051002502441406, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011496543884277344, 'bn2': 0.00019168853759765625, 'conv3': 0.00034928321838378906, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011491775512695312, 'bn1': 0.0001933574676513672, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011434555053710938, 'bn2': 0.0002410411834716797, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006537437438964844, 'bn1': 0.00011444091796875, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011363029479980469, 'bn2': 0.00010895729064941406, 'conv3': 0.00028824806213378906, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011377334594726562, 'bn1': 0.0001232624053955078, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011377334594726562, 'bn2': 0.00010895729064941406, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 177\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016453266143798828, 'bn1': 0.0005555152893066406, 'relu1': 0.0003249645233154297, 'conv2': 0.0016262531280517578, 'bn2': 0.0005469322204589844, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016264915466308594, 'bn1': 0.0005459785461425781, 'relu1': 0.00032401084899902344, 'conv2': 0.0016222000122070312, 'bn2': 0.0005490779876708984, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010459423065185547, 'bn1': 0.0003180503845214844, 'relu1': 0.00017309188842773438, 'conv2': 0.0013031959533691406, 'bn2': 0.0003104209899902344, 'conv3': 0.00039887428283691406, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013034343719482422, 'bn1': 0.00031566619873046875, 'relu1': 0.00017309188842773438, 'conv2': 0.0013012886047363281, 'bn2': 0.000308990478515625, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007915496826171875, 'bn1': 0.00021791458129882812, 'relu1': 0.0001010894775390625, 'conv2': 0.0011513233184814453, 'bn2': 0.00019812583923339844, 'conv3': 0.0003540515899658203, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011506080627441406, 'bn1': 0.0002009868621826172, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.00020432472229003906, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006549358367919922, 'bn1': 0.00011515617370605469, 'relu1': 5.8650970458984375e-05, 'conv2': 0.00113677978515625, 'bn2': 0.00010895729064941406, 'conv3': 0.0002880096435546875, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.0011382102966308594, 'bn1': 0.0001308917999267578, 'relu1': 6.389617919921875e-05, 'conv2': 0.0011398792266845703, 'bn2': 0.00011801719665527344, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 178\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001653432846069336, 'bn1': 0.0005621910095214844, 'relu1': 0.0003275871276855469, 'conv2': 0.0016291141510009766, 'bn2': 0.0005514621734619141, 'residual_add_relu2': 0.0007700920104980469}\n",
      "{'conv1': 0.0016326904296875, 'bn1': 0.0005517005920410156, 'relu1': 0.0003254413604736328, 'conv2': 0.0016262531280517578, 'bn2': 0.0005428791046142578, 'residual_add_relu2': 0.0007681846618652344}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010530948638916016, 'bn1': 0.00033092498779296875, 'relu1': 0.00017952919006347656, 'conv2': 0.001314401626586914, 'bn2': 0.0003223419189453125, 'conv3': 0.00041484832763671875, 'residual_add_relu2': 0.00039458274841308594}\n",
      "{'conv1': 0.0013124942779541016, 'bn1': 0.0003216266632080078, 'relu1': 0.00017642974853515625, 'conv2': 0.0013051033020019531, 'bn2': 0.0003161430358886719, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007889270782470703, 'bn1': 0.00020575523376464844, 'relu1': 0.00010180473327636719, 'conv2': 0.0011515617370605469, 'bn2': 0.00020122528076171875, 'conv3': 0.00035572052001953125, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.0011513233184814453, 'bn1': 0.00020647048950195312, 'relu1': 0.00010132789611816406, 'conv2': 0.001150369644165039, 'bn2': 0.0001983642578125, 'residual_add_relu2': 0.00020599365234375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006618499755859375, 'bn1': 0.0001380443572998047, 'relu1': 6.413459777832031e-05, 'conv2': 0.0011444091796875, 'bn2': 0.00012493133544921875, 'conv3': 0.000301361083984375, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011453628540039062, 'bn1': 0.00012993812561035156, 'relu1': 6.222724914550781e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.00012421607971191406, 'residual_add_relu2': 0.00011229515075683594}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 179\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016498565673828125, 'bn1': 0.0005631446838378906, 'relu1': 0.00032591819763183594, 'conv2': 0.0016367435455322266, 'bn2': 0.0005571842193603516, 'residual_add_relu2': 0.0007712841033935547}\n",
      "{'conv1': 0.0016341209411621094, 'bn1': 0.0005619525909423828, 'relu1': 0.0003249645233154297, 'conv2': 0.0016281604766845703, 'bn2': 0.0005466938018798828, 'residual_add_relu2': 0.0007643699645996094}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010476112365722656, 'bn1': 0.00032067298889160156, 'relu1': 0.00017714500427246094, 'conv2': 0.0013074874877929688, 'bn2': 0.00030994415283203125, 'conv3': 0.00040340423583984375, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013053417205810547, 'bn1': 0.0003268718719482422, 'relu1': 0.00017690658569335938, 'conv2': 0.0013058185577392578, 'bn2': 0.000316619873046875, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007908344268798828, 'bn1': 0.0002162456512451172, 'relu1': 0.00010180473327636719, 'conv2': 0.0011548995971679688, 'bn2': 0.00020122528076171875, 'conv3': 0.0003597736358642578, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.001154184341430664, 'bn1': 0.0002079010009765625, 'relu1': 0.00010037422180175781, 'conv2': 0.0011515617370605469, 'bn2': 0.00020122528076171875, 'residual_add_relu2': 0.00020599365234375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006594657897949219, 'bn1': 0.00012731552124023438, 'relu1': 8.177757263183594e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.0001342296600341797, 'conv3': 0.0003020763397216797, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011463165283203125, 'bn1': 0.0001277923583984375, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011386871337890625, 'bn2': 0.0001575946807861328, 'residual_add_relu2': 0.00011348724365234375}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 180\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016415119171142578, 'bn1': 0.0005571842193603516, 'relu1': 0.0003268718719482422, 'conv2': 0.0016269683837890625, 'bn2': 0.0005471706390380859, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016295909881591797, 'bn1': 0.0005538463592529297, 'relu1': 0.0003249645233154297, 'conv2': 0.0016269683837890625, 'bn2': 0.0005488395690917969, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010454654693603516, 'bn1': 0.000316619873046875, 'relu1': 0.0001761913299560547, 'conv2': 0.0013055801391601562, 'bn2': 0.00031256675720214844, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.0003936290740966797}\n",
      "{'conv1': 0.00130462646484375, 'bn1': 0.0003180503845214844, 'relu1': 0.00017571449279785156, 'conv2': 0.0013017654418945312, 'bn2': 0.00030994415283203125, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007867813110351562, 'bn1': 0.0002002716064453125, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011513233184814453, 'bn2': 0.00019741058349609375, 'conv3': 0.0003523826599121094, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011522769927978516, 'bn1': 0.00021076202392578125, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011508464813232422, 'bn2': 0.0001957416534423828, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006575584411621094, 'bn1': 0.0001239776611328125, 'relu1': 5.9604644775390625e-05, 'conv2': 0.001142263412475586, 'bn2': 0.00012564659118652344, 'conv3': 0.00029754638671875, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011434555053710938, 'bn1': 0.0001227855682373047, 'relu1': 6.29425048828125e-05, 'conv2': 0.0011372566223144531, 'bn2': 0.00012063980102539062, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 181\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016436576843261719, 'bn1': 0.0005533695220947266, 'relu1': 0.0003273487091064453, 'conv2': 0.0016286373138427734, 'bn2': 0.0005469322204589844, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016312599182128906, 'bn1': 0.0005497932434082031, 'relu1': 0.0003230571746826172, 'conv2': 0.0016281604766845703, 'bn2': 0.0005457401275634766, 'residual_add_relu2': 0.0007619857788085938}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.00104522705078125, 'bn1': 0.00031757354736328125, 'relu1': 0.0001723766326904297, 'conv2': 0.0013043880462646484, 'bn2': 0.00031495094299316406, 'conv3': 0.00040149688720703125, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013320446014404297, 'bn1': 0.0003979206085205078, 'relu1': 0.00018167495727539062, 'conv2': 0.0013175010681152344, 'bn2': 0.00030875205993652344, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007879734039306641, 'bn1': 0.00021338462829589844, 'relu1': 0.00010132789611816406, 'conv2': 0.0011548995971679688, 'bn2': 0.00018858909606933594, 'conv3': 0.0003504753112792969, 'residual_add_relu2': 0.00020265579223632812}\n",
      "{'conv1': 0.0011508464813232422, 'bn1': 0.00020051002502441406, 'relu1': 9.989738464355469e-05, 'conv2': 0.0011501312255859375, 'bn2': 0.0001914501190185547, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006563663482666016, 'bn1': 0.0001201629638671875, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011398792266845703, 'bn2': 0.00011205673217773438, 'conv3': 0.0002923011779785156, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011413097381591797, 'bn1': 0.00011706352233886719, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011358261108398438, 'bn2': 0.00012755393981933594, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 182\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016551017761230469, 'bn1': 0.0005805492401123047, 'relu1': 0.00032973289489746094, 'conv2': 0.0016398429870605469, 'bn2': 0.0005662441253662109, 'residual_add_relu2': 0.0007679462432861328}\n",
      "{'conv1': 0.001636505126953125, 'bn1': 0.0005681514739990234, 'relu1': 0.00032639503479003906, 'conv2': 0.0016274452209472656, 'bn2': 0.0005669593811035156, 'residual_add_relu2': 0.0007665157318115234}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010592937469482422, 'bn1': 0.00032711029052734375, 'relu1': 0.00017762184143066406, 'conv2': 0.0013120174407958984, 'bn2': 0.00032329559326171875, 'conv3': 0.00042176246643066406, 'residual_add_relu2': 0.0003941059112548828}\n",
      "{'conv1': 0.001316070556640625, 'bn1': 0.0003306865692138672, 'relu1': 0.0001780986785888672, 'conv2': 0.0013141632080078125, 'bn2': 0.0003237724304199219, 'residual_add_relu2': 0.0003941059112548828}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007932186126708984, 'bn1': 0.00021576881408691406, 'relu1': 0.00010132789611816406, 'conv2': 0.0011591911315917969, 'bn2': 0.00020623207092285156, 'conv3': 0.0003631114959716797, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.0011548995971679688, 'bn1': 0.00021076202392578125, 'relu1': 0.00010085105895996094, 'conv2': 0.00115203857421875, 'bn2': 0.00020432472229003906, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006618499755859375, 'bn1': 0.00015306472778320312, 'relu1': 6.413459777832031e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.00013589859008789062, 'conv3': 0.00030231475830078125, 'residual_add_relu2': 0.00011301040649414062}\n",
      "{'conv1': 0.0011479854583740234, 'bn1': 0.0001323223114013672, 'relu1': 6.222724914550781e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.00015234947204589844, 'residual_add_relu2': 0.00011396408081054688}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 183\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001680135726928711, 'bn1': 0.0005927085876464844, 'relu1': 0.0003387928009033203, 'conv2': 0.0016608238220214844, 'bn2': 0.0005652904510498047, 'residual_add_relu2': 0.0007734298706054688}\n",
      "{'conv1': 0.0016493797302246094, 'bn1': 0.0005710124969482422, 'relu1': 0.0003345012664794922, 'conv2': 0.0016431808471679688, 'bn2': 0.0005652904510498047, 'residual_add_relu2': 0.0007665157318115234}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010645389556884766, 'bn1': 0.00033354759216308594, 'relu1': 0.000186920166015625, 'conv2': 0.0013210773468017578, 'bn2': 0.00033545494079589844, 'conv3': 0.00042510032653808594, 'residual_add_relu2': 0.0003933906555175781}\n",
      "{'conv1': 0.0013141632080078125, 'bn1': 0.00033593177795410156, 'relu1': 0.00018310546875, 'conv2': 0.0013124942779541016, 'bn2': 0.0003261566162109375, 'residual_add_relu2': 0.00039315223693847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008041858673095703, 'bn1': 0.00022029876708984375, 'relu1': 0.00010848045349121094, 'conv2': 0.0011606216430664062, 'bn2': 0.0002148151397705078, 'conv3': 0.0003635883331298828, 'residual_add_relu2': 0.00020813941955566406}\n",
      "{'conv1': 0.0011553764343261719, 'bn1': 0.0002276897430419922, 'relu1': 0.00010466575622558594, 'conv2': 0.0011568069458007812, 'bn2': 0.00021386146545410156, 'residual_add_relu2': 0.00020694732666015625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006639957427978516, 'bn1': 0.00014710426330566406, 'relu1': 6.556510925292969e-05, 'conv2': 0.0011439323425292969, 'bn2': 0.0001251697540283203, 'conv3': 0.00028896331787109375, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011436939239501953, 'bn1': 0.0001277923583984375, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.00013518333435058594, 'residual_add_relu2': 0.0001125335693359375}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 184\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016465187072753906, 'bn1': 0.00055694580078125, 'relu1': 0.00032520294189453125, 'conv2': 0.0016429424285888672, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007698535919189453}\n",
      "{'conv1': 0.0016324520111083984, 'bn1': 0.0005562305450439453, 'relu1': 0.00032711029052734375, 'conv2': 0.0016307830810546875, 'bn2': 0.0005629062652587891, 'residual_add_relu2': 0.0007655620574951172}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010526180267333984, 'bn1': 0.00033164024353027344, 'relu1': 0.00017595291137695312, 'conv2': 0.0013096332550048828, 'bn2': 0.00032067298889160156, 'conv3': 0.0004067420959472656, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013027191162109375, 'bn1': 0.0003170967102050781, 'relu1': 0.0001747608184814453, 'conv2': 0.0013010501861572266, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007922649383544922, 'bn1': 0.0002033710479736328, 'relu1': 9.918212890625e-05, 'conv2': 0.0011539459228515625, 'bn2': 0.00019860267639160156, 'conv3': 0.0003540515899658203, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.0011539459228515625, 'bn1': 0.00020074844360351562, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011467933654785156, 'bn2': 0.00019502639770507812, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006632804870605469, 'bn1': 0.00012445449829101562, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011415481567382812, 'bn2': 0.00012040138244628906, 'conv3': 0.0002956390380859375, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.001140594482421875, 'bn1': 0.00012302398681640625, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00011897087097167969, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 185\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016608238220214844, 'bn1': 0.0005674362182617188, 'relu1': 0.0003256797790527344, 'conv2': 0.001623392105102539, 'bn2': 0.0005509853363037109, 'residual_add_relu2': 0.0007750988006591797}\n",
      "{'conv1': 0.0016262531280517578, 'bn1': 0.0005450248718261719, 'relu1': 0.00032210350036621094, 'conv2': 0.0016186237335205078, 'bn2': 0.0005421638488769531, 'residual_add_relu2': 0.0007643699645996094}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001039266586303711, 'bn1': 0.00031185150146484375, 'relu1': 0.00017309188842773438, 'conv2': 0.001302480697631836, 'bn2': 0.00030303001403808594, 'conv3': 0.00039696693420410156, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013055801391601562, 'bn1': 0.0003180503845214844, 'relu1': 0.00017309188842773438, 'conv2': 0.0013003349304199219, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007860660552978516, 'bn1': 0.0002148151397705078, 'relu1': 0.00010275840759277344, 'conv2': 0.0011548995971679688, 'bn2': 0.0001976490020751953, 'conv3': 0.0003552436828613281, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011513233184814453, 'bn1': 0.00019884109497070312, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011467933654785156, 'bn2': 0.0001995563507080078, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006570816040039062, 'bn1': 0.00012683868408203125, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011420249938964844, 'bn2': 0.00012826919555664062, 'conv3': 0.0002951622009277344, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011425018310546875, 'bn1': 0.0001304149627685547, 'relu1': 6.031990051269531e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00012373924255371094, 'residual_add_relu2': 0.00011181831359863281}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 186\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016379356384277344, 'bn1': 0.0005552768707275391, 'relu1': 0.0003235340118408203, 'conv2': 0.0016241073608398438, 'bn2': 0.0005619525909423828, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.001631021499633789, 'bn1': 0.0005543231964111328, 'relu1': 0.0003247261047363281, 'conv2': 0.001623392105102539, 'bn2': 0.0005450248718261719, 'residual_add_relu2': 0.0007617473602294922}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010437965393066406, 'bn1': 0.0003147125244140625, 'relu1': 0.00017333030700683594, 'conv2': 0.0013022422790527344, 'bn2': 0.00031828880310058594, 'conv3': 0.000400543212890625, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013034343719482422, 'bn1': 0.0003159046173095703, 'relu1': 0.00017309188842773438, 'conv2': 0.0013003349304199219, 'bn2': 0.0003180503845214844, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.00078582763671875, 'bn1': 0.00019979476928710938, 'relu1': 0.00011348724365234375, 'conv2': 0.0011529922485351562, 'bn2': 0.0002052783966064453, 'conv3': 0.00035500526428222656, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0011515617370605469, 'bn1': 0.0002105236053466797, 'relu1': 0.00010061264038085938, 'conv2': 0.0011506080627441406, 'bn2': 0.00020074844360351562, 'residual_add_relu2': 0.00020623207092285156}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006561279296875, 'bn1': 0.00012063980102539062, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011403560638427734, 'bn2': 0.00012373924255371094, 'conv3': 0.00029540061950683594, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011436939239501953, 'bn1': 0.00012874603271484375, 'relu1': 6.008148193359375e-05, 'conv2': 0.001138925552368164, 'bn2': 0.00011587142944335938, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 187\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016512870788574219, 'bn1': 0.0005574226379394531, 'relu1': 0.0003235340118408203, 'conv2': 0.0016360282897949219, 'bn2': 0.0005552768707275391, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.001634836196899414, 'bn1': 0.0005445480346679688, 'relu1': 0.0003273487091064453, 'conv2': 0.0016334056854248047, 'bn2': 0.0005459785461425781, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010426044464111328, 'bn1': 0.00031638145446777344, 'relu1': 0.00017142295837402344, 'conv2': 0.0013012886047363281, 'bn2': 0.0003151893615722656, 'conv3': 0.00040149688720703125, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013022422790527344, 'bn1': 0.0003085136413574219, 'relu1': 0.00017118453979492188, 'conv2': 0.0012974739074707031, 'bn2': 0.0003018379211425781, 'residual_add_relu2': 0.00038886070251464844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007836818695068359, 'bn1': 0.0002002716064453125, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011467933654785156, 'bn2': 0.0002048015594482422, 'conv3': 0.0003542900085449219, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011525154113769531, 'bn1': 0.00019311904907226562, 'relu1': 9.489059448242188e-05, 'conv2': 0.0011448860168457031, 'bn2': 0.00020742416381835938, 'residual_add_relu2': 0.00021600723266601562}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006592273712158203, 'bn1': 0.00012683868408203125, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011410713195800781, 'bn2': 0.00011467933654785156, 'conv3': 0.0002963542938232422, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011413097381591797, 'bn1': 0.00012254714965820312, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011386871337890625, 'bn2': 0.00011491775512695312, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 188\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016448497772216797, 'bn1': 0.0005619525909423828, 'relu1': 0.0003249645233154297, 'conv2': 0.0016350746154785156, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007688999176025391}\n",
      "{'conv1': 0.0016362667083740234, 'bn1': 0.0005538463592529297, 'relu1': 0.00032591819763183594, 'conv2': 0.0016345977783203125, 'bn2': 0.0005478858947753906, 'residual_add_relu2': 0.0007700920104980469}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010488033294677734, 'bn1': 0.0003311634063720703, 'relu1': 0.0001747608184814453, 'conv2': 0.001308441162109375, 'bn2': 0.0003304481506347656, 'conv3': 0.0004055500030517578, 'residual_add_relu2': 0.0003921985626220703}\n",
      "{'conv1': 0.0013053417205810547, 'bn1': 0.0003142356872558594, 'relu1': 0.00017452239990234375, 'conv2': 0.0013005733489990234, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007848739624023438, 'bn1': 0.0001983642578125, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.0001952648162841797, 'conv3': 0.00035452842712402344, 'residual_add_relu2': 0.0002086162567138672}\n",
      "{'conv1': 0.0011560916900634766, 'bn1': 0.00020003318786621094, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011467933654785156, 'bn2': 0.00019502639770507812, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006573200225830078, 'bn1': 0.0001220703125, 'relu1': 6.29425048828125e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00011444091796875, 'conv3': 0.0002968311309814453, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011425018310546875, 'bn1': 0.00012922286987304688, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011391639709472656, 'bn2': 0.00011658668518066406, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 189\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016529560089111328, 'bn1': 0.0005609989166259766, 'relu1': 0.00032401084899902344, 'conv2': 0.0016252994537353516, 'bn2': 0.0005421638488769531, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016341209411621094, 'bn1': 0.0005533695220947266, 'relu1': 0.0003237724304199219, 'conv2': 0.0016210079193115234, 'bn2': 0.0005500316619873047, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010459423065185547, 'bn1': 0.0003170967102050781, 'relu1': 0.0001728534698486328, 'conv2': 0.0013034343719482422, 'bn2': 0.00031375885009765625, 'conv3': 0.00039839744567871094, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013320446014404297, 'bn1': 0.0003266334533691406, 'relu1': 0.00017523765563964844, 'conv2': 0.0013115406036376953, 'bn2': 0.0003132820129394531, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007877349853515625, 'bn1': 0.00020694732666015625, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.0001983642578125, 'conv3': 0.00035500526428222656, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.00115203857421875, 'bn1': 0.00019979476928710938, 'relu1': 9.799003601074219e-05, 'conv2': 0.001146554946899414, 'bn2': 0.00018739700317382812, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006551742553710938, 'bn1': 0.00011706352233886719, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011379718780517578, 'bn2': 0.00011777877807617188, 'conv3': 0.0002875328063964844, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.0011358261108398438, 'bn1': 0.00011086463928222656, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011990070343017578, 'bn2': 0.00011992454528808594, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 190\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016722679138183594, 'bn1': 0.0005586147308349609, 'relu1': 0.0003249645233154297, 'conv2': 0.0016429424285888672, 'bn2': 0.0005586147308349609, 'residual_add_relu2': 0.0007691383361816406}\n",
      "{'conv1': 0.0016410350799560547, 'bn1': 0.0005562305450439453, 'relu1': 0.0003256797790527344, 'conv2': 0.001631021499633789, 'bn2': 0.0005495548248291016, 'residual_add_relu2': 0.0007672309875488281}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010483264923095703, 'bn1': 0.00032329559326171875, 'relu1': 0.00017523765563964844, 'conv2': 0.001306295394897461, 'bn2': 0.0003199577331542969, 'conv3': 0.00040030479431152344, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013022422790527344, 'bn1': 0.00031495094299316406, 'relu1': 0.00017380714416503906, 'conv2': 0.0013022422790527344, 'bn2': 0.00030732154846191406, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007860660552978516, 'bn1': 0.00020074844360351562, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011501312255859375, 'bn2': 0.0002033710479736328, 'conv3': 0.0003609657287597656, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011527538299560547, 'bn1': 0.00021076202392578125, 'relu1': 0.00010418891906738281, 'conv2': 0.0011506080627441406, 'bn2': 0.00019979476928710938, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006630420684814453, 'bn1': 0.00013780593872070312, 'relu1': 6.365776062011719e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.00011801719665527344, 'conv3': 0.0002932548522949219, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.001140594482421875, 'bn1': 0.0001304149627685547, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011360645294189453, 'bn2': 0.00013303756713867188, 'residual_add_relu2': 0.00011301040649414062}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 191\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016598701477050781, 'bn1': 0.0005574226379394531, 'relu1': 0.0003247261047363281, 'conv2': 0.0016300678253173828, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.0007677078247070312}\n",
      "{'conv1': 0.0016436576843261719, 'bn1': 0.0005557537078857422, 'relu1': 0.000324249267578125, 'conv2': 0.0016276836395263672, 'bn2': 0.0005519390106201172, 'residual_add_relu2': 0.0007665157318115234}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010502338409423828, 'bn1': 0.0003249645233154297, 'relu1': 0.00017690658569335938, 'conv2': 0.001310586929321289, 'bn2': 0.0003192424774169922, 'conv3': 0.00040411949157714844, 'residual_add_relu2': 0.000392913818359375}\n",
      "{'conv1': 0.0013108253479003906, 'bn1': 0.0003254413604736328, 'relu1': 0.00017690658569335938, 'conv2': 0.001306295394897461, 'bn2': 0.000316619873046875, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007905960083007812, 'bn1': 0.0002086162567138672, 'relu1': 0.0001010894775390625, 'conv2': 0.0011539459228515625, 'bn2': 0.00020647048950195312, 'conv3': 0.0003578662872314453, 'residual_add_relu2': 0.0002067089080810547}\n",
      "{'conv1': 0.0011551380157470703, 'bn1': 0.000209808349609375, 'relu1': 0.00010132789611816406, 'conv2': 0.0011546611785888672, 'bn2': 0.00020813941955566406, 'residual_add_relu2': 0.00020694732666015625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006620883941650391, 'bn1': 0.0001227855682373047, 'relu1': 5.984306335449219e-05, 'conv2': 0.001140594482421875, 'bn2': 0.00011515617370605469, 'conv3': 0.00029158592224121094, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011458396911621094, 'bn1': 0.0001304149627685547, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011401176452636719, 'bn2': 0.000118255615234375, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 192\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.00164794921875, 'bn1': 0.0005764961242675781, 'relu1': 0.0003273487091064453, 'conv2': 0.0016486644744873047, 'bn2': 0.0005700588226318359, 'residual_add_relu2': 0.0007703304290771484}\n",
      "{'conv1': 0.0016465187072753906, 'bn1': 0.0005650520324707031, 'relu1': 0.0003268718719482422, 'conv2': 0.0016384124755859375, 'bn2': 0.0005564689636230469, 'residual_add_relu2': 0.000766754150390625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010504722595214844, 'bn1': 0.0003323554992675781, 'relu1': 0.00017595291137695312, 'conv2': 0.0013358592987060547, 'bn2': 0.0004241466522216797, 'conv3': 0.00043272972106933594, 'residual_add_relu2': 0.00039458274841308594}\n",
      "{'conv1': 0.0013175010681152344, 'bn1': 0.00032520294189453125, 'relu1': 0.00018906593322753906, 'conv2': 0.0013096332550048828, 'bn2': 0.000324249267578125, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007922649383544922, 'bn1': 0.00020647048950195312, 'relu1': 0.00010037422180175781, 'conv2': 0.0011548995971679688, 'bn2': 0.00019931793212890625, 'conv3': 0.0003559589385986328, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011513233184814453, 'bn1': 0.00019621849060058594, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.0001976490020751953, 'residual_add_relu2': 0.00020313262939453125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006589889526367188, 'bn1': 0.00011992454528808594, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011391639709472656, 'bn2': 0.00011873245239257812, 'conv3': 0.0002942085266113281, 'residual_add_relu2': 0.00010967254638671875}\n",
      "{'conv1': 0.0011398792266845703, 'bn1': 0.0001201629638671875, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011358261108398438, 'bn2': 0.0001087188720703125, 'residual_add_relu2': 0.00010848045349121094}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 193\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001644134521484375, 'bn1': 0.0005629062652587891, 'relu1': 0.0003261566162109375, 'conv2': 0.0016329288482666016, 'bn2': 0.0005552768707275391, 'residual_add_relu2': 0.0007646083831787109}\n",
      "{'conv1': 0.001628875732421875, 'bn1': 0.0005526542663574219, 'relu1': 0.0003254413604736328, 'conv2': 0.001627206802368164, 'bn2': 0.0005476474761962891, 'residual_add_relu2': 0.0007674694061279297}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010590553283691406, 'bn1': 0.00032067298889160156, 'relu1': 0.00017309188842773438, 'conv2': 0.0013031959533691406, 'bn2': 0.000308990478515625, 'conv3': 0.00040435791015625, 'residual_add_relu2': 0.000392913818359375}\n",
      "{'conv1': 0.0013041496276855469, 'bn1': 0.0003287792205810547, 'relu1': 0.0001747608184814453, 'conv2': 0.0013031959533691406, 'bn2': 0.0003097057342529297, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007848739624023438, 'bn1': 0.000194549560546875, 'relu1': 9.655952453613281e-05, 'conv2': 0.001146078109741211, 'bn2': 0.00019598007202148438, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011568069458007812, 'bn1': 0.0002002716064453125, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.00020575523376464844, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006589889526367188, 'bn1': 0.0001285076141357422, 'relu1': 6.103515625e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.00011873245239257812, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011539459228515625}\n",
      "{'conv1': 0.0011472702026367188, 'bn1': 0.00012969970703125, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011398792266845703, 'bn2': 0.00011587142944335938, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 194\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016446113586425781, 'bn1': 0.0005578994750976562, 'relu1': 0.00032711029052734375, 'conv2': 0.0016338825225830078, 'bn2': 0.0005507469177246094, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.0016312599182128906, 'bn1': 0.0005431175231933594, 'relu1': 0.00032401084899902344, 'conv2': 0.0016245841979980469, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010426044464111328, 'bn1': 0.00032901763916015625, 'relu1': 0.0001773834228515625, 'conv2': 0.0013058185577392578, 'bn2': 0.00031876564025878906, 'conv3': 0.0004024505615234375, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.001310586929321289, 'bn1': 0.00031948089599609375, 'relu1': 0.0001742839813232422, 'conv2': 0.0013060569763183594, 'bn2': 0.00031948089599609375, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007901191711425781, 'bn1': 0.00020241737365722656, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.000217437744140625, 'conv3': 0.00035953521728515625, 'residual_add_relu2': 0.00020647048950195312}\n",
      "{'conv1': 0.001157522201538086, 'bn1': 0.00021600723266601562, 'relu1': 0.00010442733764648438, 'conv2': 0.001155853271484375, 'bn2': 0.00021004676818847656, 'residual_add_relu2': 0.0002079010009765625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000667572021484375, 'bn1': 0.00013256072998046875, 'relu1': 6.198883056640625e-05, 'conv2': 0.0011448860168457031, 'bn2': 0.0001246929168701172, 'conv3': 0.00029540061950683594, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011448860168457031, 'bn1': 0.00012302398681640625, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011386871337890625, 'bn2': 0.00011444091796875, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 195\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001651763916015625, 'bn1': 0.0005772113800048828, 'relu1': 0.00032830238342285156, 'conv2': 0.0016257762908935547, 'bn2': 0.0005512237548828125, 'residual_add_relu2': 0.0007681846618652344}\n",
      "{'conv1': 0.0016291141510009766, 'bn1': 0.0005481243133544922, 'relu1': 0.00032401084899902344, 'conv2': 0.0016248226165771484, 'bn2': 0.0005517005920410156, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001050710678100586, 'bn1': 0.00032901763916015625, 'relu1': 0.00017452239990234375, 'conv2': 0.0013074874877929688, 'bn2': 0.0003123283386230469, 'conv3': 0.0004019737243652344, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013043880462646484, 'bn1': 0.0003218650817871094, 'relu1': 0.00017380714416503906, 'conv2': 0.0013020038604736328, 'bn2': 0.0003113746643066406, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007870197296142578, 'bn1': 0.0002079010009765625, 'relu1': 0.00010061264038085938, 'conv2': 0.0011568069458007812, 'bn2': 0.0002067089080810547, 'conv3': 0.0003571510314941406, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.00115966796875, 'bn1': 0.000202178955078125, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.0001964569091796875, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006649494171142578, 'bn1': 0.00012421607971191406, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011401176452636719, 'bn2': 0.00011491775512695312, 'conv3': 0.0002923011779785156, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011429786682128906, 'bn1': 0.0001227855682373047, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011444091796875, 'bn2': 0.00016379356384277344, 'residual_add_relu2': 0.00011849403381347656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 196\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001638650894165039, 'bn1': 0.0005564689636230469, 'relu1': 0.00032448768615722656, 'conv2': 0.0016214847564697266, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.0007643699645996094}\n",
      "{'conv1': 0.0016219615936279297, 'bn1': 0.0005452632904052734, 'relu1': 0.00032329559326171875, 'conv2': 0.001617431640625, 'bn2': 0.0005636215209960938, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010457038879394531, 'bn1': 0.0003151893615722656, 'relu1': 0.00018405914306640625, 'conv2': 0.0013043880462646484, 'bn2': 0.0003409385681152344, 'conv3': 0.00040078163146972656, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013020038604736328, 'bn1': 0.00031375885009765625, 'relu1': 0.00017499923706054688, 'conv2': 0.0013015270233154297, 'bn2': 0.00031113624572753906, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008091926574707031, 'bn1': 0.00020933151245117188, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00019812583923339844, 'conv3': 0.000354766845703125, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011777877807617188, 'bn1': 0.00020170211791992188, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.00020194053649902344, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006654262542724609, 'bn1': 0.00012159347534179688, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011398792266845703, 'bn2': 0.00011515617370605469, 'conv3': 0.0002911090850830078, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.001140594482421875, 'bn1': 0.0001285076141357422, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.00012445449829101562, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 197\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016582012176513672, 'bn1': 0.0005507469177246094, 'relu1': 0.0003216266632080078, 'conv2': 0.0016345977783203125, 'bn2': 0.0005345344543457031, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.001627206802368164, 'bn1': 0.0005364418029785156, 'relu1': 0.0003228187561035156, 'conv2': 0.0016243457794189453, 'bn2': 0.0005364418029785156, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010356903076171875, 'bn1': 0.00030541419982910156, 'relu1': 0.00017023086547851562, 'conv2': 0.0013012886047363281, 'bn2': 0.00030875205993652344, 'conv3': 0.00039696693420410156, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0012993812561035156, 'bn1': 0.00031685829162597656, 'relu1': 0.00017380714416503906, 'conv2': 0.0013027191162109375, 'bn2': 0.0003173351287841797, 'residual_add_relu2': 0.000392913818359375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007886886596679688, 'bn1': 0.00019741058349609375, 'relu1': 9.632110595703125e-05, 'conv2': 0.001146554946899414, 'bn2': 0.00018835067749023438, 'conv3': 0.0003533363342285156, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.00115203857421875, 'bn1': 0.0001990795135498047, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.0001976490020751953, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006570816040039062, 'bn1': 0.00012540817260742188, 'relu1': 6.079673767089844e-05, 'conv2': 0.001146554946899414, 'bn2': 0.0001201629638671875, 'conv3': 0.0002968311309814453, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.001142263412475586, 'bn1': 0.00012636184692382812, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011401176452636719, 'bn2': 0.00011801719665527344, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 198\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001641988754272461, 'bn1': 0.0005457401275634766, 'relu1': 0.0003218650817871094, 'conv2': 0.0016341209411621094, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.0007627010345458984}\n",
      "{'conv1': 0.0016303062438964844, 'bn1': 0.0005462169647216797, 'relu1': 0.0003228187561035156, 'conv2': 0.001621246337890625, 'bn2': 0.0005338191986083984, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001043081283569336, 'bn1': 0.0003142356872558594, 'relu1': 0.00017380714416503906, 'conv2': 0.0013017654418945312, 'bn2': 0.00030684471130371094, 'conv3': 0.000400543212890625, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013051033020019531, 'bn1': 0.0003197193145751953, 'relu1': 0.00017452239990234375, 'conv2': 0.0013039112091064453, 'bn2': 0.0003113746643066406, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007879734039306641, 'bn1': 0.00020313262939453125, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00019407272338867188, 'conv3': 0.00035119056701660156, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011508464813232422, 'bn1': 0.0002014636993408203, 'relu1': 9.870529174804688e-05, 'conv2': 0.001146554946899414, 'bn2': 0.00019431114196777344, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006566047668457031, 'bn1': 0.00011777877807617188, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011403560638427734, 'bn2': 0.00018143653869628906, 'conv3': 0.00029778480529785156, 'residual_add_relu2': 0.00011372566223144531}\n",
      "{'conv1': 0.0011456012725830078, 'bn1': 0.00012254714965820312, 'relu1': 5.8650970458984375e-05, 'conv2': 0.001138448715209961, 'bn2': 0.00011539459228515625, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 199\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016589164733886719, 'bn1': 0.0005710124969482422, 'relu1': 0.00032591819763183594, 'conv2': 0.0016369819641113281, 'bn2': 0.0005574226379394531, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016312599182128906, 'bn1': 0.0005486011505126953, 'relu1': 0.0003273487091064453, 'conv2': 0.0016248226165771484, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010445117950439453, 'bn1': 0.0003266334533691406, 'relu1': 0.00017571449279785156, 'conv2': 0.0013070106506347656, 'bn2': 0.000316619873046875, 'conv3': 0.00040340423583984375, 'residual_add_relu2': 0.0003962516784667969}\n",
      "{'conv1': 0.0013058185577392578, 'bn1': 0.00031495094299316406, 'relu1': 0.00017333030700683594, 'conv2': 0.0013000965118408203, 'bn2': 0.00030803680419921875, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007855892181396484, 'bn1': 0.0002014636993408203, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00019311904907226562, 'conv3': 0.0003542900085449219, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011510848999023438, 'bn1': 0.00021767616271972656, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00020313262939453125, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006580352783203125, 'bn1': 0.00012826919555664062, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011413097381591797, 'bn2': 0.00011730194091796875, 'conv3': 0.0002961158752441406, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011413097381591797, 'bn1': 0.00013017654418945312, 'relu1': 6.198883056640625e-05, 'conv2': 0.0011413097381591797, 'bn2': 0.00012254714965820312, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 200\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016505718231201172, 'bn1': 0.0005612373352050781, 'relu1': 0.0003275871276855469, 'conv2': 0.0016243457794189453, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016295909881591797, 'bn1': 0.0005469322204589844, 'relu1': 0.00032329559326171875, 'conv2': 0.0016160011291503906, 'bn2': 0.0005373954772949219, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010514259338378906, 'bn1': 0.0003178119659423828, 'relu1': 0.00017261505126953125, 'conv2': 0.0012998580932617188, 'bn2': 0.0003027915954589844, 'conv3': 0.0003943443298339844, 'residual_add_relu2': 0.0004000663757324219}\n",
      "{'conv1': 0.0013048648834228516, 'bn1': 0.0003070831298828125, 'relu1': 0.00017189979553222656, 'conv2': 0.0012962818145751953, 'bn2': 0.00030040740966796875, 'residual_add_relu2': 0.0003876686096191406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007798671722412109, 'bn1': 0.00019288063049316406, 'relu1': 0.00010919570922851562, 'conv2': 0.0011484622955322266, 'bn2': 0.000194549560546875, 'conv3': 0.0003504753112792969, 'residual_add_relu2': 0.0002033710479736328}\n",
      "{'conv1': 0.0011494159698486328, 'bn1': 0.0001957416534423828, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00019550323486328125, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006570816040039062, 'bn1': 0.0001227855682373047, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011410713195800781, 'bn2': 0.00013446807861328125, 'conv3': 0.0002961158752441406, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.0011458396911621094, 'bn1': 0.00012969970703125, 'relu1': 6.246566772460938e-05, 'conv2': 0.0011425018310546875, 'bn2': 0.00012612342834472656, 'residual_add_relu2': 0.00011181831359863281}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 201\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016553401947021484, 'bn1': 0.0005538463592529297, 'relu1': 0.00032258033752441406, 'conv2': 0.0016279220581054688, 'bn2': 0.0005445480346679688, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016317367553710938, 'bn1': 0.0005509853363037109, 'relu1': 0.00032258033752441406, 'conv2': 0.001634359359741211, 'bn2': 0.0005354881286621094, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010423660278320312, 'bn1': 0.00030803680419921875, 'relu1': 0.0001704692840576172, 'conv2': 0.0013058185577392578, 'bn2': 0.00030303001403808594, 'conv3': 0.00043129920959472656, 'residual_add_relu2': 0.00039267539978027344}\n",
      "{'conv1': 0.0013072490692138672, 'bn1': 0.0003192424774169922, 'relu1': 0.00017404556274414062, 'conv2': 0.0012998580932617188, 'bn2': 0.00031113624572753906, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007872581481933594, 'bn1': 0.00019884109497070312, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.00019407272338867188, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011501312255859375, 'bn1': 0.00020074844360351562, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011610984802246094, 'bn2': 0.0001990795135498047, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006539821624755859, 'bn1': 0.00011563301086425781, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011374950408935547, 'bn2': 0.0001087188720703125, 'conv3': 0.0002841949462890625, 'residual_add_relu2': 0.00011348724365234375}\n",
      "{'conv1': 0.001138448715209961, 'bn1': 0.00011610984802246094, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011336803436279297, 'bn2': 0.00010752677917480469, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 202\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001645803451538086, 'bn1': 0.0005452632904052734, 'relu1': 0.0003218650817871094, 'conv2': 0.0016260147094726562, 'bn2': 0.0005333423614501953, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016224384307861328, 'bn1': 0.0005354881286621094, 'relu1': 0.0003230571746826172, 'conv2': 0.0016286373138427734, 'bn2': 0.0005300045013427734, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010380744934082031, 'bn1': 0.00030541419982910156, 'relu1': 0.00017070770263671875, 'conv2': 0.0012979507446289062, 'bn2': 0.0003018379211425781, 'conv3': 0.00039577484130859375, 'residual_add_relu2': 0.000408172607421875}\n",
      "{'conv1': 0.0013074874877929688, 'bn1': 0.0003273487091064453, 'relu1': 0.00017571449279785156, 'conv2': 0.0013039112091064453, 'bn2': 0.00031113624572753906, 'residual_add_relu2': 0.00039315223693847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007884502410888672, 'bn1': 0.0001957416534423828, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00018739700317382812, 'conv3': 0.00035190582275390625, 'residual_add_relu2': 0.0002033710479736328}\n",
      "{'conv1': 0.0011477470397949219, 'bn1': 0.0001938343048095703, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011439323425292969, 'bn2': 0.0001900196075439453, 'residual_add_relu2': 0.00020313262939453125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006532669067382812, 'bn1': 0.0001220703125, 'relu1': 5.888938903808594e-05, 'conv2': 0.001138448715209961, 'bn2': 0.00010728836059570312, 'conv3': 0.0002899169921875, 'residual_add_relu2': 0.00010895729064941406}\n",
      "{'conv1': 0.00113677978515625, 'bn1': 0.00012230873107910156, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011370182037353516, 'bn2': 0.000118255615234375, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 203\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016453266143798828, 'bn1': 0.000553131103515625, 'relu1': 0.00032448768615722656, 'conv2': 0.0016298294067382812, 'bn2': 0.0005512237548828125, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.001634359359741211, 'bn1': 0.000545501708984375, 'relu1': 0.00032448768615722656, 'conv2': 0.0016222000122070312, 'bn2': 0.0005466938018798828, 'residual_add_relu2': 0.0007662773132324219}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010471343994140625, 'bn1': 0.00033664703369140625, 'relu1': 0.00017404556274414062, 'conv2': 0.001306295394897461, 'bn2': 0.00031757354736328125, 'conv3': 0.00040221214294433594, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.001299142837524414, 'bn1': 0.00031757354736328125, 'relu1': 0.00017309188842773438, 'conv2': 0.001300811767578125, 'bn2': 0.0003178119659423828, 'residual_add_relu2': 0.000392913818359375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007920265197753906, 'bn1': 0.0002105236053466797, 'relu1': 0.00010180473327636719, 'conv2': 0.0011572837829589844, 'bn2': 0.00020694732666015625, 'conv3': 0.00035881996154785156, 'residual_add_relu2': 0.0002067089080810547}\n",
      "{'conv1': 0.0011568069458007812, 'bn1': 0.00021839141845703125, 'relu1': 0.00010275840759277344, 'conv2': 0.0011551380157470703, 'bn2': 0.0002162456512451172, 'residual_add_relu2': 0.00020837783813476562}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000667572021484375, 'bn1': 0.0001308917999267578, 'relu1': 6.270408630371094e-05, 'conv2': 0.0011448860168457031, 'bn2': 0.00012612342834472656, 'conv3': 0.00029778480529785156, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011463165283203125, 'bn1': 0.00012183189392089844, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011374950408935547, 'bn2': 0.00011348724365234375, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 204\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016579627990722656, 'bn1': 0.0005619525909423828, 'relu1': 0.00032591819763183594, 'conv2': 0.0016317367553710938, 'bn2': 0.000537872314453125, 'residual_add_relu2': 0.0007648468017578125}\n",
      "{'conv1': 0.0016238689422607422, 'bn1': 0.0005447864532470703, 'relu1': 0.0003294944763183594, 'conv2': 0.0016188621520996094, 'bn2': 0.0005502700805664062, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010519027709960938, 'bn1': 0.0003197193145751953, 'relu1': 0.00017380714416503906, 'conv2': 0.001302957534790039, 'bn2': 0.000308990478515625, 'conv3': 0.0003993511199951172, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013051033020019531, 'bn1': 0.0003345012664794922, 'relu1': 0.0001819133758544922, 'conv2': 0.001310110092163086, 'bn2': 0.0003230571746826172, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007936954498291016, 'bn1': 0.00022482872009277344, 'relu1': 0.000102996826171875, 'conv2': 0.0011627674102783203, 'bn2': 0.0002148151397705078, 'conv3': 0.0003592967987060547, 'residual_add_relu2': 0.00020647048950195312}\n",
      "{'conv1': 0.0011556148529052734, 'bn1': 0.00021004676818847656, 'relu1': 0.00010085105895996094, 'conv2': 0.0011529922485351562, 'bn2': 0.0002162456512451172, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006635189056396484, 'bn1': 0.00013256072998046875, 'relu1': 6.198883056640625e-05, 'conv2': 0.0011458396911621094, 'bn2': 0.00011348724365234375, 'conv3': 0.00029277801513671875, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011420249938964844, 'bn1': 0.00012254714965820312, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011370182037353516, 'bn2': 0.00011801719665527344, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 205\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016469955444335938, 'bn1': 0.0005509853363037109, 'relu1': 0.00032329559326171875, 'conv2': 0.0016293525695800781, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.001622915267944336, 'bn1': 0.0005376338958740234, 'relu1': 0.0003268718719482422, 'conv2': 0.0016252994537353516, 'bn2': 0.0005662441253662109, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010519027709960938, 'bn1': 0.0003261566162109375, 'relu1': 0.0001766681671142578, 'conv2': 0.001308441162109375, 'bn2': 0.00032067298889160156, 'conv3': 0.00040650367736816406, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013096332550048828, 'bn1': 0.0003323554992675781, 'relu1': 0.00017762184143066406, 'conv2': 0.0013093948364257812, 'bn2': 0.0003304481506347656, 'residual_add_relu2': 0.0003952980041503906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007936954498291016, 'bn1': 0.0002028942108154297, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00019693374633789062, 'conv3': 0.00035262107849121094, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011510848999023438, 'bn1': 0.0001983642578125, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011582374572753906, 'bn2': 0.0001995563507080078, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006570816040039062, 'bn1': 0.00012254714965820312, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011401176452636719, 'bn2': 0.00011563301086425781, 'conv3': 0.0002932548522949219, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.00012969970703125, 'relu1': 6.103515625e-05, 'conv2': 0.0011403560638427734, 'bn2': 0.00011587142944335938, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 206\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016384124755859375, 'bn1': 0.0005602836608886719, 'relu1': 0.0003266334533691406, 'conv2': 0.001626729965209961, 'bn2': 0.0005433559417724609, 'residual_add_relu2': 0.0007643699645996094}\n",
      "{'conv1': 0.0016350746154785156, 'bn1': 0.0005583763122558594, 'relu1': 0.0003237724304199219, 'conv2': 0.0016269683837890625, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010516643524169922, 'bn1': 0.00031685829162597656, 'relu1': 0.0001723766326904297, 'conv2': 0.0013036727905273438, 'bn2': 0.00030994415283203125, 'conv3': 0.00040340423583984375, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013041496276855469, 'bn1': 0.0003256797790527344, 'relu1': 0.00017523765563964844, 'conv2': 0.0013039112091064453, 'bn2': 0.00032639503479003906, 'residual_add_relu2': 0.00039267539978027344}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007886886596679688, 'bn1': 0.00020313262939453125, 'relu1': 0.0001010894775390625, 'conv2': 0.00115203857421875, 'bn2': 0.00019788742065429688, 'conv3': 0.0003561973571777344, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011529922485351562, 'bn1': 0.00019812583923339844, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011434555053710938, 'bn2': 0.00018835067749023438, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006580352783203125, 'bn1': 0.0001270771026611328, 'relu1': 6.031990051269531e-05, 'conv2': 0.001142263412475586, 'bn2': 0.00012612342834472656, 'conv3': 0.00029587745666503906, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.001148223876953125, 'bn1': 0.00012564659118652344, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011398792266845703, 'bn2': 0.00011897087097167969, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 207\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016436576843261719, 'bn1': 0.0005583763122558594, 'relu1': 0.0003266334533691406, 'conv2': 0.0016260147094726562, 'bn2': 0.0005502700805664062, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016329288482666016, 'bn1': 0.0005424022674560547, 'relu1': 0.0003223419189453125, 'conv2': 0.0016248226165771484, 'bn2': 0.0005323886871337891, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010576248168945312, 'bn1': 0.0003256797790527344, 'relu1': 0.00017571449279785156, 'conv2': 0.0013074874877929688, 'bn2': 0.0003185272216796875, 'conv3': 0.00040531158447265625, 'residual_add_relu2': 0.0003952980041503906}\n",
      "{'conv1': 0.0013155937194824219, 'bn1': 0.0003249645233154297, 'relu1': 0.0001761913299560547, 'conv2': 0.0013043880462646484, 'bn2': 0.00031828880310058594, 'residual_add_relu2': 0.000392913818359375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007894039154052734, 'bn1': 0.00021004676818847656, 'relu1': 0.00010085105895996094, 'conv2': 0.0011529922485351562, 'bn2': 0.00020194053649902344, 'conv3': 0.0003573894500732422, 'residual_add_relu2': 0.00020647048950195312}\n",
      "{'conv1': 0.0011556148529052734, 'bn1': 0.000217437744140625, 'relu1': 0.00010085105895996094, 'conv2': 0.0011534690856933594, 'bn2': 0.00020313262939453125, 'residual_add_relu2': 0.00020575523376464844}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006670951843261719, 'bn1': 0.000125885009765625, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011413097381591797, 'bn2': 0.00012946128845214844, 'conv3': 0.00029850006103515625, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.0001227855682373047, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011374950408935547, 'bn2': 0.00011515617370605469, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 208\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016655921936035156, 'bn1': 0.0005717277526855469, 'relu1': 0.00033164024353027344, 'conv2': 0.001651763916015625, 'bn2': 0.0005497932434082031, 'residual_add_relu2': 0.0007700920104980469}\n",
      "{'conv1': 0.0016582012176513672, 'bn1': 0.0005512237548828125, 'relu1': 0.0003285408020019531, 'conv2': 0.0016491413116455078, 'bn2': 0.0005438327789306641, 'residual_add_relu2': 0.0007734298706054688}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010676383972167969, 'bn1': 0.0003323554992675781, 'relu1': 0.0001842975616455078, 'conv2': 0.0013384819030761719, 'bn2': 0.00031375885009765625, 'conv3': 0.0004138946533203125, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013275146484375, 'bn1': 0.0003151893615722656, 'relu1': 0.00017714500427246094, 'conv2': 0.0013132095336914062, 'bn2': 0.0003123283386230469, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007960796356201172, 'bn1': 0.00020623207092285156, 'relu1': 0.00010442733764648438, 'conv2': 0.0011608600616455078, 'bn2': 0.00020503997802734375, 'conv3': 0.00035572052001953125, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011572837829589844, 'bn1': 0.0001964569091796875, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00019216537475585938, 'residual_add_relu2': 0.00022125244140625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006647109985351562, 'bn1': 0.00012230873107910156, 'relu1': 5.8650970458984375e-05, 'conv2': 0.001146554946899414, 'bn2': 0.00011205673217773438, 'conv3': 0.00028967857360839844, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011453628540039062, 'bn1': 0.00011467933654785156, 'relu1': 5.698204040527344e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.0001125335693359375, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 209\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016427040100097656, 'bn1': 0.0005555152893066406, 'relu1': 0.0003247261047363281, 'conv2': 0.0016307830810546875, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.001631021499633789, 'bn1': 0.0005764961242675781, 'relu1': 0.0003273487091064453, 'conv2': 0.0016326904296875, 'bn2': 0.0005512237548828125, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010483264923095703, 'bn1': 0.0003197193145751953, 'relu1': 0.0001742839813232422, 'conv2': 0.0013124942779541016, 'bn2': 0.0003097057342529297, 'conv3': 0.0004000663757324219, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013117790222167969, 'bn1': 0.0003170967102050781, 'relu1': 0.0001728534698486328, 'conv2': 0.0013091564178466797, 'bn2': 0.00031757354736328125, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007929801940917969, 'bn1': 0.0002028942108154297, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011568069458007812, 'bn2': 0.0001983642578125, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.0011599063873291016, 'bn1': 0.00020003318786621094, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.0001983642578125, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006620883941650391, 'bn1': 0.00012159347534179688, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00011372566223144531, 'conv3': 0.0002892017364501953, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011563301086425781, 'bn1': 0.0001366138458251953, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00011610984802246094, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 210\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016498565673828125, 'bn1': 0.0005564689636230469, 'relu1': 0.0003249645233154297, 'conv2': 0.0016391277313232422, 'bn2': 0.0005433559417724609, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016388893127441406, 'bn1': 0.0005438327789306641, 'relu1': 0.00032258033752441406, 'conv2': 0.0016245841979980469, 'bn2': 0.0005321502685546875, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001043558120727539, 'bn1': 0.0003070831298828125, 'relu1': 0.0001709461212158203, 'conv2': 0.0013058185577392578, 'bn2': 0.00030159950256347656, 'conv3': 0.0003933906555175781, 'residual_add_relu2': 0.00038886070251464844}\n",
      "{'conv1': 0.001312255859375, 'bn1': 0.00031447410583496094, 'relu1': 0.00017333030700683594, 'conv2': 0.0013060569763183594, 'bn2': 0.00030231475830078125, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007908344268798828, 'bn1': 0.00019407272338867188, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.0001964569091796875, 'conv3': 0.0003516674041748047, 'residual_add_relu2': 0.0002033710479736328}\n",
      "{'conv1': 0.0011589527130126953, 'bn1': 0.00019884109497070312, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00018858909606933594, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.00066375732421875, 'bn1': 0.0001251697540283203, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.00011992454528808594, 'conv3': 0.00029730796813964844, 'residual_add_relu2': 0.00011229515075683594}\n",
      "{'conv1': 0.0011496543884277344, 'bn1': 0.0001277923583984375, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.00011539459228515625, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 211\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016486644744873047, 'bn1': 0.0005624294281005859, 'relu1': 0.000324249267578125, 'conv2': 0.0016312599182128906, 'bn2': 0.0005490779876708984, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016319751739501953, 'bn1': 0.0005447864532470703, 'relu1': 0.0003235340118408203, 'conv2': 0.0016245841979980469, 'bn2': 0.0005426406860351562, 'residual_add_relu2': 0.0007619857788085938}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010459423065185547, 'bn1': 0.00033783912658691406, 'relu1': 0.00017404556274414062, 'conv2': 0.0013158321380615234, 'bn2': 0.0003192424774169922, 'conv3': 0.00040531158447265625, 'residual_add_relu2': 0.00039315223693847656}\n",
      "{'conv1': 0.0013120174407958984, 'bn1': 0.0003185272216796875, 'relu1': 0.00017452239990234375, 'conv2': 0.001310586929321289, 'bn2': 0.00031065940856933594, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007889270782470703, 'bn1': 0.0002028942108154297, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011582374572753906, 'bn2': 0.0001990795135498047, 'conv3': 0.0003552436828613281, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.001178741455078125, 'bn1': 0.000209808349609375, 'relu1': 0.00010013580322265625, 'conv2': 0.001157999038696289, 'bn2': 0.00020837783813476562, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.00066375732421875, 'bn1': 0.00012683868408203125, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011508464813232422, 'bn2': 0.00012946128845214844, 'conv3': 0.000301361083984375, 'residual_add_relu2': 0.00011324882507324219}\n",
      "{'conv1': 0.001153707504272461, 'bn1': 0.000133514404296875, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011513233184814453, 'bn2': 0.0001232624053955078, 'residual_add_relu2': 0.0001125335693359375}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 212\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016508102416992188, 'bn1': 0.0005700588226318359, 'relu1': 0.0003256797790527344, 'conv2': 0.0016274452209472656, 'bn2': 0.0005457401275634766, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016319751739501953, 'bn1': 0.0005433559417724609, 'relu1': 0.00032448768615722656, 'conv2': 0.0016300678253173828, 'bn2': 0.0005512237548828125, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010514259338378906, 'bn1': 0.0003173351287841797, 'relu1': 0.00017309188842773438, 'conv2': 0.0013115406036376953, 'bn2': 0.00030422210693359375, 'conv3': 0.0003952980041503906, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.001308441162109375, 'bn1': 0.0003139972686767578, 'relu1': 0.0001735687255859375, 'conv2': 0.0013082027435302734, 'bn2': 0.00030875205993652344, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007908344268798828, 'bn1': 0.00021457672119140625, 'relu1': 0.00010776519775390625, 'conv2': 0.0011615753173828125, 'bn2': 0.00020194053649902344, 'conv3': 0.0003523826599121094, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011553764343261719, 'bn1': 0.0001926422119140625, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00019431114196777344, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006616115570068359, 'bn1': 0.0001220703125, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00011420249938964844, 'conv3': 0.0002903938293457031, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011532306671142578, 'bn1': 0.0001289844512939453, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.00012421607971191406, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 213\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016531944274902344, 'bn1': 0.00055694580078125, 'relu1': 0.0003254413604736328, 'conv2': 0.0016393661499023438, 'bn2': 0.0005428791046142578, 'residual_add_relu2': 0.0007648468017578125}\n",
      "{'conv1': 0.0016484260559082031, 'bn1': 0.0005679130554199219, 'relu1': 0.0003273487091064453, 'conv2': 0.0016324520111083984, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0015473365783691406, 'bn1': 0.0003688335418701172, 'relu1': 0.00018167495727539062, 'conv2': 0.0013225078582763672, 'bn2': 0.00034356117248535156, 'conv3': 0.0004055500030517578, 'residual_add_relu2': 0.0003936290740966797}\n",
      "{'conv1': 0.0013318061828613281, 'bn1': 0.00033926963806152344, 'relu1': 0.0001862049102783203, 'conv2': 0.0013232231140136719, 'bn2': 0.0003273487091064453, 'residual_add_relu2': 0.00039649009704589844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008001327514648438, 'bn1': 0.00021696090698242188, 'relu1': 0.00010228157043457031, 'conv2': 0.001163482666015625, 'bn2': 0.00021195411682128906, 'conv3': 0.00035881996154785156, 'residual_add_relu2': 0.00020837783813476562}\n",
      "{'conv1': 0.0011677742004394531, 'bn1': 0.0002162456512451172, 'relu1': 0.00010466575622558594, 'conv2': 0.0011627674102783203, 'bn2': 0.00020813941955566406, 'residual_add_relu2': 0.00021195411682128906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006711483001708984, 'bn1': 0.0001418590545654297, 'relu1': 7.319450378417969e-05, 'conv2': 0.0011594295501708984, 'bn2': 0.00013566017150878906, 'conv3': 0.00030040740966796875, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011515617370605469, 'bn1': 0.00012254714965820312, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011463165283203125, 'bn2': 0.00011849403381347656, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 214\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016412734985351562, 'bn1': 0.0005724430084228516, 'relu1': 0.0003285408020019531, 'conv2': 0.0016436576843261719, 'bn2': 0.0005679130554199219, 'residual_add_relu2': 0.0007710456848144531}\n",
      "{'conv1': 0.0016341209411621094, 'bn1': 0.0005469322204589844, 'relu1': 0.00032329559326171875, 'conv2': 0.0016341209411621094, 'bn2': 0.0005400180816650391, 'residual_add_relu2': 0.0007643699645996094}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010495185852050781, 'bn1': 0.00032258033752441406, 'relu1': 0.00017380714416503906, 'conv2': 0.0013120174407958984, 'bn2': 0.0003180503845214844, 'conv3': 0.0004012584686279297, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.001310110092163086, 'bn1': 0.0003142356872558594, 'relu1': 0.00017404556274414062, 'conv2': 0.0013086795806884766, 'bn2': 0.00031256675720214844, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007905960083007812, 'bn1': 0.000209808349609375, 'relu1': 0.00010251998901367188, 'conv2': 0.0011649131774902344, 'bn2': 0.00020575523376464844, 'conv3': 0.00035762786865234375, 'residual_add_relu2': 0.00020766258239746094}\n",
      "{'conv1': 0.0011730194091796875, 'bn1': 0.00021576881408691406, 'relu1': 0.0001010894775390625, 'conv2': 0.0011610984802246094, 'bn2': 0.00020384788513183594, 'residual_add_relu2': 0.0002071857452392578}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006651878356933594, 'bn1': 0.00013303756713867188, 'relu1': 6.151199340820312e-05, 'conv2': 0.001153707504272461, 'bn2': 0.00012350082397460938, 'conv3': 0.0003006458282470703, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.0011534690856933594, 'bn1': 0.0001308917999267578, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.0001347064971923828, 'residual_add_relu2': 0.00011301040649414062}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 215\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016567707061767578, 'bn1': 0.0005571842193603516, 'relu1': 0.00032591819763183594, 'conv2': 0.001634359359741211, 'bn2': 0.0005404949188232422, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.001631021499633789, 'bn1': 0.0005450248718261719, 'relu1': 0.0003223419189453125, 'conv2': 0.0016314983367919922, 'bn2': 0.00054931640625, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010492801666259766, 'bn1': 0.00031447410583496094, 'relu1': 0.00017333030700683594, 'conv2': 0.0013115406036376953, 'bn2': 0.0003113746643066406, 'conv3': 0.000400543212890625, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013093948364257812, 'bn1': 0.00031185150146484375, 'relu1': 0.0001728534698486328, 'conv2': 0.0013072490692138672, 'bn2': 0.0003132820129394531, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007941722869873047, 'bn1': 0.0002014636993408203, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011589527130126953, 'bn2': 0.00019073486328125, 'conv3': 0.0003497600555419922, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.001154184341430664, 'bn1': 0.00019168853759765625, 'relu1': 9.512901306152344e-05, 'conv2': 0.001149892807006836, 'bn2': 0.00019025802612304688, 'residual_add_relu2': 0.00020265579223632812}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006535053253173828, 'bn1': 0.00011706352233886719, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011444091796875, 'bn2': 0.0001163482666015625, 'conv3': 0.00028896331787109375, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.001148223876953125, 'bn1': 0.0001289844512939453, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.0001277923583984375, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 216\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016603469848632812, 'bn1': 0.0005576610565185547, 'relu1': 0.0003230571746826172, 'conv2': 0.0016367435455322266, 'bn2': 0.0005731582641601562, 'residual_add_relu2': 0.0007703304290771484}\n",
      "{'conv1': 0.0016369819641113281, 'bn1': 0.0005545616149902344, 'relu1': 0.000324249267578125, 'conv2': 0.0016300678253173828, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.0007619857788085938}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010478496551513672, 'bn1': 0.0003159046173095703, 'relu1': 0.00017261505126953125, 'conv2': 0.0013110637664794922, 'bn2': 0.0003085136413574219, 'conv3': 0.000400543212890625, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013158321380615234, 'bn1': 0.0003333091735839844, 'relu1': 0.0001761913299560547, 'conv2': 0.0013141632080078125, 'bn2': 0.0003180503845214844, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007891654968261719, 'bn1': 0.00020694732666015625, 'relu1': 0.00010347366333007812, 'conv2': 0.0011646747589111328, 'bn2': 0.00020575523376464844, 'conv3': 0.0003819465637207031, 'residual_add_relu2': 0.0002129077911376953}\n",
      "{'conv1': 0.0011682510375976562, 'bn1': 0.0002002716064453125, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.00019860267639160156, 'residual_add_relu2': 0.00020599365234375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006649494171142578, 'bn1': 0.00012445449829101562, 'relu1': 6.103515625e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.00012230873107910156, 'conv3': 0.00029206275939941406, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.001148223876953125, 'bn1': 0.00012350082397460938, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011444091796875, 'bn2': 0.00010752677917480469, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 217\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016489028930664062, 'bn1': 0.0005631446838378906, 'relu1': 0.000324249267578125, 'conv2': 0.0016329288482666016, 'bn2': 0.0005333423614501953, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016298294067382812, 'bn1': 0.0005419254302978516, 'relu1': 0.00032210350036621094, 'conv2': 0.0016210079193115234, 'bn2': 0.0005440711975097656, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001047372817993164, 'bn1': 0.00031757354736328125, 'relu1': 0.000171661376953125, 'conv2': 0.0013089179992675781, 'bn2': 0.00031304359436035156, 'conv3': 0.00040030479431152344, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.001310110092163086, 'bn1': 0.0003139972686767578, 'relu1': 0.0001735687255859375, 'conv2': 0.0013060569763183594, 'bn2': 0.0003046989440917969, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007846355438232422, 'bn1': 0.00019168853759765625, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011534690856933594, 'bn2': 0.00020432472229003906, 'conv3': 0.00035500526428222656, 'residual_add_relu2': 0.00020647048950195312}\n",
      "{'conv1': 0.0011680126190185547, 'bn1': 0.00020384788513183594, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.00018787384033203125, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006556510925292969, 'bn1': 0.0001323223114013672, 'relu1': 6.151199340820312e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.000118255615234375, 'conv3': 0.0002918243408203125, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011491775512695312, 'bn1': 0.00012087821960449219, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011439323425292969, 'bn2': 0.00011706352233886719, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 218\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001661062240600586, 'bn1': 0.0005631446838378906, 'relu1': 0.0003275871276855469, 'conv2': 0.0016334056854248047, 'bn2': 0.0005507469177246094, 'residual_add_relu2': 0.0007710456848144531}\n",
      "{'conv1': 0.0016486644744873047, 'bn1': 0.0005507469177246094, 'relu1': 0.0003268718719482422, 'conv2': 0.0016336441040039062, 'bn2': 0.0005486011505126953, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010542869567871094, 'bn1': 0.0003256797790527344, 'relu1': 0.00017571449279785156, 'conv2': 0.0013148784637451172, 'bn2': 0.0003154277801513672, 'conv3': 0.0004069805145263672, 'residual_add_relu2': 0.0003921985626220703}\n",
      "{'conv1': 0.0013124942779541016, 'bn1': 0.0003230571746826172, 'relu1': 0.0001766681671142578, 'conv2': 0.0013134479522705078, 'bn2': 0.0003387928009033203, 'residual_add_relu2': 0.0003936290740966797}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007979869842529297, 'bn1': 0.00020813941955566406, 'relu1': 0.00010251998901367188, 'conv2': 0.0011639595031738281, 'bn2': 0.00020051002502441406, 'conv3': 0.00035500526428222656, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.00115966796875, 'bn1': 0.00026226043701171875, 'relu1': 9.989738464355469e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.0001971721649169922, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006597042083740234, 'bn1': 0.00011992454528808594, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00012159347534179688, 'conv3': 0.0002949237823486328, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.00012040138244628906, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011425018310546875, 'bn2': 0.000110626220703125, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 219\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016551017761230469, 'bn1': 0.0005707740783691406, 'relu1': 0.00032520294189453125, 'conv2': 0.0016360282897949219, 'bn2': 0.0005371570587158203, 'residual_add_relu2': 0.0007727146148681641}\n",
      "{'conv1': 0.0016357898712158203, 'bn1': 0.0005476474761962891, 'relu1': 0.0003237724304199219, 'conv2': 0.0016298294067382812, 'bn2': 0.0005614757537841797, 'residual_add_relu2': 0.0007655620574951172}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010528564453125, 'bn1': 0.00031876564025878906, 'relu1': 0.0001735687255859375, 'conv2': 0.0013134479522705078, 'bn2': 0.00031256675720214844, 'conv3': 0.000400543212890625, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013096332550048828, 'bn1': 0.0003135204315185547, 'relu1': 0.0001747608184814453, 'conv2': 0.0013089179992675781, 'bn2': 0.0003108978271484375, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007853507995605469, 'bn1': 0.00019359588623046875, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011591911315917969, 'bn2': 0.00020551681518554688, 'conv3': 0.00035262107849121094, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011560916900634766, 'bn1': 0.000202178955078125, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.00020742416381835938, 'residual_add_relu2': 0.00020766258239746094}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006682872772216797, 'bn1': 0.0001270771026611328, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011496543884277344, 'bn2': 0.00011730194091796875, 'conv3': 0.0002942085266113281, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.001153707504272461, 'bn1': 0.00012683868408203125, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011470317840576172, 'bn2': 0.0001163482666015625, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 220\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016553401947021484, 'bn1': 0.0005581378936767578, 'relu1': 0.00032401084899902344, 'conv2': 0.0016357898712158203, 'bn2': 0.0005433559417724609, 'residual_add_relu2': 0.0007648468017578125}\n",
      "{'conv1': 0.0016422271728515625, 'bn1': 0.0005424022674560547, 'relu1': 0.000324249267578125, 'conv2': 0.0016357898712158203, 'bn2': 0.0005462169647216797, 'residual_add_relu2': 0.0007653236389160156}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010509490966796875, 'bn1': 0.0003147125244140625, 'relu1': 0.00017499923706054688, 'conv2': 0.0013096332550048828, 'bn2': 0.0003132820129394531, 'conv3': 0.0004012584686279297, 'residual_add_relu2': 0.00038933753967285156}\n",
      "{'conv1': 0.0013103485107421875, 'bn1': 0.0003139972686767578, 'relu1': 0.00017404556274414062, 'conv2': 0.0013093948364257812, 'bn2': 0.0003108978271484375, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000789642333984375, 'bn1': 0.0001990795135498047, 'relu1': 9.822845458984375e-05, 'conv2': 0.0015032291412353516, 'bn2': 0.00030517578125, 'conv3': 0.00037860870361328125, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.0011649131774902344, 'bn1': 0.00021386146545410156, 'relu1': 0.00010132789611816406, 'conv2': 0.001161813735961914, 'bn2': 0.00021529197692871094, 'residual_add_relu2': 0.00020885467529296875}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006771087646484375, 'bn1': 0.0001480579376220703, 'relu1': 6.389617919921875e-05, 'conv2': 0.0011577606201171875, 'bn2': 0.00013017654418945312, 'conv3': 0.0003046989440917969, 'residual_add_relu2': 0.00011420249938964844}\n",
      "{'conv1': 0.0011641979217529297, 'bn1': 0.00015282630920410156, 'relu1': 6.651878356933594e-05, 'conv2': 0.0011568069458007812, 'bn2': 0.00012993812561035156, 'residual_add_relu2': 0.00011205673217773438}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 221\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016605854034423828, 'bn1': 0.0005488395690917969, 'relu1': 0.00032329559326171875, 'conv2': 0.001636505126953125, 'bn2': 0.0005373954772949219, 'residual_add_relu2': 0.0007634162902832031}\n",
      "{'conv1': 0.0016293525695800781, 'bn1': 0.0005412101745605469, 'relu1': 0.0003228187561035156, 'conv2': 0.0016226768493652344, 'bn2': 0.0005309581756591797, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010499954223632812, 'bn1': 0.00031495094299316406, 'relu1': 0.0001723766326904297, 'conv2': 0.0013089179992675781, 'bn2': 0.0003044605255126953, 'conv3': 0.00045299530029296875, 'residual_add_relu2': 0.00039315223693847656}\n",
      "{'conv1': 0.0013229846954345703, 'bn1': 0.00031495094299316406, 'relu1': 0.00017404556274414062, 'conv2': 0.0013043880462646484, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.00039196014404296875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008289813995361328, 'bn1': 0.00020503997802734375, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011620521545410156, 'bn2': 0.00019598007202148438, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.001161813735961914, 'bn1': 0.00021529197692871094, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.0001964569091796875, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006616115570068359, 'bn1': 0.00012183189392089844, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.00012063980102539062, 'conv3': 0.00029158592224121094, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.00012159347534179688, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.00011491775512695312, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 222\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001748800277709961, 'bn1': 0.0006122589111328125, 'relu1': 0.000339508056640625, 'conv2': 0.0016522407531738281, 'bn2': 0.0005667209625244141, 'residual_add_relu2': 0.0007748603820800781}\n",
      "{'conv1': 0.0016558170318603516, 'bn1': 0.0005695819854736328, 'relu1': 0.00033211708068847656, 'conv2': 0.0016422271728515625, 'bn2': 0.0005576610565185547, 'residual_add_relu2': 0.0007672309875488281}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010707378387451172, 'bn1': 0.00035762786865234375, 'relu1': 0.000186920166015625, 'conv2': 0.0013277530670166016, 'bn2': 0.00033020973205566406, 'conv3': 0.0004208087921142578, 'residual_add_relu2': 0.00039696693420410156}\n",
      "{'conv1': 0.0013265609741210938, 'bn1': 0.00033092498779296875, 'relu1': 0.0001850128173828125, 'conv2': 0.0013170242309570312, 'bn2': 0.00032901763916015625, 'residual_add_relu2': 0.0003981590270996094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008041858673095703, 'bn1': 0.00022125244140625, 'relu1': 0.00010633468627929688, 'conv2': 0.0011680126190185547, 'bn2': 0.0002124309539794922, 'conv3': 0.0003650188446044922, 'residual_add_relu2': 0.00020933151245117188}\n",
      "{'conv1': 0.001165628433227539, 'bn1': 0.0002288818359375, 'relu1': 0.00010371208190917969, 'conv2': 0.0011620521545410156, 'bn2': 0.00021314620971679688, 'residual_add_relu2': 0.00020813941955566406}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006697177886962891, 'bn1': 0.0001437664031982422, 'relu1': 6.29425048828125e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.0001442432403564453, 'conv3': 0.0003077983856201172, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.0011584758758544922, 'bn1': 0.000141143798828125, 'relu1': 6.198883056640625e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.0001361370086669922, 'residual_add_relu2': 0.00011467933654785156}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 223\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016644001007080078, 'bn1': 0.0005807876586914062, 'relu1': 0.00032711029052734375, 'conv2': 0.0016341209411621094, 'bn2': 0.0005524158477783203, 'residual_add_relu2': 0.00077056884765625}\n",
      "{'conv1': 0.0016469955444335938, 'bn1': 0.0005476474761962891, 'relu1': 0.0003261566162109375, 'conv2': 0.0016367435455322266, 'bn2': 0.0005459785461425781, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010631084442138672, 'bn1': 0.00032019615173339844, 'relu1': 0.00017333030700683594, 'conv2': 0.0013120174407958984, 'bn2': 0.00031375885009765625, 'conv3': 0.0004069805145263672, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013155937194824219, 'bn1': 0.000316619873046875, 'relu1': 0.00024318695068359375, 'conv2': 0.0013141632080078125, 'bn2': 0.0003135204315185547, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007886886596679688, 'bn1': 0.00019621849060058594, 'relu1': 9.775161743164062e-05, 'conv2': 0.001155853271484375, 'bn2': 0.00020074844360351562, 'conv3': 0.00035452842712402344, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.00115966796875, 'bn1': 0.00020170211791992188, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.0001976490020751953, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006656646728515625, 'bn1': 0.00012493133544921875, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00011610984802246094, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011491775512695312, 'bn1': 0.0001552104949951172, 'relu1': 6.198883056640625e-05, 'conv2': 0.0011491775512695312, 'bn2': 0.00011944770812988281, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 224\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001661062240600586, 'bn1': 0.0005588531494140625, 'relu1': 0.0003237724304199219, 'conv2': 0.0016467571258544922, 'bn2': 0.0005440711975097656, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016400814056396484, 'bn1': 0.0005469322204589844, 'relu1': 0.00032329559326171875, 'conv2': 0.0016279220581054688, 'bn2': 0.0005459785461425781, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010442733764648438, 'bn1': 0.0003190040588378906, 'relu1': 0.00017333030700683594, 'conv2': 0.0013117790222167969, 'bn2': 0.0003116130828857422, 'conv3': 0.0004017353057861328, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013093948364257812, 'bn1': 0.0003147125244140625, 'relu1': 0.00017762184143066406, 'conv2': 0.0013060569763183594, 'bn2': 0.0003180503845214844, 'residual_add_relu2': 0.00039267539978027344}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007901191711425781, 'bn1': 0.00020313262939453125, 'relu1': 9.894371032714844e-05, 'conv2': 0.001161336898803711, 'bn2': 0.00020194053649902344, 'conv3': 0.00035572052001953125, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.0011599063873291016, 'bn1': 0.00019812583923339844, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011501312255859375, 'bn2': 0.00019216537475585938, 'residual_add_relu2': 0.00020599365234375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006768703460693359, 'bn1': 0.00013017654418945312, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00011205673217773438, 'conv3': 0.0002930164337158203, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011444091796875, 'bn1': 0.00012993812561035156, 'relu1': 6.389617919921875e-05, 'conv2': 0.0011534690856933594, 'bn2': 0.00011348724365234375, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 225\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001649618148803711, 'bn1': 0.0005505084991455078, 'relu1': 0.0003235340118408203, 'conv2': 0.0016422271728515625, 'bn2': 0.0005357265472412109, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016324520111083984, 'bn1': 0.0005474090576171875, 'relu1': 0.0003235340118408203, 'conv2': 0.001631021499633789, 'bn2': 0.0005338191986083984, 'residual_add_relu2': 0.0007612705230712891}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010411739349365234, 'bn1': 0.0003058910369873047, 'relu1': 0.0001709461212158203, 'conv2': 0.0013036727905273438, 'bn2': 0.0003044605255126953, 'conv3': 0.0003952980041503906, 'residual_add_relu2': 0.00038933753967285156}\n",
      "{'conv1': 0.00130462646484375, 'bn1': 0.00030493736267089844, 'relu1': 0.00017142295837402344, 'conv2': 0.0013022422790527344, 'bn2': 0.0003039836883544922, 'residual_add_relu2': 0.0003876686096191406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007843971252441406, 'bn1': 0.00019311904907226562, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011529922485351562, 'bn2': 0.00019216537475585938, 'conv3': 0.0003504753112792969, 'residual_add_relu2': 0.0002033710479736328}\n",
      "{'conv1': 0.0011546611785888672, 'bn1': 0.00019979476928710938, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00019359588623046875, 'residual_add_relu2': 0.00020575523376464844}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006604194641113281, 'bn1': 0.00013113021850585938, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00011682510375976562, 'conv3': 0.0002989768981933594, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011491775512695312, 'bn1': 0.00011491775512695312, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011425018310546875, 'bn2': 0.0001125335693359375, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 226\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016579627990722656, 'bn1': 0.0005555152893066406, 'relu1': 0.00032401084899902344, 'conv2': 0.0016264915466308594, 'bn2': 0.0005347728729248047, 'residual_add_relu2': 0.0007634162902832031}\n",
      "{'conv1': 0.0016269683837890625, 'bn1': 0.0005414485931396484, 'relu1': 0.0003266334533691406, 'conv2': 0.0016243457794189453, 'bn2': 0.0005440711975097656, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010416507720947266, 'bn1': 0.00030684471130371094, 'relu1': 0.00017070770263671875, 'conv2': 0.0013058185577392578, 'bn2': 0.0003113746643066406, 'conv3': 0.0004012584686279297, 'residual_add_relu2': 0.0003883838653564453}\n",
      "{'conv1': 0.0013093948364257812, 'bn1': 0.00031375885009765625, 'relu1': 0.00017261505126953125, 'conv2': 0.0013103485107421875, 'bn2': 0.00031256675720214844, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007905960083007812, 'bn1': 0.0001995563507080078, 'relu1': 9.894371032714844e-05, 'conv2': 0.001155853271484375, 'bn2': 0.0001933574676513672, 'conv3': 0.0003609657287597656, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011603832244873047, 'bn1': 0.00020051002502441406, 'relu1': 9.72747802734375e-05, 'conv2': 0.001153707504272461, 'bn2': 0.0001957416534423828, 'residual_add_relu2': 0.0002033710479736328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006723403930664062, 'bn1': 0.00012922286987304688, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.00010943412780761719, 'conv3': 0.00029158592224121094, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011444091796875, 'bn1': 0.00011038780212402344, 'relu1': 6.103515625e-05, 'conv2': 0.0011415481567382812, 'bn2': 0.000118255615234375, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 227\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016446113586425781, 'bn1': 0.0005538463592529297, 'relu1': 0.0003230571746826172, 'conv2': 0.0016248226165771484, 'bn2': 0.0005369186401367188, 'residual_add_relu2': 0.0007646083831787109}\n",
      "{'conv1': 0.0016350746154785156, 'bn1': 0.0005364418029785156, 'relu1': 0.0003211498260498047, 'conv2': 0.0016260147094726562, 'bn2': 0.0005424022674560547, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010454654693603516, 'bn1': 0.00031495094299316406, 'relu1': 0.00017595291137695312, 'conv2': 0.0013134479522705078, 'bn2': 0.00032067298889160156, 'conv3': 0.0004031658172607422, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013103485107421875, 'bn1': 0.00031685829162597656, 'relu1': 0.00017309188842773438, 'conv2': 0.0013074874877929688, 'bn2': 0.0003120899200439453, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007822513580322266, 'bn1': 0.0001914501190185547, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011508464813232422, 'bn2': 0.00019049644470214844, 'conv3': 0.0003604888916015625, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011570453643798828, 'bn1': 0.00019288063049316406, 'relu1': 9.560585021972656e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00018477439880371094, 'residual_add_relu2': 0.00020265579223632812}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006542205810546875, 'bn1': 0.00011682510375976562, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011425018310546875, 'bn2': 0.00010514259338378906, 'conv3': 0.0002884864807128906, 'residual_add_relu2': 0.00010943412780761719}\n",
      "{'conv1': 0.0011432170867919922, 'bn1': 0.00011181831359863281, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011408329010009766, 'bn2': 0.00011110305786132812, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 228\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016486644744873047, 'bn1': 0.0005581378936767578, 'relu1': 0.0003254413604736328, 'conv2': 0.0016295909881591797, 'bn2': 0.0005321502685546875, 'residual_add_relu2': 0.0007631778717041016}\n",
      "{'conv1': 0.0016293525695800781, 'bn1': 0.0005495548248291016, 'relu1': 0.0003216266632080078, 'conv2': 0.0016300678253173828, 'bn2': 0.0005304813385009766, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010433197021484375, 'bn1': 0.0003066062927246094, 'relu1': 0.00017142295837402344, 'conv2': 0.001306295394897461, 'bn2': 0.0003082752227783203, 'conv3': 0.0004017353057861328, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013096332550048828, 'bn1': 0.0003108978271484375, 'relu1': 0.0001728534698486328, 'conv2': 0.0013051033020019531, 'bn2': 0.0003204345703125, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007913112640380859, 'bn1': 0.00020313262939453125, 'relu1': 9.894371032714844e-05, 'conv2': 0.001157522201538086, 'bn2': 0.00021266937255859375, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011548995971679688, 'bn1': 0.0001952648162841797, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.0001926422119140625, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006587505340576172, 'bn1': 0.00011587142944335938, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011444091796875, 'bn2': 0.00011205673217773438, 'conv3': 0.0002918243408203125, 'residual_add_relu2': 0.00010943412780761719}\n",
      "{'conv1': 0.0011456012725830078, 'bn1': 0.00011324882507324219, 'relu1': 5.6743621826171875e-05, 'conv2': 0.0011415481567382812, 'bn2': 0.0001232624053955078, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 229\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001649618148803711, 'bn1': 0.0005462169647216797, 'relu1': 0.00032138824462890625, 'conv2': 0.0016341209411621094, 'bn2': 0.0005333423614501953, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.001634836196899414, 'bn1': 0.0005404949188232422, 'relu1': 0.0003223419189453125, 'conv2': 0.001631021499633789, 'bn2': 0.0005359649658203125, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010449886322021484, 'bn1': 0.0003077983856201172, 'relu1': 0.00017118453979492188, 'conv2': 0.0013070106506347656, 'bn2': 0.0003063678741455078, 'conv3': 0.00039696693420410156, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013079643249511719, 'bn1': 0.0003101825714111328, 'relu1': 0.00017309188842773438, 'conv2': 0.0013082027435302734, 'bn2': 0.00031113624572753906, 'residual_add_relu2': 0.00038886070251464844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007853507995605469, 'bn1': 0.00019168853759765625, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00018453598022460938, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.00020766258239746094}\n",
      "{'conv1': 0.0011589527130126953, 'bn1': 0.000194549560546875, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011501312255859375, 'bn2': 0.0001850128173828125, 'residual_add_relu2': 0.000202178955078125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006546974182128906, 'bn1': 0.00016951560974121094, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00011706352233886719, 'conv3': 0.000293731689453125, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011453628540039062, 'bn1': 0.00011348724365234375, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011408329010009766, 'bn2': 0.00012135505676269531, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 230\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016393661499023438, 'bn1': 0.0005548000335693359, 'relu1': 0.00033283233642578125, 'conv2': 0.0016355514526367188, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016436576843261719, 'bn1': 0.0005552768707275391, 'relu1': 0.00032329559326171875, 'conv2': 0.0016322135925292969, 'bn2': 0.0005338191986083984, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.00104522705078125, 'bn1': 0.00030875205993652344, 'relu1': 0.00017142295837402344, 'conv2': 0.001306295394897461, 'bn2': 0.00030350685119628906, 'conv3': 0.00039696693420410156, 'residual_add_relu2': 0.00038933753967285156}\n",
      "{'conv1': 0.00130462646484375, 'bn1': 0.00030541419982910156, 'relu1': 0.0001697540283203125, 'conv2': 0.0013058185577392578, 'bn2': 0.0003097057342529297, 'residual_add_relu2': 0.0003879070281982422}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007860660552978516, 'bn1': 0.0001900196075439453, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011548995971679688, 'bn2': 0.00018858909606933594, 'conv3': 0.00034999847412109375, 'residual_add_relu2': 0.0002033710479736328}\n",
      "{'conv1': 0.0011548995971679688, 'bn1': 0.00020170211791992188, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.000194549560546875, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000659942626953125, 'bn1': 0.00012302398681640625, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.0001201629638671875, 'conv3': 0.0002913475036621094, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011489391326904297, 'bn1': 0.00014710426330566406, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.00013256072998046875, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 231\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016536712646484375, 'bn1': 0.0005543231964111328, 'relu1': 0.000331878662109375, 'conv2': 0.001634359359741211, 'bn2': 0.0005469322204589844, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016338825225830078, 'bn1': 0.0005593299865722656, 'relu1': 0.00032830238342285156, 'conv2': 0.0016276836395263672, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.00077056884765625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010519027709960938, 'bn1': 0.0003185272216796875, 'relu1': 0.0001728534698486328, 'conv2': 0.001317739486694336, 'bn2': 0.00033402442932128906, 'conv3': 0.00040721893310546875, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013110637664794922, 'bn1': 0.00030875205993652344, 'relu1': 0.00017380714416503906, 'conv2': 0.0016143321990966797, 'bn2': 0.0004143714904785156, 'residual_add_relu2': 0.000396728515625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008137226104736328, 'bn1': 0.00020885467529296875, 'relu1': 0.00010085105895996094, 'conv2': 0.0011610984802246094, 'bn2': 0.00019788742065429688, 'conv3': 0.0003724098205566406, 'residual_add_relu2': 0.00020813941955566406}\n",
      "{'conv1': 0.0011668205261230469, 'bn1': 0.0002048015594482422, 'relu1': 9.870529174804688e-05, 'conv2': 0.001155853271484375, 'bn2': 0.0001957416534423828, 'residual_add_relu2': 0.00020742416381835938}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006673336029052734, 'bn1': 0.00013947486877441406, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00011396408081054688, 'conv3': 0.0002944469451904297, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.000118255615234375, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.00012421607971191406, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 232\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016548633575439453, 'bn1': 0.0005624294281005859, 'relu1': 0.00032639503479003906, 'conv2': 0.0016324520111083984, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016360282897949219, 'bn1': 0.0005490779876708984, 'relu1': 0.0003237724304199219, 'conv2': 0.0016312599182128906, 'bn2': 0.0005450248718261719, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010521411895751953, 'bn1': 0.0003192424774169922, 'relu1': 0.0001728534698486328, 'conv2': 0.001310110092163086, 'bn2': 0.00031304359436035156, 'conv3': 0.00040340423583984375, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013132095336914062, 'bn1': 0.0003139972686767578, 'relu1': 0.00017309188842773438, 'conv2': 0.0013091564178466797, 'bn2': 0.0003371238708496094, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007996559143066406, 'bn1': 0.0002028942108154297, 'relu1': 9.942054748535156e-05, 'conv2': 0.001161336898803711, 'bn2': 0.00020170211791992188, 'conv3': 0.0003533363342285156, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011870861053466797, 'bn1': 0.0002028942108154297, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.0002300739288330078}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006773471832275391, 'bn1': 0.00012922286987304688, 'relu1': 6.103515625e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.00011610984802246094, 'conv3': 0.0002918243408203125, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011489391326904297, 'bn1': 0.00012183189392089844, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00011897087097167969, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 233\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016567707061767578, 'bn1': 0.0005688667297363281, 'relu1': 0.0003275871276855469, 'conv2': 0.0016438961029052734, 'bn2': 0.0005521774291992188, 'residual_add_relu2': 0.0007808208465576172}\n",
      "{'conv1': 0.001645803451538086, 'bn1': 0.0005578994750976562, 'relu1': 0.00033020973205566406, 'conv2': 0.0016355514526367188, 'bn2': 0.0005557537078857422, 'residual_add_relu2': 0.0007681846618652344}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010547637939453125, 'bn1': 0.00032973289489746094, 'relu1': 0.0001766681671142578, 'conv2': 0.0013263225555419922, 'bn2': 0.000324249267578125, 'conv3': 0.0004100799560546875, 'residual_add_relu2': 0.0003943443298339844}\n",
      "{'conv1': 0.0013170242309570312, 'bn1': 0.0003154277801513672, 'relu1': 0.00017690658569335938, 'conv2': 0.0013079643249511719, 'bn2': 0.00031757354736328125, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007877349853515625, 'bn1': 0.0001952648162841797, 'relu1': 9.703636169433594e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.0002167224884033203, 'conv3': 0.0003578662872314453, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011582374572753906, 'bn1': 0.00020170211791992188, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011773109436035156, 'bn2': 0.00023031234741210938, 'residual_add_relu2': 0.00020742416381835938}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006690025329589844, 'bn1': 0.0001246929168701172, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.000118255615234375, 'conv3': 0.00029587745666503906, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.00012540817260742188, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011458396911621094, 'bn2': 0.00011658668518066406, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 234\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016586780548095703, 'bn1': 0.0005583763122558594, 'relu1': 0.00032448768615722656, 'conv2': 0.00164031982421875, 'bn2': 0.0005352497100830078, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016353130340576172, 'bn1': 0.00054931640625, 'relu1': 0.00032401084899902344, 'conv2': 0.0016303062438964844, 'bn2': 0.0005395412445068359, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001043558120727539, 'bn1': 0.00031566619873046875, 'relu1': 0.0001709461212158203, 'conv2': 0.0013089179992675781, 'bn2': 0.00031256675720214844, 'conv3': 0.0004038810729980469, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013096332550048828, 'bn1': 0.00031495094299316406, 'relu1': 0.0001735687255859375, 'conv2': 0.0013086795806884766, 'bn2': 0.0003352165222167969, 'residual_add_relu2': 0.00039458274841308594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007970333099365234, 'bn1': 0.0002105236053466797, 'relu1': 0.000102996826171875, 'conv2': 0.0011744499206542969, 'bn2': 0.0002186298370361328, 'conv3': 0.00035858154296875, 'residual_add_relu2': 0.00020647048950195312}\n",
      "{'conv1': 0.0011718273162841797, 'bn1': 0.00021314620971679688, 'relu1': 0.0001010894775390625, 'conv2': 0.0011599063873291016, 'bn2': 0.0002105236053466797, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006697177886962891, 'bn1': 0.00013971328735351562, 'relu1': 6.222724914550781e-05, 'conv2': 0.001153707504272461, 'bn2': 0.00012946128845214844, 'conv3': 0.0003020763397216797, 'residual_add_relu2': 0.00011372566223144531}\n",
      "{'conv1': 0.0011548995971679688, 'bn1': 0.000118255615234375, 'relu1': 5.6743621826171875e-05, 'conv2': 0.0011403560638427734, 'bn2': 0.00010991096496582031, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 235\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016460418701171875, 'bn1': 0.0005557537078857422, 'relu1': 0.0003249645233154297, 'conv2': 0.0016262531280517578, 'bn2': 0.0005397796630859375, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016312599182128906, 'bn1': 0.0005404949188232422, 'relu1': 0.0003216266632080078, 'conv2': 0.0016295909881591797, 'bn2': 0.0005333423614501953, 'residual_add_relu2': 0.0007605552673339844}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010411739349365234, 'bn1': 0.00031447410583496094, 'relu1': 0.00017213821411132812, 'conv2': 0.0013086795806884766, 'bn2': 0.0003113746643066406, 'conv3': 0.0003993511199951172, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013098716735839844, 'bn1': 0.0003147125244140625, 'relu1': 0.0001747608184814453, 'conv2': 0.0013072490692138672, 'bn2': 0.0003151893615722656, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007891654968261719, 'bn1': 0.0001926422119140625, 'relu1': 9.679794311523438e-05, 'conv2': 0.00115203857421875, 'bn2': 0.00019931793212890625, 'conv3': 0.00035572052001953125, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011591911315917969, 'bn1': 0.00019121170043945312, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00018453598022460938, 'residual_add_relu2': 0.00020742416381835938}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006625652313232422, 'bn1': 0.00011563301086425781, 'relu1': 5.698204040527344e-05, 'conv2': 0.0011434555053710938, 'bn2': 0.00010585784912109375, 'conv3': 0.00028824806213378906, 'residual_add_relu2': 0.00010848045349121094}\n",
      "{'conv1': 0.0011434555053710938, 'bn1': 0.00011610984802246094, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011417865753173828, 'bn2': 0.00010991096496582031, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 236\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016417503356933594, 'bn1': 0.0005524158477783203, 'relu1': 0.0003261566162109375, 'conv2': 0.0016322135925292969, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016303062438964844, 'bn1': 0.0005364418029785156, 'relu1': 0.0003218650817871094, 'conv2': 0.0016241073608398438, 'bn2': 0.0005314350128173828, 'residual_add_relu2': 0.0007615089416503906}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001043558120727539, 'bn1': 0.00030875205993652344, 'relu1': 0.00017070770263671875, 'conv2': 0.0013048648834228516, 'bn2': 0.00030493736267089844, 'conv3': 0.00039577484130859375, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.0013065338134765625, 'bn1': 0.0003044605255126953, 'relu1': 0.0001709461212158203, 'conv2': 0.001302957534790039, 'bn2': 0.0003135204315185547, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007879734039306641, 'bn1': 0.0001938343048095703, 'relu1': 9.5367431640625e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.0001957416534423828, 'conv3': 0.0003502368927001953, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011599063873291016, 'bn1': 0.00019931793212890625, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00019359588623046875, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006608963012695312, 'bn1': 0.0001308917999267578, 'relu1': 6.103515625e-05, 'conv2': 0.0011472702026367188, 'bn2': 0.00010991096496582031, 'conv3': 0.00030159950256347656, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011467933654785156, 'bn1': 0.00011277198791503906, 'relu1': 5.650520324707031e-05, 'conv2': 0.0011413097381591797, 'bn2': 0.00011181831359863281, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 237\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016489028930664062, 'bn1': 0.0005567073822021484, 'relu1': 0.0003237724304199219, 'conv2': 0.0016317367553710938, 'bn2': 0.0005388259887695312, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016279220581054688, 'bn1': 0.0005371570587158203, 'relu1': 0.00032258033752441406, 'conv2': 0.0016322135925292969, 'bn2': 0.0005457401275634766, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001049041748046875, 'bn1': 0.00031447410583496094, 'relu1': 0.00017189979553222656, 'conv2': 0.0013194084167480469, 'bn2': 0.0003108978271484375, 'conv3': 0.00040078163146972656, 'residual_add_relu2': 0.000392913818359375}\n",
      "{'conv1': 0.0013093948364257812, 'bn1': 0.0003120899200439453, 'relu1': 0.0001742839813232422, 'conv2': 0.0013103485107421875, 'bn2': 0.00030922889709472656, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007886886596679688, 'bn1': 0.0002033710479736328, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011582374572753906, 'bn2': 0.00019884109497070312, 'conv3': 0.00035572052001953125, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011625289916992188, 'bn1': 0.00020122528076171875, 'relu1': 9.870529174804688e-05, 'conv2': 0.0012001991271972656, 'bn2': 0.0002052783966064453, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006639957427978516, 'bn1': 0.00012373924255371094, 'relu1': 6.103515625e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00011229515075683594, 'conv3': 0.0002923011779785156, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.001146078109741211, 'bn1': 0.00012302398681640625, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011444091796875, 'bn2': 0.0001163482666015625, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 238\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016589164733886719, 'bn1': 0.0005524158477783203, 'relu1': 0.0003228187561035156, 'conv2': 0.0016362667083740234, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016393661499023438, 'bn1': 0.0005481243133544922, 'relu1': 0.00032830238342285156, 'conv2': 0.0016341209411621094, 'bn2': 0.0005390644073486328, 'residual_add_relu2': 0.0007677078247070312}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010528564453125, 'bn1': 0.00031638145446777344, 'relu1': 0.00017261505126953125, 'conv2': 0.001314401626586914, 'bn2': 0.0003108978271484375, 'conv3': 0.0004024505615234375, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.001313924789428711, 'bn1': 0.00031447410583496094, 'relu1': 0.00017213821411132812, 'conv2': 0.0013036727905273438, 'bn2': 0.00030517578125, 'residual_add_relu2': 0.00042724609375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007958412170410156, 'bn1': 0.00020360946655273438, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011568069458007812, 'bn2': 0.0001933574676513672, 'conv3': 0.0003523826599121094, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011601448059082031, 'bn1': 0.00020360946655273438, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011548995971679688, 'bn2': 0.0001952648162841797, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006592273712158203, 'bn1': 0.00012612342834472656, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.00011873245239257812, 'conv3': 0.00029587745666503906, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011491775512695312, 'bn1': 0.00012373924255371094, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.00011801719665527344, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 239\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016472339630126953, 'bn1': 0.0005538463592529297, 'relu1': 0.0003237724304199219, 'conv2': 0.0016286373138427734, 'bn2': 0.0005390644073486328, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.0016338825225830078, 'bn1': 0.0005464553833007812, 'relu1': 0.0003237724304199219, 'conv2': 0.0016295909881591797, 'bn2': 0.0005304813385009766, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010445117950439453, 'bn1': 0.00030732154846191406, 'relu1': 0.00017023086547851562, 'conv2': 0.0013048648834228516, 'bn2': 0.0003001689910888672, 'conv3': 0.0003943443298339844, 'residual_add_relu2': 0.00038933753967285156}\n",
      "{'conv1': 0.0013070106506347656, 'bn1': 0.00030612945556640625, 'relu1': 0.00017118453979492188, 'conv2': 0.001302480697631836, 'bn2': 0.0003008842468261719, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007865428924560547, 'bn1': 0.00020265579223632812, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.00020384788513183594, 'conv3': 0.0003592967987060547, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011644363403320312, 'bn1': 0.00021886825561523438, 'relu1': 0.00010228157043457031, 'conv2': 0.0011606216430664062, 'bn2': 0.0002028942108154297, 'residual_add_relu2': 0.00020813941955566406}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006678104400634766, 'bn1': 0.0001327991485595703, 'relu1': 6.246566772460938e-05, 'conv2': 0.0011539459228515625, 'bn2': 0.0001323223114013672, 'conv3': 0.0002989768981933594, 'residual_add_relu2': 0.00011301040649414062}\n",
      "{'conv1': 0.0011534690856933594, 'bn1': 0.00012063980102539062, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011448860168457031, 'bn2': 0.00012612342834472656, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 240\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016584396362304688, 'bn1': 0.0005555152893066406, 'relu1': 0.00032448768615722656, 'conv2': 0.0016300678253173828, 'bn2': 0.0005419254302978516, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016336441040039062, 'bn1': 0.0005424022674560547, 'relu1': 0.00032258033752441406, 'conv2': 0.0016300678253173828, 'bn2': 0.0005321502685546875, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010404586791992188, 'bn1': 0.0003120899200439453, 'relu1': 0.0001723766326904297, 'conv2': 0.001308441162109375, 'bn2': 0.00030875205993652344, 'conv3': 0.0003974437713623047, 'residual_add_relu2': 0.0003948211669921875}\n",
      "{'conv1': 0.0013098716735839844, 'bn1': 0.00031638145446777344, 'relu1': 0.0001728534698486328, 'conv2': 0.0013072490692138672, 'bn2': 0.0003020763397216797, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007891654968261719, 'bn1': 0.00020170211791992188, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011582374572753906, 'bn2': 0.0001952648162841797, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011587142944335938, 'bn1': 0.00019741058349609375, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011563301086425781, 'bn2': 0.00020170211791992188, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006625652313232422, 'bn1': 0.00011587142944335938, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.00011610984802246094, 'conv3': 0.0002932548522949219, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011563301086425781, 'bn1': 0.0001227855682373047, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.00011563301086425781, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 241\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016574859619140625, 'bn1': 0.0005543231964111328, 'relu1': 0.0003247261047363281, 'conv2': 0.0016336441040039062, 'bn2': 0.0005450248718261719, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.0016300678253173828, 'bn1': 0.0005490779876708984, 'relu1': 0.00032401084899902344, 'conv2': 0.0016245841979980469, 'bn2': 0.0005404949188232422, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010492801666259766, 'bn1': 0.0003139972686767578, 'relu1': 0.0001723766326904297, 'conv2': 0.0013074874877929688, 'bn2': 0.00030112266540527344, 'conv3': 0.000396728515625, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.001310110092163086, 'bn1': 0.00031256675720214844, 'relu1': 0.00017380714416503906, 'conv2': 0.001306772232055664, 'bn2': 0.0003085136413574219, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000789642333984375, 'bn1': 0.00019931793212890625, 'relu1': 0.00010132789611816406, 'conv2': 0.00115966796875, 'bn2': 0.00020575523376464844, 'conv3': 0.0003516674041748047, 'residual_add_relu2': 0.0002033710479736328}\n",
      "{'conv1': 0.0011544227600097656, 'bn1': 0.00019741058349609375, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.00018715858459472656, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006566047668457031, 'bn1': 0.00011467933654785156, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011436939239501953, 'bn2': 0.00010991096496582031, 'conv3': 0.0002899169921875, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011448860168457031, 'bn1': 0.00011396408081054688, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011398792266845703, 'bn2': 0.00010585784912109375, 'residual_add_relu2': 0.00010800361633300781}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 242\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016465187072753906, 'bn1': 0.0005543231964111328, 'relu1': 0.0003230571746826172, 'conv2': 0.0016350746154785156, 'bn2': 0.0005452632904052734, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.0016415119171142578, 'bn1': 0.0005466938018798828, 'relu1': 0.0003254413604736328, 'conv2': 0.0016412734985351562, 'bn2': 0.0005447864532470703, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010497570037841797, 'bn1': 0.00031566619873046875, 'relu1': 0.00017333030700683594, 'conv2': 0.0013086795806884766, 'bn2': 0.00030875205993652344, 'conv3': 0.00039887428283691406, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.001313924789428711, 'bn1': 0.00031495094299316406, 'relu1': 0.00017333030700683594, 'conv2': 0.0013060569763183594, 'bn2': 0.0003075599670410156, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007939338684082031, 'bn1': 0.00020003318786621094, 'relu1': 9.751319885253906e-05, 'conv2': 0.001155853271484375, 'bn2': 0.0001938343048095703, 'conv3': 0.0003523826599121094, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011599063873291016, 'bn1': 0.00020241737365722656, 'relu1': 9.799003601074219e-05, 'conv2': 0.001153707504272461, 'bn2': 0.00019311904907226562, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006639957427978516, 'bn1': 0.0001220703125, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011470317840576172, 'bn2': 0.00011730194091796875, 'conv3': 0.00029349327087402344, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.00012040138244628906, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00011515617370605469, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 243\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016636848449707031, 'bn1': 0.0005631446838378906, 'relu1': 0.0003390312194824219, 'conv2': 0.0016932487487792969, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.001631021499633789, 'bn1': 0.0005497932434082031, 'relu1': 0.00032329559326171875, 'conv2': 0.0016307830810546875, 'bn2': 0.0005397796630859375, 'residual_add_relu2': 0.0007658004760742188}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010523796081542969, 'bn1': 0.0003178119659423828, 'relu1': 0.00017309188842773438, 'conv2': 0.0013110637664794922, 'bn2': 0.000308990478515625, 'conv3': 0.00040411949157714844, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013303756713867188, 'bn1': 0.00032138824462890625, 'relu1': 0.00017523765563964844, 'conv2': 0.0013103485107421875, 'bn2': 0.0003132820129394531, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007927417755126953, 'bn1': 0.00020360946655273438, 'relu1': 0.00010132789611816406, 'conv2': 0.0011587142944335938, 'bn2': 0.00020194053649902344, 'conv3': 0.00035762786865234375, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0011603832244873047, 'bn1': 0.00020360946655273438, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00019550323486328125, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006630420684814453, 'bn1': 0.0001285076141357422, 'relu1': 6.0558319091796875e-05, 'conv2': 0.001150369644165039, 'bn2': 0.00011992454528808594, 'conv3': 0.0002970695495605469, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011556148529052734, 'bn1': 0.00012111663818359375, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011463165283203125, 'bn2': 0.00011539459228515625, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 244\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016589164733886719, 'bn1': 0.0005548000335693359, 'relu1': 0.00032401084899902344, 'conv2': 0.0016312599182128906, 'bn2': 0.0005404949188232422, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016345977783203125, 'bn1': 0.0005447864532470703, 'relu1': 0.00032401084899902344, 'conv2': 0.0016355514526367188, 'bn2': 0.000545501708984375, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010514259338378906, 'bn1': 0.0003132820129394531, 'relu1': 0.00017499923706054688, 'conv2': 0.0013136863708496094, 'bn2': 0.00031495094299316406, 'conv3': 0.00040340423583984375, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013158321380615234, 'bn1': 0.0003154277801513672, 'relu1': 0.00017333030700683594, 'conv2': 0.0013065338134765625, 'bn2': 0.00030803680419921875, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007882118225097656, 'bn1': 0.00019884109497070312, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011563301086425781, 'bn2': 0.000194549560546875, 'conv3': 0.0003516674041748047, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.001157522201538086, 'bn1': 0.00019288063049316406, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00018715858459472656, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006558895111083984, 'bn1': 0.00012087821960449219, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00011801719665527344, 'conv3': 0.0002944469451904297, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.001146554946899414, 'bn1': 0.00013065338134765625, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011458396911621094, 'bn2': 0.0001163482666015625, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 245\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016512870788574219, 'bn1': 0.0005595684051513672, 'relu1': 0.000324249267578125, 'conv2': 0.0016415119171142578, 'bn2': 0.0005471706390380859, 'residual_add_relu2': 0.0007688999176025391}\n",
      "{'conv1': 0.0016446113586425781, 'bn1': 0.0005512237548828125, 'relu1': 0.0003249645233154297, 'conv2': 0.0016324520111083984, 'bn2': 0.00057220458984375, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010485649108886719, 'bn1': 0.0003197193145751953, 'relu1': 0.0001735687255859375, 'conv2': 0.0013117790222167969, 'bn2': 0.0003275871276855469, 'conv3': 0.00040340423583984375, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013113021850585938, 'bn1': 0.0003135204315185547, 'relu1': 0.00017333030700683594, 'conv2': 0.0013117790222167969, 'bn2': 0.0003151893615722656, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007898807525634766, 'bn1': 0.00020051002502441406, 'relu1': 9.918212890625e-05, 'conv2': 0.0011615753173828125, 'bn2': 0.0002014636993408203, 'conv3': 0.00035500526428222656, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011582374572753906, 'bn1': 0.0002002716064453125, 'relu1': 0.00010061264038085938, 'conv2': 0.001154184341430664, 'bn2': 0.00019431114196777344, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006623268127441406, 'bn1': 0.0001556873321533203, 'relu1': 7.677078247070312e-05, 'conv2': 0.001188516616821289, 'bn2': 0.00016236305236816406, 'conv3': 0.0003437995910644531, 'residual_add_relu2': 0.00011444091796875}\n",
      "{'conv1': 0.0011532306671142578, 'bn1': 0.0001308917999267578, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.00018715858459472656, 'residual_add_relu2': 0.00011277198791503906}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 246\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001661062240600586, 'bn1': 0.0005650520324707031, 'relu1': 0.0003247261047363281, 'conv2': 0.0016350746154785156, 'bn2': 0.0005521774291992188, 'residual_add_relu2': 0.0007822513580322266}\n",
      "{'conv1': 0.0016355514526367188, 'bn1': 0.0005581378936767578, 'relu1': 0.00032830238342285156, 'conv2': 0.001636505126953125, 'bn2': 0.0005545616149902344, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010595321655273438, 'bn1': 0.000370025634765625, 'relu1': 0.00017976760864257812, 'conv2': 0.0013327598571777344, 'bn2': 0.00036144256591796875, 'conv3': 0.0004248619079589844, 'residual_add_relu2': 0.0003974437713623047}\n",
      "{'conv1': 0.001325368881225586, 'bn1': 0.0003371238708496094, 'relu1': 0.00017714500427246094, 'conv2': 0.0013146400451660156, 'bn2': 0.00034332275390625, 'residual_add_relu2': 0.0003943443298339844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008018016815185547, 'bn1': 0.00021600723266601562, 'relu1': 0.00010156631469726562, 'conv2': 0.0011649131774902344, 'bn2': 0.00020551681518554688, 'conv3': 0.0003604888916015625, 'residual_add_relu2': 0.00020647048950195312}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.00020384788513183594, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.000202178955078125, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.00066375732421875, 'bn1': 0.00013327598571777344, 'relu1': 6.151199340820312e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.0001277923583984375, 'conv3': 0.00029659271240234375, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.001153707504272461, 'bn1': 0.00012636184692382812, 'relu1': 6.270408630371094e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.0001227855682373047, 'residual_add_relu2': 0.00011181831359863281}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 247\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016562938690185547, 'bn1': 0.0005583763122558594, 'relu1': 0.00032448768615722656, 'conv2': 0.0016317367553710938, 'bn2': 0.0005476474761962891, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.0016376972198486328, 'bn1': 0.0005490779876708984, 'relu1': 0.00032210350036621094, 'conv2': 0.0016379356384277344, 'bn2': 0.0005390644073486328, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010480880737304688, 'bn1': 0.0003151893615722656, 'relu1': 0.00017261505126953125, 'conv2': 0.001310586929321289, 'bn2': 0.0003097057342529297, 'conv3': 0.00040149688720703125, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013096332550048828, 'bn1': 0.00031566619873046875, 'relu1': 0.00017380714416503906, 'conv2': 0.0013074874877929688, 'bn2': 0.00030612945556640625, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007874965667724609, 'bn1': 0.00019240379333496094, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011544227600097656, 'bn2': 0.00018787384033203125, 'conv3': 0.0003490447998046875, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.0011608600616455078, 'bn1': 0.00020003318786621094, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011548995971679688, 'bn2': 0.000194549560546875, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006611347198486328, 'bn1': 0.000125885009765625, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.00011563301086425781, 'conv3': 0.0002949237823486328, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011479854583740234, 'bn1': 0.00012373924255371094, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.00011873245239257812, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 248\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016429424285888672, 'bn1': 0.0005567073822021484, 'relu1': 0.0003254413604736328, 'conv2': 0.0016360282897949219, 'bn2': 0.0005466938018798828, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.00164031982421875, 'bn1': 0.0005452632904052734, 'relu1': 0.0003275871276855469, 'conv2': 0.0016317367553710938, 'bn2': 0.0005445480346679688, 'residual_add_relu2': 0.0007615089416503906}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001051187515258789, 'bn1': 0.0003409385681152344, 'relu1': 0.00017786026000976562, 'conv2': 0.0013127326965332031, 'bn2': 0.00031113624572753906, 'conv3': 0.00040149688720703125, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013129711151123047, 'bn1': 0.00032448768615722656, 'relu1': 0.00017595291137695312, 'conv2': 0.001310110092163086, 'bn2': 0.00031256675720214844, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000789642333984375, 'bn1': 0.000194549560546875, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.000194549560546875, 'conv3': 0.00034999847412109375, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.0011565685272216797, 'bn1': 0.00019931793212890625, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011544227600097656, 'bn2': 0.00019621849060058594, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006775856018066406, 'bn1': 0.00012969970703125, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00011587142944335938, 'conv3': 0.0002949237823486328, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011551380157470703, 'bn1': 0.00012350082397460938, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.00011515617370605469, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 249\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016446113586425781, 'bn1': 0.0005581378936767578, 'relu1': 0.00032329559326171875, 'conv2': 0.0016326904296875, 'bn2': 0.0005457401275634766, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016374588012695312, 'bn1': 0.0005462169647216797, 'relu1': 0.00032401084899902344, 'conv2': 0.0016264915466308594, 'bn2': 0.0005371570587158203, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010476112365722656, 'bn1': 0.0003159046173095703, 'relu1': 0.00017261505126953125, 'conv2': 0.001308441162109375, 'bn2': 0.0003085136413574219, 'conv3': 0.000400543212890625, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013148784637451172, 'bn1': 0.0003154277801513672, 'relu1': 0.00017380714416503906, 'conv2': 0.001306772232055664, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007946491241455078, 'bn1': 0.00020051002502441406, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011563301086425781, 'bn2': 0.00019598007202148438, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011584758758544922, 'bn1': 0.00020956993103027344, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011544227600097656, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000659942626953125, 'bn1': 0.00012111663818359375, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.00013184547424316406, 'conv3': 0.00029730796813964844, 'residual_add_relu2': 0.00011229515075683594}\n",
      "{'conv1': 0.0011479854583740234, 'bn1': 0.00012111663818359375, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.00011491775512695312, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 250\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016503334045410156, 'bn1': 0.0005440711975097656, 'relu1': 0.0003211498260498047, 'conv2': 0.0016338825225830078, 'bn2': 0.0005440711975097656, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016326904296875, 'bn1': 0.0005440711975097656, 'relu1': 0.00032639503479003906, 'conv2': 0.0016317367553710938, 'bn2': 0.0005393028259277344, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010488033294677734, 'bn1': 0.0003161430358886719, 'relu1': 0.0001735687255859375, 'conv2': 0.0013086795806884766, 'bn2': 0.0003085136413574219, 'conv3': 0.00040650367736816406, 'residual_add_relu2': 0.00039196014404296875}\n",
      "{'conv1': 0.0013132095336914062, 'bn1': 0.000308990478515625, 'relu1': 0.00017118453979492188, 'conv2': 0.0013043880462646484, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007932186126708984, 'bn1': 0.0001952648162841797, 'relu1': 9.655952453613281e-05, 'conv2': 0.001154184341430664, 'bn2': 0.0001876354217529297, 'conv3': 0.0003497600555419922, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.0011553764343261719, 'bn1': 0.00019502639770507812, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.0001933574676513672, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006604194641113281, 'bn1': 0.00012135505676269531, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011467933654785156, 'bn2': 0.00011706352233886719, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011458396911621094, 'bn1': 0.00011467933654785156, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011408329010009766, 'bn2': 0.00010967254638671875, 'residual_add_relu2': 0.00010848045349121094}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 251\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016489028930664062, 'bn1': 0.0005669593811035156, 'relu1': 0.0003273487091064453, 'conv2': 0.0016303062438964844, 'bn2': 0.0005440711975097656, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.001638650894165039, 'bn1': 0.00054931640625, 'relu1': 0.0003216266632080078, 'conv2': 0.0016293525695800781, 'bn2': 0.0005362033843994141, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010497570037841797, 'bn1': 0.0003154277801513672, 'relu1': 0.000171661376953125, 'conv2': 0.0013089179992675781, 'bn2': 0.0003085136413574219, 'conv3': 0.00040221214294433594, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013089179992675781, 'bn1': 0.00030684471130371094, 'relu1': 0.00017023086547851562, 'conv2': 0.0013034343719482422, 'bn2': 0.00030493736267089844, 'residual_add_relu2': 0.0003876686096191406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007886886596679688, 'bn1': 0.00019502639770507812, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.0001881122589111328, 'conv3': 0.00035190582275390625, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011584758758544922, 'bn1': 0.00020623207092285156, 'relu1': 9.894371032714844e-05, 'conv2': 0.001155853271484375, 'bn2': 0.00019478797912597656, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006594657897949219, 'bn1': 0.00012135505676269531, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.00011706352233886719, 'conv3': 0.0002913475036621094, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.001148223876953125, 'bn1': 0.00012135505676269531, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011436939239501953, 'bn2': 0.00011420249938964844, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 252\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016582012176513672, 'bn1': 0.0005495548248291016, 'relu1': 0.0003237724304199219, 'conv2': 0.0016369819641113281, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.0016324520111083984, 'bn1': 0.0005476474761962891, 'relu1': 0.00032329559326171875, 'conv2': 0.0016300678253173828, 'bn2': 0.0005338191986083984, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010445117950439453, 'bn1': 0.00030875205993652344, 'relu1': 0.0001704692840576172, 'conv2': 0.0013053417205810547, 'bn2': 0.0003058910369873047, 'conv3': 0.0003955364227294922, 'residual_add_relu2': 0.00038886070251464844}\n",
      "{'conv1': 0.0013072490692138672, 'bn1': 0.0003075599670410156, 'relu1': 0.00017023086547851562, 'conv2': 0.001302957534790039, 'bn2': 0.0003063678741455078, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007886886596679688, 'bn1': 0.0001995563507080078, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011544227600097656, 'bn2': 0.00018906593322753906, 'conv3': 0.00034880638122558594, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011570453643798828, 'bn1': 0.000194549560546875, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011508464813232422, 'bn2': 0.0001857280731201172, 'residual_add_relu2': 0.00020599365234375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006587505340576172, 'bn1': 0.00011396408081054688, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011436939239501953, 'bn2': 0.0001125335693359375, 'conv3': 0.00028824806213378906, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.0011451244354248047, 'bn1': 0.00012135505676269531, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011444091796875, 'bn2': 0.00011515617370605469, 'residual_add_relu2': 0.00011539459228515625}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 253\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001646280288696289, 'bn1': 0.0005526542663574219, 'relu1': 0.0003261566162109375, 'conv2': 0.0016269683837890625, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007693767547607422}\n",
      "{'conv1': 0.0016319751739501953, 'bn1': 0.0005450248718261719, 'relu1': 0.00032329559326171875, 'conv2': 0.0016252994537353516, 'bn2': 0.0005357265472412109, 'residual_add_relu2': 0.0007662773132324219}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010485649108886719, 'bn1': 0.000316619873046875, 'relu1': 0.0001723766326904297, 'conv2': 0.0013082027435302734, 'bn2': 0.00031757354736328125, 'conv3': 0.0003993511199951172, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.001306295394897461, 'bn1': 0.00033211708068847656, 'relu1': 0.00017189979553222656, 'conv2': 0.0013048648834228516, 'bn2': 0.0003120899200439453, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007884502410888672, 'bn1': 0.00020122528076171875, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.00019359588623046875, 'conv3': 0.0003523826599121094, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.001165628433227539, 'bn1': 0.00020265579223632812, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011544227600097656, 'bn2': 0.00019478797912597656, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006654262542724609, 'bn1': 0.0001239776611328125, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00011801719665527344, 'conv3': 0.0002944469451904297, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011475086212158203, 'bn1': 0.00011968612670898438, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011448860168457031, 'bn2': 0.00011849403381347656, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 254\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016505718231201172, 'bn1': 0.0005657672882080078, 'relu1': 0.00032448768615722656, 'conv2': 0.0016279220581054688, 'bn2': 0.0005340576171875, 'residual_add_relu2': 0.0007638931274414062}\n",
      "{'conv1': 0.0016326904296875, 'bn1': 0.0005540847778320312, 'relu1': 0.00032448768615722656, 'conv2': 0.0016317367553710938, 'bn2': 0.0005433559417724609, 'residual_add_relu2': 0.000766754150390625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010573863983154297, 'bn1': 0.0003170967102050781, 'relu1': 0.00017333030700683594, 'conv2': 0.001310110092163086, 'bn2': 0.00030803680419921875, 'conv3': 0.0004057884216308594, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013120174407958984, 'bn1': 0.0003139972686767578, 'relu1': 0.0001735687255859375, 'conv2': 0.0013055801391601562, 'bn2': 0.00030612945556640625, 'residual_add_relu2': 0.0003879070281982422}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007867813110351562, 'bn1': 0.00019168853759765625, 'relu1': 9.679794311523438e-05, 'conv2': 0.001153707504272461, 'bn2': 0.0001850128173828125, 'conv3': 0.0003495216369628906, 'residual_add_relu2': 0.0002028942108154297}\n",
      "{'conv1': 0.0011544227600097656, 'bn1': 0.00020074844360351562, 'relu1': 9.584426879882812e-05, 'conv2': 0.0011539459228515625, 'bn2': 0.0001857280731201172, 'residual_add_relu2': 0.00020265579223632812}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006601810455322266, 'bn1': 0.0001442432403564453, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00011372566223144531, 'conv3': 0.0002903938293457031, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011487007141113281, 'bn1': 0.00011587142944335938, 'relu1': 5.888938903808594e-05, 'conv2': 0.001146078109741211, 'bn2': 0.00013875961303710938, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 255\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016531944274902344, 'bn1': 0.0005562305450439453, 'relu1': 0.0003235340118408203, 'conv2': 0.0016412734985351562, 'bn2': 0.0005424022674560547, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.001638650894165039, 'bn1': 0.0005495548248291016, 'relu1': 0.000324249267578125, 'conv2': 0.0016312599182128906, 'bn2': 0.0005309581756591797, 'residual_add_relu2': 0.0007617473602294922}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010526180267333984, 'bn1': 0.0003154277801513672, 'relu1': 0.00017261505126953125, 'conv2': 0.0013086795806884766, 'bn2': 0.00032782554626464844, 'conv3': 0.0004017353057861328, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013134479522705078, 'bn1': 0.0003151893615722656, 'relu1': 0.00017380714416503906, 'conv2': 0.0013079643249511719, 'bn2': 0.0003082752227783203, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007908344268798828, 'bn1': 0.0002002716064453125, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.00019288063049316406, 'conv3': 0.00035381317138671875, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.001163482666015625, 'bn1': 0.0002124309539794922, 'relu1': 0.00010180473327636719, 'conv2': 0.0011601448059082031, 'bn2': 0.00020384788513183594, 'residual_add_relu2': 0.00020694732666015625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006561279296875, 'bn1': 0.00012087821960449219, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011470317840576172, 'bn2': 0.00011777877807617188, 'conv3': 0.0002951622009277344, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011494159698486328, 'bn1': 0.00012111663818359375, 'relu1': 5.745887756347656e-05, 'conv2': 0.001140594482421875, 'bn2': 0.0001087188720703125, 'residual_add_relu2': 0.0001087188720703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 256\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.00164794921875, 'bn1': 0.0005538463592529297, 'relu1': 0.00032329559326171875, 'conv2': 0.001634836196899414, 'bn2': 0.0005404949188232422, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016322135925292969, 'bn1': 0.0005445480346679688, 'relu1': 0.0003218650817871094, 'conv2': 0.0016238689422607422, 'bn2': 0.0005385875701904297, 'residual_add_relu2': 0.0007643699645996094}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010447502136230469, 'bn1': 0.00031185150146484375, 'relu1': 0.00017118453979492188, 'conv2': 0.0013079643249511719, 'bn2': 0.00030422210693359375, 'conv3': 0.0003979206085205078, 'residual_add_relu2': 0.00039267539978027344}\n",
      "{'conv1': 0.0013120174407958984, 'bn1': 0.0003082752227783203, 'relu1': 0.00017213821411132812, 'conv2': 0.0013036727905273438, 'bn2': 0.00030040740966796875, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007846355438232422, 'bn1': 0.0001895427703857422, 'relu1': 9.584426879882812e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.00018715858459472656, 'conv3': 0.0003476142883300781, 'residual_add_relu2': 0.00020265579223632812}\n",
      "{'conv1': 0.0011546611785888672, 'bn1': 0.00019812583923339844, 'relu1': 9.918212890625e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.00019812583923339844, 'residual_add_relu2': 0.00020313262939453125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006587505340576172, 'bn1': 0.00011706352233886719, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011458396911621094, 'bn2': 0.00012302398681640625, 'conv3': 0.000293731689453125, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011458396911621094, 'bn1': 0.00012087821960449219, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011444091796875, 'bn2': 0.00012087821960449219, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 257\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016508102416992188, 'bn1': 0.0005526542663574219, 'relu1': 0.0003230571746826172, 'conv2': 0.001631021499633789, 'bn2': 0.0005421638488769531, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016331672668457031, 'bn1': 0.000560760498046875, 'relu1': 0.0003249645233154297, 'conv2': 0.0016274452209472656, 'bn2': 0.0005381107330322266, 'residual_add_relu2': 0.0007643699645996094}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010471343994140625, 'bn1': 0.0003147125244140625, 'relu1': 0.0001723766326904297, 'conv2': 0.001310110092163086, 'bn2': 0.00030994415283203125, 'conv3': 0.0004107952117919922, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013093948364257812, 'bn1': 0.000324249267578125, 'relu1': 0.00017452239990234375, 'conv2': 0.0013074874877929688, 'bn2': 0.0004038810729980469, 'residual_add_relu2': 0.0003924369812011719}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007922649383544922, 'bn1': 0.00023055076599121094, 'relu1': 0.00010251998901367188, 'conv2': 0.0011637210845947266, 'bn2': 0.0001990795135498047, 'conv3': 0.0003535747528076172, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011591911315917969, 'bn1': 0.00020456314086914062, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011551380157470703, 'bn2': 0.00018906593322753906, 'residual_add_relu2': 0.0002033710479736328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006566047668457031, 'bn1': 0.00011491775512695312, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011458396911621094, 'bn2': 0.00012946128845214844, 'conv3': 0.00028777122497558594, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.0011453628540039062, 'bn1': 0.00011515617370605469, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011425018310546875, 'bn2': 0.00011944770812988281, 'residual_add_relu2': 0.0001087188720703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 258\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016524791717529297, 'bn1': 0.00055694580078125, 'relu1': 0.00032591819763183594, 'conv2': 0.0016317367553710938, 'bn2': 0.0005371570587158203, 'residual_add_relu2': 0.0007646083831787109}\n",
      "{'conv1': 0.0016312599182128906, 'bn1': 0.0005400180816650391, 'relu1': 0.00032210350036621094, 'conv2': 0.0016298294067382812, 'bn2': 0.0005338191986083984, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010426044464111328, 'bn1': 0.0003066062927246094, 'relu1': 0.00017070770263671875, 'conv2': 0.0013189315795898438, 'bn2': 0.00030493736267089844, 'conv3': 0.00040149688720703125, 'residual_add_relu2': 0.00038933753967285156}\n",
      "{'conv1': 0.0013077259063720703, 'bn1': 0.00030422210693359375, 'relu1': 0.00017023086547851562, 'conv2': 0.0013041496276855469, 'bn2': 0.0003116130828857422, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007913112640380859, 'bn1': 0.00020170211791992188, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011568069458007812, 'bn2': 0.00019407272338867188, 'conv3': 0.0003542900085449219, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011570453643798828, 'bn1': 0.0002033710479736328, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.0001990795135498047, 'residual_add_relu2': 0.00020766258239746094}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006597042083740234, 'bn1': 0.00012612342834472656, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.0001304149627685547, 'conv3': 0.00029969215393066406, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011489391326904297, 'bn1': 0.00011396408081054688, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.00011324882507324219, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 259\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016524791717529297, 'bn1': 0.0005550384521484375, 'relu1': 0.0003266334533691406, 'conv2': 0.0016341209411621094, 'bn2': 0.0005435943603515625, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.0016374588012695312, 'bn1': 0.0005497932434082031, 'relu1': 0.00032448768615722656, 'conv2': 0.0016279220581054688, 'bn2': 0.0005383491516113281, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010485649108886719, 'bn1': 0.00032138824462890625, 'relu1': 0.0001728534698486328, 'conv2': 0.0013120174407958984, 'bn2': 0.0003345012664794922, 'conv3': 0.0004031658172607422, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013124942779541016, 'bn1': 0.00031876564025878906, 'relu1': 0.00017452239990234375, 'conv2': 0.0013089179992675781, 'bn2': 0.000316619873046875, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007917881011962891, 'bn1': 0.0001990795135498047, 'relu1': 9.799003601074219e-05, 'conv2': 0.001157999038696289, 'bn2': 0.00019478797912597656, 'conv3': 0.00035452842712402344, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011603832244873047, 'bn1': 0.00020194053649902344, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011539459228515625, 'bn2': 0.0002090930938720703, 'residual_add_relu2': 0.00020647048950195312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006632804870605469, 'bn1': 0.00013184547424316406, 'relu1': 6.151199340820312e-05, 'conv2': 0.0011622905731201172, 'bn2': 0.0001220703125, 'conv3': 0.0002949237823486328, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011496543884277344, 'bn1': 0.0001232624053955078, 'relu1': 5.9604644775390625e-05, 'conv2': 0.001146554946899414, 'bn2': 0.0001270771026611328, 'residual_add_relu2': 0.00011205673217773438}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 260\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001672506332397461, 'bn1': 0.0005693435668945312, 'relu1': 0.0003285408020019531, 'conv2': 0.0016522407531738281, 'bn2': 0.0005462169647216797, 'residual_add_relu2': 0.0007700920104980469}\n",
      "{'conv1': 0.0016541481018066406, 'bn1': 0.00054931640625, 'relu1': 0.00032830238342285156, 'conv2': 0.0016331672668457031, 'bn2': 0.0005462169647216797, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010561943054199219, 'bn1': 0.00031948089599609375, 'relu1': 0.00017595291137695312, 'conv2': 0.0013246536254882812, 'bn2': 0.0003204345703125, 'conv3': 0.000408172607421875, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013170242309570312, 'bn1': 0.0003170967102050781, 'relu1': 0.00017452239990234375, 'conv2': 0.0013129711151123047, 'bn2': 0.0003211498260498047, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007898807525634766, 'bn1': 0.00020360946655273438, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011582374572753906, 'bn2': 0.00019669532775878906, 'conv3': 0.00036144256591796875, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00019812583923339844, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.000194549560546875, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006606578826904297, 'bn1': 0.00013518333435058594, 'relu1': 6.103515625e-05, 'conv2': 0.0011491775512695312, 'bn2': 0.00011420249938964844, 'conv3': 0.00029349327087402344, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011463165283203125, 'bn1': 0.0001239776611328125, 'relu1': 5.936622619628906e-05, 'conv2': 0.001146078109741211, 'bn2': 0.00011944770812988281, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 261\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016582012176513672, 'bn1': 0.0005574226379394531, 'relu1': 0.0003249645233154297, 'conv2': 0.0016336441040039062, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007696151733398438}\n",
      "{'conv1': 0.0016319751739501953, 'bn1': 0.0005428791046142578, 'relu1': 0.0003261566162109375, 'conv2': 0.0016276836395263672, 'bn2': 0.0005552768707275391, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010488033294677734, 'bn1': 0.00032019615173339844, 'relu1': 0.00017309188842773438, 'conv2': 0.0013120174407958984, 'bn2': 0.0003116130828857422, 'conv3': 0.00040268898010253906, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013113021850585938, 'bn1': 0.00031685829162597656, 'relu1': 0.0001761913299560547, 'conv2': 0.0013086795806884766, 'bn2': 0.0003039836883544922, 'residual_add_relu2': 0.00038814544677734375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007901191711425781, 'bn1': 0.0001964569091796875, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011548995971679688, 'bn2': 0.00019168853759765625, 'conv3': 0.0003509521484375, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.001154184341430664, 'bn1': 0.00019550323486328125, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.0001990795135498047, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006656646728515625, 'bn1': 0.0001239776611328125, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011496543884277344, 'bn2': 0.00011587142944335938, 'conv3': 0.0002956390380859375, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011489391326904297, 'bn1': 0.0001232624053955078, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011446475982666016, 'bn2': 0.0001163482666015625, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 262\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016613006591796875, 'bn1': 0.0005600452423095703, 'relu1': 0.0003285408020019531, 'conv2': 0.0016307830810546875, 'bn2': 0.0005462169647216797, 'residual_add_relu2': 0.0007684230804443359}\n",
      "{'conv1': 0.0016405582427978516, 'bn1': 0.0005505084991455078, 'relu1': 0.00032258033752441406, 'conv2': 0.001634836196899414, 'bn2': 0.0005452632904052734, 'residual_add_relu2': 0.0007617473602294922}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010480880737304688, 'bn1': 0.0003082752227783203, 'relu1': 0.0001709461212158203, 'conv2': 0.0013091564178466797, 'bn2': 0.0003046989440917969, 'conv3': 0.00039649009704589844, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013058185577392578, 'bn1': 0.0006797313690185547, 'relu1': 0.00020432472229003906, 'conv2': 0.0013244152069091797, 'bn2': 0.0003383159637451172, 'residual_add_relu2': 0.00039196014404296875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008206367492675781, 'bn1': 0.0002129077911376953, 'relu1': 0.0001277923583984375, 'conv2': 0.001169443130493164, 'bn2': 0.0002086162567138672, 'conv3': 0.0003578662872314453, 'residual_add_relu2': 0.0002067089080810547}\n",
      "{'conv1': 0.001163482666015625, 'bn1': 0.0002086162567138672, 'relu1': 0.00010013580322265625, 'conv2': 0.0011594295501708984, 'bn2': 0.00021004676818847656, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006692409515380859, 'bn1': 0.00013780593872070312, 'relu1': 6.318092346191406e-05, 'conv2': 0.001153707504272461, 'bn2': 0.0001227855682373047, 'conv3': 0.00030040740966796875, 'residual_add_relu2': 0.00011301040649414062}\n",
      "{'conv1': 0.0011553764343261719, 'bn1': 0.0001361370086669922, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011501312255859375, 'bn2': 0.00012421607971191406, 'residual_add_relu2': 0.00011205673217773438}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 263\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016622543334960938, 'bn1': 0.0005688667297363281, 'relu1': 0.00032782554626464844, 'conv2': 0.0016355514526367188, 'bn2': 0.000553131103515625, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016405582427978516, 'bn1': 0.0005476474761962891, 'relu1': 0.00032448768615722656, 'conv2': 0.0016345977783203125, 'bn2': 0.0005381107330322266, 'residual_add_relu2': 0.0007672309875488281}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010509490966796875, 'bn1': 0.0003170967102050781, 'relu1': 0.00017309188842773438, 'conv2': 0.0013103485107421875, 'bn2': 0.0003097057342529297, 'conv3': 0.0004038810729980469, 'residual_add_relu2': 0.0003921985626220703}\n",
      "{'conv1': 0.0013115406036376953, 'bn1': 0.00031495094299316406, 'relu1': 0.00017404556274414062, 'conv2': 0.0013072490692138672, 'bn2': 0.00031065940856933594, 'residual_add_relu2': 0.00039267539978027344}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007944107055664062, 'bn1': 0.0002040863037109375, 'relu1': 9.989738464355469e-05, 'conv2': 0.001157522201538086, 'bn2': 0.00019741058349609375, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011603832244873047, 'bn1': 0.00020360946655273438, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011544227600097656, 'bn2': 0.00019598007202148438, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006608963012695312, 'bn1': 0.0001232624053955078, 'relu1': 5.91278076171875e-05, 'conv2': 0.001148223876953125, 'bn2': 0.00011730194091796875, 'conv3': 0.00029540061950683594, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011487007141113281, 'bn1': 0.0001227855682373047, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011458396911621094, 'bn2': 0.00011515617370605469, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 264\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016484260559082031, 'bn1': 0.0005578994750976562, 'relu1': 0.000324249267578125, 'conv2': 0.0016357898712158203, 'bn2': 0.0005426406860351562, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.001642465591430664, 'bn1': 0.0005452632904052734, 'relu1': 0.00032520294189453125, 'conv2': 0.0016260147094726562, 'bn2': 0.0005660057067871094, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010516643524169922, 'bn1': 0.00031638145446777344, 'relu1': 0.00017333030700683594, 'conv2': 0.0013146400451660156, 'bn2': 0.00031566619873046875, 'conv3': 0.0004029273986816406, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.001310586929321289, 'bn1': 0.0003154277801513672, 'relu1': 0.00017380714416503906, 'conv2': 0.0013103485107421875, 'bn2': 0.0003123283386230469, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007903575897216797, 'bn1': 0.00019979476928710938, 'relu1': 9.822845458984375e-05, 'conv2': 0.001157999038696289, 'bn2': 0.00020623207092285156, 'conv3': 0.000354766845703125, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011589527130126953, 'bn1': 0.0002009868621826172, 'relu1': 9.918212890625e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.00019431114196777344, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006618499755859375, 'bn1': 0.00012493133544921875, 'relu1': 5.936622619628906e-05, 'conv2': 0.001148223876953125, 'bn2': 0.00013518333435058594, 'conv3': 0.0002963542938232422, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011489391326904297, 'bn1': 0.0001227855682373047, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011463165283203125, 'bn2': 0.00011754035949707031, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 265\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016472339630126953, 'bn1': 0.0005478858947753906, 'relu1': 0.00032448768615722656, 'conv2': 0.0016303062438964844, 'bn2': 0.0005371570587158203, 'residual_add_relu2': 0.0007634162902832031}\n",
      "{'conv1': 0.0016293525695800781, 'bn1': 0.0005459785461425781, 'relu1': 0.0003247261047363281, 'conv2': 0.0016298294067382812, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001049041748046875, 'bn1': 0.00031566619873046875, 'relu1': 0.00017261505126953125, 'conv2': 0.0013103485107421875, 'bn2': 0.0003094673156738281, 'conv3': 0.0003991127014160156, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013117790222167969, 'bn1': 0.0003135204315185547, 'relu1': 0.0001735687255859375, 'conv2': 0.0013086795806884766, 'bn2': 0.000308990478515625, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007867813110351562, 'bn1': 0.0002048015594482422, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011534690856933594, 'bn2': 0.0001914501190185547, 'conv3': 0.0003516674041748047, 'residual_add_relu2': 0.00021076202392578125}\n",
      "{'conv1': 0.0011653900146484375, 'bn1': 0.00020933151245117188, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011548995971679688, 'bn2': 0.0001900196075439453, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006575584411621094, 'bn1': 0.00011706352233886719, 'relu1': 5.817413330078125e-05, 'conv2': 0.001146554946899414, 'bn2': 0.00011348724365234375, 'conv3': 0.00029587745666503906, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011463165283203125, 'bn1': 0.00013017654418945312, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011472702026367188, 'bn2': 0.00011444091796875, 'residual_add_relu2': 0.0001087188720703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 266\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001676797866821289, 'bn1': 0.0006048679351806641, 'relu1': 0.0003352165222167969, 'conv2': 0.0016481876373291016, 'bn2': 0.000598907470703125, 'residual_add_relu2': 0.0007808208465576172}\n",
      "{'conv1': 0.0016567707061767578, 'bn1': 0.0005807876586914062, 'relu1': 0.00033164024353027344, 'conv2': 0.0016508102416992188, 'bn2': 0.0005719661712646484, 'residual_add_relu2': 0.0007700920104980469}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010688304901123047, 'bn1': 0.00034618377685546875, 'relu1': 0.00018072128295898438, 'conv2': 0.0013239383697509766, 'bn2': 0.00034999847412109375, 'conv3': 0.00042366981506347656, 'residual_add_relu2': 0.00039839744567871094}\n",
      "{'conv1': 0.0013267993927001953, 'bn1': 0.0003426074981689453, 'relu1': 0.0001811981201171875, 'conv2': 0.0013229846954345703, 'bn2': 0.0003414154052734375, 'residual_add_relu2': 0.0003962516784667969}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008077621459960938, 'bn1': 0.00023174285888671875, 'relu1': 0.00010704994201660156, 'conv2': 0.0011889934539794922, 'bn2': 0.00023365020751953125, 'conv3': 0.0003726482391357422, 'residual_add_relu2': 0.0002110004425048828}\n",
      "{'conv1': 0.001172780990600586, 'bn1': 0.0002288818359375, 'relu1': 0.00010657310485839844, 'conv2': 0.0011703968048095703, 'bn2': 0.00022363662719726562, 'residual_add_relu2': 0.0002219676971435547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006792545318603516, 'bn1': 0.0001533031463623047, 'relu1': 6.723403930664062e-05, 'conv2': 0.0011644363403320312, 'bn2': 0.0001697540283203125, 'conv3': 0.00031876564025878906, 'residual_add_relu2': 0.00011658668518066406}\n",
      "{'conv1': 0.0011646747589111328, 'bn1': 0.00015735626220703125, 'relu1': 6.747245788574219e-05, 'conv2': 0.0011606216430664062, 'bn2': 0.0001442432403564453, 'residual_add_relu2': 0.00011539459228515625}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 267\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016515254974365234, 'bn1': 0.0005664825439453125, 'relu1': 0.00032830238342285156, 'conv2': 0.0016372203826904297, 'bn2': 0.0005669593811035156, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016357898712158203, 'bn1': 0.0005526542663574219, 'relu1': 0.00032401084899902344, 'conv2': 0.001634359359741211, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007643699645996094}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010471343994140625, 'bn1': 0.00031638145446777344, 'relu1': 0.00017309188842773438, 'conv2': 0.0013098716735839844, 'bn2': 0.0003037452697753906, 'conv3': 0.0003993511199951172, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013093948364257812, 'bn1': 0.00030994415283203125, 'relu1': 0.00017213821411132812, 'conv2': 0.0013096332550048828, 'bn2': 0.0003807544708251953, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007932186126708984, 'bn1': 0.00020241737365722656, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011577606201171875, 'bn2': 0.00019621849060058594, 'conv3': 0.0003552436828613281, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011603832244873047, 'bn1': 0.0002040863037109375, 'relu1': 9.846687316894531e-05, 'conv2': 0.001155853271484375, 'bn2': 0.00019550323486328125, 'residual_add_relu2': 0.00020575523376464844}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006625652313232422, 'bn1': 0.00012421607971191406, 'relu1': 6.151199340820312e-05, 'conv2': 0.0011861324310302734, 'bn2': 0.0002655982971191406, 'conv3': 0.00032138824462890625, 'residual_add_relu2': 0.00011515617370605469}\n",
      "{'conv1': 0.0011584758758544922, 'bn1': 0.00013184547424316406, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011501312255859375, 'bn2': 0.00012922286987304688, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 268\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016551017761230469, 'bn1': 0.0005609989166259766, 'relu1': 0.0003254413604736328, 'conv2': 0.0016319751739501953, 'bn2': 0.000545501708984375, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016312599182128906, 'bn1': 0.0005471706390380859, 'relu1': 0.0003216266632080078, 'conv2': 0.0016329288482666016, 'bn2': 0.0005400180816650391, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010521411895751953, 'bn1': 0.00031566619873046875, 'relu1': 0.00017261505126953125, 'conv2': 0.0013110637664794922, 'bn2': 0.00031185150146484375, 'conv3': 0.000400543212890625, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013110637664794922, 'bn1': 0.0003180503845214844, 'relu1': 0.00017547607421875, 'conv2': 0.0013079643249511719, 'bn2': 0.0003123283386230469, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007898807525634766, 'bn1': 0.0001983642578125, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011551380157470703, 'bn2': 0.0001888275146484375, 'conv3': 0.0003533363342285156, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.0011606216430664062, 'bn1': 0.0001976490020751953, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011529922485351562, 'bn2': 0.00018739700317382812, 'residual_add_relu2': 0.00020241737365722656}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006601810455322266, 'bn1': 0.00011777877807617188, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011501312255859375, 'bn2': 0.00011777877807617188, 'conv3': 0.00029087066650390625, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011463165283203125, 'bn1': 0.00011396408081054688, 'relu1': 5.7220458984375e-05, 'conv2': 0.0011420249938964844, 'bn2': 0.000110626220703125, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 269\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016531944274902344, 'bn1': 0.0005567073822021484, 'relu1': 0.00032401084899902344, 'conv2': 0.0016393661499023438, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0017359256744384766, 'bn1': 0.0005729198455810547, 'relu1': 0.00033354759216308594, 'conv2': 0.0016422271728515625, 'bn2': 0.0005438327789306641, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010557174682617188, 'bn1': 0.0003154277801513672, 'relu1': 0.0001766681671142578, 'conv2': 0.00131988525390625, 'bn2': 0.0003116130828857422, 'conv3': 0.00041413307189941406, 'residual_add_relu2': 0.00039267539978027344}\n",
      "{'conv1': 0.0013148784637451172, 'bn1': 0.0003180503845214844, 'relu1': 0.00017952919006347656, 'conv2': 0.0013165473937988281, 'bn2': 0.00032067298889160156, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007970333099365234, 'bn1': 0.00021338462829589844, 'relu1': 0.00010514259338378906, 'conv2': 0.001163482666015625, 'bn2': 0.00020742416381835938, 'conv3': 0.0003647804260253906, 'residual_add_relu2': 0.00020647048950195312}\n",
      "{'conv1': 0.0011594295501708984, 'bn1': 0.0002124309539794922, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.00021266937255859375, 'residual_add_relu2': 0.00020694732666015625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006630420684814453, 'bn1': 0.00012421607971191406, 'relu1': 5.9604644775390625e-05, 'conv2': 0.001150369644165039, 'bn2': 0.00011849403381347656, 'conv3': 0.0002963542938232422, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011496543884277344, 'bn1': 0.00019168853759765625, 'relu1': 6.222724914550781e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.00012826919555664062, 'residual_add_relu2': 0.00011301040649414062}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 270\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016791820526123047, 'bn1': 0.0005819797515869141, 'relu1': 0.00033354759216308594, 'conv2': 0.0016565322875976562, 'bn2': 0.0005729198455810547, 'residual_add_relu2': 0.0007719993591308594}\n",
      "{'conv1': 0.0016484260559082031, 'bn1': 0.0005769729614257812, 'relu1': 0.0003311634063720703, 'conv2': 0.0016405582427978516, 'bn2': 0.0005629062652587891, 'residual_add_relu2': 0.0007693767547607422}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010747909545898438, 'bn1': 0.0003528594970703125, 'relu1': 0.0001952648162841797, 'conv2': 0.0013256072998046875, 'bn2': 0.0003368854522705078, 'conv3': 0.00041604042053222656, 'residual_add_relu2': 0.0003962516784667969}\n",
      "{'conv1': 0.0013267993927001953, 'bn1': 0.00034117698669433594, 'relu1': 0.00018405914306640625, 'conv2': 0.001322031021118164, 'bn2': 0.0003342628479003906, 'residual_add_relu2': 0.0003955364227294922}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008068084716796875, 'bn1': 0.00022673606872558594, 'relu1': 0.00010561943054199219, 'conv2': 0.0011684894561767578, 'bn2': 0.0002205371856689453, 'conv3': 0.0003662109375, 'residual_add_relu2': 0.00020837783813476562}\n",
      "{'conv1': 0.001171112060546875, 'bn1': 0.0002923011779785156, 'relu1': 0.00010943412780761719, 'conv2': 0.0011718273162841797, 'bn2': 0.00022029876708984375, 'residual_add_relu2': 0.00020885467529296875}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000675201416015625, 'bn1': 0.00014734268188476562, 'relu1': 6.604194641113281e-05, 'conv2': 0.001161336898803711, 'bn2': 0.00014495849609375, 'conv3': 0.0003120899200439453, 'residual_add_relu2': 0.00011706352233886719}\n",
      "{'conv1': 0.0011873245239257812, 'bn1': 0.00020313262939453125, 'relu1': 7.081031799316406e-05, 'conv2': 0.0011730194091796875, 'bn2': 0.00023865699768066406, 'residual_add_relu2': 0.00012183189392089844}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 271\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016698837280273438, 'bn1': 0.0005843639373779297, 'relu1': 0.0003306865692138672, 'conv2': 0.0016448497772216797, 'bn2': 0.0005700588226318359, 'residual_add_relu2': 0.0007700920104980469}\n",
      "{'conv1': 0.0016443729400634766, 'bn1': 0.0005724430084228516, 'relu1': 0.00032973289489746094, 'conv2': 0.0016376972198486328, 'bn2': 0.0005631446838378906, 'residual_add_relu2': 0.0007700920104980469}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010635852813720703, 'bn1': 0.0003414154052734375, 'relu1': 0.00017905235290527344, 'conv2': 0.001323699951171875, 'bn2': 0.0003330707550048828, 'conv3': 0.00041484832763671875, 'residual_add_relu2': 0.00039696693420410156}\n",
      "{'conv1': 0.0013244152069091797, 'bn1': 0.0003402233123779297, 'relu1': 0.0001800060272216797, 'conv2': 0.00131988525390625, 'bn2': 0.0003314018249511719, 'residual_add_relu2': 0.00039505958557128906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008027553558349609, 'bn1': 0.0002231597900390625, 'relu1': 0.00010538101196289062, 'conv2': 0.001169443130493164, 'bn2': 0.00022101402282714844, 'conv3': 0.0003681182861328125, 'residual_add_relu2': 0.0002086162567138672}\n",
      "{'conv1': 0.0011701583862304688, 'bn1': 0.0002288818359375, 'relu1': 0.00010538101196289062, 'conv2': 0.0011706352233886719, 'bn2': 0.00024437904357910156, 'residual_add_relu2': 0.00021076202392578125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006783008575439453, 'bn1': 0.000148773193359375, 'relu1': 6.699562072753906e-05, 'conv2': 0.0011620521545410156, 'bn2': 0.0001506805419921875, 'conv3': 0.00031185150146484375, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.0011670589447021484, 'bn1': 0.00014829635620117188, 'relu1': 6.556510925292969e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.00014543533325195312, 'residual_add_relu2': 0.00011539459228515625}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 272\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001680612564086914, 'bn1': 0.0005891323089599609, 'relu1': 0.00033020973205566406, 'conv2': 0.001651763916015625, 'bn2': 0.0005791187286376953, 'residual_add_relu2': 0.000774383544921875}\n",
      "{'conv1': 0.0016503334045410156, 'bn1': 0.0005948543548583984, 'relu1': 0.00033092498779296875, 'conv2': 0.0016541481018066406, 'bn2': 0.0005700588226318359, 'residual_add_relu2': 0.0007669925689697266}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010645389556884766, 'bn1': 0.00034427642822265625, 'relu1': 0.000179290771484375, 'conv2': 0.0013277530670166016, 'bn2': 0.0003345012664794922, 'conv3': 0.00041985511779785156, 'residual_add_relu2': 0.00039649009704589844}\n",
      "{'conv1': 0.0013244152069091797, 'bn1': 0.0003421306610107422, 'relu1': 0.00018024444580078125, 'conv2': 0.0013217926025390625, 'bn2': 0.0004012584686279297, 'residual_add_relu2': 0.0003991127014160156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008096694946289062, 'bn1': 0.0002307891845703125, 'relu1': 0.00010466575622558594, 'conv2': 0.0011718273162841797, 'bn2': 0.0002257823944091797, 'conv3': 0.0003695487976074219, 'residual_add_relu2': 0.000209808349609375}\n",
      "{'conv1': 0.0011720657348632812, 'bn1': 0.0002276897430419922, 'relu1': 0.00010466575622558594, 'conv2': 0.0011677742004394531, 'bn2': 0.00022912025451660156, 'residual_add_relu2': 0.0002090930938720703}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000675201416015625, 'bn1': 0.00015425682067871094, 'relu1': 6.604194641113281e-05, 'conv2': 0.0011649131774902344, 'bn2': 0.00014853477478027344, 'conv3': 0.0003147125244140625, 'residual_add_relu2': 0.0001163482666015625}\n",
      "{'conv1': 0.0011661052703857422, 'bn1': 0.00015091896057128906, 'relu1': 6.556510925292969e-05, 'conv2': 0.001157999038696289, 'bn2': 0.00015997886657714844, 'residual_add_relu2': 0.00011563301086425781}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 273\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016634464263916016, 'bn1': 0.0005815029144287109, 'relu1': 0.000331878662109375, 'conv2': 0.0016551017761230469, 'bn2': 0.0005688667297363281, 'residual_add_relu2': 0.0007715225219726562}\n",
      "{'conv1': 0.0016448497772216797, 'bn1': 0.0005826950073242188, 'relu1': 0.00033164024353027344, 'conv2': 0.0016515254974365234, 'bn2': 0.0005784034729003906, 'residual_add_relu2': 0.0007686614990234375}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010650157928466797, 'bn1': 0.0003407001495361328, 'relu1': 0.000179290771484375, 'conv2': 0.0013210773468017578, 'bn2': 0.00033402442932128906, 'conv3': 0.00041413307189941406, 'residual_add_relu2': 0.00039386749267578125}\n",
      "{'conv1': 0.0013251304626464844, 'bn1': 0.0003399848937988281, 'relu1': 0.00018024444580078125, 'conv2': 0.0013191699981689453, 'bn2': 0.0004189014434814453, 'residual_add_relu2': 0.000396728515625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008077621459960938, 'bn1': 0.00022673606872558594, 'relu1': 0.0001049041748046875, 'conv2': 0.001171112060546875, 'bn2': 0.000217437744140625, 'conv3': 0.00036597251892089844, 'residual_add_relu2': 0.0002086162567138672}\n",
      "{'conv1': 0.0011763572692871094, 'bn1': 0.0002262592315673828, 'relu1': 0.0001049041748046875, 'conv2': 0.0011665821075439453, 'bn2': 0.0002193450927734375, 'residual_add_relu2': 0.00021028518676757812}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006749629974365234, 'bn1': 0.00015616416931152344, 'relu1': 6.771087646484375e-05, 'conv2': 0.0011620521545410156, 'bn2': 0.00014162063598632812, 'conv3': 0.00030732154846191406, 'residual_add_relu2': 0.00011587142944335938}\n",
      "{'conv1': 0.001161336898803711, 'bn1': 0.0001468658447265625, 'relu1': 6.604194641113281e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.0001430511474609375, 'residual_add_relu2': 0.00011491775512695312}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 274\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001676797866821289, 'bn1': 0.0005791187286376953, 'relu1': 0.0003311634063720703, 'conv2': 0.0016551017761230469, 'bn2': 0.0005681514739990234, 'residual_add_relu2': 0.0007703304290771484}\n",
      "{'conv1': 0.0016601085662841797, 'bn1': 0.0005700588226318359, 'relu1': 0.00033473968505859375, 'conv2': 0.0016503334045410156, 'bn2': 0.0005638599395751953, 'residual_add_relu2': 0.0007693767547607422}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010652542114257812, 'bn1': 0.0003390312194824219, 'relu1': 0.00017952919006347656, 'conv2': 0.0013208389282226562, 'bn2': 0.00033402442932128906, 'conv3': 0.0004229545593261719, 'residual_add_relu2': 0.00039696693420410156}\n",
      "{'conv1': 0.001329660415649414, 'bn1': 0.0003459453582763672, 'relu1': 0.00018024444580078125, 'conv2': 0.0013239383697509766, 'bn2': 0.0003380775451660156, 'residual_add_relu2': 0.000396728515625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008041858673095703, 'bn1': 0.00022363662719726562, 'relu1': 0.00010442733764648438, 'conv2': 0.0011701583862304688, 'bn2': 0.0002205371856689453, 'conv3': 0.0003650188446044922, 'residual_add_relu2': 0.000209808349609375}\n",
      "{'conv1': 0.0011725425720214844, 'bn1': 0.0002262592315673828, 'relu1': 0.0001049041748046875, 'conv2': 0.0011682510375976562, 'bn2': 0.0002193450927734375, 'residual_add_relu2': 0.0002086162567138672}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006763935089111328, 'bn1': 0.00015425682067871094, 'relu1': 7.081031799316406e-05, 'conv2': 0.0011649131774902344, 'bn2': 0.00014352798461914062, 'conv3': 0.0003097057342529297, 'residual_add_relu2': 0.00011539459228515625}\n",
      "{'conv1': 0.0011622905731201172, 'bn1': 0.00014543533325195312, 'relu1': 6.580352783203125e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.00014328956604003906, 'residual_add_relu2': 0.00011587142944335938}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 275\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016727447509765625, 'bn1': 0.0005834102630615234, 'relu1': 0.0003337860107421875, 'conv2': 0.00164794921875, 'bn2': 0.0005660057067871094, 'residual_add_relu2': 0.0007722377777099609}\n",
      "{'conv1': 0.0016498565673828125, 'bn1': 0.0005698204040527344, 'relu1': 0.00032973289489746094, 'conv2': 0.001644134521484375, 'bn2': 0.0005633831024169922, 'residual_add_relu2': 0.0007679462432861328}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010685920715332031, 'bn1': 0.00034117698669433594, 'relu1': 0.00017905235290527344, 'conv2': 0.001322031021118164, 'bn2': 0.00033545494079589844, 'conv3': 0.0004134178161621094, 'residual_add_relu2': 0.0003962516784667969}\n",
      "{'conv1': 0.0013358592987060547, 'bn1': 0.0003631114959716797, 'relu1': 0.0001857280731201172, 'conv2': 0.0013246536254882812, 'bn2': 0.0003407001495361328, 'residual_add_relu2': 0.00039505958557128906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008037090301513672, 'bn1': 0.0002257823944091797, 'relu1': 0.00010609626770019531, 'conv2': 0.0011713504791259766, 'bn2': 0.0002231597900390625, 'conv3': 0.00036644935607910156, 'residual_add_relu2': 0.00020956993103027344}\n",
      "{'conv1': 0.0011723041534423828, 'bn1': 0.00022554397583007812, 'relu1': 0.00010466575622558594, 'conv2': 0.0011668205261230469, 'bn2': 0.00022125244140625, 'residual_add_relu2': 0.0002090930938720703}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006759166717529297, 'bn1': 0.00014781951904296875, 'relu1': 6.723403930664062e-05, 'conv2': 0.0011599063873291016, 'bn2': 0.0001404285430908203, 'conv3': 0.0003046989440917969, 'residual_add_relu2': 0.00011563301086425781}\n",
      "{'conv1': 0.0011665821075439453, 'bn1': 0.0001518726348876953, 'relu1': 6.604194641113281e-05, 'conv2': 0.0011594295501708984, 'bn2': 0.00014090538024902344, 'residual_add_relu2': 0.00011420249938964844}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 276\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016586780548095703, 'bn1': 0.000583648681640625, 'relu1': 0.00032973289489746094, 'conv2': 0.0016431808471679688, 'bn2': 0.000568389892578125, 'residual_add_relu2': 0.0007712841033935547}\n",
      "{'conv1': 0.0016455650329589844, 'bn1': 0.0005731582641601562, 'relu1': 0.0003299713134765625, 'conv2': 0.0016391277313232422, 'bn2': 0.0005655288696289062, 'residual_add_relu2': 0.0007674694061279297}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010671615600585938, 'bn1': 0.0003490447998046875, 'relu1': 0.0001804828643798828, 'conv2': 0.0013244152069091797, 'bn2': 0.00033545494079589844, 'conv3': 0.00041484832763671875, 'residual_add_relu2': 0.00039577484130859375}\n",
      "{'conv1': 0.0013244152069091797, 'bn1': 0.00037217140197753906, 'relu1': 0.00018310546875, 'conv2': 0.001321554183959961, 'bn2': 0.0003368854522705078, 'residual_add_relu2': 0.000396728515625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008015632629394531, 'bn1': 0.00023031234741210938, 'relu1': 0.00010561943054199219, 'conv2': 0.0011703968048095703, 'bn2': 0.00022292137145996094, 'conv3': 0.0003669261932373047, 'residual_add_relu2': 0.00021076202392578125}\n",
      "{'conv1': 0.0011768341064453125, 'bn1': 0.000225067138671875, 'relu1': 0.0001049041748046875, 'conv2': 0.0011675357818603516, 'bn2': 0.00022077560424804688, 'residual_add_relu2': 0.00020885467529296875}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006749629974365234, 'bn1': 0.00014734268188476562, 'relu1': 6.651878356933594e-05, 'conv2': 0.0011603832244873047, 'bn2': 0.0001404285430908203, 'conv3': 0.0003116130828857422, 'residual_add_relu2': 0.00011515617370605469}\n",
      "{'conv1': 0.0011630058288574219, 'bn1': 0.00014901161193847656, 'relu1': 6.604194641113281e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.00014781951904296875, 'residual_add_relu2': 0.0001163482666015625}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 277\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016684532165527344, 'bn1': 0.0005891323089599609, 'relu1': 0.0003330707550048828, 'conv2': 0.0016489028930664062, 'bn2': 0.0005702972412109375, 'residual_add_relu2': 0.00077056884765625}\n",
      "{'conv1': 0.0016608238220214844, 'bn1': 0.0005729198455810547, 'relu1': 0.00033020973205566406, 'conv2': 0.001644134521484375, 'bn2': 0.0005674362182617188, 'residual_add_relu2': 0.0007679462432861328}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010600090026855469, 'bn1': 0.00033783912658691406, 'relu1': 0.00017976760864257812, 'conv2': 0.001329660415649414, 'bn2': 0.00033354759216308594, 'conv3': 0.00041294097900390625, 'residual_add_relu2': 0.0003943443298339844}\n",
      "{'conv1': 0.001321554183959961, 'bn1': 0.0003414154052734375, 'relu1': 0.00018477439880371094, 'conv2': 0.0013241767883300781, 'bn2': 0.0003371238708496094, 'residual_add_relu2': 0.0003941059112548828}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008020401000976562, 'bn1': 0.0002231597900390625, 'relu1': 0.00010418891906738281, 'conv2': 0.0011706352233886719, 'bn2': 0.0002219676971435547, 'conv3': 0.0003662109375, 'residual_add_relu2': 0.00020956993103027344}\n",
      "{'conv1': 0.0011715888977050781, 'bn1': 0.0002231597900390625, 'relu1': 0.00010561943054199219, 'conv2': 0.0011668205261230469, 'bn2': 0.00022673606872558594, 'residual_add_relu2': 0.000209808349609375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006780624389648438, 'bn1': 0.00014734268188476562, 'relu1': 6.628036499023438e-05, 'conv2': 0.00115966796875, 'bn2': 0.0001437664031982422, 'conv3': 0.0003082752227783203, 'residual_add_relu2': 0.00011682510375976562}\n",
      "{'conv1': 0.0011632442474365234, 'bn1': 0.0001480579376220703, 'relu1': 6.651878356933594e-05, 'conv2': 0.0011587142944335938, 'bn2': 0.0001385211944580078, 'residual_add_relu2': 0.00011491775512695312}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 278\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016748905181884766, 'bn1': 0.0005929470062255859, 'relu1': 0.0003337860107421875, 'conv2': 0.0016505718231201172, 'bn2': 0.0005738735198974609, 'residual_add_relu2': 0.0007724761962890625}\n",
      "{'conv1': 0.0016503334045410156, 'bn1': 0.0005729198455810547, 'relu1': 0.0003306865692138672, 'conv2': 0.001644134521484375, 'bn2': 0.0005650520324707031, 'residual_add_relu2': 0.0007731914520263672}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001069784164428711, 'bn1': 0.0003426074981689453, 'relu1': 0.0001838207244873047, 'conv2': 0.0013260841369628906, 'bn2': 0.00033664703369140625, 'conv3': 0.0004181861877441406, 'residual_add_relu2': 0.0003948211669921875}\n",
      "{'conv1': 0.0013260841369628906, 'bn1': 0.0003464221954345703, 'relu1': 0.00018596649169921875, 'conv2': 0.001323699951171875, 'bn2': 0.0003380775451660156, 'residual_add_relu2': 0.0003943443298339844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008044242858886719, 'bn1': 0.0002307891845703125, 'relu1': 0.00010919570922851562, 'conv2': 0.0011746883392333984, 'bn2': 0.0002276897430419922, 'conv3': 0.0003681182861328125, 'residual_add_relu2': 0.0002079010009765625}\n",
      "{'conv1': 0.001172780990600586, 'bn1': 0.0002269744873046875, 'relu1': 0.00010395050048828125, 'conv2': 0.0011682510375976562, 'bn2': 0.00022149085998535156, 'residual_add_relu2': 0.00020837783813476562}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006799697875976562, 'bn1': 0.00015473365783691406, 'relu1': 6.699562072753906e-05, 'conv2': 0.0011622905731201172, 'bn2': 0.00014066696166992188, 'conv3': 0.00030922889709472656, 'residual_add_relu2': 0.00011539459228515625}\n",
      "{'conv1': 0.001178741455078125, 'bn1': 0.00014734268188476562, 'relu1': 6.866455078125e-05, 'conv2': 0.0011601448059082031, 'bn2': 0.0001423358917236328, 'residual_add_relu2': 0.00011491775512695312}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 279\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016632080078125, 'bn1': 0.0005807876586914062, 'relu1': 0.00033092498779296875, 'conv2': 0.0016415119171142578, 'bn2': 0.0005648136138916016, 'residual_add_relu2': 0.0007729530334472656}\n",
      "{'conv1': 0.0016455650329589844, 'bn1': 0.0005714893341064453, 'relu1': 0.0003285408020019531, 'conv2': 0.0016453266143798828, 'bn2': 0.0005638599395751953, 'residual_add_relu2': 0.0007681846618652344}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010597705841064453, 'bn1': 0.0003376007080078125, 'relu1': 0.00018024444580078125, 'conv2': 0.0013217926025390625, 'bn2': 0.0003345012664794922, 'conv3': 0.0004112720489501953, 'residual_add_relu2': 0.00039577484130859375}\n",
      "{'conv1': 0.0013227462768554688, 'bn1': 0.0003390312194824219, 'relu1': 0.0001811981201171875, 'conv2': 0.0013194084167480469, 'bn2': 0.00033283233642578125, 'residual_add_relu2': 0.0003955364227294922}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008058547973632812, 'bn1': 0.00022292137145996094, 'relu1': 0.00012564659118652344, 'conv2': 0.0011756420135498047, 'bn2': 0.00022482872009277344, 'conv3': 0.00036597251892089844, 'residual_add_relu2': 0.000209808349609375}\n",
      "{'conv1': 0.0011723041534423828, 'bn1': 0.00024819374084472656, 'relu1': 0.0001068115234375, 'conv2': 0.0011701583862304688, 'bn2': 0.0002238750457763672, 'residual_add_relu2': 0.00020813941955566406}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006742477416992188, 'bn1': 0.00014519691467285156, 'relu1': 6.699562072753906e-05, 'conv2': 0.001161813735961914, 'bn2': 0.00014662742614746094, 'conv3': 0.0003097057342529297, 'residual_add_relu2': 0.00011658668518066406}\n",
      "{'conv1': 0.0011692047119140625, 'bn1': 0.00015735626220703125, 'relu1': 6.723403930664062e-05, 'conv2': 0.0011608600616455078, 'bn2': 0.00014090538024902344, 'residual_add_relu2': 0.00011444091796875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 280\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001672983169555664, 'bn1': 0.0005941390991210938, 'relu1': 0.0003311634063720703, 'conv2': 0.00164794921875, 'bn2': 0.0005719661712646484, 'residual_add_relu2': 0.000774383544921875}\n",
      "{'conv1': 0.0016446113586425781, 'bn1': 0.0005788803100585938, 'relu1': 0.0003299713134765625, 'conv2': 0.001646280288696289, 'bn2': 0.0005707740783691406, 'residual_add_relu2': 0.0007681846618652344}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001062631607055664, 'bn1': 0.0003533363342285156, 'relu1': 0.00018167495727539062, 'conv2': 0.0013251304626464844, 'bn2': 0.0003345012664794922, 'conv3': 0.00041675567626953125, 'residual_add_relu2': 0.0003941059112548828}\n",
      "{'conv1': 0.0013234615325927734, 'bn1': 0.00033926963806152344, 'relu1': 0.0001804828643798828, 'conv2': 0.0013189315795898438, 'bn2': 0.0003323554992675781, 'residual_add_relu2': 0.0003952980041503906}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008039474487304688, 'bn1': 0.00022530555725097656, 'relu1': 0.00010895729064941406, 'conv2': 0.0011758804321289062, 'bn2': 0.0002262592315673828, 'conv3': 0.0003674030303955078, 'residual_add_relu2': 0.00020933151245117188}\n",
      "{'conv1': 0.0011713504791259766, 'bn1': 0.00022459030151367188, 'relu1': 0.00010466575622558594, 'conv2': 0.0011675357818603516, 'bn2': 0.00022220611572265625, 'residual_add_relu2': 0.0002086162567138672}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006737709045410156, 'bn1': 0.00014829635620117188, 'relu1': 6.628036499023438e-05, 'conv2': 0.0011615753173828125, 'bn2': 0.00014162063598632812, 'conv3': 0.0003101825714111328, 'residual_add_relu2': 0.00011563301086425781}\n",
      "{'conv1': 0.0011658668518066406, 'bn1': 0.0001475811004638672, 'relu1': 6.604194641113281e-05, 'conv2': 0.001157999038696289, 'bn2': 0.0001423358917236328, 'residual_add_relu2': 0.00011491775512695312}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 281\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016713142395019531, 'bn1': 0.0005841255187988281, 'relu1': 0.0003311634063720703, 'conv2': 0.0016429424285888672, 'bn2': 0.0005702972412109375, 'residual_add_relu2': 0.0007710456848144531}\n",
      "{'conv1': 0.0016484260559082031, 'bn1': 0.0005693435668945312, 'relu1': 0.0003299713134765625, 'conv2': 0.0016455650329589844, 'bn2': 0.0005655288696289062, 'residual_add_relu2': 0.0007665157318115234}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010631084442138672, 'bn1': 0.0003478527069091797, 'relu1': 0.00018095970153808594, 'conv2': 0.0013222694396972656, 'bn2': 0.00033283233642578125, 'conv3': 0.00041413307189941406, 'residual_add_relu2': 0.0003933906555175781}\n",
      "{'conv1': 0.001322031021118164, 'bn1': 0.00036334991455078125, 'relu1': 0.0001819133758544922, 'conv2': 0.0013208389282226562, 'bn2': 0.00033545494079589844, 'residual_add_relu2': 0.0003955364227294922}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008037090301513672, 'bn1': 0.0002269744873046875, 'relu1': 0.00010609626770019531, 'conv2': 0.0011723041534423828, 'bn2': 0.00022220611572265625, 'conv3': 0.0003662109375, 'residual_add_relu2': 0.00020933151245117188}\n",
      "{'conv1': 0.0011708736419677734, 'bn1': 0.00022411346435546875, 'relu1': 0.00010418891906738281, 'conv2': 0.0012462139129638672, 'bn2': 0.00023651123046875, 'residual_add_relu2': 0.00021147727966308594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006754398345947266, 'bn1': 0.0001461505889892578, 'relu1': 6.556510925292969e-05, 'conv2': 0.0011622905731201172, 'bn2': 0.00014090538024902344, 'conv3': 0.000316619873046875, 'residual_add_relu2': 0.00011563301086425781}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.0001475811004638672, 'relu1': 6.604194641113281e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.0001399517059326172, 'residual_add_relu2': 0.00011444091796875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 282\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016651153564453125, 'bn1': 0.0005724430084228516, 'relu1': 0.00032711029052734375, 'conv2': 0.0016391277313232422, 'bn2': 0.0005526542663574219, 'residual_add_relu2': 0.0007677078247070312}\n",
      "{'conv1': 0.0016374588012695312, 'bn1': 0.0005469322204589844, 'relu1': 0.0003261566162109375, 'conv2': 0.0016255378723144531, 'bn2': 0.0005450248718261719, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001051187515258789, 'bn1': 0.00032210350036621094, 'relu1': 0.00017595291137695312, 'conv2': 0.0013179779052734375, 'bn2': 0.0003120899200439453, 'conv3': 0.0004019737243652344, 'residual_add_relu2': 0.000392913818359375}\n",
      "{'conv1': 0.0013098716735839844, 'bn1': 0.0003204345703125, 'relu1': 0.00017499923706054688, 'conv2': 0.001308441162109375, 'bn2': 0.0003094673156738281, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000789642333984375, 'bn1': 0.0002014636993408203, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.00019741058349609375, 'conv3': 0.00035381317138671875, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.001161336898803711, 'bn1': 0.0002002716064453125, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011544227600097656, 'bn2': 0.00019931793212890625, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006611347198486328, 'bn1': 0.00012493133544921875, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.00011682510375976562, 'conv3': 0.0003027915954589844, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011489391326904297, 'bn1': 0.0001232624053955078, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.00011658668518066406, 'residual_add_relu2': 0.00011229515075683594}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 283\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016453266143798828, 'bn1': 0.0005609989166259766, 'relu1': 0.00032520294189453125, 'conv2': 0.0016298294067382812, 'bn2': 0.0005478858947753906, 'residual_add_relu2': 0.0007691383361816406}\n",
      "{'conv1': 0.0016415119171142578, 'bn1': 0.0005640983581542969, 'relu1': 0.0003254413604736328, 'conv2': 0.0016360282897949219, 'bn2': 0.0005419254302978516, 'residual_add_relu2': 0.0007674694061279297}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010488033294677734, 'bn1': 0.00031638145446777344, 'relu1': 0.000171661376953125, 'conv2': 0.0013093948364257812, 'bn2': 0.00030231475830078125, 'conv3': 0.000392913818359375, 'residual_add_relu2': 0.00038886070251464844}\n",
      "{'conv1': 0.0013053417205810547, 'bn1': 0.0003173351287841797, 'relu1': 0.00017404556274414062, 'conv2': 0.0013091564178466797, 'bn2': 0.0003185272216796875, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007917881011962891, 'bn1': 0.00020766258239746094, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011591911315917969, 'bn2': 0.00019598007202148438, 'conv3': 0.0003540515899658203, 'residual_add_relu2': 0.00020933151245117188}\n",
      "{'conv1': 0.0011610984802246094, 'bn1': 0.00019407272338867188, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.0001900196075439453, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006563663482666016, 'bn1': 0.00011563301086425781, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011446475982666016, 'bn2': 0.00011134147644042969, 'conv3': 0.0002982616424560547, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011477470397949219, 'bn1': 0.0001537799835205078, 'relu1': 5.91278076171875e-05, 'conv2': 0.001142263412475586, 'bn2': 0.00010943412780761719, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 284\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016481876373291016, 'bn1': 0.0005540847778320312, 'relu1': 0.0003237724304199219, 'conv2': 0.0016293525695800781, 'bn2': 0.0005390644073486328, 'residual_add_relu2': 0.0007693767547607422}\n",
      "{'conv1': 0.0016400814056396484, 'bn1': 0.0005519390106201172, 'relu1': 0.0003247261047363281, 'conv2': 0.0016260147094726562, 'bn2': 0.0005474090576171875, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010485649108886719, 'bn1': 0.0003185272216796875, 'relu1': 0.0001728534698486328, 'conv2': 0.0013110637664794922, 'bn2': 0.0003094673156738281, 'conv3': 0.0003962516784667969, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.0013115406036376953, 'bn1': 0.000316619873046875, 'relu1': 0.00017189979553222656, 'conv2': 0.001306295394897461, 'bn2': 0.0003066062927246094, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007860660552978516, 'bn1': 0.00020384788513183594, 'relu1': 9.703636169433594e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.0001900196075439453, 'conv3': 0.0003485679626464844, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011544227600097656, 'bn1': 0.0001919269561767578, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00019621849060058594, 'residual_add_relu2': 0.00020694732666015625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006642341613769531, 'bn1': 0.00011801719665527344, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00010967254638671875, 'conv3': 0.00029277801513671875, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011496543884277344, 'bn1': 0.0001251697540283203, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011463165283203125, 'bn2': 0.00012350082397460938, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 285\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016596317291259766, 'bn1': 0.0005495548248291016, 'relu1': 0.00032329559326171875, 'conv2': 0.0016372203826904297, 'bn2': 0.0005447864532470703, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016417503356933594, 'bn1': 0.0005483627319335938, 'relu1': 0.00032448768615722656, 'conv2': 0.001628875732421875, 'bn2': 0.0005357265472412109, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010480880737304688, 'bn1': 0.00032401084899902344, 'relu1': 0.0001773834228515625, 'conv2': 0.0013134479522705078, 'bn2': 0.00031757354736328125, 'conv3': 0.0004062652587890625, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013148784637451172, 'bn1': 0.0003228187561035156, 'relu1': 0.0001766681671142578, 'conv2': 0.0013098716735839844, 'bn2': 0.0003116130828857422, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007855892181396484, 'bn1': 0.00019931793212890625, 'relu1': 0.00011730194091796875, 'conv2': 0.0011565685272216797, 'bn2': 0.00019097328186035156, 'conv3': 0.00034928321838378906, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011582374572753906, 'bn1': 0.00020575523376464844, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.00019502639770507812, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006606578826904297, 'bn1': 0.0001304149627685547, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.000125885009765625, 'conv3': 0.0002961158752441406, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011494159698486328, 'bn1': 0.0001246929168701172, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011436939239501953, 'bn2': 0.00010848045349121094, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 286\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016591548919677734, 'bn1': 0.0005536079406738281, 'relu1': 0.0003237724304199219, 'conv2': 0.0016291141510009766, 'bn2': 0.0005490779876708984, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016341209411621094, 'bn1': 0.0005471706390380859, 'relu1': 0.0003235340118408203, 'conv2': 0.001634359359741211, 'bn2': 0.0005331039428710938, 'residual_add_relu2': 0.0007615089416503906}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010459423065185547, 'bn1': 0.00031065940856933594, 'relu1': 0.00017309188842773438, 'conv2': 0.0013093948364257812, 'bn2': 0.0003070831298828125, 'conv3': 0.0003986358642578125, 'residual_add_relu2': 0.000392913818359375}\n",
      "{'conv1': 0.0013194084167480469, 'bn1': 0.0003170967102050781, 'relu1': 0.00017380714416503906, 'conv2': 0.0013065338134765625, 'bn2': 0.0003075599670410156, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007996559143066406, 'bn1': 0.0002028942108154297, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011568069458007812, 'bn2': 0.00018835067749023438, 'conv3': 0.00034999847412109375, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011556148529052734, 'bn1': 0.0002009868621826172, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011529922485351562, 'bn2': 0.0001888275146484375, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006561279296875, 'bn1': 0.00011873245239257812, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011446475982666016, 'bn2': 0.00011849403381347656, 'conv3': 0.0002989768981933594, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.00012040138244628906, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.00013399124145507812, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 287\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016481876373291016, 'bn1': 0.0005557537078857422, 'relu1': 0.00032711029052734375, 'conv2': 0.001641988754272461, 'bn2': 0.0005526542663574219, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.001638650894165039, 'bn1': 0.0005471706390380859, 'relu1': 0.0003230571746826172, 'conv2': 0.0016300678253173828, 'bn2': 0.0005376338958740234, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010554790496826172, 'bn1': 0.0003173351287841797, 'relu1': 0.00017333030700683594, 'conv2': 0.0013108253479003906, 'bn2': 0.0003108978271484375, 'conv3': 0.00040149688720703125, 'residual_add_relu2': 0.00039267539978027344}\n",
      "{'conv1': 0.0013120174407958984, 'bn1': 0.00031566619873046875, 'relu1': 0.00017333030700683594, 'conv2': 0.001306295394897461, 'bn2': 0.00030231475830078125, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007920265197753906, 'bn1': 0.0001952648162841797, 'relu1': 9.703636169433594e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00018835067749023438, 'conv3': 0.0003504753112792969, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011615753173828125, 'bn1': 0.00020194053649902344, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011563301086425781, 'bn2': 0.00019502639770507812, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000659942626953125, 'bn1': 0.0001220703125, 'relu1': 6.079673767089844e-05, 'conv2': 0.001150369644165039, 'bn2': 0.00012874603271484375, 'conv3': 0.0003006458282470703, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.0011539459228515625, 'bn1': 0.00012969970703125, 'relu1': 6.175041198730469e-05, 'conv2': 0.001148223876953125, 'bn2': 0.0001232624053955078, 'residual_add_relu2': 0.00011181831359863281}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 288\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016527175903320312, 'bn1': 0.0005595684051513672, 'relu1': 0.0003237724304199219, 'conv2': 0.0016434192657470703, 'bn2': 0.0005400180816650391, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.0016460418701171875, 'bn1': 0.0005438327789306641, 'relu1': 0.00032329559326171875, 'conv2': 0.001638174057006836, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007691383361816406}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001051187515258789, 'bn1': 0.00030732154846191406, 'relu1': 0.00017118453979492188, 'conv2': 0.0013134479522705078, 'bn2': 0.0003044605255126953, 'conv3': 0.0003960132598876953, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013093948364257812, 'bn1': 0.0003147125244140625, 'relu1': 0.00017380714416503906, 'conv2': 0.0013079643249511719, 'bn2': 0.0003364086151123047, 'residual_add_relu2': 0.00039315223693847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007929801940917969, 'bn1': 0.00019621849060058594, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011563301086425781, 'bn2': 0.00022101402282714844, 'conv3': 0.00035881996154785156, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011594295501708984, 'bn1': 0.00019884109497070312, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.0001926422119140625, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006618499755859375, 'bn1': 0.0001289844512939453, 'relu1': 6.079673767089844e-05, 'conv2': 0.001148223876953125, 'bn2': 0.00011610984802246094, 'conv3': 0.0002951622009277344, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011491775512695312, 'bn1': 0.00012063980102539062, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011568069458007812, 'bn2': 0.0001277923583984375, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 289\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016574859619140625, 'bn1': 0.0005571842193603516, 'relu1': 0.00032258033752441406, 'conv2': 0.0016486644744873047, 'bn2': 0.0005419254302978516, 'residual_add_relu2': 0.0007646083831787109}\n",
      "{'conv1': 0.0016436576843261719, 'bn1': 0.0005381107330322266, 'relu1': 0.0003216266632080078, 'conv2': 0.0016307830810546875, 'bn2': 0.000553131103515625, 'residual_add_relu2': 0.0007653236389160156}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010526180267333984, 'bn1': 0.0003228187561035156, 'relu1': 0.00017380714416503906, 'conv2': 0.0013103485107421875, 'bn2': 0.00030994415283203125, 'conv3': 0.00040078163146972656, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013098716735839844, 'bn1': 0.0003228187561035156, 'relu1': 0.00017523765563964844, 'conv2': 0.001310586929321289, 'bn2': 0.0003113746643066406, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007922649383544922, 'bn1': 0.00020360946655273438, 'relu1': 0.00010013580322265625, 'conv2': 0.0011641979217529297, 'bn2': 0.00020003318786621094, 'conv3': 0.0003559589385986328, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011591911315917969, 'bn1': 0.00020456314086914062, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.00021314620971679688, 'residual_add_relu2': 0.00020575523376464844}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006663799285888672, 'bn1': 0.0001277923583984375, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011501312255859375, 'bn2': 0.00012040138244628906, 'conv3': 0.0002930164337158203, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011539459228515625, 'bn1': 0.000125885009765625, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.000118255615234375, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 290\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016474723815917969, 'bn1': 0.0005583763122558594, 'relu1': 0.0003237724304199219, 'conv2': 0.0016391277313232422, 'bn2': 0.0005507469177246094, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.0016355514526367188, 'bn1': 0.0005421638488769531, 'relu1': 0.00032329559326171875, 'conv2': 0.0016398429870605469, 'bn2': 0.0005326271057128906, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010440349578857422, 'bn1': 0.00030922889709472656, 'relu1': 0.00017189979553222656, 'conv2': 0.0013070106506347656, 'bn2': 0.00030231475830078125, 'conv3': 0.0003955364227294922, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013113021850585938, 'bn1': 0.0003311634063720703, 'relu1': 0.0001742839813232422, 'conv2': 0.0013113021850585938, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000789642333984375, 'bn1': 0.00019979476928710938, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.0001995563507080078, 'conv3': 0.0003516674041748047, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.0011556148529052734, 'bn1': 0.00019288063049316406, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.00019073486328125, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006589889526367188, 'bn1': 0.0001232624053955078, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00010919570922851562, 'conv3': 0.00028824806213378906, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011456012725830078, 'bn1': 0.00011754035949707031, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011420249938964844, 'bn2': 0.00010824203491210938, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 291\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016489028930664062, 'bn1': 0.0005619525909423828, 'relu1': 0.0003223419189453125, 'conv2': 0.0016334056854248047, 'bn2': 0.0005693435668945312, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.001634359359741211, 'bn1': 0.0005595684051513672, 'relu1': 0.00032258033752441406, 'conv2': 0.0016291141510009766, 'bn2': 0.0005352497100830078, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001050710678100586, 'bn1': 0.0003116130828857422, 'relu1': 0.0001709461212158203, 'conv2': 0.0013091564178466797, 'bn2': 0.0003027915954589844, 'conv3': 0.0004000663757324219, 'residual_add_relu2': 0.0003886222839355469}\n",
      "{'conv1': 0.0013184547424316406, 'bn1': 0.00031185150146484375, 'relu1': 0.00017261505126953125, 'conv2': 0.0013055801391601562, 'bn2': 0.00031447410583496094, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007886886596679688, 'bn1': 0.00019621849060058594, 'relu1': 0.00010037422180175781, 'conv2': 0.0011546611785888672, 'bn2': 0.00018930435180664062, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011553764343261719, 'bn1': 0.00020194053649902344, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011544227600097656, 'bn2': 0.00020051002502441406, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006597042083740234, 'bn1': 0.0001270771026611328, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011446475982666016, 'bn2': 0.00018525123596191406, 'conv3': 0.00029754638671875, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011489391326904297, 'bn1': 0.0001220703125, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011439323425292969, 'bn2': 0.00011992454528808594, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 292\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001653909683227539, 'bn1': 0.0005540847778320312, 'relu1': 0.00032329559326171875, 'conv2': 0.0016400814056396484, 'bn2': 0.0005540847778320312, 'residual_add_relu2': 0.0007677078247070312}\n",
      "{'conv1': 0.0016422271728515625, 'bn1': 0.0005474090576171875, 'relu1': 0.0003235340118408203, 'conv2': 0.0016376972198486328, 'bn2': 0.000537872314453125, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010499954223632812, 'bn1': 0.00031757354736328125, 'relu1': 0.00017309188842773438, 'conv2': 0.0013189315795898438, 'bn2': 0.0003082752227783203, 'conv3': 0.0003974437713623047, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013172626495361328, 'bn1': 0.0003178119659423828, 'relu1': 0.0001735687255859375, 'conv2': 0.001306772232055664, 'bn2': 0.00030803680419921875, 'residual_add_relu2': 0.0003886222839355469}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.00078582763671875, 'bn1': 0.00021314620971679688, 'relu1': 9.942054748535156e-05, 'conv2': 0.00115966796875, 'bn2': 0.00019598007202148438, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011599063873291016, 'bn1': 0.00020623207092285156, 'relu1': 0.00016069412231445312, 'conv2': 0.001161813735961914, 'bn2': 0.00020003318786621094, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006597042083740234, 'bn1': 0.00012135505676269531, 'relu1': 6.103515625e-05, 'conv2': 0.001148223876953125, 'bn2': 0.00011539459228515625, 'conv3': 0.0002913475036621094, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.001149892807006836, 'bn1': 0.00012874603271484375, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.00011491775512695312, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 293\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016558170318603516, 'bn1': 0.0005717277526855469, 'relu1': 0.00032520294189453125, 'conv2': 0.001638174057006836, 'bn2': 0.0005440711975097656, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.001630544662475586, 'bn1': 0.0005567073822021484, 'relu1': 0.000324249267578125, 'conv2': 0.0016345977783203125, 'bn2': 0.0005404949188232422, 'residual_add_relu2': 0.0007677078247070312}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010521411895751953, 'bn1': 0.00031566619873046875, 'relu1': 0.0001728534698486328, 'conv2': 0.0013132095336914062, 'bn2': 0.00031065940856933594, 'conv3': 0.00041985511779785156, 'residual_add_relu2': 0.00039267539978027344}\n",
      "{'conv1': 0.0013136863708496094, 'bn1': 0.0003180503845214844, 'relu1': 0.00017404556274414062, 'conv2': 0.001306772232055664, 'bn2': 0.00036215782165527344, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007874965667724609, 'bn1': 0.0001964569091796875, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.00019598007202148438, 'conv3': 0.0003566741943359375, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011603832244873047, 'bn1': 0.00020313262939453125, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.00019884109497070312, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000659942626953125, 'bn1': 0.0001239776611328125, 'relu1': 5.936622619628906e-05, 'conv2': 0.001150369644165039, 'bn2': 0.0001220703125, 'conv3': 0.00029730796813964844, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011506080627441406, 'bn1': 0.0001201629638671875, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011439323425292969, 'bn2': 0.00012922286987304688, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 294\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016562938690185547, 'bn1': 0.0005502700805664062, 'relu1': 0.00032401084899902344, 'conv2': 0.0016400814056396484, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007677078247070312}\n",
      "{'conv1': 0.001634836196899414, 'bn1': 0.0005471706390380859, 'relu1': 0.0003216266632080078, 'conv2': 0.0016281604766845703, 'bn2': 0.0005393028259277344, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010561943054199219, 'bn1': 0.0003218650817871094, 'relu1': 0.00017380714416503906, 'conv2': 0.0013110637664794922, 'bn2': 0.00030994415283203125, 'conv3': 0.0004012584686279297, 'residual_add_relu2': 0.0003943443298339844}\n",
      "{'conv1': 0.0013146400451660156, 'bn1': 0.000316619873046875, 'relu1': 0.0001742839813232422, 'conv2': 0.0013074874877929688, 'bn2': 0.00030875205993652344, 'residual_add_relu2': 0.00039386749267578125}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007948875427246094, 'bn1': 0.0002014636993408203, 'relu1': 0.0001125335693359375, 'conv2': 0.0011606216430664062, 'bn2': 0.000202178955078125, 'conv3': 0.000354766845703125, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011608600616455078, 'bn1': 0.00020766258239746094, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00018978118896484375, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006577968597412109, 'bn1': 0.00011563301086425781, 'relu1': 5.7220458984375e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00011181831359863281, 'conv3': 0.0002923011779785156, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011489391326904297, 'bn1': 0.00011515617370605469, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011413097381591797, 'bn2': 0.00010728836059570312, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 295\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016636848449707031, 'bn1': 0.0005536079406738281, 'relu1': 0.000324249267578125, 'conv2': 0.0016312599182128906, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016376972198486328, 'bn1': 0.0005424022674560547, 'relu1': 0.00032520294189453125, 'conv2': 0.0016260147094726562, 'bn2': 0.0005342960357666016, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010457038879394531, 'bn1': 0.0003097057342529297, 'relu1': 0.00017023086547851562, 'conv2': 0.0013055801391601562, 'bn2': 0.00030422210693359375, 'conv3': 0.0004000663757324219, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.001310110092163086, 'bn1': 0.0003094673156738281, 'relu1': 0.0001709461212158203, 'conv2': 0.0013031959533691406, 'bn2': 0.00031185150146484375, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007855892181396484, 'bn1': 0.00019025802612304688, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.0001862049102783203, 'conv3': 0.0003483295440673828, 'residual_add_relu2': 0.00020241737365722656}\n",
      "{'conv1': 0.0011539459228515625, 'bn1': 0.00019598007202148438, 'relu1': 9.560585021972656e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.0001862049102783203, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006594657897949219, 'bn1': 0.00011968612670898438, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011463165283203125, 'bn2': 0.00012183189392089844, 'conv3': 0.00029087066650390625, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011446475982666016, 'bn1': 0.00011420249938964844, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011415481567382812, 'bn2': 0.00011587142944335938, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 296\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001642465591430664, 'bn1': 0.0005526542663574219, 'relu1': 0.0003237724304199219, 'conv2': 0.0016283988952636719, 'bn2': 0.0005397796630859375, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.001641988754272461, 'bn1': 0.0005564689636230469, 'relu1': 0.00032639503479003906, 'conv2': 0.0016372203826904297, 'bn2': 0.0005366802215576172, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010526180267333984, 'bn1': 0.0003151893615722656, 'relu1': 0.00017333030700683594, 'conv2': 0.001310110092163086, 'bn2': 0.0003113746643066406, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.000392913818359375}\n",
      "{'conv1': 0.0013113021850585938, 'bn1': 0.0003139972686767578, 'relu1': 0.0001728534698486328, 'conv2': 0.0013060569763183594, 'bn2': 0.0003066062927246094, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007925033569335938, 'bn1': 0.0001990795135498047, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.00019407272338867188, 'conv3': 0.00035071372985839844, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.00115966796875, 'bn1': 0.00021028518676757812, 'relu1': 0.00010037422180175781, 'conv2': 0.0011556148529052734, 'bn2': 0.00019621849060058594, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006594657897949219, 'bn1': 0.00012063980102539062, 'relu1': 6.008148193359375e-05, 'conv2': 0.0013079643249511719, 'bn2': 0.0001766681671142578, 'conv3': 0.0003046989440917969, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011546611785888672, 'bn1': 0.00012254714965820312, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.00011610984802246094, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 297\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016646385192871094, 'bn1': 0.0005571842193603516, 'relu1': 0.0003249645233154297, 'conv2': 0.001636505126953125, 'bn2': 0.0005435943603515625, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016379356384277344, 'bn1': 0.0005402565002441406, 'relu1': 0.00032258033752441406, 'conv2': 0.0016391277313232422, 'bn2': 0.0005364418029785156, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010521411895751953, 'bn1': 0.0003151893615722656, 'relu1': 0.00017309188842773438, 'conv2': 0.001316070556640625, 'bn2': 0.00031495094299316406, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.001310586929321289, 'bn1': 0.0003142356872558594, 'relu1': 0.00017333030700683594, 'conv2': 0.0013082027435302734, 'bn2': 0.00031185150146484375, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007889270782470703, 'bn1': 0.00020051002502441406, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00019550323486328125, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011625289916992188, 'bn1': 0.00020122528076171875, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011539459228515625, 'bn2': 0.00018644332885742188, 'residual_add_relu2': 0.00020313262939453125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006608963012695312, 'bn1': 0.0001728534698486328, 'relu1': 6.461143493652344e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00011420249938964844, 'conv3': 0.0002925395965576172, 'residual_add_relu2': 0.00010967254638671875}\n",
      "{'conv1': 0.0011448860168457031, 'bn1': 0.00012159347534179688, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.00011229515075683594, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 298\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016524791717529297, 'bn1': 0.0005502700805664062, 'relu1': 0.00032639503479003906, 'conv2': 0.0016360282897949219, 'bn2': 0.0005483627319335938, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016455650329589844, 'bn1': 0.0005733966827392578, 'relu1': 0.00032520294189453125, 'conv2': 0.001641988754272461, 'bn2': 0.0005397796630859375, 'residual_add_relu2': 0.0007710456848144531}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010526180267333984, 'bn1': 0.0003173351287841797, 'relu1': 0.00017189979553222656, 'conv2': 0.0013060569763183594, 'bn2': 0.0003209114074707031, 'conv3': 0.00039958953857421875, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013051033020019531, 'bn1': 0.0003094673156738281, 'relu1': 0.00017213821411132812, 'conv2': 0.0013036727905273438, 'bn2': 0.0003154277801513672, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007917881011962891, 'bn1': 0.0001990795135498047, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.00019407272338867188, 'conv3': 0.0003540515899658203, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011746883392333984, 'bn1': 0.0002040863037109375, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011539459228515625, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006604194641113281, 'bn1': 0.00012302398681640625, 'relu1': 0.00012683868408203125, 'conv2': 0.001165628433227539, 'bn2': 0.00012183189392089844, 'conv3': 0.0002963542938232422, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.00011992454528808594, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00011873245239257812, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 299\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016522407531738281, 'bn1': 0.0005626678466796875, 'relu1': 0.00032782554626464844, 'conv2': 0.0016465187072753906, 'bn2': 0.0005450248718261719, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.001634359359741211, 'bn1': 0.0005586147308349609, 'relu1': 0.00032401084899902344, 'conv2': 0.0016319751739501953, 'bn2': 0.0005502700805664062, 'residual_add_relu2': 0.0007653236389160156}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010497570037841797, 'bn1': 0.00031304359436035156, 'relu1': 0.0001723766326904297, 'conv2': 0.001312255859375, 'bn2': 0.0003304481506347656, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.001308441162109375, 'bn1': 0.0003104209899902344, 'relu1': 0.00017118453979492188, 'conv2': 0.0013041496276855469, 'bn2': 0.0003037452697753906, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000789642333984375, 'bn1': 0.00019884109497070312, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011568069458007812, 'bn2': 0.0001952648162841797, 'conv3': 0.00035381317138671875, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.001165628433227539, 'bn1': 0.00020170211791992188, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011544227600097656, 'bn2': 0.000194549560546875, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006594657897949219, 'bn1': 0.0001361370086669922, 'relu1': 6.031990051269531e-05, 'conv2': 0.001149892807006836, 'bn2': 0.00011658668518066406, 'conv3': 0.0002944469451904297, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011487007141113281, 'bn1': 0.00011467933654785156, 'relu1': 5.7220458984375e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.000118255615234375, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 300\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001669168472290039, 'bn1': 0.000579833984375, 'relu1': 0.0003268718719482422, 'conv2': 0.0016396045684814453, 'bn2': 0.0005464553833007812, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.001649618148803711, 'bn1': 0.0005450248718261719, 'relu1': 0.00032210350036621094, 'conv2': 0.001631021499633789, 'bn2': 0.0005574226379394531, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010521411895751953, 'bn1': 0.00031685829162597656, 'relu1': 0.00017333030700683594, 'conv2': 0.0013110637664794922, 'bn2': 0.0003287792205810547, 'conv3': 0.00040602684020996094, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013113021850585938, 'bn1': 0.00032067298889160156, 'relu1': 0.00017523765563964844, 'conv2': 0.001312255859375, 'bn2': 0.0003249645233154297, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007913112640380859, 'bn1': 0.0002040863037109375, 'relu1': 9.965896606445312e-05, 'conv2': 0.001157522201538086, 'bn2': 0.0001895427703857422, 'conv3': 0.0003650188446044922, 'residual_add_relu2': 0.0002067089080810547}\n",
      "{'conv1': 0.0011594295501708984, 'bn1': 0.0001957416534423828, 'relu1': 9.72747802734375e-05, 'conv2': 0.001150369644165039, 'bn2': 0.0001862049102783203, 'residual_add_relu2': 0.0002033710479736328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006573200225830078, 'bn1': 0.00012969970703125, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.000110626220703125, 'conv3': 0.0002906322479248047, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011484622955322266, 'bn1': 0.00011730194091796875, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.00012087821960449219, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 301\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016443729400634766, 'bn1': 0.0005486011505126953, 'relu1': 0.00032448768615722656, 'conv2': 0.0016260147094726562, 'bn2': 0.0005359649658203125, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.001630544662475586, 'bn1': 0.00054931640625, 'relu1': 0.0003230571746826172, 'conv2': 0.0016293525695800781, 'bn2': 0.0005438327789306641, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010485649108886719, 'bn1': 0.00031566619873046875, 'relu1': 0.0001735687255859375, 'conv2': 0.0013077259063720703, 'bn2': 0.00031948089599609375, 'conv3': 0.00040268898010253906, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013115406036376953, 'bn1': 0.0003135204315185547, 'relu1': 0.00017333030700683594, 'conv2': 0.0013070106506347656, 'bn2': 0.00033020973205566406, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007891654968261719, 'bn1': 0.0002009868621826172, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011577606201171875, 'bn2': 0.00020003318786621094, 'conv3': 0.0003559589385986328, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.0011594295501708984, 'bn1': 0.00019931793212890625, 'relu1': 9.584426879882812e-05, 'conv2': 0.001149892807006836, 'bn2': 0.00018787384033203125, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006601810455322266, 'bn1': 0.00011610984802246094, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.00011754035949707031, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011434555053710938, 'bn1': 0.00011396408081054688, 'relu1': 5.698204040527344e-05, 'conv2': 0.0011496543884277344, 'bn2': 0.00012040138244628906, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 302\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001661062240600586, 'bn1': 0.0005695819854736328, 'relu1': 0.0003273487091064453, 'conv2': 0.001636505126953125, 'bn2': 0.0005578994750976562, 'residual_add_relu2': 0.0007710456848144531}\n",
      "{'conv1': 0.0016345977783203125, 'bn1': 0.0007586479187011719, 'relu1': 0.0004055500030517578, 'conv2': 0.0016870498657226562, 'bn2': 0.0005843639373779297, 'residual_add_relu2': 0.0007677078247070312}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010616779327392578, 'bn1': 0.00034928321838378906, 'relu1': 0.0001819133758544922, 'conv2': 0.0013303756713867188, 'bn2': 0.0003292560577392578, 'conv3': 0.00042700767517089844, 'residual_add_relu2': 0.00039315223693847656}\n",
      "{'conv1': 0.0013298988342285156, 'bn1': 0.00033020973205566406, 'relu1': 0.00018262863159179688, 'conv2': 0.0013201236724853516, 'bn2': 0.0003235340118408203, 'residual_add_relu2': 0.000396728515625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008113384246826172, 'bn1': 0.00022363662719726562, 'relu1': 0.00010752677917480469, 'conv2': 0.001171112060546875, 'bn2': 0.0002167224884033203, 'conv3': 0.00036716461181640625, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.0011725425720214844, 'bn1': 0.00021696090698242188, 'relu1': 0.00010657310485839844, 'conv2': 0.0011622905731201172, 'bn2': 0.00024628639221191406, 'residual_add_relu2': 0.00020766258239746094}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006673336029052734, 'bn1': 0.00013375282287597656, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.0001399517059326172, 'conv3': 0.0003039836883544922, 'residual_add_relu2': 0.00011301040649414062}\n",
      "{'conv1': 0.0011529922485351562, 'bn1': 0.00013184547424316406, 'relu1': 6.246566772460938e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.0001270771026611328, 'residual_add_relu2': 0.00011181831359863281}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 303\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016570091247558594, 'bn1': 0.0005650520324707031, 'relu1': 0.0003254413604736328, 'conv2': 0.0016388893127441406, 'bn2': 0.0005438327789306641, 'residual_add_relu2': 0.0007710456848144531}\n",
      "{'conv1': 0.0016312599182128906, 'bn1': 0.0005450248718261719, 'relu1': 0.0003228187561035156, 'conv2': 0.0016338825225830078, 'bn2': 0.0005435943603515625, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010495185852050781, 'bn1': 0.0003147125244140625, 'relu1': 0.0001735687255859375, 'conv2': 0.0013108253479003906, 'bn2': 0.0003154277801513672, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013089179992675781, 'bn1': 0.0003132820129394531, 'relu1': 0.0001735687255859375, 'conv2': 0.0013074874877929688, 'bn2': 0.00031447410583496094, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007886886596679688, 'bn1': 0.00019502639770507812, 'relu1': 9.655952453613281e-05, 'conv2': 0.001153707504272461, 'bn2': 0.00019359588623046875, 'conv3': 0.0003516674041748047, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011653900146484375, 'bn1': 0.0002014636993408203, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011551380157470703, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006630420684814453, 'bn1': 0.00012373924255371094, 'relu1': 6.031990051269531e-05, 'conv2': 0.001148223876953125, 'bn2': 0.00011515617370605469, 'conv3': 0.00029659271240234375, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011496543884277344, 'bn1': 0.00011992454528808594, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011458396911621094, 'bn2': 0.00013709068298339844, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 304\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001651763916015625, 'bn1': 0.0005688667297363281, 'relu1': 0.0003249645233154297, 'conv2': 0.0016353130340576172, 'bn2': 0.0005502700805664062, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.0016355514526367188, 'bn1': 0.0005464553833007812, 'relu1': 0.0003223419189453125, 'conv2': 0.001626729965209961, 'bn2': 0.0005407333374023438, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010499954223632812, 'bn1': 0.0003190040588378906, 'relu1': 0.00017333030700683594, 'conv2': 0.0013093948364257812, 'bn2': 0.00031375885009765625, 'conv3': 0.00039958953857421875, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013098716735839844, 'bn1': 0.0003120899200439453, 'relu1': 0.00017333030700683594, 'conv2': 0.0013074874877929688, 'bn2': 0.0003123283386230469, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007882118225097656, 'bn1': 0.00019931793212890625, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00019812583923339844, 'conv3': 0.00035119056701660156, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011584758758544922, 'bn1': 0.00019311904907226562, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.0001983642578125, 'residual_add_relu2': 0.0003867149353027344}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006995201110839844, 'bn1': 0.00013899803161621094, 'relu1': 6.532669067382812e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.00012302398681640625, 'conv3': 0.00030231475830078125, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011513233184814453, 'bn1': 0.00015425682067871094, 'relu1': 6.556510925292969e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00012087821960449219, 'residual_add_relu2': 0.00011324882507324219}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 305\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001646280288696289, 'bn1': 0.0005693435668945312, 'relu1': 0.0003273487091064453, 'conv2': 0.0016400814056396484, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007715225219726562}\n",
      "{'conv1': 0.001638174057006836, 'bn1': 0.0005495548248291016, 'relu1': 0.0003218650817871094, 'conv2': 0.0016314983367919922, 'bn2': 0.0005517005920410156, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010514259338378906, 'bn1': 0.0003192424774169922, 'relu1': 0.00017452239990234375, 'conv2': 0.0013148784637451172, 'bn2': 0.0003116130828857422, 'conv3': 0.0004024505615234375, 'residual_add_relu2': 0.00039196014404296875}\n",
      "{'conv1': 0.0013108253479003906, 'bn1': 0.0003185272216796875, 'relu1': 0.00017309188842773438, 'conv2': 0.0013086795806884766, 'bn2': 0.000308990478515625, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007886886596679688, 'bn1': 0.0002002716064453125, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011589527130126953, 'bn2': 0.0002048015594482422, 'conv3': 0.0003578662872314453, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.001157999038696289, 'bn1': 0.00020051002502441406, 'relu1': 9.775161743164062e-05, 'conv2': 0.001155853271484375, 'bn2': 0.0002033710479736328, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006630420684814453, 'bn1': 0.0001220703125, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011496543884277344, 'bn2': 0.00011491775512695312, 'conv3': 0.00029587745666503906, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011491775512695312, 'bn1': 0.00012564659118652344, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011448860168457031, 'bn2': 0.00011491775512695312, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 306\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016546249389648438, 'bn1': 0.0005598068237304688, 'relu1': 0.0003247261047363281, 'conv2': 0.0016405582427978516, 'bn2': 0.0005433559417724609, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016314983367919922, 'bn1': 0.0005445480346679688, 'relu1': 0.0003230571746826172, 'conv2': 0.001631021499633789, 'bn2': 0.0005645751953125, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010499954223632812, 'bn1': 0.0003154277801513672, 'relu1': 0.00017309188842773438, 'conv2': 0.0013108253479003906, 'bn2': 0.0003058910369873047, 'conv3': 0.0003948211669921875, 'residual_add_relu2': 0.00038933753967285156}\n",
      "{'conv1': 0.0013086795806884766, 'bn1': 0.0003066062927246094, 'relu1': 0.000171661376953125, 'conv2': 0.001314401626586914, 'bn2': 0.0003058910369873047, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007889270782470703, 'bn1': 0.0001926422119140625, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011534690856933594, 'bn2': 0.0002071857452392578, 'conv3': 0.00035500526428222656, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011594295501708984, 'bn1': 0.0002002716064453125, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011544227600097656, 'bn2': 0.00019550323486328125, 'residual_add_relu2': 0.00020623207092285156}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006616115570068359, 'bn1': 0.0001246929168701172, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00011587142944335938, 'conv3': 0.00029087066650390625, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011494159698486328, 'bn1': 0.00013709068298339844, 'relu1': 6.270408630371094e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00011277198791503906, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 307\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016622543334960938, 'bn1': 0.00055694580078125, 'relu1': 0.0003266334533691406, 'conv2': 0.0016400814056396484, 'bn2': 0.0005469322204589844, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.0016410350799560547, 'bn1': 0.0005433559417724609, 'relu1': 0.0003261566162109375, 'conv2': 0.0016307830810546875, 'bn2': 0.0005404949188232422, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010499954223632812, 'bn1': 0.0003178119659423828, 'relu1': 0.00017309188842773438, 'conv2': 0.0013153553009033203, 'bn2': 0.000308990478515625, 'conv3': 0.0004012584686279297, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013136863708496094, 'bn1': 0.00032019615173339844, 'relu1': 0.00017333030700683594, 'conv2': 0.001308441162109375, 'bn2': 0.00030994415283203125, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007882118225097656, 'bn1': 0.00022935867309570312, 'relu1': 9.918212890625e-05, 'conv2': 0.0011591911315917969, 'bn2': 0.00019621849060058594, 'conv3': 0.00035381317138671875, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011591911315917969, 'bn1': 0.0001995563507080078, 'relu1': 9.72747802734375e-05, 'conv2': 0.001154184341430664, 'bn2': 0.00020551681518554688, 'residual_add_relu2': 0.00020575523376464844}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006620883941650391, 'bn1': 0.00012564659118652344, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.00011587142944335938, 'conv3': 0.0002963542938232422, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.0001270771026611328, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011467933654785156, 'bn2': 0.00011658668518066406, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 308\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016562938690185547, 'bn1': 0.0005545616149902344, 'relu1': 0.0003237724304199219, 'conv2': 0.0016312599182128906, 'bn2': 0.0005643367767333984, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.001638174057006836, 'bn1': 0.0005481243133544922, 'relu1': 0.00032258033752441406, 'conv2': 0.0016300678253173828, 'bn2': 0.0005369186401367188, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010614395141601562, 'bn1': 0.0003161430358886719, 'relu1': 0.00017261505126953125, 'conv2': 0.0013093948364257812, 'bn2': 0.0003085136413574219, 'conv3': 0.0003991127014160156, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.0013246536254882812, 'bn1': 0.0003266334533691406, 'relu1': 0.00017404556274414062, 'conv2': 0.001308441162109375, 'bn2': 0.00031065940856933594, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007944107055664062, 'bn1': 0.0002307891845703125, 'relu1': 0.00010156631469726562, 'conv2': 0.0011625289916992188, 'bn2': 0.0002040863037109375, 'conv3': 0.0003554821014404297, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011646747589111328, 'bn1': 0.0002205371856689453, 'relu1': 0.00010013580322265625, 'conv2': 0.00115966796875, 'bn2': 0.0002048015594482422, 'residual_add_relu2': 0.00020623207092285156}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006644725799560547, 'bn1': 0.00012230873107910156, 'relu1': 6.0558319091796875e-05, 'conv2': 0.001149892807006836, 'bn2': 0.00013017654418945312, 'conv3': 0.0003027915954589844, 'residual_add_relu2': 0.00011324882507324219}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00013399124145507812, 'relu1': 6.246566772460938e-05, 'conv2': 0.0011496543884277344, 'bn2': 0.00012612342834472656, 'residual_add_relu2': 0.00011372566223144531}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 309\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016591548919677734, 'bn1': 0.0005700588226318359, 'relu1': 0.00032711029052734375, 'conv2': 0.001634359359741211, 'bn2': 0.0005514621734619141, 'residual_add_relu2': 0.0007693767547607422}\n",
      "{'conv1': 0.0016379356384277344, 'bn1': 0.0005459785461425781, 'relu1': 0.00032329559326171875, 'conv2': 0.0016355514526367188, 'bn2': 0.0005500316619873047, 'residual_add_relu2': 0.0007658004760742188}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010466575622558594, 'bn1': 0.00031495094299316406, 'relu1': 0.00017261505126953125, 'conv2': 0.0013108253479003906, 'bn2': 0.00031065940856933594, 'conv3': 0.000400543212890625, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013127326965332031, 'bn1': 0.0003113746643066406, 'relu1': 0.00017404556274414062, 'conv2': 0.0013077259063720703, 'bn2': 0.0003132820129394531, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007894039154052734, 'bn1': 0.0001983642578125, 'relu1': 9.703636169433594e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.000194549560546875, 'conv3': 0.0003535747528076172, 'residual_add_relu2': 0.00021386146545410156}\n",
      "{'conv1': 0.0011646747589111328, 'bn1': 0.00020051002502441406, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011551380157470703, 'bn2': 0.00019478797912597656, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006639957427978516, 'bn1': 0.00015616416931152344, 'relu1': 6.818771362304688e-05, 'conv2': 0.0011534690856933594, 'bn2': 0.00011897087097167969, 'conv3': 0.0002930164337158203, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011451244354248047, 'bn1': 0.00012040138244628906, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011451244354248047, 'bn2': 0.00012063980102539062, 'residual_add_relu2': 0.00011181831359863281}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 310\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016536712646484375, 'bn1': 0.0005674362182617188, 'relu1': 0.0003285408020019531, 'conv2': 0.0016410350799560547, 'bn2': 0.0005505084991455078, 'residual_add_relu2': 0.0007693767547607422}\n",
      "{'conv1': 0.0016369819641113281, 'bn1': 0.0005524158477783203, 'relu1': 0.00032520294189453125, 'conv2': 0.0016360282897949219, 'bn2': 0.0005497932434082031, 'residual_add_relu2': 0.0007653236389160156}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010561943054199219, 'bn1': 0.00032448768615722656, 'relu1': 0.00017523765563964844, 'conv2': 0.001314401626586914, 'bn2': 0.00032258033752441406, 'conv3': 0.0004067420959472656, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.001314401626586914, 'bn1': 0.00032138824462890625, 'relu1': 0.00017595291137695312, 'conv2': 0.0013124942779541016, 'bn2': 0.00032258033752441406, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.00079345703125, 'bn1': 0.00022101402282714844, 'relu1': 0.00010013580322265625, 'conv2': 0.0011591911315917969, 'bn2': 0.00021648406982421875, 'conv3': 0.0003635883331298828, 'residual_add_relu2': 0.00020647048950195312}\n",
      "{'conv1': 0.0011661052703857422, 'bn1': 0.00021004676818847656, 'relu1': 0.00010085105895996094, 'conv2': 0.001157999038696289, 'bn2': 0.00020241737365722656, 'residual_add_relu2': 0.0002079010009765625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006766319274902344, 'bn1': 0.00014066696166992188, 'relu1': 6.389617919921875e-05, 'conv2': 0.0011529922485351562, 'bn2': 0.00011658668518066406, 'conv3': 0.000293731689453125, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011491775512695312, 'bn1': 0.0001277923583984375, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00011754035949707031, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 311\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016562938690185547, 'bn1': 0.0005526542663574219, 'relu1': 0.0003209114074707031, 'conv2': 0.0016326904296875, 'bn2': 0.0005383491516113281, 'residual_add_relu2': 0.0007643699645996094}\n",
      "{'conv1': 0.0016443729400634766, 'bn1': 0.0005466938018798828, 'relu1': 0.0003218650817871094, 'conv2': 0.0016946792602539062, 'bn2': 0.0005433559417724609, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010476112365722656, 'bn1': 0.00031876564025878906, 'relu1': 0.0001735687255859375, 'conv2': 0.0013103485107421875, 'bn2': 0.00030732154846191406, 'conv3': 0.0003991127014160156, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013134479522705078, 'bn1': 0.0003185272216796875, 'relu1': 0.0001728534698486328, 'conv2': 0.0013065338134765625, 'bn2': 0.0003077983856201172, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007929801940917969, 'bn1': 0.0001995563507080078, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011589527130126953, 'bn2': 0.00019693374633789062, 'conv3': 0.0003523826599121094, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011577606201171875, 'bn1': 0.00019860267639160156, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011551380157470703, 'bn2': 0.0002086162567138672, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006906986236572266, 'bn1': 0.0001251697540283203, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00011563301086425781, 'conv3': 0.0002932548522949219, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011513233184814453, 'bn1': 0.00012612342834472656, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011446475982666016, 'bn2': 0.00011539459228515625, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 312\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016527175903320312, 'bn1': 0.0005548000335693359, 'relu1': 0.0003235340118408203, 'conv2': 0.001634836196899414, 'bn2': 0.0005476474761962891, 'residual_add_relu2': 0.0007638931274414062}\n",
      "{'conv1': 0.0016338825225830078, 'bn1': 0.0005350112915039062, 'relu1': 0.0003223419189453125, 'conv2': 0.0016362667083740234, 'bn2': 0.00054931640625, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010502338409423828, 'bn1': 0.0003199577331542969, 'relu1': 0.00017309188842773438, 'conv2': 0.0013098716735839844, 'bn2': 0.0003097057342529297, 'conv3': 0.0004017353057861328, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013117790222167969, 'bn1': 0.00033354759216308594, 'relu1': 0.00017690658569335938, 'conv2': 0.0013148784637451172, 'bn2': 0.0003216266632080078, 'residual_add_relu2': 0.00039196014404296875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007953643798828125, 'bn1': 0.0002124309539794922, 'relu1': 0.000102996826171875, 'conv2': 0.0011625289916992188, 'bn2': 0.00019502639770507812, 'conv3': 0.00035190582275390625, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011589527130126953, 'bn1': 0.0002002716064453125, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00021147727966308594, 'residual_add_relu2': 0.00020599365234375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006618499755859375, 'bn1': 0.0001220703125, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.00011444091796875, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011491775512695312, 'bn1': 0.0001246929168701172, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00011515617370605469, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 313\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001672506332397461, 'bn1': 0.0005619525909423828, 'relu1': 0.00032639503479003906, 'conv2': 0.001638650894165039, 'bn2': 0.0005578994750976562, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016412734985351562, 'bn1': 0.0005521774291992188, 'relu1': 0.0003237724304199219, 'conv2': 0.0016360282897949219, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010523796081542969, 'bn1': 0.0003197193145751953, 'relu1': 0.00017333030700683594, 'conv2': 0.0013089179992675781, 'bn2': 0.000308990478515625, 'conv3': 0.00040459632873535156, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013148784637451172, 'bn1': 0.0003173351287841797, 'relu1': 0.00017452239990234375, 'conv2': 0.0013089179992675781, 'bn2': 0.00031065940856933594, 'residual_add_relu2': 0.00039196014404296875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007865428924560547, 'bn1': 0.00019860267639160156, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00019550323486328125, 'conv3': 0.00035643577575683594, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011591911315917969, 'bn1': 0.00019741058349609375, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.000194549560546875, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006620883941650391, 'bn1': 0.0001277923583984375, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011501312255859375, 'bn2': 0.0001270771026611328, 'conv3': 0.00029921531677246094, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.0011513233184814453, 'bn1': 0.0001201629638671875, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011456012725830078, 'bn2': 0.000118255615234375, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 314\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016541481018066406, 'bn1': 0.0005657672882080078, 'relu1': 0.000324249267578125, 'conv2': 0.0016367435455322266, 'bn2': 0.0005400180816650391, 'residual_add_relu2': 0.0007648468017578125}\n",
      "{'conv1': 0.0016546249389648438, 'bn1': 0.0005478858947753906, 'relu1': 0.00032401084899902344, 'conv2': 0.0016367435455322266, 'bn2': 0.0005433559417724609, 'residual_add_relu2': 0.0007653236389160156}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010514259338378906, 'bn1': 0.0003147125244140625, 'relu1': 0.00017309188842773438, 'conv2': 0.001317739486694336, 'bn2': 0.0003120899200439453, 'conv3': 0.0003986358642578125, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013136863708496094, 'bn1': 0.0003139972686767578, 'relu1': 0.00017309188842773438, 'conv2': 0.0013093948364257812, 'bn2': 0.00032258033752441406, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007941722869873047, 'bn1': 0.00020265579223632812, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011563301086425781, 'bn2': 0.0001888275146484375, 'conv3': 0.0003647804260253906, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011601448059082031, 'bn1': 0.000202178955078125, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011544227600097656, 'bn2': 0.00019407272338867188, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006604194641113281, 'bn1': 0.0001251697540283203, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00011539459228515625, 'conv3': 0.0002930164337158203, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011508464813232422, 'bn1': 0.00012040138244628906, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011436939239501953, 'bn2': 0.00011968612670898438, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 315\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016512870788574219, 'bn1': 0.0005588531494140625, 'relu1': 0.00032520294189453125, 'conv2': 0.0016353130340576172, 'bn2': 0.0005419254302978516, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.001644134521484375, 'bn1': 0.000545501708984375, 'relu1': 0.0003218650817871094, 'conv2': 0.0016314983367919922, 'bn2': 0.0005426406860351562, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010488033294677734, 'bn1': 0.0003180503845214844, 'relu1': 0.00017213821411132812, 'conv2': 0.0013113021850585938, 'bn2': 0.00031280517578125, 'conv3': 0.0003991127014160156, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.001310110092163086, 'bn1': 0.00031447410583496094, 'relu1': 0.00017380714416503906, 'conv2': 0.001310110092163086, 'bn2': 0.00032019615173339844, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007908344268798828, 'bn1': 0.0002002716064453125, 'relu1': 9.942054748535156e-05, 'conv2': 0.001157522201538086, 'bn2': 0.0001990795135498047, 'conv3': 0.0003533363342285156, 'residual_add_relu2': 0.0002200603485107422}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.00020122528076171875, 'relu1': 9.775161743164062e-05, 'conv2': 0.001154184341430664, 'bn2': 0.0001952648162841797, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006620883941650391, 'bn1': 0.0001232624053955078, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00011515617370605469, 'conv3': 0.0002903938293457031, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011479854583740234, 'bn1': 0.00011992454528808594, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.0001266002655029297, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 316\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001653909683227539, 'bn1': 0.000560760498046875, 'relu1': 0.00032639503479003906, 'conv2': 0.0016336441040039062, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.0016357898712158203, 'bn1': 0.0005483627319335938, 'relu1': 0.0003256797790527344, 'conv2': 0.0016312599182128906, 'bn2': 0.0005476474761962891, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010459423065185547, 'bn1': 0.0003170967102050781, 'relu1': 0.00017261505126953125, 'conv2': 0.0013110637664794922, 'bn2': 0.0003075599670410156, 'conv3': 0.0003998279571533203, 'residual_add_relu2': 0.00038886070251464844}\n",
      "{'conv1': 0.0013055801391601562, 'bn1': 0.00030875205993652344, 'relu1': 0.00017070770263671875, 'conv2': 0.0013041496276855469, 'bn2': 0.0003116130828857422, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007882118225097656, 'bn1': 0.000202178955078125, 'relu1': 0.00010156631469726562, 'conv2': 0.00115966796875, 'bn2': 0.0002117156982421875, 'conv3': 0.00035643577575683594, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011594295501708984, 'bn1': 0.00019979476928710938, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011548995971679688, 'bn2': 0.00020313262939453125, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006623268127441406, 'bn1': 0.0001266002655029297, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00011706352233886719, 'conv3': 0.00030040740966796875, 'residual_add_relu2': 0.00011229515075683594}\n",
      "{'conv1': 0.001163482666015625, 'bn1': 0.00012803077697753906, 'relu1': 6.580352783203125e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.00012826919555664062, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 317\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016529560089111328, 'bn1': 0.0005574226379394531, 'relu1': 0.000324249267578125, 'conv2': 0.0016260147094726562, 'bn2': 0.0005376338958740234, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.001636505126953125, 'bn1': 0.0005457401275634766, 'relu1': 0.00032210350036621094, 'conv2': 0.0016314983367919922, 'bn2': 0.0005509853363037109, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001050710678100586, 'bn1': 0.0003147125244140625, 'relu1': 0.0001735687255859375, 'conv2': 0.0013206005096435547, 'bn2': 0.0003108978271484375, 'conv3': 0.0004000663757324219, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013093948364257812, 'bn1': 0.0003139972686767578, 'relu1': 0.00017452239990234375, 'conv2': 0.001310110092163086, 'bn2': 0.000308990478515625, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007863044738769531, 'bn1': 0.00019884109497070312, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.00020456314086914062, 'conv3': 0.0003521442413330078, 'residual_add_relu2': 0.00020265579223632812}\n",
      "{'conv1': 0.0011563301086425781, 'bn1': 0.0001933574676513672, 'relu1': 9.560585021972656e-05, 'conv2': 0.001155853271484375, 'bn2': 0.0001983642578125, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006616115570068359, 'bn1': 0.00012063980102539062, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00011658668518066406, 'conv3': 0.0002944469451904297, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011494159698486328, 'bn1': 0.00012731552124023438, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011467933654785156, 'bn2': 0.0001163482666015625, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 318\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016529560089111328, 'bn1': 0.0005552768707275391, 'relu1': 0.0003235340118408203, 'conv2': 0.0016334056854248047, 'bn2': 0.0006034374237060547, 'residual_add_relu2': 0.0007677078247070312}\n",
      "{'conv1': 0.0016450881958007812, 'bn1': 0.000545501708984375, 'relu1': 0.0003254413604736328, 'conv2': 0.0016326904296875, 'bn2': 0.0005445480346679688, 'residual_add_relu2': 0.0007746219635009766}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010502338409423828, 'bn1': 0.0003170967102050781, 'relu1': 0.0001728534698486328, 'conv2': 0.0013091564178466797, 'bn2': 0.000308990478515625, 'conv3': 0.0003979206085205078, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013189315795898438, 'bn1': 0.00036716461181640625, 'relu1': 0.000179290771484375, 'conv2': 0.0013210773468017578, 'bn2': 0.000308990478515625, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007939338684082031, 'bn1': 0.000209808349609375, 'relu1': 9.918212890625e-05, 'conv2': 0.0011606216430664062, 'bn2': 0.00019025802612304688, 'conv3': 0.0003554821014404297, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0011570453643798828, 'bn1': 0.00020456314086914062, 'relu1': 0.00010561943054199219, 'conv2': 0.0011713504791259766, 'bn2': 0.00020623207092285156, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006628036499023438, 'bn1': 0.00013589859008789062, 'relu1': 6.008148193359375e-05, 'conv2': 0.001150369644165039, 'bn2': 0.000118255615234375, 'conv3': 0.0003082752227783203, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011501312255859375, 'bn1': 0.0001251697540283203, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011467933654785156, 'bn2': 0.00011777877807617188, 'residual_add_relu2': 0.00011229515075683594}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 319\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016651153564453125, 'bn1': 0.0005536079406738281, 'relu1': 0.00032448768615722656, 'conv2': 0.0016369819641113281, 'bn2': 0.000560760498046875, 'residual_add_relu2': 0.0007622241973876953}\n",
      "{'conv1': 0.0016324520111083984, 'bn1': 0.0005407333374023438, 'relu1': 0.00032138824462890625, 'conv2': 0.0016350746154785156, 'bn2': 0.0005333423614501953, 'residual_add_relu2': 0.0007643699645996094}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010542869567871094, 'bn1': 0.00032138824462890625, 'relu1': 0.00017333030700683594, 'conv2': 0.0013091564178466797, 'bn2': 0.0003066062927246094, 'conv3': 0.0004036426544189453, 'residual_add_relu2': 0.00039267539978027344}\n",
      "{'conv1': 0.0013108253479003906, 'bn1': 0.0003135204315185547, 'relu1': 0.00017261505126953125, 'conv2': 0.0013074874877929688, 'bn2': 0.000308990478515625, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007889270782470703, 'bn1': 0.0001990795135498047, 'relu1': 9.870529174804688e-05, 'conv2': 0.001155853271484375, 'bn2': 0.00019502639770507812, 'conv3': 0.00035262107849121094, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011589527130126953, 'bn1': 0.000202178955078125, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00019407272338867188, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006601810455322266, 'bn1': 0.00012040138244628906, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00011849403381347656, 'conv3': 0.0002925395965576172, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011479854583740234, 'bn1': 0.00012111663818359375, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011439323425292969, 'bn2': 0.00011897087097167969, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 320\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001653432846069336, 'bn1': 0.0005562305450439453, 'relu1': 0.0003285408020019531, 'conv2': 0.0016434192657470703, 'bn2': 0.0005450248718261719, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016314983367919922, 'bn1': 0.0005543231964111328, 'relu1': 0.0003249645233154297, 'conv2': 0.001634359359741211, 'bn2': 0.0005390644073486328, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010459423065185547, 'bn1': 0.00031375885009765625, 'relu1': 0.0001735687255859375, 'conv2': 0.0013096332550048828, 'bn2': 0.00032019615173339844, 'conv3': 0.00039887428283691406, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013103485107421875, 'bn1': 0.0003147125244140625, 'relu1': 0.0001723766326904297, 'conv2': 0.001306295394897461, 'bn2': 0.00031256675720214844, 'residual_add_relu2': 0.00038886070251464844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007863044738769531, 'bn1': 0.0001926422119140625, 'relu1': 9.608268737792969e-05, 'conv2': 0.001153707504272461, 'bn2': 0.0001850128173828125, 'conv3': 0.0003490447998046875, 'residual_add_relu2': 0.00020265579223632812}\n",
      "{'conv1': 0.0011572837829589844, 'bn1': 0.00019359588623046875, 'relu1': 9.72747802734375e-05, 'conv2': 0.001153707504272461, 'bn2': 0.00019502639770507812, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006587505340576172, 'bn1': 0.00012111663818359375, 'relu1': 5.9604644775390625e-05, 'conv2': 0.001148223876953125, 'bn2': 0.00011920928955078125, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011496543884277344, 'bn1': 0.0001220703125, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011458396911621094, 'bn2': 0.00011992454528808594, 'residual_add_relu2': 0.00011324882507324219}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 321\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016489028930664062, 'bn1': 0.0005495548248291016, 'relu1': 0.00032711029052734375, 'conv2': 0.001626729965209961, 'bn2': 0.0005421638488769531, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016341209411621094, 'bn1': 0.0005474090576171875, 'relu1': 0.0003266334533691406, 'conv2': 0.001630544662475586, 'bn2': 0.0005381107330322266, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010476112365722656, 'bn1': 0.00031447410583496094, 'relu1': 0.00017261505126953125, 'conv2': 0.0013113021850585938, 'bn2': 0.00031185150146484375, 'conv3': 0.00040340423583984375, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013124942779541016, 'bn1': 0.0003132820129394531, 'relu1': 0.00017261505126953125, 'conv2': 0.0013079643249511719, 'bn2': 0.00031185150146484375, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007903575897216797, 'bn1': 0.00019288063049316406, 'relu1': 9.751319885253906e-05, 'conv2': 0.00115203857421875, 'bn2': 0.0001842975616455078, 'conv3': 0.00034689903259277344, 'residual_add_relu2': 0.0002460479736328125}\n",
      "{'conv1': 0.0011644363403320312, 'bn1': 0.0001952648162841797, 'relu1': 9.703636169433594e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.0001862049102783203, 'residual_add_relu2': 0.0002033710479736328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006549358367919922, 'bn1': 0.00011801719665527344, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00011920928955078125, 'conv3': 0.00029587745666503906, 'residual_add_relu2': 0.00011229515075683594}\n",
      "{'conv1': 0.0011467933654785156, 'bn1': 0.00012087821960449219, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.00012636184692382812, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 322\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016436576843261719, 'bn1': 0.0005586147308349609, 'relu1': 0.00032591819763183594, 'conv2': 0.0016307830810546875, 'bn2': 0.0005426406860351562, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016319751739501953, 'bn1': 0.0005471706390380859, 'relu1': 0.00032448768615722656, 'conv2': 0.0016286373138427734, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010502338409423828, 'bn1': 0.0003139972686767578, 'relu1': 0.00017142295837402344, 'conv2': 0.001310110092163086, 'bn2': 0.00031447410583496094, 'conv3': 0.0004000663757324219, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013091564178466797, 'bn1': 0.00031447410583496094, 'relu1': 0.0001728534698486328, 'conv2': 0.0013072490692138672, 'bn2': 0.0003192424774169922, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007915496826171875, 'bn1': 0.0002002716064453125, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011568069458007812, 'bn2': 0.00019359588623046875, 'conv3': 0.0003516674041748047, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.0011637210845947266, 'bn1': 0.0002002716064453125, 'relu1': 9.751319885253906e-05, 'conv2': 0.001154184341430664, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006608963012695312, 'bn1': 0.00012350082397460938, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00011539459228515625, 'conv3': 0.0002932548522949219, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011501312255859375, 'bn1': 0.00012111663818359375, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00012493133544921875, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 323\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016438961029052734, 'bn1': 0.0005619525909423828, 'relu1': 0.0003235340118408203, 'conv2': 0.0016269683837890625, 'bn2': 0.0005295276641845703, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016295909881591797, 'bn1': 0.0005366802215576172, 'relu1': 0.00032067298889160156, 'conv2': 0.0016222000122070312, 'bn2': 0.0005333423614501953, 'residual_add_relu2': 0.0007662773132324219}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010416507720947266, 'bn1': 0.00030422210693359375, 'relu1': 0.00016999244689941406, 'conv2': 0.0013065338134765625, 'bn2': 0.00030493736267089844, 'conv3': 0.0003955364227294922, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013060569763183594, 'bn1': 0.0003113746643066406, 'relu1': 0.00017261505126953125, 'conv2': 0.001306772232055664, 'bn2': 0.0003120899200439453, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000789642333984375, 'bn1': 0.0002067089080810547, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.00019407272338867188, 'conv3': 0.0003535747528076172, 'residual_add_relu2': 0.00020885467529296875}\n",
      "{'conv1': 0.001165151596069336, 'bn1': 0.000194549560546875, 'relu1': 9.72747802734375e-05, 'conv2': 0.001150369644165039, 'bn2': 0.00018644332885742188, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006570816040039062, 'bn1': 0.00011563301086425781, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011439323425292969, 'bn2': 0.00012874603271484375, 'conv3': 0.0002944469451904297, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011446475982666016, 'bn1': 0.00011563301086425781, 'relu1': 5.7220458984375e-05, 'conv2': 0.0011429786682128906, 'bn2': 0.00012159347534179688, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 324\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016596317291259766, 'bn1': 0.0005514621734619141, 'relu1': 0.0003230571746826172, 'conv2': 0.0016341209411621094, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.0007734298706054688}\n",
      "{'conv1': 0.0016396045684814453, 'bn1': 0.0005450248718261719, 'relu1': 0.000324249267578125, 'conv2': 0.001641988754272461, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010478496551513672, 'bn1': 0.0003139972686767578, 'relu1': 0.0001728534698486328, 'conv2': 0.001308441162109375, 'bn2': 0.00031113624572753906, 'conv3': 0.00039839744567871094, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013096332550048828, 'bn1': 0.0003132820129394531, 'relu1': 0.00017309188842773438, 'conv2': 0.0013070106506347656, 'bn2': 0.0003116130828857422, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007908344268798828, 'bn1': 0.0002009868621826172, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011577606201171875, 'bn2': 0.00019621849060058594, 'conv3': 0.0003535747528076172, 'residual_add_relu2': 0.00021004676818847656}\n",
      "{'conv1': 0.0011641979217529297, 'bn1': 0.00020194053649902344, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011534690856933594, 'bn2': 0.00019431114196777344, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006623268127441406, 'bn1': 0.00012826919555664062, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.00011730194091796875, 'conv3': 0.0002956390380859375, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011472702026367188, 'bn1': 0.0001220703125, 'relu1': 5.91278076171875e-05, 'conv2': 0.001146078109741211, 'bn2': 0.00013136863708496094, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 325\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016543865203857422, 'bn1': 0.0005545616149902344, 'relu1': 0.0003228187561035156, 'conv2': 0.0016338825225830078, 'bn2': 0.0005450248718261719, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.0016345977783203125, 'bn1': 0.0005440711975097656, 'relu1': 0.0003254413604736328, 'conv2': 0.0016295909881591797, 'bn2': 0.0005438327789306641, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001054525375366211, 'bn1': 0.0003230571746826172, 'relu1': 0.00017499923706054688, 'conv2': 0.0013158321380615234, 'bn2': 0.00033473968505859375, 'conv3': 0.0004069805145263672, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013179779052734375, 'bn1': 0.000335693359375, 'relu1': 0.0001780986785888672, 'conv2': 0.0013175010681152344, 'bn2': 0.00032210350036621094, 'residual_add_relu2': 0.0003936290740966797}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007944107055664062, 'bn1': 0.00021076202392578125, 'relu1': 0.00010061264038085938, 'conv2': 0.0011637210845947266, 'bn2': 0.00021958351135253906, 'conv3': 0.00036215782165527344, 'residual_add_relu2': 0.00020766258239746094}\n",
      "{'conv1': 0.001163482666015625, 'bn1': 0.0002105236053466797, 'relu1': 0.00010037422180175781, 'conv2': 0.0011603832244873047, 'bn2': 0.0002715587615966797, 'residual_add_relu2': 0.00020837783813476562}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006935596466064453, 'bn1': 0.00013494491577148438, 'relu1': 6.318092346191406e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.00011539459228515625, 'conv3': 0.0002951622009277344, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.001157999038696289, 'bn1': 0.00012564659118652344, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011453628540039062, 'bn2': 0.00011372566223144531, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 326\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001644134521484375, 'bn1': 0.0005586147308349609, 'relu1': 0.000324249267578125, 'conv2': 0.0016317367553710938, 'bn2': 0.0005440711975097656, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.0016303062438964844, 'bn1': 0.0005464553833007812, 'relu1': 0.0003247261047363281, 'conv2': 0.0016286373138427734, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010519027709960938, 'bn1': 0.0003306865692138672, 'relu1': 0.00017452239990234375, 'conv2': 0.001310110092163086, 'bn2': 0.00030922889709472656, 'conv3': 0.0003981590270996094, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013096332550048828, 'bn1': 0.0003170967102050781, 'relu1': 0.00017261505126953125, 'conv2': 0.0013082027435302734, 'bn2': 0.0003077983856201172, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007877349853515625, 'bn1': 0.00019860267639160156, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00020003318786621094, 'conv3': 0.00035381317138671875, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.00020122528076171875, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.0002067089080810547, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006623268127441406, 'bn1': 0.00012302398681640625, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.00011491775512695312, 'conv3': 0.0002949237823486328, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011513233184814453, 'bn1': 0.00013113021850585938, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00011563301086425781, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 327\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016672611236572266, 'bn1': 0.0005581378936767578, 'relu1': 0.00032520294189453125, 'conv2': 0.0016443729400634766, 'bn2': 0.0005564689636230469, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016450881958007812, 'bn1': 0.0005538463592529297, 'relu1': 0.0003349781036376953, 'conv2': 0.0016474723815917969, 'bn2': 0.0005457401275634766, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010499954223632812, 'bn1': 0.0003185272216796875, 'relu1': 0.00017261505126953125, 'conv2': 0.001318216323852539, 'bn2': 0.0003070831298828125, 'conv3': 0.00039839744567871094, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013108253479003906, 'bn1': 0.0003185272216796875, 'relu1': 0.00017380714416503906, 'conv2': 0.0013077259063720703, 'bn2': 0.00030994415283203125, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007910728454589844, 'bn1': 0.00020313262939453125, 'relu1': 9.894371032714844e-05, 'conv2': 0.001157522201538086, 'bn2': 0.00019407272338867188, 'conv3': 0.0003540515899658203, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011622905731201172, 'bn1': 0.00020122528076171875, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.0002067089080810547, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006618499755859375, 'bn1': 0.00012159347534179688, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.00011563301086425781, 'conv3': 0.0002963542938232422, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011522769927978516, 'bn1': 0.00012421607971191406, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011436939239501953, 'bn2': 0.00011491775512695312, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 328\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016586780548095703, 'bn1': 0.0005562305450439453, 'relu1': 0.0003249645233154297, 'conv2': 0.001638650894165039, 'bn2': 0.0005421638488769531, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.0016460418701171875, 'bn1': 0.0005478858947753906, 'relu1': 0.0003235340118408203, 'conv2': 0.0016367435455322266, 'bn2': 0.0005373954772949219, 'residual_add_relu2': 0.000766754150390625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010480880737304688, 'bn1': 0.0003161430358886719, 'relu1': 0.00017333030700683594, 'conv2': 0.0013117790222167969, 'bn2': 0.0003197193145751953, 'conv3': 0.0004024505615234375, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013093948364257812, 'bn1': 0.00031566619873046875, 'relu1': 0.00017380714416503906, 'conv2': 0.0013065338134765625, 'bn2': 0.00032210350036621094, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007910728454589844, 'bn1': 0.0002014636993408203, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011568069458007812, 'bn2': 0.000194549560546875, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.0002071857452392578}\n",
      "{'conv1': 0.0011777877807617188, 'bn1': 0.0002067089080810547, 'relu1': 9.918212890625e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.00019502639770507812, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006647109985351562, 'bn1': 0.00012159347534179688, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00011610984802246094, 'conv3': 0.00029540061950683594, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011477470397949219, 'bn1': 0.00012183189392089844, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011458396911621094, 'bn2': 0.00012040138244628906, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 329\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016701221466064453, 'bn1': 0.0005702972412109375, 'relu1': 0.00033020973205566406, 'conv2': 0.001638174057006836, 'bn2': 0.0005588531494140625, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.0016376972198486328, 'bn1': 0.0005478858947753906, 'relu1': 0.0003266334533691406, 'conv2': 0.0016338825225830078, 'bn2': 0.0005388259887695312, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010521411895751953, 'bn1': 0.0003223419189453125, 'relu1': 0.0001728534698486328, 'conv2': 0.0013093948364257812, 'bn2': 0.0003147125244140625, 'conv3': 0.00040435791015625, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013134479522705078, 'bn1': 0.0003237724304199219, 'relu1': 0.00017571449279785156, 'conv2': 0.0013089179992675781, 'bn2': 0.00033545494079589844, 'residual_add_relu2': 0.00039315223693847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007932186126708984, 'bn1': 0.00021123886108398438, 'relu1': 0.00010061264038085938, 'conv2': 0.0011606216430664062, 'bn2': 0.00019693374633789062, 'conv3': 0.0003566741943359375, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011601448059082031, 'bn1': 0.00020170211791992188, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011649131774902344, 'bn2': 0.00019860267639160156, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006628036499023438, 'bn1': 0.0001251697540283203, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.00011777877807617188, 'conv3': 0.0002961158752441406, 'residual_add_relu2': 0.00011324882507324219}\n",
      "{'conv1': 0.0011527538299560547, 'bn1': 0.0001239776611328125, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011463165283203125, 'bn2': 0.00010919570922851562, 'residual_add_relu2': 0.0001087188720703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 330\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016536712646484375, 'bn1': 0.0005536079406738281, 'relu1': 0.0003247261047363281, 'conv2': 0.001631021499633789, 'bn2': 0.0005471706390380859, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.001634359359741211, 'bn1': 0.0005440711975097656, 'relu1': 0.0003216266632080078, 'conv2': 0.001626729965209961, 'bn2': 0.0005335807800292969, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010433197021484375, 'bn1': 0.0003204345703125, 'relu1': 0.00017547607421875, 'conv2': 0.0013120174407958984, 'bn2': 0.0003082752227783203, 'conv3': 0.00039887428283691406, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013124942779541016, 'bn1': 0.0003192424774169922, 'relu1': 0.00017213821411132812, 'conv2': 0.001306772232055664, 'bn2': 0.00031113624572753906, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007929801940917969, 'bn1': 0.00020194053649902344, 'relu1': 0.00010013580322265625, 'conv2': 0.001157522201538086, 'bn2': 0.00019550323486328125, 'conv3': 0.0003533363342285156, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011577606201171875, 'bn1': 0.00019311904907226562, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.00019168853759765625, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006570816040039062, 'bn1': 0.00011706352233886719, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011436939239501953, 'bn2': 0.00011444091796875, 'conv3': 0.0002949237823486328, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.001149892807006836, 'bn1': 0.00013494491577148438, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.00010991096496582031, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 331\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001653432846069336, 'bn1': 0.0005545616149902344, 'relu1': 0.00032448768615722656, 'conv2': 0.0016384124755859375, 'bn2': 0.000560760498046875, 'residual_add_relu2': 0.0007648468017578125}\n",
      "{'conv1': 0.0016427040100097656, 'bn1': 0.0005414485931396484, 'relu1': 0.00032782554626464844, 'conv2': 0.0016336441040039062, 'bn2': 0.0005376338958740234, 'residual_add_relu2': 0.0007669925689697266}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010488033294677734, 'bn1': 0.0003116130828857422, 'relu1': 0.0001704692840576172, 'conv2': 0.0013141632080078125, 'bn2': 0.00030231475830078125, 'conv3': 0.0003943443298339844, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013053417205810547, 'bn1': 0.000316619873046875, 'relu1': 0.00017380714416503906, 'conv2': 0.0013077259063720703, 'bn2': 0.00030922889709472656, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008442401885986328, 'bn1': 0.0002090930938720703, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011587142944335938, 'bn2': 0.0001964569091796875, 'conv3': 0.00035381317138671875, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0011625289916992188, 'bn1': 0.0002009868621826172, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011563301086425781, 'bn2': 0.0001990795135498047, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006613731384277344, 'bn1': 0.00012111663818359375, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.00011539459228515625, 'conv3': 0.00029206275939941406, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011546611785888672, 'bn1': 0.00012230873107910156, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011441707611083984, 'bn2': 0.00011491775512695312, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 332\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016543865203857422, 'bn1': 0.0005576610565185547, 'relu1': 0.00032448768615722656, 'conv2': 0.0016350746154785156, 'bn2': 0.0005376338958740234, 'residual_add_relu2': 0.0007648468017578125}\n",
      "{'conv1': 0.0016329288482666016, 'bn1': 0.0005366802215576172, 'relu1': 0.0003223419189453125, 'conv2': 0.0016291141510009766, 'bn2': 0.0005326271057128906, 'residual_add_relu2': 0.0007617473602294922}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010447502136230469, 'bn1': 0.0003097057342529297, 'relu1': 0.00017070770263671875, 'conv2': 0.0013082027435302734, 'bn2': 0.00030112266540527344, 'conv3': 0.00039768218994140625, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.001310110092163086, 'bn1': 0.00033020973205566406, 'relu1': 0.00017571449279785156, 'conv2': 0.0013093948364257812, 'bn2': 0.0003104209899902344, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000789642333984375, 'bn1': 0.0002148151397705078, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011625289916992188, 'bn2': 0.0001957416534423828, 'conv3': 0.00035262107849121094, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.001161813735961914, 'bn1': 0.00020241737365722656, 'relu1': 9.775161743164062e-05, 'conv2': 0.001171112060546875, 'bn2': 0.00020360946655273438, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006639957427978516, 'bn1': 0.0001246929168701172, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011463165283203125, 'bn2': 0.00011730194091796875, 'conv3': 0.0002961158752441406, 'residual_add_relu2': 0.00011396408081054688}\n",
      "{'conv1': 0.0011539459228515625, 'bn1': 0.00011777877807617188, 'relu1': 5.7220458984375e-05, 'conv2': 0.0011432170867919922, 'bn2': 0.00011181831359863281, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 333\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016617774963378906, 'bn1': 0.0005517005920410156, 'relu1': 0.00032258033752441406, 'conv2': 0.0016374588012695312, 'bn2': 0.0005359649658203125, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.001641988754272461, 'bn1': 0.0005409717559814453, 'relu1': 0.0003230571746826172, 'conv2': 0.0016243457794189453, 'bn2': 0.0005390644073486328, 'residual_add_relu2': 0.0007677078247070312}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010495185852050781, 'bn1': 0.00031566619873046875, 'relu1': 0.00017976760864257812, 'conv2': 0.0013165473937988281, 'bn2': 0.0003159046173095703, 'conv3': 0.00040078163146972656, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013093948364257812, 'bn1': 0.00031828880310058594, 'relu1': 0.0001742839813232422, 'conv2': 0.0013079643249511719, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007901191711425781, 'bn1': 0.0001995563507080078, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011587142944335938, 'bn2': 0.00021004676818847656, 'conv3': 0.0003573894500732422, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011551380157470703, 'bn1': 0.00020051002502441406, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011513233184814453, 'bn2': 0.00019097328186035156, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006577968597412109, 'bn1': 0.00011610984802246094, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011434555053710938, 'bn2': 0.00010776519775390625, 'conv3': 0.0002923011779785156, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.001146078109741211, 'bn1': 0.00011777877807617188, 'relu1': 5.7220458984375e-05, 'conv2': 0.001142263412475586, 'bn2': 0.00011277198791503906, 'residual_add_relu2': 0.0001087188720703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 334\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016522407531738281, 'bn1': 0.0005545616149902344, 'relu1': 0.0003237724304199219, 'conv2': 0.0016369819641113281, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016422271728515625, 'bn1': 0.0005447864532470703, 'relu1': 0.0003230571746826172, 'conv2': 0.0016255378723144531, 'bn2': 0.0005335807800292969, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001043558120727539, 'bn1': 0.0003101825714111328, 'relu1': 0.00017070770263671875, 'conv2': 0.001306295394897461, 'bn2': 0.0003097057342529297, 'conv3': 0.0003974437713623047, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.0013065338134765625, 'bn1': 0.00030493736267089844, 'relu1': 0.0001704692840576172, 'conv2': 0.0013022422790527344, 'bn2': 0.00031280517578125, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007872581481933594, 'bn1': 0.00018978118896484375, 'relu1': 9.584426879882812e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.00018644332885742188, 'conv3': 0.00035071372985839844, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.0001952648162841797, 'relu1': 9.608268737792969e-05, 'conv2': 0.001150369644165039, 'bn2': 0.00018715858459472656, 'residual_add_relu2': 0.0002033710479736328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006632804870605469, 'bn1': 0.00014591217041015625, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00013399124145507812, 'conv3': 0.000293731689453125, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011446475982666016, 'bn1': 0.00011777877807617188, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011420249938964844, 'bn2': 0.0001239776611328125, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 335\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016582012176513672, 'bn1': 0.0005593299865722656, 'relu1': 0.0003254413604736328, 'conv2': 0.0016448497772216797, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016582012176513672, 'bn1': 0.0005462169647216797, 'relu1': 0.00032591819763183594, 'conv2': 0.0016531944274902344, 'bn2': 0.0005512237548828125, 'residual_add_relu2': 0.0007655620574951172}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010628700256347656, 'bn1': 0.00032639503479003906, 'relu1': 0.00017571449279785156, 'conv2': 0.0013399124145507812, 'bn2': 0.00033164024353027344, 'conv3': 0.0004112720489501953, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013284683227539062, 'bn1': 0.00030803680419921875, 'relu1': 0.0001723766326904297, 'conv2': 0.001329183578491211, 'bn2': 0.00030422210693359375, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007953643798828125, 'bn1': 0.0001964569091796875, 'relu1': 9.751319885253906e-05, 'conv2': 0.0011773109436035156, 'bn2': 0.00020694732666015625, 'conv3': 0.0003600120544433594, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.001178741455078125, 'bn1': 0.00019931793212890625, 'relu1': 9.894371032714844e-05, 'conv2': 0.001173257827758789, 'bn2': 0.00019884109497070312, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006687641143798828, 'bn1': 0.0001277923583984375, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011663436889648438, 'bn2': 0.00011610984802246094, 'conv3': 0.00030303001403808594, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011653900146484375, 'bn1': 0.00012445449829101562, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011606216430664062, 'bn2': 0.00011444091796875, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 336\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016570091247558594, 'bn1': 0.0005540847778320312, 'relu1': 0.0003237724304199219, 'conv2': 0.001641988754272461, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016460418701171875, 'bn1': 0.0005528926849365234, 'relu1': 0.0003204345703125, 'conv2': 0.0016400814056396484, 'bn2': 0.0005352497100830078, 'residual_add_relu2': 0.0007610321044921875}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010476112365722656, 'bn1': 0.0003032684326171875, 'relu1': 0.0001690387725830078, 'conv2': 0.0013194084167480469, 'bn2': 0.0003077983856201172, 'conv3': 0.0003960132598876953, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013186931610107422, 'bn1': 0.00030612945556640625, 'relu1': 0.00017070770263671875, 'conv2': 0.0013132095336914062, 'bn2': 0.00030541419982910156, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007879734039306641, 'bn1': 0.00019359588623046875, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011615753173828125, 'bn2': 0.00019741058349609375, 'conv3': 0.00035452842712402344, 'residual_add_relu2': 0.0002028942108154297}\n",
      "{'conv1': 0.0011622905731201172, 'bn1': 0.00019407272338867188, 'relu1': 9.655952453613281e-05, 'conv2': 0.001157522201538086, 'bn2': 0.0001895427703857422, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006608963012695312, 'bn1': 0.00011539459228515625, 'relu1': 5.7697296142578125e-05, 'conv2': 0.00115203857421875, 'bn2': 0.00010800361633300781, 'conv3': 0.00028824806213378906, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.00115203857421875, 'bn1': 0.00013017654418945312, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.0001220703125, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 337\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016562938690185547, 'bn1': 0.0005688667297363281, 'relu1': 0.0003275871276855469, 'conv2': 0.0016498565673828125, 'bn2': 0.0005707740783691406, 'residual_add_relu2': 0.0007691383361816406}\n",
      "{'conv1': 0.0016467571258544922, 'bn1': 0.0005526542663574219, 'relu1': 0.00032639503479003906, 'conv2': 0.0016443729400634766, 'bn2': 0.0005352497100830078, 'residual_add_relu2': 0.0007615089416503906}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010476112365722656, 'bn1': 0.00031375885009765625, 'relu1': 0.00017118453979492188, 'conv2': 0.001312255859375, 'bn2': 0.0003037452697753906, 'conv3': 0.0003936290740966797, 'residual_add_relu2': 0.00038886070251464844}\n",
      "{'conv1': 0.0013124942779541016, 'bn1': 0.0003101825714111328, 'relu1': 0.0001709461212158203, 'conv2': 0.001310586929321289, 'bn2': 0.00030803680419921875, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007922649383544922, 'bn1': 0.00019669532775878906, 'relu1': 9.894371032714844e-05, 'conv2': 0.00116729736328125, 'bn2': 0.00020551681518554688, 'conv3': 0.0003566741943359375, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.001165628433227539, 'bn1': 0.00020003318786621094, 'relu1': 9.799003601074219e-05, 'conv2': 0.001161813735961914, 'bn2': 0.0002052783966064453, 'residual_add_relu2': 0.00020623207092285156}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006687641143798828, 'bn1': 0.00012946128845214844, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011603832244873047, 'bn2': 0.00012373924255371094, 'conv3': 0.0003025531768798828, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.001161813735961914, 'bn1': 0.00014066696166992188, 'relu1': 6.246566772460938e-05, 'conv2': 0.001157999038696289, 'bn2': 0.0001239776611328125, 'residual_add_relu2': 0.00011229515075683594}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 338\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016717910766601562, 'bn1': 0.0005557537078857422, 'relu1': 0.0003249645233154297, 'conv2': 0.0016443729400634766, 'bn2': 0.0005447864532470703, 'residual_add_relu2': 0.0007681846618652344}\n",
      "{'conv1': 0.0016510486602783203, 'bn1': 0.0005435943603515625, 'relu1': 0.00032711029052734375, 'conv2': 0.0016360282897949219, 'bn2': 0.0005497932434082031, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010554790496826172, 'bn1': 0.00034117698669433594, 'relu1': 0.00017881393432617188, 'conv2': 0.0013225078582763672, 'bn2': 0.0003159046173095703, 'conv3': 0.00040340423583984375, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013210773468017578, 'bn1': 0.00031876564025878906, 'relu1': 0.0001735687255859375, 'conv2': 0.0013141632080078125, 'bn2': 0.00031065940856933594, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007929801940917969, 'bn1': 0.00019931793212890625, 'relu1': 0.0001475811004638672, 'conv2': 0.0011703968048095703, 'bn2': 0.00020003318786621094, 'conv3': 0.0003542900085449219, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.001171112060546875, 'bn1': 0.00019979476928710938, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011615753173828125, 'bn2': 0.00020265579223632812, 'residual_add_relu2': 0.0002028942108154297}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.00066375732421875, 'bn1': 0.00011920928955078125, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.00010967254638671875, 'conv3': 0.00029397010803222656, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011525154113769531, 'bn1': 0.00013756752014160156, 'relu1': 6.103515625e-05, 'conv2': 0.0011551380157470703, 'bn2': 0.00011777877807617188, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 339\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.00165557861328125, 'bn1': 0.0005533695220947266, 'relu1': 0.0003266334533691406, 'conv2': 0.0016393661499023438, 'bn2': 0.0005421638488769531, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016412734985351562, 'bn1': 0.0005476474761962891, 'relu1': 0.0003237724304199219, 'conv2': 0.001636505126953125, 'bn2': 0.0005395412445068359, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010466575622558594, 'bn1': 0.0003097057342529297, 'relu1': 0.00017142295837402344, 'conv2': 0.0013134479522705078, 'bn2': 0.00030350685119628906, 'conv3': 0.0004107952117919922, 'residual_add_relu2': 0.00039267539978027344}\n",
      "{'conv1': 0.0013175010681152344, 'bn1': 0.00031256675720214844, 'relu1': 0.00017309188842773438, 'conv2': 0.0013129711151123047, 'bn2': 0.0003056526184082031, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007867813110351562, 'bn1': 0.0001900196075439453, 'relu1': 9.584426879882812e-05, 'conv2': 0.0011577606201171875, 'bn2': 0.0001895427703857422, 'conv3': 0.0003509521484375, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.001161336898803711, 'bn1': 0.0001952648162841797, 'relu1': 9.560585021972656e-05, 'conv2': 0.0011582374572753906, 'bn2': 0.00018858909606933594, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006601810455322266, 'bn1': 0.00011587142944335938, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011534690856933594, 'bn2': 0.00012826919555664062, 'conv3': 0.0003008842468261719, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011563301086425781, 'bn1': 0.00012040138244628906, 'relu1': 5.936622619628906e-05, 'conv2': 0.001153707504272461, 'bn2': 0.00011944770812988281, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 340\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016567707061767578, 'bn1': 0.0005521774291992188, 'relu1': 0.0003247261047363281, 'conv2': 0.001634836196899414, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007646083831787109}\n",
      "{'conv1': 0.0016472339630126953, 'bn1': 0.0005514621734619141, 'relu1': 0.0003256797790527344, 'conv2': 0.0016391277313232422, 'bn2': 0.0005533695220947266, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010535717010498047, 'bn1': 0.0003159046173095703, 'relu1': 0.00017333030700683594, 'conv2': 0.0013175010681152344, 'bn2': 0.00031113624572753906, 'conv3': 0.0004017353057861328, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013175010681152344, 'bn1': 0.0003139972686767578, 'relu1': 0.00017380714416503906, 'conv2': 0.0013146400451660156, 'bn2': 0.0003190040588378906, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007941722869873047, 'bn1': 0.000202178955078125, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011632442474365234, 'bn2': 0.00019431114196777344, 'conv3': 0.0003666877746582031, 'residual_add_relu2': 0.0002079010009765625}\n",
      "{'conv1': 0.0011696815490722656, 'bn1': 0.00020194053649902344, 'relu1': 9.918212890625e-05, 'conv2': 0.0011615753173828125, 'bn2': 0.00019407272338867188, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006663799285888672, 'bn1': 0.00012540817260742188, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.0001163482666015625, 'conv3': 0.000293731689453125, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.0001220703125, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.00011992454528808594, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 341\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016660690307617188, 'bn1': 0.0005574226379394531, 'relu1': 0.00032329559326171875, 'conv2': 0.001638650894165039, 'bn2': 0.0005328655242919922, 'residual_add_relu2': 0.0007648468017578125}\n",
      "{'conv1': 0.001634836196899414, 'bn1': 0.0005464553833007812, 'relu1': 0.00032210350036621094, 'conv2': 0.0016376972198486328, 'bn2': 0.0005352497100830078, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010478496551513672, 'bn1': 0.0003037452697753906, 'relu1': 0.0001709461212158203, 'conv2': 0.0013120174407958984, 'bn2': 0.0003020763397216797, 'conv3': 0.00039577484130859375, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013110637664794922, 'bn1': 0.00030231475830078125, 'relu1': 0.0001704692840576172, 'conv2': 0.0013096332550048828, 'bn2': 0.0003027915954589844, 'residual_add_relu2': 0.0003883838653564453}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007889270782470703, 'bn1': 0.00019121170043945312, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011601448059082031, 'bn2': 0.00019025802612304688, 'conv3': 0.00035071372985839844, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.0011668205261230469, 'bn1': 0.00020074844360351562, 'relu1': 9.846687316894531e-05, 'conv2': 0.001161813735961914, 'bn2': 0.00019311904907226562, 'residual_add_relu2': 0.00020599365234375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006716251373291016, 'bn1': 0.00012540817260742188, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011563301086425781, 'bn2': 0.00011539459228515625, 'conv3': 0.0002906322479248047, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00012111663818359375, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011539459228515625, 'bn2': 0.00011515617370605469, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 342\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016751289367675781, 'bn1': 0.0005717277526855469, 'relu1': 0.0003275871276855469, 'conv2': 0.0016512870788574219, 'bn2': 0.0005545616149902344, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.0016584396362304688, 'bn1': 0.0005533695220947266, 'relu1': 0.00032591819763183594, 'conv2': 0.001641988754272461, 'bn2': 0.0005507469177246094, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010607242584228516, 'bn1': 0.00032591819763183594, 'relu1': 0.00017547607421875, 'conv2': 0.0013260841369628906, 'bn2': 0.00032591819763183594, 'conv3': 0.0004150867462158203, 'residual_add_relu2': 0.0003960132598876953}\n",
      "{'conv1': 0.0013306140899658203, 'bn1': 0.00033664703369140625, 'relu1': 0.0001800060272216797, 'conv2': 0.0013248920440673828, 'bn2': 0.0003199577331542969, 'residual_add_relu2': 0.00039196014404296875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008018016815185547, 'bn1': 0.00021123886108398438, 'relu1': 0.000102996826171875, 'conv2': 0.0011699199676513672, 'bn2': 0.0002124309539794922, 'conv3': 0.00036025047302246094, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.0011720657348632812, 'bn1': 0.00021338462829589844, 'relu1': 0.00010132789611816406, 'conv2': 0.0011682510375976562, 'bn2': 0.0002956390380859375, 'residual_add_relu2': 0.0002071857452392578}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006783008575439453, 'bn1': 0.00013971328735351562, 'relu1': 6.341934204101562e-05, 'conv2': 0.0011630058288574219, 'bn2': 0.00012803077697753906, 'conv3': 0.0003044605255126953, 'residual_add_relu2': 0.00011396408081054688}\n",
      "{'conv1': 0.0011646747589111328, 'bn1': 0.00013709068298339844, 'relu1': 6.341934204101562e-05, 'conv2': 0.0011591911315917969, 'bn2': 0.00012969970703125, 'residual_add_relu2': 0.00011229515075683594}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 343\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001661062240600586, 'bn1': 0.0005540847778320312, 'relu1': 0.0003247261047363281, 'conv2': 0.0016345977783203125, 'bn2': 0.0005459785461425781, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016455650329589844, 'bn1': 0.00054931640625, 'relu1': 0.0003230571746826172, 'conv2': 0.001636505126953125, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010535717010498047, 'bn1': 0.0003159046173095703, 'relu1': 0.0001728534698486328, 'conv2': 0.0013163089752197266, 'bn2': 0.0003113746643066406, 'conv3': 0.00040268898010253906, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013167858123779297, 'bn1': 0.00031375885009765625, 'relu1': 0.00017333030700683594, 'conv2': 0.0013136863708496094, 'bn2': 0.0003056526184082031, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007927417755126953, 'bn1': 0.00020074844360351562, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011644363403320312, 'bn2': 0.00019407272338867188, 'conv3': 0.0003533363342285156, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011661052703857422, 'bn1': 0.00020837783813476562, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011658668518066406, 'bn2': 0.0001971721649169922, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006680488586425781, 'bn1': 0.00012564659118652344, 'relu1': 5.9604644775390625e-05, 'conv2': 0.001157522201538086, 'bn2': 0.00012111663818359375, 'conv3': 0.0002963542938232422, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011572837829589844, 'bn1': 0.00012135505676269531, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.00011467933654785156, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 344\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016486644744873047, 'bn1': 0.0005540847778320312, 'relu1': 0.0003235340118408203, 'conv2': 0.0016436576843261719, 'bn2': 0.0005393028259277344, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016438961029052734, 'bn1': 0.0005550384521484375, 'relu1': 0.0003249645233154297, 'conv2': 0.0016362667083740234, 'bn2': 0.0005478858947753906, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010559558868408203, 'bn1': 0.00032520294189453125, 'relu1': 0.00017452239990234375, 'conv2': 0.0013206005096435547, 'bn2': 0.0003075599670410156, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.00039315223693847656}\n",
      "{'conv1': 0.001321554183959961, 'bn1': 0.00031685829162597656, 'relu1': 0.00017261505126953125, 'conv2': 0.0013132095336914062, 'bn2': 0.000308990478515625, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007941722869873047, 'bn1': 0.0001995563507080078, 'relu1': 9.822845458984375e-05, 'conv2': 0.001165628433227539, 'bn2': 0.0001957416534423828, 'conv3': 0.00035262107849121094, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011637210845947266, 'bn1': 0.00020241737365722656, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011622905731201172, 'bn2': 0.00021839141845703125, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006656646728515625, 'bn1': 0.00011563301086425781, 'relu1': 5.817413330078125e-05, 'conv2': 0.00115203857421875, 'bn2': 0.00011944770812988281, 'conv3': 0.00029754638671875, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011551380157470703, 'bn1': 0.00012183189392089844, 'relu1': 5.984306335449219e-05, 'conv2': 0.00115203857421875, 'bn2': 0.00011420249938964844, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 345\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001653909683227539, 'bn1': 0.0005595684051513672, 'relu1': 0.000324249267578125, 'conv2': 0.0016396045684814453, 'bn2': 0.0005393028259277344, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.001638650894165039, 'bn1': 0.0005495548248291016, 'relu1': 0.0003235340118408203, 'conv2': 0.0016436576843261719, 'bn2': 0.0005502700805664062, 'residual_add_relu2': 0.0007658004760742188}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001058816909790039, 'bn1': 0.0003268718719482422, 'relu1': 0.00017571449279785156, 'conv2': 0.0013232231140136719, 'bn2': 0.0003230571746826172, 'conv3': 0.0004086494445800781, 'residual_add_relu2': 0.000392913818359375}\n",
      "{'conv1': 0.001325845718383789, 'bn1': 0.0003266334533691406, 'relu1': 0.0001761913299560547, 'conv2': 0.0013208389282226562, 'bn2': 0.0003209114074707031, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007982254028320312, 'bn1': 0.00020813941955566406, 'relu1': 0.00010180473327636719, 'conv2': 0.0011699199676513672, 'bn2': 0.00020360946655273438, 'conv3': 0.00035881996154785156, 'residual_add_relu2': 0.00020813941955566406}\n",
      "{'conv1': 0.0011746883392333984, 'bn1': 0.00021028518676757812, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011670589447021484, 'bn2': 0.00020241737365722656, 'residual_add_relu2': 0.00020647048950195312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006690025329589844, 'bn1': 0.00013494491577148438, 'relu1': 6.270408630371094e-05, 'conv2': 0.0011620521545410156, 'bn2': 0.00012493133544921875, 'conv3': 0.00030303001403808594, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011610984802246094, 'bn1': 0.0001316070556640625, 'relu1': 6.127357482910156e-05, 'conv2': 0.001157522201538086, 'bn2': 0.00012564659118652344, 'residual_add_relu2': 0.00011205673217773438}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 346\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016736984252929688, 'bn1': 0.0005617141723632812, 'relu1': 0.0003237724304199219, 'conv2': 0.0016522407531738281, 'bn2': 0.0005474090576171875, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016489028930664062, 'bn1': 0.0005438327789306641, 'relu1': 0.0003228187561035156, 'conv2': 0.0016407966613769531, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010561943054199219, 'bn1': 0.00032258033752441406, 'relu1': 0.00017452239990234375, 'conv2': 0.0013208389282226562, 'bn2': 0.00031113624572753906, 'conv3': 0.00040221214294433594, 'residual_add_relu2': 0.0003921985626220703}\n",
      "{'conv1': 0.001323699951171875, 'bn1': 0.0003256797790527344, 'relu1': 0.0001766681671142578, 'conv2': 0.0013203620910644531, 'bn2': 0.0003197193145751953, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007941722869873047, 'bn1': 0.0001976490020751953, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011637210845947266, 'bn2': 0.00020313262939453125, 'conv3': 0.0003578662872314453, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.00116729736328125, 'bn1': 0.00020122528076171875, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011620521545410156, 'bn2': 0.0002040863037109375, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006656646728515625, 'bn1': 0.00012135505676269531, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00011563301086425781, 'conv3': 0.00029397010803222656, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011582374572753906, 'bn1': 0.0001246929168701172, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00011372566223144531, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 347\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016713142395019531, 'bn1': 0.000560760498046875, 'relu1': 0.00032782554626464844, 'conv2': 0.0016515254974365234, 'bn2': 0.0005478858947753906, 'residual_add_relu2': 0.0007717609405517578}\n",
      "{'conv1': 0.0016405582427978516, 'bn1': 0.0005524158477783203, 'relu1': 0.0003237724304199219, 'conv2': 0.001636505126953125, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001056671142578125, 'bn1': 0.0003178119659423828, 'relu1': 0.00017333030700683594, 'conv2': 0.0013172626495361328, 'bn2': 0.000308990478515625, 'conv3': 0.0004036426544189453, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013196468353271484, 'bn1': 0.0003228187561035156, 'relu1': 0.00017523765563964844, 'conv2': 0.001316070556640625, 'bn2': 0.00030922889709472656, 'residual_add_relu2': 0.00039267539978027344}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007951259613037109, 'bn1': 0.00020432472229003906, 'relu1': 0.00010061264038085938, 'conv2': 0.0011668205261230469, 'bn2': 0.00019550323486328125, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.001168966293334961, 'bn1': 0.00020956993103027344, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011639595031738281, 'bn2': 0.000194549560546875, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006663799285888672, 'bn1': 0.00012683868408203125, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.00012421607971191406, 'conv3': 0.00029587745666503906, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011582374572753906, 'bn1': 0.0001239776611328125, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00011730194091796875, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 348\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016489028930664062, 'bn1': 0.0005538463592529297, 'relu1': 0.0003256797790527344, 'conv2': 0.0016391277313232422, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007677078247070312}\n",
      "{'conv1': 0.0016448497772216797, 'bn1': 0.0005457401275634766, 'relu1': 0.0003230571746826172, 'conv2': 0.0016391277313232422, 'bn2': 0.0005385875701904297, 'residual_add_relu2': 0.0007643699645996094}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010485649108886719, 'bn1': 0.00031256675720214844, 'relu1': 0.00017309188842773438, 'conv2': 0.0013170242309570312, 'bn2': 0.00032210350036621094, 'conv3': 0.00040149688720703125, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.001318216323852539, 'bn1': 0.0003135204315185547, 'relu1': 0.0001735687255859375, 'conv2': 0.0013146400451660156, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007920265197753906, 'bn1': 0.0001983642578125, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011641979217529297, 'bn2': 0.0001926422119140625, 'conv3': 0.0003669261932373047, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.0011692047119140625, 'bn1': 0.00020122528076171875, 'relu1': 9.72747802734375e-05, 'conv2': 0.001161813735961914, 'bn2': 0.00019431114196777344, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006642341613769531, 'bn1': 0.00012135505676269531, 'relu1': 6.794929504394531e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.00011563301086425781, 'conv3': 0.0002944469451904297, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011563301086425781, 'bn1': 0.00012183189392089844, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011529922485351562, 'bn2': 0.0001251697540283203, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 349\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016498565673828125, 'bn1': 0.0005524158477783203, 'relu1': 0.00032520294189453125, 'conv2': 0.0016400814056396484, 'bn2': 0.0005421638488769531, 'residual_add_relu2': 0.0007643699645996094}\n",
      "{'conv1': 0.0016355514526367188, 'bn1': 0.0005397796630859375, 'relu1': 0.00032138824462890625, 'conv2': 0.0016283988952636719, 'bn2': 0.0005326271057128906, 'residual_add_relu2': 0.0007605552673339844}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010485649108886719, 'bn1': 0.00030875205993652344, 'relu1': 0.00016999244689941406, 'conv2': 0.001312255859375, 'bn2': 0.0003025531768798828, 'conv3': 0.00039315223693847656, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013124942779541016, 'bn1': 0.0003039836883544922, 'relu1': 0.0001704692840576172, 'conv2': 0.001310586929321289, 'bn2': 0.0003063678741455078, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007874965667724609, 'bn1': 0.0001900196075439453, 'relu1': 9.560585021972656e-05, 'conv2': 0.0011591911315917969, 'bn2': 0.0001862049102783203, 'conv3': 0.00034689903259277344, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.001163482666015625, 'bn1': 0.00019931793212890625, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011625289916992188, 'bn2': 0.00019502639770507812, 'residual_add_relu2': 0.00020647048950195312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006654262542724609, 'bn1': 0.00012302398681640625, 'relu1': 6.747245788574219e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.0001163482666015625, 'conv3': 0.0002956390380859375, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011548995971679688, 'bn1': 0.00012063980102539062, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.00012612342834472656, 'residual_add_relu2': 0.00011229515075683594}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 350\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016562938690185547, 'bn1': 0.0005521774291992188, 'relu1': 0.00033211708068847656, 'conv2': 0.0016446113586425781, 'bn2': 0.0005447864532470703, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016508102416992188, 'bn1': 0.0005471706390380859, 'relu1': 0.00032639503479003906, 'conv2': 0.001638650894165039, 'bn2': 0.0005366802215576172, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010652542114257812, 'bn1': 0.0003123283386230469, 'relu1': 0.00017261505126953125, 'conv2': 0.0013172626495361328, 'bn2': 0.0003180503845214844, 'conv3': 0.0004017353057861328, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013163089752197266, 'bn1': 0.00031447410583496094, 'relu1': 0.0001735687255859375, 'conv2': 0.0013146400451660156, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007994174957275391, 'bn1': 0.00021004676818847656, 'relu1': 0.00010061264038085938, 'conv2': 0.001168966293334961, 'bn2': 0.00020384788513183594, 'conv3': 0.0003578662872314453, 'residual_add_relu2': 0.00020647048950195312}\n",
      "{'conv1': 0.0011720657348632812, 'bn1': 0.00021028518676757812, 'relu1': 0.00010037422180175781, 'conv2': 0.0011670589447021484, 'bn2': 0.00020503997802734375, 'residual_add_relu2': 0.00020694732666015625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006716251373291016, 'bn1': 0.00013399124145507812, 'relu1': 6.246566772460938e-05, 'conv2': 0.0011606216430664062, 'bn2': 0.0001270771026611328, 'conv3': 0.0003001689910888672, 'residual_add_relu2': 0.00011301040649414062}\n",
      "{'conv1': 0.0011637210845947266, 'bn1': 0.0001308917999267578, 'relu1': 6.103515625e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.0001270771026611328, 'residual_add_relu2': 0.00011277198791503906}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 351\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001669168472290039, 'bn1': 0.0005674362182617188, 'relu1': 0.00032711029052734375, 'conv2': 0.001644134521484375, 'bn2': 0.0005459785461425781, 'residual_add_relu2': 0.0007727146148681641}\n",
      "{'conv1': 0.0016446113586425781, 'bn1': 0.0005517005920410156, 'relu1': 0.0003249645233154297, 'conv2': 0.0016431808471679688, 'bn2': 0.0005481243133544922, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010526180267333984, 'bn1': 0.0003523826599121094, 'relu1': 0.00017595291137695312, 'conv2': 0.0013217926025390625, 'bn2': 0.0003142356872558594, 'conv3': 0.0004031658172607422, 'residual_add_relu2': 0.00038933753967285156}\n",
      "{'conv1': 0.0013179779052734375, 'bn1': 0.00031876564025878906, 'relu1': 0.0001735687255859375, 'conv2': 0.0013148784637451172, 'bn2': 0.0003116130828857422, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007939338684082031, 'bn1': 0.0002028942108154297, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011670589447021484, 'bn2': 0.0001964569091796875, 'conv3': 0.00035643577575683594, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011682510375976562, 'bn1': 0.0001995563507080078, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011646747589111328, 'bn2': 0.00020837783813476562, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006709098815917969, 'bn1': 0.0001246929168701172, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00011682510375976562, 'conv3': 0.00029540061950683594, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011568069458007812, 'bn1': 0.00012683868408203125, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00011944770812988281, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 352\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016536712646484375, 'bn1': 0.0005548000335693359, 'relu1': 0.00032448768615722656, 'conv2': 0.0016360282897949219, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016388893127441406, 'bn1': 0.0005424022674560547, 'relu1': 0.00032329559326171875, 'conv2': 0.0016407966613769531, 'bn2': 0.0005385875701904297, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001054525375366211, 'bn1': 0.0003161430358886719, 'relu1': 0.00017333030700683594, 'conv2': 0.0013175010681152344, 'bn2': 0.0003116130828857422, 'conv3': 0.0003991127014160156, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013175010681152344, 'bn1': 0.00031375885009765625, 'relu1': 0.0001728534698486328, 'conv2': 0.0013151168823242188, 'bn2': 0.0003116130828857422, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007927417755126953, 'bn1': 0.00020194053649902344, 'relu1': 9.870529174804688e-05, 'conv2': 0.001165151596069336, 'bn2': 0.00019621849060058594, 'conv3': 0.00035190582275390625, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011682510375976562, 'bn1': 0.0001938343048095703, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.00019073486328125, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006611347198486328, 'bn1': 0.00011587142944335938, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00010704994201660156, 'conv3': 0.00028967857360839844, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011529922485351562, 'bn1': 0.0001227855682373047, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011529922485351562, 'bn2': 0.000118255615234375, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 353\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.00165557861328125, 'bn1': 0.0005555152893066406, 'relu1': 0.0003247261047363281, 'conv2': 0.0016369819641113281, 'bn2': 0.0005495548248291016, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016460418701171875, 'bn1': 0.0005486011505126953, 'relu1': 0.0003235340118408203, 'conv2': 0.0016376972198486328, 'bn2': 0.0005400180816650391, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010561943054199219, 'bn1': 0.0003159046173095703, 'relu1': 0.0001735687255859375, 'conv2': 0.0013184547424316406, 'bn2': 0.00030803680419921875, 'conv3': 0.0003986358642578125, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013275146484375, 'bn1': 0.00031447410583496094, 'relu1': 0.0001735687255859375, 'conv2': 0.0013148784637451172, 'bn2': 0.0003058910369873047, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.00080108642578125, 'bn1': 0.0002028942108154297, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011632442474365234, 'bn2': 0.00019478797912597656, 'conv3': 0.00035381317138671875, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.001168966293334961, 'bn1': 0.00020313262939453125, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011637210845947266, 'bn2': 0.0001957416534423828, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006639957427978516, 'bn1': 0.00012040138244628906, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011548995971679688, 'bn2': 0.00011777877807617188, 'conv3': 0.0002963542938232422, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.001157522201538086, 'bn1': 0.00012159347534179688, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00011348724365234375, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 354\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001650094985961914, 'bn1': 0.0005528926849365234, 'relu1': 0.0003256797790527344, 'conv2': 0.0016369819641113281, 'bn2': 0.0005445480346679688, 'residual_add_relu2': 0.0007681846618652344}\n",
      "{'conv1': 0.0016405582427978516, 'bn1': 0.000545501708984375, 'relu1': 0.00032329559326171875, 'conv2': 0.0016317367553710938, 'bn2': 0.0005366802215576172, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010535717010498047, 'bn1': 0.0003178119659423828, 'relu1': 0.00017333030700683594, 'conv2': 0.0013175010681152344, 'bn2': 0.0003075599670410156, 'conv3': 0.00039839744567871094, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.001318216323852539, 'bn1': 0.0003132820129394531, 'relu1': 0.00017333030700683594, 'conv2': 0.0013151168823242188, 'bn2': 0.00030732154846191406, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008585453033447266, 'bn1': 0.000213623046875, 'relu1': 0.0001010894775390625, 'conv2': 0.0011692047119140625, 'bn2': 0.00019359588623046875, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.00022029876708984375}\n",
      "{'conv1': 0.0011742115020751953, 'bn1': 0.00021409988403320312, 'relu1': 0.00010061264038085938, 'conv2': 0.0011680126190185547, 'bn2': 0.00020623207092285156, 'residual_add_relu2': 0.00020647048950195312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006699562072753906, 'bn1': 0.00013446807861328125, 'relu1': 6.29425048828125e-05, 'conv2': 0.0011622905731201172, 'bn2': 0.00013017654418945312, 'conv3': 0.00029969215393066406, 'residual_add_relu2': 0.00011324882507324219}\n",
      "{'conv1': 0.0011639595031738281, 'bn1': 0.00013208389282226562, 'relu1': 6.318092346191406e-05, 'conv2': 0.0011582374572753906, 'bn2': 0.00012636184692382812, 'residual_add_relu2': 0.0001125335693359375}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 355\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016586780548095703, 'bn1': 0.0005559921264648438, 'relu1': 0.00032520294189453125, 'conv2': 0.0016427040100097656, 'bn2': 0.0005614757537841797, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016465187072753906, 'bn1': 0.0005445480346679688, 'relu1': 0.00032401084899902344, 'conv2': 0.0016338825225830078, 'bn2': 0.0005459785461425781, 'residual_add_relu2': 0.0007643699645996094}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010509490966796875, 'bn1': 0.0003142356872558594, 'relu1': 0.00017309188842773438, 'conv2': 0.0013201236724853516, 'bn2': 0.0003135204315185547, 'conv3': 0.00040268898010253906, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013175010681152344, 'bn1': 0.00031566619873046875, 'relu1': 0.00017309188842773438, 'conv2': 0.0013170242309570312, 'bn2': 0.00033211708068847656, 'residual_add_relu2': 0.0003941059112548828}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007994174957275391, 'bn1': 0.00021386146545410156, 'relu1': 0.00010204315185546875, 'conv2': 0.0011723041534423828, 'bn2': 0.00020647048950195312, 'conv3': 0.0003597736358642578, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011720657348632812, 'bn1': 0.000209808349609375, 'relu1': 0.00010061264038085938, 'conv2': 0.0011670589447021484, 'bn2': 0.0002071857452392578, 'residual_add_relu2': 0.00020647048950195312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006687641143798828, 'bn1': 0.00013756752014160156, 'relu1': 6.365776062011719e-05, 'conv2': 0.001165628433227539, 'bn2': 0.0001289844512939453, 'conv3': 0.00029921531677246094, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.0011637210845947266, 'bn1': 0.00012636184692382812, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011513233184814453, 'bn2': 0.00012350082397460938, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 356\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016486644744873047, 'bn1': 0.0005564689636230469, 'relu1': 0.00032401084899902344, 'conv2': 0.0016362667083740234, 'bn2': 0.0005426406860351562, 'residual_add_relu2': 0.0007679462432861328}\n",
      "{'conv1': 0.0016446113586425781, 'bn1': 0.0005447864532470703, 'relu1': 0.0003230571746826172, 'conv2': 0.0016407966613769531, 'bn2': 0.0005393028259277344, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001051187515258789, 'bn1': 0.0003135204315185547, 'relu1': 0.00017261505126953125, 'conv2': 0.0013170242309570312, 'bn2': 0.0003104209899902344, 'conv3': 0.0003991127014160156, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013153553009033203, 'bn1': 0.0003120899200439453, 'relu1': 0.00017452239990234375, 'conv2': 0.0013148784637451172, 'bn2': 0.0003027915954589844, 'residual_add_relu2': 0.00038886070251464844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007891654968261719, 'bn1': 0.00019812583923339844, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011637210845947266, 'bn2': 0.0002033710479736328, 'conv3': 0.00035643577575683594, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011682510375976562, 'bn1': 0.00019979476928710938, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011622905731201172, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006656646728515625, 'bn1': 0.00012373924255371094, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.00011587142944335938, 'conv3': 0.00029659271240234375, 'residual_add_relu2': 0.00011324882507324219}\n",
      "{'conv1': 0.0011622905731201172, 'bn1': 0.00013875961303710938, 'relu1': 6.29425048828125e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.00011587142944335938, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 357\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016565322875976562, 'bn1': 0.0005540847778320312, 'relu1': 0.0003249645233154297, 'conv2': 0.0016453266143798828, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007648468017578125}\n",
      "{'conv1': 0.0016384124755859375, 'bn1': 0.0005393028259277344, 'relu1': 0.0003204345703125, 'conv2': 0.0016405582427978516, 'bn2': 0.0005326271057128906, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010461807250976562, 'bn1': 0.0003178119659423828, 'relu1': 0.0001728534698486328, 'conv2': 0.00131988525390625, 'bn2': 0.00030803680419921875, 'conv3': 0.0003991127014160156, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013208389282226562, 'bn1': 0.0003190040588378906, 'relu1': 0.00017333030700683594, 'conv2': 0.001316070556640625, 'bn2': 0.00030994415283203125, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007903575897216797, 'bn1': 0.00018930435180664062, 'relu1': 9.72747802734375e-05, 'conv2': 0.00115966796875, 'bn2': 0.00018906593322753906, 'conv3': 0.00034999847412109375, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011649131774902344, 'bn1': 0.00019407272338867188, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011589527130126953, 'bn2': 0.0001957416534423828, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006630420684814453, 'bn1': 0.00012111663818359375, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00011467933654785156, 'conv3': 0.00029730796813964844, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.001157522201538086, 'bn1': 0.00012874603271484375, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011551380157470703, 'bn2': 0.00011849403381347656, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 358\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016906261444091797, 'bn1': 0.0006144046783447266, 'relu1': 0.00033783912658691406, 'conv2': 0.001725912094116211, 'bn2': 0.000591278076171875, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016510486602783203, 'bn1': 0.0005533695220947266, 'relu1': 0.0003287792205810547, 'conv2': 0.0016434192657470703, 'bn2': 0.0005452632904052734, 'residual_add_relu2': 0.0007643699645996094}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010540485382080078, 'bn1': 0.0003101825714111328, 'relu1': 0.00017261505126953125, 'conv2': 0.0013146400451660156, 'bn2': 0.0003066062927246094, 'conv3': 0.00039958953857421875, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.001318216323852539, 'bn1': 0.0003142356872558594, 'relu1': 0.0001735687255859375, 'conv2': 0.0013151168823242188, 'bn2': 0.0003123283386230469, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007941722869873047, 'bn1': 0.00020813941955566406, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011644363403320312, 'bn2': 0.00019621849060058594, 'conv3': 0.00035572052001953125, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.0011706352233886719, 'bn1': 0.0002048015594482422, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011632442474365234, 'bn2': 0.00020122528076171875, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006678104400634766, 'bn1': 0.00012755393981933594, 'relu1': 6.103515625e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00011920928955078125, 'conv3': 0.0003001689910888672, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011632442474365234, 'bn1': 0.00012421607971191406, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011508464813232422, 'bn2': 0.00011777877807617188, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 359\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016508102416992188, 'bn1': 0.0005443096160888672, 'relu1': 0.00032329559326171875, 'conv2': 0.001638650894165039, 'bn2': 0.0005409717559814453, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.0016367435455322266, 'bn1': 0.0005381107330322266, 'relu1': 0.00032258033752441406, 'conv2': 0.0016334056854248047, 'bn2': 0.0005314350128173828, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010492801666259766, 'bn1': 0.00031566619873046875, 'relu1': 0.0001728534698486328, 'conv2': 0.0013155937194824219, 'bn2': 0.0003075599670410156, 'conv3': 0.00039887428283691406, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.001325368881225586, 'bn1': 0.0003159046173095703, 'relu1': 0.00017261505126953125, 'conv2': 0.0013129711151123047, 'bn2': 0.0003094673156738281, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007951259613037109, 'bn1': 0.0001983642578125, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011632442474365234, 'bn2': 0.000194549560546875, 'conv3': 0.00035452842712402344, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011663436889648438, 'bn1': 0.00020194053649902344, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011620521545410156, 'bn2': 0.00019478797912597656, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000667572021484375, 'bn1': 0.00012254714965820312, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011548995971679688, 'bn2': 0.00011491775512695312, 'conv3': 0.0002925395965576172, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011553764343261719, 'bn1': 0.00012040138244628906, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.00011610984802246094, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 360\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016529560089111328, 'bn1': 0.000553131103515625, 'relu1': 0.0003228187561035156, 'conv2': 0.001638650894165039, 'bn2': 0.0005428791046142578, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.0016448497772216797, 'bn1': 0.0005471706390380859, 'relu1': 0.00032448768615722656, 'conv2': 0.001646280288696289, 'bn2': 0.0005397796630859375, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010516643524169922, 'bn1': 0.0003139972686767578, 'relu1': 0.00017309188842773438, 'conv2': 0.001316070556640625, 'bn2': 0.0003082752227783203, 'conv3': 0.00039958953857421875, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013179779052734375, 'bn1': 0.00031685829162597656, 'relu1': 0.00017333030700683594, 'conv2': 0.0013134479522705078, 'bn2': 0.00030922889709472656, 'residual_add_relu2': 0.0008411407470703125}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008258819580078125, 'bn1': 0.00022101402282714844, 'relu1': 0.00010395050048828125, 'conv2': 0.0011658668518066406, 'bn2': 0.00019741058349609375, 'conv3': 0.00035452842712402344, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011682510375976562, 'bn1': 0.00020766258239746094, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011641979217529297, 'bn2': 0.00019431114196777344, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006604194641113281, 'bn1': 0.00011968612670898438, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011529922485351562, 'bn2': 0.00011587142944335938, 'conv3': 0.0002930164337158203, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.001154184341430664, 'bn1': 0.00011134147644042969, 'relu1': 5.6743621826171875e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.00011110305786132812, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 361\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016605854034423828, 'bn1': 0.0005562305450439453, 'relu1': 0.000324249267578125, 'conv2': 0.0016453266143798828, 'bn2': 0.0005404949188232422, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016489028930664062, 'bn1': 0.0005452632904052734, 'relu1': 0.0003230571746826172, 'conv2': 0.0016334056854248047, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001049041748046875, 'bn1': 0.00030732154846191406, 'relu1': 0.00017142295837402344, 'conv2': 0.0013129711151123047, 'bn2': 0.0003027915954589844, 'conv3': 0.0003981590270996094, 'residual_add_relu2': 0.00038886070251464844}\n",
      "{'conv1': 0.0013141632080078125, 'bn1': 0.00031113624572753906, 'relu1': 0.00017380714416503906, 'conv2': 0.0013146400451660156, 'bn2': 0.0003097057342529297, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007917881011962891, 'bn1': 0.00019979476928710938, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011935234069824219, 'bn2': 0.00020599365234375, 'conv3': 0.0003559589385986328, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.0011684894561767578, 'bn1': 0.0002014636993408203, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011625289916992188, 'bn2': 0.00019359588623046875, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006732940673828125, 'bn1': 0.0001220703125, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.00011515617370605469, 'conv3': 0.0002923011779785156, 'residual_add_relu2': 0.00011301040649414062}\n",
      "{'conv1': 0.0011577606201171875, 'bn1': 0.00012063980102539062, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00011706352233886719, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 362\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016837120056152344, 'bn1': 0.0005741119384765625, 'relu1': 0.00032711029052734375, 'conv2': 0.0016515254974365234, 'bn2': 0.0005626678466796875, 'residual_add_relu2': 0.0007693767547607422}\n",
      "{'conv1': 0.001645803451538086, 'bn1': 0.0005440711975097656, 'relu1': 0.00032210350036621094, 'conv2': 0.0016367435455322266, 'bn2': 0.0005393028259277344, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010497570037841797, 'bn1': 0.0003142356872558594, 'relu1': 0.0001728534698486328, 'conv2': 0.001317739486694336, 'bn2': 0.000308990478515625, 'conv3': 0.0003998279571533203, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013172626495361328, 'bn1': 0.0003120899200439453, 'relu1': 0.0001735687255859375, 'conv2': 0.0013136863708496094, 'bn2': 0.0003108978271484375, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007920265197753906, 'bn1': 0.00019931793212890625, 'relu1': 0.0001010894775390625, 'conv2': 0.0011675357818603516, 'bn2': 0.00020766258239746094, 'conv3': 0.0003554821014404297, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011684894561767578, 'bn1': 0.000202178955078125, 'relu1': 9.775161743164062e-05, 'conv2': 0.001161813735961914, 'bn2': 0.0001952648162841797, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006673336029052734, 'bn1': 0.00012350082397460938, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.00011515617370605469, 'conv3': 0.0002949237823486328, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011563301086425781, 'bn1': 0.00012040138244628906, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.00011754035949707031, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 363\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016608238220214844, 'bn1': 0.0005552768707275391, 'relu1': 0.0003228187561035156, 'conv2': 0.00164031982421875, 'bn2': 0.0005428791046142578, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016443729400634766, 'bn1': 0.0005512237548828125, 'relu1': 0.000324249267578125, 'conv2': 0.001634359359741211, 'bn2': 0.0005319118499755859, 'residual_add_relu2': 0.0007669925689697266}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010466575622558594, 'bn1': 0.0003116130828857422, 'relu1': 0.00017309188842773438, 'conv2': 0.0013163089752197266, 'bn2': 0.0002999305725097656, 'conv3': 0.0003955364227294922, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013132095336914062, 'bn1': 0.0003135204315185547, 'relu1': 0.0001723766326904297, 'conv2': 0.0013124942779541016, 'bn2': 0.0003085136413574219, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008904933929443359, 'bn1': 0.00029850006103515625, 'relu1': 0.00011086463928222656, 'conv2': 0.0011868476867675781, 'bn2': 0.0002033710479736328, 'conv3': 0.0003616809844970703, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.0011699199676513672, 'bn1': 0.00020551681518554688, 'relu1': 9.918212890625e-05, 'conv2': 0.0011649131774902344, 'bn2': 0.0002002716064453125, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006690025329589844, 'bn1': 0.0001285076141357422, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.00011897087097167969, 'conv3': 0.0002968311309814453, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011589527130126953, 'bn1': 0.00012373924255371094, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00011682510375976562, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 364\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016551017761230469, 'bn1': 0.0005571842193603516, 'relu1': 0.0003266334533691406, 'conv2': 0.0016446113586425781, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016503334045410156, 'bn1': 0.0005562305450439453, 'relu1': 0.0003254413604736328, 'conv2': 0.0016398429870605469, 'bn2': 0.0005388259887695312, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010554790496826172, 'bn1': 0.0003170967102050781, 'relu1': 0.0001723766326904297, 'conv2': 0.0013172626495361328, 'bn2': 0.00031948089599609375, 'conv3': 0.000408172607421875, 'residual_add_relu2': 0.00039267539978027344}\n",
      "{'conv1': 0.0013210773468017578, 'bn1': 0.00031828880310058594, 'relu1': 0.00017595291137695312, 'conv2': 0.0013158321380615234, 'bn2': 0.0003228187561035156, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007987022399902344, 'bn1': 0.0002009868621826172, 'relu1': 9.894371032714844e-05, 'conv2': 0.001169443130493164, 'bn2': 0.0001957416534423828, 'conv3': 0.0003554821014404297, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.00116729736328125, 'bn1': 0.00019884109497070312, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011680126190185547, 'bn2': 0.0001957416534423828, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006647109985351562, 'bn1': 0.00012421607971191406, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011548995971679688, 'bn2': 0.00011467933654785156, 'conv3': 0.00028967857360839844, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.0011570453643798828, 'bn1': 0.00012111663818359375, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.00012755393981933594, 'residual_add_relu2': 0.00011301040649414062}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 365\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016872882843017578, 'bn1': 0.0005888938903808594, 'relu1': 0.00033593177795410156, 'conv2': 0.001661062240600586, 'bn2': 0.0005960464477539062, 'residual_add_relu2': 0.0007760524749755859}\n",
      "{'conv1': 0.0016584396362304688, 'bn1': 0.0005764961242675781, 'relu1': 0.0003333091735839844, 'conv2': 0.00165557861328125, 'bn2': 0.0005595684051513672, 'residual_add_relu2': 0.0007672309875488281}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010714530944824219, 'bn1': 0.0003383159637451172, 'relu1': 0.000179290771484375, 'conv2': 0.0013353824615478516, 'bn2': 0.00033092498779296875, 'conv3': 0.0004177093505859375, 'residual_add_relu2': 0.00039315223693847656}\n",
      "{'conv1': 0.0013275146484375, 'bn1': 0.00032639503479003906, 'relu1': 0.00018095970153808594, 'conv2': 0.0013232231140136719, 'bn2': 0.0003180503845214844, 'residual_add_relu2': 0.0003936290740966797}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008063316345214844, 'bn1': 0.00021028518676757812, 'relu1': 0.00010418891906738281, 'conv2': 0.0011687278747558594, 'bn2': 0.00020432472229003906, 'conv3': 0.0003635883331298828, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011682510375976562, 'bn1': 0.00021004676818847656, 'relu1': 0.00010156631469726562, 'conv2': 0.0011637210845947266, 'bn2': 0.00020241737365722656, 'residual_add_relu2': 0.00020599365234375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006685256958007812, 'bn1': 0.00014066696166992188, 'relu1': 6.556510925292969e-05, 'conv2': 0.00115966796875, 'bn2': 0.0001354217529296875, 'conv3': 0.0003027915954589844, 'residual_add_relu2': 0.00011467933654785156}\n",
      "{'conv1': 0.0011637210845947266, 'bn1': 0.00014257431030273438, 'relu1': 6.365776062011719e-05, 'conv2': 0.001157999038696289, 'bn2': 0.00014853477478027344, 'residual_add_relu2': 0.00011324882507324219}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 366\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016503334045410156, 'bn1': 0.0005536079406738281, 'relu1': 0.00032448768615722656, 'conv2': 0.001638174057006836, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016396045684814453, 'bn1': 0.0005543231964111328, 'relu1': 0.0003249645233154297, 'conv2': 0.0016369819641113281, 'bn2': 0.0005366802215576172, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001054525375366211, 'bn1': 0.00032258033752441406, 'relu1': 0.00017499923706054688, 'conv2': 0.00131988525390625, 'bn2': 0.0003192424774169922, 'conv3': 0.0004048347473144531, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013210773468017578, 'bn1': 0.0003116130828857422, 'relu1': 0.00017523765563964844, 'conv2': 0.0013151168823242188, 'bn2': 0.00031280517578125, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007917881011962891, 'bn1': 0.0001990795135498047, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011653900146484375, 'bn2': 0.0002028942108154297, 'conv3': 0.0003578662872314453, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.0011713504791259766, 'bn1': 0.00020933151245117188, 'relu1': 0.00010061264038085938, 'conv2': 0.0011661052703857422, 'bn2': 0.00020432472229003906, 'residual_add_relu2': 0.00020599365234375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006847381591796875, 'bn1': 0.00014734268188476562, 'relu1': 6.29425048828125e-05, 'conv2': 0.0011615753173828125, 'bn2': 0.00012540817260742188, 'conv3': 0.0002999305725097656, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.0011615753173828125, 'bn1': 0.00013017654418945312, 'relu1': 6.151199340820312e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.0001373291015625, 'residual_add_relu2': 0.00011372566223144531}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 367\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016672611236572266, 'bn1': 0.0005693435668945312, 'relu1': 0.0003273487091064453, 'conv2': 0.0016503334045410156, 'bn2': 0.0005526542663574219, 'residual_add_relu2': 0.0007681846618652344}\n",
      "{'conv1': 0.00165557861328125, 'bn1': 0.0005557537078857422, 'relu1': 0.0003256797790527344, 'conv2': 0.0016450881958007812, 'bn2': 0.0005521774291992188, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010542869567871094, 'bn1': 0.0003151893615722656, 'relu1': 0.00017213821411132812, 'conv2': 0.0013284683227539062, 'bn2': 0.0003190040588378906, 'conv3': 0.0004048347473144531, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013170242309570312, 'bn1': 0.0003147125244140625, 'relu1': 0.0001728534698486328, 'conv2': 0.0013158321380615234, 'bn2': 0.0003161430358886719, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007891654968261719, 'bn1': 0.00019788742065429688, 'relu1': 9.703636169433594e-05, 'conv2': 0.001161813735961914, 'bn2': 0.0001971721649169922, 'conv3': 0.0003535747528076172, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011637210845947266, 'bn1': 0.00019407272338867188, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011589527130126953, 'bn2': 0.0001995563507080078, 'residual_add_relu2': 0.00020575523376464844}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006654262542724609, 'bn1': 0.00011968612670898438, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011551380157470703, 'bn2': 0.00011181831359863281, 'conv3': 0.00029587745666503906, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011565685272216797, 'bn1': 0.00012111663818359375, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00011610984802246094, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 368\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016667842864990234, 'bn1': 0.0005533695220947266, 'relu1': 0.00032401084899902344, 'conv2': 0.0016448497772216797, 'bn2': 0.0005366802215576172, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016450881958007812, 'bn1': 0.0005469322204589844, 'relu1': 0.0003228187561035156, 'conv2': 0.0016422271728515625, 'bn2': 0.0005311965942382812, 'residual_add_relu2': 0.0007603168487548828}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001051187515258789, 'bn1': 0.00037789344787597656, 'relu1': 0.00017499923706054688, 'conv2': 0.0013191699981689453, 'bn2': 0.0003113746643066406, 'conv3': 0.00039768218994140625, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013165473937988281, 'bn1': 0.00031447410583496094, 'relu1': 0.00017333030700683594, 'conv2': 0.0013136863708496094, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007905960083007812, 'bn1': 0.0002009868621826172, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011644363403320312, 'bn2': 0.00019788742065429688, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.001165628433227539, 'bn1': 0.0002009868621826172, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011622905731201172, 'bn2': 0.0001976490020751953, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006651878356933594, 'bn1': 0.00012540817260742188, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.00011539459228515625, 'conv3': 0.00029349327087402344, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011556148529052734, 'bn1': 0.0001227855682373047, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011529922485351562, 'bn2': 0.00011682510375976562, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 369\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001653909683227539, 'bn1': 0.0005543231964111328, 'relu1': 0.00032401084899902344, 'conv2': 0.0016341209411621094, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016453266143798828, 'bn1': 0.0005438327789306641, 'relu1': 0.00032591819763183594, 'conv2': 0.0016379356384277344, 'bn2': 0.0005397796630859375, 'residual_add_relu2': 0.0007615089416503906}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010533332824707031, 'bn1': 0.0003218650817871094, 'relu1': 0.00017333030700683594, 'conv2': 0.0013179779052734375, 'bn2': 0.0003082752227783203, 'conv3': 0.00040030479431152344, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013191699981689453, 'bn1': 0.0003154277801513672, 'relu1': 0.00017333030700683594, 'conv2': 0.0013146400451660156, 'bn2': 0.00030875205993652344, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007920265197753906, 'bn1': 0.00020122528076171875, 'relu1': 0.00010251998901367188, 'conv2': 0.0011677742004394531, 'bn2': 0.0001990795135498047, 'conv3': 0.0003554821014404297, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011649131774902344, 'bn1': 0.00019979476928710938, 'relu1': 0.00010013580322265625, 'conv2': 0.001163482666015625, 'bn2': 0.00019693374633789062, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006632804870605469, 'bn1': 0.00012540817260742188, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011563301086425781, 'bn2': 0.0001246929168701172, 'conv3': 0.0003006458282470703, 'residual_add_relu2': 0.00011348724365234375}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.0001304149627685547, 'relu1': 6.222724914550781e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00011396408081054688, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 370\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016605854034423828, 'bn1': 0.0005536079406738281, 'relu1': 0.0003230571746826172, 'conv2': 0.0016362667083740234, 'bn2': 0.0005409717559814453, 'residual_add_relu2': 0.0007688999176025391}\n",
      "{'conv1': 0.0016376972198486328, 'bn1': 0.0005433559417724609, 'relu1': 0.00032401084899902344, 'conv2': 0.0016307830810546875, 'bn2': 0.0005474090576171875, 'residual_add_relu2': 0.0007615089416503906}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010516643524169922, 'bn1': 0.000316619873046875, 'relu1': 0.00017333030700683594, 'conv2': 0.001317739486694336, 'bn2': 0.0003185272216796875, 'conv3': 0.0004048347473144531, 'residual_add_relu2': 0.0003921985626220703}\n",
      "{'conv1': 0.0013241767883300781, 'bn1': 0.0003273487091064453, 'relu1': 0.00017833709716796875, 'conv2': 0.001321554183959961, 'bn2': 0.0003204345703125, 'residual_add_relu2': 0.0003933906555175781}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007994174957275391, 'bn1': 0.00021409988403320312, 'relu1': 0.00010204315185546875, 'conv2': 0.0011696815490722656, 'bn2': 0.00020575523376464844, 'conv3': 0.00035881996154785156, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011706352233886719, 'bn1': 0.00021219253540039062, 'relu1': 9.989738464355469e-05, 'conv2': 0.0011668205261230469, 'bn2': 0.00021266937255859375, 'residual_add_relu2': 0.00020694732666015625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006701946258544922, 'bn1': 0.00013256072998046875, 'relu1': 6.246566772460938e-05, 'conv2': 0.0011587142944335938, 'bn2': 0.00012373924255371094, 'conv3': 0.0002999305725097656, 'residual_add_relu2': 0.00011301040649414062}\n",
      "{'conv1': 0.0011608600616455078, 'bn1': 0.00012087821960449219, 'relu1': 5.9604644775390625e-05, 'conv2': 0.00115203857421875, 'bn2': 0.0001163482666015625, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 371\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016665458679199219, 'bn1': 0.0005583763122558594, 'relu1': 0.00032448768615722656, 'conv2': 0.0016405582427978516, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.0016412734985351562, 'bn1': 0.0005445480346679688, 'relu1': 0.00032329559326171875, 'conv2': 0.001634836196899414, 'bn2': 0.0005385875701904297, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010523796081542969, 'bn1': 0.0003139972686767578, 'relu1': 0.0001735687255859375, 'conv2': 0.0013163089752197266, 'bn2': 0.0003135204315185547, 'conv3': 0.0004000663757324219, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013217926025390625, 'bn1': 0.0003147125244140625, 'relu1': 0.0001735687255859375, 'conv2': 0.0013148784637451172, 'bn2': 0.0003123283386230469, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007994174957275391, 'bn1': 0.00020122528076171875, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011637210845947266, 'bn2': 0.0001957416534423828, 'conv3': 0.00035452842712402344, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.001165151596069336, 'bn1': 0.00019979476928710938, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011630058288574219, 'bn2': 0.00019550323486328125, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006642341613769531, 'bn1': 0.0001232624053955078, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011599063873291016, 'bn2': 0.00011610984802246094, 'conv3': 0.0002949237823486328, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00012159347534179688, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.00011777877807617188, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 372\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016663074493408203, 'bn1': 0.0005557537078857422, 'relu1': 0.0003249645233154297, 'conv2': 0.0016446113586425781, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016505718231201172, 'bn1': 0.0005464553833007812, 'relu1': 0.0003216266632080078, 'conv2': 0.001642465591430664, 'bn2': 0.0005409717559814453, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010528564453125, 'bn1': 0.00031566619873046875, 'relu1': 0.00017189979553222656, 'conv2': 0.0013172626495361328, 'bn2': 0.00030875205993652344, 'conv3': 0.0003998279571533203, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013201236724853516, 'bn1': 0.000316619873046875, 'relu1': 0.0001881122589111328, 'conv2': 0.0013225078582763672, 'bn2': 0.00031566619873046875, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007958412170410156, 'bn1': 0.00019979476928710938, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011644363403320312, 'bn2': 0.0002052783966064453, 'conv3': 0.0003559589385986328, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011696815490722656, 'bn1': 0.0002014636993408203, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011622905731201172, 'bn2': 0.00019669532775878906, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006647109985351562, 'bn1': 0.00012302398681640625, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.0001163482666015625, 'conv3': 0.00029349327087402344, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011570453643798828, 'bn1': 0.00012445449829101562, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00011587142944335938, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 373\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016624927520751953, 'bn1': 0.0005636215209960938, 'relu1': 0.00032806396484375, 'conv2': 0.0016515254974365234, 'bn2': 0.0005564689636230469, 'residual_add_relu2': 0.0007684230804443359}\n",
      "{'conv1': 0.0016498565673828125, 'bn1': 0.0005590915679931641, 'relu1': 0.0003268718719482422, 'conv2': 0.0016417503356933594, 'bn2': 0.00054931640625, 'residual_add_relu2': 0.0007679462432861328}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010585784912109375, 'bn1': 0.0003254413604736328, 'relu1': 0.00017595291137695312, 'conv2': 0.001321554183959961, 'bn2': 0.0003185272216796875, 'conv3': 0.00040650367736816406, 'residual_add_relu2': 0.00039315223693847656}\n",
      "{'conv1': 0.0013301372528076172, 'bn1': 0.000324249267578125, 'relu1': 0.00017714500427246094, 'conv2': 0.0013196468353271484, 'bn2': 0.0003204345703125, 'residual_add_relu2': 0.000392913818359375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007989406585693359, 'bn1': 0.0002110004425048828, 'relu1': 0.00010085105895996094, 'conv2': 0.0011696815490722656, 'bn2': 0.00021767616271972656, 'conv3': 0.0003573894500732422, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011713504791259766, 'bn1': 0.00021958351135253906, 'relu1': 0.00010251998901367188, 'conv2': 0.001168966293334961, 'bn2': 0.00020503997802734375, 'residual_add_relu2': 0.00020647048950195312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.00066375732421875, 'bn1': 0.00013208389282226562, 'relu1': 6.198883056640625e-05, 'conv2': 0.00115966796875, 'bn2': 0.00012564659118652344, 'conv3': 0.00030040740966796875, 'residual_add_relu2': 0.00011372566223144531}\n",
      "{'conv1': 0.0011620521545410156, 'bn1': 0.00012564659118652344, 'relu1': 6.008148193359375e-05, 'conv2': 0.001154184341430664, 'bn2': 0.00011610984802246094, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 374\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016694068908691406, 'bn1': 0.0005621910095214844, 'relu1': 0.0003254413604736328, 'conv2': 0.00164031982421875, 'bn2': 0.0005433559417724609, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.00164031982421875, 'bn1': 0.0005490779876708984, 'relu1': 0.0003237724304199219, 'conv2': 0.0016362667083740234, 'bn2': 0.0005383491516113281, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010561943054199219, 'bn1': 0.00031828880310058594, 'relu1': 0.00017333030700683594, 'conv2': 0.0013158321380615234, 'bn2': 0.0003116130828857422, 'conv3': 0.00040435791015625, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.001318216323852539, 'bn1': 0.0003185272216796875, 'relu1': 0.00017547607421875, 'conv2': 0.001317739486694336, 'bn2': 0.0003209114074707031, 'residual_add_relu2': 0.00039196014404296875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007963180541992188, 'bn1': 0.0002033710479736328, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011661052703857422, 'bn2': 0.00018525123596191406, 'conv3': 0.0003504753112792969, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.001163482666015625, 'bn1': 0.0001952648162841797, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011577606201171875, 'bn2': 0.000194549560546875, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006673336029052734, 'bn1': 0.00012683868408203125, 'relu1': 6.151199340820312e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.00011587142944335938, 'conv3': 0.00029015541076660156, 'residual_add_relu2': 0.00011229515075683594}\n",
      "{'conv1': 0.0011584758758544922, 'bn1': 0.00012302398681640625, 'relu1': 6.008148193359375e-05, 'conv2': 0.001153707504272461, 'bn2': 0.00012135505676269531, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 375\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001659393310546875, 'bn1': 0.0005526542663574219, 'relu1': 0.0003235340118408203, 'conv2': 0.0016436576843261719, 'bn2': 0.0005419254302978516, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016520023345947266, 'bn1': 0.0005476474761962891, 'relu1': 0.00032329559326171875, 'conv2': 0.0016400814056396484, 'bn2': 0.0005395412445068359, 'residual_add_relu2': 0.0007655620574951172}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010542869567871094, 'bn1': 0.0003151893615722656, 'relu1': 0.0001742839813232422, 'conv2': 0.0013267993927001953, 'bn2': 0.0003082752227783203, 'conv3': 0.0003993511199951172, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.001322031021118164, 'bn1': 0.00032782554626464844, 'relu1': 0.00017499923706054688, 'conv2': 0.0013163089752197266, 'bn2': 0.000308990478515625, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007922649383544922, 'bn1': 0.0001990795135498047, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011641979217529297, 'bn2': 0.00020241737365722656, 'conv3': 0.0003559589385986328, 'residual_add_relu2': 0.0002071857452392578}\n",
      "{'conv1': 0.0011658668518066406, 'bn1': 0.0002009868621826172, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011615753173828125, 'bn2': 0.00019812583923339844, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006694793701171875, 'bn1': 0.00012159347534179688, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011539459228515625, 'bn2': 0.00011539459228515625, 'conv3': 0.0002951622009277344, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.001157522201538086, 'bn1': 0.00012350082397460938, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.00011610984802246094, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 376\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.00165557861328125, 'bn1': 0.0005521774291992188, 'relu1': 0.0003237724304199219, 'conv2': 0.001641988754272461, 'bn2': 0.0005400180816650391, 'residual_add_relu2': 0.0007631778717041016}\n",
      "{'conv1': 0.001644134521484375, 'bn1': 0.0005383491516113281, 'relu1': 0.00032329559326171875, 'conv2': 0.001644134521484375, 'bn2': 0.0005309581756591797, 'residual_add_relu2': 0.0007615089416503906}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0012927055358886719, 'bn1': 0.0004298686981201172, 'relu1': 0.00018739700317382812, 'conv2': 0.001336812973022461, 'bn2': 0.0003209114074707031, 'conv3': 0.0004107952117919922, 'residual_add_relu2': 0.0003936290740966797}\n",
      "{'conv1': 0.0013282299041748047, 'bn1': 0.0003311634063720703, 'relu1': 0.0001823902130126953, 'conv2': 0.0013208389282226562, 'bn2': 0.00031685829162597656, 'residual_add_relu2': 0.000392913818359375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007944107055664062, 'bn1': 0.00021648406982421875, 'relu1': 0.00010418891906738281, 'conv2': 0.0011680126190185547, 'bn2': 0.000202178955078125, 'conv3': 0.0003616809844970703, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011658668518066406, 'bn1': 0.0001976490020751953, 'relu1': 0.00010251998901367188, 'conv2': 0.0011601448059082031, 'bn2': 0.00019812583923339844, 'residual_add_relu2': 0.00020599365234375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.00066375732421875, 'bn1': 0.00012373924255371094, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011551380157470703, 'bn2': 0.00012445449829101562, 'conv3': 0.0002970695495605469, 'residual_add_relu2': 0.00011348724365234375}\n",
      "{'conv1': 0.0011601448059082031, 'bn1': 0.0001304149627685547, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011529922485351562, 'bn2': 0.00013017654418945312, 'residual_add_relu2': 0.00011205673217773438}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 377\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016584396362304688, 'bn1': 0.0005567073822021484, 'relu1': 0.00032258033752441406, 'conv2': 0.0016489028930664062, 'bn2': 0.0005424022674560547, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016410350799560547, 'bn1': 0.000553131103515625, 'relu1': 0.0003228187561035156, 'conv2': 0.0016326904296875, 'bn2': 0.0005428791046142578, 'residual_add_relu2': 0.0007655620574951172}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010509490966796875, 'bn1': 0.00031566619873046875, 'relu1': 0.00017261505126953125, 'conv2': 0.001313924789428711, 'bn2': 0.0003066062927246094, 'conv3': 0.0004017353057861328, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.001317739486694336, 'bn1': 0.00031685829162597656, 'relu1': 0.0001728534698486328, 'conv2': 0.0013129711151123047, 'bn2': 0.00037097930908203125, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007958412170410156, 'bn1': 0.00020265579223632812, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011644363403320312, 'bn2': 0.00019693374633789062, 'conv3': 0.0003535747528076172, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.001168966293334961, 'bn1': 0.000202178955078125, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006649494171142578, 'bn1': 0.00012350082397460938, 'relu1': 6.008148193359375e-05, 'conv2': 0.001155853271484375, 'bn2': 0.00011801719665527344, 'conv3': 0.0002944469451904297, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00012087821960449219, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011534690856933594, 'bn2': 0.00011849403381347656, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 378\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001653432846069336, 'bn1': 0.0005521774291992188, 'relu1': 0.0003237724304199219, 'conv2': 0.0016341209411621094, 'bn2': 0.0005421638488769531, 'residual_add_relu2': 0.0007646083831787109}\n",
      "{'conv1': 0.0016450881958007812, 'bn1': 0.0005469322204589844, 'relu1': 0.0003211498260498047, 'conv2': 0.001638174057006836, 'bn2': 0.0005385875701904297, 'residual_add_relu2': 0.0007665157318115234}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010523796081542969, 'bn1': 0.00031447410583496094, 'relu1': 0.0001735687255859375, 'conv2': 0.0013163089752197266, 'bn2': 0.00030994415283203125, 'conv3': 0.0003993511199951172, 'residual_add_relu2': 0.00039196014404296875}\n",
      "{'conv1': 0.0013184547424316406, 'bn1': 0.0003132820129394531, 'relu1': 0.00017309188842773438, 'conv2': 0.0013134479522705078, 'bn2': 0.000308990478515625, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000789642333984375, 'bn1': 0.00019311904907226562, 'relu1': 9.560585021972656e-05, 'conv2': 0.0011603832244873047, 'bn2': 0.000186920166015625, 'conv3': 0.0003504753112792969, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.0011630058288574219, 'bn1': 0.000194549560546875, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011577606201171875, 'bn2': 0.0001888275146484375, 'residual_add_relu2': 0.00020265579223632812}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006604194641113281, 'bn1': 0.00011515617370605469, 'relu1': 5.8650970458984375e-05, 'conv2': 0.001157999038696289, 'bn2': 0.0001678466796875, 'conv3': 0.0003132820129394531, 'residual_add_relu2': 0.00011420249938964844}\n",
      "{'conv1': 0.0011644363403320312, 'bn1': 0.00012731552124023438, 'relu1': 5.91278076171875e-05, 'conv2': 0.001155853271484375, 'bn2': 0.00014066696166992188, 'residual_add_relu2': 0.00011181831359863281}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 379\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016603469848632812, 'bn1': 0.0005474090576171875, 'relu1': 0.00032639503479003906, 'conv2': 0.0016465187072753906, 'bn2': 0.0005438327789306641, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016531944274902344, 'bn1': 0.0005445480346679688, 'relu1': 0.0003261566162109375, 'conv2': 0.0016438961029052734, 'bn2': 0.0005428791046142578, 'residual_add_relu2': 0.0007615089416503906}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010616779327392578, 'bn1': 0.00031256675720214844, 'relu1': 0.00017213821411132812, 'conv2': 0.0013241767883300781, 'bn2': 0.00030303001403808594, 'conv3': 0.00039696693420410156, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013124942779541016, 'bn1': 0.0003058910369873047, 'relu1': 0.00017118453979492188, 'conv2': 0.0013103485107421875, 'bn2': 0.0003075599670410156, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007951259613037109, 'bn1': 0.0001983642578125, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011675357818603516, 'bn2': 0.00019621849060058594, 'conv3': 0.0003566741943359375, 'residual_add_relu2': 0.00021457672119140625}\n",
      "{'conv1': 0.0011675357818603516, 'bn1': 0.00020003318786621094, 'relu1': 9.72747802734375e-05, 'conv2': 0.001161336898803711, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006692409515380859, 'bn1': 0.00012421607971191406, 'relu1': 5.91278076171875e-05, 'conv2': 0.00115203857421875, 'bn2': 0.00010800361633300781, 'conv3': 0.0002930164337158203, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011515617370605469, 'bn1': 0.00011396408081054688, 'relu1': 5.6743621826171875e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.0001251697540283203, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 380\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016531944274902344, 'bn1': 0.0005486011505126953, 'relu1': 0.0003218650817871094, 'conv2': 0.0016477108001708984, 'bn2': 0.0005419254302978516, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.00164794921875, 'bn1': 0.0005507469177246094, 'relu1': 0.0003211498260498047, 'conv2': 0.0016412734985351562, 'bn2': 0.0005371570587158203, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010488033294677734, 'bn1': 0.00030803680419921875, 'relu1': 0.00017070770263671875, 'conv2': 0.001313924789428711, 'bn2': 0.00031256675720214844, 'conv3': 0.0003974437713623047, 'residual_add_relu2': 0.0003886222839355469}\n",
      "{'conv1': 0.0013127326965332031, 'bn1': 0.0003063678741455078, 'relu1': 0.000171661376953125, 'conv2': 0.0013108253479003906, 'bn2': 0.00030612945556640625, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007927417755126953, 'bn1': 0.00019598007202148438, 'relu1': 9.655952453613281e-05, 'conv2': 0.001161336898803711, 'bn2': 0.00018930435180664062, 'conv3': 0.0003604888916015625, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011625289916992188, 'bn1': 0.00019311904907226562, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.00018525123596191406, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006592273712158203, 'bn1': 0.00011801719665527344, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.00010967254638671875, 'conv3': 0.0002884864807128906, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011527538299560547, 'bn1': 0.00011301040649414062, 'relu1': 5.698204040527344e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.00012159347534179688, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 381\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016694068908691406, 'bn1': 0.0005550384521484375, 'relu1': 0.00032520294189453125, 'conv2': 0.001646280288696289, 'bn2': 0.0005462169647216797, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.0016405582427978516, 'bn1': 0.0005424022674560547, 'relu1': 0.0003285408020019531, 'conv2': 0.0016326904296875, 'bn2': 0.0005445480346679688, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010535717010498047, 'bn1': 0.00033283233642578125, 'relu1': 0.00017333030700683594, 'conv2': 0.0013191699981689453, 'bn2': 0.00031256675720214844, 'conv3': 0.0004017353057861328, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013203620910644531, 'bn1': 0.0003223419189453125, 'relu1': 0.00017380714416503906, 'conv2': 0.0013165473937988281, 'bn2': 0.0003104209899902344, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008001327514648438, 'bn1': 0.00020265579223632812, 'relu1': 0.00010633468627929688, 'conv2': 0.0011751651763916016, 'bn2': 0.00020623207092285156, 'conv3': 0.0003552436828613281, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0011646747589111328, 'bn1': 0.0001990795135498047, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011646747589111328, 'bn2': 0.00020074844360351562, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006787776947021484, 'bn1': 0.00012731552124023438, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.00011563301086425781, 'conv3': 0.0002899169921875, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011565685272216797, 'bn1': 0.00012493133544921875, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.00011539459228515625, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 382\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016896724700927734, 'bn1': 0.0005981922149658203, 'relu1': 0.0003361701965332031, 'conv2': 0.0016624927520751953, 'bn2': 0.0005745887756347656, 'residual_add_relu2': 0.0007789134979248047}\n",
      "{'conv1': 0.001659393310546875, 'bn1': 0.0005733966827392578, 'relu1': 0.0003333091735839844, 'conv2': 0.0016567707061767578, 'bn2': 0.000576019287109375, 'residual_add_relu2': 0.00077056884765625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0012836456298828125, 'bn1': 0.0005896091461181641, 'relu1': 0.00023865699768066406, 'conv2': 0.0014100074768066406, 'bn2': 0.0003521442413330078, 'conv3': 0.0004184246063232422, 'residual_add_relu2': 0.00039768218994140625}\n",
      "{'conv1': 0.0013298988342285156, 'bn1': 0.00035858154296875, 'relu1': 0.00018143653869628906, 'conv2': 0.0013287067413330078, 'bn2': 0.0003497600555419922, 'residual_add_relu2': 0.0003962516784667969}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008080005645751953, 'bn1': 0.0002357959747314453, 'relu1': 0.00010561943054199219, 'conv2': 0.0011761188507080078, 'bn2': 0.0002148151397705078, 'conv3': 0.0003650188446044922, 'residual_add_relu2': 0.00021505355834960938}\n",
      "{'conv1': 0.0011816024780273438, 'bn1': 0.00021910667419433594, 'relu1': 0.00010180473327636719, 'conv2': 0.0011718273162841797, 'bn2': 0.00023698806762695312, 'residual_add_relu2': 0.00020933151245117188}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006773471832275391, 'bn1': 0.00018024444580078125, 'relu1': 6.937980651855469e-05, 'conv2': 0.0011680126190185547, 'bn2': 0.000133514404296875, 'conv3': 0.0003006458282470703, 'residual_add_relu2': 0.00011467933654785156}\n",
      "{'conv1': 0.0011692047119140625, 'bn1': 0.00015878677368164062, 'relu1': 6.4849853515625e-05, 'conv2': 0.0011665821075439453, 'bn2': 0.00015616416931152344, 'residual_add_relu2': 0.00011515617370605469}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 383\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001711130142211914, 'bn1': 0.0005879402160644531, 'relu1': 0.0003292560577392578, 'conv2': 0.0016565322875976562, 'bn2': 0.0005810260772705078, 'residual_add_relu2': 0.0007719993591308594}\n",
      "{'conv1': 0.0016582012176513672, 'bn1': 0.0005803108215332031, 'relu1': 0.0003311634063720703, 'conv2': 0.0016646385192871094, 'bn2': 0.0005664825439453125, 'residual_add_relu2': 0.0007753372192382812}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010678768157958984, 'bn1': 0.0003802776336669922, 'relu1': 0.00018143653869628906, 'conv2': 0.0013282299041748047, 'bn2': 0.0003292560577392578, 'conv3': 0.0004363059997558594, 'residual_add_relu2': 0.00039458274841308594}\n",
      "{'conv1': 0.0013282299041748047, 'bn1': 0.00033974647521972656, 'relu1': 0.00017642974853515625, 'conv2': 0.0013196468353271484, 'bn2': 0.0003113746643066406, 'residual_add_relu2': 0.0003993511199951172}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007998943328857422, 'bn1': 0.0002079010009765625, 'relu1': 9.918212890625e-05, 'conv2': 0.0011684894561767578, 'bn2': 0.0002269744873046875, 'conv3': 0.0003654956817626953, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011734962463378906, 'bn1': 0.00022983551025390625, 'relu1': 0.00010251998901367188, 'conv2': 0.0011715888977050781, 'bn2': 0.0002129077911376953, 'residual_add_relu2': 0.00021028518676757812}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006694793701171875, 'bn1': 0.0001270771026611328, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011589527130126953, 'bn2': 0.0001392364501953125, 'conv3': 0.0009140968322753906, 'residual_add_relu2': 0.00012755393981933594}\n",
      "{'conv1': 0.0011796951293945312, 'bn1': 0.00015997886657714844, 'relu1': 6.246566772460938e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.00011849403381347656, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 384\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001661539077758789, 'bn1': 0.0005719661712646484, 'relu1': 0.0003261566162109375, 'conv2': 0.0016410350799560547, 'bn2': 0.0005669593811035156, 'residual_add_relu2': 0.0007729530334472656}\n",
      "{'conv1': 0.001661062240600586, 'bn1': 0.0005757808685302734, 'relu1': 0.0003287792205810547, 'conv2': 0.0016455650329589844, 'bn2': 0.0005738735198974609, 'residual_add_relu2': 0.000766754150390625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010612010955810547, 'bn1': 0.0003459453582763672, 'relu1': 0.00018024444580078125, 'conv2': 0.0013277530670166016, 'bn2': 0.0003445148468017578, 'conv3': 0.0004107952117919922, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.001325368881225586, 'bn1': 0.00034809112548828125, 'relu1': 0.00017881393432617188, 'conv2': 0.0013260841369628906, 'bn2': 0.0003407001495361328, 'residual_add_relu2': 0.00039315223693847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008022785186767578, 'bn1': 0.00022745132446289062, 'relu1': 0.00010251998901367188, 'conv2': 0.0011730194091796875, 'bn2': 0.00020956993103027344, 'conv3': 0.00035858154296875, 'residual_add_relu2': 0.0002167224884033203}\n",
      "{'conv1': 0.0011739730834960938, 'bn1': 0.00020265579223632812, 'relu1': 9.870529174804688e-05, 'conv2': 0.001163482666015625, 'bn2': 0.00022077560424804688, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006670951843261719, 'bn1': 0.0001246929168701172, 'relu1': 6.103515625e-05, 'conv2': 0.0011782646179199219, 'bn2': 0.0001285076141357422, 'conv3': 0.00029921531677246094, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.0011606216430664062, 'bn1': 0.0001499652862548828, 'relu1': 6.29425048828125e-05, 'conv2': 0.0011606216430664062, 'bn2': 0.00015425682067871094, 'residual_add_relu2': 0.00011324882507324219}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 385\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016622543334960938, 'bn1': 0.0005505084991455078, 'relu1': 0.0003314018249511719, 'conv2': 0.0016438961029052734, 'bn2': 0.0005543231964111328, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016417503356933594, 'bn1': 0.0005583763122558594, 'relu1': 0.00032258033752441406, 'conv2': 0.0016319751739501953, 'bn2': 0.0005533695220947266, 'residual_add_relu2': 0.0007653236389160156}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001071929931640625, 'bn1': 0.0003209114074707031, 'relu1': 0.0001766681671142578, 'conv2': 0.0013301372528076172, 'bn2': 0.0003173351287841797, 'conv3': 0.00041604042053222656, 'residual_add_relu2': 0.0004000663757324219}\n",
      "{'conv1': 0.0013315677642822266, 'bn1': 0.00031876564025878906, 'relu1': 0.0001761913299560547, 'conv2': 0.0013298988342285156, 'bn2': 0.0003185272216796875, 'residual_add_relu2': 0.00044226646423339844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008153915405273438, 'bn1': 0.0002079010009765625, 'relu1': 9.918212890625e-05, 'conv2': 0.0011668205261230469, 'bn2': 0.00021314620971679688, 'conv3': 0.0003592967987060547, 'residual_add_relu2': 0.0002033710479736328}\n",
      "{'conv1': 0.0011658668518066406, 'bn1': 0.0002315044403076172, 'relu1': 0.0001010894775390625, 'conv2': 0.0011670589447021484, 'bn2': 0.00019741058349609375, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006656646728515625, 'bn1': 0.000141143798828125, 'relu1': 6.198883056640625e-05, 'conv2': 0.00115966796875, 'bn2': 0.00012350082397460938, 'conv3': 0.0002970695495605469, 'residual_add_relu2': 0.00011992454528808594}\n",
      "{'conv1': 0.0011646747589111328, 'bn1': 0.00012421607971191406, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011548995971679688, 'bn2': 0.00013899803161621094, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 386\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016703605651855469, 'bn1': 0.0005743503570556641, 'relu1': 0.00032711029052734375, 'conv2': 0.0016474723815917969, 'bn2': 0.000560760498046875, 'residual_add_relu2': 0.0007688999176025391}\n",
      "{'conv1': 0.0016603469848632812, 'bn1': 0.0005631446838378906, 'relu1': 0.0003261566162109375, 'conv2': 0.0016367435455322266, 'bn2': 0.0005602836608886719, 'residual_add_relu2': 0.0007658004760742188}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010542869567871094, 'bn1': 0.000331878662109375, 'relu1': 0.00017547607421875, 'conv2': 0.0013225078582763672, 'bn2': 0.00033283233642578125, 'conv3': 0.00040793418884277344, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013194084167480469, 'bn1': 0.00033211708068847656, 'relu1': 0.00017523765563964844, 'conv2': 0.0013189315795898438, 'bn2': 0.0003342628479003906, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007987022399902344, 'bn1': 0.0002315044403076172, 'relu1': 0.00010156631469726562, 'conv2': 0.0011675357818603516, 'bn2': 0.00019884109497070312, 'conv3': 0.0003540515899658203, 'residual_add_relu2': 0.0002079010009765625}\n",
      "{'conv1': 0.0011832714080810547, 'bn1': 0.00020432472229003906, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011641979217529297, 'bn2': 0.0002162456512451172, 'residual_add_relu2': 0.00020599365234375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.001132965087890625, 'bn1': 0.0002684593200683594, 'relu1': 7.033348083496094e-05, 'conv2': 0.0011801719665527344, 'bn2': 0.000125885009765625, 'conv3': 0.00029850006103515625, 'residual_add_relu2': 0.00011610984802246094}\n",
      "{'conv1': 0.0011854171752929688, 'bn1': 0.0001361370086669922, 'relu1': 6.270408630371094e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.0001430511474609375, 'residual_add_relu2': 0.0001125335693359375}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 387\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016617774963378906, 'bn1': 0.0005598068237304688, 'relu1': 0.00032448768615722656, 'conv2': 0.0016417503356933594, 'bn2': 0.0005629062652587891, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.0016434192657470703, 'bn1': 0.0005550384521484375, 'relu1': 0.00032258033752441406, 'conv2': 0.0016350746154785156, 'bn2': 0.0005352497100830078, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010650157928466797, 'bn1': 0.00032329559326171875, 'relu1': 0.0001735687255859375, 'conv2': 0.0013196468353271484, 'bn2': 0.0003116130828857422, 'conv3': 0.0004031658172607422, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013213157653808594, 'bn1': 0.0003199577331542969, 'relu1': 0.00017642974853515625, 'conv2': 0.0013167858123779297, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.00039196014404296875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007967948913574219, 'bn1': 0.00020384788513183594, 'relu1': 0.00010132789611816406, 'conv2': 0.0011665821075439453, 'bn2': 0.0001964569091796875, 'conv3': 0.0003554821014404297, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011692047119140625, 'bn1': 0.00020551681518554688, 'relu1': 9.918212890625e-05, 'conv2': 0.0011630058288574219, 'bn2': 0.00019550323486328125, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.00066375732421875, 'bn1': 0.00012373924255371094, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00011420249938964844, 'conv3': 0.0002913475036621094, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011534690856933594, 'bn1': 0.00011563301086425781, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.0001087188720703125, 'residual_add_relu2': 0.00010800361633300781}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 388\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016601085662841797, 'bn1': 0.0008711814880371094, 'relu1': 0.0003883838653564453, 'conv2': 0.0016846656799316406, 'bn2': 0.0005896091461181641, 'residual_add_relu2': 0.0007777214050292969}\n",
      "{'conv1': 0.0016546249389648438, 'bn1': 0.0005643367767333984, 'relu1': 0.0003275871276855469, 'conv2': 0.0016541481018066406, 'bn2': 0.0005552768707275391, 'residual_add_relu2': 0.0007662773132324219}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010647773742675781, 'bn1': 0.0003237724304199219, 'relu1': 0.00017833709716796875, 'conv2': 0.0013339519500732422, 'bn2': 0.0003554821014404297, 'conv3': 0.0004189014434814453, 'residual_add_relu2': 0.0003921985626220703}\n",
      "{'conv1': 0.0013241767883300781, 'bn1': 0.0003161430358886719, 'relu1': 0.0001800060272216797, 'conv2': 0.0013227462768554688, 'bn2': 0.00033164024353027344, 'residual_add_relu2': 0.00039267539978027344}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008063316345214844, 'bn1': 0.0002110004425048828, 'relu1': 0.00010538101196289062, 'conv2': 0.0011751651763916016, 'bn2': 0.00020384788513183594, 'conv3': 0.00036907196044921875, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011661052703857422, 'bn1': 0.00021123886108398438, 'relu1': 9.822845458984375e-05, 'conv2': 0.001161336898803711, 'bn2': 0.00020432472229003906, 'residual_add_relu2': 0.0002071857452392578}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006678104400634766, 'bn1': 0.00015306472778320312, 'relu1': 6.246566772460938e-05, 'conv2': 0.0011599063873291016, 'bn2': 0.00012350082397460938, 'conv3': 0.0002994537353515625, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.001161336898803711, 'bn1': 0.0001323223114013672, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00014162063598632812, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 389\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016579627990722656, 'bn1': 0.0005590915679931641, 'relu1': 0.000324249267578125, 'conv2': 0.0016465187072753906, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007679462432861328}\n",
      "{'conv1': 0.0016460418701171875, 'bn1': 0.0005452632904052734, 'relu1': 0.0003230571746826172, 'conv2': 0.0016398429870605469, 'bn2': 0.0005428791046142578, 'residual_add_relu2': 0.0007619857788085938}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010578632354736328, 'bn1': 0.0003204345703125, 'relu1': 0.00017833709716796875, 'conv2': 0.0013213157653808594, 'bn2': 0.0003266334533691406, 'conv3': 0.00040078163146972656, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.001314401626586914, 'bn1': 0.0003147125244140625, 'relu1': 0.0001800060272216797, 'conv2': 0.0013298988342285156, 'bn2': 0.0003185272216796875, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.00079345703125, 'bn1': 0.00019288063049316406, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011615753173828125, 'bn2': 0.00020575523376464844, 'conv3': 0.0003542900085449219, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.00020837783813476562, 'relu1': 9.846687316894531e-05, 'conv2': 0.001163482666015625, 'bn2': 0.00020956993103027344, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006670951843261719, 'bn1': 0.00012254714965820312, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.00011539459228515625, 'conv3': 0.0002906322479248047, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.001157999038696289, 'bn1': 0.00013875961303710938, 'relu1': 6.151199340820312e-05, 'conv2': 0.0011563301086425781, 'bn2': 0.00011682510375976562, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 390\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016705989837646484, 'bn1': 0.0005540847778320312, 'relu1': 0.00032448768615722656, 'conv2': 0.0016498565673828125, 'bn2': 0.0005562305450439453, 'residual_add_relu2': 0.0007722377777099609}\n",
      "{'conv1': 0.001644134521484375, 'bn1': 0.0005440711975097656, 'relu1': 0.00032329559326171875, 'conv2': 0.0016453266143798828, 'bn2': 0.0005426406860351562, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010573863983154297, 'bn1': 0.0003311634063720703, 'relu1': 0.00017642974853515625, 'conv2': 0.0013241767883300781, 'bn2': 0.0003192424774169922, 'conv3': 0.0004088878631591797, 'residual_add_relu2': 0.00039196014404296875}\n",
      "{'conv1': 0.0013239383697509766, 'bn1': 0.0003268718719482422, 'relu1': 0.00017595291137695312, 'conv2': 0.0013229846954345703, 'bn2': 0.0003192424774169922, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008008480072021484, 'bn1': 0.0002162456512451172, 'relu1': 0.00010156631469726562, 'conv2': 0.0011715888977050781, 'bn2': 0.0002067089080810547, 'conv3': 0.0003612041473388672, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.0011715888977050781, 'bn1': 0.0002110004425048828, 'relu1': 0.00010132789611816406, 'conv2': 0.0011668205261230469, 'bn2': 0.00021982192993164062, 'residual_add_relu2': 0.00020694732666015625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006668567657470703, 'bn1': 0.00012564659118652344, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011591911315917969, 'bn2': 0.00011873245239257812, 'conv3': 0.00030422210693359375, 'residual_add_relu2': 0.00011396408081054688}\n",
      "{'conv1': 0.0011706352233886719, 'bn1': 0.0001304149627685547, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011551380157470703, 'bn2': 0.00013399124145507812, 'residual_add_relu2': 0.00011277198791503906}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 391\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016586780548095703, 'bn1': 0.0005612373352050781, 'relu1': 0.0003268718719482422, 'conv2': 0.0016434192657470703, 'bn2': 0.0005457401275634766, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016384124755859375, 'bn1': 0.0005509853363037109, 'relu1': 0.00032448768615722656, 'conv2': 0.0016341209411621094, 'bn2': 0.0005488395690917969, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010559558868408203, 'bn1': 0.0003151893615722656, 'relu1': 0.00017213821411132812, 'conv2': 0.0013172626495361328, 'bn2': 0.00031375885009765625, 'conv3': 0.00040078163146972656, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013167858123779297, 'bn1': 0.00031280517578125, 'relu1': 0.00017404556274414062, 'conv2': 0.001314401626586914, 'bn2': 0.0003135204315185547, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007932186126708984, 'bn1': 0.00019979476928710938, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011687278747558594, 'bn2': 0.00019598007202148438, 'conv3': 0.000370025634765625, 'residual_add_relu2': 0.0002067089080810547}\n",
      "{'conv1': 0.0011706352233886719, 'bn1': 0.00020265579223632812, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011622905731201172, 'bn2': 0.000194549560546875, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006644725799560547, 'bn1': 0.00012564659118652344, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011563301086425781, 'bn2': 0.0001163482666015625, 'conv3': 0.00029397010803222656, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011565685272216797, 'bn1': 0.00012564659118652344, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011539459228515625, 'bn2': 0.00012922286987304688, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 392\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016551017761230469, 'bn1': 0.0005559921264648438, 'relu1': 0.0003249645233154297, 'conv2': 0.0016338825225830078, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007684230804443359}\n",
      "{'conv1': 0.0016417503356933594, 'bn1': 0.0005445480346679688, 'relu1': 0.0003247261047363281, 'conv2': 0.0016338825225830078, 'bn2': 0.0005440711975097656, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010540485382080078, 'bn1': 0.0003085136413574219, 'relu1': 0.00017189979553222656, 'conv2': 0.0013148784637451172, 'bn2': 0.0003132820129394531, 'conv3': 0.00040268898010253906, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013194084167480469, 'bn1': 0.00031304359436035156, 'relu1': 0.00017523765563964844, 'conv2': 0.0013153553009033203, 'bn2': 0.0003108978271484375, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007948875427246094, 'bn1': 0.00021791458129882812, 'relu1': 0.00010180473327636719, 'conv2': 0.0011680126190185547, 'bn2': 0.00020813941955566406, 'conv3': 0.00035643577575683594, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011699199676513672, 'bn1': 0.0002002716064453125, 'relu1': 9.918212890625e-05, 'conv2': 0.0011763572692871094, 'bn2': 0.00021076202392578125, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006661415100097656, 'bn1': 0.0001270771026611328, 'relu1': 6.0558319091796875e-05, 'conv2': 0.001155853271484375, 'bn2': 0.00011539459228515625, 'conv3': 0.0002982616424560547, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011589527130126953, 'bn1': 0.0001354217529296875, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.0001163482666015625, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 393\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016586780548095703, 'bn1': 0.0005497932434082031, 'relu1': 0.00032258033752441406, 'conv2': 0.0016415119171142578, 'bn2': 0.0005486011505126953, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016586780548095703, 'bn1': 0.0005502700805664062, 'relu1': 0.0003256797790527344, 'conv2': 0.0016338825225830078, 'bn2': 0.0005373954772949219, 'residual_add_relu2': 0.0007674694061279297}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001066446304321289, 'bn1': 0.00031828880310058594, 'relu1': 0.00017523765563964844, 'conv2': 0.0013186931610107422, 'bn2': 0.0003120899200439453, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.00039196014404296875}\n",
      "{'conv1': 0.0013303756713867188, 'bn1': 0.0003371238708496094, 'relu1': 0.00017571449279785156, 'conv2': 0.0013158321380615234, 'bn2': 0.00031185150146484375, 'residual_add_relu2': 0.00043654441833496094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008115768432617188, 'bn1': 0.00020647048950195312, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011646747589111328, 'bn2': 0.0001964569091796875, 'conv3': 0.0003497600555419922, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.0011646747589111328, 'bn1': 0.00021123886108398438, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011639595031738281, 'bn2': 0.0001952648162841797, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006639957427978516, 'bn1': 0.00012159347534179688, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.00013113021850585938, 'conv3': 0.00029921531677246094, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011563301086425781, 'bn1': 0.00011539459228515625, 'relu1': 5.7220458984375e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.0001087188720703125, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 394\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016672611236572266, 'bn1': 0.0005552768707275391, 'relu1': 0.00032448768615722656, 'conv2': 0.0016443729400634766, 'bn2': 0.0005543231964111328, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.0016453266143798828, 'bn1': 0.0005588531494140625, 'relu1': 0.0003228187561035156, 'conv2': 0.0016369819641113281, 'bn2': 0.0005319118499755859, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010514259338378906, 'bn1': 0.00031876564025878906, 'relu1': 0.0001728534698486328, 'conv2': 0.0013167858123779297, 'bn2': 0.0003066062927246094, 'conv3': 0.0003986358642578125, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013167858123779297, 'bn1': 0.0003330707550048828, 'relu1': 0.00017452239990234375, 'conv2': 0.0013179779052734375, 'bn2': 0.0003116130828857422, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007946491241455078, 'bn1': 0.0002028942108154297, 'relu1': 0.00010180473327636719, 'conv2': 0.0011649131774902344, 'bn2': 0.00019478797912597656, 'conv3': 0.00035119056701660156, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011653900146484375, 'bn1': 0.0002663135528564453, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011639595031738281, 'bn2': 0.0001964569091796875, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006628036499023438, 'bn1': 0.00012135505676269531, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00012874603271484375, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011563301086425781, 'bn1': 0.00012159347534179688, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00011467933654785156, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 395\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016469955444335938, 'bn1': 0.0005517005920410156, 'relu1': 0.00032401084899902344, 'conv2': 0.0016355514526367188, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.0007643699645996094}\n",
      "{'conv1': 0.0016345977783203125, 'bn1': 0.0005478858947753906, 'relu1': 0.00032258033752441406, 'conv2': 0.001634359359741211, 'bn2': 0.0005295276641845703, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010471343994140625, 'bn1': 0.0003077983856201172, 'relu1': 0.00017142295837402344, 'conv2': 0.0013134479522705078, 'bn2': 0.0003018379211425781, 'conv3': 0.0003952980041503906, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013148784637451172, 'bn1': 0.00031375885009765625, 'relu1': 0.00017070770263671875, 'conv2': 0.0013103485107421875, 'bn2': 0.00031065940856933594, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007936954498291016, 'bn1': 0.00019359588623046875, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011599063873291016, 'bn2': 0.00018644332885742188, 'conv3': 0.00034999847412109375, 'residual_add_relu2': 0.0002028942108154297}\n",
      "{'conv1': 0.001165151596069336, 'bn1': 0.00022482872009277344, 'relu1': 9.799003601074219e-05, 'conv2': 0.001163482666015625, 'bn2': 0.00019025802612304688, 'residual_add_relu2': 0.0002033710479736328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006601810455322266, 'bn1': 0.00011467933654785156, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00011873245239257812, 'conv3': 0.0002970695495605469, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011527538299560547, 'bn1': 0.00011181831359863281, 'relu1': 5.6743621826171875e-05, 'conv2': 0.0011484622955322266, 'bn2': 0.00010824203491210938, 'residual_add_relu2': 0.00010824203491210938}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 396\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016570091247558594, 'bn1': 0.0005452632904052734, 'relu1': 0.00032138824462890625, 'conv2': 0.0016384124755859375, 'bn2': 0.0005438327789306641, 'residual_add_relu2': 0.0007634162902832031}\n",
      "{'conv1': 0.0016548633575439453, 'bn1': 0.0005443096160888672, 'relu1': 0.000324249267578125, 'conv2': 0.0016434192657470703, 'bn2': 0.0005316734313964844, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010628700256347656, 'bn1': 0.0003178119659423828, 'relu1': 0.00017380714416503906, 'conv2': 0.0013260841369628906, 'bn2': 0.0003077983856201172, 'conv3': 0.0003986358642578125, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013277530670166016, 'bn1': 0.00033283233642578125, 'relu1': 0.00017547607421875, 'conv2': 0.0013153553009033203, 'bn2': 0.0003094673156738281, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008001327514648438, 'bn1': 0.00020241737365722656, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011646747589111328, 'bn2': 0.000194549560546875, 'conv3': 0.00035262107849121094, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.00021028518676757812, 'relu1': 9.894371032714844e-05, 'conv2': 0.001163482666015625, 'bn2': 0.00019502639770507812, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006668567657470703, 'bn1': 0.0001232624053955078, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00013017654418945312, 'conv3': 0.0002994537353515625, 'residual_add_relu2': 0.00011229515075683594}\n",
      "{'conv1': 0.0011563301086425781, 'bn1': 0.00012135505676269531, 'relu1': 5.91278076171875e-05, 'conv2': 0.00115203857421875, 'bn2': 0.00011420249938964844, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 397\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016436576843261719, 'bn1': 0.0005452632904052734, 'relu1': 0.0006225109100341797, 'conv2': 0.001706838607788086, 'bn2': 0.00057220458984375, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016469955444335938, 'bn1': 0.0005624294281005859, 'relu1': 0.00032639503479003906, 'conv2': 0.0016393661499023438, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007669925689697266}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010573863983154297, 'bn1': 0.0003204345703125, 'relu1': 0.00017309188842773438, 'conv2': 0.0013163089752197266, 'bn2': 0.0003147125244140625, 'conv3': 0.00040268898010253906, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013155937194824219, 'bn1': 0.0003142356872558594, 'relu1': 0.00017380714416503906, 'conv2': 0.0013141632080078125, 'bn2': 0.0003223419189453125, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007903575897216797, 'bn1': 0.0001964569091796875, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011653900146484375, 'bn2': 0.0001862049102783203, 'conv3': 0.0003514289855957031, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.0011723041534423828, 'bn1': 0.0001952648162841797, 'relu1': 9.584426879882812e-05, 'conv2': 0.0011577606201171875, 'bn2': 0.00020837783813476562, 'residual_add_relu2': 0.0002028942108154297}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006642341613769531, 'bn1': 0.00013327598571777344, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011544227600097656, 'bn2': 0.00011682510375976562, 'conv3': 0.0002968311309814453, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.001157999038696289, 'bn1': 0.00012373924255371094, 'relu1': 6.151199340820312e-05, 'conv2': 0.001154184341430664, 'bn2': 0.00012159347534179688, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 398\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001665353775024414, 'bn1': 0.0005826950073242188, 'relu1': 0.00032591819763183594, 'conv2': 0.0016467571258544922, 'bn2': 0.0005445480346679688, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016446113586425781, 'bn1': 0.0005567073822021484, 'relu1': 0.00032711029052734375, 'conv2': 0.0016410350799560547, 'bn2': 0.000545501708984375, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010509490966796875, 'bn1': 0.00031447410583496094, 'relu1': 0.00017261505126953125, 'conv2': 0.0013196468353271484, 'bn2': 0.0003752708435058594, 'conv3': 0.0004150867462158203, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013186931610107422, 'bn1': 0.00031638145446777344, 'relu1': 0.00017380714416503906, 'conv2': 0.0013146400451660156, 'bn2': 0.0003159046173095703, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007977485656738281, 'bn1': 0.0002009868621826172, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011649131774902344, 'bn2': 0.00019550323486328125, 'conv3': 0.0003535747528076172, 'residual_add_relu2': 0.00020766258239746094}\n",
      "{'conv1': 0.0011718273162841797, 'bn1': 0.00020194053649902344, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011625289916992188, 'bn2': 0.0001957416534423828, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000667572021484375, 'bn1': 0.000125885009765625, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00011682510375976562, 'conv3': 0.0002942085266113281, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011563301086425781, 'bn1': 0.00012111663818359375, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00012087821960449219, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 399\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016586780548095703, 'bn1': 0.0005557537078857422, 'relu1': 0.0003235340118408203, 'conv2': 0.001638174057006836, 'bn2': 0.0005435943603515625, 'residual_add_relu2': 0.0007688999176025391}\n",
      "{'conv1': 0.001646280288696289, 'bn1': 0.0005540847778320312, 'relu1': 0.0003237724304199219, 'conv2': 0.0016345977783203125, 'bn2': 0.0005459785461425781, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010516643524169922, 'bn1': 0.0003094673156738281, 'relu1': 0.0001723766326904297, 'conv2': 0.0013165473937988281, 'bn2': 0.0003116130828857422, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.001318216323852539, 'bn1': 0.0007767677307128906, 'relu1': 0.0001957416534423828, 'conv2': 0.0013341903686523438, 'bn2': 0.0003249645233154297, 'residual_add_relu2': 0.0003979206085205078}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008046627044677734, 'bn1': 0.00020599365234375, 'relu1': 0.00010347366333007812, 'conv2': 0.0011758804321289062, 'bn2': 0.0002090930938720703, 'conv3': 0.00036907196044921875, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.001173257827758789, 'bn1': 0.0002090930938720703, 'relu1': 0.00010585784912109375, 'conv2': 0.0011708736419677734, 'bn2': 0.0002040863037109375, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006611347198486328, 'bn1': 0.00012159347534179688, 'relu1': 6.079673767089844e-05, 'conv2': 0.001154184341430664, 'bn2': 0.00011754035949707031, 'conv3': 0.00029754638671875, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.0011565685272216797, 'bn1': 0.00012993812561035156, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011513233184814453, 'bn2': 0.00011515617370605469, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 400\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016586780548095703, 'bn1': 0.0005543231964111328, 'relu1': 0.0003237724304199219, 'conv2': 0.0016491413116455078, 'bn2': 0.0005409717559814453, 'residual_add_relu2': 0.000762939453125}\n",
      "{'conv1': 0.0016415119171142578, 'bn1': 0.0005469322204589844, 'relu1': 0.0003211498260498047, 'conv2': 0.0016474723815917969, 'bn2': 0.0005338191986083984, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010528564453125, 'bn1': 0.0003151893615722656, 'relu1': 0.00017571449279785156, 'conv2': 0.0013265609741210938, 'bn2': 0.00030803680419921875, 'conv3': 0.0003993511199951172, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013263225555419922, 'bn1': 0.0003256797790527344, 'relu1': 0.00017452239990234375, 'conv2': 0.0013170242309570312, 'bn2': 0.00030803680419921875, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007991790771484375, 'bn1': 0.0002346038818359375, 'relu1': 0.00010085105895996094, 'conv2': 0.0011670589447021484, 'bn2': 0.0001938343048095703, 'conv3': 0.0003514289855957031, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.0011625289916992188, 'bn1': 0.000202178955078125, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011661052703857422, 'bn2': 0.0002009868621826172, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006642341613769531, 'bn1': 0.00012183189392089844, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011551380157470703, 'bn2': 0.0001266002655029297, 'conv3': 0.0003006458282470703, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011556148529052734, 'bn1': 0.00012159347534179688, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00011539459228515625, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 401\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016543865203857422, 'bn1': 0.0005595684051513672, 'relu1': 0.0003249645233154297, 'conv2': 0.0016398429870605469, 'bn2': 0.0005452632904052734, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016431808471679688, 'bn1': 0.000545501708984375, 'relu1': 0.000324249267578125, 'conv2': 0.00164031982421875, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001051187515258789, 'bn1': 0.0003070831298828125, 'relu1': 0.00017118453979492188, 'conv2': 0.0013151168823242188, 'bn2': 0.0003001689910888672, 'conv3': 0.00039577484130859375, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013265609741210938, 'bn1': 0.0003108978271484375, 'relu1': 0.00017189979553222656, 'conv2': 0.001310110092163086, 'bn2': 0.0003039836883544922, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007982254028320312, 'bn1': 0.00019788742065429688, 'relu1': 0.00010085105895996094, 'conv2': 0.0011615753173828125, 'bn2': 0.0001888275146484375, 'conv3': 0.0003497600555419922, 'residual_add_relu2': 0.0002033710479736328}\n",
      "{'conv1': 0.0011622905731201172, 'bn1': 0.00020265579223632812, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011606216430664062, 'bn2': 0.000186920166015625, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006678104400634766, 'bn1': 0.00011658668518066406, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011529922485351562, 'bn2': 0.00011873245239257812, 'conv3': 0.000293731689453125, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.001153707504272461, 'bn1': 0.00011539459228515625, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00011348724365234375, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 402\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016751289367675781, 'bn1': 0.0005605220794677734, 'relu1': 0.0003254413604736328, 'conv2': 0.0016484260559082031, 'bn2': 0.0005459785461425781, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016486644744873047, 'bn1': 0.0005447864532470703, 'relu1': 0.0003228187561035156, 'conv2': 0.0016393661499023438, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010519027709960938, 'bn1': 0.00032448768615722656, 'relu1': 0.00017571449279785156, 'conv2': 0.0013265609741210938, 'bn2': 0.00032138824462890625, 'conv3': 0.0004100799560546875, 'residual_add_relu2': 0.0003962516784667969}\n",
      "{'conv1': 0.0013260841369628906, 'bn1': 0.00032591819763183594, 'relu1': 0.00017762184143066406, 'conv2': 0.0013229846954345703, 'bn2': 0.00034046173095703125, 'residual_add_relu2': 0.00040078163146972656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008106231689453125, 'bn1': 0.0002243518829345703, 'relu1': 0.00010204315185546875, 'conv2': 0.0011739730834960938, 'bn2': 0.00020837783813476562, 'conv3': 0.0003604888916015625, 'residual_add_relu2': 0.00020742416381835938}\n",
      "{'conv1': 0.001172780990600586, 'bn1': 0.00021910667419433594, 'relu1': 0.00010251998901367188, 'conv2': 0.0011687278747558594, 'bn2': 0.00019812583923339844, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.00066375732421875, 'bn1': 0.00012731552124023438, 'relu1': 6.031990051269531e-05, 'conv2': 0.001157522201538086, 'bn2': 0.00013113021850585938, 'conv3': 0.0002956390380859375, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011589527130126953, 'bn1': 0.0001201629638671875, 'relu1': 5.91278076171875e-05, 'conv2': 0.001155853271484375, 'bn2': 0.00015664100646972656, 'residual_add_relu2': 0.0001163482666015625}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 403\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016598701477050781, 'bn1': 0.0005598068237304688, 'relu1': 0.00032401084899902344, 'conv2': 0.0016410350799560547, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016453266143798828, 'bn1': 0.0005457401275634766, 'relu1': 0.00032329559326171875, 'conv2': 0.0016384124755859375, 'bn2': 0.0005409717559814453, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010528564453125, 'bn1': 0.0003147125244140625, 'relu1': 0.00017333030700683594, 'conv2': 0.001317739486694336, 'bn2': 0.0003204345703125, 'conv3': 0.00040411949157714844, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013184547424316406, 'bn1': 0.00031375885009765625, 'relu1': 0.00017380714416503906, 'conv2': 0.001314401626586914, 'bn2': 0.00032067298889160156, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007905960083007812, 'bn1': 0.00019240379333496094, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011608600616455078, 'bn2': 0.00019288063049316406, 'conv3': 0.0003509521484375, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011632442474365234, 'bn1': 0.00019931793212890625, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011627674102783203, 'bn2': 0.00021767616271972656, 'residual_add_relu2': 0.00020647048950195312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006680488586425781, 'bn1': 0.0001239776611328125, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00011587142944335938, 'conv3': 0.00029277801513671875, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011556148529052734, 'bn1': 0.00012087821960449219, 'relu1': 7.009506225585938e-05, 'conv2': 0.0011534690856933594, 'bn2': 0.00012159347534179688, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 404\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016512870788574219, 'bn1': 0.0005550384521484375, 'relu1': 0.0003228187561035156, 'conv2': 0.00164031982421875, 'bn2': 0.0005304813385009766, 'residual_add_relu2': 0.0007643699645996094}\n",
      "{'conv1': 0.0016355514526367188, 'bn1': 0.0005373954772949219, 'relu1': 0.00032401084899902344, 'conv2': 0.0016374588012695312, 'bn2': 0.0005338191986083984, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010519027709960938, 'bn1': 0.00030541419982910156, 'relu1': 0.00016951560974121094, 'conv2': 0.001312255859375, 'bn2': 0.00030803680419921875, 'conv3': 0.0003981590270996094, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013146400451660156, 'bn1': 0.0003032684326171875, 'relu1': 0.000171661376953125, 'conv2': 0.0013093948364257812, 'bn2': 0.0003039836883544922, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007901191711425781, 'bn1': 0.00019073486328125, 'relu1': 9.512901306152344e-05, 'conv2': 0.0011591911315917969, 'bn2': 0.0001914501190185547, 'conv3': 0.0003521442413330078, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011606216430664062, 'bn1': 0.00019025802612304688, 'relu1': 9.584426879882812e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.00018596649169921875, 'residual_add_relu2': 0.000202178955078125}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006580352783203125, 'bn1': 0.00012111663818359375, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00011181831359863281, 'conv3': 0.00029206275939941406, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.0011577606201171875, 'bn1': 0.0001163482666015625, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011491775512695312, 'bn2': 0.00012493133544921875, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 405\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016579627990722656, 'bn1': 0.00055694580078125, 'relu1': 0.00032520294189453125, 'conv2': 0.0016360282897949219, 'bn2': 0.0005364418029785156, 'residual_add_relu2': 0.000762939453125}\n",
      "{'conv1': 0.0016360282897949219, 'bn1': 0.0005359649658203125, 'relu1': 0.0003218650817871094, 'conv2': 0.001631021499633789, 'bn2': 0.0005335807800292969, 'residual_add_relu2': 0.0007617473602294922}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001050710678100586, 'bn1': 0.00034332275390625, 'relu1': 0.00017595291137695312, 'conv2': 0.0013172626495361328, 'bn2': 0.0003132820129394531, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013184547424316406, 'bn1': 0.00031685829162597656, 'relu1': 0.0001766681671142578, 'conv2': 0.0013158321380615234, 'bn2': 0.00030517578125, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007929801940917969, 'bn1': 0.00019931793212890625, 'relu1': 0.00010251998901367188, 'conv2': 0.0011775493621826172, 'bn2': 0.00020170211791992188, 'conv3': 0.00034999847412109375, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.0001971721649169922, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011577606201171875, 'bn2': 0.0001983642578125, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006618499755859375, 'bn1': 0.00011754035949707031, 'relu1': 5.841255187988281e-05, 'conv2': 0.00115203857421875, 'bn2': 0.00011610984802246094, 'conv3': 0.00029206275939941406, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011620521545410156, 'bn1': 0.00012826919555664062, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00011110305786132812, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 406\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016639232635498047, 'bn1': 0.0005590915679931641, 'relu1': 0.0003249645233154297, 'conv2': 0.0016498565673828125, 'bn2': 0.0005507469177246094, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016474723815917969, 'bn1': 0.0005450248718261719, 'relu1': 0.00032258033752441406, 'conv2': 0.0016357898712158203, 'bn2': 0.0005464553833007812, 'residual_add_relu2': 0.0007619857788085938}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010538101196289062, 'bn1': 0.000308990478515625, 'relu1': 0.00017189979553222656, 'conv2': 0.001314401626586914, 'bn2': 0.00030493736267089844, 'conv3': 0.000392913818359375, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013151168823242188, 'bn1': 0.00031638145446777344, 'relu1': 0.00017380714416503906, 'conv2': 0.0013132095336914062, 'bn2': 0.00030803680419921875, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007925033569335938, 'bn1': 0.0002002716064453125, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011630058288574219, 'bn2': 0.00019693374633789062, 'conv3': 0.000354766845703125, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.0011684894561767578, 'bn1': 0.0001995563507080078, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011622905731201172, 'bn2': 0.00020456314086914062, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006642341613769531, 'bn1': 0.00012063980102539062, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011539459228515625, 'bn2': 0.0001163482666015625, 'conv3': 0.0002951622009277344, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011568069458007812, 'bn1': 0.00012612342834472656, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.00011539459228515625, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 407\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016636848449707031, 'bn1': 0.0005517005920410156, 'relu1': 0.00032401084899902344, 'conv2': 0.0016398429870605469, 'bn2': 0.0005435943603515625, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016391277313232422, 'bn1': 0.0005469322204589844, 'relu1': 0.0003235340118408203, 'conv2': 0.0016412734985351562, 'bn2': 0.0005400180816650391, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010516643524169922, 'bn1': 0.0003216266632080078, 'relu1': 0.0001728534698486328, 'conv2': 0.0013186931610107422, 'bn2': 0.0003082752227783203, 'conv3': 0.0004000663757324219, 'residual_add_relu2': 0.0003921985626220703}\n",
      "{'conv1': 0.0013167858123779297, 'bn1': 0.000316619873046875, 'relu1': 0.0001728534698486328, 'conv2': 0.0013155937194824219, 'bn2': 0.000308990478515625, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007932186126708984, 'bn1': 0.0002257823944091797, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011661052703857422, 'bn2': 0.0001957416534423828, 'conv3': 0.0003533363342285156, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.001165628433227539, 'bn1': 0.00020313262939453125, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011632442474365234, 'bn2': 0.0001957416534423828, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006632804870605469, 'bn1': 0.00012183189392089844, 'relu1': 6.031990051269531e-05, 'conv2': 0.0012066364288330078, 'bn2': 0.00013303756713867188, 'conv3': 0.0002968311309814453, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011568069458007812, 'bn1': 0.00012087821960449219, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00011420249938964844, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 408\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.00165557861328125, 'bn1': 0.0005540847778320312, 'relu1': 0.0003237724304199219, 'conv2': 0.0016360282897949219, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016527175903320312, 'bn1': 0.0005433559417724609, 'relu1': 0.00032067298889160156, 'conv2': 0.0016317367553710938, 'bn2': 0.0005288124084472656, 'residual_add_relu2': 0.0007615089416503906}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010476112365722656, 'bn1': 0.0003097057342529297, 'relu1': 0.0001704692840576172, 'conv2': 0.0013113021850585938, 'bn2': 0.00030159950256347656, 'conv3': 0.00039315223693847656, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013170242309570312, 'bn1': 0.0003180503845214844, 'relu1': 0.0001735687255859375, 'conv2': 0.001316070556640625, 'bn2': 0.00030732154846191406, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007917881011962891, 'bn1': 0.00020360946655273438, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011639595031738281, 'bn2': 0.00019502639770507812, 'conv3': 0.0003514289855957031, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011665821075439453, 'bn1': 0.0002124309539794922, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011630058288574219, 'bn2': 0.0001957416534423828, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006587505340576172, 'bn1': 0.00011539459228515625, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.00011205673217773438, 'conv3': 0.0002970695495605469, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.00115203857421875, 'bn1': 0.00011539459228515625, 'relu1': 5.793571472167969e-05, 'conv2': 0.001149892807006836, 'bn2': 0.00011444091796875, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 409\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016636848449707031, 'bn1': 0.0005521774291992188, 'relu1': 0.0003235340118408203, 'conv2': 0.0016429424285888672, 'bn2': 0.0005466938018798828, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.001650094985961914, 'bn1': 0.0005452632904052734, 'relu1': 0.00032591819763183594, 'conv2': 0.0016460418701171875, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010552406311035156, 'bn1': 0.0003228187561035156, 'relu1': 0.0001742839813232422, 'conv2': 0.001325368881225586, 'bn2': 0.0003101825714111328, 'conv3': 0.0003993511199951172, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.0013179779052734375, 'bn1': 0.0003178119659423828, 'relu1': 0.0001728534698486328, 'conv2': 0.0013158321380615234, 'bn2': 0.0003063678741455078, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007905960083007812, 'bn1': 0.00019502639770507812, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011622905731201172, 'bn2': 0.0001888275146484375, 'conv3': 0.00035071372985839844, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011661052703857422, 'bn1': 0.0001995563507080078, 'relu1': 0.0001366138458251953, 'conv2': 0.0011641979217529297, 'bn2': 0.00020432472229003906, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006632804870605469, 'bn1': 0.0001220703125, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.00011491775512695312, 'conv3': 0.00030112266540527344, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011577606201171875, 'bn1': 0.00012159347534179688, 'relu1': 5.9604644775390625e-05, 'conv2': 0.001155853271484375, 'bn2': 0.0001163482666015625, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 410\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001668691635131836, 'bn1': 0.0005581378936767578, 'relu1': 0.0003247261047363281, 'conv2': 0.0016431808471679688, 'bn2': 0.0005550384521484375, 'residual_add_relu2': 0.0007677078247070312}\n",
      "{'conv1': 0.0016474723815917969, 'bn1': 0.0005538463592529297, 'relu1': 0.0003273487091064453, 'conv2': 0.001644134521484375, 'bn2': 0.0005407333374023438, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010678768157958984, 'bn1': 0.000316619873046875, 'relu1': 0.00017309188842773438, 'conv2': 0.0013158321380615234, 'bn2': 0.0003082752227783203, 'conv3': 0.0004050731658935547, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013229846954345703, 'bn1': 0.000335693359375, 'relu1': 0.00017690658569335938, 'conv2': 0.0013179779052734375, 'bn2': 0.00030612945556640625, 'residual_add_relu2': 0.00038814544677734375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007882118225097656, 'bn1': 0.0001971721649169922, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011632442474365234, 'bn2': 0.00018930435180664062, 'conv3': 0.0003504753112792969, 'residual_add_relu2': 0.0002028942108154297}\n",
      "{'conv1': 0.0011646747589111328, 'bn1': 0.00019431114196777344, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011577606201171875, 'bn2': 0.00018453598022460938, 'residual_add_relu2': 0.00020241737365722656}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006613731384277344, 'bn1': 0.00012087821960449219, 'relu1': 5.7697296142578125e-05, 'conv2': 0.001153707504272461, 'bn2': 0.00011301040649414062, 'conv3': 0.0002868175506591797, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011548995971679688, 'bn1': 0.00011420249938964844, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00010919570922851562, 'residual_add_relu2': 0.0001087188720703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 411\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016617774963378906, 'bn1': 0.0005624294281005859, 'relu1': 0.00032210350036621094, 'conv2': 0.0016417503356933594, 'bn2': 0.0005364418029785156, 'residual_add_relu2': 0.0007638931274414062}\n",
      "{'conv1': 0.0016384124755859375, 'bn1': 0.0005462169647216797, 'relu1': 0.0003216266632080078, 'conv2': 0.0016446113586425781, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010526180267333984, 'bn1': 0.0003135204315185547, 'relu1': 0.00017213821411132812, 'conv2': 0.0013184547424316406, 'bn2': 0.00031065940856933594, 'conv3': 0.0003986358642578125, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013129711151123047, 'bn1': 0.000308990478515625, 'relu1': 0.00017213821411132812, 'conv2': 0.0013096332550048828, 'bn2': 0.00030422210693359375, 'residual_add_relu2': 0.0003883838653564453}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007870197296142578, 'bn1': 0.0001900196075439453, 'relu1': 9.560585021972656e-05, 'conv2': 0.0011589527130126953, 'bn2': 0.00018548965454101562, 'conv3': 0.0003979206085205078, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011665821075439453, 'bn1': 0.00019240379333496094, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.00018858909606933594, 'residual_add_relu2': 0.0002033710479736328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006585121154785156, 'bn1': 0.00011515617370605469, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00011014938354492188, 'conv3': 0.0002892017364501953, 'residual_add_relu2': 0.00010919570922851562}\n",
      "{'conv1': 0.0011522769927978516, 'bn1': 0.00011086463928222656, 'relu1': 5.7220458984375e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.00012421607971191406, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 412\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016562938690185547, 'bn1': 0.0005545616149902344, 'relu1': 0.0003235340118408203, 'conv2': 0.0016376972198486328, 'bn2': 0.0005390644073486328, 'residual_add_relu2': 0.0007634162902832031}\n",
      "{'conv1': 0.0016407966613769531, 'bn1': 0.0005476474761962891, 'relu1': 0.00032448768615722656, 'conv2': 0.0016417503356933594, 'bn2': 0.0005598068237304688, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010609626770019531, 'bn1': 0.00031566619873046875, 'relu1': 0.0001704692840576172, 'conv2': 0.001314401626586914, 'bn2': 0.00030612945556640625, 'conv3': 0.0003955364227294922, 'residual_add_relu2': 0.0003883838653564453}\n",
      "{'conv1': 0.001312255859375, 'bn1': 0.00030303001403808594, 'relu1': 0.00017070770263671875, 'conv2': 0.0013108253479003906, 'bn2': 0.0003159046173095703, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007910728454589844, 'bn1': 0.0001914501190185547, 'relu1': 9.584426879882812e-05, 'conv2': 0.00115966796875, 'bn2': 0.0001895427703857422, 'conv3': 0.0003509521484375, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0011682510375976562, 'bn1': 0.00019168853759765625, 'relu1': 9.512901306152344e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.0001938343048095703, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006651878356933594, 'bn1': 0.0001246929168701172, 'relu1': 5.936622619628906e-05, 'conv2': 0.001155853271484375, 'bn2': 0.00011539459228515625, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.0011568069458007812, 'bn1': 0.00012230873107910156, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.00012350082397460938, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 413\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016570091247558594, 'bn1': 0.0005681514739990234, 'relu1': 0.0003261566162109375, 'conv2': 0.0016400814056396484, 'bn2': 0.0005383491516113281, 'residual_add_relu2': 0.0007724761962890625}\n",
      "{'conv1': 0.0016393661499023438, 'bn1': 0.0005469322204589844, 'relu1': 0.0003209114074707031, 'conv2': 0.0016357898712158203, 'bn2': 0.0005376338958740234, 'residual_add_relu2': 0.0007755756378173828}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010478496551513672, 'bn1': 0.0003132820129394531, 'relu1': 0.00017571449279785156, 'conv2': 0.0013191699981689453, 'bn2': 0.0003075599670410156, 'conv3': 0.00039768218994140625, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013151168823242188, 'bn1': 0.0003070831298828125, 'relu1': 0.00017118453979492188, 'conv2': 0.0013127326965332031, 'bn2': 0.00030517578125, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007889270782470703, 'bn1': 0.0001926422119140625, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011625289916992188, 'bn2': 0.000194549560546875, 'conv3': 0.0003521442413330078, 'residual_add_relu2': 0.00020432472229003906}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.00019407272338867188, 'relu1': 9.679794311523438e-05, 'conv2': 0.001157999038696289, 'bn2': 0.0001919269561767578, 'residual_add_relu2': 0.0002028942108154297}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006594657897949219, 'bn1': 0.00011730194091796875, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00010704994201660156, 'conv3': 0.0002887248992919922, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.0011515617370605469, 'bn1': 0.00011396408081054688, 'relu1': 5.698204040527344e-05, 'conv2': 0.001149892807006836, 'bn2': 0.00011491775512695312, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 414\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016491413116455078, 'bn1': 0.0005459785461425781, 'relu1': 0.0003230571746826172, 'conv2': 0.0016341209411621094, 'bn2': 0.0005333423614501953, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016396045684814453, 'bn1': 0.0005407333374023438, 'relu1': 0.00032258033752441406, 'conv2': 0.0016298294067382812, 'bn2': 0.0005400180816650391, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010497570037841797, 'bn1': 0.0003190040588378906, 'relu1': 0.00017261505126953125, 'conv2': 0.0013167858123779297, 'bn2': 0.0003190040588378906, 'conv3': 0.0004019737243652344, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.0013163089752197266, 'bn1': 0.00031375885009765625, 'relu1': 0.00017404556274414062, 'conv2': 0.0013167858123779297, 'bn2': 0.0003132820129394531, 'residual_add_relu2': 0.00039196014404296875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007889270782470703, 'bn1': 0.0001957416534423828, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011646747589111328, 'bn2': 0.00019097328186035156, 'conv3': 0.0003540515899658203, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011661052703857422, 'bn1': 0.00020003318786621094, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011622905731201172, 'bn2': 0.00018739700317382812, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006644725799560547, 'bn1': 0.00012755393981933594, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00011563301086425781, 'conv3': 0.0002911090850830078, 'residual_add_relu2': 0.00011229515075683594}\n",
      "{'conv1': 0.0011548995971679688, 'bn1': 0.00011968612670898438, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.0001266002655029297, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 415\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016629695892333984, 'bn1': 0.0005469322204589844, 'relu1': 0.0003223419189453125, 'conv2': 0.001642465591430664, 'bn2': 0.0006008148193359375, 'residual_add_relu2': 0.0007727146148681641}\n",
      "{'conv1': 0.0016627311706542969, 'bn1': 0.0005557537078857422, 'relu1': 0.0003273487091064453, 'conv2': 0.0016436576843261719, 'bn2': 0.0005500316619873047, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010564327239990234, 'bn1': 0.00032806396484375, 'relu1': 0.0001742839813232422, 'conv2': 0.0013227462768554688, 'bn2': 0.00031280517578125, 'conv3': 0.0004036426544189453, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013206005096435547, 'bn1': 0.00032591819763183594, 'relu1': 0.00017523765563964844, 'conv2': 0.0013167858123779297, 'bn2': 0.0003142356872558594, 'residual_add_relu2': 0.0003905296325683594}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008096694946289062, 'bn1': 0.0002079010009765625, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011653900146484375, 'bn2': 0.0001983642578125, 'conv3': 0.0003573894500732422, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.00116729736328125, 'bn1': 0.00024700164794921875, 'relu1': 0.00010180473327636719, 'conv2': 0.0011668205261230469, 'bn2': 0.0001952648162841797, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006620883941650391, 'bn1': 0.00011920928955078125, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011546611785888672, 'bn2': 0.00012135505676269531, 'conv3': 0.0003027915954589844, 'residual_add_relu2': 0.00011754035949707031}\n",
      "{'conv1': 0.0011630058288574219, 'bn1': 0.0001266002655029297, 'relu1': 6.008148193359375e-05, 'conv2': 0.00115203857421875, 'bn2': 0.000118255615234375, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 416\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016663074493408203, 'bn1': 0.0005555152893066406, 'relu1': 0.0003235340118408203, 'conv2': 0.00164031982421875, 'bn2': 0.00054931640625, 'residual_add_relu2': 0.0007669925689697266}\n",
      "{'conv1': 0.0016422271728515625, 'bn1': 0.0005464553833007812, 'relu1': 0.00032401084899902344, 'conv2': 0.0016405582427978516, 'bn2': 0.0005297660827636719, 'residual_add_relu2': 0.0007622241973876953}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010492801666259766, 'bn1': 0.0003101825714111328, 'relu1': 0.0001709461212158203, 'conv2': 0.0013110637664794922, 'bn2': 0.00029659271240234375, 'conv3': 0.0003921985626220703, 'residual_add_relu2': 0.0003879070281982422}\n",
      "{'conv1': 0.0013225078582763672, 'bn1': 0.00033164024353027344, 'relu1': 0.0001766681671142578, 'conv2': 0.0013217926025390625, 'bn2': 0.0003190040588378906, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008006095886230469, 'bn1': 0.00021505355834960938, 'relu1': 0.00010132789611816406, 'conv2': 0.0011696815490722656, 'bn2': 0.00020551681518554688, 'conv3': 0.0003597736358642578, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.0011742115020751953, 'bn1': 0.00022935867309570312, 'relu1': 0.00010228157043457031, 'conv2': 0.001171112060546875, 'bn2': 0.00020503997802734375, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006711483001708984, 'bn1': 0.00012135505676269531, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00011920928955078125, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.001161813735961914, 'bn1': 0.0001201629638671875, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00011277198791503906, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 417\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016558170318603516, 'bn1': 0.0005638599395751953, 'relu1': 0.000324249267578125, 'conv2': 0.0016405582427978516, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016484260559082031, 'bn1': 0.0005578994750976562, 'relu1': 0.0003249645233154297, 'conv2': 0.001641988754272461, 'bn2': 0.0005469322204589844, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010492801666259766, 'bn1': 0.00031447410583496094, 'relu1': 0.0001728534698486328, 'conv2': 0.001322031021118164, 'bn2': 0.0003139972686767578, 'conv3': 0.000400543212890625, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013172626495361328, 'bn1': 0.0003135204315185547, 'relu1': 0.0001728534698486328, 'conv2': 0.001316070556640625, 'bn2': 0.0003070831298828125, 'residual_add_relu2': 0.0003886222839355469}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007884502410888672, 'bn1': 0.00019216537475585938, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011599063873291016, 'bn2': 0.00018787384033203125, 'conv3': 0.00034880638122558594, 'residual_add_relu2': 0.00020647048950195312}\n",
      "{'conv1': 0.0011675357818603516, 'bn1': 0.0001971721649169922, 'relu1': 9.679794311523438e-05, 'conv2': 0.0011591911315917969, 'bn2': 0.00018858909606933594, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006601810455322266, 'bn1': 0.00011754035949707031, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011513233184814453, 'bn2': 0.00010919570922851562, 'conv3': 0.0002906322479248047, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.0011522769927978516, 'bn1': 0.00011515617370605469, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.00011157989501953125, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 418\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001665353775024414, 'bn1': 0.0005555152893066406, 'relu1': 0.0003247261047363281, 'conv2': 0.0016434192657470703, 'bn2': 0.0005400180816650391, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016474723815917969, 'bn1': 0.0005466938018798828, 'relu1': 0.00032448768615722656, 'conv2': 0.0016317367553710938, 'bn2': 0.0005459785461425781, 'residual_add_relu2': 0.000766754150390625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010519027709960938, 'bn1': 0.0003142356872558594, 'relu1': 0.000171661376953125, 'conv2': 0.0013208389282226562, 'bn2': 0.0003123283386230469, 'conv3': 0.00040340423583984375, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013191699981689453, 'bn1': 0.0003147125244140625, 'relu1': 0.0001735687255859375, 'conv2': 0.0013132095336914062, 'bn2': 0.00031256675720214844, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007925033569335938, 'bn1': 0.0001995563507080078, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011622905731201172, 'bn2': 0.00019311904907226562, 'conv3': 0.0003676414489746094, 'residual_add_relu2': 0.00020599365234375}\n",
      "{'conv1': 0.0011668205261230469, 'bn1': 0.00019359588623046875, 'relu1': 9.5367431640625e-05, 'conv2': 0.0011587142944335938, 'bn2': 0.0002028942108154297, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006649494171142578, 'bn1': 0.0001361370086669922, 'relu1': 6.103515625e-05, 'conv2': 0.0011577606201171875, 'bn2': 0.00011610984802246094, 'conv3': 0.0002949237823486328, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011582374572753906, 'bn1': 0.00012230873107910156, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.00012493133544921875, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 419\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016586780548095703, 'bn1': 0.0005543231964111328, 'relu1': 0.0003247261047363281, 'conv2': 0.0016436576843261719, 'bn2': 0.0005452632904052734, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016515254974365234, 'bn1': 0.0005450248718261719, 'relu1': 0.00032401084899902344, 'conv2': 0.0016412734985351562, 'bn2': 0.0005373954772949219, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010576248168945312, 'bn1': 0.00031948089599609375, 'relu1': 0.0001735687255859375, 'conv2': 0.0013163089752197266, 'bn2': 0.0003101825714111328, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.0003941059112548828}\n",
      "{'conv1': 0.0013184547424316406, 'bn1': 0.00031685829162597656, 'relu1': 0.00017380714416503906, 'conv2': 0.001314401626586914, 'bn2': 0.000308990478515625, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007920265197753906, 'bn1': 0.0002586841583251953, 'relu1': 9.942054748535156e-05, 'conv2': 0.001165628433227539, 'bn2': 0.0001957416534423828, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011661052703857422, 'bn1': 0.0001990795135498047, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011639595031738281, 'bn2': 0.00020623207092285156, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006642341613769531, 'bn1': 0.00012183189392089844, 'relu1': 6.461143493652344e-05, 'conv2': 0.0011548995971679688, 'bn2': 0.00010895729064941406, 'conv3': 0.00028824806213378906, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011625289916992188, 'bn1': 0.00011539459228515625, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.00011801719665527344, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 420\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016639232635498047, 'bn1': 0.0005509853363037109, 'relu1': 0.0003237724304199219, 'conv2': 0.001638174057006836, 'bn2': 0.0005524158477783203, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.0016410350799560547, 'bn1': 0.0005521774291992188, 'relu1': 0.00032448768615722656, 'conv2': 0.001634836196899414, 'bn2': 0.0005390644073486328, 'residual_add_relu2': 0.0007615089416503906}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010504722595214844, 'bn1': 0.000316619873046875, 'relu1': 0.00017261505126953125, 'conv2': 0.0013206005096435547, 'bn2': 0.00031876564025878906, 'conv3': 0.0004062652587890625, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013284683227539062, 'bn1': 0.00033283233642578125, 'relu1': 0.00017786026000976562, 'conv2': 0.001323699951171875, 'bn2': 0.0003197193145751953, 'residual_add_relu2': 0.00039196014404296875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008060932159423828, 'bn1': 0.0002739429473876953, 'relu1': 0.00011014938354492188, 'conv2': 0.0011811256408691406, 'bn2': 0.0002167224884033203, 'conv3': 0.0003840923309326172, 'residual_add_relu2': 0.0002086162567138672}\n",
      "{'conv1': 0.0011782646179199219, 'bn1': 0.00023317337036132812, 'relu1': 0.00010228157043457031, 'conv2': 0.0011703968048095703, 'bn2': 0.00020647048950195312, 'residual_add_relu2': 0.00020623207092285156}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006754398345947266, 'bn1': 0.00013709068298339844, 'relu1': 6.29425048828125e-05, 'conv2': 0.001161813735961914, 'bn2': 0.0001316070556640625, 'conv3': 0.0002987384796142578, 'residual_add_relu2': 0.00011324882507324219}\n",
      "{'conv1': 0.0011620521545410156, 'bn1': 0.0001327991485595703, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011601448059082031, 'bn2': 0.0001239776611328125, 'residual_add_relu2': 0.0001125335693359375}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 421\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016558170318603516, 'bn1': 0.0005719661712646484, 'relu1': 0.0003254413604736328, 'conv2': 0.0016450881958007812, 'bn2': 0.0005667209625244141, 'residual_add_relu2': 0.0007698535919189453}\n",
      "{'conv1': 0.001641988754272461, 'bn1': 0.0005471706390380859, 'relu1': 0.00032329559326171875, 'conv2': 0.0016489028930664062, 'bn2': 0.0005555152893066406, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010552406311035156, 'bn1': 0.00031828880310058594, 'relu1': 0.0001735687255859375, 'conv2': 0.001318216323852539, 'bn2': 0.0003116130828857422, 'conv3': 0.0003979206085205078, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013165473937988281, 'bn1': 0.0003151893615722656, 'relu1': 0.00017499923706054688, 'conv2': 0.0013132095336914062, 'bn2': 0.00031185150146484375, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007929801940917969, 'bn1': 0.00019812583923339844, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011746883392333984, 'bn2': 0.0001990795135498047, 'conv3': 0.0003535747528076172, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0011641979217529297, 'bn1': 0.0002009868621826172, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011620521545410156, 'bn2': 0.0002071857452392578, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006659030914306641, 'bn1': 0.0001227855682373047, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00011467933654785156, 'conv3': 0.00029397010803222656, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.0011568069458007812, 'bn1': 0.00012445449829101562, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00014328956604003906, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 422\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016651153564453125, 'bn1': 0.0005831718444824219, 'relu1': 0.0003304481506347656, 'conv2': 0.0016527175903320312, 'bn2': 0.0005595684051513672, 'residual_add_relu2': 0.0007712841033935547}\n",
      "{'conv1': 0.001651763916015625, 'bn1': 0.0005609989166259766, 'relu1': 0.00032711029052734375, 'conv2': 0.0016405582427978516, 'bn2': 0.0005552768707275391, 'residual_add_relu2': 0.0007688999176025391}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010592937469482422, 'bn1': 0.00032830238342285156, 'relu1': 0.0001761913299560547, 'conv2': 0.0013227462768554688, 'bn2': 0.0003268718719482422, 'conv3': 0.0004107952117919922, 'residual_add_relu2': 0.0003936290740966797}\n",
      "{'conv1': 0.0013246536254882812, 'bn1': 0.0003268718719482422, 'relu1': 0.00017642974853515625, 'conv2': 0.0013203620910644531, 'bn2': 0.0003235340118408203, 'residual_add_relu2': 0.0003917217254638672}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008003711700439453, 'bn1': 0.0002129077911376953, 'relu1': 0.00010204315185546875, 'conv2': 0.0011706352233886719, 'bn2': 0.0002071857452392578, 'conv3': 0.0003726482391357422, 'residual_add_relu2': 0.00020766258239746094}\n",
      "{'conv1': 0.0011734962463378906, 'bn1': 0.0002148151397705078, 'relu1': 0.00010204315185546875, 'conv2': 0.001169443130493164, 'bn2': 0.00020647048950195312, 'residual_add_relu2': 0.00020647048950195312}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006709098815917969, 'bn1': 0.0001468658447265625, 'relu1': 6.389617919921875e-05, 'conv2': 0.001163482666015625, 'bn2': 0.00012946128845214844, 'conv3': 0.0003025531768798828, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.0011632442474365234, 'bn1': 0.00013494491577148438, 'relu1': 6.151199340820312e-05, 'conv2': 0.0011591911315917969, 'bn2': 0.00014710426330566406, 'residual_add_relu2': 0.00011372566223144531}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 423\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001672983169555664, 'bn1': 0.0005614757537841797, 'relu1': 0.0003254413604736328, 'conv2': 0.0016422271728515625, 'bn2': 0.0005500316619873047, 'residual_add_relu2': 0.0007686614990234375}\n",
      "{'conv1': 0.0016415119171142578, 'bn1': 0.0005488395690917969, 'relu1': 0.0003237724304199219, 'conv2': 0.0016396045684814453, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007653236389160156}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001066446304321289, 'bn1': 0.0003192424774169922, 'relu1': 0.00017309188842773438, 'conv2': 0.0013194084167480469, 'bn2': 0.0003075599670410156, 'conv3': 0.0004038810729980469, 'residual_add_relu2': 0.0003886222839355469}\n",
      "{'conv1': 0.0013189315795898438, 'bn1': 0.0003139972686767578, 'relu1': 0.00017333030700683594, 'conv2': 0.001313924789428711, 'bn2': 0.00030803680419921875, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007903575897216797, 'bn1': 0.0002028942108154297, 'relu1': 9.918212890625e-05, 'conv2': 0.0011668205261230469, 'bn2': 0.0001976490020751953, 'conv3': 0.000354766845703125, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.001165151596069336, 'bn1': 0.0002033710479736328, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011630058288574219, 'bn2': 0.0001957416534423828, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006647109985351562, 'bn1': 0.00012493133544921875, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011785030364990234, 'bn2': 0.00014853477478027344, 'conv3': 0.0003025531768798828, 'residual_add_relu2': 0.00011134147644042969}\n",
      "{'conv1': 0.001157522201538086, 'bn1': 0.0001232624053955078, 'relu1': 5.936622619628906e-05, 'conv2': 0.00115203857421875, 'bn2': 0.00011777877807617188, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 424\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016622543334960938, 'bn1': 0.0005557537078857422, 'relu1': 0.000324249267578125, 'conv2': 0.0016367435455322266, 'bn2': 0.0005624294281005859, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016417503356933594, 'bn1': 0.0005588531494140625, 'relu1': 0.00032448768615722656, 'conv2': 0.0016398429870605469, 'bn2': 0.0005376338958740234, 'residual_add_relu2': 0.0007648468017578125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010600090026855469, 'bn1': 0.0003173351287841797, 'relu1': 0.00017333030700683594, 'conv2': 0.001317739486694336, 'bn2': 0.00030612945556640625, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.0003955364227294922}\n",
      "{'conv1': 0.0013277530670166016, 'bn1': 0.000316619873046875, 'relu1': 0.00017380714416503906, 'conv2': 0.0013155937194824219, 'bn2': 0.0003094673156738281, 'residual_add_relu2': 0.00039267539978027344}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008046627044677734, 'bn1': 0.0002033710479736328, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011641979217529297, 'bn2': 0.00019478797912597656, 'conv3': 0.00035381317138671875, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011677742004394531, 'bn1': 0.0002129077911376953, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011653900146484375, 'bn2': 0.000194549560546875, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006730556488037109, 'bn1': 0.0001475811004638672, 'relu1': 6.175041198730469e-05, 'conv2': 0.0011591911315917969, 'bn2': 0.0001468658447265625, 'conv3': 0.0003066062927246094, 'residual_add_relu2': 0.00011301040649414062}\n",
      "{'conv1': 0.001161813735961914, 'bn1': 0.00012254714965820312, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.00011444091796875, 'residual_add_relu2': 0.00011229515075683594}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 425\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001645803451538086, 'bn1': 0.0005681514739990234, 'relu1': 0.000324249267578125, 'conv2': 0.001634359359741211, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016415119171142578, 'bn1': 0.0005595684051513672, 'relu1': 0.00032520294189453125, 'conv2': 0.0016427040100097656, 'bn2': 0.0005524158477783203, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010514259338378906, 'bn1': 0.00031375885009765625, 'relu1': 0.0001728534698486328, 'conv2': 0.0013194084167480469, 'bn2': 0.0003139972686767578, 'conv3': 0.000400543212890625, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013184547424316406, 'bn1': 0.0003094673156738281, 'relu1': 0.0001723766326904297, 'conv2': 0.0013127326965332031, 'bn2': 0.0003113746643066406, 'residual_add_relu2': 0.0003876686096191406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007927417755126953, 'bn1': 0.00019097328186035156, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.00018596649169921875, 'conv3': 0.00035190582275390625, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.0011668205261230469, 'bn1': 0.0001952648162841797, 'relu1': 9.584426879882812e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.00018644332885742188, 'residual_add_relu2': 0.0002033710479736328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006613731384277344, 'bn1': 0.00011968612670898438, 'relu1': 5.793571472167969e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00010919570922851562, 'conv3': 0.0002872943878173828, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.0011525154113769531, 'bn1': 0.00012135505676269531, 'relu1': 5.91278076171875e-05, 'conv2': 0.00115203857421875, 'bn2': 0.00011944770812988281, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 426\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0018620491027832031, 'bn1': 0.0007948875427246094, 'relu1': 0.0003781318664550781, 'conv2': 0.0017285346984863281, 'bn2': 0.0005495548248291016, 'residual_add_relu2': 0.0007648468017578125}\n",
      "{'conv1': 0.0016391277313232422, 'bn1': 0.0005550384521484375, 'relu1': 0.000324249267578125, 'conv2': 0.0016410350799560547, 'bn2': 0.0005404949188232422, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010573863983154297, 'bn1': 0.0003185272216796875, 'relu1': 0.00017213821411132812, 'conv2': 0.0013163089752197266, 'bn2': 0.0003037452697753906, 'conv3': 0.0003993511199951172, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013155937194824219, 'bn1': 0.00033855438232421875, 'relu1': 0.0001735687255859375, 'conv2': 0.001312255859375, 'bn2': 0.00030517578125, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000797271728515625, 'bn1': 0.00020265579223632812, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011661052703857422, 'bn2': 0.00019669532775878906, 'conv3': 0.0003533363342285156, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011632442474365234, 'bn1': 0.00020432472229003906, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011627674102783203, 'bn2': 0.00018930435180664062, 'residual_add_relu2': 0.0002033710479736328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006632804870605469, 'bn1': 0.00012755393981933594, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011563301086425781, 'bn2': 0.00012612342834472656, 'conv3': 0.00029277801513671875, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011584758758544922, 'bn1': 0.00012302398681640625, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.0001163482666015625, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 427\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016520023345947266, 'bn1': 0.0005540847778320312, 'relu1': 0.00032401084899902344, 'conv2': 0.001638174057006836, 'bn2': 0.0005342960357666016, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016355514526367188, 'bn1': 0.0005352497100830078, 'relu1': 0.00032067298889160156, 'conv2': 0.0016345977783203125, 'bn2': 0.0005347728729248047, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010471343994140625, 'bn1': 0.0003075599670410156, 'relu1': 0.00016999244689941406, 'conv2': 0.0013132095336914062, 'bn2': 0.0003032684326171875, 'conv3': 0.0003960132598876953, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.001313924789428711, 'bn1': 0.0003066062927246094, 'relu1': 0.00017404556274414062, 'conv2': 0.0013155937194824219, 'bn2': 0.0003094673156738281, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007941722869873047, 'bn1': 0.00019311904907226562, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011589527130126953, 'bn2': 0.00020360946655273438, 'conv3': 0.0003552436828613281, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.001161813735961914, 'bn1': 0.000194549560546875, 'relu1': 9.584426879882812e-05, 'conv2': 0.0011591911315917969, 'bn2': 0.0001881122589111328, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.000659942626953125, 'bn1': 0.0001220703125, 'relu1': 6.103515625e-05, 'conv2': 0.0011644363403320312, 'bn2': 0.00011038780212402344, 'conv3': 0.0002906322479248047, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.001153707504272461, 'bn1': 0.00011444091796875, 'relu1': 5.745887756347656e-05, 'conv2': 0.001149892807006836, 'bn2': 0.00011229515075683594, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 428\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001653432846069336, 'bn1': 0.0005543231964111328, 'relu1': 0.0003235340118408203, 'conv2': 0.00164031982421875, 'bn2': 0.0005424022674560547, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016469955444335938, 'bn1': 0.0005381107330322266, 'relu1': 0.00032019615173339844, 'conv2': 0.0016293525695800781, 'bn2': 0.0005345344543457031, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010514259338378906, 'bn1': 0.0003223419189453125, 'relu1': 0.0001735687255859375, 'conv2': 0.001317739486694336, 'bn2': 0.0003101825714111328, 'conv3': 0.0003991127014160156, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013165473937988281, 'bn1': 0.0003070831298828125, 'relu1': 0.00017070770263671875, 'conv2': 0.001312255859375, 'bn2': 0.0003116130828857422, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007920265197753906, 'bn1': 0.00019311904907226562, 'relu1': 9.799003601074219e-05, 'conv2': 0.001161336898803711, 'bn2': 0.000186920166015625, 'conv3': 0.00034999847412109375, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011646747589111328, 'bn1': 0.00019431114196777344, 'relu1': 9.703636169433594e-05, 'conv2': 0.0011587142944335938, 'bn2': 0.0001876354217529297, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.00066375732421875, 'bn1': 0.00012421607971191406, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00011777877807617188, 'conv3': 0.00029349327087402344, 'residual_add_relu2': 0.00011038780212402344}\n",
      "{'conv1': 0.0011532306671142578, 'bn1': 0.00011420249938964844, 'relu1': 5.745887756347656e-05, 'conv2': 0.001173257827758789, 'bn2': 0.00021219253540039062, 'residual_add_relu2': 0.00011873245239257812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 429\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016548633575439453, 'bn1': 0.0005474090576171875, 'relu1': 0.00032258033752441406, 'conv2': 0.0016491413116455078, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016422271728515625, 'bn1': 0.0005407333374023438, 'relu1': 0.0003218650817871094, 'conv2': 0.0016374588012695312, 'bn2': 0.0005407333374023438, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010497570037841797, 'bn1': 0.0003230571746826172, 'relu1': 0.00017309188842773438, 'conv2': 0.0013172626495361328, 'bn2': 0.0003085136413574219, 'conv3': 0.00040030479431152344, 'residual_add_relu2': 0.0003883838653564453}\n",
      "{'conv1': 0.001314401626586914, 'bn1': 0.0003159046173095703, 'relu1': 0.0001728534698486328, 'conv2': 0.0013151168823242188, 'bn2': 0.00030875205993652344, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007927417755126953, 'bn1': 0.00020623207092285156, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011639595031738281, 'bn2': 0.00019478797912597656, 'conv3': 0.000354766845703125, 'residual_add_relu2': 0.00020647048950195312}\n",
      "{'conv1': 0.0011677742004394531, 'bn1': 0.0002040863037109375, 'relu1': 9.775161743164062e-05, 'conv2': 0.00115966796875, 'bn2': 0.00019216537475585938, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006601810455322266, 'bn1': 0.00011396408081054688, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011508464813232422, 'bn2': 0.0001087188720703125, 'conv3': 0.0002899169921875, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011525154113769531, 'bn1': 0.00012302398681640625, 'relu1': 5.8650970458984375e-05, 'conv2': 0.001149892807006836, 'bn2': 0.00010752677917480469, 'residual_add_relu2': 0.00010824203491210938}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 430\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016751289367675781, 'bn1': 0.0005698204040527344, 'relu1': 0.0003275871276855469, 'conv2': 0.0016438961029052734, 'bn2': 0.0005586147308349609, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.0016467571258544922, 'bn1': 0.0005578994750976562, 'relu1': 0.0003247261047363281, 'conv2': 0.0016434192657470703, 'bn2': 0.0005421638488769531, 'residual_add_relu2': 0.0007662773132324219}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010671615600585938, 'bn1': 0.0003185272216796875, 'relu1': 0.0001728534698486328, 'conv2': 0.0013194084167480469, 'bn2': 0.0003104209899902344, 'conv3': 0.0004017353057861328, 'residual_add_relu2': 0.00039196014404296875}\n",
      "{'conv1': 0.0013222694396972656, 'bn1': 0.0003161430358886719, 'relu1': 0.00017380714416503906, 'conv2': 0.0013153553009033203, 'bn2': 0.0003101825714111328, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007951259613037109, 'bn1': 0.00020456314086914062, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011658668518066406, 'bn2': 0.00019598007202148438, 'conv3': 0.0003783702850341797, 'residual_add_relu2': 0.0002071857452392578}\n",
      "{'conv1': 0.0011696815490722656, 'bn1': 0.0002040863037109375, 'relu1': 9.822845458984375e-05, 'conv2': 0.0011630058288574219, 'bn2': 0.00020003318786621094, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006651878356933594, 'bn1': 0.00012636184692382812, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011606216430664062, 'bn2': 0.00012302398681640625, 'conv3': 0.0002982616424560547, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011568069458007812, 'bn1': 0.0001201629638671875, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.00011491775512695312, 'residual_add_relu2': 0.00011110305786132812}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 431\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016624927520751953, 'bn1': 0.0005588531494140625, 'relu1': 0.00032401084899902344, 'conv2': 0.0016410350799560547, 'bn2': 0.0005419254302978516, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016446113586425781, 'bn1': 0.0005452632904052734, 'relu1': 0.00032329559326171875, 'conv2': 0.0016407966613769531, 'bn2': 0.0005438327789306641, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010535717010498047, 'bn1': 0.00032591819763183594, 'relu1': 0.00017523765563964844, 'conv2': 0.0013337135314941406, 'bn2': 0.00031685829162597656, 'conv3': 0.0003986358642578125, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.001316070556640625, 'bn1': 0.0003151893615722656, 'relu1': 0.00018286705017089844, 'conv2': 0.0013279914855957031, 'bn2': 0.000316619873046875, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007915496826171875, 'bn1': 0.00019979476928710938, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011646747589111328, 'bn2': 0.0002219676971435547, 'conv3': 0.0003600120544433594, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011668205261230469, 'bn1': 0.00020051002502441406, 'relu1': 9.72747802734375e-05, 'conv2': 0.001161813735961914, 'bn2': 0.00019884109497070312, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006642341613769531, 'bn1': 0.0001227855682373047, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00011539459228515625, 'conv3': 0.000293731689453125, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011632442474365234, 'bn1': 0.00012731552124023438, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011508464813232422, 'bn2': 0.0001087188720703125, 'residual_add_relu2': 0.00011014938354492188}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 432\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016546249389648438, 'bn1': 0.0005526542663574219, 'relu1': 0.0003237724304199219, 'conv2': 0.0016336441040039062, 'bn2': 0.0005364418029785156, 'residual_add_relu2': 0.0007638931274414062}\n",
      "{'conv1': 0.0016331672668457031, 'bn1': 0.0005352497100830078, 'relu1': 0.0003197193145751953, 'conv2': 0.0016300678253173828, 'bn2': 0.0005376338958740234, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010516643524169922, 'bn1': 0.0003273487091064453, 'relu1': 0.00017452239990234375, 'conv2': 0.0013184547424316406, 'bn2': 0.0003101825714111328, 'conv3': 0.00040459632873535156, 'residual_add_relu2': 0.00039196014404296875}\n",
      "{'conv1': 0.0013201236724853516, 'bn1': 0.0003197193145751953, 'relu1': 0.00017333030700683594, 'conv2': 0.0013155937194824219, 'bn2': 0.0003085136413574219, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007925033569335938, 'bn1': 0.00020241737365722656, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011632442474365234, 'bn2': 0.0002071857452392578, 'conv3': 0.00035309791564941406, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011641979217529297, 'bn1': 0.0001938343048095703, 'relu1': 9.584426879882812e-05, 'conv2': 0.0011599063873291016, 'bn2': 0.0002110004425048828, 'residual_add_relu2': 0.00020694732666015625}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006654262542724609, 'bn1': 0.00012612342834472656, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.00011491775512695312, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011572837829589844, 'bn1': 0.0001246929168701172, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00011205673217773438, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 433\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016624927520751953, 'bn1': 0.0005438327789306641, 'relu1': 0.00032210350036621094, 'conv2': 0.0016362667083740234, 'bn2': 0.0005345344543457031, 'residual_add_relu2': 0.0007643699645996094}\n",
      "{'conv1': 0.0016338825225830078, 'bn1': 0.000545501708984375, 'relu1': 0.0003218650817871094, 'conv2': 0.0016355514526367188, 'bn2': 0.000530242919921875, 'residual_add_relu2': 0.0007655620574951172}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010476112365722656, 'bn1': 0.0003032684326171875, 'relu1': 0.0001704692840576172, 'conv2': 0.001312255859375, 'bn2': 0.00029921531677246094, 'conv3': 0.00039386749267578125, 'residual_add_relu2': 0.0003914833068847656}\n",
      "{'conv1': 0.0013184547424316406, 'bn1': 0.0003070831298828125, 'relu1': 0.0001709461212158203, 'conv2': 0.0013089179992675781, 'bn2': 0.00029969215393066406, 'residual_add_relu2': 0.0003960132598876953}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007917881011962891, 'bn1': 0.00019168853759765625, 'relu1': 9.584426879882812e-05, 'conv2': 0.0011594295501708984, 'bn2': 0.0001850128173828125, 'conv3': 0.0003466606140136719, 'residual_add_relu2': 0.00020241737365722656}\n",
      "{'conv1': 0.001161336898803711, 'bn1': 0.0002014636993408203, 'relu1': 9.655952453613281e-05, 'conv2': 0.00115966796875, 'bn2': 0.00018596649169921875, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006573200225830078, 'bn1': 0.00011181831359863281, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.0001246929168701172, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00010943412780761719}\n",
      "{'conv1': 0.00115203857421875, 'bn1': 0.0001163482666015625, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.0001246929168701172, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 434\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016536712646484375, 'bn1': 0.0005435943603515625, 'relu1': 0.0003209114074707031, 'conv2': 0.0016357898712158203, 'bn2': 0.0005440711975097656, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016410350799560547, 'bn1': 0.0005376338958740234, 'relu1': 0.0003337860107421875, 'conv2': 0.0016331672668457031, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010535717010498047, 'bn1': 0.00031685829162597656, 'relu1': 0.00017547607421875, 'conv2': 0.0013213157653808594, 'bn2': 0.0003097057342529297, 'conv3': 0.00040078163146972656, 'residual_add_relu2': 0.0003921985626220703}\n",
      "{'conv1': 0.0013189315795898438, 'bn1': 0.00031566619873046875, 'relu1': 0.00017333030700683594, 'conv2': 0.0013136863708496094, 'bn2': 0.0003085136413574219, 'residual_add_relu2': 0.0003993511199951172}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008018016815185547, 'bn1': 0.00019979476928710938, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011639595031738281, 'bn2': 0.00018739700317382812, 'conv3': 0.0003490447998046875, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.001161813735961914, 'bn1': 0.00019621849060058594, 'relu1': 9.5367431640625e-05, 'conv2': 0.001157522201538086, 'bn2': 0.0001876354217529297, 'residual_add_relu2': 0.0002033710479736328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006608963012695312, 'bn1': 0.00011897087097167969, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00011324882507324219, 'conv3': 0.00029206275939941406, 'residual_add_relu2': 0.00010967254638671875}\n",
      "{'conv1': 0.0011529922485351562, 'bn1': 0.00012135505676269531, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.00011777877807617188, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 435\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001667022705078125, 'bn1': 0.0005588531494140625, 'relu1': 0.00032901763916015625, 'conv2': 0.0016431808471679688, 'bn2': 0.0005393028259277344, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016422271728515625, 'bn1': 0.0005438327789306641, 'relu1': 0.0003211498260498047, 'conv2': 0.001638174057006836, 'bn2': 0.0005338191986083984, 'residual_add_relu2': 0.0007660388946533203}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010509490966796875, 'bn1': 0.0003094673156738281, 'relu1': 0.0001709461212158203, 'conv2': 0.001313924789428711, 'bn2': 0.0003027915954589844, 'conv3': 0.00040459632873535156, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013172626495361328, 'bn1': 0.0003178119659423828, 'relu1': 0.00017309188842773438, 'conv2': 0.0013132095336914062, 'bn2': 0.00031375885009765625, 'residual_add_relu2': 0.0003898143768310547}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007905960083007812, 'bn1': 0.00019025802612304688, 'relu1': 9.751319885253906e-05, 'conv2': 0.00115966796875, 'bn2': 0.00018858909606933594, 'conv3': 0.0003490447998046875, 'residual_add_relu2': 0.00020241737365722656}\n",
      "{'conv1': 0.001178741455078125, 'bn1': 0.00020051002502441406, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011594295501708984, 'bn2': 0.00018596649169921875, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006582736968994141, 'bn1': 0.00011229515075683594, 'relu1': 5.7220458984375e-05, 'conv2': 0.0011508464813232422, 'bn2': 0.00011777877807617188, 'conv3': 0.0002932548522949219, 'residual_add_relu2': 0.00010919570922851562}\n",
      "{'conv1': 0.00115203857421875, 'bn1': 0.00011014938354492188, 'relu1': 5.6743621826171875e-05, 'conv2': 0.0011487007141113281, 'bn2': 0.00011539459228515625, 'residual_add_relu2': 0.00010943412780761719}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 436\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016601085662841797, 'bn1': 0.0005621910095214844, 'relu1': 0.0003268718719482422, 'conv2': 0.0016467571258544922, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007691383361816406}\n",
      "{'conv1': 0.001641988754272461, 'bn1': 0.0005514621734619141, 'relu1': 0.0003228187561035156, 'conv2': 0.00164031982421875, 'bn2': 0.0005457401275634766, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001054525375366211, 'bn1': 0.0003170967102050781, 'relu1': 0.00017309188842773438, 'conv2': 0.0013179779052734375, 'bn2': 0.0003185272216796875, 'conv3': 0.00040531158447265625, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013201236724853516, 'bn1': 0.0003204345703125, 'relu1': 0.0001773834228515625, 'conv2': 0.0013175010681152344, 'bn2': 0.00031280517578125, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007944107055664062, 'bn1': 0.0002033710479736328, 'relu1': 0.00010085105895996094, 'conv2': 0.0011675357818603516, 'bn2': 0.00022363662719726562, 'conv3': 0.0003654956817626953, 'residual_add_relu2': 0.00020742416381835938}\n",
      "{'conv1': 0.0011730194091796875, 'bn1': 0.0002117156982421875, 'relu1': 0.0001010894775390625, 'conv2': 0.0011675357818603516, 'bn2': 0.00020766258239746094, 'residual_add_relu2': 0.0002071857452392578}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006730556488037109, 'bn1': 0.00013685226440429688, 'relu1': 6.246566772460938e-05, 'conv2': 0.0011627674102783203, 'bn2': 0.00011730194091796875, 'conv3': 0.0002961158752441406, 'residual_add_relu2': 0.00011229515075683594}\n",
      "{'conv1': 0.0011599063873291016, 'bn1': 0.00013065338134765625, 'relu1': 6.29425048828125e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00011944770812988281, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 437\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016684532165527344, 'bn1': 0.000560760498046875, 'relu1': 0.0003256797790527344, 'conv2': 0.0016460418701171875, 'bn2': 0.0005424022674560547, 'residual_add_relu2': 0.0007681846618652344}\n",
      "{'conv1': 0.0016422271728515625, 'bn1': 0.0005581378936767578, 'relu1': 0.00032591819763183594, 'conv2': 0.001638174057006836, 'bn2': 0.0005383491516113281, 'residual_add_relu2': 0.000766754150390625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010526180267333984, 'bn1': 0.000316619873046875, 'relu1': 0.0001728534698486328, 'conv2': 0.0013191699981689453, 'bn2': 0.0003104209899902344, 'conv3': 0.00040459632873535156, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013175010681152344, 'bn1': 0.0003151893615722656, 'relu1': 0.0001742839813232422, 'conv2': 0.0013172626495361328, 'bn2': 0.0003139972686767578, 'residual_add_relu2': 0.00039196014404296875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007948875427246094, 'bn1': 0.00020194053649902344, 'relu1': 9.918212890625e-05, 'conv2': 0.001165151596069336, 'bn2': 0.00019693374633789062, 'conv3': 0.0003552436828613281, 'residual_add_relu2': 0.00020551681518554688}\n",
      "{'conv1': 0.0012545585632324219, 'bn1': 0.00021076202392578125, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011632442474365234, 'bn2': 0.00019598007202148438, 'residual_add_relu2': 0.00020623207092285156}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006642341613769531, 'bn1': 0.0001251697540283203, 'relu1': 6.151199340820312e-05, 'conv2': 0.0011594295501708984, 'bn2': 0.00011897087097167969, 'conv3': 0.00029587745666503906, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011587142944335938, 'bn1': 0.00012493133544921875, 'relu1': 6.103515625e-05, 'conv2': 0.001153707504272461, 'bn2': 0.00012302398681640625, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 438\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001661062240600586, 'bn1': 0.0005664825439453125, 'relu1': 0.0003249645233154297, 'conv2': 0.0016372203826904297, 'bn2': 0.0005590915679931641, 'residual_add_relu2': 0.0007708072662353516}\n",
      "{'conv1': 0.0016527175903320312, 'bn1': 0.0005691051483154297, 'relu1': 0.00032782554626464844, 'conv2': 0.0016438961029052734, 'bn2': 0.0005459785461425781, 'residual_add_relu2': 0.0007724761962890625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010561943054199219, 'bn1': 0.0003211498260498047, 'relu1': 0.00017547607421875, 'conv2': 0.0013267993927001953, 'bn2': 0.0003216266632080078, 'conv3': 0.00044035911560058594, 'residual_add_relu2': 0.0003981590270996094}\n",
      "{'conv1': 0.0013306140899658203, 'bn1': 0.0003216266632080078, 'relu1': 0.00017571449279785156, 'conv2': 0.0013167858123779297, 'bn2': 0.00031828880310058594, 'residual_add_relu2': 0.00039386749267578125}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007965564727783203, 'bn1': 0.00020599365234375, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011696815490722656, 'bn2': 0.00020360946655273438, 'conv3': 0.0003597736358642578, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.001172780990600586, 'bn1': 0.0002167224884033203, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011665821075439453, 'bn2': 0.0002028942108154297, 'residual_add_relu2': 0.00020503997802734375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006687641143798828, 'bn1': 0.00013184547424316406, 'relu1': 6.127357482910156e-05, 'conv2': 0.0011591911315917969, 'bn2': 0.00012803077697753906, 'conv3': 0.00030422210693359375, 'residual_add_relu2': 0.00011277198791503906}\n",
      "{'conv1': 0.0011589527130126953, 'bn1': 0.0001277923583984375, 'relu1': 6.222724914550781e-05, 'conv2': 0.0011551380157470703, 'bn2': 0.0001227855682373047, 'residual_add_relu2': 0.00011324882507324219}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 439\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016605854034423828, 'bn1': 0.0006031990051269531, 'relu1': 0.00032830238342285156, 'conv2': 0.0016412734985351562, 'bn2': 0.0005469322204589844, 'residual_add_relu2': 0.0007688999176025391}\n",
      "{'conv1': 0.0016477108001708984, 'bn1': 0.0005447864532470703, 'relu1': 0.0003223419189453125, 'conv2': 0.0016376972198486328, 'bn2': 0.0005450248718261719, 'residual_add_relu2': 0.0007627010345458984}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010530948638916016, 'bn1': 0.0003192424774169922, 'relu1': 0.000171661376953125, 'conv2': 0.001317739486694336, 'bn2': 0.0003151893615722656, 'conv3': 0.0004017353057861328, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.0013179779052734375, 'bn1': 0.0003159046173095703, 'relu1': 0.0001742839813232422, 'conv2': 0.001317739486694336, 'bn2': 0.00031304359436035156, 'residual_add_relu2': 0.0003921985626220703}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007932186126708984, 'bn1': 0.00020074844360351562, 'relu1': 9.918212890625e-05, 'conv2': 0.0011658668518066406, 'bn2': 0.00020503997802734375, 'conv3': 0.00035643577575683594, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.00116729736328125, 'bn1': 0.00020194053649902344, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011630058288574219, 'bn2': 0.00019598007202148438, 'residual_add_relu2': 0.00020623207092285156}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006673336029052734, 'bn1': 0.00012731552124023438, 'relu1': 6.008148193359375e-05, 'conv2': 0.001155853271484375, 'bn2': 0.00011706352233886719, 'conv3': 0.00029349327087402344, 'residual_add_relu2': 0.0001125335693359375}\n",
      "{'conv1': 0.0011577606201171875, 'bn1': 0.00014638900756835938, 'relu1': 6.198883056640625e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.00011754035949707031, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 440\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016679763793945312, 'bn1': 0.0005822181701660156, 'relu1': 0.0003275871276855469, 'conv2': 0.0016467571258544922, 'bn2': 0.0005614757537841797, 'residual_add_relu2': 0.0007677078247070312}\n",
      "{'conv1': 0.0016431808471679688, 'bn1': 0.0005500316619873047, 'relu1': 0.00032520294189453125, 'conv2': 0.0016372203826904297, 'bn2': 0.0005426406860351562, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010533332824707031, 'bn1': 0.0003216266632080078, 'relu1': 0.00017380714416503906, 'conv2': 0.0013217926025390625, 'bn2': 0.00030994415283203125, 'conv3': 0.0004050731658935547, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013196468353271484, 'bn1': 0.0003249645233154297, 'relu1': 0.00017499923706054688, 'conv2': 0.0013201236724853516, 'bn2': 0.0003113746643066406, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000797271728515625, 'bn1': 0.0002067089080810547, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011677742004394531, 'bn2': 0.00019788742065429688, 'conv3': 0.0003561973571777344, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011668205261230469, 'bn1': 0.00022554397583007812, 'relu1': 0.00010156631469726562, 'conv2': 0.0011644363403320312, 'bn2': 0.0001995563507080078, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006639957427978516, 'bn1': 0.00012636184692382812, 'relu1': 6.031990051269531e-05, 'conv2': 0.0011568069458007812, 'bn2': 0.00011801719665527344, 'conv3': 0.0002970695495605469, 'residual_add_relu2': 0.00011348724365234375}\n",
      "{'conv1': 0.0011610984802246094, 'bn1': 0.00012350082397460938, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011532306671142578, 'bn2': 0.00011467933654785156, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 441\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016710758209228516, 'bn1': 0.0005586147308349609, 'relu1': 0.00032591819763183594, 'conv2': 0.0016453266143798828, 'bn2': 0.0005476474761962891, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016391277313232422, 'bn1': 0.0005621910095214844, 'relu1': 0.0003247261047363281, 'conv2': 0.0016367435455322266, 'bn2': 0.0005385875701904297, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.00106048583984375, 'bn1': 0.0003211498260498047, 'relu1': 0.0001709461212158203, 'conv2': 0.001314401626586914, 'bn2': 0.0003113746643066406, 'conv3': 0.0004153251647949219, 'residual_add_relu2': 0.0003943443298339844}\n",
      "{'conv1': 0.0013234615325927734, 'bn1': 0.00031757354736328125, 'relu1': 0.00017452239990234375, 'conv2': 0.0013239383697509766, 'bn2': 0.00033736228942871094, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007956027984619141, 'bn1': 0.000202178955078125, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011649131774902344, 'bn2': 0.0001952648162841797, 'conv3': 0.0003514289855957031, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011663436889648438, 'bn1': 0.00021076202392578125, 'relu1': 9.942054748535156e-05, 'conv2': 0.0011637210845947266, 'bn2': 0.00019550323486328125, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006597042083740234, 'bn1': 0.00011563301086425781, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00011324882507324219, 'conv3': 0.0002887248992919922, 'residual_add_relu2': 0.00010967254638671875}\n",
      "{'conv1': 0.0011522769927978516, 'bn1': 0.00011372566223144531, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011489391326904297, 'bn2': 0.001399993896484375, 'residual_add_relu2': 0.00011420249938964844}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 442\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016584396362304688, 'bn1': 0.0005652904510498047, 'relu1': 0.00032210350036621094, 'conv2': 0.001649618148803711, 'bn2': 0.0005326271057128906, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.0016491413116455078, 'bn1': 0.0005385875701904297, 'relu1': 0.00032329559326171875, 'conv2': 0.0016388893127441406, 'bn2': 0.0005409717559814453, 'residual_add_relu2': 0.0007615089416503906}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010592937469482422, 'bn1': 0.00031447410583496094, 'relu1': 0.00017261505126953125, 'conv2': 0.0013256072998046875, 'bn2': 0.00031280517578125, 'conv3': 0.0004050731658935547, 'residual_add_relu2': 0.00039124488830566406}\n",
      "{'conv1': 0.0013234615325927734, 'bn1': 0.00031638145446777344, 'relu1': 0.0001735687255859375, 'conv2': 0.0013170242309570312, 'bn2': 0.0003104209899902344, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007944107055664062, 'bn1': 0.0002009868621826172, 'relu1': 9.775161743164062e-05, 'conv2': 0.001163482666015625, 'bn2': 0.00020456314086914062, 'conv3': 0.0003559589385986328, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011661052703857422, 'bn1': 0.0002009868621826172, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011601448059082031, 'bn2': 0.00019407272338867188, 'residual_add_relu2': 0.0002067089080810547}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006644725799560547, 'bn1': 0.0001220703125, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011548995971679688, 'bn2': 0.00011467933654785156, 'conv3': 0.00029349327087402344, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.001161336898803711, 'bn1': 0.00012874603271484375, 'relu1': 6.103515625e-05, 'conv2': 0.0011563301086425781, 'bn2': 0.00011682510375976562, 'residual_add_relu2': 0.00010967254638671875}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 443\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016529560089111328, 'bn1': 0.0005512237548828125, 'relu1': 0.0003216266632080078, 'conv2': 0.0016319751739501953, 'bn2': 0.0005497932434082031, 'residual_add_relu2': 0.0007648468017578125}\n",
      "{'conv1': 0.0016446113586425781, 'bn1': 0.000537872314453125, 'relu1': 0.0007464885711669922, 'conv2': 0.0016710758209228516, 'bn2': 0.0005688667297363281, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010571479797363281, 'bn1': 0.0003211498260498047, 'relu1': 0.00017404556274414062, 'conv2': 0.001318216323852539, 'bn2': 0.0003018379211425781, 'conv3': 0.0003962516784667969, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.0013148784637451172, 'bn1': 0.00030994415283203125, 'relu1': 0.00017142295837402344, 'conv2': 0.0013110637664794922, 'bn2': 0.0003039836883544922, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007905960083007812, 'bn1': 0.00019669532775878906, 'relu1': 9.703636169433594e-05, 'conv2': 0.0011606216430664062, 'bn2': 0.00018978118896484375, 'conv3': 0.00034928321838378906, 'residual_add_relu2': 0.0002033710479736328}\n",
      "{'conv1': 0.0011630058288574219, 'bn1': 0.00019025802612304688, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011582374572753906, 'bn2': 0.00018668174743652344, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006575584411621094, 'bn1': 0.00011539459228515625, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00010848045349121094, 'conv3': 0.0003380775451660156, 'residual_add_relu2': 0.00011658668518066406}\n",
      "{'conv1': 0.0011622905731201172, 'bn1': 0.00011873245239257812, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011491775512695312, 'bn2': 0.00010776519775390625, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 444\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016677379608154297, 'bn1': 0.0005533695220947266, 'relu1': 0.00032329559326171875, 'conv2': 0.0016438961029052734, 'bn2': 0.0005409717559814453, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016391277313232422, 'bn1': 0.0005347728729248047, 'relu1': 0.0003218650817871094, 'conv2': 0.0016369819641113281, 'bn2': 0.0005292892456054688, 'residual_add_relu2': 0.0007610321044921875}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010454654693603516, 'bn1': 0.0003070831298828125, 'relu1': 0.0001709461212158203, 'conv2': 0.0013120174407958984, 'bn2': 0.0003085136413574219, 'conv3': 0.0003948211669921875, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.0013134479522705078, 'bn1': 0.0003132820129394531, 'relu1': 0.00017404556274414062, 'conv2': 0.0013170242309570312, 'bn2': 0.0003077983856201172, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007929801940917969, 'bn1': 0.00020360946655273438, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011644363403320312, 'bn2': 0.00019478797912597656, 'conv3': 0.0003521442413330078, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011658668518066406, 'bn1': 0.0001990795135498047, 'relu1': 9.918212890625e-05, 'conv2': 0.0011641979217529297, 'bn2': 0.00021696090698242188, 'residual_add_relu2': 0.0002052783966064453}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006716251373291016, 'bn1': 0.0001232624053955078, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011529922485351562, 'bn2': 0.00010919570922851562, 'conv3': 0.0002911090850830078, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00012230873107910156, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011513233184814453, 'bn2': 0.00011467933654785156, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 445\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016565322875976562, 'bn1': 0.000553131103515625, 'relu1': 0.00032329559326171875, 'conv2': 0.0016376972198486328, 'bn2': 0.0005490779876708984, 'residual_add_relu2': 0.0007653236389160156}\n",
      "{'conv1': 0.0016407966613769531, 'bn1': 0.0005407333374023438, 'relu1': 0.00032210350036621094, 'conv2': 0.0016362667083740234, 'bn2': 0.0005364418029785156, 'residual_add_relu2': 0.0007617473602294922}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010523796081542969, 'bn1': 0.0003077983856201172, 'relu1': 0.00017070770263671875, 'conv2': 0.001313924789428711, 'bn2': 0.00030159950256347656, 'conv3': 0.0003972053527832031, 'residual_add_relu2': 0.0003895759582519531}\n",
      "{'conv1': 0.0013260841369628906, 'bn1': 0.0003113746643066406, 'relu1': 0.00017189979553222656, 'conv2': 0.0013115406036376953, 'bn2': 0.0003018379211425781, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007915496826171875, 'bn1': 0.00019621849060058594, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011615753173828125, 'bn2': 0.0001850128173828125, 'conv3': 0.0003483295440673828, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.001165151596069336, 'bn1': 0.00019669532775878906, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.00018835067749023438, 'residual_add_relu2': 0.00020241737365722656}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006582736968994141, 'bn1': 0.00011181831359863281, 'relu1': 5.7220458984375e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.00011897087097167969, 'conv3': 0.00028967857360839844, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.0011515617370605469, 'bn1': 0.00011229515075683594, 'relu1': 5.650520324707031e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00010514259338378906, 'residual_add_relu2': 0.00010824203491210938}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 446\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016591548919677734, 'bn1': 0.0005714893341064453, 'relu1': 0.0003275871276855469, 'conv2': 0.00164794921875, 'bn2': 0.0005533695220947266, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.0016446113586425781, 'bn1': 0.0005564689636230469, 'relu1': 0.0003261566162109375, 'conv2': 0.0016455650329589844, 'bn2': 0.0005519390106201172, 'residual_add_relu2': 0.0007641315460205078}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001051187515258789, 'bn1': 0.0003139972686767578, 'relu1': 0.00017499923706054688, 'conv2': 0.0013148784637451172, 'bn2': 0.00030732154846191406, 'conv3': 0.0004131793975830078, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013196468353271484, 'bn1': 0.0003135204315185547, 'relu1': 0.00017452239990234375, 'conv2': 0.0013136863708496094, 'bn2': 0.0003037452697753906, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007917881011962891, 'bn1': 0.00019431114196777344, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011594295501708984, 'bn2': 0.00018715858459472656, 'conv3': 0.0003485679626464844, 'residual_add_relu2': 0.00020313262939453125}\n",
      "{'conv1': 0.0011622905731201172, 'bn1': 0.0001995563507080078, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011594295501708984, 'bn2': 0.00018715858459472656, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006606578826904297, 'bn1': 0.00011444091796875, 'relu1': 5.745887756347656e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00011086463928222656, 'conv3': 0.00028967857360839844, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011568069458007812, 'bn1': 0.00011420249938964844, 'relu1': 5.7220458984375e-05, 'conv2': 0.0011475086212158203, 'bn2': 0.00010776519775390625, 'residual_add_relu2': 0.00010800361633300781}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 447\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016622543334960938, 'bn1': 0.0005655288696289062, 'relu1': 0.0003266334533691406, 'conv2': 0.0016405582427978516, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007646083831787109}\n",
      "{'conv1': 0.0016522407531738281, 'bn1': 0.0005431175231933594, 'relu1': 0.00032258033752441406, 'conv2': 0.0016512870788574219, 'bn2': 0.0005428791046142578, 'residual_add_relu2': 0.0007617473602294922}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010516643524169922, 'bn1': 0.0003104209899902344, 'relu1': 0.0001709461212158203, 'conv2': 0.0013124942779541016, 'bn2': 0.0003120899200439453, 'conv3': 0.0004036426544189453, 'residual_add_relu2': 0.0003905296325683594}\n",
      "{'conv1': 0.00131988525390625, 'bn1': 0.0003204345703125, 'relu1': 0.00017523765563964844, 'conv2': 0.0013172626495361328, 'bn2': 0.000316619873046875, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007956027984619141, 'bn1': 0.00020170211791992188, 'relu1': 9.989738464355469e-05, 'conv2': 0.00116729736328125, 'bn2': 0.0001964569091796875, 'conv3': 0.0003619194030761719, 'residual_add_relu2': 0.00020623207092285156}\n",
      "{'conv1': 0.0011677742004394531, 'bn1': 0.0002079010009765625, 'relu1': 9.894371032714844e-05, 'conv2': 0.0011630058288574219, 'bn2': 0.00019502639770507812, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006678104400634766, 'bn1': 0.00012946128845214844, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.00011801719665527344, 'conv3': 0.00029397010803222656, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011599063873291016, 'bn1': 0.0001232624053955078, 'relu1': 6.198883056640625e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00012874603271484375, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 448\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016565322875976562, 'bn1': 0.0005512237548828125, 'relu1': 0.0003230571746826172, 'conv2': 0.0016427040100097656, 'bn2': 0.0005319118499755859, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016455650329589844, 'bn1': 0.0005393028259277344, 'relu1': 0.0003209114074707031, 'conv2': 0.001634359359741211, 'bn2': 0.0005428791046142578, 'residual_add_relu2': 0.0007672309875488281}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010540485382080078, 'bn1': 0.0003161430358886719, 'relu1': 0.000171661376953125, 'conv2': 0.0013175010681152344, 'bn2': 0.00031304359436035156, 'conv3': 0.00039958953857421875, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013186931610107422, 'bn1': 0.00031495094299316406, 'relu1': 0.00017380714416503906, 'conv2': 0.0013136863708496094, 'bn2': 0.0003132820129394531, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007929801940917969, 'bn1': 0.0001995563507080078, 'relu1': 0.00010228157043457031, 'conv2': 0.001165628433227539, 'bn2': 0.00019931793212890625, 'conv3': 0.0003542900085449219, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.001165151596069336, 'bn1': 0.00019860267639160156, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011608600616455078, 'bn2': 0.0001952648162841797, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006663799285888672, 'bn1': 0.00012254714965820312, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011551380157470703, 'bn2': 0.00011444091796875, 'conv3': 0.0002887248992919922, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011565685272216797, 'bn1': 0.00012230873107910156, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0012464523315429688, 'bn2': 0.00012683868408203125, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 449\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016591548919677734, 'bn1': 0.0005469322204589844, 'relu1': 0.0003254413604736328, 'conv2': 0.001638650894165039, 'bn2': 0.0005478858947753906, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016400814056396484, 'bn1': 0.0005476474761962891, 'relu1': 0.00032591819763183594, 'conv2': 0.0016429424285888672, 'bn2': 0.0005390644073486328, 'residual_add_relu2': 0.0007638931274414062}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010590553283691406, 'bn1': 0.0003223419189453125, 'relu1': 0.00017762184143066406, 'conv2': 0.0013170242309570312, 'bn2': 0.00030517578125, 'conv3': 0.00040531158447265625, 'residual_add_relu2': 0.0003910064697265625}\n",
      "{'conv1': 0.001321554183959961, 'bn1': 0.00030684471130371094, 'relu1': 0.0001785755157470703, 'conv2': 0.0013134479522705078, 'bn2': 0.0003256797790527344, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008442401885986328, 'bn1': 0.00019788742065429688, 'relu1': 0.00010037422180175781, 'conv2': 0.0011625289916992188, 'bn2': 0.00018858909606933594, 'conv3': 0.0003497600555419922, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.001163482666015625, 'bn1': 0.00020122528076171875, 'relu1': 9.775161743164062e-05, 'conv2': 0.001161336898803711, 'bn2': 0.00018906593322753906, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006582736968994141, 'bn1': 0.00011348724365234375, 'relu1': 5.7220458984375e-05, 'conv2': 0.001154184341430664, 'bn2': 0.00013518333435058594, 'conv3': 0.00029587745666503906, 'residual_add_relu2': 0.00011229515075683594}\n",
      "{'conv1': 0.0011570453643798828, 'bn1': 0.00012350082397460938, 'relu1': 5.8650970458984375e-05, 'conv2': 0.001153707504272461, 'bn2': 0.00011944770812988281, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 450\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016508102416992188, 'bn1': 0.0005559921264648438, 'relu1': 0.0003249645233154297, 'conv2': 0.0016334056854248047, 'bn2': 0.0005347728729248047, 'residual_add_relu2': 0.0007646083831787109}\n",
      "{'conv1': 0.0016405582427978516, 'bn1': 0.0005328655242919922, 'relu1': 0.0003218650817871094, 'conv2': 0.0016336441040039062, 'bn2': 0.0005371570587158203, 'residual_add_relu2': 0.0007612705230712891}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010504722595214844, 'bn1': 0.0003082752227783203, 'relu1': 0.00017070770263671875, 'conv2': 0.001310586929321289, 'bn2': 0.0003066062927246094, 'conv3': 0.0004112720489501953, 'residual_add_relu2': 0.0003936290740966797}\n",
      "{'conv1': 0.001322031021118164, 'bn1': 0.0003247261047363281, 'relu1': 0.00017571449279785156, 'conv2': 0.00131988525390625, 'bn2': 0.00032019615173339844, 'residual_add_relu2': 0.00039315223693847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007965564727783203, 'bn1': 0.00021147727966308594, 'relu1': 0.00010251998901367188, 'conv2': 0.0011684894561767578, 'bn2': 0.00020694732666015625, 'conv3': 0.0003612041473388672, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.0011692047119140625, 'bn1': 0.00021004676818847656, 'relu1': 0.00010085105895996094, 'conv2': 0.0011646747589111328, 'bn2': 0.00018930435180664062, 'residual_add_relu2': 0.00020360946655273438}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006663799285888672, 'bn1': 0.00011587142944335938, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011513233184814453, 'bn2': 0.00010585784912109375, 'conv3': 0.0002872943878173828, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.0011522769927978516, 'bn1': 0.00011563301086425781, 'relu1': 5.698204040527344e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.00010609626770019531, 'residual_add_relu2': 0.00010848045349121094}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 451\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016601085662841797, 'bn1': 0.0005497932434082031, 'relu1': 0.00032210350036621094, 'conv2': 0.0016429424285888672, 'bn2': 0.000537872314453125, 'residual_add_relu2': 0.0007646083831787109}\n",
      "{'conv1': 0.0016360282897949219, 'bn1': 0.0005466938018798828, 'relu1': 0.000324249267578125, 'conv2': 0.0016369819641113281, 'bn2': 0.0005314350128173828, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010528564453125, 'bn1': 0.0003116130828857422, 'relu1': 0.00017070770263671875, 'conv2': 0.0013120174407958984, 'bn2': 0.00030159950256347656, 'conv3': 0.00039649009704589844, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013775825500488281, 'bn1': 0.00031304359436035156, 'relu1': 0.00017261505126953125, 'conv2': 0.0013098716735839844, 'bn2': 0.0003025531768798828, 'residual_add_relu2': 0.0004467964172363281}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008006095886230469, 'bn1': 0.00020313262939453125, 'relu1': 9.918212890625e-05, 'conv2': 0.0011658668518066406, 'bn2': 0.00019550323486328125, 'conv3': 0.00035500526428222656, 'residual_add_relu2': 0.0002048015594482422}\n",
      "{'conv1': 0.0011675357818603516, 'bn1': 0.00022268295288085938, 'relu1': 9.965896606445312e-05, 'conv2': 0.0011641979217529297, 'bn2': 0.00019788742065429688, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006644725799560547, 'bn1': 0.00011777877807617188, 'relu1': 5.841255187988281e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00011801719665527344, 'conv3': 0.0002963542938232422, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011608600616455078, 'bn1': 0.0001227855682373047, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.00010943412780761719, 'residual_add_relu2': 0.0001087188720703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 452\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016636848449707031, 'bn1': 0.0005538463592529297, 'relu1': 0.000324249267578125, 'conv2': 0.0016434192657470703, 'bn2': 0.0005474090576171875, 'residual_add_relu2': 0.0007684230804443359}\n",
      "{'conv1': 0.001638174057006836, 'bn1': 0.0005450248718261719, 'relu1': 0.00032258033752441406, 'conv2': 0.0016374588012695312, 'bn2': 0.0005402565002441406, 'residual_add_relu2': 0.0007624626159667969}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010504722595214844, 'bn1': 0.0003151893615722656, 'relu1': 0.00017213821411132812, 'conv2': 0.0013194084167480469, 'bn2': 0.0003085136413574219, 'conv3': 0.00040912628173828125, 'residual_add_relu2': 0.0003924369812011719}\n",
      "{'conv1': 0.0013175010681152344, 'bn1': 0.0003209114074707031, 'relu1': 0.00017333030700683594, 'conv2': 0.0013170242309570312, 'bn2': 0.0003161430358886719, 'residual_add_relu2': 0.0003914833068847656}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007975101470947266, 'bn1': 0.00020313262939453125, 'relu1': 9.632110595703125e-05, 'conv2': 0.001161336898803711, 'bn2': 0.0001964569091796875, 'conv3': 0.00035381317138671875, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.00116729736328125, 'bn1': 0.0002110004425048828, 'relu1': 9.918212890625e-05, 'conv2': 0.0011639595031738281, 'bn2': 0.0001983642578125, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006647109985351562, 'bn1': 0.00012493133544921875, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.0001220703125, 'conv3': 0.00029850006103515625, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011572837829589844, 'bn1': 0.00012230873107910156, 'relu1': 6.031990051269531e-05, 'conv2': 0.00115203857421875, 'bn2': 0.00012493133544921875, 'residual_add_relu2': 0.00011157989501953125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 453\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016467571258544922, 'bn1': 0.0005474090576171875, 'relu1': 0.0003223419189453125, 'conv2': 0.0016334056854248047, 'bn2': 0.0005407333374023438, 'residual_add_relu2': 0.0007658004760742188}\n",
      "{'conv1': 0.001653909683227539, 'bn1': 0.000545501708984375, 'relu1': 0.00032258033752441406, 'conv2': 0.0016427040100097656, 'bn2': 0.0005397796630859375, 'residual_add_relu2': 0.0007684230804443359}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010547637939453125, 'bn1': 0.0003147125244140625, 'relu1': 0.0001728534698486328, 'conv2': 0.0013170242309570312, 'bn2': 0.0003097057342529297, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013172626495361328, 'bn1': 0.0003132820129394531, 'relu1': 0.0001728534698486328, 'conv2': 0.0013158321380615234, 'bn2': 0.00031948089599609375, 'residual_add_relu2': 0.00039124488830566406}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007951259613037109, 'bn1': 0.00020241737365722656, 'relu1': 9.989738464355469e-05, 'conv2': 0.001165628433227539, 'bn2': 0.0001964569091796875, 'conv3': 0.0003566741943359375, 'residual_add_relu2': 0.00020575523376464844}\n",
      "{'conv1': 0.0011708736419677734, 'bn1': 0.00020003318786621094, 'relu1': 9.799003601074219e-05, 'conv2': 0.0011620521545410156, 'bn2': 0.00019550323486328125, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006639957427978516, 'bn1': 0.00012373924255371094, 'relu1': 6.0558319091796875e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00011658668518066406, 'conv3': 0.0002923011779785156, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00012063980102539062, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00011658668518066406, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 454\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016474723815917969, 'bn1': 0.0005643367767333984, 'relu1': 0.0003256797790527344, 'conv2': 0.001634359359741211, 'bn2': 0.0005431175231933594, 'residual_add_relu2': 0.0007660388946533203}\n",
      "{'conv1': 0.0016405582427978516, 'bn1': 0.0005407333374023438, 'relu1': 0.0003275871276855469, 'conv2': 0.001638650894165039, 'bn2': 0.0005385875701904297, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010509490966796875, 'bn1': 0.0003147125244140625, 'relu1': 0.00017213821411132812, 'conv2': 0.001316070556640625, 'bn2': 0.0003025531768798828, 'conv3': 0.0003979206085205078, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.0013153553009033203, 'bn1': 0.00030994415283203125, 'relu1': 0.000171661376953125, 'conv2': 0.001310110092163086, 'bn2': 0.0003025531768798828, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007891654968261719, 'bn1': 0.00019311904907226562, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011603832244873047, 'bn2': 0.00019550323486328125, 'conv3': 0.0004169940948486328, 'residual_add_relu2': 0.00020647048950195312}\n",
      "{'conv1': 0.0011746883392333984, 'bn1': 0.00019598007202148438, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011587142944335938, 'bn2': 0.00019502639770507812, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006654262542724609, 'bn1': 0.00012874603271484375, 'relu1': 6.103515625e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.00011658668518066406, 'conv3': 0.0002923011779785156, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011560916900634766, 'bn1': 0.00012111663818359375, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011560916900634766, 'bn2': 0.00011444091796875, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 455\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016589164733886719, 'bn1': 0.0005502700805664062, 'relu1': 0.0003235340118408203, 'conv2': 0.0016415119171142578, 'bn2': 0.00054168701171875, 'residual_add_relu2': 0.0007648468017578125}\n",
      "{'conv1': 0.0016624927520751953, 'bn1': 0.0005488395690917969, 'relu1': 0.0003249645233154297, 'conv2': 0.0016384124755859375, 'bn2': 0.0005381107330322266, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010514259338378906, 'bn1': 0.00031638145446777344, 'relu1': 0.0001735687255859375, 'conv2': 0.001318216323852539, 'bn2': 0.00030803680419921875, 'conv3': 0.000400543212890625, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.001318216323852539, 'bn1': 0.0003151893615722656, 'relu1': 0.00017380714416503906, 'conv2': 0.0013155937194824219, 'bn2': 0.0003085136413574219, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.00079345703125, 'bn1': 0.00020003318786621094, 'relu1': 0.0001552104949951172, 'conv2': 0.0011737346649169922, 'bn2': 0.0001983642578125, 'conv3': 0.00035452842712402344, 'residual_add_relu2': 0.0002033710479736328}\n",
      "{'conv1': 0.0011653900146484375, 'bn1': 0.00020051002502441406, 'relu1': 9.822845458984375e-05, 'conv2': 0.001161813735961914, 'bn2': 0.00019693374633789062, 'residual_add_relu2': 0.00020456314086914062}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006632804870605469, 'bn1': 0.00012874603271484375, 'relu1': 5.984306335449219e-05, 'conv2': 0.0011556148529052734, 'bn2': 0.00011444091796875, 'conv3': 0.0002942085266113281, 'residual_add_relu2': 0.00011110305786132812}\n",
      "{'conv1': 0.0011560916900634766, 'bn1': 0.000125885009765625, 'relu1': 5.936622619628906e-05, 'conv2': 0.00115203857421875, 'bn2': 0.00011491775512695312, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 456\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016598701477050781, 'bn1': 0.0005578994750976562, 'relu1': 0.0003237724304199219, 'conv2': 0.0016334056854248047, 'bn2': 0.0005412101745605469, 'residual_add_relu2': 0.0007672309875488281}\n",
      "{'conv1': 0.00164031982421875, 'bn1': 0.0005543231964111328, 'relu1': 0.00032401084899902344, 'conv2': 0.0016388893127441406, 'bn2': 0.0005385875701904297, 'residual_add_relu2': 0.0007636547088623047}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010504722595214844, 'bn1': 0.0003228187561035156, 'relu1': 0.00017333030700683594, 'conv2': 0.0013167858123779297, 'bn2': 0.00030922889709472656, 'conv3': 0.0003986358642578125, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.0013132095336914062, 'bn1': 0.0003094673156738281, 'relu1': 0.000171661376953125, 'conv2': 0.0013115406036376953, 'bn2': 0.000301361083984375, 'residual_add_relu2': 0.00039005279541015625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000789642333984375, 'bn1': 0.00019168853759765625, 'relu1': 9.655952453613281e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.0001857280731201172, 'conv3': 0.0003485679626464844, 'residual_add_relu2': 0.0002028942108154297}\n",
      "{'conv1': 0.0011591911315917969, 'bn1': 0.0001919269561767578, 'relu1': 9.679794311523438e-05, 'conv2': 0.001157522201538086, 'bn2': 0.00019478797912597656, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006632804870605469, 'bn1': 0.0001201629638671875, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011553764343261719, 'bn2': 0.00011539459228515625, 'conv3': 0.00029778480529785156, 'residual_add_relu2': 0.00011181831359863281}\n",
      "{'conv1': 0.0011582374572753906, 'bn1': 0.0001227855682373047, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011518001556396484, 'bn2': 0.00011539459228515625, 'residual_add_relu2': 0.00011038780212402344}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 457\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016477108001708984, 'bn1': 0.0005524158477783203, 'relu1': 0.000324249267578125, 'conv2': 0.0016367435455322266, 'bn2': 0.0005435943603515625, 'residual_add_relu2': 0.0007665157318115234}\n",
      "{'conv1': 0.0016498565673828125, 'bn1': 0.0005462169647216797, 'relu1': 0.00032639503479003906, 'conv2': 0.001638174057006836, 'bn2': 0.0005488395690917969, 'residual_add_relu2': 0.0007634162902832031}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010530948638916016, 'bn1': 0.0003142356872558594, 'relu1': 0.0001723766326904297, 'conv2': 0.001317739486694336, 'bn2': 0.0003147125244140625, 'conv3': 0.0004010200500488281, 'residual_add_relu2': 0.0003902912139892578}\n",
      "{'conv1': 0.0013165473937988281, 'bn1': 0.0003142356872558594, 'relu1': 0.0001735687255859375, 'conv2': 0.0013134479522705078, 'bn2': 0.0003094673156738281, 'residual_add_relu2': 0.0003910064697265625}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007879734039306641, 'bn1': 0.00019216537475585938, 'relu1': 9.560585021972656e-05, 'conv2': 0.0011608600616455078, 'bn2': 0.00018787384033203125, 'conv3': 0.00034928321838378906, 'residual_add_relu2': 0.0002028942108154297}\n",
      "{'conv1': 0.0011646747589111328, 'bn1': 0.0001938343048095703, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.00019407272338867188, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006694793701171875, 'bn1': 0.00012373924255371094, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.00011587142944335938, 'conv3': 0.0002923011779785156, 'residual_add_relu2': 0.00011086463928222656}\n",
      "{'conv1': 0.0011560916900634766, 'bn1': 0.00011396408081054688, 'relu1': 5.7697296142578125e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00012063980102539062, 'residual_add_relu2': 0.00011086463928222656}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 458\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001657247543334961, 'bn1': 0.0005605220794677734, 'relu1': 0.00032591819763183594, 'conv2': 0.001644134521484375, 'bn2': 0.0005371570587158203, 'residual_add_relu2': 0.0007662773132324219}\n",
      "{'conv1': 0.0016407966613769531, 'bn1': 0.0005471706390380859, 'relu1': 0.00032329559326171875, 'conv2': 0.0016362667083740234, 'bn2': 0.0005352497100830078, 'residual_add_relu2': 0.000766754150390625}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.001054525375366211, 'bn1': 0.0003170967102050781, 'relu1': 0.0001728534698486328, 'conv2': 0.0013179779052734375, 'bn2': 0.0003108978271484375, 'conv3': 0.00040411949157714844, 'residual_add_relu2': 0.00039005279541015625}\n",
      "{'conv1': 0.001317739486694336, 'bn1': 0.00031757354736328125, 'relu1': 0.00017547607421875, 'conv2': 0.001316070556640625, 'bn2': 0.0003185272216796875, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007927417755126953, 'bn1': 0.00020313262939453125, 'relu1': 0.00010085105895996094, 'conv2': 0.0011658668518066406, 'bn2': 0.00019860267639160156, 'conv3': 0.00035572052001953125, 'residual_add_relu2': 0.00023984909057617188}\n",
      "{'conv1': 0.0011777877807617188, 'bn1': 0.000213623046875, 'relu1': 0.00010371208190917969, 'conv2': 0.0011687278747558594, 'bn2': 0.0002071857452392578, 'residual_add_relu2': 0.0002071857452392578}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006732940673828125, 'bn1': 0.000141143798828125, 'relu1': 6.270408630371094e-05, 'conv2': 0.0011627674102783203, 'bn2': 0.000125885009765625, 'conv3': 0.00029754638671875, 'residual_add_relu2': 0.00011348724365234375}\n",
      "{'conv1': 0.001165151596069336, 'bn1': 0.00013017654418945312, 'relu1': 6.389617919921875e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.0001277923583984375, 'residual_add_relu2': 0.0001125335693359375}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 459\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016641616821289062, 'bn1': 0.0005700588226318359, 'relu1': 0.0003273487091064453, 'conv2': 0.0016493797302246094, 'bn2': 0.0005533695220947266, 'residual_add_relu2': 0.0007674694061279297}\n",
      "{'conv1': 0.001657724380493164, 'bn1': 0.0005533695220947266, 'relu1': 0.00032258033752441406, 'conv2': 0.0016345977783203125, 'bn2': 0.0005426406860351562, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010497570037841797, 'bn1': 0.00031828880310058594, 'relu1': 0.0001735687255859375, 'conv2': 0.0013165473937988281, 'bn2': 0.0003077983856201172, 'conv3': 0.00040078163146972656, 'residual_add_relu2': 0.00039076805114746094}\n",
      "{'conv1': 0.0013170242309570312, 'bn1': 0.00031447410583496094, 'relu1': 0.00017309188842773438, 'conv2': 0.001313924789428711, 'bn2': 0.0003094673156738281, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007932186126708984, 'bn1': 0.00019788742065429688, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011646747589111328, 'bn2': 0.00019669532775878906, 'conv3': 0.0003523826599121094, 'residual_add_relu2': 0.00020503997802734375}\n",
      "{'conv1': 0.0011661052703857422, 'bn1': 0.00020051002502441406, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011639595031738281, 'bn2': 0.00020575523376464844, 'residual_add_relu2': 0.00020551681518554688}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006651878356933594, 'bn1': 0.00012230873107910156, 'relu1': 6.079673767089844e-05, 'conv2': 0.0011572837829589844, 'bn2': 0.00011682510375976562, 'conv3': 0.0002930164337158203, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.0011572837829589844, 'bn1': 0.00012445449829101562, 'relu1': 5.91278076171875e-05, 'conv2': 0.0011527538299560547, 'bn2': 0.00011539459228515625, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 460\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016655921936035156, 'bn1': 0.0005753040313720703, 'relu1': 0.0003247261047363281, 'conv2': 0.0016384124755859375, 'bn2': 0.0005486011505126953, 'residual_add_relu2': 0.000766754150390625}\n",
      "{'conv1': 0.0016405582427978516, 'bn1': 0.0005519390106201172, 'relu1': 0.000324249267578125, 'conv2': 0.0016388893127441406, 'bn2': 0.0005371570587158203, 'residual_add_relu2': 0.0007658004760742188}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010557174682617188, 'bn1': 0.0003178119659423828, 'relu1': 0.0001747608184814453, 'conv2': 0.0013196468353271484, 'bn2': 0.0003116130828857422, 'conv3': 0.0004024505615234375, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013179779052734375, 'bn1': 0.00031495094299316406, 'relu1': 0.0001742839813232422, 'conv2': 0.0013175010681152344, 'bn2': 0.00030922889709472656, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008046627044677734, 'bn1': 0.00020647048950195312, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011670589447021484, 'bn2': 0.0002155303955078125, 'conv3': 0.00035572052001953125, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.001165628433227539, 'bn1': 0.000213623046875, 'relu1': 0.00010037422180175781, 'conv2': 0.0011649131774902344, 'bn2': 0.00019741058349609375, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006654262542724609, 'bn1': 0.0001246929168701172, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011565685272216797, 'bn2': 0.00012111663818359375, 'conv3': 0.0002994537353515625, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.001157522201538086, 'bn1': 0.0001227855682373047, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011525154113769531, 'bn2': 0.00011873245239257812, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 461\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.001641988754272461, 'bn1': 0.0005509853363037109, 'relu1': 0.00032210350036621094, 'conv2': 0.0016412734985351562, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.0007655620574951172}\n",
      "{'conv1': 0.0016369819641113281, 'bn1': 0.0005443096160888672, 'relu1': 0.0003230571746826172, 'conv2': 0.001638174057006836, 'bn2': 0.0005424022674560547, 'residual_add_relu2': 0.000762939453125}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010502338409423828, 'bn1': 0.00030303001403808594, 'relu1': 0.0001704692840576172, 'conv2': 0.0013124942779541016, 'bn2': 0.0003159046173095703, 'conv3': 0.00039577484130859375, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013141632080078125, 'bn1': 0.0003075599670410156, 'relu1': 0.000171661376953125, 'conv2': 0.0013103485107421875, 'bn2': 0.0003223419189453125, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.000789642333984375, 'bn1': 0.00019049644470214844, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011599063873291016, 'bn2': 0.00018835067749023438, 'conv3': 0.0003495216369628906, 'residual_add_relu2': 0.00020360946655273438}\n",
      "{'conv1': 0.001161813735961914, 'bn1': 0.00019311904907226562, 'relu1': 9.632110595703125e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.00018906593322753906, 'residual_add_relu2': 0.0002033710479736328}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006723403930664062, 'bn1': 0.00012373924255371094, 'relu1': 6.008148193359375e-05, 'conv2': 0.0011737346649169922, 'bn2': 0.00012183189392089844, 'conv3': 0.0002949237823486328, 'residual_add_relu2': 0.000110626220703125}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00012063980102539062, 'relu1': 5.888938903808594e-05, 'conv2': 0.0011522769927978516, 'bn2': 0.00012302398681640625, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 462\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016779899597167969, 'bn1': 0.0005750656127929688, 'relu1': 0.0003299713134765625, 'conv2': 0.0016536712646484375, 'bn2': 0.0005555152893066406, 'residual_add_relu2': 0.0007696151733398438}\n",
      "{'conv1': 0.0016505718231201172, 'bn1': 0.0005595684051513672, 'relu1': 0.00032639503479003906, 'conv2': 0.0016436576843261719, 'bn2': 0.0005536079406738281, 'residual_add_relu2': 0.0007674694061279297}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010600090026855469, 'bn1': 0.0003249645233154297, 'relu1': 0.0001766681671142578, 'conv2': 0.0013294219970703125, 'bn2': 0.00033164024353027344, 'conv3': 0.0004100799560546875, 'residual_add_relu2': 0.00039315223693847656}\n",
      "{'conv1': 0.0013241767883300781, 'bn1': 0.0003266334533691406, 'relu1': 0.00017786026000976562, 'conv2': 0.0013227462768554688, 'bn2': 0.0003254413604736328, 'residual_add_relu2': 0.0003943443298339844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0008056163787841797, 'bn1': 0.00021457672119140625, 'relu1': 0.00010275840759277344, 'conv2': 0.0011734962463378906, 'bn2': 0.00020766258239746094, 'conv3': 0.0003604888916015625, 'residual_add_relu2': 0.0002067089080810547}\n",
      "{'conv1': 0.0011746883392333984, 'bn1': 0.0002155303955078125, 'relu1': 0.0001010894775390625, 'conv2': 0.0011684894561767578, 'bn2': 0.0002090930938720703, 'residual_add_relu2': 0.00020599365234375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0007047653198242188, 'bn1': 0.000148773193359375, 'relu1': 6.461143493652344e-05, 'conv2': 0.0011663436889648438, 'bn2': 0.00012946128845214844, 'conv3': 0.000301361083984375, 'residual_add_relu2': 0.00011372566223144531}\n",
      "{'conv1': 0.0011625289916992188, 'bn1': 0.00013136863708496094, 'relu1': 6.29425048828125e-05, 'conv2': 0.0011582374572753906, 'bn2': 0.0001285076141357422, 'residual_add_relu2': 0.00011277198791503906}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 463\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016601085662841797, 'bn1': 0.0005550384521484375, 'relu1': 0.00032329559326171875, 'conv2': 0.0016384124755859375, 'bn2': 0.0005393028259277344, 'residual_add_relu2': 0.000762939453125}\n",
      "{'conv1': 0.001634359359741211, 'bn1': 0.0005366802215576172, 'relu1': 0.0003199577331542969, 'conv2': 0.0016300678253173828, 'bn2': 0.0005328655242919922, 'residual_add_relu2': 0.0007646083831787109}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010461807250976562, 'bn1': 0.0003056526184082031, 'relu1': 0.0001704692840576172, 'conv2': 0.0013129711151123047, 'bn2': 0.0003108978271484375, 'conv3': 0.00040149688720703125, 'residual_add_relu2': 0.0003898143768310547}\n",
      "{'conv1': 0.0013184547424316406, 'bn1': 0.00031256675720214844, 'relu1': 0.00018095970153808594, 'conv2': 0.0013158321380615234, 'bn2': 0.0003085136413574219, 'residual_add_relu2': 0.00039076805114746094}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007927417755126953, 'bn1': 0.0001990795135498047, 'relu1': 9.608268737792969e-05, 'conv2': 0.00115966796875, 'bn2': 0.00019049644470214844, 'conv3': 0.00035071372985839844, 'residual_add_relu2': 0.0002040863037109375}\n",
      "{'conv1': 0.0011627674102783203, 'bn1': 0.00019288063049316406, 'relu1': 9.72747802734375e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.0010075569152832031, 'residual_add_relu2': 0.00022268295288085938}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006761550903320312, 'bn1': 0.00012350082397460938, 'relu1': 5.984306335449219e-05, 'conv2': 0.001153707504272461, 'bn2': 0.00010991096496582031, 'conv3': 0.0002980232238769531, 'residual_add_relu2': 0.00011301040649414062}\n",
      "{'conv1': 0.0011641979217529297, 'bn1': 0.00013136863708496094, 'relu1': 5.9604644775390625e-05, 'conv2': 0.0011570453643798828, 'bn2': 0.0001201629638671875, 'residual_add_relu2': 0.00011134147644042969}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 464\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016522407531738281, 'bn1': 0.0005486011505126953, 'relu1': 0.0003237724304199219, 'conv2': 0.0016422271728515625, 'bn2': 0.0005419254302978516, 'residual_add_relu2': 0.0007646083831787109}\n",
      "{'conv1': 0.001638650894165039, 'bn1': 0.0005421638488769531, 'relu1': 0.0003223419189453125, 'conv2': 0.0016391277313232422, 'bn2': 0.000537872314453125, 'residual_add_relu2': 0.0007631778717041016}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010485649108886719, 'bn1': 0.00031566619873046875, 'relu1': 0.00017118453979492188, 'conv2': 0.0013113021850585938, 'bn2': 0.00030112266540527344, 'conv3': 0.0003943443298339844, 'residual_add_relu2': 0.00038886070251464844}\n",
      "{'conv1': 0.0013127326965332031, 'bn1': 0.0003132820129394531, 'relu1': 0.00017309188842773438, 'conv2': 0.0013136863708496094, 'bn2': 0.00030112266540527344, 'residual_add_relu2': 0.00038909912109375}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007970333099365234, 'bn1': 0.0001914501190185547, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011601448059082031, 'bn2': 0.00018787384033203125, 'conv3': 0.0003483295440673828, 'residual_add_relu2': 0.00020384788513183594}\n",
      "{'conv1': 0.001161336898803711, 'bn1': 0.0001926422119140625, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011584758758544922, 'bn2': 0.00019931793212890625, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006651878356933594, 'bn1': 0.00011420249938964844, 'relu1': 5.698204040527344e-05, 'conv2': 0.0011496543884277344, 'bn2': 0.00010752677917480469, 'conv3': 0.00028967857360839844, 'residual_add_relu2': 0.00010943412780761719}\n",
      "{'conv1': 0.0011548995971679688, 'bn1': 0.00011706352233886719, 'relu1': 5.817413330078125e-05, 'conv2': 0.0011494159698486328, 'bn2': 0.00010848045349121094, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 465\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016551017761230469, 'bn1': 0.0005435943603515625, 'relu1': 0.0003209114074707031, 'conv2': 0.0016407966613769531, 'bn2': 0.0011081695556640625, 'residual_add_relu2': 0.0007786750793457031}\n",
      "{'conv1': 0.0016515254974365234, 'bn1': 0.0005588531494140625, 'relu1': 0.00032210350036621094, 'conv2': 0.001641988754272461, 'bn2': 0.0005323886871337891, 'residual_add_relu2': 0.0007619857788085938}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010495185852050781, 'bn1': 0.000308990478515625, 'relu1': 0.0001697540283203125, 'conv2': 0.001312255859375, 'bn2': 0.00030040740966796875, 'conv3': 0.0003948211669921875, 'residual_add_relu2': 0.0003876686096191406}\n",
      "{'conv1': 0.0013189315795898438, 'bn1': 0.0003075599670410156, 'relu1': 0.00017380714416503906, 'conv2': 0.0013136863708496094, 'bn2': 0.00031065940856933594, 'residual_add_relu2': 0.00038886070251464844}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007917881011962891, 'bn1': 0.00019812583923339844, 'relu1': 0.00010132789611816406, 'conv2': 0.001165151596069336, 'bn2': 0.0002002716064453125, 'conv3': 0.00035381317138671875, 'residual_add_relu2': 0.0002071857452392578}\n",
      "{'conv1': 0.0011644363403320312, 'bn1': 0.00019431114196777344, 'relu1': 9.608268737792969e-05, 'conv2': 0.0011582374572753906, 'bn2': 0.00019478797912597656, 'residual_add_relu2': 0.0002048015594482422}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006630420684814453, 'bn1': 0.0001246929168701172, 'relu1': 5.936622619628906e-05, 'conv2': 0.0011515617370605469, 'bn2': 0.00010776519775390625, 'conv3': 0.00029015541076660156, 'residual_add_relu2': 0.00010991096496582031}\n",
      "{'conv1': 0.00115203857421875, 'bn1': 0.00011396408081054688, 'relu1': 5.793571472167969e-05, 'conv2': 0.001148223876953125, 'bn2': 0.00011515617370605469, 'residual_add_relu2': 0.000110626220703125}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 466\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016596317291259766, 'bn1': 0.0005514621734619141, 'relu1': 0.00032329559326171875, 'conv2': 0.0016453266143798828, 'bn2': 0.0005443096160888672, 'residual_add_relu2': 0.0007641315460205078}\n",
      "{'conv1': 0.0016376972198486328, 'bn1': 0.0005648136138916016, 'relu1': 0.0003235340118408203, 'conv2': 0.0016341209411621094, 'bn2': 0.0005383491516113281, 'residual_add_relu2': 0.0007619857788085938}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010499954223632812, 'bn1': 0.0003132820129394531, 'relu1': 0.0001728534698486328, 'conv2': 0.0013155937194824219, 'bn2': 0.0003075599670410156, 'conv3': 0.0003952980041503906, 'residual_add_relu2': 0.0003917217254638672}\n",
      "{'conv1': 0.0013163089752197266, 'bn1': 0.00031566619873046875, 'relu1': 0.00017213821411132812, 'conv2': 0.0013134479522705078, 'bn2': 0.00030803680419921875, 'residual_add_relu2': 0.00038933753967285156}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007882118225097656, 'bn1': 0.00019931793212890625, 'relu1': 9.775161743164062e-05, 'conv2': 0.0011630058288574219, 'bn2': 0.0001933574676513672, 'conv3': 0.0003650188446044922, 'residual_add_relu2': 0.00020694732666015625}\n",
      "{'conv1': 0.0011668205261230469, 'bn1': 0.00021076202392578125, 'relu1': 9.870529174804688e-05, 'conv2': 0.0011632442474365234, 'bn2': 0.000194549560546875, 'residual_add_relu2': 0.00020432472229003906}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006632804870605469, 'bn1': 0.00012087821960449219, 'relu1': 5.984306335449219e-05, 'conv2': 0.001154184341430664, 'bn2': 0.00012683868408203125, 'conv3': 0.00029468536376953125, 'residual_add_relu2': 0.00011157989501953125}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00011968612670898438, 'relu1': 5.8650970458984375e-05, 'conv2': 0.0011510848999023438, 'bn2': 0.00011229515075683594, 'residual_add_relu2': 0.00010991096496582031}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 467\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016486644744873047, 'bn1': 0.0005435943603515625, 'relu1': 0.0003216266632080078, 'conv2': 0.0016334056854248047, 'bn2': 0.0005354881286621094, 'residual_add_relu2': 0.0007631778717041016}\n",
      "{'conv1': 0.0016355514526367188, 'bn1': 0.0005397796630859375, 'relu1': 0.0003237724304199219, 'conv2': 0.0016331672668457031, 'bn2': 0.0005369186401367188, 'residual_add_relu2': 0.0007650852203369141}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010502338409423828, 'bn1': 0.0003123283386230469, 'relu1': 0.00017213821411132812, 'conv2': 0.0013155937194824219, 'bn2': 0.0003063678741455078, 'conv3': 0.00039505958557128906, 'residual_add_relu2': 0.00038933753967285156}\n",
      "{'conv1': 0.0013191699981689453, 'bn1': 0.00031304359436035156, 'relu1': 0.0001723766326904297, 'conv2': 0.001313924789428711, 'bn2': 0.00030732154846191406, 'residual_add_relu2': 0.0003895759582519531}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007956027984619141, 'bn1': 0.0001990795135498047, 'relu1': 9.822845458984375e-05, 'conv2': 0.001161336898803711, 'bn2': 0.00019216537475585938, 'conv3': 0.0003528594970703125, 'residual_add_relu2': 0.0002052783966064453}\n",
      "{'conv1': 0.0011649131774902344, 'bn1': 0.00019502639770507812, 'relu1': 9.584426879882812e-05, 'conv2': 0.0011589527130126953, 'bn2': 0.0001876354217529297, 'residual_add_relu2': 0.00020384788513183594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006592273712158203, 'bn1': 0.00011277198791503906, 'relu1': 5.698204040527344e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00010991096496582031, 'conv3': 0.00029015541076660156, 'residual_add_relu2': 0.00011014938354492188}\n",
      "{'conv1': 0.0011525154113769531, 'bn1': 0.00011396408081054688, 'relu1': 5.698204040527344e-05, 'conv2': 0.0011479854583740234, 'bn2': 0.00010800361633300781, 'residual_add_relu2': 0.00010895729064941406}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 468\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0016508102416992188, 'bn1': 0.0005552768707275391, 'relu1': 0.0003235340118408203, 'conv2': 0.001636505126953125, 'bn2': 0.0005414485931396484, 'residual_add_relu2': 0.0007650852203369141}\n",
      "{'conv1': 0.0016407966613769531, 'bn1': 0.0005426406860351562, 'relu1': 0.00032067298889160156, 'conv2': 0.001638174057006836, 'bn2': 0.0005316734313964844, 'residual_add_relu2': 0.0007643699645996094}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0010471343994140625, 'bn1': 0.0003075599670410156, 'relu1': 0.00017070770263671875, 'conv2': 0.0013124942779541016, 'bn2': 0.0003006458282470703, 'conv3': 0.00039196014404296875, 'residual_add_relu2': 0.00038909912109375}\n",
      "{'conv1': 0.0013134479522705078, 'bn1': 0.00031447410583496094, 'relu1': 0.00017309188842773438, 'conv2': 0.0013148784637451172, 'bn2': 0.0003075599670410156, 'residual_add_relu2': 0.0003902912139892578}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0007910728454589844, 'bn1': 0.00019931793212890625, 'relu1': 0.00010013580322265625, 'conv2': 0.001165151596069336, 'bn2': 0.0001952648162841797, 'conv3': 0.0003523826599121094, 'residual_add_relu2': 0.00020456314086914062}\n",
      "{'conv1': 0.0011646747589111328, 'bn1': 0.0001983642578125, 'relu1': 9.846687316894531e-05, 'conv2': 0.0011615753173828125, 'bn2': 0.00019550323486328125, 'residual_add_relu2': 0.0002040863037109375}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006628036499023438, 'bn1': 0.00011301040649414062, 'relu1': 5.7220458984375e-05, 'conv2': 0.0011506080627441406, 'bn2': 0.00010776519775390625, 'conv3': 0.00029015541076660156, 'residual_add_relu2': 0.00011205673217773438}\n",
      "{'conv1': 0.001155853271484375, 'bn1': 0.00011491775512695312, 'relu1': 5.626678466796875e-05, 'conv2': 0.0011477470397949219, 'bn2': 0.00010728836059570312, 'residual_add_relu2': 0.00010919570922851562}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "The batch is: 469\n",
      "The name of the layer is: Sequential_0\n",
      "Conv2d\n",
      "BatchNorm2d\n",
      "ReLU\n",
      "MaxPool2d\n",
      "The name of the layer is: Sequential_1\n",
      "{'conv1': 0.0012707710266113281, 'bn1': 0.0004410743713378906, 'relu1': 0.00025010108947753906, 'conv2': 0.0012466907501220703, 'bn2': 0.0004267692565917969, 'residual_add_relu2': 0.0005779266357421875}\n",
      "{'conv1': 0.0012509822845458984, 'bn1': 0.0004329681396484375, 'relu1': 0.0002484321594238281, 'conv2': 0.00124359130859375, 'bn2': 0.00042128562927246094, 'residual_add_relu2': 0.0005762577056884766}\n",
      "The name of the layer is: Sequential_2\n",
      "{'conv1': 0.0008184909820556641, 'bn1': 0.0002589225769042969, 'relu1': 0.0001354217529296875, 'conv2': 0.0010118484497070312, 'bn2': 0.00025010108947753906, 'conv3': 0.00036072731018066406, 'residual_add_relu2': 0.0002994537353515625}\n",
      "{'conv1': 0.0010085105895996094, 'bn1': 0.0002582073211669922, 'relu1': 0.00013756752014160156, 'conv2': 0.0010058879852294922, 'bn2': 0.00025272369384765625, 'residual_add_relu2': 0.00029754638671875}\n",
      "The name of the layer is: Sequential_3\n",
      "{'conv1': 0.0006573200225830078, 'bn1': 0.00018644332885742188, 'relu1': 8.559226989746094e-05, 'conv2': 0.0009093284606933594, 'bn2': 0.0001614093780517578, 'conv3': 0.0002899169921875, 'residual_add_relu2': 0.0001583099365234375}\n",
      "{'conv1': 0.0009014606475830078, 'bn1': 0.0001652240753173828, 'relu1': 7.939338684082031e-05, 'conv2': 0.0008940696716308594, 'bn2': 0.000164031982421875, 'residual_add_relu2': 0.00015807151794433594}\n",
      "The name of the layer is: Sequential_4\n",
      "{'conv1': 0.0006377696990966797, 'bn1': 0.00011444091796875, 'relu1': 5.030632019042969e-05, 'conv2': 0.0009541511535644531, 'bn2': 0.00010442733764648438, 'conv3': 0.0002505779266357422, 'residual_add_relu2': 8.702278137207031e-05}\n",
      "{'conv1': 0.0009365081787109375, 'bn1': 0.00010395050048828125, 'relu1': 4.9591064453125e-05, 'conv2': 0.0009312629699707031, 'bn2': 0.0001068115234375, 'residual_add_relu2': 8.678436279296875e-05}\n",
      "The name of the layer is: AdaptiveAvgPool2d_5\n",
      "The name of the layer is: Flatten_5\n",
      "The name of the layer is: Linear_5\n",
      "train acc 0.796, test acc 0.739\n"
     ]
    }
   ],
   "source": [
    "# sampling_interval = 0.002 # 2ms\n",
    "sampling_interval = 0.002 # 1ms\n",
    "# create the folder to store the data\n",
    "main_folder = DataList[0]\n",
    "\n",
    "print('The folder is:', main_folder)\n",
    "    # find out that if the folder exists in the data path\n",
    "    # 判断文件是否存在\n",
    "if main_folder.exists():\n",
    "    print(\"文件存在。\")\n",
    "else:\n",
    "    os.makedirs(main_folder)\n",
    "    print(\"文件不存在，已创建。\")\n",
    "    print(\"文件创建于：\", main_folder)\n",
    "for epoch in epochs:\n",
    "    for batch in batch_size:\n",
    "        for round in range(rounds):\n",
    "            train_model(main_folder, batch, epoch, round, lr, device, sampling_interval, resnet18_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greenai",
   "language": "python",
   "name": "greenai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
