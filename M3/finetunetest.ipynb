{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dtjgp/miniconda3/envs/greenai/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/dtjgp/miniconda3/envs/greenai/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned layer: 0\n",
      "Pruned layer: 3\n",
      "Pruned layer: 6\n",
      "Pruned layer: 8\n",
      "Pruned layer: 10\n",
      "Epoch 1/10: Train Loss: 2.897, Train Acc: 28.33%, Test Loss: 1.914, Test Acc: 47.60%, Epoch Time: 93.49s\n",
      "Epoch 2/10: Train Loss: 1.828, Train Acc: 49.65%, Test Loss: 1.639, Test Acc: 55.06%, Epoch Time: 89.03s\n",
      "Epoch 3/10: Train Loss: 1.532, Train Acc: 56.78%, Test Loss: 1.396, Test Acc: 60.65%, Epoch Time: 88.92s\n",
      "Epoch 4/10: Train Loss: 1.350, Train Acc: 61.12%, Test Loss: 1.322, Test Acc: 62.35%, Epoch Time: 89.05s\n",
      "Epoch 5/10: Train Loss: 1.231, Train Acc: 64.13%, Test Loss: 1.272, Test Acc: 63.74%, Epoch Time: 89.16s\n",
      "Epoch 6/10: Train Loss: 1.122, Train Acc: 66.90%, Test Loss: 1.195, Test Acc: 65.58%, Epoch Time: 88.59s\n",
      "Epoch 7/10: Train Loss: 1.042, Train Acc: 68.70%, Test Loss: 1.170, Test Acc: 66.33%, Epoch Time: 89.00s\n",
      "Epoch 8/10: Train Loss: 0.970, Train Acc: 70.73%, Test Loss: 1.155, Test Acc: 66.88%, Epoch Time: 88.88s\n",
      "Epoch 9/10: Train Loss: 0.899, Train Acc: 72.74%, Test Loss: 1.123, Test Acc: 68.12%, Epoch Time: 88.90s\n",
      "Epoch 10/10: Train Loss: 0.843, Train Acc: 74.22%, Test Loss: 1.146, Test Acc: 67.48%, Epoch Time: 88.75s\n",
      "Fine-tuning finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "\n",
    "# 设置设备：MacBook 推荐使用 mps，如不可用则使用 cuda 或 cpu\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ---------------------------\n",
    "# 数据预处理与加载\n",
    "# ---------------------------\n",
    "# 训练集数据预处理：resize 到256, 随机裁剪 224×224, 随机水平翻转, 转为 Tensor, 并归一化\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# 测试集数据预处理：resize 到256, CenterCrop 到224×224, 转为 Tensor, 并归一化\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 下载并加载 CIFAR100 数据集\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n",
    "test_dataset  = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# ---------------------------\n",
    "# 模型加载与修改\n",
    "# ---------------------------\n",
    "# 加载预训练的 AlexNet 模型\n",
    "model = models.alexnet(pretrained=True)\n",
    "# 修改最后一层全连接层，使其输出 100 类\n",
    "num_features = model.classifier[6].in_features  # 原本为4096\n",
    "model.classifier[6] = nn.Linear(num_features, 100)\n",
    "model = model.to(device)\n",
    "\n",
    "# 定义损失函数与优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# ---------------------------\n",
    "# 结构化剪枝操作\n",
    "# ---------------------------\n",
    "# 针对 model.features 中的所有卷积层，采用 L1 范数进行结构化剪枝（剪除 20% 的输出通道）\n",
    "for name, module in model.features.named_modules():\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        prune.ln_structured(module, name='weight', amount=0.2, n=1, dim=0)\n",
    "        # 移除剪枝时增加的 reparameterization，使剪枝结果永久生效\n",
    "        prune.remove(module, 'weight')\n",
    "        print(f\"Pruned layer: {name}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 微调训练\n",
    "# ---------------------------\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_train += targets.size(0)\n",
    "        correct_train += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100. * correct_train / total_train\n",
    "    \n",
    "    # 在测试集上评估模型\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_test += targets.size(0)\n",
    "            correct_test += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    test_loss = running_test_loss / len(test_loader)\n",
    "    test_acc = 100. * correct_test / total_test\n",
    "    \n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
    "          f\"Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, \"\n",
    "          f\"Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%, \"\n",
    "          f\"Epoch Time: {epoch_time:.2f}s\")\n",
    "\n",
    "print(\"Fine-tuning finished.\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# 加载 CIFAR100 测试集（train=False），数据会自动下载到 './data' 目录\n",
    "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "data_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, _) in enumerate(data_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        _ = model(inputs)\n",
    "        if i >= 10:\n",
    "            break\n",
    "    \n",
    "# 测量推断时间：对前 num_samples 个样本进行时间测量，并计算平均推断时间\n",
    "num_samples = 100\n",
    "total_time = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, _) in enumerate(data_loader):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "        inputs = inputs.to(device)\n",
    "        # 对于 mps 设备，目前无需手动同步，直接计时即可\n",
    "        start_time = time.time()\n",
    "        _ = model(inputs)\n",
    "        end_time = time.time()\n",
    "        total_time += (end_time - start_time)\n",
    "    \n",
    "    \n",
    "average_time = total_time / num_samples\n",
    "print(\"Average inference time over {} samples in {}: {:.6f} seconds\".format(num_samples, model.__class__.__name__, average_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dtjgp/miniconda3/envs/greenai/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/dtjgp/miniconda3/envs/greenai/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pruning: Total params: 11227812, Nonzero params: 11227812, Sparsity: 0.00%\n",
      "Pruned layer: conv1\n",
      "Pruned layer: layer1.0.conv1\n",
      "Pruned layer: layer1.0.conv2\n",
      "Pruned layer: layer1.1.conv1\n",
      "Pruned layer: layer1.1.conv2\n",
      "Pruned layer: layer2.0.conv1\n",
      "Pruned layer: layer2.0.conv2\n",
      "Pruned layer: layer2.0.downsample.0\n",
      "Pruned layer: layer2.1.conv1\n",
      "Pruned layer: layer2.1.conv2\n",
      "Pruned layer: layer3.0.conv1\n",
      "Pruned layer: layer3.0.conv2\n",
      "Pruned layer: layer3.0.downsample.0\n",
      "Pruned layer: layer3.1.conv1\n",
      "Pruned layer: layer3.1.conv2\n",
      "Pruned layer: layer4.0.conv1\n",
      "Pruned layer: layer4.0.conv2\n",
      "Pruned layer: layer4.0.downsample.0\n",
      "Pruned layer: layer4.1.conv1\n",
      "Pruned layer: layer4.1.conv2\n",
      "After pruning: Total params: 11227812, Nonzero params: 9000493, Sparsity: 19.84%\n",
      "Epoch 1/10: Train Loss: 2.571, Train Acc: 38.93%, Test Loss: 1.600, Test Acc: 57.59%, Epoch Time: 156.28s\n",
      "Epoch 2/10: Train Loss: 1.393, Train Acc: 62.76%, Test Loss: 1.175, Test Acc: 66.73%, Epoch Time: 152.65s\n",
      "Epoch 3/10: Train Loss: 1.065, Train Acc: 70.25%, Test Loss: 1.020, Test Acc: 70.69%, Epoch Time: 152.16s\n",
      "Epoch 4/10: Train Loss: 0.880, Train Acc: 75.06%, Test Loss: 0.928, Test Acc: 73.23%, Epoch Time: 152.36s\n",
      "Epoch 5/10: Train Loss: 0.750, Train Acc: 78.43%, Test Loss: 0.871, Test Acc: 74.35%, Epoch Time: 153.78s\n",
      "Epoch 6/10: Train Loss: 0.655, Train Acc: 80.91%, Test Loss: 0.850, Test Acc: 74.64%, Epoch Time: 157.70s\n",
      "Epoch 7/10: Train Loss: 0.581, Train Acc: 83.03%, Test Loss: 0.820, Test Acc: 75.69%, Epoch Time: 153.30s\n",
      "Epoch 8/10: Train Loss: 0.513, Train Acc: 85.32%, Test Loss: 0.810, Test Acc: 76.04%, Epoch Time: 152.99s\n",
      "Epoch 9/10: Train Loss: 0.453, Train Acc: 86.88%, Test Loss: 0.774, Test Acc: 77.55%, Epoch Time: 153.36s\n",
      "Epoch 10/10: Train Loss: 0.405, Train Acc: 88.43%, Test Loss: 0.781, Test Acc: 77.39%, Epoch Time: 153.80s\n",
      "Fine-tuning finished.\n",
      "Files already downloaded and verified\n",
      "Average inference time over 100 samples in ResNet: 0.003042 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import time\n",
    "\n",
    "# 设置设备：优先使用 mps（适用于 MacBook），否则使用 cuda 或 cpu\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ---------------------------\n",
    "# 数据预处理与加载\n",
    "# ---------------------------\n",
    "# 训练集数据预处理：resize 到256, 随机裁剪 224×224, 随机水平翻转, 转为 Tensor, 并归一化\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# 测试集数据预处理：resize 到256, CenterCrop 到224×224, 转为 Tensor, 并归一化\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 下载并加载 CIFAR100 数据集\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n",
    "test_dataset  = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# ---------------------------\n",
    "# 模型加载与修改（使用 ResNet18）\n",
    "# ---------------------------\n",
    "model = models.resnet18(pretrained=True)\n",
    "# 修改最后一层全连接层，使其输出 100 类\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 100)\n",
    "model = model.to(device)\n",
    "\n",
    "# 定义损失函数与优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# ---------------------------\n",
    "# 定义辅助函数：统计模型参数量\n",
    "# ---------------------------\n",
    "def get_model_size(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    nonzero_params = sum(torch.count_nonzero(p).item() for p in model.parameters())\n",
    "    return total_params, nonzero_params\n",
    "\n",
    "# 打印剪枝前模型的参数统计信息\n",
    "total_before, nonzero_before = get_model_size(model)\n",
    "print(f\"Before pruning: Total params: {total_before}, Nonzero params: {nonzero_before}, Sparsity: {100*(1 - nonzero_before/total_before):.2f}%\")\n",
    "\n",
    "# ---------------------------\n",
    "# 结构化剪枝操作\n",
    "# ---------------------------\n",
    "# 对模型中所有的卷积层进行结构化剪枝（剪除 20% 的输出通道）\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        prune.ln_structured(module, name='weight', amount=0.2, n=1, dim=0)\n",
    "        # 移除剪枝时增加的 reparameterization，使剪枝结果永久生效\n",
    "        prune.remove(module, 'weight')\n",
    "        print(f\"Pruned layer: {name}\")\n",
    "\n",
    "# 打印剪枝后模型的参数统计信息\n",
    "total_after, nonzero_after = get_model_size(model)\n",
    "print(f\"After pruning: Total params: {total_after}, Nonzero params: {nonzero_after}, Sparsity: {100*(1 - nonzero_after/total_after):.2f}%\")\n",
    "\n",
    "# ---------------------------\n",
    "# 微调训练\n",
    "# ---------------------------\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_train += targets.size(0)\n",
    "        correct_train += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100. * correct_train / total_train\n",
    "    \n",
    "    # 在测试集上评估模型\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_test += targets.size(0)\n",
    "            correct_test += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    test_loss = running_test_loss / len(test_loader)\n",
    "    test_acc = 100. * correct_test / total_test\n",
    "    \n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
    "          f\"Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, \"\n",
    "          f\"Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%, \"\n",
    "          f\"Epoch Time: {epoch_time:.2f}s\")\n",
    "\n",
    "print(\"Fine-tuning finished.\")\n",
    "\n",
    "# ---------------------------\n",
    "# 推断时间测试（取部分测试样本）\n",
    "# ---------------------------\n",
    "# 使用与测试集相同的预处理加载测试数据\n",
    "inference_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)\n",
    "data_loader = DataLoader(inference_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 预热部分样本\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, _) in enumerate(data_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        _ = model(inputs)\n",
    "        if i >= 10:\n",
    "            break\n",
    "\n",
    "# 测量推断时间：对前 num_samples 个样本进行时间测量，并计算平均推断时间\n",
    "num_samples = 100\n",
    "total_time = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, _) in enumerate(data_loader):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "        inputs = inputs.to(device)\n",
    "        start_time = time.time()\n",
    "        _ = model(inputs)\n",
    "        end_time = time.time()\n",
    "        total_time += (end_time - start_time)\n",
    "    \n",
    "average_time = total_time / num_samples\n",
    "print(\"Average inference time over {} samples in {}: {:.6f} seconds\".format(num_samples, model.__class__.__name__, average_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GreenAI",
   "language": "python",
   "name": "greenai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
