{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ad276f",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 深度卷积神经网络（AlexNet）\n",
    ":label:`sec_alexnet`\n",
    "\n",
    "在LeNet提出后，卷积神经网络在计算机视觉和机器学习领域中很有名气。但卷积神经网络并没有主导这些领域。这是因为虽然LeNet在小数据集上取得了很好的效果，但是在更大、更真实的数据集上训练卷积神经网络的性能和可行性还有待研究。事实上，在上世纪90年代初到2012年之间的大部分时间里，神经网络往往被其他机器学习方法超越，如支持向量机（support vector machines）。\n",
    "\n",
    "在计算机视觉中，直接将神经网络与其他机器学习方法进行比较也许不公平。这是因为，卷积神经网络的输入是由原始像素值或是经过简单预处理（例如居中、缩放）的像素值组成的。但在使用传统机器学习方法时，从业者永远不会将原始像素作为输入。在传统机器学习方法中，计算机视觉流水线是由经过人的手工精心设计的特征流水线组成的。对于这些传统方法，大部分的进展都来自于对特征有了更聪明的想法，并且学习到的算法往往归于事后的解释。\n",
    "\n",
    "虽然上世纪90年代就有了一些神经网络加速卡，但仅靠它们还不足以开发出有大量参数的深层多通道多层卷积神经网络。此外，当时的数据集仍然相对较小。除了这些障碍，训练神经网络的一些关键技巧仍然缺失，包括启发式参数初始化、随机梯度下降的变体、非挤压激活函数和有效的正则化技术。\n",
    "\n",
    "因此，与训练*端到端*（从像素到分类结果）系统不同，经典机器学习的流水线看起来更像下面这样：\n",
    "\n",
    "1. 获取一个有趣的数据集。在早期，收集这些数据集需要昂贵的传感器（在当时最先进的图像也就100万像素）。\n",
    "2. 根据光学、几何学、其他知识以及偶然的发现，手工对特征数据集进行预处理。\n",
    "3. 通过标准的特征提取算法，如SIFT（尺度不变特征变换） :cite:`Lowe.2004`和SURF（加速鲁棒特征） :cite:`Bay.Tuytelaars.Van-Gool.2006`或其他手动调整的流水线来输入数据。\n",
    "4. 将提取的特征送入最喜欢的分类器中（例如线性模型或其它核方法），以训练分类器。\n",
    "\n",
    "当人们和机器学习研究人员交谈时，会发现机器学习研究人员相信机器学习既重要又美丽：优雅的理论去证明各种模型的性质。机器学习是一个正在蓬勃发展、严谨且非常有用的领域。然而，当人们和计算机视觉研究人员交谈，会听到一个完全不同的故事。计算机视觉研究人员会告诉一个诡异事实————推动领域进步的是数据特征，而不是学习算法。计算机视觉研究人员相信，从对最终模型精度的影响来说，更大或更干净的数据集、或是稍微改进的特征提取，比任何学习算法带来的进步要大得多。\n",
    "\n",
    "## 学习表征\n",
    "\n",
    "另一种预测这个领域发展的方法————观察图像特征的提取方法。在2012年前，图像特征都是机械地计算出来的。事实上，设计一套新的特征函数、改进结果，并撰写论文是盛极一时的潮流。SIFT :cite:`Lowe.2004`、SURF :cite:`Bay.Tuytelaars.Van-Gool.2006`、HOG（定向梯度直方图） :cite:`Dalal.Triggs.2005`、[bags of visual words](https://en.wikipedia.org/wiki/Bag-of-words_model_in_computer_vision)和类似的特征提取方法占据了主导地位。\n",
    "\n",
    "另一组研究人员，包括Yann LeCun、Geoff Hinton、Yoshua Bengio、Andrew Ng、Shun ichi Amari和Juergen Schmidhuber，想法则与众不同：他们认为特征本身应该被学习。此外，他们还认为，在合理地复杂性前提下，特征应该由多个共同学习的神经网络层组成，每个层都有可学习的参数。在机器视觉中，最底层可能检测边缘、颜色和纹理。事实上，Alex Krizhevsky、Ilya Sutskever和Geoff Hinton提出了一种新的卷积神经网络变体*AlexNet*。在2012年ImageNet挑战赛中取得了轰动一时的成绩。AlexNet以Alex Krizhevsky的名字命名，他是论文 :cite:`Krizhevsky.Sutskever.Hinton.2012`的第一作者。\n",
    "\n",
    "有趣的是，在网络的最底层，模型学习到了一些类似于传统滤波器的特征抽取器。 :numref:`fig_filters`是从AlexNet论文 :cite:`Krizhevsky.Sutskever.Hinton.2012`复制的，描述了底层图像特征。\n",
    "\n",
    "![AlexNet第一层学习到的特征抽取器。](../img/filters.png)\n",
    ":width:`400px`\n",
    ":label:`fig_filters`\n",
    "\n",
    "AlexNet的更高层建立在这些底层表示的基础上，以表示更大的特征，如眼睛、鼻子、草叶等等。而更高的层可以检测整个物体，如人、飞机、狗或飞盘。最终的隐藏神经元可以学习图像的综合表示，从而使属于不同类别的数据易于区分。尽管一直有一群执着的研究者不断钻研，试图学习视觉数据的逐级表征，然而很长一段时间里这些尝试都未有突破。深度卷积神经网络的突破出现在2012年。突破可归因于两个关键因素。\n",
    "\n",
    "### 缺少的成分：数据\n",
    "\n",
    "包含许多特征的深度模型需要大量的有标签数据，才能显著优于基于凸优化的传统方法（如线性方法和核方法）。\n",
    "然而，限于早期计算机有限的存储和90年代有限的研究预算，大部分研究只基于小的公开数据集。例如，不少研究论文基于加州大学欧文分校（UCI）提供的若干个公开数据集，其中许多数据集只有几百至几千张在非自然环境下以低分辨率拍摄的图像。这一状况在2010年前后兴起的大数据浪潮中得到改善。2009年，ImageNet数据集发布，并发起ImageNet挑战赛：要求研究人员从100万个样本中训练模型，以区分1000个不同类别的对象。ImageNet数据集由斯坦福教授李飞飞小组的研究人员开发，利用谷歌图像搜索（Google Image Search）对每一类图像进行预筛选，并利用亚马逊众包（Amazon Mechanical Turk）来标注每张图片的相关类别。这种规模是前所未有的。这项被称为ImageNet的挑战赛推动了计算机视觉和机器学习研究的发展，挑战研究人员确定哪些模型能够在更大的数据规模下表现最好。\n",
    "\n",
    "### 缺少的成分：硬件\n",
    "\n",
    "深度学习对计算资源要求很高，训练可能需要数百个迭代轮数，每次迭代都需要通过代价高昂的许多线性代数层传递数据。这也是为什么在20世纪90年代至21世纪初，优化凸目标的简单算法是研究人员的首选。然而，用GPU训练神经网络改变了这一格局。*图形处理器*（Graphics Processing Unit，GPU）早年用来加速图形处理，使电脑游戏玩家受益。GPU可优化高吞吐量的$4 \\times 4$矩阵和向量乘法，从而服务于基本的图形任务。幸运的是，这些数学运算与卷积层的计算惊人地相似。由此，英伟达（NVIDIA）和ATI已经开始为通用计算操作优化gpu，甚至把它们作为*通用GPU*（general-purpose GPUs，GPGPU）来销售。\n",
    "\n",
    "那么GPU比CPU强在哪里呢？\n",
    "\n",
    "首先，我们深度理解一下中央处理器（Central Processing Unit，CPU）的*核心*。\n",
    "CPU的每个核心都拥有高时钟频率的运行能力，和高达数MB的三级缓存（L3Cache）。\n",
    "它们非常适合执行各种指令，具有分支预测器、深层流水线和其他使CPU能够运行各种程序的功能。\n",
    "然而，这种明显的优势也是它的致命弱点：通用核心的制造成本非常高。\n",
    "它们需要大量的芯片面积、复杂的支持结构（内存接口、内核之间的缓存逻辑、高速互连等等），而且它们在任何单个任务上的性能都相对较差。\n",
    "现代笔记本电脑最多有4核，即使是高端服务器也很少超过64核，因为它们的性价比不高。\n",
    "\n",
    "相比于CPU，GPU由$100 \\sim 1000$个小的处理单元组成（NVIDIA、ATI、ARM和其他芯片供应商之间的细节稍有不同），通常被分成更大的组（NVIDIA称之为warps）。\n",
    "虽然每个GPU核心都相对较弱，有时甚至以低于1GHz的时钟频率运行，但庞大的核心数量使GPU比CPU快几个数量级。\n",
    "例如，NVIDIA最近一代的Ampere GPU架构为每个芯片提供了高达312 TFlops的浮点性能，而CPU的浮点性能到目前为止还没有超过1 TFlops。\n",
    "之所以有如此大的差距，原因其实很简单：首先，功耗往往会随时钟频率呈二次方增长。\n",
    "对于一个CPU核心，假设它的运行速度比GPU快4倍，但可以使用16个GPU核代替，那么GPU的综合性能就是CPU的$16 \\times 1/4 = 4$倍。\n",
    "其次，GPU内核要简单得多，这使得它们更节能。\n",
    "此外，深度学习中的许多操作需要相对较高的内存带宽，而GPU拥有10倍于CPU的带宽。\n",
    "\n",
    "回到2012年的重大突破，当Alex Krizhevsky和Ilya Sutskever实现了可以在GPU硬件上运行的深度卷积神经网络时，一个重大突破出现了。他们意识到卷积神经网络中的计算瓶颈：卷积和矩阵乘法，都是可以在硬件上并行化的操作。\n",
    "于是，他们使用两个显存为3GB的NVIDIA GTX580 GPU实现了快速卷积运算。他们的创新[cuda-convnet](https://code.google.com/archive/p/cuda-convnet/)几年来它一直是行业标准，并推动了深度学习热潮。\n",
    "\n",
    "## AlexNet\n",
    "\n",
    "2012年，AlexNet横空出世。它首次证明了学习到的特征可以超越手工设计的特征。它一举打破了计算机视觉研究的现状。\n",
    "AlexNet使用了8层卷积神经网络，并以很大的优势赢得了2012年ImageNet图像识别挑战赛。\n",
    "\n",
    "AlexNet和LeNet的架构非常相似，如 :numref:`fig_alexnet`所示。\n",
    "注意，本书在这里提供的是一个稍微精简版本的AlexNet，去除了当年需要两个小型GPU同时运算的设计特点。\n",
    "\n",
    "![从LeNet（左）到AlexNet（右）](../img/alexnet.svg)\n",
    ":label:`fig_alexnet`\n",
    "\n",
    "AlexNet和LeNet的设计理念非常相似，但也存在显著差异。\n",
    "\n",
    "1. AlexNet比相对较小的LeNet5要深得多。AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。\n",
    "2. AlexNet使用ReLU而不是sigmoid作为其激活函数。\n",
    "\n",
    "下面的内容将深入研究AlexNet的细节。\n",
    "\n",
    "### 模型设计\n",
    "\n",
    "在AlexNet的第一层，卷积窗口的形状是$11\\times11$。\n",
    "由于ImageNet中大多数图像的宽和高比MNIST图像的多10倍以上，因此，需要一个更大的卷积窗口来捕获目标。\n",
    "第二层中的卷积窗口形状被缩减为$5\\times5$，然后是$3\\times3$。\n",
    "此外，在第一层、第二层和第五层卷积层之后，加入窗口形状为$3\\times3$、步幅为2的最大汇聚层。\n",
    "而且，AlexNet的卷积通道数目是LeNet的10倍。\n",
    "\n",
    "在最后一个卷积层后有两个全连接层，分别有4096个输出。\n",
    "这两个巨大的全连接层拥有将近1GB的模型参数。\n",
    "由于早期GPU显存有限，原版的AlexNet采用了双数据流设计，使得每个GPU只负责存储和计算模型的一半参数。\n",
    "幸运的是，现在GPU显存相对充裕，所以现在很少需要跨GPU分解模型（因此，本书的AlexNet模型在这方面与原始论文稍有不同）。\n",
    "\n",
    "### 激活函数\n",
    "\n",
    "此外，AlexNet将sigmoid激活函数改为更简单的ReLU激活函数。\n",
    "一方面，ReLU激活函数的计算更简单，它不需要如sigmoid激活函数那般复杂的求幂运算。\n",
    "另一方面，当使用不同的参数初始化方法时，ReLU激活函数使训练模型更加容易。\n",
    "当sigmoid激活函数的输出非常接近于0或1时，这些区域的梯度几乎为0，因此反向传播无法继续更新一些模型参数。\n",
    "相反，ReLU激活函数在正区间的梯度总是1。\n",
    "因此，如果模型参数没有正确初始化，sigmoid函数可能在正区间内得到几乎为0的梯度，从而使模型无法得到有效的训练。\n",
    "\n",
    "### 容量控制和预处理\n",
    "\n",
    "AlexNet通过暂退法（ :numref:`sec_dropout`）控制全连接层的模型复杂度，而LeNet只使用了权重衰减。\n",
    "为了进一步扩充数据，AlexNet在训练时增加了大量的图像增强数据，如翻转、裁切和变色。\n",
    "这使得模型更健壮，更大的样本量有效地减少了过拟合。\n",
    "在 :numref:`sec_image_augmentation`中更详细地讨论数据扩增。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c7ae34b7",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import time\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "net = nn.Sequential(\n",
    "    # 这里使用一个11*11的更大窗口来捕捉对象。\n",
    "    # 同时，步幅为4，以减少输出的高度和宽度。\n",
    "    # 另外，输出通道的数目远大于LeNet\n",
    "    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 使用三个连续的卷积层和较小的卷积窗口。\n",
    "    # 除了最后的卷积层，输出通道的数量进一步增加。\n",
    "    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Flatten(),\n",
    "    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合\n",
    "    nn.Linear(6400, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "    nn.Linear(4096, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d97a07",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "[**我们构造一个**]高度和宽度都为224的(**单通道数据，来观察每一层输出的形状**)。\n",
    "它与 :numref:`fig_alexnet`中的AlexNet架构相匹配。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "37a7ec36",
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 96, 54, 54])\n",
      "ReLU output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 26, 26])\n",
      "ReLU output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 256, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 5, 5])\n",
      "Flatten output shape:\t torch.Size([1, 6400])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1, 1, 224, 224)\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c79a7",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "## 读取数据集\n",
    "\n",
    "尽管原文中AlexNet是在ImageNet上进行训练的，但本书在这里使用的是Fashion-MNIST数据集。因为即使在现代GPU上，训练ImageNet模型，同时使其收敛可能需要数小时或数天的时间。\n",
    "将AlexNet直接应用于Fashion-MNIST的一个问题是，[**Fashion-MNIST图像的分辨率**]（$28 \\times 28$像素）(**低于ImageNet图像。**)\n",
    "为了解决这个问题，(**我们将它们增加到$224 \\times 224$**)（通常来讲这不是一个明智的做法，但在这里这样做是为了有效使用AlexNet架构）。\n",
    "这里需要使用`d2l.load_data_fashion_mnist`函数中的`resize`参数执行此调整。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4c1552a8",
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[0;32m----> 2\u001b[0m train_iter, test_iter \u001b[38;5;241m=\u001b[39m \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data_fashion_mnist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print the shape of the train_iter\u001b[39;00m\n\u001b[1;32m      4\u001b[0m list_of_i \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/d2l/torch.py:3018\u001b[0m, in \u001b[0;36mload_data_fashion_mnist\u001b[0;34m(batch_size, resize)\u001b[0m\n\u001b[1;32m   3016\u001b[0m     trans\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, transforms\u001b[38;5;241m.\u001b[39mResize(resize))\n\u001b[1;32m   3017\u001b[0m trans \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose(trans)\n\u001b[0;32m-> 3018\u001b[0m mnist_train \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFashionMNIST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3020\u001b[0m mnist_test \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mFashionMNIST(\n\u001b[1;32m   3021\u001b[0m     root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtrans, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(mnist_train, batch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   3023\u001b[0m                                     num_workers\u001b[38;5;241m=\u001b[39mget_dataloader_workers()),\n\u001b[1;32m   3024\u001b[0m         torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(mnist_test, batch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3025\u001b[0m                                     num_workers\u001b[38;5;241m=\u001b[39mget_dataloader_workers()))\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/torchvision/datasets/mnist.py:99\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/torchvision/datasets/mnist.py:179\u001b[0m, in \u001b[0;36mMNIST.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# download files\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename, md5 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresources:\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/os.py:213\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/os.py:213\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/os.py:223\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data'"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "# print the shape of the train_iter\n",
    "list_of_i = []\n",
    "for i, (X, y) in enumerate(train_iter):\n",
    "    list_of_i.append(i)\n",
    "\n",
    "print('the shape of the train_iter is:', np.array(list_of_i).shape)\n",
    "# print(list_of_i)\n",
    "# print the first 10 batch of the train_iter\n",
    "for i, (X, y) in enumerate(train_iter):\n",
    "    if i < 10:\n",
    "        print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d484d7f3",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "## [**训练AlexNet**]\n",
    "\n",
    "现在AlexNet可以开始被训练了。与 :numref:`sec_lenet`中的LeNet相比，这里的主要变化是使用更小的学习速率训练，这是因为网络更深更广、图像分辨率更高，训练卷积神经网络就更昂贵。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "516c82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_powermetrics(file_path):\n",
    "    \"\"\"\n",
    "    Run powermetrics and retrieve the output.\n",
    "    :param interval: Sampling interval in milliseconds.\n",
    "    :param count: Number of samples to retrieve.s\n",
    "    :return: The output from powermetrics.\n",
    "    \"\"\"\n",
    "    # Define the command as a list of arguments\n",
    "    cmd = [\"sudo\", \"powermetrics\",  \"-i\", \"1000\", \"--samplers\", \"cpu_power,gpu_power\", \"-a\", \"1\", \"-o\", file_path]\n",
    "    process = subprocess.Popen(cmd)\n",
    "    return process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "89638b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_data_process(file_path):\n",
    "    \"\"\"\n",
    "    Read the output file of powermetric and extract the power value\n",
    "    :param file_path: The path of the output file of powermetric.\n",
    "    :return: The list of power values.\n",
    "    \"\"\"\n",
    "    list_power = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Combined Power' in line:\n",
    "                power_value = line.split(':')[1].strip()\n",
    "                # print(power_value)\n",
    "                # Remove the unit\n",
    "                power_value = power_value.replace('mW', '')\n",
    "                # Convert to integer\n",
    "                power_value = int(power_value)\n",
    "                list_power.append(power_value)\n",
    "    '''\n",
    "    The data from list_power is the Conbined Power of each second.\n",
    "    The data is the Power of each second.\n",
    "    we need to calculate the energy consumption of the whole process.\n",
    "    and need to change the J to kWh.\n",
    "    '''\n",
    "    # calculate the energy consumption\n",
    "    energy_consumption = 0\n",
    "    for i in range(len(list_power)):\n",
    "       energy_consumption += list_power[i]\n",
    "    # change the mW to W\n",
    "    energy_consumption = energy_consumption / 1000\n",
    "    # calculate the energy consumption, the interval is 1 second, and the energy unit is J\n",
    "    energy_consumption = energy_consumption * 1\n",
    "    # change the J to kWh\n",
    "    energy_consumption = energy_consumption / 3600000\n",
    "    return energy_consumption, list_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "41bfa77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_file = 'energy_alexnet.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "对train_ch6()函数进行修改，使得能够在每一层的前向传播的时候，记录下时间, \n",
    "能耗部分不好进行具体统计，因为每个层的能耗有区别，并且时间过短，所以采用的方式为计算总能耗和总时长，最后通过平均值来计算估算的能耗\n",
    "'''\n",
    "def train_ch6self(net, train_iter, test_iter, num_epochs, lr, device, energy_file):\n",
    "    def init_weights(m): # 初始化权重\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    # set a list of layer name\n",
    "    list_layer_name = ['Conv2d','ReLU','MaxPool2d','Linear','Dropout','Flatten'] # 该模型中包括的所有的层的名字\n",
    "    # create a numpy array to store the time and energy consumption, the shape is (num_epochs, len(list_layer_name), 2)\n",
    "    # for each epoch, the shape is (6,2), contains the total time and the energy consumption of each layer\n",
    "    timeenergy_data_forward = np.zeros((num_epochs, len(list_layer_name), 2)) \n",
    "    # for each epoch, the shape is (6,2), contains the total time of each part in a round, which is to_device, forward, loss, backward, optimizer，test_round\n",
    "    # and the 2 means time and energy consumption, respectively\n",
    "    timeenergy_data_round = np.zeros((num_epochs, 6, 2)) \n",
    "    # create another numpy array to store the data of each epoch, 1 column is training loss, 2 column is training accuracy, 3 column is test accuracy\n",
    "    acc_data = []\n",
    "    # create a numpy array to store the train loss and train accuracy\n",
    "    train_l = []\n",
    "    train_acc = []\n",
    "    # create a numpy array to store the epoch and running time\n",
    "    time_data_epoch = np.zeros((num_epochs, 2))\n",
    "    # create a numpy array to store the energy consumption of each epoch\n",
    "    energy_data_epoch = np.zeros((num_epochs, 1), dtype=object)\n",
    "    # print the training device\n",
    "    print('training on', device)\n",
    "    net.to(device) # 将模型放到对应的设备上\n",
    "    # 初始化optimizer和loss\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    # 初始化计时器\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)   \n",
    "    # 开始训练\n",
    "    for epoch in range(num_epochs):\n",
    "        print('epoch %d' % (epoch + 1))\n",
    "        # each epoch, set a timer to record the time\n",
    "        timer.start()\n",
    "        powermetrics_process = run_powermetrics(energy_file)\n",
    "        net.train() # 设置为训练模式\n",
    "        # 初始化每个epoch的统计时间的变量\n",
    "        time_to_device_cost, time_forward, time_cost_loss = 0,0,0\n",
    "        time_cost_backward, time_cost_optimizer, time_test_acc_cost = 0,0,0\n",
    "        train_l_epoch = []\n",
    "        train_acc_epoch = []\n",
    "        metric = d2l.Accumulator(3)\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            print('round %d' % (i))\n",
    "            time_round_start = time.time() # 计算每一轮的时间s\n",
    "            optimizer.zero_grad() # 将optimizer的梯度清零s\n",
    "        ##################################################################################\n",
    "            # 计算将数据放到对应的设备上的时间\n",
    "            time_to_device_cost_i = 0\n",
    "            time_to_device = time.time()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            time_to_device_end = time.time()\n",
    "            time_to_device_cost_i = time_to_device_end - time_to_device\n",
    "            print('time to device %f sec' % (time_to_device_cost_i))\n",
    "            time_to_device_cost += time_to_device_cost_i\n",
    "        ##################################################################################\n",
    "            # 将原本的模型进行修改，使得能够逐层进行运行，并且在这个过程中，记录下时间和能量\n",
    "            y_hat = X\n",
    "            for layer in net:\n",
    "                time_cost_layer = 0\n",
    "                layer_name = layer.__class__.__name__ # 获取层的名字\n",
    "                # find out the layer name is in where of the list\n",
    "                layer_index = list_layer_name.index(layer_name)\n",
    "                # calculate the time\n",
    "                time_start_layer = time.time()\n",
    "                y_hat = layer(y_hat)\n",
    "                time_end_layer = time.time()\n",
    "                time_cost_layer = time_end_layer - time_start_layer\n",
    "                timeenergy_data_forward[epoch,layer_index,0] += time_cost_layer\n",
    "                if torch.isinf(y_hat).any() or torch.isnan(y_hat).any():\n",
    "                    print(\"Inf or NaN detected in y_hat\")\n",
    "            # 计算前向的时间\n",
    "            time_forward = np.sum(timeenergy_data_forward[epoch,:,0])\n",
    "            print('time forward %f sec' % (time_forward))\n",
    "        ##################################################################################\n",
    "            # 计算loss\n",
    "            time_cost_loss_i = 0 # 初始化loss的时间\n",
    "            time_start_loss = time.time()\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            # print(loss)\n",
    "            time_end_loss = time.time()\n",
    "            time_cost_loss_i = time_end_loss - time_start_loss\n",
    "            print('loss time %f sec' % (time_cost_loss_i))\n",
    "            time_cost_loss += time_cost_loss_i\n",
    "        ##################################################################################\n",
    "            # 计算backward\n",
    "            time_cost_backward_i = 0 # 初始化backward的时间\n",
    "            time_start_backward = time.time()\n",
    "            loss.backward()\n",
    "            time_end_backward = time.time()\n",
    "            time_cost_backward_i = time_end_backward - time_start_backward\n",
    "            print('backward time %f sec' % (time_cost_backward_i))\n",
    "            time_cost_backward += time_cost_backward_i\n",
    "        ##################################################################################\n",
    "            # 计算optimizer\n",
    "            time_cost_optimizer_i = 0 # 初始化optimizer的时间\n",
    "            time_start_optimizer = time.time()\n",
    "            optimizer.step()\n",
    "            time_end_optimizer = time.time()\n",
    "            time_cost_optimizer_i = time_end_optimizer - time_start_optimizer\n",
    "            print('optimizer time %f sec' % (time_cost_optimizer_i))\n",
    "            time_cost_optimizer += time_cost_optimizer_i\n",
    "        ##################################################################################\n",
    "            time_round_end = time.time()\n",
    "            time_round_cost = time_round_end - time_round_start\n",
    "            print(f'training time in round {i} cost {time_round_cost} sec')\n",
    "        ##################################################################################\n",
    "            with torch.no_grad():\n",
    "                metric.add(loss * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            train_l_i = metric[0] / metric[2]\n",
    "            train_acc_i = metric[1] / metric[2]\n",
    "            train_l_epoch.append(train_l_i)\n",
    "            train_acc_epoch.append(train_acc_i)\n",
    "            print('loss %f, train acc %f' % (train_l_i, train_acc_i))\n",
    "        train_l.append(train_l_epoch)\n",
    "        train_acc.append(train_acc_epoch)\n",
    "        ##################################################################################\n",
    "        # 进行模型的test部分运行\n",
    "        time_test_acc_cost_epoch = 0\n",
    "        time_test_acc_start = time.time()\n",
    "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter, device)\n",
    "        time_test_acc_end = time.time()\n",
    "        time_test_acc_cost_epoch = time_test_acc_end - time_test_acc_start\n",
    "        time_test_acc_cost += time_test_acc_cost_epoch\n",
    "        print('test acc is %f' % (test_acc))\n",
    "        acc_data.append(test_acc)\n",
    "        ##################################################################################\n",
    "        # 将每一轮的每个部分的时间加入到time_data_round中\n",
    "        timeenergy_data_round[epoch,0,0] = time_to_device_cost\n",
    "        timeenergy_data_round[epoch,1,0] = time_forward\n",
    "        timeenergy_data_round[epoch,2,0] = time_cost_loss\n",
    "        timeenergy_data_round[epoch,3,0] = time_cost_backward\n",
    "        timeenergy_data_round[epoch,4,0] = time_cost_optimizer\n",
    "        timeenergy_data_round[epoch,5,0] = time_test_acc_cost\n",
    "        ##################################################################################\n",
    "        # stop the powermetrics\n",
    "        powermetrics_process.terminate()\n",
    "        powermetrics_process.wait()\n",
    "        timer.stop() # 停止计时 \n",
    "        time_data_epoch[epoch,0] = epoch + 1\n",
    "        time_data_epoch[epoch,1] = timer.sum()\n",
    "        print('epoch %d, time %f sec' % (epoch, timer.sum()))\n",
    "        ##################################################################################\n",
    "        # calculate the energy consumption of each layer\n",
    "        energy_consumption, power_list_model = txt_data_process(energy_file)\n",
    "        training_time_epoch_record = len(power_list_model)\n",
    "        energy_consumption_J = energy_consumption * 3600000\n",
    "        avg_energy_cost_persec = energy_consumption_J / training_time_epoch_record  # 计算每秒的平均能耗\n",
    "        ##################################################################################\n",
    "        # 将每一轮的每个部分的能耗加入到time_data_forward中\n",
    "        for l in range(len(timeenergy_data_forward[epoch,:,0])):\n",
    "            timeenergy_data_forward[epoch, l, 1] = timeenergy_data_forward[epoch, l, 0] * avg_energy_cost_persec\n",
    "        # 将每一轮的每个部分的能耗加入到time_data_round中\n",
    "        for m in range(len(timeenergy_data_round[epoch,:,0])):\n",
    "            timeenergy_data_round[epoch, m, 1] = timeenergy_data_round[epoch, m, 0] * avg_energy_cost_persec\n",
    "        ##################################################################################\n",
    "        # 对采集到的能耗数据进行保存\n",
    "        energy_data_epoch[epoch,0] = power_list_model\n",
    "        \n",
    "    return timeenergy_data_forward, timeenergy_data_round, acc_data, train_l, train_acc, time_data_epoch, energy_data_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on mps\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "powermetrics: can't open output file for writing\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lr, num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m timeenergy_data_forward, timeenergy_data_round, acc_data, train_l, train_acc, time_data_epoch, energy_data_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ch6self\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menergy_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[110], line 48\u001b[0m, in \u001b[0;36mtrain_ch6self\u001b[0;34m(net, train_iter, test_iter, num_epochs, lr, device, energy_file)\u001b[0m\n\u001b[1;32m     46\u001b[0m train_acc_epoch \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     47\u001b[0m metric \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mAccumulator(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mround \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (i))\n\u001b[1;32m     50\u001b[0m     time_round_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;66;03m# 计算每一轮的时间s\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/torch/utils/data/dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1035\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/multiprocessing/popen_spawn_posix.py:42\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     40\u001b[0m tracker_fd \u001b[38;5;241m=\u001b[39m resource_tracker\u001b[38;5;241m.\u001b[39mgetfd()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds\u001b[38;5;241m.\u001b[39mappend(tracker_fd)\n\u001b[0;32m---> 42\u001b[0m prep_data \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_preparation_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[1;32m     44\u001b[0m set_spawning_popen(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/multiprocessing/spawn.py:176\u001b[0m, in \u001b[0;36mget_preparation_data\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     sys_path[i] \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mORIGINAL_DIR\n\u001b[1;32m    171\u001b[0m d\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    172\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    173\u001b[0m     sys_path\u001b[38;5;241m=\u001b[39msys_path,\n\u001b[1;32m    174\u001b[0m     sys_argv\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39margv,\n\u001b[1;32m    175\u001b[0m     orig_dir\u001b[38;5;241m=\u001b[39mprocess\u001b[38;5;241m.\u001b[39mORIGINAL_DIR,\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    177\u001b[0m     start_method\u001b[38;5;241m=\u001b[39mget_start_method(),\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# Figure out whether to initialise main in the subprocess as a module\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# or through direct execution (or to leave it alone entirely)\u001b[39;00m\n\u001b[1;32m    182\u001b[0m main_module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 5\n",
    "device = 'mps'\n",
    "timeenergy_data_forward, timeenergy_data_round, acc_data, train_l, train_acc, time_data_epoch, energy_data_epoch = train_ch6self(net, train_iter, test_iter, num_epochs, lr, device, energy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d7896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dtjgp/Learning/Thesis/GreenAI/M1chip/Third_part/FL_code\n",
      "/Users/dtjgp/Learning/Thesis/GreenAI/M1chip/Third_part\n",
      "/Users/dtjgp/Learning/Thesis/GreenAI/M1chip/Third_part/data/5epochs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "working_dir = os.getcwd()\n",
    "print(working_dir)\n",
    "\n",
    "# get the parent directory\n",
    "parent_dir = os.path.dirname(working_dir)\n",
    "print(parent_dir)\n",
    "\n",
    "# get the data directory\n",
    "data_dir = os.path.join(parent_dir, 'data/5epochs')\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83054b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the parameters in the data directory\n",
    "data_dir_selected = os.path.join(data_dir, 'net2')\n",
    "torch.save(net, os.path.join(data_dir_selected,'net_alexnet.pth'))\n",
    "torch.save(net.state_dict(), os.path.join(data_dir_selected, 'net_state_dict_alexnet.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeenergy_data_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeenergy_data_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_data_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_data_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# working_dir = os.getcwd()\n",
    "# working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dtjgp/Learning/Thesis/GreenAI/M1chip/Third_part/data/5epochs/net2/info\n"
     ]
    }
   ],
   "source": [
    "# # find the second_part folder\n",
    "info_dir = os.path.join(data_dir_selected, 'info')\n",
    "print(info_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data as .npy file\n",
    "np.save(os.path.join(info_dir, 'timeenergy_data_forward.npy'), timeenergy_data_forward)\n",
    "np.save(os.path.join(info_dir, 'timeenergy_data_round.npy'), timeenergy_data_round)\n",
    "np.save(os.path.join(info_dir, 'acc_data.npy'), acc_data)\n",
    "np.save(os.path.join(info_dir, 'train_acc.npy'), train_acc)\n",
    "np.save(os.path.join(info_dir, 'train_l.npy'), train_l)\n",
    "np.save(os.path.join(info_dir, 'time_data_epoch.npy'), time_data_epoch)\n",
    "np.save(os.path.join(info_dir, 'energy_data_epoch.npy'), energy_data_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
