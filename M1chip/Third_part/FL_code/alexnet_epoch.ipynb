{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ad276f",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 深度卷积神经网络（AlexNet）\n",
    ":label:`sec_alexnet`\n",
    "\n",
    "在LeNet提出后，卷积神经网络在计算机视觉和机器学习领域中很有名气。但卷积神经网络并没有主导这些领域。这是因为虽然LeNet在小数据集上取得了很好的效果，但是在更大、更真实的数据集上训练卷积神经网络的性能和可行性还有待研究。事实上，在上世纪90年代初到2012年之间的大部分时间里，神经网络往往被其他机器学习方法超越，如支持向量机（support vector machines）。\n",
    "\n",
    "在计算机视觉中，直接将神经网络与其他机器学习方法进行比较也许不公平。这是因为，卷积神经网络的输入是由原始像素值或是经过简单预处理（例如居中、缩放）的像素值组成的。但在使用传统机器学习方法时，从业者永远不会将原始像素作为输入。在传统机器学习方法中，计算机视觉流水线是由经过人的手工精心设计的特征流水线组成的。对于这些传统方法，大部分的进展都来自于对特征有了更聪明的想法，并且学习到的算法往往归于事后的解释。\n",
    "\n",
    "虽然上世纪90年代就有了一些神经网络加速卡，但仅靠它们还不足以开发出有大量参数的深层多通道多层卷积神经网络。此外，当时的数据集仍然相对较小。除了这些障碍，训练神经网络的一些关键技巧仍然缺失，包括启发式参数初始化、随机梯度下降的变体、非挤压激活函数和有效的正则化技术。\n",
    "\n",
    "因此，与训练*端到端*（从像素到分类结果）系统不同，经典机器学习的流水线看起来更像下面这样：\n",
    "\n",
    "1. 获取一个有趣的数据集。在早期，收集这些数据集需要昂贵的传感器（在当时最先进的图像也就100万像素）。\n",
    "2. 根据光学、几何学、其他知识以及偶然的发现，手工对特征数据集进行预处理。\n",
    "3. 通过标准的特征提取算法，如SIFT（尺度不变特征变换） :cite:`Lowe.2004`和SURF（加速鲁棒特征） :cite:`Bay.Tuytelaars.Van-Gool.2006`或其他手动调整的流水线来输入数据。\n",
    "4. 将提取的特征送入最喜欢的分类器中（例如线性模型或其它核方法），以训练分类器。\n",
    "\n",
    "当人们和机器学习研究人员交谈时，会发现机器学习研究人员相信机器学习既重要又美丽：优雅的理论去证明各种模型的性质。机器学习是一个正在蓬勃发展、严谨且非常有用的领域。然而，当人们和计算机视觉研究人员交谈，会听到一个完全不同的故事。计算机视觉研究人员会告诉一个诡异事实————推动领域进步的是数据特征，而不是学习算法。计算机视觉研究人员相信，从对最终模型精度的影响来说，更大或更干净的数据集、或是稍微改进的特征提取，比任何学习算法带来的进步要大得多。\n",
    "\n",
    "## 学习表征\n",
    "\n",
    "另一种预测这个领域发展的方法————观察图像特征的提取方法。在2012年前，图像特征都是机械地计算出来的。事实上，设计一套新的特征函数、改进结果，并撰写论文是盛极一时的潮流。SIFT :cite:`Lowe.2004`、SURF :cite:`Bay.Tuytelaars.Van-Gool.2006`、HOG（定向梯度直方图） :cite:`Dalal.Triggs.2005`、[bags of visual words](https://en.wikipedia.org/wiki/Bag-of-words_model_in_computer_vision)和类似的特征提取方法占据了主导地位。\n",
    "\n",
    "另一组研究人员，包括Yann LeCun、Geoff Hinton、Yoshua Bengio、Andrew Ng、Shun ichi Amari和Juergen Schmidhuber，想法则与众不同：他们认为特征本身应该被学习。此外，他们还认为，在合理地复杂性前提下，特征应该由多个共同学习的神经网络层组成，每个层都有可学习的参数。在机器视觉中，最底层可能检测边缘、颜色和纹理。事实上，Alex Krizhevsky、Ilya Sutskever和Geoff Hinton提出了一种新的卷积神经网络变体*AlexNet*。在2012年ImageNet挑战赛中取得了轰动一时的成绩。AlexNet以Alex Krizhevsky的名字命名，他是论文 :cite:`Krizhevsky.Sutskever.Hinton.2012`的第一作者。\n",
    "\n",
    "有趣的是，在网络的最底层，模型学习到了一些类似于传统滤波器的特征抽取器。 :numref:`fig_filters`是从AlexNet论文 :cite:`Krizhevsky.Sutskever.Hinton.2012`复制的，描述了底层图像特征。\n",
    "\n",
    "![AlexNet第一层学习到的特征抽取器。](../img/filters.png)\n",
    ":width:`400px`\n",
    ":label:`fig_filters`\n",
    "\n",
    "AlexNet的更高层建立在这些底层表示的基础上，以表示更大的特征，如眼睛、鼻子、草叶等等。而更高的层可以检测整个物体，如人、飞机、狗或飞盘。最终的隐藏神经元可以学习图像的综合表示，从而使属于不同类别的数据易于区分。尽管一直有一群执着的研究者不断钻研，试图学习视觉数据的逐级表征，然而很长一段时间里这些尝试都未有突破。深度卷积神经网络的突破出现在2012年。突破可归因于两个关键因素。\n",
    "\n",
    "### 缺少的成分：数据\n",
    "\n",
    "包含许多特征的深度模型需要大量的有标签数据，才能显著优于基于凸优化的传统方法（如线性方法和核方法）。\n",
    "然而，限于早期计算机有限的存储和90年代有限的研究预算，大部分研究只基于小的公开数据集。例如，不少研究论文基于加州大学欧文分校（UCI）提供的若干个公开数据集，其中许多数据集只有几百至几千张在非自然环境下以低分辨率拍摄的图像。这一状况在2010年前后兴起的大数据浪潮中得到改善。2009年，ImageNet数据集发布，并发起ImageNet挑战赛：要求研究人员从100万个样本中训练模型，以区分1000个不同类别的对象。ImageNet数据集由斯坦福教授李飞飞小组的研究人员开发，利用谷歌图像搜索（Google Image Search）对每一类图像进行预筛选，并利用亚马逊众包（Amazon Mechanical Turk）来标注每张图片的相关类别。这种规模是前所未有的。这项被称为ImageNet的挑战赛推动了计算机视觉和机器学习研究的发展，挑战研究人员确定哪些模型能够在更大的数据规模下表现最好。\n",
    "\n",
    "### 缺少的成分：硬件\n",
    "\n",
    "深度学习对计算资源要求很高，训练可能需要数百个迭代轮数，每次迭代都需要通过代价高昂的许多线性代数层传递数据。这也是为什么在20世纪90年代至21世纪初，优化凸目标的简单算法是研究人员的首选。然而，用GPU训练神经网络改变了这一格局。*图形处理器*（Graphics Processing Unit，GPU）早年用来加速图形处理，使电脑游戏玩家受益。GPU可优化高吞吐量的$4 \\times 4$矩阵和向量乘法，从而服务于基本的图形任务。幸运的是，这些数学运算与卷积层的计算惊人地相似。由此，英伟达（NVIDIA）和ATI已经开始为通用计算操作优化gpu，甚至把它们作为*通用GPU*（general-purpose GPUs，GPGPU）来销售。\n",
    "\n",
    "那么GPU比CPU强在哪里呢？\n",
    "\n",
    "首先，我们深度理解一下中央处理器（Central Processing Unit，CPU）的*核心*。\n",
    "CPU的每个核心都拥有高时钟频率的运行能力，和高达数MB的三级缓存（L3Cache）。\n",
    "它们非常适合执行各种指令，具有分支预测器、深层流水线和其他使CPU能够运行各种程序的功能。\n",
    "然而，这种明显的优势也是它的致命弱点：通用核心的制造成本非常高。\n",
    "它们需要大量的芯片面积、复杂的支持结构（内存接口、内核之间的缓存逻辑、高速互连等等），而且它们在任何单个任务上的性能都相对较差。\n",
    "现代笔记本电脑最多有4核，即使是高端服务器也很少超过64核，因为它们的性价比不高。\n",
    "\n",
    "相比于CPU，GPU由$100 \\sim 1000$个小的处理单元组成（NVIDIA、ATI、ARM和其他芯片供应商之间的细节稍有不同），通常被分成更大的组（NVIDIA称之为warps）。\n",
    "虽然每个GPU核心都相对较弱，有时甚至以低于1GHz的时钟频率运行，但庞大的核心数量使GPU比CPU快几个数量级。\n",
    "例如，NVIDIA最近一代的Ampere GPU架构为每个芯片提供了高达312 TFlops的浮点性能，而CPU的浮点性能到目前为止还没有超过1 TFlops。\n",
    "之所以有如此大的差距，原因其实很简单：首先，功耗往往会随时钟频率呈二次方增长。\n",
    "对于一个CPU核心，假设它的运行速度比GPU快4倍，但可以使用16个GPU核代替，那么GPU的综合性能就是CPU的$16 \\times 1/4 = 4$倍。\n",
    "其次，GPU内核要简单得多，这使得它们更节能。\n",
    "此外，深度学习中的许多操作需要相对较高的内存带宽，而GPU拥有10倍于CPU的带宽。\n",
    "\n",
    "回到2012年的重大突破，当Alex Krizhevsky和Ilya Sutskever实现了可以在GPU硬件上运行的深度卷积神经网络时，一个重大突破出现了。他们意识到卷积神经网络中的计算瓶颈：卷积和矩阵乘法，都是可以在硬件上并行化的操作。\n",
    "于是，他们使用两个显存为3GB的NVIDIA GTX580 GPU实现了快速卷积运算。他们的创新[cuda-convnet](https://code.google.com/archive/p/cuda-convnet/)几年来它一直是行业标准，并推动了深度学习热潮。\n",
    "\n",
    "## AlexNet\n",
    "\n",
    "2012年，AlexNet横空出世。它首次证明了学习到的特征可以超越手工设计的特征。它一举打破了计算机视觉研究的现状。\n",
    "AlexNet使用了8层卷积神经网络，并以很大的优势赢得了2012年ImageNet图像识别挑战赛。\n",
    "\n",
    "AlexNet和LeNet的架构非常相似，如 :numref:`fig_alexnet`所示。\n",
    "注意，本书在这里提供的是一个稍微精简版本的AlexNet，去除了当年需要两个小型GPU同时运算的设计特点。\n",
    "\n",
    "![从LeNet（左）到AlexNet（右）](../img/alexnet.svg)\n",
    ":label:`fig_alexnet`\n",
    "\n",
    "AlexNet和LeNet的设计理念非常相似，但也存在显著差异。\n",
    "\n",
    "1. AlexNet比相对较小的LeNet5要深得多。AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。\n",
    "2. AlexNet使用ReLU而不是sigmoid作为其激活函数。\n",
    "\n",
    "下面的内容将深入研究AlexNet的细节。\n",
    "\n",
    "### 模型设计\n",
    "\n",
    "在AlexNet的第一层，卷积窗口的形状是$11\\times11$。\n",
    "由于ImageNet中大多数图像的宽和高比MNIST图像的多10倍以上，因此，需要一个更大的卷积窗口来捕获目标。\n",
    "第二层中的卷积窗口形状被缩减为$5\\times5$，然后是$3\\times3$。\n",
    "此外，在第一层、第二层和第五层卷积层之后，加入窗口形状为$3\\times3$、步幅为2的最大汇聚层。\n",
    "而且，AlexNet的卷积通道数目是LeNet的10倍。\n",
    "\n",
    "在最后一个卷积层后有两个全连接层，分别有4096个输出。\n",
    "这两个巨大的全连接层拥有将近1GB的模型参数。\n",
    "由于早期GPU显存有限，原版的AlexNet采用了双数据流设计，使得每个GPU只负责存储和计算模型的一半参数。\n",
    "幸运的是，现在GPU显存相对充裕，所以现在很少需要跨GPU分解模型（因此，本书的AlexNet模型在这方面与原始论文稍有不同）。\n",
    "\n",
    "### 激活函数\n",
    "\n",
    "此外，AlexNet将sigmoid激活函数改为更简单的ReLU激活函数。\n",
    "一方面，ReLU激活函数的计算更简单，它不需要如sigmoid激活函数那般复杂的求幂运算。\n",
    "另一方面，当使用不同的参数初始化方法时，ReLU激活函数使训练模型更加容易。\n",
    "当sigmoid激活函数的输出非常接近于0或1时，这些区域的梯度几乎为0，因此反向传播无法继续更新一些模型参数。\n",
    "相反，ReLU激活函数在正区间的梯度总是1。\n",
    "因此，如果模型参数没有正确初始化，sigmoid函数可能在正区间内得到几乎为0的梯度，从而使模型无法得到有效的训练。\n",
    "\n",
    "### 容量控制和预处理\n",
    "\n",
    "AlexNet通过暂退法（ :numref:`sec_dropout`）控制全连接层的模型复杂度，而LeNet只使用了权重衰减。\n",
    "为了进一步扩充数据，AlexNet在训练时增加了大量的图像增强数据，如翻转、裁切和变色。\n",
    "这使得模型更健壮，更大的样本量有效地减少了过拟合。\n",
    "在 :numref:`sec_image_augmentation`中更详细地讨论数据扩增。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c7ae34b7",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import time\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "net = nn.Sequential(\n",
    "    # 这里使用一个11*11的更大窗口来捕捉对象。\n",
    "    # 同时，步幅为4，以减少输出的高度和宽度。\n",
    "    # 另外，输出通道的数目远大于LeNet\n",
    "    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 使用三个连续的卷积层和较小的卷积窗口。\n",
    "    # 除了最后的卷积层，输出通道的数量进一步增加。\n",
    "    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Flatten(),\n",
    "    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合\n",
    "    nn.Linear(6400, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "    nn.Linear(4096, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d97a07",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "[**我们构造一个**]高度和宽度都为224的(**单通道数据，来观察每一层输出的形状**)。\n",
    "它与 :numref:`fig_alexnet`中的AlexNet架构相匹配。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "37a7ec36",
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 96, 54, 54])\n",
      "ReLU output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 26, 26])\n",
      "ReLU output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 256, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 5, 5])\n",
      "Flatten output shape:\t torch.Size([1, 6400])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1, 1, 224, 224)\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c79a7",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "## 读取数据集\n",
    "\n",
    "尽管原文中AlexNet是在ImageNet上进行训练的，但本书在这里使用的是Fashion-MNIST数据集。因为即使在现代GPU上，训练ImageNet模型，同时使其收敛可能需要数小时或数天的时间。\n",
    "将AlexNet直接应用于Fashion-MNIST的一个问题是，[**Fashion-MNIST图像的分辨率**]（$28 \\times 28$像素）(**低于ImageNet图像。**)\n",
    "为了解决这个问题，(**我们将它们增加到$224 \\times 224$**)（通常来讲这不是一个明智的做法，但在这里这样做是为了有效使用AlexNet架构）。\n",
    "这里需要使用`d2l.load_data_fashion_mnist`函数中的`resize`参数执行此调整。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4c1552a8",
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the train_iter is: (469,)\n",
      "the shape of the 0 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 1 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 2 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 3 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 4 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 5 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 6 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 7 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 8 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 9 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "# print the shape of the train_iter\n",
    "list_of_i = []\n",
    "for i, (X, y) in enumerate(train_iter):\n",
    "    list_of_i.append(i)\n",
    "\n",
    "print('the shape of the train_iter is:', np.array(list_of_i).shape)\n",
    "# print(list_of_i)\n",
    "# print the first 10 batch of the train_iter\n",
    "for i, (X, y) in enumerate(train_iter):\n",
    "    if i < 10:\n",
    "        print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d484d7f3",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "## [**训练AlexNet**]\n",
    "\n",
    "现在AlexNet可以开始被训练了。与 :numref:`sec_lenet`中的LeNet相比，这里的主要变化是使用更小的学习速率训练，这是因为网络更深更广、图像分辨率更高，训练卷积神经网络就更昂贵。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "516c82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_powermetrics(file_path):\n",
    "    \"\"\"\n",
    "    Run powermetrics and retrieve the output.\n",
    "    :param interval: Sampling interval in milliseconds.\n",
    "    :param count: Number of samples to retrieve.s\n",
    "    :return: The output from powermetrics.\n",
    "    \"\"\"\n",
    "    # Define the command as a list of arguments\n",
    "    cmd = [\"sudo\", \"powermetrics\",  \"-i\", \"1000\", \"--samplers\", \"cpu_power,gpu_power\", \"-a\", \"1\", \"-o\", file_path]\n",
    "    process = subprocess.Popen(cmd)\n",
    "    return process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "89638b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_data_process(file_path):\n",
    "    \"\"\"\n",
    "    Read the output file of powermetric and extract the power value\n",
    "    :param file_path: The path of the output file of powermetric.\n",
    "    :return: The list of power values.\n",
    "    \"\"\"\n",
    "    list_power = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Combined Power' in line:\n",
    "                power_value = line.split(':')[1].strip()\n",
    "                # print(power_value)\n",
    "                # Remove the unit\n",
    "                power_value = power_value.replace('mW', '')\n",
    "                # Convert to integer\n",
    "                power_value = int(power_value)\n",
    "                list_power.append(power_value)\n",
    "    '''\n",
    "    The data from list_power is the Conbined Power of each second.\n",
    "    The data is the Power of each second.\n",
    "    we need to calculate the energy consumption of the whole process.\n",
    "    and need to change the J to kWh.\n",
    "    '''\n",
    "    # calculate the energy consumption\n",
    "    energy_consumption = 0\n",
    "    for i in range(len(list_power)):\n",
    "       energy_consumption += list_power[i]\n",
    "    # change the mW to W\n",
    "    energy_consumption = energy_consumption / 1000\n",
    "    # calculate the energy consumption, the interval is 1 second, and the energy unit is J\n",
    "    energy_consumption = energy_consumption * 1\n",
    "    # change the J to kWh\n",
    "    energy_consumption = energy_consumption / 3600000\n",
    "    return energy_consumption, list_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "41bfa77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_file = 'energy_alexnet.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "对train_ch6()函数进行修改，使得能够在每一层的前向传播的时候，记录下时间, \n",
    "能耗部分不好进行具体统计，因为每个层的能耗有区别，并且时间过短，所以采用的方式为计算总能耗和总时长，最后通过平均值来计算估算的能耗\n",
    "'''\n",
    "def train_ch6self(net, train_iter, test_iter, num_epochs, lr, device, energy_file):\n",
    "    def init_weights(m): # 初始化权重\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    # set a list of layer name\n",
    "    list_layer_name = ['Conv2d','ReLU','MaxPool2d','Linear','Dropout','Flatten'] # 该模型中包括的所有的层的名字\n",
    "    # create a numpy array to store the time and energy consumption, the shape is (num_epochs, len(list_layer_name), 2)\n",
    "    # for each epoch, the shape is (6,2), contains the total time and the energy consumption of each layer\n",
    "    timeenergy_data_forward = np.zeros((num_epochs, len(list_layer_name), 2)) \n",
    "    # for each epoch, the shape is (6,2), contains the total time of each part in a round, which is to_device, forward, loss, backward, optimizer，test_round\n",
    "    # and the 2 means time and energy consumption, respectively\n",
    "    timeenergy_data_round = np.zeros((num_epochs, 6, 2)) \n",
    "    # create another numpy array to store the data of each epoch, 1 column is training loss, 2 column is training accuracy, 3 column is test accuracy\n",
    "    acc_data = []\n",
    "    # create a numpy array to store the train loss and train accuracy\n",
    "    train_l = []\n",
    "    train_acc = []\n",
    "    # create a numpy array to store the epoch and running time\n",
    "    time_data_epoch = np.zeros((num_epochs, 2))\n",
    "    # create a numpy array to store the energy consumption of each epoch\n",
    "    energy_data_epoch = np.zeros((num_epochs, 1), dtype=object)\n",
    "    # print the training device\n",
    "    print('training on', device)\n",
    "    net.to(device) # 将模型放到对应的设备上\n",
    "    # 初始化optimizer和loss\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    # 初始化计时器\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)   \n",
    "    # 开始训练\n",
    "    for epoch in range(num_epochs):\n",
    "        print('epoch %d' % (epoch + 1))\n",
    "        # each epoch, set a timer to record the time\n",
    "        timer.start()\n",
    "        powermetrics_process = run_powermetrics(energy_file)\n",
    "        net.train() # 设置为训练模式\n",
    "        # 初始化每个epoch的统计时间的变量\n",
    "        time_to_device_cost, time_forward, time_cost_loss = 0,0,0\n",
    "        time_cost_backward, time_cost_optimizer, time_test_acc_cost = 0,0,0\n",
    "        train_l_epoch = []\n",
    "        train_acc_epoch = []\n",
    "        metric = d2l.Accumulator(3)\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            print('round %d' % (i))\n",
    "            time_round_start = time.time() # 计算每一轮的时间s\n",
    "            optimizer.zero_grad() # 将optimizer的梯度清零s\n",
    "        ##################################################################################\n",
    "            # 计算将数据放到对应的设备上的时间\n",
    "            time_to_device_cost_i = 0\n",
    "            time_to_device = time.time()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            time_to_device_end = time.time()\n",
    "            time_to_device_cost_i = time_to_device_end - time_to_device\n",
    "            print('time to device %f sec' % (time_to_device_cost_i))\n",
    "            time_to_device_cost += time_to_device_cost_i\n",
    "        ##################################################################################\n",
    "            # 将原本的模型进行修改，使得能够逐层进行运行，并且在这个过程中，记录下时间和能量\n",
    "            y_hat = X\n",
    "            for layer in net:\n",
    "                time_cost_layer = 0\n",
    "                layer_name = layer.__class__.__name__ # 获取层的名字\n",
    "                # find out the layer name is in where of the list\n",
    "                layer_index = list_layer_name.index(layer_name)\n",
    "                # calculate the time\n",
    "                time_start_layer = time.time()\n",
    "                y_hat = layer(y_hat)\n",
    "                time_end_layer = time.time()\n",
    "                time_cost_layer = time_end_layer - time_start_layer\n",
    "                timeenergy_data_forward[epoch,layer_index,0] += time_cost_layer\n",
    "                if torch.isinf(y_hat).any() or torch.isnan(y_hat).any():\n",
    "                    print(\"Inf or NaN detected in y_hat\")\n",
    "            # 计算前向的时间\n",
    "            time_forward = np.sum(timeenergy_data_forward[epoch,:,0])\n",
    "            print('time forward %f sec' % (time_forward))\n",
    "        ##################################################################################\n",
    "            # 计算loss\n",
    "            time_cost_loss_i = 0 # 初始化loss的时间\n",
    "            time_start_loss = time.time()\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            # print(loss)\n",
    "            time_end_loss = time.time()\n",
    "            time_cost_loss_i = time_end_loss - time_start_loss\n",
    "            print('loss time %f sec' % (time_cost_loss_i))\n",
    "            time_cost_loss += time_cost_loss_i\n",
    "        ##################################################################################\n",
    "            # 计算backward\n",
    "            time_cost_backward_i = 0 # 初始化backward的时间\n",
    "            time_start_backward = time.time()\n",
    "            loss.backward()\n",
    "            time_end_backward = time.time()\n",
    "            time_cost_backward_i = time_end_backward - time_start_backward\n",
    "            print('backward time %f sec' % (time_cost_backward_i))\n",
    "            time_cost_backward += time_cost_backward_i\n",
    "        ##################################################################################\n",
    "            # 计算optimizer\n",
    "            time_cost_optimizer_i = 0 # 初始化optimizer的时间\n",
    "            time_start_optimizer = time.time()\n",
    "            optimizer.step()\n",
    "            time_end_optimizer = time.time()\n",
    "            time_cost_optimizer_i = time_end_optimizer - time_start_optimizer\n",
    "            print('optimizer time %f sec' % (time_cost_optimizer_i))\n",
    "            time_cost_optimizer += time_cost_optimizer_i\n",
    "        ##################################################################################\n",
    "            time_round_end = time.time()\n",
    "            time_round_cost = time_round_end - time_round_start\n",
    "            print(f'training time in round {i} cost {time_round_cost} sec')\n",
    "        ##################################################################################\n",
    "            with torch.no_grad():\n",
    "                metric.add(loss * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            train_l_i = metric[0] / metric[2]\n",
    "            train_acc_i = metric[1] / metric[2]\n",
    "            train_l_epoch.append(train_l_i)\n",
    "            train_acc_epoch.append(train_acc_i)\n",
    "            print('loss %f, train acc %f' % (train_l_i, train_acc_i))\n",
    "        train_l.append(train_l_epoch)\n",
    "        train_acc.append(train_acc_epoch)\n",
    "        ##################################################################################\n",
    "        # 进行模型的test部分运行\n",
    "        time_test_acc_cost_epoch = 0\n",
    "        time_test_acc_start = time.time()\n",
    "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter, device)\n",
    "        time_test_acc_end = time.time()\n",
    "        time_test_acc_cost_epoch = time_test_acc_end - time_test_acc_start\n",
    "        time_test_acc_cost += time_test_acc_cost_epoch\n",
    "        print('test acc is %f' % (test_acc))\n",
    "        acc_data.append(test_acc)\n",
    "        ##################################################################################\n",
    "        # 将每一轮的每个部分的时间加入到time_data_round中\n",
    "        timeenergy_data_round[epoch,0,0] = time_to_device_cost\n",
    "        timeenergy_data_round[epoch,1,0] = time_forward\n",
    "        timeenergy_data_round[epoch,2,0] = time_cost_loss\n",
    "        timeenergy_data_round[epoch,3,0] = time_cost_backward\n",
    "        timeenergy_data_round[epoch,4,0] = time_cost_optimizer\n",
    "        timeenergy_data_round[epoch,5,0] = time_test_acc_cost\n",
    "        ##################################################################################\n",
    "        # stop the powermetrics\n",
    "        powermetrics_process.terminate()\n",
    "        powermetrics_process.wait()\n",
    "        timer.stop() # 停止计时 \n",
    "        time_data_epoch[epoch,0] = epoch + 1\n",
    "        time_data_epoch[epoch,1] = timer.sum()\n",
    "        print('epoch %d, time %f sec' % (epoch, timer.sum()))\n",
    "        ##################################################################################\n",
    "        # calculate the energy consumption of each layer\n",
    "        energy_consumption, power_list_model = txt_data_process(energy_file)\n",
    "        training_time_epoch_record = len(power_list_model)\n",
    "        energy_consumption_J = energy_consumption * 3600000\n",
    "        avg_energy_cost_persec = energy_consumption_J / training_time_epoch_record  # 计算每秒的平均能耗\n",
    "        ##################################################################################\n",
    "        # 将每一轮的每个部分的能耗加入到time_data_forward中\n",
    "        for l in range(len(timeenergy_data_forward[epoch,:,0])):\n",
    "            timeenergy_data_forward[epoch, l, 1] = timeenergy_data_forward[epoch, l, 0] * avg_energy_cost_persec\n",
    "        # 将每一轮的每个部分的能耗加入到time_data_round中\n",
    "        for m in range(len(timeenergy_data_round[epoch,:,0])):\n",
    "            timeenergy_data_round[epoch, m, 1] = timeenergy_data_round[epoch, m, 0] * avg_energy_cost_persec\n",
    "        ##################################################################################\n",
    "        # 对采集到的能耗数据进行保存\n",
    "        energy_data_epoch[epoch,0] = power_list_model\n",
    "        \n",
    "    return timeenergy_data_forward, timeenergy_data_round, acc_data, train_l, train_acc, time_data_epoch, energy_data_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on mps\n",
      "epoch 1\n",
      "round 0\n",
      "time to device 0.032565 sec\n",
      "time forward 0.043169 sec\n",
      "loss time 0.001367 sec\n",
      "backward time 0.014572 sec\n",
      "optimizer time 0.006612 sec\n",
      "training time in round 0 cost 1.1814849376678467 sec\n",
      "loss 2.305690, train acc 0.078125\n",
      "round 1\n",
      "time to device 0.006535 sec\n",
      "time forward 0.054988 sec\n",
      "loss time 0.001183 sec\n",
      "backward time 0.011148 sec\n",
      "optimizer time 0.004026 sec\n",
      "training time in round 1 cost 0.42551398277282715 sec\n",
      "loss 2.305090, train acc 0.074219\n",
      "round 2\n",
      "time to device 0.007460 sec\n",
      "time forward 0.065155 sec\n",
      "loss time 0.001090 sec\n",
      "backward time 0.009829 sec\n",
      "optimizer time 0.004751 sec\n",
      "training time in round 2 cost 0.388530969619751 sec\n",
      "loss 2.304176, train acc 0.085938\n",
      "round 3\n",
      "time to device 0.007300 sec\n",
      "time forward 0.077115 sec\n",
      "loss time 0.001278 sec\n",
      "backward time 0.010814 sec\n",
      "optimizer time 0.003979 sec\n",
      "training time in round 3 cost 0.40775203704833984 sec\n",
      "loss 2.303623, train acc 0.083984\n",
      "round 4\n",
      "time to device 0.009240 sec\n",
      "time forward 0.088060 sec\n",
      "loss time 0.001222 sec\n",
      "backward time 0.009566 sec\n",
      "optimizer time 0.004920 sec\n",
      "training time in round 4 cost 0.3976871967315674 sec\n",
      "loss 2.303246, train acc 0.084375\n",
      "round 5\n",
      "time to device 0.010209 sec\n",
      "time forward 0.098227 sec\n",
      "loss time 0.001070 sec\n",
      "backward time 0.009907 sec\n",
      "optimizer time 0.004224 sec\n",
      "training time in round 5 cost 0.39168286323547363 sec\n",
      "loss 2.303101, train acc 0.084635\n",
      "round 6\n",
      "time to device 0.008915 sec\n",
      "time forward 0.110451 sec\n",
      "loss time 0.001303 sec\n",
      "backward time 0.011397 sec\n",
      "optimizer time 0.003715 sec\n",
      "training time in round 6 cost 0.40146374702453613 sec\n",
      "loss 2.303185, train acc 0.087054\n",
      "round 7\n",
      "time to device 0.010921 sec\n",
      "time forward 0.123261 sec\n",
      "loss time 0.001293 sec\n",
      "backward time 0.012368 sec\n",
      "optimizer time 0.006327 sec\n",
      "training time in round 7 cost 0.4131739139556885 sec\n",
      "loss 2.303143, train acc 0.091797\n",
      "round 8\n",
      "time to device 0.011856 sec\n",
      "time forward 0.137813 sec\n",
      "loss time 0.001497 sec\n",
      "backward time 0.011002 sec\n",
      "optimizer time 0.004234 sec\n",
      "training time in round 8 cost 0.406574010848999 sec\n",
      "loss 2.302559, train acc 0.092882\n",
      "round 9\n",
      "time to device 0.009474 sec\n",
      "time forward 0.150192 sec\n",
      "loss time 0.000625 sec\n",
      "backward time 0.007976 sec\n",
      "optimizer time 0.004333 sec\n",
      "training time in round 9 cost 0.6787610054016113 sec\n",
      "loss 2.302414, train acc 0.094531\n",
      "round 10\n",
      "time to device 0.011687 sec\n",
      "time forward 0.160725 sec\n",
      "loss time 0.001259 sec\n",
      "backward time 0.007319 sec\n",
      "optimizer time 0.003471 sec\n",
      "training time in round 10 cost 0.5184288024902344 sec\n",
      "loss 2.302237, train acc 0.097301\n",
      "round 11\n",
      "time to device 0.021560 sec\n",
      "time forward 0.173848 sec\n",
      "loss time 0.001298 sec\n",
      "backward time 0.013729 sec\n",
      "optimizer time 0.003832 sec\n",
      "training time in round 11 cost 0.42096686363220215 sec\n",
      "loss 2.301776, train acc 0.101562\n",
      "round 12\n",
      "time to device 0.012705 sec\n",
      "time forward 0.185199 sec\n",
      "loss time 0.001215 sec\n",
      "backward time 0.009629 sec\n",
      "optimizer time 0.002219 sec\n",
      "training time in round 12 cost 0.41481494903564453 sec\n",
      "loss 2.301882, train acc 0.103966\n",
      "round 13\n",
      "time to device 0.008745 sec\n",
      "time forward 0.195951 sec\n",
      "loss time 0.000646 sec\n",
      "backward time 0.006331 sec\n",
      "optimizer time 0.002786 sec\n",
      "training time in round 13 cost 0.376453161239624 sec\n",
      "loss 2.301924, train acc 0.104353\n",
      "round 14\n",
      "time to device 0.009022 sec\n",
      "time forward 0.208519 sec\n",
      "loss time 0.001287 sec\n",
      "backward time 0.010494 sec\n",
      "optimizer time 0.003142 sec\n",
      "training time in round 14 cost 0.40929102897644043 sec\n",
      "loss 2.301834, train acc 0.103125\n",
      "round 15\n",
      "time to device 0.006954 sec\n",
      "time forward 0.222094 sec\n",
      "loss time 0.001107 sec\n",
      "backward time 0.011509 sec\n",
      "optimizer time 0.002091 sec\n",
      "training time in round 15 cost 0.4088010787963867 sec\n",
      "loss 2.301593, train acc 0.105469\n",
      "round 16\n",
      "time to device 0.007329 sec\n",
      "time forward 0.234208 sec\n",
      "loss time 0.001475 sec\n",
      "backward time 0.018087 sec\n",
      "optimizer time 0.001971 sec\n",
      "training time in round 16 cost 0.41432714462280273 sec\n",
      "loss 2.301474, train acc 0.105239\n",
      "round 17\n",
      "time to device 0.009591 sec\n",
      "time forward 0.250867 sec\n",
      "loss time 0.001116 sec\n",
      "backward time 0.009036 sec\n",
      "optimizer time 0.003506 sec\n",
      "training time in round 17 cost 0.4013659954071045 sec\n",
      "loss 2.300956, train acc 0.105903\n",
      "round 18\n",
      "time to device 0.013575 sec\n",
      "time forward 0.264489 sec\n",
      "loss time 0.002983 sec\n",
      "backward time 0.010278 sec\n",
      "optimizer time 0.003919 sec\n",
      "training time in round 18 cost 0.399871826171875 sec\n",
      "loss 2.301018, train acc 0.103207\n",
      "round 19\n",
      "time to device 0.010151 sec\n",
      "time forward 0.276691 sec\n",
      "loss time 0.000765 sec\n",
      "backward time 0.008083 sec\n",
      "optimizer time 0.003795 sec\n",
      "training time in round 19 cost 0.39957189559936523 sec\n",
      "loss 2.300995, train acc 0.103516\n",
      "round 20\n",
      "time to device 0.006771 sec\n",
      "time forward 0.287698 sec\n",
      "loss time 0.001092 sec\n",
      "backward time 0.009943 sec\n",
      "optimizer time 0.003574 sec\n",
      "training time in round 20 cost 0.3730940818786621 sec\n",
      "loss 2.300939, train acc 0.103051\n",
      "round 21\n",
      "time to device 0.008500 sec\n",
      "time forward 0.298653 sec\n",
      "loss time 0.001184 sec\n",
      "backward time 0.007849 sec\n",
      "optimizer time 0.002935 sec\n",
      "training time in round 21 cost 0.39064478874206543 sec\n",
      "loss 2.300778, train acc 0.102983\n",
      "round 22\n",
      "time to device 0.006449 sec\n",
      "time forward 0.311465 sec\n",
      "loss time 0.001246 sec\n",
      "backward time 0.011908 sec\n",
      "optimizer time 0.003829 sec\n",
      "training time in round 22 cost 0.40589284896850586 sec\n",
      "loss 2.300523, train acc 0.104959\n",
      "round 23\n",
      "time to device 0.009048 sec\n",
      "time forward 0.322865 sec\n",
      "loss time 0.000643 sec\n",
      "backward time 0.006896 sec\n",
      "optimizer time 0.002336 sec\n",
      "training time in round 23 cost 0.4560129642486572 sec\n",
      "loss 2.300411, train acc 0.104167\n",
      "round 24\n",
      "time to device 0.012750 sec\n",
      "time forward 0.334078 sec\n",
      "loss time 0.000722 sec\n",
      "backward time 0.007744 sec\n",
      "optimizer time 0.002262 sec\n",
      "training time in round 24 cost 0.418428897857666 sec\n",
      "loss 2.300277, train acc 0.104375\n",
      "round 25\n",
      "time to device 0.007011 sec\n",
      "time forward 0.349999 sec\n",
      "loss time 0.000542 sec\n",
      "backward time 0.008067 sec\n",
      "optimizer time 0.002863 sec\n",
      "training time in round 25 cost 0.39035916328430176 sec\n",
      "loss 2.299934, train acc 0.105769\n",
      "round 26\n",
      "time to device 0.007109 sec\n",
      "time forward 0.361768 sec\n",
      "loss time 0.000782 sec\n",
      "backward time 0.011565 sec\n",
      "optimizer time 0.003036 sec\n",
      "training time in round 26 cost 0.4043731689453125 sec\n",
      "loss 2.299886, train acc 0.105613\n",
      "round 27\n",
      "time to device 0.006110 sec\n",
      "time forward 0.369652 sec\n",
      "loss time 0.000469 sec\n",
      "backward time 0.004940 sec\n",
      "optimizer time 0.002364 sec\n",
      "training time in round 27 cost 0.37652015686035156 sec\n",
      "loss 2.299747, train acc 0.106027\n",
      "round 28\n",
      "time to device 0.006825 sec\n",
      "time forward 0.385314 sec\n",
      "loss time 0.001566 sec\n",
      "backward time 0.013616 sec\n",
      "optimizer time 0.004256 sec\n",
      "training time in round 28 cost 0.44101786613464355 sec\n",
      "loss 2.299721, train acc 0.106412\n",
      "round 29\n",
      "time to device 0.008398 sec\n",
      "time forward 0.398069 sec\n",
      "loss time 0.001468 sec\n",
      "backward time 0.013640 sec\n",
      "optimizer time 0.004452 sec\n",
      "training time in round 29 cost 0.38439393043518066 sec\n",
      "loss 2.299669, train acc 0.105208\n",
      "round 30\n",
      "time to device 0.006932 sec\n",
      "time forward 0.409665 sec\n",
      "loss time 0.000466 sec\n",
      "backward time 0.004621 sec\n",
      "optimizer time 0.002141 sec\n",
      "training time in round 30 cost 0.3752148151397705 sec\n",
      "loss 2.299810, train acc 0.105091\n",
      "round 31\n",
      "time to device 0.006759 sec\n",
      "time forward 0.421170 sec\n",
      "loss time 0.001028 sec\n",
      "backward time 0.008448 sec\n",
      "optimizer time 0.003567 sec\n",
      "training time in round 31 cost 0.37830662727355957 sec\n",
      "loss 2.299647, train acc 0.106689\n",
      "round 32\n",
      "time to device 0.009882 sec\n",
      "time forward 0.435532 sec\n",
      "loss time 0.001514 sec\n",
      "backward time 0.010681 sec\n",
      "optimizer time 0.003501 sec\n",
      "training time in round 32 cost 0.38091182708740234 sec\n",
      "loss 2.299442, train acc 0.109138\n",
      "round 33\n",
      "time to device 0.009263 sec\n",
      "time forward 0.448218 sec\n",
      "loss time 0.001587 sec\n",
      "backward time 0.011293 sec\n",
      "optimizer time 0.003775 sec\n",
      "training time in round 33 cost 0.38983821868896484 sec\n",
      "loss 2.299219, train acc 0.109375\n",
      "round 34\n",
      "time to device 0.008993 sec\n",
      "time forward 0.460436 sec\n",
      "loss time 0.001513 sec\n",
      "backward time 0.011674 sec\n",
      "optimizer time 0.004108 sec\n",
      "training time in round 34 cost 0.4221360683441162 sec\n",
      "loss 2.298942, train acc 0.112277\n",
      "round 35\n",
      "time to device 0.011448 sec\n",
      "time forward 0.472895 sec\n",
      "loss time 0.003086 sec\n",
      "backward time 0.018400 sec\n",
      "optimizer time 0.003869 sec\n",
      "training time in round 35 cost 0.3938560485839844 sec\n",
      "loss 2.298675, train acc 0.113715\n",
      "round 36\n",
      "time to device 0.010830 sec\n",
      "time forward 0.484996 sec\n",
      "loss time 0.001141 sec\n",
      "backward time 0.009829 sec\n",
      "optimizer time 0.003677 sec\n",
      "training time in round 36 cost 0.3955209255218506 sec\n",
      "loss 2.298466, train acc 0.114865\n",
      "round 37\n",
      "time to device 0.008734 sec\n",
      "time forward 0.498547 sec\n",
      "loss time 0.000918 sec\n",
      "backward time 0.010518 sec\n",
      "optimizer time 0.004663 sec\n",
      "training time in round 37 cost 0.4087839126586914 sec\n",
      "loss 2.298499, train acc 0.115543\n",
      "round 38\n",
      "time to device 0.009621 sec\n",
      "time forward 0.511249 sec\n",
      "loss time 0.001081 sec\n",
      "backward time 0.009412 sec\n",
      "optimizer time 0.004567 sec\n",
      "training time in round 38 cost 0.4168989658355713 sec\n",
      "loss 2.298289, train acc 0.115184\n",
      "round 39\n",
      "time to device 0.006633 sec\n",
      "time forward 0.522963 sec\n",
      "loss time 0.001688 sec\n",
      "backward time 0.008534 sec\n",
      "optimizer time 0.002081 sec\n",
      "training time in round 39 cost 0.39998388290405273 sec\n",
      "loss 2.298271, train acc 0.114062\n",
      "round 40\n",
      "time to device 0.009958 sec\n",
      "time forward 0.535535 sec\n",
      "loss time 0.000565 sec\n",
      "backward time 0.004762 sec\n",
      "optimizer time 0.002453 sec\n",
      "training time in round 40 cost 0.39229702949523926 sec\n",
      "loss 2.298091, train acc 0.114901\n",
      "round 41\n",
      "time to device 0.008131 sec\n",
      "time forward 0.550307 sec\n",
      "loss time 0.001395 sec\n",
      "backward time 0.006384 sec\n",
      "optimizer time 0.002409 sec\n",
      "training time in round 41 cost 0.4012470245361328 sec\n",
      "loss 2.297889, train acc 0.115513\n",
      "round 42\n",
      "time to device 0.007484 sec\n",
      "time forward 0.565526 sec\n",
      "loss time 0.001587 sec\n",
      "backward time 0.011041 sec\n",
      "optimizer time 0.004485 sec\n",
      "training time in round 42 cost 0.39611387252807617 sec\n",
      "loss 2.297710, train acc 0.116097\n",
      "round 43\n",
      "time to device 0.009988 sec\n",
      "time forward 0.573792 sec\n",
      "loss time 0.000902 sec\n",
      "backward time 0.006441 sec\n",
      "optimizer time 0.003657 sec\n",
      "training time in round 43 cost 0.3834099769592285 sec\n",
      "loss 2.297548, train acc 0.117010\n",
      "round 44\n",
      "time to device 0.012222 sec\n",
      "time forward 0.587597 sec\n",
      "loss time 0.000557 sec\n",
      "backward time 0.005100 sec\n",
      "optimizer time 0.002839 sec\n",
      "training time in round 44 cost 0.38959407806396484 sec\n",
      "loss 2.297406, train acc 0.117882\n",
      "round 45\n",
      "time to device 0.009874 sec\n",
      "time forward 0.600471 sec\n",
      "loss time 0.001283 sec\n",
      "backward time 0.008323 sec\n",
      "optimizer time 0.003405 sec\n",
      "training time in round 45 cost 0.3925361633300781 sec\n",
      "loss 2.297338, train acc 0.117527\n",
      "round 46\n",
      "time to device 0.006860 sec\n",
      "time forward 0.608344 sec\n",
      "loss time 0.000615 sec\n",
      "backward time 0.005113 sec\n",
      "optimizer time 0.002577 sec\n",
      "training time in round 46 cost 0.3930978775024414 sec\n",
      "loss 2.297285, train acc 0.117188\n",
      "round 47\n",
      "time to device 0.008583 sec\n",
      "time forward 0.622828 sec\n",
      "loss time 0.001900 sec\n",
      "backward time 0.007186 sec\n",
      "optimizer time 0.002580 sec\n",
      "training time in round 47 cost 0.3930649757385254 sec\n",
      "loss 2.297105, train acc 0.117839\n",
      "round 48\n",
      "time to device 0.006407 sec\n",
      "time forward 0.633666 sec\n",
      "loss time 0.001181 sec\n",
      "backward time 0.019203 sec\n",
      "optimizer time 0.003841 sec\n",
      "training time in round 48 cost 0.391376256942749 sec\n",
      "loss 2.297026, train acc 0.118463\n",
      "round 49\n",
      "time to device 0.008863 sec\n",
      "time forward 0.648768 sec\n",
      "loss time 0.001666 sec\n",
      "backward time 0.012835 sec\n",
      "optimizer time 0.003914 sec\n",
      "training time in round 49 cost 0.41231775283813477 sec\n",
      "loss 2.296861, train acc 0.119375\n",
      "round 50\n",
      "time to device 0.006129 sec\n",
      "time forward 0.665328 sec\n",
      "loss time 0.001612 sec\n",
      "backward time 0.012363 sec\n",
      "optimizer time 0.003682 sec\n",
      "training time in round 50 cost 0.41762208938598633 sec\n",
      "loss 2.296696, train acc 0.119638\n",
      "round 51\n",
      "time to device 0.009424 sec\n",
      "time forward 0.681217 sec\n",
      "loss time 0.000626 sec\n",
      "backward time 0.005730 sec\n",
      "optimizer time 0.002609 sec\n",
      "training time in round 51 cost 0.45768308639526367 sec\n",
      "loss 2.296439, train acc 0.120493\n",
      "round 52\n",
      "time to device 0.009806 sec\n",
      "time forward 0.694356 sec\n",
      "loss time 0.001223 sec\n",
      "backward time 0.011661 sec\n",
      "optimizer time 0.004061 sec\n",
      "training time in round 52 cost 0.41417598724365234 sec\n",
      "loss 2.296356, train acc 0.121757\n",
      "round 53\n",
      "time to device 0.006718 sec\n",
      "time forward 0.711845 sec\n",
      "loss time 0.001307 sec\n",
      "backward time 0.011301 sec\n",
      "optimizer time 0.003790 sec\n",
      "training time in round 53 cost 0.402573823928833 sec\n",
      "loss 2.296350, train acc 0.121528\n",
      "round 54\n",
      "time to device 0.007120 sec\n",
      "time forward 0.722507 sec\n",
      "loss time 0.001051 sec\n",
      "backward time 0.009355 sec\n",
      "optimizer time 0.002261 sec\n",
      "training time in round 54 cost 0.37021899223327637 sec\n",
      "loss 2.296219, train acc 0.121733\n",
      "round 55\n",
      "time to device 0.008605 sec\n",
      "time forward 0.736457 sec\n",
      "loss time 0.000716 sec\n",
      "backward time 0.007349 sec\n",
      "optimizer time 0.003310 sec\n",
      "training time in round 55 cost 0.41982388496398926 sec\n",
      "loss 2.296077, train acc 0.122210\n",
      "round 56\n",
      "time to device 0.015743 sec\n",
      "time forward 0.747801 sec\n",
      "loss time 0.001177 sec\n",
      "backward time 0.008757 sec\n",
      "optimizer time 0.001771 sec\n",
      "training time in round 56 cost 0.39182376861572266 sec\n",
      "loss 2.295901, train acc 0.122396\n",
      "round 57\n",
      "time to device 0.006696 sec\n",
      "time forward 0.760230 sec\n",
      "loss time 0.000640 sec\n",
      "backward time 0.006002 sec\n",
      "optimizer time 0.002569 sec\n",
      "training time in round 57 cost 0.38895320892333984 sec\n",
      "loss 2.295817, train acc 0.122980\n",
      "round 58\n",
      "time to device 0.006728 sec\n",
      "time forward 0.774462 sec\n",
      "loss time 0.001678 sec\n",
      "backward time 0.013276 sec\n",
      "optimizer time 0.004084 sec\n",
      "training time in round 58 cost 0.39412522315979004 sec\n",
      "loss 2.295782, train acc 0.123279\n",
      "round 59\n",
      "time to device 0.008009 sec\n",
      "time forward 0.784840 sec\n",
      "loss time 0.000723 sec\n",
      "backward time 0.007338 sec\n",
      "optimizer time 0.003504 sec\n",
      "training time in round 59 cost 0.3986492156982422 sec\n",
      "loss 2.295727, train acc 0.123438\n",
      "round 60\n",
      "time to device 0.007200 sec\n",
      "time forward 0.798698 sec\n",
      "loss time 0.000586 sec\n",
      "backward time 0.004710 sec\n",
      "optimizer time 0.002822 sec\n",
      "training time in round 60 cost 0.44252586364746094 sec\n",
      "loss 2.295601, train acc 0.123463\n",
      "round 61\n",
      "time to device 0.006626 sec\n",
      "time forward 0.811917 sec\n",
      "loss time 0.000657 sec\n",
      "backward time 0.007244 sec\n",
      "optimizer time 0.004630 sec\n",
      "training time in round 61 cost 0.39829301834106445 sec\n",
      "loss 2.295549, train acc 0.123614\n",
      "round 62\n",
      "time to device 0.009137 sec\n",
      "time forward 0.823174 sec\n",
      "loss time 0.000544 sec\n",
      "backward time 0.004848 sec\n",
      "optimizer time 0.002585 sec\n",
      "training time in round 62 cost 0.39327192306518555 sec\n",
      "loss 2.295441, train acc 0.123884\n",
      "round 63\n",
      "time to device 0.006539 sec\n",
      "time forward 0.834596 sec\n",
      "loss time 0.001467 sec\n",
      "backward time 0.013313 sec\n",
      "optimizer time 0.004480 sec\n",
      "training time in round 63 cost 0.39725375175476074 sec\n",
      "loss 2.295349, train acc 0.124268\n",
      "round 64\n",
      "time to device 0.006893 sec\n",
      "time forward 0.845886 sec\n",
      "loss time 0.001094 sec\n",
      "backward time 0.010630 sec\n",
      "optimizer time 0.004529 sec\n",
      "training time in round 64 cost 0.3692150115966797 sec\n",
      "loss 2.295270, train acc 0.124279\n",
      "round 65\n",
      "time to device 0.008243 sec\n",
      "time forward 0.856376 sec\n",
      "loss time 0.001599 sec\n",
      "backward time 0.010297 sec\n",
      "optimizer time 0.004047 sec\n",
      "training time in round 65 cost 0.3941030502319336 sec\n",
      "loss 2.295105, train acc 0.124645\n",
      "round 66\n",
      "time to device 0.008334 sec\n",
      "time forward 0.868247 sec\n",
      "loss time 0.001261 sec\n",
      "backward time 0.010006 sec\n",
      "optimizer time 0.003864 sec\n",
      "training time in round 66 cost 0.38349413871765137 sec\n",
      "loss 2.294843, train acc 0.126049\n",
      "round 67\n",
      "time to device 0.006177 sec\n",
      "time forward 0.889273 sec\n",
      "loss time 0.000543 sec\n",
      "backward time 0.008665 sec\n",
      "optimizer time 0.003085 sec\n",
      "training time in round 67 cost 0.3968839645385742 sec\n",
      "loss 2.294746, train acc 0.125919\n",
      "round 68\n",
      "time to device 0.006794 sec\n",
      "time forward 0.901018 sec\n",
      "loss time 0.001462 sec\n",
      "backward time 0.014484 sec\n",
      "optimizer time 0.004997 sec\n",
      "training time in round 68 cost 0.38260388374328613 sec\n",
      "loss 2.294609, train acc 0.126698\n",
      "round 69\n",
      "time to device 0.007649 sec\n",
      "time forward 0.911201 sec\n",
      "loss time 0.000645 sec\n",
      "backward time 0.006601 sec\n",
      "optimizer time 0.003144 sec\n",
      "training time in round 69 cost 0.38362693786621094 sec\n",
      "loss 2.294407, train acc 0.126897\n",
      "round 70\n",
      "time to device 0.007277 sec\n",
      "time forward 0.925181 sec\n",
      "loss time 0.001829 sec\n",
      "backward time 0.015169 sec\n",
      "optimizer time 0.005529 sec\n",
      "training time in round 70 cost 0.3989541530609131 sec\n",
      "loss 2.294302, train acc 0.126761\n",
      "round 71\n",
      "time to device 0.007376 sec\n",
      "time forward 0.935456 sec\n",
      "loss time 0.000708 sec\n",
      "backward time 0.012423 sec\n",
      "optimizer time 0.003575 sec\n",
      "training time in round 71 cost 0.38485288619995117 sec\n",
      "loss 2.294176, train acc 0.126736\n",
      "round 72\n",
      "time to device 0.007818 sec\n",
      "time forward 0.949658 sec\n",
      "loss time 0.000980 sec\n",
      "backward time 0.006539 sec\n",
      "optimizer time 0.003235 sec\n",
      "training time in round 72 cost 0.41124510765075684 sec\n",
      "loss 2.294026, train acc 0.127676\n",
      "round 73\n",
      "time to device 0.013831 sec\n",
      "time forward 0.960709 sec\n",
      "loss time 0.000923 sec\n",
      "backward time 0.008802 sec\n",
      "optimizer time 0.004440 sec\n",
      "training time in round 73 cost 0.382612943649292 sec\n",
      "loss 2.293776, train acc 0.128378\n",
      "round 74\n",
      "time to device 0.011720 sec\n",
      "time forward 0.975245 sec\n",
      "loss time 0.001348 sec\n",
      "backward time 0.011916 sec\n",
      "optimizer time 0.003840 sec\n",
      "training time in round 74 cost 0.3932821750640869 sec\n",
      "loss 2.293687, train acc 0.128125\n",
      "round 75\n",
      "time to device 0.004426 sec\n",
      "time forward 0.988093 sec\n",
      "loss time 0.001932 sec\n",
      "backward time 0.012916 sec\n",
      "optimizer time 0.002338 sec\n",
      "training time in round 75 cost 0.38215208053588867 sec\n",
      "loss 2.293551, train acc 0.128392\n",
      "round 76\n",
      "time to device 0.003851 sec\n",
      "time forward 1.000145 sec\n",
      "loss time 0.000647 sec\n",
      "backward time 0.007190 sec\n",
      "optimizer time 0.002677 sec\n",
      "training time in round 76 cost 0.39507603645324707 sec\n",
      "loss 2.293379, train acc 0.128856\n",
      "round 77\n",
      "time to device 0.004671 sec\n",
      "time forward 1.011142 sec\n",
      "loss time 0.000738 sec\n",
      "backward time 0.007106 sec\n",
      "optimizer time 0.003059 sec\n",
      "training time in round 77 cost 0.37653088569641113 sec\n",
      "loss 2.293300, train acc 0.129107\n",
      "round 78\n",
      "time to device 0.004563 sec\n",
      "time forward 1.025423 sec\n",
      "loss time 0.000716 sec\n",
      "backward time 0.006420 sec\n",
      "optimizer time 0.003170 sec\n",
      "training time in round 78 cost 0.3903920650482178 sec\n",
      "loss 2.293188, train acc 0.129153\n",
      "round 79\n",
      "time to device 0.006695 sec\n",
      "time forward 1.037023 sec\n",
      "loss time 0.001118 sec\n",
      "backward time 0.013218 sec\n",
      "optimizer time 0.004712 sec\n",
      "training time in round 79 cost 0.3914210796356201 sec\n",
      "loss 2.293128, train acc 0.128906\n",
      "round 80\n",
      "time to device 0.004212 sec\n",
      "time forward 1.048838 sec\n",
      "loss time 0.001133 sec\n",
      "backward time 0.013392 sec\n",
      "optimizer time 0.005021 sec\n",
      "training time in round 80 cost 0.40302205085754395 sec\n",
      "loss 2.292973, train acc 0.129147\n",
      "round 81\n",
      "time to device 0.003997 sec\n",
      "time forward 1.061940 sec\n",
      "loss time 0.001406 sec\n",
      "backward time 0.011590 sec\n",
      "optimizer time 0.004198 sec\n",
      "training time in round 81 cost 0.40083909034729004 sec\n",
      "loss 2.292742, train acc 0.129859\n",
      "round 82\n",
      "time to device 0.004198 sec\n",
      "time forward 1.076056 sec\n",
      "loss time 0.001352 sec\n",
      "backward time 0.008388 sec\n",
      "optimizer time 0.004048 sec\n",
      "training time in round 82 cost 0.39965081214904785 sec\n",
      "loss 2.292634, train acc 0.129895\n",
      "round 83\n",
      "time to device 0.006838 sec\n",
      "time forward 1.085772 sec\n",
      "loss time 0.001162 sec\n",
      "backward time 0.008356 sec\n",
      "optimizer time 0.004878 sec\n",
      "training time in round 83 cost 0.38889217376708984 sec\n",
      "loss 2.292422, train acc 0.130487\n",
      "round 84\n",
      "time to device 0.011503 sec\n",
      "time forward 1.102263 sec\n",
      "loss time 0.001078 sec\n",
      "backward time 0.005580 sec\n",
      "optimizer time 0.004097 sec\n",
      "training time in round 84 cost 0.3974299430847168 sec\n",
      "loss 2.292242, train acc 0.130882\n",
      "round 85\n",
      "time to device 0.010089 sec\n",
      "time forward 1.117179 sec\n",
      "loss time 0.000947 sec\n",
      "backward time 0.007759 sec\n",
      "optimizer time 0.004143 sec\n",
      "training time in round 85 cost 0.39514684677124023 sec\n",
      "loss 2.292160, train acc 0.130814\n",
      "round 86\n",
      "time to device 0.007152 sec\n",
      "time forward 1.130240 sec\n",
      "loss time 0.001452 sec\n",
      "backward time 0.011651 sec\n",
      "optimizer time 0.004628 sec\n",
      "training time in round 86 cost 0.3891317844390869 sec\n",
      "loss 2.291982, train acc 0.131466\n",
      "round 87\n",
      "time to device 0.008063 sec\n",
      "time forward 1.143867 sec\n",
      "loss time 0.001428 sec\n",
      "backward time 0.013101 sec\n",
      "optimizer time 0.005709 sec\n",
      "training time in round 87 cost 0.40065789222717285 sec\n",
      "loss 2.291867, train acc 0.131747\n",
      "round 88\n",
      "time to device 0.008001 sec\n",
      "time forward 1.155529 sec\n",
      "loss time 0.001480 sec\n",
      "backward time 0.012069 sec\n",
      "optimizer time 0.004860 sec\n",
      "training time in round 88 cost 0.38197803497314453 sec\n",
      "loss 2.291773, train acc 0.131935\n",
      "round 89\n",
      "time to device 0.007739 sec\n",
      "time forward 1.167963 sec\n",
      "loss time 0.000706 sec\n",
      "backward time 0.005768 sec\n",
      "optimizer time 0.002184 sec\n",
      "training time in round 89 cost 0.38466525077819824 sec\n",
      "loss 2.291581, train acc 0.132812\n",
      "round 90\n",
      "time to device 0.008853 sec\n",
      "time forward 1.181345 sec\n",
      "loss time 0.001751 sec\n",
      "backward time 0.012346 sec\n",
      "optimizer time 0.003752 sec\n",
      "training time in round 90 cost 0.4020700454711914 sec\n",
      "loss 2.291327, train acc 0.133757\n",
      "round 91\n",
      "time to device 0.007526 sec\n",
      "time forward 1.193888 sec\n",
      "loss time 0.001106 sec\n",
      "backward time 0.009948 sec\n",
      "optimizer time 0.003746 sec\n",
      "training time in round 91 cost 0.3823678493499756 sec\n",
      "loss 2.291001, train acc 0.134851\n",
      "round 92\n",
      "time to device 0.008218 sec\n",
      "time forward 1.207312 sec\n",
      "loss time 0.001624 sec\n",
      "backward time 0.006846 sec\n",
      "optimizer time 0.003069 sec\n",
      "training time in round 92 cost 0.4056220054626465 sec\n",
      "loss 2.290806, train acc 0.135165\n",
      "round 93\n",
      "time to device 0.007499 sec\n",
      "time forward 1.222521 sec\n",
      "loss time 0.001142 sec\n",
      "backward time 0.010940 sec\n",
      "optimizer time 0.004757 sec\n",
      "training time in round 93 cost 0.40674781799316406 sec\n",
      "loss 2.290580, train acc 0.135555\n",
      "round 94\n",
      "time to device 0.004273 sec\n",
      "time forward 1.235488 sec\n",
      "loss time 0.001814 sec\n",
      "backward time 0.011675 sec\n",
      "optimizer time 0.004776 sec\n",
      "training time in round 94 cost 0.39536309242248535 sec\n",
      "loss 2.290301, train acc 0.136595\n",
      "round 95\n",
      "time to device 0.004348 sec\n",
      "time forward 1.245140 sec\n",
      "loss time 0.000432 sec\n",
      "backward time 0.003835 sec\n",
      "optimizer time 0.001938 sec\n",
      "training time in round 95 cost 0.3715839385986328 sec\n",
      "loss 2.290059, train acc 0.137288\n",
      "round 96\n",
      "time to device 0.003243 sec\n",
      "time forward 1.254591 sec\n",
      "loss time 0.001091 sec\n",
      "backward time 0.008610 sec\n",
      "optimizer time 0.003242 sec\n",
      "training time in round 96 cost 0.36322832107543945 sec\n",
      "loss 2.289792, train acc 0.138048\n",
      "round 97\n",
      "time to device 0.005085 sec\n",
      "time forward 1.264551 sec\n",
      "loss time 0.000522 sec\n",
      "backward time 0.006571 sec\n",
      "optimizer time 0.002542 sec\n",
      "training time in round 97 cost 0.3759591579437256 sec\n",
      "loss 2.289496, train acc 0.139349\n",
      "round 98\n",
      "time to device 0.007672 sec\n",
      "time forward 1.275258 sec\n",
      "loss time 0.001416 sec\n",
      "backward time 0.010687 sec\n",
      "optimizer time 0.003593 sec\n",
      "training time in round 98 cost 0.38604307174682617 sec\n",
      "loss 2.289304, train acc 0.139520\n",
      "round 99\n",
      "time to device 0.004678 sec\n",
      "time forward 1.287110 sec\n",
      "loss time 0.001914 sec\n",
      "backward time 0.014209 sec\n",
      "optimizer time 0.004527 sec\n",
      "training time in round 99 cost 0.38011789321899414 sec\n",
      "loss 2.289038, train acc 0.139687\n",
      "round 100\n",
      "time to device 0.004350 sec\n",
      "time forward 1.298641 sec\n",
      "loss time 0.002421 sec\n",
      "backward time 0.010956 sec\n",
      "optimizer time 0.004166 sec\n",
      "training time in round 100 cost 0.37963199615478516 sec\n",
      "loss 2.288860, train acc 0.140316\n",
      "round 101\n",
      "time to device 0.004164 sec\n",
      "time forward 1.309176 sec\n",
      "loss time 0.001012 sec\n",
      "backward time 0.009383 sec\n",
      "optimizer time 0.003423 sec\n",
      "training time in round 101 cost 0.36423301696777344 sec\n",
      "loss 2.288499, train acc 0.141238\n",
      "round 102\n",
      "time to device 0.003627 sec\n",
      "time forward 1.320937 sec\n",
      "loss time 0.001023 sec\n",
      "backward time 0.009790 sec\n",
      "optimizer time 0.003707 sec\n",
      "training time in round 102 cost 0.38189196586608887 sec\n",
      "loss 2.288236, train acc 0.141535\n",
      "round 103\n",
      "time to device 0.003875 sec\n",
      "time forward 1.332535 sec\n",
      "loss time 0.000973 sec\n",
      "backward time 0.011187 sec\n",
      "optimizer time 0.005047 sec\n",
      "training time in round 103 cost 0.38886594772338867 sec\n",
      "loss 2.287923, train acc 0.142353\n",
      "round 104\n",
      "time to device 0.005039 sec\n",
      "time forward 1.348847 sec\n",
      "loss time 0.000869 sec\n",
      "backward time 0.007987 sec\n",
      "optimizer time 0.002988 sec\n",
      "training time in round 104 cost 0.43530893325805664 sec\n",
      "loss 2.287703, train acc 0.142336\n",
      "round 105\n",
      "time to device 0.006246 sec\n",
      "time forward 1.359856 sec\n",
      "loss time 0.001200 sec\n",
      "backward time 0.006459 sec\n",
      "optimizer time 0.002326 sec\n",
      "training time in round 105 cost 0.36987876892089844 sec\n",
      "loss 2.287436, train acc 0.142762\n",
      "round 106\n",
      "time to device 0.008697 sec\n",
      "time forward 1.372051 sec\n",
      "loss time 0.001280 sec\n",
      "backward time 0.008086 sec\n",
      "optimizer time 0.003567 sec\n",
      "training time in round 106 cost 0.38134002685546875 sec\n",
      "loss 2.287125, train acc 0.143400\n",
      "round 107\n",
      "time to device 0.016527 sec\n",
      "time forward 1.386069 sec\n",
      "loss time 0.001662 sec\n",
      "backward time 0.011946 sec\n",
      "optimizer time 0.003787 sec\n",
      "training time in round 107 cost 0.40148377418518066 sec\n",
      "loss 2.286688, train acc 0.144604\n",
      "round 108\n",
      "time to device 0.007147 sec\n",
      "time forward 1.397958 sec\n",
      "loss time 0.001831 sec\n",
      "backward time 0.009804 sec\n",
      "optimizer time 0.002957 sec\n",
      "training time in round 108 cost 0.40538763999938965 sec\n",
      "loss 2.286434, train acc 0.144925\n",
      "round 109\n",
      "time to device 0.005046 sec\n",
      "time forward 1.405216 sec\n",
      "loss time 0.000894 sec\n",
      "backward time 0.006531 sec\n",
      "optimizer time 0.003474 sec\n",
      "training time in round 109 cost 0.36485719680786133 sec\n",
      "loss 2.286047, train acc 0.146520\n",
      "round 110\n",
      "time to device 0.006726 sec\n",
      "time forward 1.415697 sec\n",
      "loss time 0.001018 sec\n",
      "backward time 0.010459 sec\n",
      "optimizer time 0.005367 sec\n",
      "training time in round 110 cost 0.403095006942749 sec\n",
      "loss 2.285603, train acc 0.147311\n",
      "round 111\n",
      "time to device 0.005341 sec\n",
      "time forward 1.425600 sec\n",
      "loss time 0.000558 sec\n",
      "backward time 0.004704 sec\n",
      "optimizer time 0.003838 sec\n",
      "training time in round 111 cost 0.4109809398651123 sec\n",
      "loss 2.285333, train acc 0.147670\n",
      "round 112\n",
      "time to device 0.008481 sec\n",
      "time forward 1.440252 sec\n",
      "loss time 0.000804 sec\n",
      "backward time 0.006537 sec\n",
      "optimizer time 0.002909 sec\n",
      "training time in round 112 cost 0.3854830265045166 sec\n",
      "loss 2.284956, train acc 0.148438\n",
      "round 113\n",
      "time to device 0.008597 sec\n",
      "time forward 1.462569 sec\n",
      "loss time 0.000576 sec\n",
      "backward time 0.005492 sec\n",
      "optimizer time 0.002514 sec\n",
      "training time in round 113 cost 0.399033784866333 sec\n",
      "loss 2.284540, train acc 0.148849\n",
      "round 114\n",
      "time to device 0.008470 sec\n",
      "time forward 1.474936 sec\n",
      "loss time 0.002556 sec\n",
      "backward time 0.013987 sec\n",
      "optimizer time 0.004948 sec\n",
      "training time in round 114 cost 0.39202404022216797 sec\n",
      "loss 2.284142, train acc 0.149253\n",
      "round 115\n",
      "time to device 0.008260 sec\n",
      "time forward 1.483436 sec\n",
      "loss time 0.000534 sec\n",
      "backward time 0.005406 sec\n",
      "optimizer time 0.002625 sec\n",
      "training time in round 115 cost 0.40670275688171387 sec\n",
      "loss 2.283743, train acc 0.149650\n",
      "round 116\n",
      "time to device 0.015647 sec\n",
      "time forward 1.494830 sec\n",
      "loss time 0.000785 sec\n",
      "backward time 0.006626 sec\n",
      "optimizer time 0.002672 sec\n",
      "training time in round 116 cost 0.4186418056488037 sec\n",
      "loss 2.283192, train acc 0.150441\n",
      "round 117\n",
      "time to device 0.013411 sec\n",
      "time forward 1.505858 sec\n",
      "loss time 0.000715 sec\n",
      "backward time 0.007876 sec\n",
      "optimizer time 0.003155 sec\n",
      "training time in round 117 cost 0.41223716735839844 sec\n",
      "loss 2.282824, train acc 0.150490\n",
      "round 118\n",
      "time to device 0.007209 sec\n",
      "time forward 1.511909 sec\n",
      "loss time 0.000488 sec\n",
      "backward time 0.004569 sec\n",
      "optimizer time 0.002100 sec\n",
      "training time in round 118 cost 0.38608884811401367 sec\n",
      "loss 2.282242, train acc 0.151195\n",
      "round 119\n",
      "time to device 0.007061 sec\n",
      "time forward 1.520187 sec\n",
      "loss time 0.001046 sec\n",
      "backward time 0.008223 sec\n",
      "optimizer time 0.003314 sec\n",
      "training time in round 119 cost 0.39394402503967285 sec\n",
      "loss 2.281689, train acc 0.152018\n",
      "round 120\n",
      "time to device 0.005736 sec\n",
      "time forward 1.533453 sec\n",
      "loss time 0.000460 sec\n",
      "backward time 0.004029 sec\n",
      "optimizer time 0.001982 sec\n",
      "training time in round 120 cost 0.3842639923095703 sec\n",
      "loss 2.281017, train acc 0.153603\n",
      "round 121\n",
      "time to device 0.007285 sec\n",
      "time forward 1.542460 sec\n",
      "loss time 0.000894 sec\n",
      "backward time 0.008601 sec\n",
      "optimizer time 0.003060 sec\n",
      "training time in round 121 cost 0.4017810821533203 sec\n",
      "loss 2.280443, train acc 0.154521\n",
      "round 122\n",
      "time to device 0.007594 sec\n",
      "time forward 1.555921 sec\n",
      "loss time 0.002240 sec\n",
      "backward time 0.012738 sec\n",
      "optimizer time 0.007204 sec\n",
      "training time in round 122 cost 0.4095320701599121 sec\n",
      "loss 2.280004, train acc 0.155043\n",
      "round 123\n",
      "time to device 0.006750 sec\n",
      "time forward 1.567364 sec\n",
      "loss time 0.001055 sec\n",
      "backward time 0.010104 sec\n",
      "optimizer time 0.003996 sec\n",
      "training time in round 123 cost 0.38025712966918945 sec\n",
      "loss 2.279438, train acc 0.156061\n",
      "round 124\n",
      "time to device 0.007591 sec\n",
      "time forward 1.578683 sec\n",
      "loss time 0.001201 sec\n",
      "backward time 0.011135 sec\n",
      "optimizer time 0.003952 sec\n",
      "training time in round 124 cost 0.3842287063598633 sec\n",
      "loss 2.278858, train acc 0.156562\n",
      "round 125\n",
      "time to device 0.007776 sec\n",
      "time forward 1.590099 sec\n",
      "loss time 0.000660 sec\n",
      "backward time 0.005133 sec\n",
      "optimizer time 0.002321 sec\n",
      "training time in round 125 cost 0.382648229598999 sec\n",
      "loss 2.278027, train acc 0.157800\n",
      "round 126\n",
      "time to device 0.007328 sec\n",
      "time forward 1.603710 sec\n",
      "loss time 0.001197 sec\n",
      "backward time 0.009278 sec\n",
      "optimizer time 0.001981 sec\n",
      "training time in round 126 cost 0.4069058895111084 sec\n",
      "loss 2.277343, train acc 0.158649\n",
      "round 127\n",
      "time to device 0.006774 sec\n",
      "time forward 1.614442 sec\n",
      "loss time 0.001329 sec\n",
      "backward time 0.014546 sec\n",
      "optimizer time 0.004319 sec\n",
      "training time in round 127 cost 0.3780338764190674 sec\n",
      "loss 2.276690, train acc 0.159302\n",
      "round 128\n",
      "time to device 0.009555 sec\n",
      "time forward 1.626246 sec\n",
      "loss time 0.000904 sec\n",
      "backward time 0.008357 sec\n",
      "optimizer time 0.003525 sec\n",
      "training time in round 128 cost 0.4357919692993164 sec\n",
      "loss 2.275910, train acc 0.160065\n",
      "round 129\n",
      "time to device 0.009432 sec\n",
      "time forward 1.634895 sec\n",
      "loss time 0.000950 sec\n",
      "backward time 0.008555 sec\n",
      "optimizer time 0.003357 sec\n",
      "training time in round 129 cost 0.3886449337005615 sec\n",
      "loss 2.275242, train acc 0.160757\n",
      "round 130\n",
      "time to device 0.009051 sec\n",
      "time forward 1.642142 sec\n",
      "loss time 0.000431 sec\n",
      "backward time 0.004755 sec\n",
      "optimizer time 0.001918 sec\n",
      "training time in round 130 cost 0.3931419849395752 sec\n",
      "loss 2.274493, train acc 0.161319\n",
      "round 131\n",
      "time to device 0.007848 sec\n",
      "time forward 1.654613 sec\n",
      "loss time 0.000896 sec\n",
      "backward time 0.009282 sec\n",
      "optimizer time 0.004721 sec\n",
      "training time in round 131 cost 0.41711997985839844 sec\n",
      "loss 2.273581, train acc 0.162346\n",
      "round 132\n",
      "time to device 0.007591 sec\n",
      "time forward 1.664094 sec\n",
      "loss time 0.001231 sec\n",
      "backward time 0.004549 sec\n",
      "optimizer time 0.002102 sec\n",
      "training time in round 132 cost 0.4102897644042969 sec\n",
      "loss 2.272797, train acc 0.163240\n",
      "round 133\n",
      "time to device 0.005944 sec\n",
      "time forward 1.676603 sec\n",
      "loss time 0.001347 sec\n",
      "backward time 0.012655 sec\n",
      "optimizer time 0.005125 sec\n",
      "training time in round 133 cost 0.38707876205444336 sec\n",
      "loss 2.271843, train acc 0.164296\n",
      "round 134\n",
      "time to device 0.009974 sec\n",
      "time forward 1.687183 sec\n",
      "loss time 0.000837 sec\n",
      "backward time 0.011887 sec\n",
      "optimizer time 0.003438 sec\n",
      "training time in round 134 cost 0.4151191711425781 sec\n",
      "loss 2.270788, train acc 0.165336\n",
      "round 135\n",
      "time to device 0.007027 sec\n",
      "time forward 1.694742 sec\n",
      "loss time 0.000571 sec\n",
      "backward time 0.005110 sec\n",
      "optimizer time 0.003008 sec\n",
      "training time in round 135 cost 0.4000670909881592 sec\n",
      "loss 2.269865, train acc 0.165556\n",
      "round 136\n",
      "time to device 0.007850 sec\n",
      "time forward 1.703784 sec\n",
      "loss time 0.001321 sec\n",
      "backward time 0.008336 sec\n",
      "optimizer time 0.003350 sec\n",
      "training time in round 136 cost 0.39372682571411133 sec\n",
      "loss 2.268909, train acc 0.166286\n",
      "round 137\n",
      "time to device 0.007591 sec\n",
      "time forward 1.710946 sec\n",
      "loss time 0.000749 sec\n",
      "backward time 0.006365 sec\n",
      "optimizer time 0.003316 sec\n",
      "training time in round 137 cost 0.387265682220459 sec\n",
      "loss 2.267559, train acc 0.167516\n",
      "round 138\n",
      "time to device 0.009575 sec\n",
      "time forward 1.722056 sec\n",
      "loss time 0.000827 sec\n",
      "backward time 0.007236 sec\n",
      "optimizer time 0.003585 sec\n",
      "training time in round 138 cost 0.3880300521850586 sec\n",
      "loss 2.266379, train acc 0.168278\n",
      "round 139\n",
      "time to device 0.012355 sec\n",
      "time forward 1.735775 sec\n",
      "loss time 0.002058 sec\n",
      "backward time 0.007571 sec\n",
      "optimizer time 0.002973 sec\n",
      "training time in round 139 cost 0.4158148765563965 sec\n",
      "loss 2.265135, train acc 0.169531\n",
      "round 140\n",
      "time to device 0.011183 sec\n",
      "time forward 1.749476 sec\n",
      "loss time 0.000973 sec\n",
      "backward time 0.010077 sec\n",
      "optimizer time 0.004040 sec\n",
      "training time in round 140 cost 0.4374668598175049 sec\n",
      "loss 2.263733, train acc 0.170490\n",
      "round 141\n",
      "time to device 0.009812 sec\n",
      "time forward 1.760370 sec\n",
      "loss time 0.000502 sec\n",
      "backward time 0.005991 sec\n",
      "optimizer time 0.002384 sec\n",
      "training time in round 141 cost 0.3934018611907959 sec\n",
      "loss 2.262259, train acc 0.171160\n",
      "round 142\n",
      "time to device 0.008751 sec\n",
      "time forward 1.771317 sec\n",
      "loss time 0.000695 sec\n",
      "backward time 0.007891 sec\n",
      "optimizer time 0.003714 sec\n",
      "training time in round 142 cost 0.4113008975982666 sec\n",
      "loss 2.260810, train acc 0.171930\n",
      "round 143\n",
      "time to device 0.008033 sec\n",
      "time forward 1.780196 sec\n",
      "loss time 0.000640 sec\n",
      "backward time 0.008122 sec\n",
      "optimizer time 0.002665 sec\n",
      "training time in round 143 cost 0.38846898078918457 sec\n",
      "loss 2.259511, train acc 0.172526\n",
      "round 144\n",
      "time to device 0.008780 sec\n",
      "time forward 1.793694 sec\n",
      "loss time 0.001485 sec\n",
      "backward time 0.014835 sec\n",
      "optimizer time 0.004987 sec\n",
      "training time in round 144 cost 0.42442893981933594 sec\n",
      "loss 2.257579, train acc 0.173599\n",
      "round 145\n",
      "time to device 0.006860 sec\n",
      "time forward 1.803693 sec\n",
      "loss time 0.001106 sec\n",
      "backward time 0.009244 sec\n",
      "optimizer time 0.003778 sec\n",
      "training time in round 145 cost 0.40695691108703613 sec\n",
      "loss 2.255664, train acc 0.174711\n",
      "round 146\n",
      "time to device 0.007150 sec\n",
      "time forward 1.817210 sec\n",
      "loss time 0.001421 sec\n",
      "backward time 0.015529 sec\n",
      "optimizer time 0.006381 sec\n",
      "training time in round 146 cost 0.38933300971984863 sec\n",
      "loss 2.253766, train acc 0.175861\n",
      "round 147\n",
      "time to device 0.009086 sec\n",
      "time forward 1.825237 sec\n",
      "loss time 0.000775 sec\n",
      "backward time 0.006372 sec\n",
      "optimizer time 0.004206 sec\n",
      "training time in round 147 cost 0.389786958694458 sec\n",
      "loss 2.251765, train acc 0.176784\n",
      "round 148\n",
      "time to device 0.008058 sec\n",
      "time forward 1.836430 sec\n",
      "loss time 0.001148 sec\n",
      "backward time 0.010634 sec\n",
      "optimizer time 0.004355 sec\n",
      "training time in round 148 cost 0.37258076667785645 sec\n",
      "loss 2.249371, train acc 0.178219\n",
      "round 149\n",
      "time to device 0.006682 sec\n",
      "time forward 1.847971 sec\n",
      "loss time 0.001237 sec\n",
      "backward time 0.008327 sec\n",
      "optimizer time 0.002488 sec\n",
      "training time in round 149 cost 0.3931159973144531 sec\n",
      "loss 2.246551, train acc 0.179688\n",
      "round 150\n",
      "time to device 0.008017 sec\n",
      "time forward 1.859874 sec\n",
      "loss time 0.000592 sec\n",
      "backward time 0.005443 sec\n",
      "optimizer time 0.002400 sec\n",
      "training time in round 150 cost 0.39632511138916016 sec\n",
      "loss 2.244116, train acc 0.180464\n",
      "round 151\n",
      "time to device 0.007443 sec\n",
      "time forward 1.875224 sec\n",
      "loss time 0.001308 sec\n",
      "backward time 0.007384 sec\n",
      "optimizer time 0.004246 sec\n",
      "training time in round 151 cost 0.40286898612976074 sec\n",
      "loss 2.241873, train acc 0.181486\n",
      "round 152\n",
      "time to device 0.009357 sec\n",
      "time forward 1.883722 sec\n",
      "loss time 0.000422 sec\n",
      "backward time 0.004336 sec\n",
      "optimizer time 0.002029 sec\n",
      "training time in round 152 cost 0.3596937656402588 sec\n",
      "loss 2.238262, train acc 0.183007\n",
      "round 153\n",
      "time to device 0.007661 sec\n",
      "time forward 1.894927 sec\n",
      "loss time 0.001582 sec\n",
      "backward time 0.020595 sec\n",
      "optimizer time 0.002982 sec\n",
      "training time in round 153 cost 0.3867480754852295 sec\n",
      "loss 2.235646, train acc 0.183847\n",
      "round 154\n",
      "time to device 0.011560 sec\n",
      "time forward 1.905271 sec\n",
      "loss time 0.001157 sec\n",
      "backward time 0.013151 sec\n",
      "optimizer time 0.004111 sec\n",
      "training time in round 154 cost 0.38379597663879395 sec\n",
      "loss 2.232183, train acc 0.185131\n",
      "round 155\n",
      "time to device 0.007804 sec\n",
      "time forward 1.914036 sec\n",
      "loss time 0.000717 sec\n",
      "backward time 0.007389 sec\n",
      "optimizer time 0.003156 sec\n",
      "training time in round 155 cost 0.4011240005493164 sec\n",
      "loss 2.228900, train acc 0.186248\n",
      "round 156\n",
      "time to device 0.007538 sec\n",
      "time forward 1.926303 sec\n",
      "loss time 0.001155 sec\n",
      "backward time 0.010446 sec\n",
      "optimizer time 0.004370 sec\n",
      "training time in round 156 cost 0.41988110542297363 sec\n",
      "loss 2.225490, train acc 0.187550\n",
      "round 157\n",
      "time to device 0.008610 sec\n",
      "time forward 1.938851 sec\n",
      "loss time 0.000576 sec\n",
      "backward time 0.007080 sec\n",
      "optimizer time 0.002943 sec\n",
      "training time in round 157 cost 0.39906883239746094 sec\n",
      "loss 2.222656, train acc 0.188687\n",
      "round 158\n",
      "time to device 0.007617 sec\n",
      "time forward 1.948921 sec\n",
      "loss time 0.001175 sec\n",
      "backward time 0.012092 sec\n",
      "optimizer time 0.002276 sec\n",
      "training time in round 158 cost 0.3894011974334717 sec\n",
      "loss 2.218840, train acc 0.190055\n",
      "round 159\n",
      "time to device 0.006368 sec\n",
      "time forward 1.960416 sec\n",
      "loss time 0.000546 sec\n",
      "backward time 0.004955 sec\n",
      "optimizer time 0.002392 sec\n",
      "training time in round 159 cost 0.4251739978790283 sec\n",
      "loss 2.215601, train acc 0.190967\n",
      "round 160\n",
      "time to device 0.008148 sec\n",
      "time forward 1.973532 sec\n",
      "loss time 0.001133 sec\n",
      "backward time 0.010363 sec\n",
      "optimizer time 0.003954 sec\n",
      "training time in round 160 cost 0.38493895530700684 sec\n",
      "loss 2.211907, train acc 0.192352\n",
      "round 161\n",
      "time to device 0.005612 sec\n",
      "time forward 1.986326 sec\n",
      "loss time 0.001341 sec\n",
      "backward time 0.010137 sec\n",
      "optimizer time 0.002617 sec\n",
      "training time in round 161 cost 0.38578200340270996 sec\n",
      "loss 2.208538, train acc 0.193287\n",
      "round 162\n",
      "time to device 0.006347 sec\n",
      "time forward 1.997591 sec\n",
      "loss time 0.001093 sec\n",
      "backward time 0.006548 sec\n",
      "optimizer time 0.002373 sec\n",
      "training time in round 162 cost 0.39345788955688477 sec\n",
      "loss 2.204641, train acc 0.194833\n",
      "round 163\n",
      "time to device 0.005535 sec\n",
      "time forward 2.012326 sec\n",
      "loss time 0.000654 sec\n",
      "backward time 0.006052 sec\n",
      "optimizer time 0.002862 sec\n",
      "training time in round 163 cost 0.4313080310821533 sec\n",
      "loss 2.200231, train acc 0.196503\n",
      "round 164\n",
      "time to device 0.006285 sec\n",
      "time forward 2.022071 sec\n",
      "loss time 0.000930 sec\n",
      "backward time 0.008146 sec\n",
      "optimizer time 0.006118 sec\n",
      "training time in round 164 cost 0.4256398677825928 sec\n",
      "loss 2.196244, train acc 0.197869\n",
      "round 165\n",
      "time to device 0.006771 sec\n",
      "time forward 2.034258 sec\n",
      "loss time 0.001940 sec\n",
      "backward time 0.011967 sec\n",
      "optimizer time 0.004852 sec\n",
      "training time in round 165 cost 0.41045093536376953 sec\n",
      "loss 2.192372, train acc 0.199030\n",
      "round 166\n",
      "time to device 0.009837 sec\n",
      "time forward 2.047300 sec\n",
      "loss time 0.000947 sec\n",
      "backward time 0.008215 sec\n",
      "optimizer time 0.003234 sec\n",
      "training time in round 166 cost 0.37355995178222656 sec\n",
      "loss 2.188587, train acc 0.200318\n",
      "round 167\n",
      "time to device 0.007055 sec\n",
      "time forward 2.058351 sec\n",
      "loss time 0.001351 sec\n",
      "backward time 0.012239 sec\n",
      "optimizer time 0.003963 sec\n",
      "training time in round 167 cost 0.3741328716278076 sec\n",
      "loss 2.184359, train acc 0.201869\n",
      "round 168\n",
      "time to device 0.014373 sec\n",
      "time forward 2.069677 sec\n",
      "loss time 0.001361 sec\n",
      "backward time 0.010415 sec\n",
      "optimizer time 0.003500 sec\n",
      "training time in round 168 cost 0.38953089714050293 sec\n",
      "loss 2.181459, train acc 0.202524\n",
      "round 169\n",
      "time to device 0.008405 sec\n",
      "time forward 2.081603 sec\n",
      "loss time 0.001309 sec\n",
      "backward time 0.005455 sec\n",
      "optimizer time 0.002050 sec\n",
      "training time in round 169 cost 0.410247802734375 sec\n",
      "loss 2.178141, train acc 0.203585\n",
      "round 170\n",
      "time to device 0.009457 sec\n",
      "time forward 2.100193 sec\n",
      "loss time 0.000471 sec\n",
      "backward time 0.003795 sec\n",
      "optimizer time 0.003162 sec\n",
      "training time in round 170 cost 0.3890378475189209 sec\n",
      "loss 2.173827, train acc 0.205181\n",
      "round 171\n",
      "time to device 0.007743 sec\n",
      "time forward 2.109596 sec\n",
      "loss time 0.000472 sec\n",
      "backward time 0.004645 sec\n",
      "optimizer time 0.002172 sec\n",
      "training time in round 171 cost 0.37459278106689453 sec\n",
      "loss 2.169707, train acc 0.206668\n",
      "round 172\n",
      "time to device 0.008480 sec\n",
      "time forward 2.121531 sec\n",
      "loss time 0.001211 sec\n",
      "backward time 0.006470 sec\n",
      "optimizer time 0.003612 sec\n",
      "training time in round 172 cost 0.3840060234069824 sec\n",
      "loss 2.164902, train acc 0.208138\n",
      "round 173\n",
      "time to device 0.007802 sec\n",
      "time forward 2.131249 sec\n",
      "loss time 0.000819 sec\n",
      "backward time 0.009015 sec\n",
      "optimizer time 0.003931 sec\n",
      "training time in round 173 cost 0.3912649154663086 sec\n",
      "loss 2.161036, train acc 0.209231\n",
      "round 174\n",
      "time to device 0.012855 sec\n",
      "time forward 2.141531 sec\n",
      "loss time 0.001319 sec\n",
      "backward time 0.011297 sec\n",
      "optimizer time 0.004586 sec\n",
      "training time in round 174 cost 0.37190794944763184 sec\n",
      "loss 2.157220, train acc 0.210446\n",
      "round 175\n",
      "time to device 0.007510 sec\n",
      "time forward 2.152944 sec\n",
      "loss time 0.001007 sec\n",
      "backward time 0.009054 sec\n",
      "optimizer time 0.003349 sec\n",
      "training time in round 175 cost 0.37755393981933594 sec\n",
      "loss 2.153356, train acc 0.211603\n",
      "round 176\n",
      "time to device 0.010112 sec\n",
      "time forward 2.164899 sec\n",
      "loss time 0.002104 sec\n",
      "backward time 0.012869 sec\n",
      "optimizer time 0.002229 sec\n",
      "training time in round 176 cost 0.3854517936706543 sec\n",
      "loss 2.149423, train acc 0.212791\n",
      "round 177\n",
      "time to device 0.007371 sec\n",
      "time forward 2.172589 sec\n",
      "loss time 0.000427 sec\n",
      "backward time 0.004453 sec\n",
      "optimizer time 0.003164 sec\n",
      "training time in round 177 cost 0.43862009048461914 sec\n",
      "loss 2.145607, train acc 0.213878\n",
      "round 178\n",
      "time to device 0.009365 sec\n",
      "time forward 2.182991 sec\n",
      "loss time 0.000829 sec\n",
      "backward time 0.009015 sec\n",
      "optimizer time 0.002298 sec\n",
      "training time in round 178 cost 0.3799281120300293 sec\n",
      "loss 2.141689, train acc 0.215389\n",
      "round 179\n",
      "time to device 0.009561 sec\n",
      "time forward 2.197031 sec\n",
      "loss time 0.001589 sec\n",
      "backward time 0.010133 sec\n",
      "optimizer time 0.004121 sec\n",
      "training time in round 179 cost 0.38944387435913086 sec\n",
      "loss 2.137211, train acc 0.216797\n",
      "round 180\n",
      "time to device 0.007917 sec\n",
      "time forward 2.211402 sec\n",
      "loss time 0.001051 sec\n",
      "backward time 0.010124 sec\n",
      "optimizer time 0.004219 sec\n",
      "training time in round 180 cost 0.3799917697906494 sec\n",
      "loss 2.132518, train acc 0.218318\n",
      "round 181\n",
      "time to device 0.008827 sec\n",
      "time forward 2.222631 sec\n",
      "loss time 0.002037 sec\n",
      "backward time 0.012638 sec\n",
      "optimizer time 0.005010 sec\n",
      "training time in round 181 cost 0.3770768642425537 sec\n",
      "loss 2.127369, train acc 0.220167\n",
      "round 182\n",
      "time to device 0.006689 sec\n",
      "time forward 2.234801 sec\n",
      "loss time 0.001918 sec\n",
      "backward time 0.011490 sec\n",
      "optimizer time 0.004323 sec\n",
      "training time in round 182 cost 0.37012290954589844 sec\n",
      "loss 2.122356, train acc 0.221909\n",
      "round 183\n",
      "time to device 0.008098 sec\n",
      "time forward 2.245824 sec\n",
      "loss time 0.001472 sec\n",
      "backward time 0.013254 sec\n",
      "optimizer time 0.005629 sec\n",
      "training time in round 183 cost 0.372830867767334 sec\n",
      "loss 2.118814, train acc 0.222911\n",
      "round 184\n",
      "time to device 0.006824 sec\n",
      "time forward 2.259139 sec\n",
      "loss time 0.001519 sec\n",
      "backward time 0.007973 sec\n",
      "optimizer time 0.002887 sec\n",
      "training time in round 184 cost 0.39737892150878906 sec\n",
      "loss 2.115235, train acc 0.224071\n",
      "round 185\n",
      "time to device 0.008816 sec\n",
      "time forward 2.269056 sec\n",
      "loss time 0.000694 sec\n",
      "backward time 0.007305 sec\n",
      "optimizer time 0.005074 sec\n",
      "training time in round 185 cost 0.3828086853027344 sec\n",
      "loss 2.111562, train acc 0.225176\n",
      "round 186\n",
      "time to device 0.006602 sec\n",
      "time forward 2.278910 sec\n",
      "loss time 0.001136 sec\n",
      "backward time 0.009181 sec\n",
      "optimizer time 0.004149 sec\n",
      "training time in round 186 cost 0.3725121021270752 sec\n",
      "loss 2.106800, train acc 0.226813\n",
      "round 187\n",
      "time to device 0.005871 sec\n",
      "time forward 2.291170 sec\n",
      "loss time 0.000807 sec\n",
      "backward time 0.008836 sec\n",
      "optimizer time 0.005428 sec\n",
      "training time in round 187 cost 0.39433884620666504 sec\n",
      "loss 2.102056, train acc 0.228682\n",
      "round 188\n",
      "time to device 0.008023 sec\n",
      "time forward 2.304219 sec\n",
      "loss time 0.000615 sec\n",
      "backward time 0.005832 sec\n",
      "optimizer time 0.002942 sec\n",
      "training time in round 188 cost 0.4241650104522705 sec\n",
      "loss 2.098132, train acc 0.230035\n",
      "round 189\n",
      "time to device 0.007100 sec\n",
      "time forward 2.317492 sec\n",
      "loss time 0.001528 sec\n",
      "backward time 0.011391 sec\n",
      "optimizer time 0.003854 sec\n",
      "training time in round 189 cost 0.439194917678833 sec\n",
      "loss 2.093231, train acc 0.231620\n",
      "round 190\n",
      "time to device 0.006499 sec\n",
      "time forward 2.331664 sec\n",
      "loss time 0.000513 sec\n",
      "backward time 0.005077 sec\n",
      "optimizer time 0.002508 sec\n",
      "training time in round 190 cost 0.3981921672821045 sec\n",
      "loss 2.088900, train acc 0.233148\n",
      "round 191\n",
      "time to device 0.007705 sec\n",
      "time forward 2.346387 sec\n",
      "loss time 0.001407 sec\n",
      "backward time 0.009815 sec\n",
      "optimizer time 0.003588 sec\n",
      "training time in round 191 cost 0.3974599838256836 sec\n",
      "loss 2.085100, train acc 0.234416\n",
      "round 192\n",
      "time to device 0.007743 sec\n",
      "time forward 2.355373 sec\n",
      "loss time 0.000548 sec\n",
      "backward time 0.007525 sec\n",
      "optimizer time 0.002432 sec\n",
      "training time in round 192 cost 0.3805058002471924 sec\n",
      "loss 2.081315, train acc 0.235832\n",
      "round 193\n",
      "time to device 0.007729 sec\n",
      "time forward 2.365963 sec\n",
      "loss time 0.000423 sec\n",
      "backward time 0.004460 sec\n",
      "optimizer time 0.002161 sec\n",
      "training time in round 193 cost 0.44167399406433105 sec\n",
      "loss 2.077544, train acc 0.237154\n",
      "round 194\n",
      "time to device 0.006656 sec\n",
      "time forward 2.380441 sec\n",
      "loss time 0.000562 sec\n",
      "backward time 0.005647 sec\n",
      "optimizer time 0.002574 sec\n",
      "training time in round 194 cost 0.4048280715942383 sec\n",
      "loss 2.073451, train acc 0.238381\n",
      "round 195\n",
      "time to device 0.007281 sec\n",
      "time forward 2.387122 sec\n",
      "loss time 0.000535 sec\n",
      "backward time 0.005091 sec\n",
      "optimizer time 0.002496 sec\n",
      "training time in round 195 cost 0.38306617736816406 sec\n",
      "loss 2.069591, train acc 0.239676\n",
      "round 196\n",
      "time to device 0.008698 sec\n",
      "time forward 2.405185 sec\n",
      "loss time 0.001149 sec\n",
      "backward time 0.010309 sec\n",
      "optimizer time 0.003978 sec\n",
      "training time in round 196 cost 0.4015922546386719 sec\n",
      "loss 2.065233, train acc 0.240998\n",
      "round 197\n",
      "time to device 0.007329 sec\n",
      "time forward 2.416519 sec\n",
      "loss time 0.001451 sec\n",
      "backward time 0.010065 sec\n",
      "optimizer time 0.003538 sec\n",
      "training time in round 197 cost 0.3751249313354492 sec\n",
      "loss 2.060818, train acc 0.242306\n",
      "round 198\n",
      "time to device 0.006820 sec\n",
      "time forward 2.427059 sec\n",
      "loss time 0.001008 sec\n",
      "backward time 0.009344 sec\n",
      "optimizer time 0.004227 sec\n",
      "training time in round 198 cost 0.3781919479370117 sec\n",
      "loss 2.056299, train acc 0.244033\n",
      "round 199\n",
      "time to device 0.007253 sec\n",
      "time forward 2.440126 sec\n",
      "loss time 0.001145 sec\n",
      "backward time 0.009976 sec\n",
      "optimizer time 0.004089 sec\n",
      "training time in round 199 cost 0.4121239185333252 sec\n",
      "loss 2.051397, train acc 0.245586\n",
      "round 200\n",
      "time to device 0.006385 sec\n",
      "time forward 2.454743 sec\n",
      "loss time 0.000416 sec\n",
      "backward time 0.004549 sec\n",
      "optimizer time 0.001948 sec\n",
      "training time in round 200 cost 0.3807837963104248 sec\n",
      "loss 2.046944, train acc 0.246891\n",
      "round 201\n",
      "time to device 0.008140 sec\n",
      "time forward 2.464994 sec\n",
      "loss time 0.000554 sec\n",
      "backward time 0.005294 sec\n",
      "optimizer time 0.002609 sec\n",
      "training time in round 201 cost 0.4882359504699707 sec\n",
      "loss 2.043161, train acc 0.248260\n",
      "round 202\n",
      "time to device 0.006589 sec\n",
      "time forward 2.472902 sec\n",
      "loss time 0.000609 sec\n",
      "backward time 0.005637 sec\n",
      "optimizer time 0.003721 sec\n",
      "training time in round 202 cost 0.43831777572631836 sec\n",
      "loss 2.039413, train acc 0.249307\n",
      "round 203\n",
      "time to device 0.006577 sec\n",
      "time forward 2.486182 sec\n",
      "loss time 0.000772 sec\n",
      "backward time 0.006625 sec\n",
      "optimizer time 0.003096 sec\n",
      "training time in round 203 cost 0.3774890899658203 sec\n",
      "loss 2.035149, train acc 0.250728\n",
      "round 204\n",
      "time to device 0.006879 sec\n",
      "time forward 2.500606 sec\n",
      "loss time 0.001046 sec\n",
      "backward time 0.009916 sec\n",
      "optimizer time 0.003577 sec\n",
      "training time in round 204 cost 0.39214229583740234 sec\n",
      "loss 2.030040, train acc 0.252553\n",
      "round 205\n",
      "time to device 0.007022 sec\n",
      "time forward 2.506860 sec\n",
      "loss time 0.000401 sec\n",
      "backward time 0.003909 sec\n",
      "optimizer time 0.001992 sec\n",
      "training time in round 205 cost 0.35042285919189453 sec\n",
      "loss 2.025802, train acc 0.254020\n",
      "round 206\n",
      "time to device 0.006985 sec\n",
      "time forward 2.519013 sec\n",
      "loss time 0.001488 sec\n",
      "backward time 0.011775 sec\n",
      "optimizer time 0.005285 sec\n",
      "training time in round 206 cost 0.39006686210632324 sec\n",
      "loss 2.021923, train acc 0.255208\n",
      "round 207\n",
      "time to device 0.008103 sec\n",
      "time forward 2.534319 sec\n",
      "loss time 0.001102 sec\n",
      "backward time 0.011136 sec\n",
      "optimizer time 0.004402 sec\n",
      "training time in round 207 cost 0.3946378231048584 sec\n",
      "loss 2.018513, train acc 0.256611\n",
      "round 208\n",
      "time to device 0.006976 sec\n",
      "time forward 2.547432 sec\n",
      "loss time 0.000731 sec\n",
      "backward time 0.012344 sec\n",
      "optimizer time 0.003437 sec\n",
      "training time in round 208 cost 0.3974189758300781 sec\n",
      "loss 2.014899, train acc 0.257775\n",
      "round 209\n",
      "time to device 0.007364 sec\n",
      "time forward 2.559363 sec\n",
      "loss time 0.000886 sec\n",
      "backward time 0.006431 sec\n",
      "optimizer time 0.002752 sec\n",
      "training time in round 209 cost 0.4051511287689209 sec\n",
      "loss 2.011101, train acc 0.258817\n",
      "round 210\n",
      "time to device 0.010996 sec\n",
      "time forward 2.575722 sec\n",
      "loss time 0.000923 sec\n",
      "backward time 0.009464 sec\n",
      "optimizer time 0.004182 sec\n",
      "training time in round 210 cost 0.39309000968933105 sec\n",
      "loss 2.007058, train acc 0.260034\n",
      "round 211\n",
      "time to device 0.007295 sec\n",
      "time forward 2.585451 sec\n",
      "loss time 0.000964 sec\n",
      "backward time 0.009185 sec\n",
      "optimizer time 0.003684 sec\n",
      "training time in round 211 cost 0.40387892723083496 sec\n",
      "loss 2.002518, train acc 0.261498\n",
      "round 212\n",
      "time to device 0.005938 sec\n",
      "time forward 2.594936 sec\n",
      "loss time 0.001161 sec\n",
      "backward time 0.012285 sec\n",
      "optimizer time 0.003609 sec\n",
      "training time in round 212 cost 0.37619900703430176 sec\n",
      "loss 1.999175, train acc 0.262471\n",
      "round 213\n",
      "time to device 0.011117 sec\n",
      "time forward 2.607482 sec\n",
      "loss time 0.001427 sec\n",
      "backward time 0.009888 sec\n",
      "optimizer time 0.003822 sec\n",
      "training time in round 213 cost 0.4077928066253662 sec\n",
      "loss 1.996272, train acc 0.263362\n",
      "round 214\n",
      "time to device 0.008415 sec\n",
      "time forward 2.615974 sec\n",
      "loss time 0.000996 sec\n",
      "backward time 0.014255 sec\n",
      "optimizer time 0.004804 sec\n",
      "training time in round 214 cost 0.3853890895843506 sec\n",
      "loss 1.992638, train acc 0.264462\n",
      "round 215\n",
      "time to device 0.009625 sec\n",
      "time forward 2.629281 sec\n",
      "loss time 0.001041 sec\n",
      "backward time 0.010483 sec\n",
      "optimizer time 0.004527 sec\n",
      "training time in round 215 cost 0.4288027286529541 sec\n",
      "loss 1.989211, train acc 0.265734\n",
      "round 216\n",
      "time to device 0.007457 sec\n",
      "time forward 2.639378 sec\n",
      "loss time 0.001621 sec\n",
      "backward time 0.008692 sec\n",
      "optimizer time 0.002602 sec\n",
      "training time in round 216 cost 0.36618804931640625 sec\n",
      "loss 1.985424, train acc 0.267137\n",
      "round 217\n",
      "time to device 0.007765 sec\n",
      "time forward 2.651637 sec\n",
      "loss time 0.001047 sec\n",
      "backward time 0.009875 sec\n",
      "optimizer time 0.004692 sec\n",
      "training time in round 217 cost 0.3915562629699707 sec\n",
      "loss 1.981591, train acc 0.268707\n",
      "round 218\n",
      "time to device 0.007801 sec\n",
      "time forward 2.666408 sec\n",
      "loss time 0.001379 sec\n",
      "backward time 0.010155 sec\n",
      "optimizer time 0.003913 sec\n",
      "training time in round 218 cost 0.3854339122772217 sec\n",
      "loss 1.977736, train acc 0.270334\n",
      "round 219\n",
      "time to device 0.006592 sec\n",
      "time forward 2.679015 sec\n",
      "loss time 0.001485 sec\n",
      "backward time 0.010467 sec\n",
      "optimizer time 0.004013 sec\n",
      "training time in round 219 cost 0.3740060329437256 sec\n",
      "loss 1.973919, train acc 0.271555\n",
      "round 220\n",
      "time to device 0.003329 sec\n",
      "time forward 2.689136 sec\n",
      "loss time 0.001020 sec\n",
      "backward time 0.009244 sec\n",
      "optimizer time 0.003439 sec\n",
      "training time in round 220 cost 0.3604400157928467 sec\n",
      "loss 1.970750, train acc 0.272448\n",
      "round 221\n",
      "time to device 0.003149 sec\n",
      "time forward 2.699306 sec\n",
      "loss time 0.001452 sec\n",
      "backward time 0.010539 sec\n",
      "optimizer time 0.004458 sec\n",
      "training time in round 221 cost 0.3615140914916992 sec\n",
      "loss 1.966798, train acc 0.273789\n",
      "round 222\n",
      "time to device 0.004770 sec\n",
      "time forward 2.713877 sec\n",
      "loss time 0.001403 sec\n",
      "backward time 0.014943 sec\n",
      "optimizer time 0.004829 sec\n",
      "training time in round 222 cost 0.3902151584625244 sec\n",
      "loss 1.963001, train acc 0.275014\n",
      "round 223\n",
      "time to device 0.004036 sec\n",
      "time forward 2.723932 sec\n",
      "loss time 0.001115 sec\n",
      "backward time 0.009724 sec\n",
      "optimizer time 0.003553 sec\n",
      "training time in round 223 cost 0.41532111167907715 sec\n",
      "loss 1.959283, train acc 0.276158\n",
      "round 224\n",
      "time to device 0.007947 sec\n",
      "time forward 2.736322 sec\n",
      "loss time 0.001704 sec\n",
      "backward time 0.015934 sec\n",
      "optimizer time 0.004844 sec\n",
      "training time in round 224 cost 0.3916661739349365 sec\n",
      "loss 1.955588, train acc 0.277326\n",
      "round 225\n",
      "time to device 0.009451 sec\n",
      "time forward 2.746207 sec\n",
      "loss time 0.001070 sec\n",
      "backward time 0.009615 sec\n",
      "optimizer time 0.004836 sec\n",
      "training time in round 225 cost 0.38390684127807617 sec\n",
      "loss 1.952188, train acc 0.278485\n",
      "round 226\n",
      "time to device 0.009079 sec\n",
      "time forward 2.760240 sec\n",
      "loss time 0.001221 sec\n",
      "backward time 0.009628 sec\n",
      "optimizer time 0.004776 sec\n",
      "training time in round 226 cost 0.38745999336242676 sec\n",
      "loss 1.949254, train acc 0.279598\n",
      "round 227\n",
      "time to device 0.007142 sec\n",
      "time forward 2.771340 sec\n",
      "loss time 0.001536 sec\n",
      "backward time 0.010124 sec\n",
      "optimizer time 0.003755 sec\n",
      "training time in round 227 cost 0.3860640525817871 sec\n",
      "loss 1.945591, train acc 0.280976\n",
      "round 228\n",
      "time to device 0.006670 sec\n",
      "time forward 2.783746 sec\n",
      "loss time 0.001172 sec\n",
      "backward time 0.009651 sec\n",
      "optimizer time 0.003442 sec\n",
      "training time in round 228 cost 0.37207603454589844 sec\n",
      "loss 1.942115, train acc 0.282035\n",
      "round 229\n",
      "time to device 0.006515 sec\n",
      "time forward 2.796424 sec\n",
      "loss time 0.000889 sec\n",
      "backward time 0.008896 sec\n",
      "optimizer time 0.003754 sec\n",
      "training time in round 229 cost 0.37389707565307617 sec\n",
      "loss 1.938206, train acc 0.283322\n",
      "round 230\n",
      "time to device 0.007413 sec\n",
      "time forward 2.806570 sec\n",
      "loss time 0.000872 sec\n",
      "backward time 0.007845 sec\n",
      "optimizer time 0.003606 sec\n",
      "training time in round 230 cost 0.40970396995544434 sec\n",
      "loss 1.934770, train acc 0.284361\n",
      "round 231\n",
      "time to device 0.006503 sec\n",
      "time forward 2.820035 sec\n",
      "loss time 0.001559 sec\n",
      "backward time 0.012302 sec\n",
      "optimizer time 0.004220 sec\n",
      "training time in round 231 cost 0.37937402725219727 sec\n",
      "loss 1.931220, train acc 0.285392\n",
      "round 232\n",
      "time to device 0.006733 sec\n",
      "time forward 2.831318 sec\n",
      "loss time 0.001287 sec\n",
      "backward time 0.009386 sec\n",
      "optimizer time 0.004488 sec\n",
      "training time in round 232 cost 0.38224220275878906 sec\n",
      "loss 1.927511, train acc 0.286481\n",
      "round 233\n",
      "time to device 0.008661 sec\n",
      "time forward 2.841620 sec\n",
      "loss time 0.001382 sec\n",
      "backward time 0.008214 sec\n",
      "optimizer time 0.004044 sec\n",
      "training time in round 233 cost 0.38841915130615234 sec\n",
      "loss 1.923374, train acc 0.287827\n",
      "round 234\n",
      "time to device 0.011366 sec\n",
      "time forward 2.852422 sec\n",
      "loss time 0.001916 sec\n",
      "backward time 0.010117 sec\n",
      "optimizer time 0.003951 sec\n",
      "training time in round 234 cost 0.3802978992462158 sec\n",
      "loss 1.920347, train acc 0.289129\n",
      "round 235\n",
      "time to device 0.010979 sec\n",
      "time forward 2.863591 sec\n",
      "loss time 0.001202 sec\n",
      "backward time 0.014456 sec\n",
      "optimizer time 0.002272 sec\n",
      "training time in round 235 cost 0.3893299102783203 sec\n",
      "loss 1.916643, train acc 0.290552\n",
      "round 236\n",
      "time to device 0.006511 sec\n",
      "time forward 2.870899 sec\n",
      "loss time 0.000540 sec\n",
      "backward time 0.005276 sec\n",
      "optimizer time 0.003858 sec\n",
      "training time in round 236 cost 0.4391441345214844 sec\n",
      "loss 1.913147, train acc 0.291601\n",
      "round 237\n",
      "time to device 0.005051 sec\n",
      "time forward 2.885108 sec\n",
      "loss time 0.001089 sec\n",
      "backward time 0.008813 sec\n",
      "optimizer time 0.003635 sec\n",
      "training time in round 237 cost 0.40116405487060547 sec\n",
      "loss 1.909872, train acc 0.292739\n",
      "round 238\n",
      "time to device 0.007193 sec\n",
      "time forward 2.895555 sec\n",
      "loss time 0.000829 sec\n",
      "backward time 0.008811 sec\n",
      "optimizer time 0.003966 sec\n",
      "training time in round 238 cost 0.38312292098999023 sec\n",
      "loss 1.906669, train acc 0.293933\n",
      "round 239\n",
      "time to device 0.007680 sec\n",
      "time forward 2.901934 sec\n",
      "loss time 0.001468 sec\n",
      "backward time 0.004962 sec\n",
      "optimizer time 0.002377 sec\n",
      "training time in round 239 cost 0.3784058094024658 sec\n",
      "loss 1.903678, train acc 0.295052\n",
      "round 240\n",
      "time to device 0.009161 sec\n",
      "time forward 2.914977 sec\n",
      "loss time 0.001233 sec\n",
      "backward time 0.012762 sec\n",
      "optimizer time 0.005015 sec\n",
      "training time in round 240 cost 0.3868541717529297 sec\n",
      "loss 1.900474, train acc 0.296162\n",
      "round 241\n",
      "time to device 0.006817 sec\n",
      "time forward 2.927213 sec\n",
      "loss time 0.001275 sec\n",
      "backward time 0.010122 sec\n",
      "optimizer time 0.004058 sec\n",
      "training time in round 241 cost 0.3784468173980713 sec\n",
      "loss 1.897030, train acc 0.297392\n",
      "round 242\n",
      "time to device 0.007177 sec\n",
      "time forward 2.937745 sec\n",
      "loss time 0.000686 sec\n",
      "backward time 0.012479 sec\n",
      "optimizer time 0.004186 sec\n",
      "training time in round 242 cost 0.38019514083862305 sec\n",
      "loss 1.893837, train acc 0.298579\n",
      "round 243\n",
      "time to device 0.006308 sec\n",
      "time forward 2.949332 sec\n",
      "loss time 0.001380 sec\n",
      "backward time 0.011638 sec\n",
      "optimizer time 0.004605 sec\n",
      "training time in round 243 cost 0.3923149108886719 sec\n",
      "loss 1.890356, train acc 0.299981\n",
      "round 244\n",
      "time to device 0.008356 sec\n",
      "time forward 2.963015 sec\n",
      "loss time 0.001292 sec\n",
      "backward time 0.010326 sec\n",
      "optimizer time 0.003299 sec\n",
      "training time in round 244 cost 0.38944482803344727 sec\n",
      "loss 1.886813, train acc 0.301180\n",
      "round 245\n",
      "time to device 0.006296 sec\n",
      "time forward 2.974838 sec\n",
      "loss time 0.001113 sec\n",
      "backward time 0.009931 sec\n",
      "optimizer time 0.003593 sec\n",
      "training time in round 245 cost 0.40033721923828125 sec\n",
      "loss 1.883309, train acc 0.302369\n",
      "round 246\n",
      "time to device 0.008205 sec\n",
      "time forward 2.989469 sec\n",
      "loss time 0.000924 sec\n",
      "backward time 0.008540 sec\n",
      "optimizer time 0.004400 sec\n",
      "training time in round 246 cost 0.3855712413787842 sec\n",
      "loss 1.880450, train acc 0.303391\n",
      "round 247\n",
      "time to device 0.006088 sec\n",
      "time forward 3.001938 sec\n",
      "loss time 0.001221 sec\n",
      "backward time 0.007162 sec\n",
      "optimizer time 0.002715 sec\n",
      "training time in round 247 cost 0.3999941349029541 sec\n",
      "loss 1.877160, train acc 0.304435\n",
      "round 248\n",
      "time to device 0.008801 sec\n",
      "time forward 3.010737 sec\n",
      "loss time 0.000831 sec\n",
      "backward time 0.006804 sec\n",
      "optimizer time 0.003006 sec\n",
      "training time in round 248 cost 0.409470796585083 sec\n",
      "loss 1.874037, train acc 0.305409\n",
      "round 249\n",
      "time to device 0.010922 sec\n",
      "time forward 3.023453 sec\n",
      "loss time 0.001299 sec\n",
      "backward time 0.011495 sec\n",
      "optimizer time 0.004305 sec\n",
      "training time in round 249 cost 0.3885362148284912 sec\n",
      "loss 1.870406, train acc 0.306844\n",
      "round 250\n",
      "time to device 0.006500 sec\n",
      "time forward 3.034528 sec\n",
      "loss time 0.000440 sec\n",
      "backward time 0.004667 sec\n",
      "optimizer time 0.002272 sec\n",
      "training time in round 250 cost 0.39711833000183105 sec\n",
      "loss 1.867232, train acc 0.308018\n",
      "round 251\n",
      "time to device 0.009289 sec\n",
      "time forward 3.046443 sec\n",
      "loss time 0.001310 sec\n",
      "backward time 0.008295 sec\n",
      "optimizer time 0.002659 sec\n",
      "training time in round 251 cost 0.39093685150146484 sec\n",
      "loss 1.863741, train acc 0.309276\n",
      "round 252\n",
      "time to device 0.007842 sec\n",
      "time forward 3.060818 sec\n",
      "loss time 0.008524 sec\n",
      "backward time 0.012200 sec\n",
      "optimizer time 0.003876 sec\n",
      "training time in round 252 cost 0.4019162654876709 sec\n",
      "loss 1.860412, train acc 0.310369\n",
      "round 253\n",
      "time to device 0.007488 sec\n",
      "time forward 3.073585 sec\n",
      "loss time 0.000810 sec\n",
      "backward time 0.007253 sec\n",
      "optimizer time 0.003425 sec\n",
      "training time in round 253 cost 0.3952608108520508 sec\n",
      "loss 1.856950, train acc 0.311608\n",
      "round 254\n",
      "time to device 0.006863 sec\n",
      "time forward 3.082555 sec\n",
      "loss time 0.000849 sec\n",
      "backward time 0.007194 sec\n",
      "optimizer time 0.003063 sec\n",
      "training time in round 254 cost 0.3842799663543701 sec\n",
      "loss 1.853049, train acc 0.312990\n",
      "round 255\n",
      "time to device 0.009270 sec\n",
      "time forward 3.094570 sec\n",
      "loss time 0.001213 sec\n",
      "backward time 0.009296 sec\n",
      "optimizer time 0.003364 sec\n",
      "training time in round 255 cost 0.3777010440826416 sec\n",
      "loss 1.849594, train acc 0.314423\n",
      "round 256\n",
      "time to device 0.006907 sec\n",
      "time forward 3.105876 sec\n",
      "loss time 0.001394 sec\n",
      "backward time 0.006232 sec\n",
      "optimizer time 0.002242 sec\n",
      "training time in round 256 cost 0.37387895584106445 sec\n",
      "loss 1.846486, train acc 0.315297\n",
      "round 257\n",
      "time to device 0.007568 sec\n",
      "time forward 3.119704 sec\n",
      "loss time 0.001367 sec\n",
      "backward time 0.011192 sec\n",
      "optimizer time 0.004475 sec\n",
      "training time in round 257 cost 0.39542508125305176 sec\n",
      "loss 1.843660, train acc 0.316285\n",
      "round 258\n",
      "time to device 0.007860 sec\n",
      "time forward 3.132086 sec\n",
      "loss time 0.000735 sec\n",
      "backward time 0.006591 sec\n",
      "optimizer time 0.002919 sec\n",
      "training time in round 258 cost 0.38655877113342285 sec\n",
      "loss 1.840871, train acc 0.317175\n",
      "round 259\n",
      "time to device 0.007496 sec\n",
      "time forward 3.141865 sec\n",
      "loss time 0.001370 sec\n",
      "backward time 0.008399 sec\n",
      "optimizer time 0.002527 sec\n",
      "training time in round 259 cost 0.36805033683776855 sec\n",
      "loss 1.838147, train acc 0.318149\n",
      "round 260\n",
      "time to device 0.007520 sec\n",
      "time forward 3.154722 sec\n",
      "loss time 0.001267 sec\n",
      "backward time 0.008432 sec\n",
      "optimizer time 0.002163 sec\n",
      "training time in round 260 cost 0.37917017936706543 sec\n",
      "loss 1.835661, train acc 0.318966\n",
      "round 261\n",
      "time to device 0.006628 sec\n",
      "time forward 3.165910 sec\n",
      "loss time 0.001689 sec\n",
      "backward time 0.012665 sec\n",
      "optimizer time 0.004214 sec\n",
      "training time in round 261 cost 0.3710639476776123 sec\n",
      "loss 1.832655, train acc 0.319895\n",
      "round 262\n",
      "time to device 0.005636 sec\n",
      "time forward 3.176016 sec\n",
      "loss time 0.001072 sec\n",
      "backward time 0.009987 sec\n",
      "optimizer time 0.003918 sec\n",
      "training time in round 262 cost 0.36499667167663574 sec\n",
      "loss 1.829604, train acc 0.320907\n",
      "round 263\n",
      "time to device 0.006967 sec\n",
      "time forward 3.189746 sec\n",
      "loss time 0.001269 sec\n",
      "backward time 0.014784 sec\n",
      "optimizer time 0.003983 sec\n",
      "training time in round 263 cost 0.4030139446258545 sec\n",
      "loss 1.826644, train acc 0.321999\n",
      "round 264\n",
      "time to device 0.009621 sec\n",
      "time forward 3.203202 sec\n",
      "loss time 0.001401 sec\n",
      "backward time 0.012280 sec\n",
      "optimizer time 0.004598 sec\n",
      "training time in round 264 cost 0.4049198627471924 sec\n",
      "loss 1.823580, train acc 0.323143\n",
      "round 265\n",
      "time to device 0.007246 sec\n",
      "time forward 3.214328 sec\n",
      "loss time 0.001981 sec\n",
      "backward time 0.011297 sec\n",
      "optimizer time 0.004586 sec\n",
      "training time in round 265 cost 0.3754711151123047 sec\n",
      "loss 1.820204, train acc 0.324454\n",
      "round 266\n",
      "time to device 0.007176 sec\n",
      "time forward 3.224019 sec\n",
      "loss time 0.001566 sec\n",
      "backward time 0.010280 sec\n",
      "optimizer time 0.003998 sec\n",
      "training time in round 266 cost 0.3621492385864258 sec\n",
      "loss 1.817119, train acc 0.325404\n",
      "round 267\n",
      "time to device 0.008856 sec\n",
      "time forward 3.233042 sec\n",
      "loss time 0.001168 sec\n",
      "backward time 0.008593 sec\n",
      "optimizer time 0.003043 sec\n",
      "training time in round 267 cost 0.3556971549987793 sec\n",
      "loss 1.814277, train acc 0.326609\n",
      "round 268\n",
      "time to device 0.007858 sec\n",
      "time forward 3.248318 sec\n",
      "loss time 0.000451 sec\n",
      "backward time 0.004797 sec\n",
      "optimizer time 0.002121 sec\n",
      "training time in round 268 cost 0.3948509693145752 sec\n",
      "loss 1.810872, train acc 0.327747\n",
      "round 269\n",
      "time to device 0.005775 sec\n",
      "time forward 3.257805 sec\n",
      "loss time 0.000441 sec\n",
      "backward time 0.003828 sec\n",
      "optimizer time 0.001786 sec\n",
      "training time in round 269 cost 0.34708404541015625 sec\n",
      "loss 1.807747, train acc 0.328675\n",
      "round 270\n",
      "time to device 0.007085 sec\n",
      "time forward 3.269297 sec\n",
      "loss time 0.000594 sec\n",
      "backward time 0.005764 sec\n",
      "optimizer time 0.002654 sec\n",
      "training time in round 270 cost 0.4197962284088135 sec\n",
      "loss 1.804610, train acc 0.329768\n",
      "round 271\n",
      "time to device 0.006912 sec\n",
      "time forward 3.276895 sec\n",
      "loss time 0.000460 sec\n",
      "backward time 0.004512 sec\n",
      "optimizer time 0.002834 sec\n",
      "training time in round 271 cost 0.35546398162841797 sec\n",
      "loss 1.801672, train acc 0.330825\n",
      "round 272\n",
      "time to device 0.010520 sec\n",
      "time forward 3.293915 sec\n",
      "loss time 0.001061 sec\n",
      "backward time 0.009370 sec\n",
      "optimizer time 0.003834 sec\n",
      "training time in round 272 cost 0.4102611541748047 sec\n",
      "loss 1.798359, train acc 0.332046\n",
      "round 273\n",
      "time to device 0.009995 sec\n",
      "time forward 3.309216 sec\n",
      "loss time 0.001373 sec\n",
      "backward time 0.011518 sec\n",
      "optimizer time 0.003809 sec\n",
      "training time in round 273 cost 0.3999340534210205 sec\n",
      "loss 1.795384, train acc 0.332944\n",
      "round 274\n",
      "time to device 0.009462 sec\n",
      "time forward 3.318761 sec\n",
      "loss time 0.001074 sec\n",
      "backward time 0.015205 sec\n",
      "optimizer time 0.003351 sec\n",
      "training time in round 274 cost 0.3843541145324707 sec\n",
      "loss 1.792048, train acc 0.334119\n",
      "round 275\n",
      "time to device 0.006802 sec\n",
      "time forward 3.330174 sec\n",
      "loss time 0.000796 sec\n",
      "backward time 0.007824 sec\n",
      "optimizer time 0.003561 sec\n",
      "training time in round 275 cost 0.3921658992767334 sec\n",
      "loss 1.789166, train acc 0.335202\n",
      "round 276\n",
      "time to device 0.006450 sec\n",
      "time forward 3.343492 sec\n",
      "loss time 0.001239 sec\n",
      "backward time 0.014449 sec\n",
      "optimizer time 0.004425 sec\n",
      "training time in round 276 cost 0.3964829444885254 sec\n",
      "loss 1.786036, train acc 0.336304\n",
      "round 277\n",
      "time to device 0.007561 sec\n",
      "time forward 3.352509 sec\n",
      "loss time 0.000888 sec\n",
      "backward time 0.007315 sec\n",
      "optimizer time 0.003063 sec\n",
      "training time in round 277 cost 0.36124491691589355 sec\n",
      "loss 1.784292, train acc 0.336809\n",
      "round 278\n",
      "time to device 0.003885 sec\n",
      "time forward 3.363484 sec\n",
      "loss time 0.001244 sec\n",
      "backward time 0.012433 sec\n",
      "optimizer time 0.004328 sec\n",
      "training time in round 278 cost 0.3706800937652588 sec\n",
      "loss 1.781898, train acc 0.337702\n",
      "round 279\n",
      "time to device 0.003415 sec\n",
      "time forward 3.375028 sec\n",
      "loss time 0.000825 sec\n",
      "backward time 0.007523 sec\n",
      "optimizer time 0.002837 sec\n",
      "training time in round 279 cost 0.3655250072479248 sec\n",
      "loss 1.779230, train acc 0.338644\n",
      "round 280\n",
      "time to device 0.003263 sec\n",
      "time forward 3.385214 sec\n",
      "loss time 0.001293 sec\n",
      "backward time 0.010591 sec\n",
      "optimizer time 0.003679 sec\n",
      "training time in round 280 cost 0.3630821704864502 sec\n",
      "loss 1.776535, train acc 0.339524\n",
      "round 281\n",
      "time to device 0.003288 sec\n",
      "time forward 3.395839 sec\n",
      "loss time 0.000500 sec\n",
      "backward time 0.010280 sec\n",
      "optimizer time 0.002113 sec\n",
      "training time in round 281 cost 0.3776671886444092 sec\n",
      "loss 1.773948, train acc 0.340564\n",
      "round 282\n",
      "time to device 0.004347 sec\n",
      "time forward 3.408411 sec\n",
      "loss time 0.000898 sec\n",
      "backward time 0.008751 sec\n",
      "optimizer time 0.003423 sec\n",
      "training time in round 282 cost 0.4254899024963379 sec\n",
      "loss 1.771450, train acc 0.341459\n",
      "round 283\n",
      "time to device 0.005756 sec\n",
      "time forward 3.421136 sec\n",
      "loss time 0.001900 sec\n",
      "backward time 0.012384 sec\n",
      "optimizer time 0.005380 sec\n",
      "training time in round 283 cost 0.3919820785522461 sec\n",
      "loss 1.768487, train acc 0.342430\n",
      "round 284\n",
      "time to device 0.005243 sec\n",
      "time forward 3.432982 sec\n",
      "loss time 0.001033 sec\n",
      "backward time 0.009407 sec\n",
      "optimizer time 0.003553 sec\n",
      "training time in round 284 cost 0.37583422660827637 sec\n",
      "loss 1.765746, train acc 0.343284\n",
      "round 285\n",
      "time to device 0.009849 sec\n",
      "time forward 3.446627 sec\n",
      "loss time 0.001235 sec\n",
      "backward time 0.009744 sec\n",
      "optimizer time 0.004280 sec\n",
      "training time in round 285 cost 0.3973560333251953 sec\n",
      "loss 1.763079, train acc 0.344296\n",
      "round 286\n",
      "time to device 0.007766 sec\n",
      "time forward 3.453961 sec\n",
      "loss time 0.000521 sec\n",
      "backward time 0.004329 sec\n",
      "optimizer time 0.002395 sec\n",
      "training time in round 286 cost 0.38165926933288574 sec\n",
      "loss 1.760284, train acc 0.345247\n",
      "round 287\n",
      "time to device 0.008200 sec\n",
      "time forward 3.462160 sec\n",
      "loss time 0.000573 sec\n",
      "backward time 0.005291 sec\n",
      "optimizer time 0.002894 sec\n",
      "training time in round 287 cost 0.3679060935974121 sec\n",
      "loss 1.757772, train acc 0.346110\n",
      "round 288\n",
      "time to device 0.007768 sec\n",
      "time forward 3.475038 sec\n",
      "loss time 0.000853 sec\n",
      "backward time 0.006001 sec\n",
      "optimizer time 0.003016 sec\n",
      "training time in round 288 cost 0.3884868621826172 sec\n",
      "loss 1.754847, train acc 0.347237\n",
      "round 289\n",
      "time to device 0.007777 sec\n",
      "time forward 3.489933 sec\n",
      "loss time 0.001304 sec\n",
      "backward time 0.009464 sec\n",
      "optimizer time 0.002592 sec\n",
      "training time in round 289 cost 0.39948010444641113 sec\n",
      "loss 1.751541, train acc 0.348599\n",
      "round 290\n",
      "time to device 0.008218 sec\n",
      "time forward 3.501981 sec\n",
      "loss time 0.000873 sec\n",
      "backward time 0.009866 sec\n",
      "optimizer time 0.004384 sec\n",
      "training time in round 290 cost 0.4253199100494385 sec\n",
      "loss 1.748893, train acc 0.349630\n",
      "round 291\n",
      "time to device 0.006230 sec\n",
      "time forward 3.513528 sec\n",
      "loss time 0.001694 sec\n",
      "backward time 0.011854 sec\n",
      "optimizer time 0.003999 sec\n",
      "training time in round 291 cost 0.3752281665802002 sec\n",
      "loss 1.745905, train acc 0.350680\n",
      "round 292\n",
      "time to device 0.007516 sec\n",
      "time forward 3.523758 sec\n",
      "loss time 0.001319 sec\n",
      "backward time 0.016843 sec\n",
      "optimizer time 0.003669 sec\n",
      "training time in round 292 cost 0.3736410140991211 sec\n",
      "loss 1.743118, train acc 0.351749\n",
      "round 293\n",
      "time to device 0.007587 sec\n",
      "time forward 3.536032 sec\n",
      "loss time 0.001293 sec\n",
      "backward time 0.011021 sec\n",
      "optimizer time 0.004836 sec\n",
      "training time in round 293 cost 0.39398980140686035 sec\n",
      "loss 1.739849, train acc 0.352918\n",
      "round 294\n",
      "time to device 0.007744 sec\n",
      "time forward 3.547797 sec\n",
      "loss time 0.001302 sec\n",
      "backward time 0.011147 sec\n",
      "optimizer time 0.003856 sec\n",
      "training time in round 294 cost 0.37500858306884766 sec\n",
      "loss 1.737327, train acc 0.353708\n",
      "round 295\n",
      "time to device 0.006631 sec\n",
      "time forward 3.559808 sec\n",
      "loss time 0.001422 sec\n",
      "backward time 0.009220 sec\n",
      "optimizer time 0.002781 sec\n",
      "training time in round 295 cost 0.3795320987701416 sec\n",
      "loss 1.734487, train acc 0.354677\n",
      "round 296\n",
      "time to device 0.006354 sec\n",
      "time forward 3.568744 sec\n",
      "loss time 0.001113 sec\n",
      "backward time 0.009064 sec\n",
      "optimizer time 0.003437 sec\n",
      "training time in round 296 cost 0.35327982902526855 sec\n",
      "loss 1.732158, train acc 0.355508\n",
      "round 297\n",
      "time to device 0.005394 sec\n",
      "time forward 3.579732 sec\n",
      "loss time 0.001271 sec\n",
      "backward time 0.012383 sec\n",
      "optimizer time 0.004316 sec\n",
      "training time in round 297 cost 0.3609199523925781 sec\n",
      "loss 1.729151, train acc 0.356517\n",
      "round 298\n",
      "time to device 0.003835 sec\n",
      "time forward 3.591116 sec\n",
      "loss time 0.001532 sec\n",
      "backward time 0.011090 sec\n",
      "optimizer time 0.003734 sec\n",
      "training time in round 298 cost 0.3717989921569824 sec\n",
      "loss 1.725900, train acc 0.357703\n",
      "round 299\n",
      "time to device 0.003901 sec\n",
      "time forward 3.600692 sec\n",
      "loss time 0.001077 sec\n",
      "backward time 0.011593 sec\n",
      "optimizer time 0.003614 sec\n",
      "training time in round 299 cost 0.363422155380249 sec\n",
      "loss 1.722549, train acc 0.359036\n",
      "round 300\n",
      "time to device 0.003742 sec\n",
      "time forward 3.614446 sec\n",
      "loss time 0.001065 sec\n",
      "backward time 0.009832 sec\n",
      "optimizer time 0.003609 sec\n",
      "training time in round 300 cost 0.38251805305480957 sec\n",
      "loss 1.720069, train acc 0.359894\n",
      "round 301\n",
      "time to device 0.002727 sec\n",
      "time forward 3.627125 sec\n",
      "loss time 0.001150 sec\n",
      "backward time 0.009758 sec\n",
      "optimizer time 0.003468 sec\n",
      "training time in round 301 cost 0.36829710006713867 sec\n",
      "loss 1.717678, train acc 0.360798\n",
      "round 302\n",
      "time to device 0.003328 sec\n",
      "time forward 3.634386 sec\n",
      "loss time 0.000593 sec\n",
      "backward time 0.005364 sec\n",
      "optimizer time 0.002321 sec\n",
      "training time in round 302 cost 0.34449172019958496 sec\n",
      "loss 1.715179, train acc 0.361618\n",
      "round 303\n",
      "time to device 0.003450 sec\n",
      "time forward 3.644159 sec\n",
      "loss time 0.001343 sec\n",
      "backward time 0.010816 sec\n",
      "optimizer time 0.003638 sec\n",
      "training time in round 303 cost 0.35699987411499023 sec\n",
      "loss 1.712689, train acc 0.362613\n",
      "round 304\n",
      "time to device 0.004217 sec\n",
      "time forward 3.654584 sec\n",
      "loss time 0.001326 sec\n",
      "backward time 0.012116 sec\n",
      "optimizer time 0.003559 sec\n",
      "training time in round 304 cost 0.36798930168151855 sec\n",
      "loss 1.710355, train acc 0.363448\n",
      "round 305\n",
      "time to device 0.007042 sec\n",
      "time forward 3.665722 sec\n",
      "loss time 0.001281 sec\n",
      "backward time 0.010008 sec\n",
      "optimizer time 0.003614 sec\n",
      "training time in round 305 cost 0.3826577663421631 sec\n",
      "loss 1.708228, train acc 0.364354\n",
      "round 306\n",
      "time to device 0.003507 sec\n",
      "time forward 3.677261 sec\n",
      "loss time 0.000710 sec\n",
      "backward time 0.013331 sec\n",
      "optimizer time 0.002693 sec\n",
      "training time in round 306 cost 0.3915562629699707 sec\n",
      "loss 1.705711, train acc 0.365253\n",
      "round 307\n",
      "time to device 0.003842 sec\n",
      "time forward 3.689445 sec\n",
      "loss time 0.000434 sec\n",
      "backward time 0.004562 sec\n",
      "optimizer time 0.002025 sec\n",
      "training time in round 307 cost 0.39136290550231934 sec\n",
      "loss 1.703306, train acc 0.365970\n",
      "round 308\n",
      "time to device 0.003512 sec\n",
      "time forward 3.702764 sec\n",
      "loss time 0.000447 sec\n",
      "backward time 0.004035 sec\n",
      "optimizer time 0.002028 sec\n",
      "training time in round 308 cost 0.4056549072265625 sec\n",
      "loss 1.701001, train acc 0.366682\n",
      "round 309\n",
      "time to device 0.006552 sec\n",
      "time forward 3.715228 sec\n",
      "loss time 0.001079 sec\n",
      "backward time 0.007293 sec\n",
      "optimizer time 0.004016 sec\n",
      "training time in round 309 cost 0.39504218101501465 sec\n",
      "loss 1.698809, train acc 0.367414\n",
      "round 310\n",
      "time to device 0.003164 sec\n",
      "time forward 3.722381 sec\n",
      "loss time 0.000719 sec\n",
      "backward time 0.006658 sec\n",
      "optimizer time 0.002500 sec\n",
      "training time in round 310 cost 0.3506450653076172 sec\n",
      "loss 1.695805, train acc 0.368494\n",
      "round 311\n",
      "time to device 0.003502 sec\n",
      "time forward 3.732797 sec\n",
      "loss time 0.001440 sec\n",
      "backward time 0.012435 sec\n",
      "optimizer time 0.004707 sec\n",
      "training time in round 311 cost 0.3704335689544678 sec\n",
      "loss 1.693578, train acc 0.369466\n",
      "round 312\n",
      "time to device 0.003507 sec\n",
      "time forward 3.742242 sec\n",
      "loss time 0.001072 sec\n",
      "backward time 0.010776 sec\n",
      "optimizer time 0.004709 sec\n",
      "training time in round 312 cost 0.3666858673095703 sec\n",
      "loss 1.690952, train acc 0.370283\n",
      "round 313\n",
      "time to device 0.003886 sec\n",
      "time forward 3.757123 sec\n",
      "loss time 0.000800 sec\n",
      "backward time 0.007805 sec\n",
      "optimizer time 0.003299 sec\n",
      "training time in round 313 cost 0.3815162181854248 sec\n",
      "loss 1.688636, train acc 0.371069\n",
      "round 314\n",
      "time to device 0.003374 sec\n",
      "time forward 3.768935 sec\n",
      "loss time 0.001071 sec\n",
      "backward time 0.010699 sec\n",
      "optimizer time 0.004113 sec\n",
      "training time in round 314 cost 0.3793048858642578 sec\n",
      "loss 1.686403, train acc 0.371801\n",
      "round 315\n",
      "time to device 0.003882 sec\n",
      "time forward 3.780738 sec\n",
      "loss time 0.000854 sec\n",
      "backward time 0.008172 sec\n",
      "optimizer time 0.004138 sec\n",
      "training time in round 315 cost 0.41640329360961914 sec\n",
      "loss 1.683286, train acc 0.372874\n",
      "round 316\n",
      "time to device 0.006947 sec\n",
      "time forward 3.792669 sec\n",
      "loss time 0.001078 sec\n",
      "backward time 0.011966 sec\n",
      "optimizer time 0.003674 sec\n",
      "training time in round 316 cost 0.3729979991912842 sec\n",
      "loss 1.680535, train acc 0.374039\n",
      "round 317\n",
      "time to device 0.007429 sec\n",
      "time forward 3.804617 sec\n",
      "loss time 0.001290 sec\n",
      "backward time 0.010643 sec\n",
      "optimizer time 0.003595 sec\n",
      "training time in round 317 cost 0.38909006118774414 sec\n",
      "loss 1.678339, train acc 0.374754\n",
      "round 318\n",
      "time to device 0.007058 sec\n",
      "time forward 3.816722 sec\n",
      "loss time 0.001596 sec\n",
      "backward time 0.011078 sec\n",
      "optimizer time 0.004911 sec\n",
      "training time in round 318 cost 0.38281798362731934 sec\n",
      "loss 1.675949, train acc 0.375563\n",
      "round 319\n",
      "time to device 0.003880 sec\n",
      "time forward 3.827437 sec\n",
      "loss time 0.001561 sec\n",
      "backward time 0.013725 sec\n",
      "optimizer time 0.003787 sec\n",
      "training time in round 319 cost 0.36930418014526367 sec\n",
      "loss 1.673617, train acc 0.376367\n",
      "round 320\n",
      "time to device 0.006735 sec\n",
      "time forward 3.838695 sec\n",
      "loss time 0.001011 sec\n",
      "backward time 0.010219 sec\n",
      "optimizer time 0.003820 sec\n",
      "training time in round 320 cost 0.38144397735595703 sec\n",
      "loss 1.671506, train acc 0.377166\n",
      "round 321\n",
      "time to device 0.004599 sec\n",
      "time forward 3.850352 sec\n",
      "loss time 0.001027 sec\n",
      "backward time 0.009757 sec\n",
      "optimizer time 0.003487 sec\n",
      "training time in round 321 cost 0.36722683906555176 sec\n",
      "loss 1.668856, train acc 0.378106\n",
      "round 322\n",
      "time to device 0.003232 sec\n",
      "time forward 3.864542 sec\n",
      "loss time 0.001288 sec\n",
      "backward time 0.010114 sec\n",
      "optimizer time 0.003624 sec\n",
      "training time in round 322 cost 0.3745448589324951 sec\n",
      "loss 1.666451, train acc 0.379063\n",
      "round 323\n",
      "time to device 0.004154 sec\n",
      "time forward 3.875585 sec\n",
      "loss time 0.001316 sec\n",
      "backward time 0.011769 sec\n",
      "optimizer time 0.004851 sec\n",
      "training time in round 323 cost 0.38476085662841797 sec\n",
      "loss 1.664514, train acc 0.379702\n",
      "round 324\n",
      "time to device 0.006694 sec\n",
      "time forward 3.889601 sec\n",
      "loss time 0.000759 sec\n",
      "backward time 0.007672 sec\n",
      "optimizer time 0.003355 sec\n",
      "training time in round 324 cost 0.3896801471710205 sec\n",
      "loss 1.662490, train acc 0.380481\n",
      "round 325\n",
      "time to device 0.007258 sec\n",
      "time forward 3.900906 sec\n",
      "loss time 0.001249 sec\n",
      "backward time 0.007695 sec\n",
      "optimizer time 0.004274 sec\n",
      "training time in round 325 cost 0.372438907623291 sec\n",
      "loss 1.660419, train acc 0.381207\n",
      "round 326\n",
      "time to device 0.007629 sec\n",
      "time forward 3.912146 sec\n",
      "loss time 0.001803 sec\n",
      "backward time 0.017610 sec\n",
      "optimizer time 0.004102 sec\n",
      "training time in round 326 cost 0.3838229179382324 sec\n",
      "loss 1.658836, train acc 0.381833\n",
      "round 327\n",
      "time to device 0.007201 sec\n",
      "time forward 3.922846 sec\n",
      "loss time 0.001144 sec\n",
      "backward time 0.010958 sec\n",
      "optimizer time 0.005137 sec\n",
      "training time in round 327 cost 0.3808908462524414 sec\n",
      "loss 1.656653, train acc 0.382384\n",
      "round 328\n",
      "time to device 0.004664 sec\n",
      "time forward 3.935759 sec\n",
      "loss time 0.001430 sec\n",
      "backward time 0.009988 sec\n",
      "optimizer time 0.002080 sec\n",
      "training time in round 328 cost 0.39212608337402344 sec\n",
      "loss 1.654436, train acc 0.383026\n",
      "round 329\n",
      "time to device 0.007249 sec\n",
      "time forward 3.947910 sec\n",
      "loss time 0.001750 sec\n",
      "backward time 0.013139 sec\n",
      "optimizer time 0.004416 sec\n",
      "training time in round 329 cost 0.3799469470977783 sec\n",
      "loss 1.652400, train acc 0.383688\n",
      "round 330\n",
      "time to device 0.006818 sec\n",
      "time forward 3.960456 sec\n",
      "loss time 0.001859 sec\n",
      "backward time 0.014794 sec\n",
      "optimizer time 0.004503 sec\n",
      "training time in round 330 cost 0.38445091247558594 sec\n",
      "loss 1.650131, train acc 0.384488\n",
      "round 331\n",
      "time to device 0.003276 sec\n",
      "time forward 3.971250 sec\n",
      "loss time 0.001312 sec\n",
      "backward time 0.010956 sec\n",
      "optimizer time 0.003726 sec\n",
      "training time in round 331 cost 0.3633542060852051 sec\n",
      "loss 1.647798, train acc 0.385260\n",
      "round 332\n",
      "time to device 0.005898 sec\n",
      "time forward 3.981333 sec\n",
      "loss time 0.000849 sec\n",
      "backward time 0.006973 sec\n",
      "optimizer time 0.003100 sec\n",
      "training time in round 332 cost 0.40738511085510254 sec\n",
      "loss 1.645917, train acc 0.386027\n",
      "round 333\n",
      "time to device 0.006871 sec\n",
      "time forward 3.991720 sec\n",
      "loss time 0.000933 sec\n",
      "backward time 0.009326 sec\n",
      "optimizer time 0.002685 sec\n",
      "training time in round 333 cost 0.3925449848175049 sec\n",
      "loss 1.643730, train acc 0.386695\n",
      "round 334\n",
      "time to device 0.006351 sec\n",
      "time forward 3.998006 sec\n",
      "loss time 0.000498 sec\n",
      "backward time 0.007890 sec\n",
      "optimizer time 0.003402 sec\n",
      "training time in round 334 cost 0.38309693336486816 sec\n",
      "loss 1.641616, train acc 0.387523\n",
      "round 335\n",
      "time to device 0.009351 sec\n",
      "time forward 4.009290 sec\n",
      "loss time 0.000478 sec\n",
      "backward time 0.006710 sec\n",
      "optimizer time 0.002282 sec\n",
      "training time in round 335 cost 0.4019639492034912 sec\n",
      "loss 1.639430, train acc 0.388323\n",
      "round 336\n",
      "time to device 0.009016 sec\n",
      "time forward 4.020320 sec\n",
      "loss time 0.000737 sec\n",
      "backward time 0.006519 sec\n",
      "optimizer time 0.003410 sec\n",
      "training time in round 336 cost 0.42340588569641113 sec\n",
      "loss 1.637055, train acc 0.389188\n",
      "round 337\n",
      "time to device 0.006964 sec\n",
      "time forward 4.031258 sec\n",
      "loss time 0.001234 sec\n",
      "backward time 0.010726 sec\n",
      "optimizer time 0.004099 sec\n",
      "training time in round 337 cost 0.37584900856018066 sec\n",
      "loss 1.634815, train acc 0.390047\n",
      "round 338\n",
      "time to device 0.007076 sec\n",
      "time forward 4.044404 sec\n",
      "loss time 0.001259 sec\n",
      "backward time 0.012871 sec\n",
      "optimizer time 0.003298 sec\n",
      "training time in round 338 cost 0.39516592025756836 sec\n",
      "loss 1.632534, train acc 0.390832\n",
      "round 339\n",
      "time to device 0.006671 sec\n",
      "time forward 4.059518 sec\n",
      "loss time 0.000908 sec\n",
      "backward time 0.008238 sec\n",
      "optimizer time 0.003691 sec\n",
      "training time in round 339 cost 0.39268922805786133 sec\n",
      "loss 1.630664, train acc 0.391567\n",
      "round 340\n",
      "time to device 0.007435 sec\n",
      "time forward 4.072167 sec\n",
      "loss time 0.001333 sec\n",
      "backward time 0.011610 sec\n",
      "optimizer time 0.004529 sec\n",
      "training time in round 340 cost 0.3906419277191162 sec\n",
      "loss 1.628671, train acc 0.392206\n",
      "round 341\n",
      "time to device 0.005685 sec\n",
      "time forward 4.080925 sec\n",
      "loss time 0.000448 sec\n",
      "backward time 0.004326 sec\n",
      "optimizer time 0.002315 sec\n",
      "training time in round 341 cost 0.34717702865600586 sec\n",
      "loss 1.626388, train acc 0.392955\n",
      "round 342\n",
      "time to device 0.006885 sec\n",
      "time forward 4.092683 sec\n",
      "loss time 0.001388 sec\n",
      "backward time 0.010838 sec\n",
      "optimizer time 0.002032 sec\n",
      "training time in round 342 cost 0.37505316734313965 sec\n",
      "loss 1.624269, train acc 0.393677\n",
      "round 343\n",
      "time to device 0.010395 sec\n",
      "time forward 4.104346 sec\n",
      "loss time 0.000492 sec\n",
      "backward time 0.004198 sec\n",
      "optimizer time 0.002122 sec\n",
      "training time in round 343 cost 0.38722896575927734 sec\n",
      "loss 1.622002, train acc 0.394509\n",
      "round 344\n",
      "time to device 0.005644 sec\n",
      "time forward 4.111957 sec\n",
      "loss time 0.001085 sec\n",
      "backward time 0.009981 sec\n",
      "optimizer time 0.003949 sec\n",
      "training time in round 344 cost 0.35204267501831055 sec\n",
      "loss 1.619747, train acc 0.395313\n",
      "round 345\n",
      "time to device 0.005979 sec\n",
      "time forward 4.124506 sec\n",
      "loss time 0.000456 sec\n",
      "backward time 0.004160 sec\n",
      "optimizer time 0.002025 sec\n",
      "training time in round 345 cost 0.4059760570526123 sec\n",
      "loss 1.617327, train acc 0.396134\n",
      "round 346\n",
      "time to device 0.007426 sec\n",
      "time forward 4.133339 sec\n",
      "loss time 0.001286 sec\n",
      "backward time 0.009791 sec\n",
      "optimizer time 0.003930 sec\n",
      "training time in round 346 cost 0.36461710929870605 sec\n",
      "loss 1.614992, train acc 0.396997\n",
      "round 347\n",
      "time to device 0.004743 sec\n",
      "time forward 4.141575 sec\n",
      "loss time 0.001090 sec\n",
      "backward time 0.009366 sec\n",
      "optimizer time 0.003855 sec\n",
      "training time in round 347 cost 0.358349084854126 sec\n",
      "loss 1.613076, train acc 0.397831\n",
      "round 348\n",
      "time to device 0.009164 sec\n",
      "time forward 4.147435 sec\n",
      "loss time 0.000578 sec\n",
      "backward time 0.004170 sec\n",
      "optimizer time 0.002002 sec\n",
      "training time in round 348 cost 0.3540689945220947 sec\n",
      "loss 1.611214, train acc 0.398572\n",
      "round 349\n",
      "time to device 0.006652 sec\n",
      "time forward 4.157723 sec\n",
      "loss time 0.000455 sec\n",
      "backward time 0.003912 sec\n",
      "optimizer time 0.001682 sec\n",
      "training time in round 349 cost 0.36809611320495605 sec\n",
      "loss 1.609470, train acc 0.399107\n",
      "round 350\n",
      "time to device 0.008432 sec\n",
      "time forward 4.167318 sec\n",
      "loss time 0.000732 sec\n",
      "backward time 0.006498 sec\n",
      "optimizer time 0.003506 sec\n",
      "training time in round 350 cost 0.3655052185058594 sec\n",
      "loss 1.607566, train acc 0.399817\n",
      "round 351\n",
      "time to device 0.003376 sec\n",
      "time forward 4.179361 sec\n",
      "loss time 0.000562 sec\n",
      "backward time 0.007550 sec\n",
      "optimizer time 0.002754 sec\n",
      "training time in round 351 cost 0.3932931423187256 sec\n",
      "loss 1.605724, train acc 0.400568\n",
      "round 352\n",
      "time to device 0.006343 sec\n",
      "time forward 4.190645 sec\n",
      "loss time 0.001093 sec\n",
      "backward time 0.007676 sec\n",
      "optimizer time 0.003251 sec\n",
      "training time in round 352 cost 0.3698101043701172 sec\n",
      "loss 1.603920, train acc 0.401248\n",
      "round 353\n",
      "time to device 0.007053 sec\n",
      "time forward 4.202926 sec\n",
      "loss time 0.001197 sec\n",
      "backward time 0.009588 sec\n",
      "optimizer time 0.003223 sec\n",
      "training time in round 353 cost 0.41770195960998535 sec\n",
      "loss 1.601527, train acc 0.402145\n",
      "round 354\n",
      "time to device 0.010942 sec\n",
      "time forward 4.216326 sec\n",
      "loss time 0.000774 sec\n",
      "backward time 0.007357 sec\n",
      "optimizer time 0.004775 sec\n",
      "training time in round 354 cost 0.40233683586120605 sec\n",
      "loss 1.599888, train acc 0.402795\n",
      "round 355\n",
      "time to device 0.003465 sec\n",
      "time forward 4.223968 sec\n",
      "loss time 0.000668 sec\n",
      "backward time 0.004806 sec\n",
      "optimizer time 0.003171 sec\n",
      "training time in round 355 cost 0.3843870162963867 sec\n",
      "loss 1.597603, train acc 0.403551\n",
      "round 356\n",
      "time to device 0.004142 sec\n",
      "time forward 4.237143 sec\n",
      "loss time 0.001321 sec\n",
      "backward time 0.013014 sec\n",
      "optimizer time 0.004892 sec\n",
      "training time in round 356 cost 0.3868749141693115 sec\n",
      "loss 1.595473, train acc 0.404302\n",
      "round 357\n",
      "time to device 0.003516 sec\n",
      "time forward 4.247166 sec\n",
      "loss time 0.001506 sec\n",
      "backward time 0.011600 sec\n",
      "optimizer time 0.004327 sec\n",
      "training time in round 357 cost 0.3666350841522217 sec\n",
      "loss 1.593018, train acc 0.405115\n",
      "round 358\n",
      "time to device 0.002943 sec\n",
      "time forward 4.259816 sec\n",
      "loss time 0.000764 sec\n",
      "backward time 0.007040 sec\n",
      "optimizer time 0.002358 sec\n",
      "training time in round 358 cost 0.4076201915740967 sec\n",
      "loss 1.591130, train acc 0.405728\n",
      "round 359\n",
      "time to device 0.004709 sec\n",
      "time forward 4.271405 sec\n",
      "loss time 0.000906 sec\n",
      "backward time 0.007698 sec\n",
      "optimizer time 0.003663 sec\n",
      "training time in round 359 cost 0.40905022621154785 sec\n",
      "loss 1.589546, train acc 0.406293\n",
      "round 360\n",
      "time to device 0.007524 sec\n",
      "time forward 4.282888 sec\n",
      "loss time 0.001126 sec\n",
      "backward time 0.009142 sec\n",
      "optimizer time 0.003070 sec\n",
      "training time in round 360 cost 0.3793349266052246 sec\n",
      "loss 1.587953, train acc 0.406986\n",
      "round 361\n",
      "time to device 0.008682 sec\n",
      "time forward 4.295577 sec\n",
      "loss time 0.000589 sec\n",
      "backward time 0.005638 sec\n",
      "optimizer time 0.006096 sec\n",
      "training time in round 361 cost 0.39101099967956543 sec\n",
      "loss 1.585960, train acc 0.407890\n",
      "round 362\n",
      "time to device 0.010010 sec\n",
      "time forward 4.306501 sec\n",
      "loss time 0.000952 sec\n",
      "backward time 0.009393 sec\n",
      "optimizer time 0.003706 sec\n",
      "training time in round 362 cost 0.3760209083557129 sec\n",
      "loss 1.584085, train acc 0.408596\n",
      "round 363\n",
      "time to device 0.006609 sec\n",
      "time forward 4.317876 sec\n",
      "loss time 0.001861 sec\n",
      "backward time 0.014704 sec\n",
      "optimizer time 0.005094 sec\n",
      "training time in round 363 cost 0.38796091079711914 sec\n",
      "loss 1.582226, train acc 0.409534\n",
      "round 364\n",
      "time to device 0.009242 sec\n",
      "time forward 4.329649 sec\n",
      "loss time 0.001577 sec\n",
      "backward time 0.010320 sec\n",
      "optimizer time 0.004207 sec\n",
      "training time in round 364 cost 0.40871286392211914 sec\n",
      "loss 1.580444, train acc 0.410103\n",
      "round 365\n",
      "time to device 0.006593 sec\n",
      "time forward 4.340489 sec\n",
      "loss time 0.001028 sec\n",
      "backward time 0.006807 sec\n",
      "optimizer time 0.004032 sec\n",
      "training time in round 365 cost 0.3719968795776367 sec\n",
      "loss 1.578487, train acc 0.410754\n",
      "round 366\n",
      "time to device 0.008463 sec\n",
      "time forward 4.351771 sec\n",
      "loss time 0.000504 sec\n",
      "backward time 0.010073 sec\n",
      "optimizer time 0.003271 sec\n",
      "training time in round 366 cost 0.385404109954834 sec\n",
      "loss 1.576814, train acc 0.411487\n",
      "round 367\n",
      "time to device 0.007928 sec\n",
      "time forward 4.364846 sec\n",
      "loss time 0.001674 sec\n",
      "backward time 0.008491 sec\n",
      "optimizer time 0.003120 sec\n",
      "training time in round 367 cost 0.3962748050689697 sec\n",
      "loss 1.574941, train acc 0.412152\n",
      "round 368\n",
      "time to device 0.007142 sec\n",
      "time forward 4.376413 sec\n",
      "loss time 0.001591 sec\n",
      "backward time 0.009478 sec\n",
      "optimizer time 0.002521 sec\n",
      "training time in round 368 cost 0.4011821746826172 sec\n",
      "loss 1.573269, train acc 0.412835\n",
      "round 369\n",
      "time to device 0.008156 sec\n",
      "time forward 4.383629 sec\n",
      "loss time 0.001110 sec\n",
      "backward time 0.005510 sec\n",
      "optimizer time 0.002462 sec\n",
      "training time in round 369 cost 0.38088297843933105 sec\n",
      "loss 1.571281, train acc 0.413682\n",
      "round 370\n",
      "time to device 0.006664 sec\n",
      "time forward 4.395591 sec\n",
      "loss time 0.001242 sec\n",
      "backward time 0.010794 sec\n",
      "optimizer time 0.004063 sec\n",
      "training time in round 370 cost 0.38187289237976074 sec\n",
      "loss 1.569493, train acc 0.414273\n",
      "round 371\n",
      "time to device 0.008799 sec\n",
      "time forward 4.409275 sec\n",
      "loss time 0.001495 sec\n",
      "backward time 0.005726 sec\n",
      "optimizer time 0.003168 sec\n",
      "training time in round 371 cost 0.3994152545928955 sec\n",
      "loss 1.568223, train acc 0.414861\n",
      "round 372\n",
      "time to device 0.006467 sec\n",
      "time forward 4.416775 sec\n",
      "loss time 0.000513 sec\n",
      "backward time 0.005502 sec\n",
      "optimizer time 0.004632 sec\n",
      "training time in round 372 cost 0.39050960540771484 sec\n",
      "loss 1.566285, train acc 0.415675\n",
      "round 373\n",
      "time to device 0.007453 sec\n",
      "time forward 4.427806 sec\n",
      "loss time 0.001361 sec\n",
      "backward time 0.009419 sec\n",
      "optimizer time 0.002741 sec\n",
      "training time in round 373 cost 0.37334394454956055 sec\n",
      "loss 1.564139, train acc 0.416486\n",
      "round 374\n",
      "time to device 0.008329 sec\n",
      "time forward 4.438646 sec\n",
      "loss time 0.001528 sec\n",
      "backward time 0.010910 sec\n",
      "optimizer time 0.003125 sec\n",
      "training time in round 374 cost 0.38527917861938477 sec\n",
      "loss 1.561902, train acc 0.417271\n",
      "round 375\n",
      "time to device 0.008852 sec\n",
      "time forward 4.451859 sec\n",
      "loss time 0.001372 sec\n",
      "backward time 0.020286 sec\n",
      "optimizer time 0.003592 sec\n",
      "training time in round 375 cost 0.4084491729736328 sec\n",
      "loss 1.559762, train acc 0.418156\n",
      "round 376\n",
      "time to device 0.006776 sec\n",
      "time forward 4.465168 sec\n",
      "loss time 0.000449 sec\n",
      "backward time 0.004248 sec\n",
      "optimizer time 0.002024 sec\n",
      "training time in round 376 cost 0.4090280532836914 sec\n",
      "loss 1.557631, train acc 0.418995\n",
      "round 377\n",
      "time to device 0.006194 sec\n",
      "time forward 4.475459 sec\n",
      "loss time 0.000598 sec\n",
      "backward time 0.007867 sec\n",
      "optimizer time 0.002449 sec\n",
      "training time in round 377 cost 0.3917503356933594 sec\n",
      "loss 1.555786, train acc 0.419808\n",
      "round 378\n",
      "time to device 0.006765 sec\n",
      "time forward 4.490417 sec\n",
      "loss time 0.000613 sec\n",
      "backward time 0.006470 sec\n",
      "optimizer time 0.002562 sec\n",
      "training time in round 378 cost 0.4183940887451172 sec\n",
      "loss 1.554028, train acc 0.420453\n",
      "round 379\n",
      "time to device 0.007359 sec\n",
      "time forward 4.503528 sec\n",
      "loss time 0.000803 sec\n",
      "backward time 0.007487 sec\n",
      "optimizer time 0.003095 sec\n",
      "training time in round 379 cost 0.41374802589416504 sec\n",
      "loss 1.552045, train acc 0.421053\n",
      "round 380\n",
      "time to device 0.006862 sec\n",
      "time forward 4.513140 sec\n",
      "loss time 0.001259 sec\n",
      "backward time 0.007556 sec\n",
      "optimizer time 0.003840 sec\n",
      "training time in round 380 cost 0.364948034286499 sec\n",
      "loss 1.549838, train acc 0.421813\n",
      "round 381\n",
      "time to device 0.007019 sec\n",
      "time forward 4.520501 sec\n",
      "loss time 0.000855 sec\n",
      "backward time 0.005446 sec\n",
      "optimizer time 0.004514 sec\n",
      "training time in round 381 cost 0.38605308532714844 sec\n",
      "loss 1.547792, train acc 0.422673\n",
      "round 382\n",
      "time to device 0.007335 sec\n",
      "time forward 4.534397 sec\n",
      "loss time 0.001313 sec\n",
      "backward time 0.006136 sec\n",
      "optimizer time 0.003341 sec\n",
      "training time in round 382 cost 0.398104190826416 sec\n",
      "loss 1.545891, train acc 0.423384\n",
      "round 383\n",
      "time to device 0.008051 sec\n",
      "time forward 4.546823 sec\n",
      "loss time 0.001774 sec\n",
      "backward time 0.012503 sec\n",
      "optimizer time 0.005477 sec\n",
      "training time in round 383 cost 0.39627504348754883 sec\n",
      "loss 1.543923, train acc 0.424093\n",
      "round 384\n",
      "time to device 0.008792 sec\n",
      "time forward 4.556957 sec\n",
      "loss time 0.001107 sec\n",
      "backward time 0.010644 sec\n",
      "optimizer time 0.003815 sec\n",
      "training time in round 384 cost 0.3714938163757324 sec\n",
      "loss 1.541980, train acc 0.424817\n",
      "round 385\n",
      "time to device 0.007346 sec\n",
      "time forward 4.565720 sec\n",
      "loss time 0.000891 sec\n",
      "backward time 0.007667 sec\n",
      "optimizer time 0.003010 sec\n",
      "training time in round 385 cost 0.36115503311157227 sec\n",
      "loss 1.539770, train acc 0.425721\n",
      "round 386\n",
      "time to device 0.006560 sec\n",
      "time forward 4.575590 sec\n",
      "loss time 0.001313 sec\n",
      "backward time 0.016510 sec\n",
      "optimizer time 0.003768 sec\n",
      "training time in round 386 cost 0.3675518035888672 sec\n",
      "loss 1.538389, train acc 0.426235\n",
      "round 387\n",
      "time to device 0.007172 sec\n",
      "time forward 4.584319 sec\n",
      "loss time 0.001344 sec\n",
      "backward time 0.010277 sec\n",
      "optimizer time 0.003514 sec\n",
      "training time in round 387 cost 0.3562278747558594 sec\n",
      "loss 1.536240, train acc 0.426989\n",
      "round 388\n",
      "time to device 0.006175 sec\n",
      "time forward 4.594026 sec\n",
      "loss time 0.001438 sec\n",
      "backward time 0.009566 sec\n",
      "optimizer time 0.003888 sec\n",
      "training time in round 388 cost 0.36899781227111816 sec\n",
      "loss 1.534053, train acc 0.427900\n",
      "round 389\n",
      "time to device 0.006328 sec\n",
      "time forward 4.605563 sec\n",
      "loss time 0.001264 sec\n",
      "backward time 0.009806 sec\n",
      "optimizer time 0.003512 sec\n",
      "training time in round 389 cost 0.37560200691223145 sec\n",
      "loss 1.532217, train acc 0.428546\n",
      "round 390\n",
      "time to device 0.003830 sec\n",
      "time forward 4.616508 sec\n",
      "loss time 0.001058 sec\n",
      "backward time 0.009643 sec\n",
      "optimizer time 0.003475 sec\n",
      "training time in round 390 cost 0.376662015914917 sec\n",
      "loss 1.530409, train acc 0.429168\n",
      "round 391\n",
      "time to device 0.004674 sec\n",
      "time forward 4.626937 sec\n",
      "loss time 0.001077 sec\n",
      "backward time 0.009965 sec\n",
      "optimizer time 0.003532 sec\n",
      "training time in round 391 cost 0.3623521327972412 sec\n",
      "loss 1.528538, train acc 0.429867\n",
      "round 392\n",
      "time to device 0.005543 sec\n",
      "time forward 4.639406 sec\n",
      "loss time 0.001771 sec\n",
      "backward time 0.011701 sec\n",
      "optimizer time 0.003875 sec\n",
      "training time in round 392 cost 0.3788478374481201 sec\n",
      "loss 1.527043, train acc 0.430403\n",
      "round 393\n",
      "time to device 0.002807 sec\n",
      "time forward 4.649294 sec\n",
      "loss time 0.001313 sec\n",
      "backward time 0.010647 sec\n",
      "optimizer time 0.003520 sec\n",
      "training time in round 393 cost 0.36234402656555176 sec\n",
      "loss 1.525547, train acc 0.430917\n",
      "round 394\n",
      "time to device 0.003853 sec\n",
      "time forward 4.658271 sec\n",
      "loss time 0.000740 sec\n",
      "backward time 0.007158 sec\n",
      "optimizer time 0.002909 sec\n",
      "training time in round 394 cost 0.35649895668029785 sec\n",
      "loss 1.523683, train acc 0.431646\n",
      "round 395\n",
      "time to device 0.003580 sec\n",
      "time forward 4.670084 sec\n",
      "loss time 0.000658 sec\n",
      "backward time 0.005646 sec\n",
      "optimizer time 0.002577 sec\n",
      "training time in round 395 cost 0.36383986473083496 sec\n",
      "loss 1.521915, train acc 0.432311\n",
      "round 396\n",
      "time to device 0.004610 sec\n",
      "time forward 4.681493 sec\n",
      "loss time 0.001337 sec\n",
      "backward time 0.010698 sec\n",
      "optimizer time 0.003606 sec\n",
      "training time in round 396 cost 0.3730278015136719 sec\n",
      "loss 1.520101, train acc 0.433013\n",
      "round 397\n",
      "time to device 0.002999 sec\n",
      "time forward 4.694506 sec\n",
      "loss time 0.001470 sec\n",
      "backward time 0.010419 sec\n",
      "optimizer time 0.001885 sec\n",
      "training time in round 397 cost 0.3849489688873291 sec\n",
      "loss 1.518209, train acc 0.433613\n",
      "round 398\n",
      "time to device 0.003605 sec\n",
      "time forward 4.705844 sec\n",
      "loss time 0.001116 sec\n",
      "backward time 0.011042 sec\n",
      "optimizer time 0.002071 sec\n",
      "training time in round 398 cost 0.3763740062713623 sec\n",
      "loss 1.516142, train acc 0.434465\n",
      "round 399\n",
      "time to device 0.004019 sec\n",
      "time forward 4.718509 sec\n",
      "loss time 0.001307 sec\n",
      "backward time 0.011171 sec\n",
      "optimizer time 0.004140 sec\n",
      "training time in round 399 cost 0.3773019313812256 sec\n",
      "loss 1.514047, train acc 0.435195\n",
      "round 400\n",
      "time to device 0.007457 sec\n",
      "time forward 4.731257 sec\n",
      "loss time 0.001362 sec\n",
      "backward time 0.015533 sec\n",
      "optimizer time 0.004340 sec\n",
      "training time in round 400 cost 0.4028129577636719 sec\n",
      "loss 1.512295, train acc 0.436058\n",
      "round 401\n",
      "time to device 0.010527 sec\n",
      "time forward 4.743599 sec\n",
      "loss time 0.001301 sec\n",
      "backward time 0.007639 sec\n",
      "optimizer time 0.003105 sec\n",
      "training time in round 401 cost 0.3933732509613037 sec\n",
      "loss 1.510499, train acc 0.436684\n",
      "round 402\n",
      "time to device 0.006229 sec\n",
      "time forward 4.756297 sec\n",
      "loss time 0.001473 sec\n",
      "backward time 0.011828 sec\n",
      "optimizer time 0.005140 sec\n",
      "training time in round 402 cost 0.38027215003967285 sec\n",
      "loss 1.508803, train acc 0.437345\n",
      "round 403\n",
      "time to device 0.008438 sec\n",
      "time forward 4.768072 sec\n",
      "loss time 0.001062 sec\n",
      "backward time 0.009484 sec\n",
      "optimizer time 0.003964 sec\n",
      "training time in round 403 cost 0.37595486640930176 sec\n",
      "loss 1.507334, train acc 0.437848\n",
      "round 404\n",
      "time to device 0.006750 sec\n",
      "time forward 4.775696 sec\n",
      "loss time 0.000566 sec\n",
      "backward time 0.007713 sec\n",
      "optimizer time 0.004539 sec\n",
      "training time in round 404 cost 0.4377930164337158 sec\n",
      "loss 1.505992, train acc 0.438272\n",
      "round 405\n",
      "time to device 0.006573 sec\n",
      "time forward 4.786263 sec\n",
      "loss time 0.001055 sec\n",
      "backward time 0.009835 sec\n",
      "optimizer time 0.003658 sec\n",
      "training time in round 405 cost 0.3645040988922119 sec\n",
      "loss 1.504493, train acc 0.438885\n",
      "round 406\n",
      "time to device 0.008176 sec\n",
      "time forward 4.798398 sec\n",
      "loss time 0.001257 sec\n",
      "backward time 0.014260 sec\n",
      "optimizer time 0.004056 sec\n",
      "training time in round 406 cost 0.3760659694671631 sec\n",
      "loss 1.503109, train acc 0.439343\n",
      "round 407\n",
      "time to device 0.008307 sec\n",
      "time forward 4.809425 sec\n",
      "loss time 0.001334 sec\n",
      "backward time 0.010348 sec\n",
      "optimizer time 0.004129 sec\n",
      "training time in round 407 cost 0.3670070171356201 sec\n",
      "loss 1.501600, train acc 0.439779\n",
      "round 408\n",
      "time to device 0.006496 sec\n",
      "time forward 4.816705 sec\n",
      "loss time 0.000874 sec\n",
      "backward time 0.007715 sec\n",
      "optimizer time 0.003230 sec\n",
      "training time in round 408 cost 0.3651261329650879 sec\n",
      "loss 1.500330, train acc 0.440251\n",
      "round 409\n",
      "time to device 0.006347 sec\n",
      "time forward 4.828368 sec\n",
      "loss time 0.001347 sec\n",
      "backward time 0.011647 sec\n",
      "optimizer time 0.003926 sec\n",
      "training time in round 409 cost 0.37197113037109375 sec\n",
      "loss 1.498438, train acc 0.441006\n",
      "round 410\n",
      "time to device 0.005200 sec\n",
      "time forward 4.838767 sec\n",
      "loss time 0.001060 sec\n",
      "backward time 0.010861 sec\n",
      "optimizer time 0.004511 sec\n",
      "training time in round 410 cost 0.3905181884765625 sec\n",
      "loss 1.496781, train acc 0.441568\n",
      "round 411\n",
      "time to device 0.006473 sec\n",
      "time forward 4.851490 sec\n",
      "loss time 0.000586 sec\n",
      "backward time 0.007127 sec\n",
      "optimizer time 0.002262 sec\n",
      "training time in round 411 cost 0.4018819332122803 sec\n",
      "loss 1.495090, train acc 0.442051\n",
      "round 412\n",
      "time to device 0.007477 sec\n",
      "time forward 4.861163 sec\n",
      "loss time 0.000422 sec\n",
      "backward time 0.004408 sec\n",
      "optimizer time 0.002025 sec\n",
      "training time in round 412 cost 0.37645912170410156 sec\n",
      "loss 1.493465, train acc 0.442683\n",
      "round 413\n",
      "time to device 0.058880 sec\n",
      "time forward 4.907681 sec\n",
      "loss time 0.000652 sec\n",
      "backward time 0.005884 sec\n",
      "optimizer time 0.003363 sec\n",
      "training time in round 413 cost 0.6271469593048096 sec\n",
      "loss 1.492028, train acc 0.443199\n",
      "round 414\n",
      "time to device 0.007821 sec\n",
      "time forward 4.919288 sec\n",
      "loss time 0.001024 sec\n",
      "backward time 0.010810 sec\n",
      "optimizer time 0.004408 sec\n",
      "training time in round 414 cost 0.3882160186767578 sec\n",
      "loss 1.490439, train acc 0.443769\n",
      "round 415\n",
      "time to device 0.011755 sec\n",
      "time forward 4.928318 sec\n",
      "loss time 0.000566 sec\n",
      "backward time 0.005267 sec\n",
      "optimizer time 0.003686 sec\n",
      "training time in round 415 cost 0.41216206550598145 sec\n",
      "loss 1.488894, train acc 0.444280\n",
      "round 416\n",
      "time to device 0.008433 sec\n",
      "time forward 4.937216 sec\n",
      "loss time 0.000915 sec\n",
      "backward time 0.010215 sec\n",
      "optimizer time 0.005874 sec\n",
      "training time in round 416 cost 0.3849029541015625 sec\n",
      "loss 1.487366, train acc 0.444807\n",
      "round 417\n",
      "time to device 0.009493 sec\n",
      "time forward 4.946345 sec\n",
      "loss time 0.001113 sec\n",
      "backward time 0.010150 sec\n",
      "optimizer time 0.004271 sec\n",
      "training time in round 417 cost 0.382875919342041 sec\n",
      "loss 1.485515, train acc 0.445425\n",
      "round 418\n",
      "time to device 0.007756 sec\n",
      "time forward 4.955290 sec\n",
      "loss time 0.000908 sec\n",
      "backward time 0.009592 sec\n",
      "optimizer time 0.005754 sec\n",
      "training time in round 418 cost 0.3865230083465576 sec\n",
      "loss 1.483801, train acc 0.446133\n",
      "round 419\n",
      "time to device 0.008685 sec\n",
      "time forward 4.966752 sec\n",
      "loss time 0.001434 sec\n",
      "backward time 0.014610 sec\n",
      "optimizer time 0.003959 sec\n",
      "training time in round 419 cost 0.38742971420288086 sec\n",
      "loss 1.482324, train acc 0.446708\n",
      "round 420\n",
      "time to device 0.007787 sec\n",
      "time forward 4.976875 sec\n",
      "loss time 0.001120 sec\n",
      "backward time 0.008866 sec\n",
      "optimizer time 0.003775 sec\n",
      "training time in round 420 cost 0.4198310375213623 sec\n",
      "loss 1.480788, train acc 0.447280\n",
      "round 421\n",
      "time to device 0.008591 sec\n",
      "time forward 4.987790 sec\n",
      "loss time 0.001472 sec\n",
      "backward time 0.013394 sec\n",
      "optimizer time 0.005557 sec\n",
      "training time in round 421 cost 0.3822920322418213 sec\n",
      "loss 1.479480, train acc 0.447756\n",
      "round 422\n",
      "time to device 0.008215 sec\n",
      "time forward 4.997240 sec\n",
      "loss time 0.001382 sec\n",
      "backward time 0.010660 sec\n",
      "optimizer time 0.004304 sec\n",
      "training time in round 422 cost 0.3864409923553467 sec\n",
      "loss 1.478092, train acc 0.448286\n",
      "round 423\n",
      "time to device 0.008166 sec\n",
      "time forward 5.006875 sec\n",
      "loss time 0.001106 sec\n",
      "backward time 0.009882 sec\n",
      "optimizer time 0.003763 sec\n",
      "training time in round 423 cost 0.3625490665435791 sec\n",
      "loss 1.476583, train acc 0.448832\n",
      "round 424\n",
      "time to device 0.007699 sec\n",
      "time forward 5.018556 sec\n",
      "loss time 0.001837 sec\n",
      "backward time 0.016662 sec\n",
      "optimizer time 0.006003 sec\n",
      "training time in round 424 cost 0.40967297554016113 sec\n",
      "loss 1.475309, train acc 0.449357\n",
      "round 425\n",
      "time to device 0.007984 sec\n",
      "time forward 5.029844 sec\n",
      "loss time 0.001072 sec\n",
      "backward time 0.009755 sec\n",
      "optimizer time 0.004356 sec\n",
      "training time in round 425 cost 0.37331414222717285 sec\n",
      "loss 1.473792, train acc 0.449824\n",
      "round 426\n",
      "time to device 0.006903 sec\n",
      "time forward 5.042513 sec\n",
      "loss time 0.000545 sec\n",
      "backward time 0.005055 sec\n",
      "optimizer time 0.002547 sec\n",
      "training time in round 426 cost 0.3913228511810303 sec\n",
      "loss 1.472599, train acc 0.450216\n",
      "round 427\n",
      "time to device 0.006786 sec\n",
      "time forward 5.052723 sec\n",
      "loss time 0.001359 sec\n",
      "backward time 0.011290 sec\n",
      "optimizer time 0.004151 sec\n",
      "training time in round 427 cost 0.3662409782409668 sec\n",
      "loss 1.470896, train acc 0.450916\n",
      "round 428\n",
      "time to device 0.006848 sec\n",
      "time forward 5.062030 sec\n",
      "loss time 0.001395 sec\n",
      "backward time 0.010411 sec\n",
      "optimizer time 0.003606 sec\n",
      "training time in round 428 cost 0.3608262538909912 sec\n",
      "loss 1.469134, train acc 0.451613\n",
      "round 429\n",
      "time to device 0.007303 sec\n",
      "time forward 5.072182 sec\n",
      "loss time 0.001678 sec\n",
      "backward time 0.010407 sec\n",
      "optimizer time 0.003520 sec\n",
      "training time in round 429 cost 0.36507201194763184 sec\n",
      "loss 1.467794, train acc 0.452126\n",
      "round 430\n",
      "time to device 0.004184 sec\n",
      "time forward 5.082573 sec\n",
      "loss time 0.000781 sec\n",
      "backward time 0.007388 sec\n",
      "optimizer time 0.003284 sec\n",
      "training time in round 430 cost 0.37351083755493164 sec\n",
      "loss 1.465903, train acc 0.452799\n",
      "round 431\n",
      "time to device 0.003215 sec\n",
      "time forward 5.092713 sec\n",
      "loss time 0.002964 sec\n",
      "backward time 0.014441 sec\n",
      "optimizer time 0.004352 sec\n",
      "training time in round 431 cost 0.3692002296447754 sec\n",
      "loss 1.464157, train acc 0.453487\n",
      "round 432\n",
      "time to device 0.003931 sec\n",
      "time forward 5.104748 sec\n",
      "loss time 0.000845 sec\n",
      "backward time 0.008072 sec\n",
      "optimizer time 0.004424 sec\n",
      "training time in round 432 cost 0.37891507148742676 sec\n",
      "loss 1.462283, train acc 0.454208\n",
      "round 433\n",
      "time to device 0.003763 sec\n",
      "time forward 5.115842 sec\n",
      "loss time 0.000672 sec\n",
      "backward time 0.005187 sec\n",
      "optimizer time 0.003429 sec\n",
      "training time in round 433 cost 0.4388458728790283 sec\n",
      "loss 1.460737, train acc 0.454763\n",
      "round 434\n",
      "time to device 0.007502 sec\n",
      "time forward 5.125694 sec\n",
      "loss time 0.000730 sec\n",
      "backward time 0.006593 sec\n",
      "optimizer time 0.003118 sec\n",
      "training time in round 434 cost 0.40926194190979004 sec\n",
      "loss 1.459081, train acc 0.455406\n",
      "round 435\n",
      "time to device 0.006912 sec\n",
      "time forward 5.135273 sec\n",
      "loss time 0.000806 sec\n",
      "backward time 0.007390 sec\n",
      "optimizer time 0.003869 sec\n",
      "training time in round 435 cost 0.38573694229125977 sec\n",
      "loss 1.457204, train acc 0.456099\n",
      "round 436\n",
      "time to device 0.009081 sec\n",
      "time forward 5.148489 sec\n",
      "loss time 0.000907 sec\n",
      "backward time 0.009142 sec\n",
      "optimizer time 0.003751 sec\n",
      "training time in round 436 cost 0.38320279121398926 sec\n",
      "loss 1.455897, train acc 0.456629\n",
      "round 437\n",
      "time to device 0.007605 sec\n",
      "time forward 5.157616 sec\n",
      "loss time 0.000699 sec\n",
      "backward time 0.006798 sec\n",
      "optimizer time 0.003204 sec\n",
      "training time in round 437 cost 0.35619688034057617 sec\n",
      "loss 1.454224, train acc 0.457245\n",
      "round 438\n",
      "time to device 0.007164 sec\n",
      "time forward 5.247112 sec\n",
      "loss time 0.001913 sec\n",
      "backward time 0.020209 sec\n",
      "optimizer time 0.004135 sec\n",
      "training time in round 438 cost 0.6944241523742676 sec\n",
      "loss 1.452964, train acc 0.457699\n",
      "round 439\n",
      "time to device 0.009851 sec\n",
      "time forward 5.264412 sec\n",
      "loss time 0.000913 sec\n",
      "backward time 0.008473 sec\n",
      "optimizer time 0.003284 sec\n",
      "training time in round 439 cost 0.43764472007751465 sec\n",
      "loss 1.451243, train acc 0.458345\n",
      "round 440\n",
      "time to device 0.008129 sec\n",
      "time forward 5.273379 sec\n",
      "loss time 0.001083 sec\n",
      "backward time 0.009647 sec\n",
      "optimizer time 0.003691 sec\n",
      "training time in round 440 cost 0.3626232147216797 sec\n",
      "loss 1.449596, train acc 0.459007\n",
      "round 441\n",
      "time to device 0.008449 sec\n",
      "time forward 5.284441 sec\n",
      "loss time 0.000733 sec\n",
      "backward time 0.008087 sec\n",
      "optimizer time 0.003170 sec\n",
      "training time in round 441 cost 0.4104330539703369 sec\n",
      "loss 1.447647, train acc 0.459736\n",
      "round 442\n",
      "time to device 0.007469 sec\n",
      "time forward 5.293477 sec\n",
      "loss time 0.001045 sec\n",
      "backward time 0.009330 sec\n",
      "optimizer time 0.003524 sec\n",
      "training time in round 442 cost 0.36576223373413086 sec\n",
      "loss 1.445921, train acc 0.460338\n",
      "round 443\n",
      "time to device 0.008165 sec\n",
      "time forward 5.303892 sec\n",
      "loss time 0.001297 sec\n",
      "backward time 0.013052 sec\n",
      "optimizer time 0.003731 sec\n",
      "training time in round 443 cost 0.3791618347167969 sec\n",
      "loss 1.444880, train acc 0.460832\n",
      "round 444\n",
      "time to device 0.006848 sec\n",
      "time forward 5.316944 sec\n",
      "loss time 0.001271 sec\n",
      "backward time 0.011965 sec\n",
      "optimizer time 0.003878 sec\n",
      "training time in round 444 cost 0.39124202728271484 sec\n",
      "loss 1.443400, train acc 0.461324\n",
      "round 445\n",
      "time to device 0.007976 sec\n",
      "time forward 5.328146 sec\n",
      "loss time 0.001643 sec\n",
      "backward time 0.010748 sec\n",
      "optimizer time 0.003521 sec\n",
      "training time in round 445 cost 0.3694729804992676 sec\n",
      "loss 1.441939, train acc 0.461918\n",
      "round 446\n",
      "time to device 0.006719 sec\n",
      "time forward 5.338298 sec\n",
      "loss time 0.001047 sec\n",
      "backward time 0.009720 sec\n",
      "optimizer time 0.003476 sec\n",
      "training time in round 446 cost 0.3591179847717285 sec\n",
      "loss 1.440557, train acc 0.462336\n",
      "round 447\n",
      "time to device 0.005898 sec\n",
      "time forward 5.345182 sec\n",
      "loss time 0.000433 sec\n",
      "backward time 0.004376 sec\n",
      "optimizer time 0.002270 sec\n",
      "training time in round 447 cost 0.3716769218444824 sec\n",
      "loss 1.439080, train acc 0.462943\n",
      "round 448\n",
      "time to device 0.006552 sec\n",
      "time forward 5.357005 sec\n",
      "loss time 0.001586 sec\n",
      "backward time 0.011471 sec\n",
      "optimizer time 0.004785 sec\n",
      "training time in round 448 cost 0.40607690811157227 sec\n",
      "loss 1.437416, train acc 0.463547\n",
      "round 449\n",
      "time to device 0.006177 sec\n",
      "time forward 5.367714 sec\n",
      "loss time 0.001136 sec\n",
      "backward time 0.009591 sec\n",
      "optimizer time 0.003757 sec\n",
      "training time in round 449 cost 0.38960814476013184 sec\n",
      "loss 1.435741, train acc 0.464219\n",
      "round 450\n",
      "time to device 0.008077 sec\n",
      "time forward 5.377423 sec\n",
      "loss time 0.001053 sec\n",
      "backward time 0.009662 sec\n",
      "optimizer time 0.003732 sec\n",
      "training time in round 450 cost 0.3794229030609131 sec\n",
      "loss 1.434096, train acc 0.464870\n",
      "round 451\n",
      "time to device 0.006782 sec\n",
      "time forward 5.386008 sec\n",
      "loss time 0.001039 sec\n",
      "backward time 0.010678 sec\n",
      "optimizer time 0.003430 sec\n",
      "training time in round 451 cost 0.35704517364501953 sec\n",
      "loss 1.432564, train acc 0.465414\n",
      "round 452\n",
      "time to device 0.005780 sec\n",
      "time forward 5.395745 sec\n",
      "loss time 0.001338 sec\n",
      "backward time 0.010998 sec\n",
      "optimizer time 0.003850 sec\n",
      "training time in round 452 cost 0.3723781108856201 sec\n",
      "loss 1.431466, train acc 0.465870\n",
      "round 453\n",
      "time to device 0.006609 sec\n",
      "time forward 5.404051 sec\n",
      "loss time 0.001051 sec\n",
      "backward time 0.009782 sec\n",
      "optimizer time 0.003621 sec\n",
      "training time in round 453 cost 0.36870622634887695 sec\n",
      "loss 1.430057, train acc 0.466513\n",
      "round 454\n",
      "time to device 0.006401 sec\n",
      "time forward 5.413266 sec\n",
      "loss time 0.001008 sec\n",
      "backward time 0.009361 sec\n",
      "optimizer time 0.003492 sec\n",
      "training time in round 454 cost 0.3553929328918457 sec\n",
      "loss 1.428998, train acc 0.467016\n",
      "round 455\n",
      "time to device 0.007507 sec\n",
      "time forward 5.423163 sec\n",
      "loss time 0.001315 sec\n",
      "backward time 0.010784 sec\n",
      "optimizer time 0.004767 sec\n",
      "training time in round 455 cost 0.3692739009857178 sec\n",
      "loss 1.427613, train acc 0.467619\n",
      "round 456\n",
      "time to device 0.007118 sec\n",
      "time forward 5.434455 sec\n",
      "loss time 0.001461 sec\n",
      "backward time 0.013998 sec\n",
      "optimizer time 0.004751 sec\n",
      "training time in round 456 cost 0.37495899200439453 sec\n",
      "loss 1.426056, train acc 0.468169\n",
      "round 457\n",
      "time to device 0.006891 sec\n",
      "time forward 5.445768 sec\n",
      "loss time 0.000502 sec\n",
      "backward time 0.004759 sec\n",
      "optimizer time 0.002473 sec\n",
      "training time in round 457 cost 0.36062002182006836 sec\n",
      "loss 1.424602, train acc 0.468733\n",
      "round 458\n",
      "time to device 0.006944 sec\n",
      "time forward 5.455590 sec\n",
      "loss time 0.001132 sec\n",
      "backward time 0.010078 sec\n",
      "optimizer time 0.003952 sec\n",
      "training time in round 458 cost 0.36397218704223633 sec\n",
      "loss 1.422867, train acc 0.469312\n",
      "round 459\n",
      "time to device 0.006427 sec\n",
      "time forward 5.470588 sec\n",
      "loss time 0.000909 sec\n",
      "backward time 0.008441 sec\n",
      "optimizer time 0.003280 sec\n",
      "training time in round 459 cost 0.3689460754394531 sec\n",
      "loss 1.421546, train acc 0.469803\n",
      "round 460\n",
      "time to device 0.007118 sec\n",
      "time forward 5.482262 sec\n",
      "loss time 0.001234 sec\n",
      "backward time 0.013587 sec\n",
      "optimizer time 0.004308 sec\n",
      "training time in round 460 cost 0.37572717666625977 sec\n",
      "loss 1.420149, train acc 0.470411\n",
      "round 461\n",
      "time to device 0.007437 sec\n",
      "time forward 5.498988 sec\n",
      "loss time 0.001711 sec\n",
      "backward time 0.008934 sec\n",
      "optimizer time 0.002402 sec\n",
      "training time in round 461 cost 0.40583181381225586 sec\n",
      "loss 1.418813, train acc 0.471016\n",
      "round 462\n",
      "time to device 0.006487 sec\n",
      "time forward 5.511485 sec\n",
      "loss time 0.000928 sec\n",
      "backward time 0.009647 sec\n",
      "optimizer time 0.003932 sec\n",
      "training time in round 462 cost 0.383774995803833 sec\n",
      "loss 1.417519, train acc 0.471484\n",
      "round 463\n",
      "time to device 0.006264 sec\n",
      "time forward 5.523267 sec\n",
      "loss time 0.001785 sec\n",
      "backward time 0.013044 sec\n",
      "optimizer time 0.003653 sec\n",
      "training time in round 463 cost 0.3817291259765625 sec\n",
      "loss 1.416344, train acc 0.471882\n",
      "round 464\n",
      "time to device 0.004905 sec\n",
      "time forward 5.536409 sec\n",
      "loss time 0.001152 sec\n",
      "backward time 0.008461 sec\n",
      "optimizer time 0.002697 sec\n",
      "training time in round 464 cost 0.37938404083251953 sec\n",
      "loss 1.415035, train acc 0.472312\n",
      "round 465\n",
      "time to device 0.004184 sec\n",
      "time forward 5.545643 sec\n",
      "loss time 0.001075 sec\n",
      "backward time 0.009029 sec\n",
      "optimizer time 0.003366 sec\n",
      "training time in round 465 cost 0.3544423580169678 sec\n",
      "loss 1.413341, train acc 0.472908\n",
      "round 466\n",
      "time to device 0.003307 sec\n",
      "time forward 5.559949 sec\n",
      "loss time 0.002500 sec\n",
      "backward time 0.014319 sec\n",
      "optimizer time 0.004482 sec\n",
      "training time in round 466 cost 0.3827970027923584 sec\n",
      "loss 1.411938, train acc 0.473535\n",
      "round 467\n",
      "time to device 0.003892 sec\n",
      "time forward 5.569757 sec\n",
      "loss time 0.000598 sec\n",
      "backward time 0.005702 sec\n",
      "optimizer time 0.002836 sec\n",
      "training time in round 467 cost 0.3567049503326416 sec\n",
      "loss 1.410421, train acc 0.474092\n",
      "round 468\n",
      "time to device 0.002918 sec\n",
      "time forward 5.588956 sec\n",
      "loss time 0.002123 sec\n",
      "backward time 0.015865 sec\n",
      "optimizer time 0.003695 sec\n",
      "training time in round 468 cost 0.3248629570007324 sec\n",
      "loss 1.409461, train acc 0.474500\n",
      "test acc is 0.746400\n",
      "epoch 0, time 418.684282 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 2\n",
    "device = 'mps'\n",
    "timeenergy_data_forward, timeenergy_data_round, acc_data, train_l, train_acc, time_data_epoch, energy_data_epoch = train_ch6self(net, train_iter, test_iter, num_epochs, lr, device, energy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "077d7896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dtjgp/Learning/Thesis/GreenAI/M1chip/Third_part/FL_code\n",
      "/Users/dtjgp/Learning/Thesis/GreenAI/M1chip/Third_part\n",
      "/Users/dtjgp/Learning/Thesis/GreenAI/M1chip/Third_part/data/1epoch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "working_dir = os.getcwd()\n",
    "print(working_dir)\n",
    "\n",
    "# get the parent directory\n",
    "parent_dir = os.path.dirname(working_dir)\n",
    "print(parent_dir)\n",
    "\n",
    "# get the data directory\n",
    "data_dir = os.path.join(parent_dir, 'data/2epochs')\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "83054b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the parameters in the data directory\n",
    "data_dir_selected = os.path.join(data_dir, 'net1')\n",
    "torch.save(net, os.path.join(data_dir_selected,'net_alexnet.pth'))\n",
    "torch.save(net.state_dict(), os.path.join(data_dir_selected, 'net_state_dict_alexnet.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeenergy_data_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeenergy_data_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_data_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_data_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# working_dir = os.getcwd()\n",
    "# working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dtjgp/Learning/Thesis/GreenAI/M1chip/Third_part/data/net10/info\n"
     ]
    }
   ],
   "source": [
    "# # find the second_part folder\n",
    "info_dir = os.path.join(data_dir_selected, 'info')\n",
    "print(info_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data as .npy file\n",
    "np.save(os.path.join(info_dir, 'timeenergy_data_forward.npy'), timeenergy_data_forward)\n",
    "np.save(os.path.join(info_dir, 'timeenergy_data_round.npy'), timeenergy_data_round)\n",
    "np.save(os.path.join(info_dir, 'acc_data.npy'), acc_data)\n",
    "np.save(os.path.join(info_dir, 'train_acc.npy'), train_acc)\n",
    "np.save(os.path.join(info_dir, 'train_l.npy'), train_l)\n",
    "np.save(os.path.join(info_dir, 'time_data_epoch.npy'), time_data_epoch)\n",
    "np.save(os.path.join(info_dir, 'energy_data_epoch.npy'), energy_data_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
