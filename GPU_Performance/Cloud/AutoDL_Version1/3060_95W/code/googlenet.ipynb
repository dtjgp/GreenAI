{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ptflops import get_model_complexity_info\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current path is: /home/yj/FinalThesis/GreenAI/Cloud/3060_95W/code\n",
      "The parent path is: /home/yj/FinalThesis/GreenAI/Cloud/3060_95W\n",
      "The data path is: /home/yj/FinalThesis/GreenAI/Cloud/3060_95W/Data/googlenet\n"
     ]
    }
   ],
   "source": [
    "'''find the Model path'''\n",
    "# find the current path\n",
    "current_path = os.getcwd()\n",
    "print('The current path is:', current_path)\n",
    "\n",
    "# find the parent path\n",
    "parent_path = Path(current_path).parent\n",
    "print('The parent path is:', parent_path)\n",
    "\n",
    "# find the data path\n",
    "data_path = parent_path / 'Data/googlenet'\n",
    "print('The data path is:', data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    # c1--c4是每条路径的输出通道数\n",
    "    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        # 线路1，单1x1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # 线路2，1x1卷积层后接3x3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1x1卷积层后接5x5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3x3最大汇聚层后接1x1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        # 在通道维度上连结输出\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)\n",
    "    \n",
    "def Googlenet(img_channel, num_labels):\n",
    "    b1 = nn.Sequential(nn.Conv2d(img_channel, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   nn.Flatten())\n",
    "\n",
    "    net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, num_labels))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Sequential\n",
      "  0: Conv2d\n",
      "  1: ReLU\n",
      "  2: MaxPool2d\n",
      "1: Sequential\n",
      "  0: Conv2d\n",
      "  1: ReLU\n",
      "  2: Conv2d\n",
      "  3: ReLU\n",
      "  4: MaxPool2d\n",
      "2: Sequential\n",
      "  0: Inception\n",
      "  1: Inception\n",
      "  2: MaxPool2d\n",
      "3: Sequential\n",
      "  0: Inception\n",
      "  1: Inception\n",
      "  2: Inception\n",
      "  3: Inception\n",
      "  4: Inception\n",
      "  5: MaxPool2d\n",
      "4: Sequential\n",
      "  0: Inception\n",
      "  1: Inception\n",
      "  2: AdaptiveAvgPool2d\n",
      "  3: Flatten\n",
      "5: Linear\n",
      "The layer name is: ['S0_C0', 'S0_R1', 'S0_M2', 'S1_C0', 'S1_R1', 'S1_C2', 'S1_R3', 'S1_M4', 'S2_I0', 'S2_I1', 'S2_M2', 'S3_I0', 'S3_I1', 'S3_I2', 'S3_I3', 'S3_I4', 'S3_M5', 'S4_I0', 'S4_I1', 'S4_A2', 'S4_F3']\n",
      "The length of layer name is: 21\n",
      "The number of blocks is: 5\n",
      "The number of inception blocks is: 9\n"
     ]
    }
   ],
   "source": [
    "net = Googlenet(1, 10)    \n",
    "LayerName = []\n",
    "block_num = 0\n",
    "incep_num = 0\n",
    "\n",
    "for num, layer in net.named_children():  # 使用 named_children 来获取层名和层\n",
    "    layername = layer.__class__.__name__\n",
    "    print(f\"{num}: {layername}\")  # 打印层名和层类名\n",
    "    \n",
    "    if layer.__class__.__name__ == 'Sequential':\n",
    "        block_num += 1\n",
    "        for sublayernum, sublayer in layer.named_children():  # 再次使用 named_children\n",
    "            sublayername = sublayer.__class__.__name__\n",
    "            if sublayername == 'Inception':\n",
    "                incep_num += 1\n",
    "            print(f\"  {sublayernum}: {sublayername}\")\n",
    "            layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}'\n",
    "            LayerName.append(layer_label)  # 收集子块的类型\n",
    "            # if sublayername == 'Inception':\n",
    "            #     incep_num += 1\n",
    "            #     for incepblocknum, incepblock in sublayer.named_children():  # 继续使用 named_children\n",
    "            #         incepblockname = incepblock.__class__.__name__\n",
    "            #         print(f\"    {incepblocknum}: {incepblockname}\")\n",
    "                    \n",
    "            #         layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}_{incepblockname[0]}{incepblocknum}'\n",
    "            #         # print('The layer label is:', layer_label)\n",
    "            #         LayerName.append(layer_label)  # 收集子子块的类型\n",
    "            # else:\n",
    "            #     layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}'\n",
    "            #     LayerName.append(layer_label)  # 收集子块的类型\n",
    "                        \n",
    "print('The layer name is:', LayerName)\n",
    "print(f'The length of layer name is: {len(LayerName)}')\n",
    "print('The number of blocks is:', block_num)\n",
    "print('The number of inception blocks is:', incep_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build different alexnet model for different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于不同的数据集，要设置不同的img_channel和num_labels\n",
    "# Fashion-MNIST中的图像通道数为1，类别数为10\n",
    "googlenet_f = Googlenet(1, 10)\n",
    "# CIFAR100中的图像通道数为3，类别数为100\n",
    "googlenet_c = Googlenet(3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Inception is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  5.98 M, 100.000% Params, 1.51 GMac, 99.594% MACs, \n",
      "  (0): Sequential(\n",
      "    3.2 k, 0.054% Params, 41.75 MMac, 2.752% MACs, \n",
      "    (0): Conv2d(3.2 k, 0.054% Params, 40.14 MMac, 2.646% MACs, 1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.053% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.053% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 1.923% Params, 361.87 MMac, 23.856% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.070% Params, 13.05 MMac, 0.860% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.013% MACs, )\n",
      "    (2): Conv2d(110.78 k, 1.853% Params, 347.42 MMac, 22.903% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.040% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.040% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    552.43 k, 9.242% Params, 433.83 MMac, 28.600% MACs, \n",
      "    (0): Inception(\n",
      "      163.7 k, 2.739% Params, 128.49 MMac, 8.470% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.207% Params, 9.68 MMac, 0.638% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(18.53 k, 0.310% Params, 14.53 MMac, 0.958% MACs, 192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(110.72 k, 1.852% Params, 86.8 MMac, 5.723% MACs, 96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(3.09 k, 0.052% Params, 2.42 MMac, 0.160% MACs, 192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(12.83 k, 0.215% Params, 10.06 MMac, 0.663% MACs, 16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 150.53 KMac, 0.010% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(6.18 k, 0.103% Params, 4.84 MMac, 0.319% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      388.74 k, 6.503% Params, 304.97 MMac, 20.105% MACs, \n",
      "      (p1_1): Conv2d(32.9 k, 0.550% Params, 25.79 MMac, 1.700% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(32.9 k, 0.550% Params, 25.79 MMac, 1.700% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(221.38 k, 3.703% Params, 173.56 MMac, 11.442% MACs, 128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(8.22 k, 0.138% Params, 6.45 MMac, 0.425% MACs, 256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(76.9 k, 1.286% Params, 60.29 MMac, 3.974% MACs, 32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 200.7 KMac, 0.013% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(16.45 k, 0.275% Params, 12.9 MMac, 0.850% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 376.32 KMac, 0.025% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    2.81 M, 46.995% Params, 551.26 MMac, 36.341% MACs, \n",
      "    (0): Inception(\n",
      "      376.18 k, 6.293% Params, 73.82 MMac, 4.867% MACs, \n",
      "      (p1_1): Conv2d(92.35 k, 1.545% Params, 18.1 MMac, 1.193% MACs, 480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(46.18 k, 0.772% Params, 9.05 MMac, 0.597% MACs, 480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(179.92 k, 3.010% Params, 35.26 MMac, 2.325% MACs, 96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(7.7 k, 0.129% Params, 1.51 MMac, 0.099% MACs, 480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(19.25 k, 0.322% Params, 3.77 MMac, 0.249% MACs, 16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 94.08 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(30.78 k, 0.515% Params, 6.03 MMac, 0.398% MACs, 480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      449.16 k, 7.514% Params, 88.14 MMac, 5.810% MACs, \n",
      "      (p1_1): Conv2d(82.08 k, 1.373% Params, 16.09 MMac, 1.061% MACs, 512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(57.46 k, 0.961% Params, 11.26 MMac, 0.742% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(226.02 k, 3.781% Params, 44.3 MMac, 2.920% MACs, 112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.206% Params, 2.41 MMac, 0.159% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.643% Params, 7.54 MMac, 0.497% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.549% Params, 6.44 MMac, 0.424% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception(\n",
      "      510.1 k, 8.534% Params, 100.08 MMac, 6.598% MACs, \n",
      "      (p1_1): Conv2d(65.66 k, 1.099% Params, 12.87 MMac, 0.848% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(65.66 k, 1.099% Params, 12.87 MMac, 0.848% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(295.17 k, 4.938% Params, 57.85 MMac, 3.814% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.206% Params, 2.41 MMac, 0.159% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.643% Params, 7.54 MMac, 0.497% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.549% Params, 6.44 MMac, 0.424% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception(\n",
      "      605.38 k, 10.128% Params, 118.75 MMac, 7.829% MACs, \n",
      "      (p1_1): Conv2d(57.46 k, 0.961% Params, 11.26 MMac, 0.742% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(73.87 k, 1.236% Params, 14.48 MMac, 0.955% MACs, 512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(373.54 k, 6.249% Params, 73.21 MMac, 4.827% MACs, 144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.42 k, 0.275% Params, 3.22 MMac, 0.212% MACs, 512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(51.26 k, 0.858% Params, 10.05 MMac, 0.662% MACs, 32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.549% Params, 6.44 MMac, 0.424% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception(\n",
      "      868.35 k, 14.527% Params, 170.3 MMac, 11.227% MACs, \n",
      "      (p1_1): Conv2d(135.42 k, 2.266% Params, 26.54 MMac, 1.750% MACs, 528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(84.64 k, 1.416% Params, 16.59 MMac, 1.094% MACs, 528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.714% Params, 90.38 MMac, 5.958% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.93 k, 0.283% Params, 3.32 MMac, 0.219% MACs, 528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.715% Params, 20.1 MMac, 1.325% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 103.49 KMac, 0.007% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(67.71 k, 1.133% Params, 13.27 MMac, 0.875% MACs, 528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 163.07 KMac, 0.011% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    2.49 M, 41.615% Params, 122.02 MMac, 8.044% MACs, \n",
      "    (0): Inception(\n",
      "      1.04 M, 17.456% Params, 51.17 MMac, 3.373% MACs, \n",
      "      (p1_1): Conv2d(213.25 k, 3.567% Params, 10.45 MMac, 0.689% MACs, 832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(133.28 k, 2.230% Params, 6.53 MMac, 0.431% MACs, 832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.714% Params, 22.59 MMac, 1.490% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(26.66 k, 0.446% Params, 1.31 MMac, 0.086% MACs, 832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.715% Params, 5.02 MMac, 0.331% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.784% Params, 5.22 MMac, 0.344% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      1.44 M, 24.158% Params, 70.8 MMac, 4.667% MACs, \n",
      "      (p1_1): Conv2d(319.87 k, 5.351% Params, 15.67 MMac, 1.033% MACs, 832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(159.94 k, 2.676% Params, 7.84 MMac, 0.517% MACs, 832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(663.94 k, 11.107% Params, 32.53 MMac, 2.145% MACs, 192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(39.98 k, 0.669% Params, 1.96 MMac, 0.129% MACs, 832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(153.73 k, 2.572% Params, 7.53 MMac, 0.497% MACs, 48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.784% Params, 5.22 MMac, 0.344% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 50.18 KMac, 0.003% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(10.25 k, 0.171% Params, 10.25 KMac, 0.001% MACs, in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       1.52 GMac\n",
      "Number of parameters:           5.98 M  \n",
      "**************************************************\n",
      "Warning: module Inception is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Sequential(\n",
      "  6.08 M, 100.000% Params, 1.59 GMac, 99.614% MACs, \n",
      "  (0): Sequential(\n",
      "    9.47 k, 0.156% Params, 120.42 MMac, 7.547% MACs, \n",
      "    (0): Conv2d(9.47 k, 0.156% Params, 118.82 MMac, 7.446% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(0, 0.000% Params, 802.82 KMac, 0.050% MACs, )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.050% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    114.94 k, 1.892% Params, 361.87 MMac, 22.678% MACs, \n",
      "    (0): Conv2d(4.16 k, 0.068% Params, 13.05 MMac, 0.818% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 200.7 KMac, 0.013% MACs, )\n",
      "    (2): Conv2d(110.78 k, 1.823% Params, 347.42 MMac, 21.773% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 602.11 KMac, 0.038% MACs, )\n",
      "    (4): MaxPool2d(0, 0.000% Params, 602.11 KMac, 0.038% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    552.43 k, 9.092% Params, 433.83 MMac, 27.188% MACs, \n",
      "    (0): Inception(\n",
      "      163.7 k, 2.694% Params, 128.49 MMac, 8.052% MACs, \n",
      "      (p1_1): Conv2d(12.35 k, 0.203% Params, 9.68 MMac, 0.607% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(18.53 k, 0.305% Params, 14.53 MMac, 0.910% MACs, 192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(110.72 k, 1.822% Params, 86.8 MMac, 5.440% MACs, 96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(3.09 k, 0.051% Params, 2.42 MMac, 0.152% MACs, 192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(12.83 k, 0.211% Params, 10.06 MMac, 0.630% MACs, 16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 150.53 KMac, 0.009% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(6.18 k, 0.102% Params, 4.84 MMac, 0.303% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      388.74 k, 6.398% Params, 304.97 MMac, 19.112% MACs, \n",
      "      (p1_1): Conv2d(32.9 k, 0.541% Params, 25.79 MMac, 1.616% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(32.9 k, 0.541% Params, 25.79 MMac, 1.616% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(221.38 k, 3.643% Params, 173.56 MMac, 10.877% MACs, 128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(8.22 k, 0.135% Params, 6.45 MMac, 0.404% MACs, 256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(76.9 k, 1.266% Params, 60.29 MMac, 3.778% MACs, 32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 200.7 KMac, 0.013% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(16.45 k, 0.271% Params, 12.9 MMac, 0.808% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(0, 0.000% Params, 376.32 KMac, 0.024% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    2.81 M, 46.233% Params, 551.26 MMac, 34.547% MACs, \n",
      "    (0): Inception(\n",
      "      376.18 k, 6.191% Params, 73.82 MMac, 4.627% MACs, \n",
      "      (p1_1): Conv2d(92.35 k, 1.520% Params, 18.1 MMac, 1.134% MACs, 480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(46.18 k, 0.760% Params, 9.05 MMac, 0.567% MACs, 480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(179.92 k, 2.961% Params, 35.26 MMac, 2.210% MACs, 96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(7.7 k, 0.127% Params, 1.51 MMac, 0.095% MACs, 480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(19.25 k, 0.317% Params, 3.77 MMac, 0.236% MACs, 16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 94.08 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(30.78 k, 0.507% Params, 6.03 MMac, 0.378% MACs, 480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      449.16 k, 7.392% Params, 88.14 MMac, 5.523% MACs, \n",
      "      (p1_1): Conv2d(82.08 k, 1.351% Params, 16.09 MMac, 1.008% MACs, 512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(57.46 k, 0.946% Params, 11.26 MMac, 0.706% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(226.02 k, 3.720% Params, 44.3 MMac, 2.776% MACs, 112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.203% Params, 2.41 MMac, 0.151% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.633% Params, 7.54 MMac, 0.472% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.540% Params, 6.44 MMac, 0.403% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception(\n",
      "      510.1 k, 8.395% Params, 100.08 MMac, 6.272% MACs, \n",
      "      (p1_1): Conv2d(65.66 k, 1.081% Params, 12.87 MMac, 0.807% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(65.66 k, 1.081% Params, 12.87 MMac, 0.807% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(295.17 k, 4.858% Params, 57.85 MMac, 3.626% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(12.31 k, 0.203% Params, 2.41 MMac, 0.151% MACs, 512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(38.46 k, 0.633% Params, 7.54 MMac, 0.472% MACs, 24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.540% Params, 6.44 MMac, 0.403% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception(\n",
      "      605.38 k, 9.963% Params, 118.75 MMac, 7.442% MACs, \n",
      "      (p1_1): Conv2d(57.46 k, 0.946% Params, 11.26 MMac, 0.706% MACs, 512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(73.87 k, 1.216% Params, 14.48 MMac, 0.907% MACs, 512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(373.54 k, 6.148% Params, 73.21 MMac, 4.588% MACs, 144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.42 k, 0.270% Params, 3.22 MMac, 0.202% MACs, 512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(51.26 k, 0.844% Params, 10.05 MMac, 0.630% MACs, 32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(32.83 k, 0.540% Params, 6.44 MMac, 0.403% MACs, 512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception(\n",
      "      868.35 k, 14.291% Params, 170.3 MMac, 10.673% MACs, \n",
      "      (p1_1): Conv2d(135.42 k, 2.229% Params, 26.54 MMac, 1.663% MACs, 528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(84.64 k, 1.393% Params, 16.59 MMac, 1.040% MACs, 528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.589% Params, 90.38 MMac, 5.664% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(16.93 k, 0.279% Params, 3.32 MMac, 0.208% MACs, 528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.687% Params, 20.1 MMac, 1.259% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 103.49 KMac, 0.006% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(67.71 k, 1.114% Params, 13.27 MMac, 0.832% MACs, 528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(0, 0.000% Params, 163.07 KMac, 0.010% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    2.49 M, 40.940% Params, 122.02 MMac, 7.647% MACs, \n",
      "    (0): Inception(\n",
      "      1.04 M, 17.173% Params, 51.17 MMac, 3.207% MACs, \n",
      "      (p1_1): Conv2d(213.25 k, 3.510% Params, 10.45 MMac, 0.655% MACs, 832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(133.28 k, 2.194% Params, 6.53 MMac, 0.409% MACs, 832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(461.12 k, 7.589% Params, 22.59 MMac, 1.416% MACs, 160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(26.66 k, 0.439% Params, 1.31 MMac, 0.082% MACs, 832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(102.53 k, 1.687% Params, 5.02 MMac, 0.315% MACs, 32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.755% Params, 5.22 MMac, 0.327% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      1.44 M, 23.767% Params, 70.8 MMac, 4.437% MACs, \n",
      "      (p1_1): Conv2d(319.87 k, 5.264% Params, 15.67 MMac, 0.982% MACs, 832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(159.94 k, 2.632% Params, 7.84 MMac, 0.491% MACs, 832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(663.94 k, 10.927% Params, 32.53 MMac, 2.039% MACs, 192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(39.98 k, 0.658% Params, 1.96 MMac, 0.123% MACs, 832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(153.73 k, 2.530% Params, 7.53 MMac, 0.472% MACs, 48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(0, 0.000% Params, 40.77 KMac, 0.003% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(106.62 k, 1.755% Params, 5.22 MMac, 0.327% MACs, 832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): AdaptiveAvgPool2d(0, 0.000% Params, 50.18 KMac, 0.003% MACs, output_size=(1, 1))\n",
      "    (3): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (5): Linear(102.5 k, 1.687% Params, 102.5 KMac, 0.006% MACs, in_features=1024, out_features=100, bias=True)\n",
      ")\n",
      "Computational complexity:       1.6 GMac\n",
      "Number of parameters:           6.08 M  \n"
     ]
    }
   ],
   "source": [
    "# fashion mnist\n",
    "with torch.cuda.device(0):\n",
    "    macs_f, params_f = get_model_complexity_info(googlenet_f, (1, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_f))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_f))\n",
    "\n",
    "print('*'*50)\n",
    "\n",
    "# cifar100\n",
    "with torch.cuda.device(0):\n",
    "    macs_c, params_c = get_model_complexity_info(googlenet_c, (3, 224, 224), as_strings=True,\n",
    "                                            print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs_c))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 192, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 480, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 832, 7, 7])\n",
      "Sequential output shape:\t torch.Size([1, 1024])\n",
      "Linear output shape:\t torch.Size([1, 10])\n",
      "**************************************************\n",
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 192, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 480, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 832, 7, 7])\n",
      "Sequential output shape:\t torch.Size([1, 1024])\n",
      "Linear output shape:\t torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "X_f = torch.randn(size=(1, 1, 224, 224), dtype=torch.float32) # fashion mnist\n",
    "X_c = torch.randn(size=(1, 3, 224, 224), dtype=torch.float32) # cifar100\n",
    "\n",
    "for layer in googlenet_f:\n",
    "    X_f=layer(X_f)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X_f.shape)\n",
    "\n",
    "print('*'*50)\n",
    "\n",
    "for layer in googlenet_c:\n",
    "    X_c=layer(X_c)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# fashion mnist\n",
    "def get_dataloader_workers():\n",
    "    \"\"\"Use 4 processes to read the data.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    return 4\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\n",
    "\n",
    "    Defined in :numref:`sec_fashion_mnist`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=get_dataloader_workers()))\n",
    "\n",
    "def load_data_cifar100(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    # import the cifar100 dataset\n",
    "    cifar_train = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    cifar_test = torchvision.datasets.CIFAR100(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(cifar_train, batch_size, shuffle=True,\n",
    "                                        num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(cifar_test, batch_size, shuffle=False,\n",
    "                                        num_workers=get_dataloader_workers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = [128, 256, 512]\n",
    "batch_size = [64]\n",
    "# epochs = [10, 20, 30, 40, 50]\n",
    "epochs = [3]\n",
    "rounds = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(net, train_iter, test_iter, LayerName, num_epochs, lr, device):\n",
    "    def init_weights(m): # 初始化权重\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    # record each block running time\n",
    "    Layers_time = np.zeros((len(LayerName), num_epochs)) # each row is a layer, each column is an epoch\n",
    "    Train_part_time = np.zeros((6, num_epochs)) # store the time to device, forward, loss, backward time, optimization time, and test time of each epoch\n",
    "    Train_acc = np.zeros(num_epochs) # store the training accuracy of each epoch\n",
    "    Test_acc = np.zeros(num_epochs) # store the test accuracy of each epoch\n",
    "    Epoch_time = np.zeros(num_epochs) # store the total time of each epoch\n",
    "    Epoch_energy = np.zeros((num_epochs,1), dtype='object') # store the total energy of each epoch\n",
    "    timer = d2l.Timer()\n",
    "    train_timer = d2l.Timer()\n",
    "    ttd_timer = d2l.Timer()\n",
    "    forward_timer = d2l.Timer()\n",
    "    loss_timer = d2l.Timer()\n",
    "    backward_timer = d2l.Timer()\n",
    "    optimizer_timer = d2l.Timer()\n",
    "    layer_timer = d2l.Timer()\n",
    "    test_timer = d2l.Timer()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    # start training\n",
    "    for epoch in range(num_epochs):\n",
    "        print('The epoch is:', epoch+1)\n",
    "        timer.start()\n",
    "        net.train()\n",
    "        ttd_epoch, forward_epoch, loss_epoch, backward_epoch, optimization_epoch, testtime_epoch= 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "        layer_epoch = np.zeros((len(LayerName), 1)) # store the total running time of each layer in one epoch\n",
    "        metric = d2l.Accumulator(3)  # train_loss, train_acc, num_examples   \n",
    "        # start the nvidia-smi command\n",
    "        with open('gpu_power_usage.csv', 'w') as file:\n",
    "            # Start the nvidia-smi command\n",
    "            nvidia_smi_process = subprocess.Popen(\n",
    "                [\"nvidia-smi\", \"--query-gpu=power.draw\", \"--format=csv\", \"--loop-ms=1000\"],\n",
    "                stdout=file,  # Redirect the output directly to the file\n",
    "                stderr=subprocess.PIPE,\n",
    "                text=True)\n",
    "        train_timer.start()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            batch_block_num = 0\n",
    "            # print('The batch is:', i+1)\n",
    "            optimizer.zero_grad()\n",
    "            # to device\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            ttd_timer.start()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            ttd_epoch += ttd_timer.stop()\n",
    "            # forward\n",
    "            forward_timer.start()\n",
    "            y_hat = X\n",
    "            for num, layer in net.named_children():\n",
    "                layername = layer.__class__.__name__\n",
    "                if layername == 'Sequential':\n",
    "                    for sublayernum, sublayer in layer.named_children():\n",
    "                        sublayername = sublayer.__class__.__name__\n",
    "                        Layer_label = f'{layername[0]}{num}_{sublayername[0]}{sublayernum}'\n",
    "                        layer_index = LayerName.index(Layer_label)\n",
    "                        # print('The layer index is:', layer_index, 'The layer label is:', Layer_label)\n",
    "                        layer_timer.start()\n",
    "                        y_hat = sublayer(y_hat)\n",
    "                        torch.cuda.synchronize()\n",
    "                        layer_epoch[layer_index] += layer_timer.stop()\n",
    "            torch.cuda.synchronize()\n",
    "            forward_epoch += forward_timer.stop()\n",
    "            # loss\n",
    "            loss_timer.start()\n",
    "            l = loss_fn(y_hat, y)\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            loss_epoch += loss_timer.stop()\n",
    "            # backward\n",
    "            backward_timer.start()\n",
    "            l.backward()\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            backward_epoch += backward_timer.stop()\n",
    "            # optimize\n",
    "            optimizer_timer.start()\n",
    "            optimizer.step()\n",
    "            torch.cuda.synchronize()  # 等待数据传输完成\n",
    "            optimization_epoch += optimizer_timer.stop()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l*X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            train_acc = metric[1] / metric[2]\n",
    "        train_epoch = train_timer.stop()\n",
    "        test_timer.start()\n",
    "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n",
    "        testtime_epoch = test_timer.stop()\n",
    "        print(f'train acc {train_acc:.3f}, test acc {test_acc:.3f}')\n",
    "        print('epoch %d, time %f sec' % (epoch+1, timer.sum()))\n",
    "        # store the time and acc data\n",
    "        Epoch_time[epoch] = timer.stop()\n",
    "        print(f'The total time of the {epoch} is:', Epoch_time[epoch])\n",
    "        Layers_time[:, epoch] = layer_epoch.flatten()\n",
    "        Train_part_time[:, epoch] = ttd_epoch, forward_epoch, loss_epoch, backward_epoch, optimization_epoch, testtime_epoch\n",
    "        print(ttd_epoch, forward_epoch, loss_epoch, backward_epoch, optimization_epoch, testtime_epoch)\n",
    "        print('*'*50)\n",
    "        print(testtime_epoch)\n",
    "        Train_acc[epoch] = train_acc\n",
    "        Test_acc[epoch] = test_acc\n",
    "        # stop the nvidia-smi command\n",
    "        nvidia_smi_process.terminate()\n",
    "        # calculate the energy consumption of each epoch\n",
    "        GPU_df = pd.read_csv('gpu_power_usage.csv')\n",
    "        for row in range(len(GPU_df)):\n",
    "            GPU_df.iloc[row,0] = GPU_df.iloc[row,0].replace(' W','')\n",
    "        Consumption_df = GPU_df.astype(float)  \n",
    "        EnergyDatai = Consumption_df.iloc[:,0].values # 将数据转换为numpy数组\n",
    "        # store the energy data\n",
    "        Epoch_energy[epoch,0] = EnergyDatai\n",
    "    return Layers_time, Train_part_time, Train_acc, Test_acc, Epoch_time, Epoch_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_f(main_folder, batch_size, num_epochs, round, lr, device, LayerName):\n",
    "    print(f'The epoch is set: {num_epochs}, batch is set: {batch_size}, is in {round+1}th running')\n",
    "    # create the folder to store the data\n",
    "    epoch_batch_folder = main_folder/f'E{num_epochs}_B{batch_size}_R{round}'\n",
    "    # 判断文件是否存在\n",
    "    if epoch_batch_folder.exists():\n",
    "        print(\"文件存在。\")\n",
    "    else:\n",
    "        os.makedirs(epoch_batch_folder)\n",
    "        print(\"文件不存在，已创建。\")\n",
    "        print(\"文件创建于：\", epoch_batch_folder)\n",
    "    train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n",
    "    # show the shape of the data\n",
    "    list_of_i = []\n",
    "    for i, (X, y) in enumerate(train_iter):\n",
    "        if i < 3:\n",
    "            print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "        else:\n",
    "            pass\n",
    "        list_of_i.append(i)\n",
    "    print(f'The number of batches is: {np.array(list_of_i).shape}')\n",
    "    Layers_time, Train_part_time, Train_acc, Test_acc, \\\n",
    "        Epoch_time, Epoch_energy = train_func(googlenet_f, train_iter, test_iter, LayerName, num_epochs, lr, device)\n",
    "    # save the data\n",
    "    np.save(epoch_batch_folder/'Layers_time.npy', Layers_time)\n",
    "    np.save(epoch_batch_folder/'Train_part_time.npy', Train_part_time)\n",
    "    np.save(epoch_batch_folder/'Train_acc.npy', Train_acc)\n",
    "    np.save(epoch_batch_folder/'Test_acc.npy', Test_acc)\n",
    "    np.save(epoch_batch_folder/'Epoch_time.npy', Epoch_time)\n",
    "    np.save(epoch_batch_folder/'Epoch_energy.npy', Epoch_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_c(main_folder, batch_size, num_epochs, round, lr, device, LayerName):\n",
    "    print(f'The epoch is set: {num_epochs}, batch is set: {batch_size}, is in {round+1}th running')\n",
    "    # create the folder to store the data\n",
    "    epoch_batch_folder = main_folder/f'E{num_epochs}_B{batch_size}_R{round}'\n",
    "    # 判断文件是否存在\n",
    "    if epoch_batch_folder.exists():\n",
    "        print(\"文件存在。\")\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(epoch_batch_folder)\n",
    "        print(\"文件不存在，已创建。\")\n",
    "        print(\"文件创建于：\", epoch_batch_folder)\n",
    "        train_iter, test_iter = load_data_cifar100(batch_size, resize=224)\n",
    "        # show the shape of the data\n",
    "        list_of_i = []\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            if i < 3:\n",
    "                print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "            else:\n",
    "                pass\n",
    "            list_of_i.append(i)\n",
    "        print(f'The number of batches is: {np.array(list_of_i).shape}')\n",
    "        Layers_time, Train_part_time, Train_acc, Test_acc, \\\n",
    "            Epoch_time, Epoch_energy = train_func(googlenet_c, train_iter, test_iter, LayerName, num_epochs, lr, device)\n",
    "        # save the data\n",
    "        np.save(epoch_batch_folder/'Layers_time.npy', Layers_time)\n",
    "        np.save(epoch_batch_folder/'Train_part_time.npy', Train_part_time)\n",
    "        np.save(epoch_batch_folder/'Train_acc.npy', Train_acc)\n",
    "        np.save(epoch_batch_folder/'Test_acc.npy', Test_acc)\n",
    "        np.save(epoch_batch_folder/'Epoch_time.npy', Epoch_time)\n",
    "        np.save(epoch_batch_folder/'Epoch_energy.npy', Epoch_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is: cuda\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('The device is:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder is: /home/yj/FinalThesis/GreenAI/Cloud/3060_95W/Data/googlenet/fashion_mnist\n",
      "文件存在。\n",
      "The epoch is set: 3, batch is set: 64, is in 1th running\n",
      "文件不存在，已创建。\n",
      "文件创建于： /home/yj/FinalThesis/GreenAI/Cloud/3060_95W/Data/googlenet/fashion_mnist/E3_B64_R0\n",
      "the shape of the 0 batch of the train_iter is: torch.Size([64, 1, 224, 224])\n",
      "the shape of the 1 batch of the train_iter is: torch.Size([64, 1, 224, 224])\n",
      "the shape of the 2 batch of the train_iter is: torch.Size([64, 1, 224, 224])\n",
      "The number of batches is: (938,)\n",
      "training on cuda\n",
      "The epoch is: 1\n",
      "train acc 0.126, test acc 0.100\n",
      "epoch 1, time 0.000000 sec\n",
      "The total time of the 0 is: 157.62592697143555\n",
      "2.1713356971740723 47.664056062698364 0.14585590362548828 94.64549326896667 0.6119422912597656 8.778051137924194\n",
      "**************************************************\n",
      "8.778051137924194\n",
      "The epoch is: 2\n",
      "train acc 0.435, test acc 0.172\n",
      "epoch 2, time 157.625927 sec\n",
      "The total time of the 1 is: 155.68332862854004\n",
      "2.1457364559173584 45.686789989471436 0.14434313774108887 94.79268598556519 0.5922157764434814 8.718846082687378\n",
      "**************************************************\n",
      "8.718846082687378\n",
      "The epoch is: 3\n",
      "train acc 0.604, test acc 0.288\n",
      "epoch 3, time 313.309256 sec\n",
      "The total time of the 2 is: 156.59564638137817\n",
      "2.1716208457946777 45.90330147743225 0.14947056770324707 95.21187233924866 0.6248879432678223 8.748314380645752\n",
      "**************************************************\n",
      "8.748314380645752\n"
     ]
    }
   ],
   "source": [
    "# create the folder to store the data\n",
    "main_folder = data_path/'fashion_mnist'\n",
    "print('The folder is:', main_folder)\n",
    "# find out that if the folder exists in the data path\n",
    "# 判断文件是否存在\n",
    "if main_folder.exists():\n",
    "    print(\"文件存在。\")\n",
    "else:\n",
    "    os.makedirs(main_folder)\n",
    "    print(\"文件不存在，已创建。\")\n",
    "    print(\"文件创建于：\", main_folder)\n",
    "for epoch in epochs:\n",
    "    for batch in batch_size:\n",
    "        for round in range(rounds):\n",
    "            train_model_f(main_folder, batch, epoch, round, lr, device, LayerName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder is: /home/yj/FinalThesis/GreenAI/Cloud/3060_95W/Data/googlenet/cifar100\n",
      "文件存在。\n",
      "The epoch is set: 3, batch is set: 64, is in 1th running\n",
      "文件不存在，已创建。\n",
      "文件创建于： /home/yj/FinalThesis/GreenAI/Cloud/3060_95W/Data/googlenet/cifar100/E3_B64_R0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "the shape of the 0 batch of the train_iter is: torch.Size([64, 3, 224, 224])\n",
      "the shape of the 1 batch of the train_iter is: torch.Size([64, 3, 224, 224])\n",
      "the shape of the 2 batch of the train_iter is: torch.Size([64, 3, 224, 224])\n",
      "The number of batches is: (782,)\n",
      "training on cuda\n",
      "The epoch is: 1\n",
      "train acc 0.009, test acc 0.010\n",
      "epoch 1, time 0.000000 sec\n",
      "The total time of the 0 is: 143.42274570465088\n",
      "4.934983253479004 38.953015089035034 0.13251733779907227 82.21806216239929 0.47989678382873535 10.20368218421936\n",
      "**************************************************\n",
      "10.20368218421936\n",
      "The epoch is: 2\n",
      "train acc 0.011, test acc 0.010\n",
      "epoch 2, time 143.422746 sec\n",
      "The total time of the 1 is: 143.5196189880371\n",
      "4.926351547241211 38.96824407577515 0.12880468368530273 82.22916221618652 0.4844636917114258 10.215012073516846\n",
      "**************************************************\n",
      "10.215012073516846\n",
      "The epoch is: 3\n",
      "train acc 0.009, test acc 0.010\n",
      "epoch 3, time 286.942365 sec\n",
      "The total time of the 2 is: 143.8328697681427\n",
      "4.922002792358398 39.09334588050842 0.13437914848327637 82.40031623840332 0.4962797164916992 10.22028112411499\n",
      "**************************************************\n",
      "10.22028112411499\n"
     ]
    }
   ],
   "source": [
    "# create the folder to store the data\n",
    "main_folder = data_path/'cifar100'\n",
    "print('The folder is:', main_folder)\n",
    "# find out that if the folder exists in the data path\n",
    "# 判断文件是否存在\n",
    "if main_folder.exists():\n",
    "    print(\"文件存在。\")\n",
    "else:\n",
    "    os.makedirs(main_folder)\n",
    "    print(\"文件不存在，已创建。\")\n",
    "    print(\"文件创建于：\", main_folder)\n",
    "for epoch in epochs:\n",
    "    for batch in batch_size:\n",
    "        for round in range(rounds):\n",
    "            train_model_c(main_folder, batch, epoch, round, lr, device, LayerName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
