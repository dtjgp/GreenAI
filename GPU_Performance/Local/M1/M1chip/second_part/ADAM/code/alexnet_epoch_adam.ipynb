{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ad276f",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 深度卷积神经网络（AlexNet）\n",
    ":label:`sec_alexnet`\n",
    "\n",
    "在LeNet提出后，卷积神经网络在计算机视觉和机器学习领域中很有名气。但卷积神经网络并没有主导这些领域。这是因为虽然LeNet在小数据集上取得了很好的效果，但是在更大、更真实的数据集上训练卷积神经网络的性能和可行性还有待研究。事实上，在上世纪90年代初到2012年之间的大部分时间里，神经网络往往被其他机器学习方法超越，如支持向量机（support vector machines）。\n",
    "\n",
    "在计算机视觉中，直接将神经网络与其他机器学习方法进行比较也许不公平。这是因为，卷积神经网络的输入是由原始像素值或是经过简单预处理（例如居中、缩放）的像素值组成的。但在使用传统机器学习方法时，从业者永远不会将原始像素作为输入。在传统机器学习方法中，计算机视觉流水线是由经过人的手工精心设计的特征流水线组成的。对于这些传统方法，大部分的进展都来自于对特征有了更聪明的想法，并且学习到的算法往往归于事后的解释。\n",
    "\n",
    "虽然上世纪90年代就有了一些神经网络加速卡，但仅靠它们还不足以开发出有大量参数的深层多通道多层卷积神经网络。此外，当时的数据集仍然相对较小。除了这些障碍，训练神经网络的一些关键技巧仍然缺失，包括启发式参数初始化、随机梯度下降的变体、非挤压激活函数和有效的正则化技术。\n",
    "\n",
    "因此，与训练*端到端*（从像素到分类结果）系统不同，经典机器学习的流水线看起来更像下面这样：\n",
    "\n",
    "1. 获取一个有趣的数据集。在早期，收集这些数据集需要昂贵的传感器（在当时最先进的图像也就100万像素）。\n",
    "2. 根据光学、几何学、其他知识以及偶然的发现，手工对特征数据集进行预处理。\n",
    "3. 通过标准的特征提取算法，如SIFT（尺度不变特征变换） :cite:`Lowe.2004`和SURF（加速鲁棒特征） :cite:`Bay.Tuytelaars.Van-Gool.2006`或其他手动调整的流水线来输入数据。\n",
    "4. 将提取的特征送入最喜欢的分类器中（例如线性模型或其它核方法），以训练分类器。\n",
    "\n",
    "当人们和机器学习研究人员交谈时，会发现机器学习研究人员相信机器学习既重要又美丽：优雅的理论去证明各种模型的性质。机器学习是一个正在蓬勃发展、严谨且非常有用的领域。然而，当人们和计算机视觉研究人员交谈，会听到一个完全不同的故事。计算机视觉研究人员会告诉一个诡异事实————推动领域进步的是数据特征，而不是学习算法。计算机视觉研究人员相信，从对最终模型精度的影响来说，更大或更干净的数据集、或是稍微改进的特征提取，比任何学习算法带来的进步要大得多。\n",
    "\n",
    "## 学习表征\n",
    "\n",
    "另一种预测这个领域发展的方法————观察图像特征的提取方法。在2012年前，图像特征都是机械地计算出来的。事实上，设计一套新的特征函数、改进结果，并撰写论文是盛极一时的潮流。SIFT :cite:`Lowe.2004`、SURF :cite:`Bay.Tuytelaars.Van-Gool.2006`、HOG（定向梯度直方图） :cite:`Dalal.Triggs.2005`、[bags of visual words](https://en.wikipedia.org/wiki/Bag-of-words_model_in_computer_vision)和类似的特征提取方法占据了主导地位。\n",
    "\n",
    "另一组研究人员，包括Yann LeCun、Geoff Hinton、Yoshua Bengio、Andrew Ng、Shun ichi Amari和Juergen Schmidhuber，想法则与众不同：他们认为特征本身应该被学习。此外，他们还认为，在合理地复杂性前提下，特征应该由多个共同学习的神经网络层组成，每个层都有可学习的参数。在机器视觉中，最底层可能检测边缘、颜色和纹理。事实上，Alex Krizhevsky、Ilya Sutskever和Geoff Hinton提出了一种新的卷积神经网络变体*AlexNet*。在2012年ImageNet挑战赛中取得了轰动一时的成绩。AlexNet以Alex Krizhevsky的名字命名，他是论文 :cite:`Krizhevsky.Sutskever.Hinton.2012`的第一作者。\n",
    "\n",
    "有趣的是，在网络的最底层，模型学习到了一些类似于传统滤波器的特征抽取器。 :numref:`fig_filters`是从AlexNet论文 :cite:`Krizhevsky.Sutskever.Hinton.2012`复制的，描述了底层图像特征。\n",
    "\n",
    "![AlexNet第一层学习到的特征抽取器。](../img/filters.png)\n",
    ":width:`400px`\n",
    ":label:`fig_filters`\n",
    "\n",
    "AlexNet的更高层建立在这些底层表示的基础上，以表示更大的特征，如眼睛、鼻子、草叶等等。而更高的层可以检测整个物体，如人、飞机、狗或飞盘。最终的隐藏神经元可以学习图像的综合表示，从而使属于不同类别的数据易于区分。尽管一直有一群执着的研究者不断钻研，试图学习视觉数据的逐级表征，然而很长一段时间里这些尝试都未有突破。深度卷积神经网络的突破出现在2012年。突破可归因于两个关键因素。\n",
    "\n",
    "### 缺少的成分：数据\n",
    "\n",
    "包含许多特征的深度模型需要大量的有标签数据，才能显著优于基于凸优化的传统方法（如线性方法和核方法）。\n",
    "然而，限于早期计算机有限的存储和90年代有限的研究预算，大部分研究只基于小的公开数据集。例如，不少研究论文基于加州大学欧文分校（UCI）提供的若干个公开数据集，其中许多数据集只有几百至几千张在非自然环境下以低分辨率拍摄的图像。这一状况在2010年前后兴起的大数据浪潮中得到改善。2009年，ImageNet数据集发布，并发起ImageNet挑战赛：要求研究人员从100万个样本中训练模型，以区分1000个不同类别的对象。ImageNet数据集由斯坦福教授李飞飞小组的研究人员开发，利用谷歌图像搜索（Google Image Search）对每一类图像进行预筛选，并利用亚马逊众包（Amazon Mechanical Turk）来标注每张图片的相关类别。这种规模是前所未有的。这项被称为ImageNet的挑战赛推动了计算机视觉和机器学习研究的发展，挑战研究人员确定哪些模型能够在更大的数据规模下表现最好。\n",
    "\n",
    "### 缺少的成分：硬件\n",
    "\n",
    "深度学习对计算资源要求很高，训练可能需要数百个迭代轮数，每次迭代都需要通过代价高昂的许多线性代数层传递数据。这也是为什么在20世纪90年代至21世纪初，优化凸目标的简单算法是研究人员的首选。然而，用GPU训练神经网络改变了这一格局。*图形处理器*（Graphics Processing Unit，GPU）早年用来加速图形处理，使电脑游戏玩家受益。GPU可优化高吞吐量的$4 \\times 4$矩阵和向量乘法，从而服务于基本的图形任务。幸运的是，这些数学运算与卷积层的计算惊人地相似。由此，英伟达（NVIDIA）和ATI已经开始为通用计算操作优化gpu，甚至把它们作为*通用GPU*（general-purpose GPUs，GPGPU）来销售。\n",
    "\n",
    "那么GPU比CPU强在哪里呢？\n",
    "\n",
    "首先，我们深度理解一下中央处理器（Central Processing Unit，CPU）的*核心*。\n",
    "CPU的每个核心都拥有高时钟频率的运行能力，和高达数MB的三级缓存（L3Cache）。\n",
    "它们非常适合执行各种指令，具有分支预测器、深层流水线和其他使CPU能够运行各种程序的功能。\n",
    "然而，这种明显的优势也是它的致命弱点：通用核心的制造成本非常高。\n",
    "它们需要大量的芯片面积、复杂的支持结构（内存接口、内核之间的缓存逻辑、高速互连等等），而且它们在任何单个任务上的性能都相对较差。\n",
    "现代笔记本电脑最多有4核，即使是高端服务器也很少超过64核，因为它们的性价比不高。\n",
    "\n",
    "相比于CPU，GPU由$100 \\sim 1000$个小的处理单元组成（NVIDIA、ATI、ARM和其他芯片供应商之间的细节稍有不同），通常被分成更大的组（NVIDIA称之为warps）。\n",
    "虽然每个GPU核心都相对较弱，有时甚至以低于1GHz的时钟频率运行，但庞大的核心数量使GPU比CPU快几个数量级。\n",
    "例如，NVIDIA最近一代的Ampere GPU架构为每个芯片提供了高达312 TFlops的浮点性能，而CPU的浮点性能到目前为止还没有超过1 TFlops。\n",
    "之所以有如此大的差距，原因其实很简单：首先，功耗往往会随时钟频率呈二次方增长。\n",
    "对于一个CPU核心，假设它的运行速度比GPU快4倍，但可以使用16个GPU核代替，那么GPU的综合性能就是CPU的$16 \\times 1/4 = 4$倍。\n",
    "其次，GPU内核要简单得多，这使得它们更节能。\n",
    "此外，深度学习中的许多操作需要相对较高的内存带宽，而GPU拥有10倍于CPU的带宽。\n",
    "\n",
    "回到2012年的重大突破，当Alex Krizhevsky和Ilya Sutskever实现了可以在GPU硬件上运行的深度卷积神经网络时，一个重大突破出现了。他们意识到卷积神经网络中的计算瓶颈：卷积和矩阵乘法，都是可以在硬件上并行化的操作。\n",
    "于是，他们使用两个显存为3GB的NVIDIA GTX580 GPU实现了快速卷积运算。他们的创新[cuda-convnet](https://code.google.com/archive/p/cuda-convnet/)几年来它一直是行业标准，并推动了深度学习热潮。\n",
    "\n",
    "## AlexNet\n",
    "\n",
    "2012年，AlexNet横空出世。它首次证明了学习到的特征可以超越手工设计的特征。它一举打破了计算机视觉研究的现状。\n",
    "AlexNet使用了8层卷积神经网络，并以很大的优势赢得了2012年ImageNet图像识别挑战赛。\n",
    "\n",
    "AlexNet和LeNet的架构非常相似，如 :numref:`fig_alexnet`所示。\n",
    "注意，本书在这里提供的是一个稍微精简版本的AlexNet，去除了当年需要两个小型GPU同时运算的设计特点。\n",
    "\n",
    "![从LeNet（左）到AlexNet（右）](../img/alexnet.svg)\n",
    ":label:`fig_alexnet`\n",
    "\n",
    "AlexNet和LeNet的设计理念非常相似，但也存在显著差异。\n",
    "\n",
    "1. AlexNet比相对较小的LeNet5要深得多。AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。\n",
    "2. AlexNet使用ReLU而不是sigmoid作为其激活函数。\n",
    "\n",
    "下面的内容将深入研究AlexNet的细节。\n",
    "\n",
    "### 模型设计\n",
    "\n",
    "在AlexNet的第一层，卷积窗口的形状是$11\\times11$。\n",
    "由于ImageNet中大多数图像的宽和高比MNIST图像的多10倍以上，因此，需要一个更大的卷积窗口来捕获目标。\n",
    "第二层中的卷积窗口形状被缩减为$5\\times5$，然后是$3\\times3$。\n",
    "此外，在第一层、第二层和第五层卷积层之后，加入窗口形状为$3\\times3$、步幅为2的最大汇聚层。\n",
    "而且，AlexNet的卷积通道数目是LeNet的10倍。\n",
    "\n",
    "在最后一个卷积层后有两个全连接层，分别有4096个输出。\n",
    "这两个巨大的全连接层拥有将近1GB的模型参数。\n",
    "由于早期GPU显存有限，原版的AlexNet采用了双数据流设计，使得每个GPU只负责存储和计算模型的一半参数。\n",
    "幸运的是，现在GPU显存相对充裕，所以现在很少需要跨GPU分解模型（因此，本书的AlexNet模型在这方面与原始论文稍有不同）。\n",
    "\n",
    "### 激活函数\n",
    "\n",
    "此外，AlexNet将sigmoid激活函数改为更简单的ReLU激活函数。\n",
    "一方面，ReLU激活函数的计算更简单，它不需要如sigmoid激活函数那般复杂的求幂运算。\n",
    "另一方面，当使用不同的参数初始化方法时，ReLU激活函数使训练模型更加容易。\n",
    "当sigmoid激活函数的输出非常接近于0或1时，这些区域的梯度几乎为0，因此反向传播无法继续更新一些模型参数。\n",
    "相反，ReLU激活函数在正区间的梯度总是1。\n",
    "因此，如果模型参数没有正确初始化，sigmoid函数可能在正区间内得到几乎为0的梯度，从而使模型无法得到有效的训练。\n",
    "\n",
    "### 容量控制和预处理\n",
    "\n",
    "AlexNet通过暂退法（ :numref:`sec_dropout`）控制全连接层的模型复杂度，而LeNet只使用了权重衰减。\n",
    "为了进一步扩充数据，AlexNet在训练时增加了大量的图像增强数据，如翻转、裁切和变色。\n",
    "这使得模型更健壮，更大的样本量有效地减少了过拟合。\n",
    "在 :numref:`sec_image_augmentation`中更详细地讨论数据扩增。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7ae34b7",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import time\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "net = nn.Sequential(\n",
    "    # 这里使用一个11*11的更大窗口来捕捉对象。\n",
    "    # 同时，步幅为4，以减少输出的高度和宽度。\n",
    "    # 另外，输出通道的数目远大于LeNet\n",
    "    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 使用三个连续的卷积层和较小的卷积窗口。\n",
    "    # 除了最后的卷积层，输出通道的数量进一步增加。\n",
    "    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Flatten(),\n",
    "    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合\n",
    "    nn.Linear(6400, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "    nn.Linear(4096, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d97a07",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "[**我们构造一个**]高度和宽度都为224的(**单通道数据，来观察每一层输出的形状**)。\n",
    "它与 :numref:`fig_alexnet`中的AlexNet架构相匹配。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37a7ec36",
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 96, 54, 54])\n",
      "ReLU output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 26, 26])\n",
      "ReLU output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 256, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 5, 5])\n",
      "Flatten output shape:\t torch.Size([1, 6400])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1, 1, 224, 224)\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c79a7",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "## 读取数据集\n",
    "\n",
    "尽管原文中AlexNet是在ImageNet上进行训练的，但本书在这里使用的是Fashion-MNIST数据集。因为即使在现代GPU上，训练ImageNet模型，同时使其收敛可能需要数小时或数天的时间。\n",
    "将AlexNet直接应用于Fashion-MNIST的一个问题是，[**Fashion-MNIST图像的分辨率**]（$28 \\times 28$像素）(**低于ImageNet图像。**)\n",
    "为了解决这个问题，(**我们将它们增加到$224 \\times 224$**)（通常来讲这不是一个明智的做法，但在这里这样做是为了有效使用AlexNet架构）。\n",
    "这里需要使用`d2l.load_data_fashion_mnist`函数中的`resize`参数执行此调整。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c1552a8",
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the train_iter is: (469,)\n",
      "the shape of the 0 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 1 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 2 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 3 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 4 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 5 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 6 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 7 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 8 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n",
      "the shape of the 9 batch of the train_iter is: torch.Size([128, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "# print the shape of the train_iter\n",
    "list_of_i = []\n",
    "for i, (X, y) in enumerate(train_iter):\n",
    "    list_of_i.append(i)\n",
    "\n",
    "print('the shape of the train_iter is:', np.array(list_of_i).shape)\n",
    "# print(list_of_i)\n",
    "# print the first 10 batch of the train_iter\n",
    "for i, (X, y) in enumerate(train_iter):\n",
    "    if i < 10:\n",
    "        print('the shape of the', i, 'batch of the train_iter is:', X.shape)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d484d7f3",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "## [**训练AlexNet**]\n",
    "\n",
    "现在AlexNet可以开始被训练了。与 :numref:`sec_lenet`中的LeNet相比，这里的主要变化是使用更小的学习速率训练，这是因为网络更深更广、图像分辨率更高，训练卷积神经网络就更昂贵。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "516c82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_powermetrics(file_path):\n",
    "    \"\"\"\n",
    "    Run powermetrics and retrieve the output.\n",
    "    :param interval: Sampling interval in milliseconds.\n",
    "    :param count: Number of samples to retrieve.s\n",
    "    :return: The output from powermetrics.\n",
    "    \"\"\"\n",
    "    # Define the command as a list of arguments\n",
    "    cmd = [\"sudo\", \"powermetrics\",  \"-i\", \"1000\", \"--samplers\", \"cpu_power,gpu_power\", \"-a\", \"1\", \"-o\", file_path]\n",
    "    process = subprocess.Popen(cmd)\n",
    "    return process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89638b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_data_process(file_path):\n",
    "    \"\"\"\n",
    "    Read the output file of powermetric and extract the power value\n",
    "    :param file_path: The path of the output file of powermetric.\n",
    "    :return: The list of power values.\n",
    "    \"\"\"\n",
    "    list_power = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Combined Power' in line:\n",
    "                power_value = line.split(':')[1].strip()\n",
    "                # print(power_value)\n",
    "                # Remove the unit\n",
    "                power_value = power_value.replace('mW', '')\n",
    "                # Convert to integer\n",
    "                power_value = int(power_value)\n",
    "                list_power.append(power_value)\n",
    "    '''\n",
    "    The data from list_power is the Conbined Power of each second.\n",
    "    The data is the Power of each second.\n",
    "    we need to calculate the energy consumption of the whole process.\n",
    "    and need to change the J to kWh.\n",
    "    '''\n",
    "    # calculate the energy consumption\n",
    "    energy_consumption = 0\n",
    "    for i in range(len(list_power)):\n",
    "       energy_consumption += list_power[i]\n",
    "    # change the mW to W\n",
    "    energy_consumption = energy_consumption / 1000\n",
    "    # calculate the energy consumption, the interval is 1 second, and the energy unit is J\n",
    "    energy_consumption = energy_consumption * 1\n",
    "    # change the J to kWh\n",
    "    energy_consumption = energy_consumption / 3600000\n",
    "    return energy_consumption, list_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41bfa77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_file = 'energy_alexnet.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "对train_ch6()函数进行修改，使得能够在每一层的前向传播的时候，记录下时间, \n",
    "能耗部分不好进行具体统计，因为每个层的能耗有区别，并且时间过短，所以采用的方式为计算总能耗和总时长，最后通过平均值来计算估算的能耗\n",
    "'''\n",
    "def train_ch6self(net, train_iter, test_iter, num_epochs, lr, device, energy_file):\n",
    "    def init_weights(m): # 初始化权重\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    # set a list of layer name\n",
    "    list_layer_name = ['Conv2d','ReLU','MaxPool2d','Linear','Dropout','Flatten'] # 该模型中包括的所有的层的名字\n",
    "    # create a numpy array to store the time and energy consumption, the shape is (num_epochs, len(list_layer_name), 2)\n",
    "    # for each epoch, the shape is (6,2), contains the total time and the energy consumption of each layer\n",
    "    timeenergy_data_forward = np.zeros((num_epochs, len(list_layer_name), 2)) \n",
    "    # for each epoch, the shape is (6,2), contains the total time of each part in a round, which is to_device, forward, loss, backward, optimizer，test_round\n",
    "    # and the 2 means time and energy consumption, respectively\n",
    "    timeenergy_data_round = np.zeros((num_epochs, 6, 2)) \n",
    "    # create another numpy array to store the data of each epoch, 1 column is training loss, 2 column is training accuracy, 3 column is test accuracy\n",
    "    acc_data = []\n",
    "    # create a numpy array to store the train loss and train accuracy\n",
    "    train_l = []\n",
    "    train_acc = []\n",
    "    # create a numpy array to store the epoch and running time\n",
    "    time_data_epoch = np.zeros((num_epochs, 2))\n",
    "    # create a numpy array to store the energy consumption of each epoch\n",
    "    energy_data_epoch = np.zeros((num_epochs, 1), dtype=object)\n",
    "    # print the training device\n",
    "    print('training on', device)\n",
    "    net.to(device) # 将模型放到对应的设备上\n",
    "    # 初始化optimizer和loss\n",
    "    # change the optimizer to adam\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    # 初始化计时器\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)   \n",
    "    # 开始训练\n",
    "    for epoch in range(num_epochs):\n",
    "        print('epoch %d' % (epoch + 1))\n",
    "        # each epoch, set a timer to record the time\n",
    "        timer.start()\n",
    "        powermetrics_process = run_powermetrics(energy_file)\n",
    "        net.train() # 设置为训练模式\n",
    "        # 初始化每个epoch的统计时间的变量\n",
    "        time_to_device_cost, time_forward, time_cost_loss = 0,0,0\n",
    "        time_cost_backward, time_cost_optimizer, time_test_acc_cost = 0,0,0\n",
    "        train_l_epoch = []\n",
    "        train_acc_epoch = []\n",
    "        metric = d2l.Accumulator(3)\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            print('round %d' % (i))\n",
    "            time_round_start = time.time() # 计算每一轮的时间s\n",
    "            optimizer.zero_grad() # 将optimizer的梯度清零s\n",
    "        ##################################################################################\n",
    "            # 计算将数据放到对应的设备上的时间\n",
    "            time_to_device_cost_i = 0\n",
    "            time_to_device = time.time()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            time_to_device_end = time.time()\n",
    "            time_to_device_cost_i = time_to_device_end - time_to_device\n",
    "            print('time to device %f sec' % (time_to_device_cost_i))\n",
    "            time_to_device_cost += time_to_device_cost_i\n",
    "        ##################################################################################\n",
    "            # 将原本的模型进行修改，使得能够逐层进行运行，并且在这个过程中，记录下时间和能量\n",
    "            y_hat = X\n",
    "            for layer in net:\n",
    "                time_cost_layer = 0\n",
    "                layer_name = layer.__class__.__name__ # 获取层的名字\n",
    "                # find out the layer name is in where of the list\n",
    "                layer_index = list_layer_name.index(layer_name)\n",
    "                # calculate the time\n",
    "                time_start_layer = time.time()\n",
    "                y_hat = layer(y_hat)\n",
    "                time_end_layer = time.time()\n",
    "                time_cost_layer = time_end_layer - time_start_layer\n",
    "                timeenergy_data_forward[epoch,layer_index,0] += time_cost_layer\n",
    "                if torch.isinf(y_hat).any() or torch.isnan(y_hat).any():\n",
    "                    print(\"Inf or NaN detected in y_hat\")\n",
    "            # 计算前向的时间\n",
    "            time_forward = np.sum(timeenergy_data_forward[epoch,:,0])\n",
    "            print('time forward %f sec' % (time_forward))\n",
    "        ##################################################################################\n",
    "            # 计算loss\n",
    "            time_cost_loss_i = 0 # 初始化loss的时间\n",
    "            time_start_loss = time.time()\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            # print(loss)\n",
    "            time_end_loss = time.time()\n",
    "            time_cost_loss_i = time_end_loss - time_start_loss\n",
    "            print('loss time %f sec' % (time_cost_loss_i))\n",
    "            time_cost_loss += time_cost_loss_i\n",
    "        ##################################################################################\n",
    "            # 计算backward\n",
    "            time_cost_backward_i = 0 # 初始化backward的时间\n",
    "            time_start_backward = time.time()\n",
    "            loss.backward()\n",
    "            time_end_backward = time.time()\n",
    "            time_cost_backward_i = time_end_backward - time_start_backward\n",
    "            print('backward time %f sec' % (time_cost_backward_i))\n",
    "            time_cost_backward += time_cost_backward_i\n",
    "        ##################################################################################\n",
    "            # 计算optimizer\n",
    "            time_cost_optimizer_i = 0 # 初始化optimizer的时间\n",
    "            time_start_optimizer = time.time()\n",
    "            optimizer.step()\n",
    "            time_end_optimizer = time.time()\n",
    "            time_cost_optimizer_i = time_end_optimizer - time_start_optimizer\n",
    "            print('optimizer time %f sec' % (time_cost_optimizer_i))\n",
    "            time_cost_optimizer += time_cost_optimizer_i\n",
    "        ##################################################################################\n",
    "            time_round_end = time.time()\n",
    "            time_round_cost = time_round_end - time_round_start\n",
    "            print(f'training time in round {i} cost {time_round_cost} sec')\n",
    "        ##################################################################################\n",
    "            with torch.no_grad():\n",
    "                metric.add(loss * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            train_l_i = metric[0] / metric[2]\n",
    "            train_acc_i = metric[1] / metric[2]\n",
    "            train_l_epoch.append(train_l_i)\n",
    "            train_acc_epoch.append(train_acc_i)\n",
    "            print('loss %f, train acc %f' % (train_l_i, train_acc_i))\n",
    "        train_l.append(train_l_epoch)\n",
    "        train_acc.append(train_acc_epoch)\n",
    "        ##################################################################################\n",
    "        # 进行模型的test部分运行\n",
    "        time_test_acc_cost_epoch = 0\n",
    "        time_test_acc_start = time.time()\n",
    "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter, device)\n",
    "        time_test_acc_end = time.time()\n",
    "        time_test_acc_cost_epoch = time_test_acc_end - time_test_acc_start\n",
    "        time_test_acc_cost += time_test_acc_cost_epoch\n",
    "        print('test acc is %f' % (test_acc))\n",
    "        acc_data.append(test_acc)\n",
    "        ##################################################################################\n",
    "        # 将每一轮的每个部分的时间加入到time_data_round中\n",
    "        timeenergy_data_round[epoch,0,0] = time_to_device_cost\n",
    "        timeenergy_data_round[epoch,1,0] = time_forward\n",
    "        timeenergy_data_round[epoch,2,0] = time_cost_loss\n",
    "        timeenergy_data_round[epoch,3,0] = time_cost_backward\n",
    "        timeenergy_data_round[epoch,4,0] = time_cost_optimizer\n",
    "        timeenergy_data_round[epoch,5,0] = time_test_acc_cost\n",
    "        ##################################################################################\n",
    "        # stop the powermetrics\n",
    "        powermetrics_process.terminate()\n",
    "        powermetrics_process.wait()\n",
    "        timer.stop() # 停止计时 \n",
    "        time_data_epoch[epoch,0] = epoch + 1\n",
    "        time_data_epoch[epoch,1] = timer.sum()\n",
    "        print('epoch %d, time %f sec' % (epoch, timer.sum()))\n",
    "        ##################################################################################\n",
    "        # calculate the energy consumption of each layer\n",
    "        energy_consumption, power_list_model = txt_data_process(energy_file)\n",
    "        training_time_epoch_record = len(power_list_model)\n",
    "        energy_consumption_J = energy_consumption * 3600000\n",
    "        avg_energy_cost_persec = energy_consumption_J / training_time_epoch_record  # 计算每秒的平均能耗\n",
    "        ##################################################################################\n",
    "        # 将每一轮的每个部分的能耗加入到time_data_forward中\n",
    "        for l in range(len(timeenergy_data_forward[epoch,:,0])):\n",
    "            timeenergy_data_forward[epoch, l, 1] = timeenergy_data_forward[epoch, l, 0] * avg_energy_cost_persec\n",
    "        # 将每一轮的每个部分的能耗加入到time_data_round中\n",
    "        for m in range(len(timeenergy_data_round[epoch,:,0])):\n",
    "            timeenergy_data_round[epoch, m, 1] = timeenergy_data_round[epoch, m, 0] * avg_energy_cost_persec\n",
    "        ##################################################################################\n",
    "        # 对采集到的能耗数据进行保存\n",
    "        energy_data_epoch[epoch,0] = power_list_model\n",
    "        \n",
    "    return timeenergy_data_forward, timeenergy_data_round, acc_data, train_l, train_acc, time_data_epoch, energy_data_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on mps\n",
      "epoch 1\n",
      "round 0\n",
      "time to device 0.036882 sec\n",
      "time forward 0.017124 sec\n",
      "loss time 0.002057 sec\n",
      "backward time 0.018350 sec\n",
      "optimizer time 0.076033 sec\n",
      "training time in round 0 cost 1.0825841426849365 sec\n",
      "loss 2.304794, train acc 0.062500\n",
      "round 1\n",
      "time to device 0.006532 sec\n",
      "time forward 0.024554 sec\n",
      "loss time 0.000383 sec\n",
      "backward time 0.003320 sec\n",
      "optimizer time 0.012678 sec\n",
      "training time in round 1 cost 0.35935068130493164 sec\n",
      "loss 849926.152397, train acc 0.070312\n",
      "round 2\n",
      "time to device 0.006919 sec\n",
      "time forward 0.034907 sec\n",
      "loss time 0.001168 sec\n",
      "backward time 0.010762 sec\n",
      "optimizer time 0.021667 sec\n",
      "training time in round 2 cost 0.4035778045654297 sec\n",
      "loss 566665.081446, train acc 0.065104\n",
      "round 3\n",
      "time to device 0.007781 sec\n",
      "time forward 0.047407 sec\n",
      "loss time 0.001050 sec\n",
      "backward time 0.013162 sec\n",
      "optimizer time 0.025294 sec\n",
      "training time in round 3 cost 0.4146902561187744 sec\n",
      "loss 425108.573597, train acc 0.078125\n",
      "round 4\n",
      "time to device 0.007340 sec\n",
      "time forward 0.058058 sec\n",
      "loss time 0.001191 sec\n",
      "backward time 0.015020 sec\n",
      "optimizer time 0.027186 sec\n",
      "training time in round 4 cost 0.4185168743133545 sec\n",
      "loss 340452.807852, train acc 0.075000\n",
      "round 5\n",
      "time to device 0.006800 sec\n",
      "time forward 0.070445 sec\n",
      "loss time 0.001004 sec\n",
      "backward time 0.012030 sec\n",
      "optimizer time 0.027319 sec\n",
      "training time in round 5 cost 0.417935848236084 sec\n",
      "loss 283726.492561, train acc 0.080729\n",
      "round 6\n",
      "time to device 0.007370 sec\n",
      "time forward 0.082767 sec\n",
      "loss time 0.001874 sec\n",
      "backward time 0.014383 sec\n",
      "optimizer time 0.027211 sec\n",
      "training time in round 6 cost 0.41544389724731445 sec\n",
      "loss 243207.888869, train acc 0.083705\n",
      "round 7\n",
      "time to device 0.006670 sec\n",
      "time forward 0.095036 sec\n",
      "loss time 0.001078 sec\n",
      "backward time 0.010198 sec\n",
      "optimizer time 0.025531 sec\n",
      "training time in round 7 cost 0.411574125289917 sec\n",
      "loss 214436.846608, train acc 0.086914\n",
      "round 8\n",
      "time to device 0.007156 sec\n",
      "time forward 0.105486 sec\n",
      "loss time 0.002060 sec\n",
      "backward time 0.016438 sec\n",
      "optimizer time 0.027690 sec\n",
      "training time in round 8 cost 0.4110238552093506 sec\n",
      "loss 190637.868663, train acc 0.092014\n",
      "round 9\n",
      "time to device 0.007274 sec\n",
      "time forward 0.119014 sec\n",
      "loss time 0.001207 sec\n",
      "backward time 0.013122 sec\n",
      "optimizer time 0.030006 sec\n",
      "training time in round 9 cost 0.40807008743286133 sec\n",
      "loss 171621.403245, train acc 0.092188\n",
      "round 10\n",
      "time to device 0.006478 sec\n",
      "time forward 0.131489 sec\n",
      "loss time 0.001020 sec\n",
      "backward time 0.018148 sec\n",
      "optimizer time 0.023297 sec\n",
      "training time in round 10 cost 0.4124622344970703 sec\n",
      "loss 156071.394751, train acc 0.093750\n",
      "round 11\n",
      "time to device 0.007006 sec\n",
      "time forward 0.143074 sec\n",
      "loss time 0.001887 sec\n",
      "backward time 0.011955 sec\n",
      "optimizer time 0.028015 sec\n",
      "training time in round 11 cost 0.4098548889160156 sec\n",
      "loss 143160.265918, train acc 0.093099\n",
      "round 12\n",
      "time to device 0.006580 sec\n",
      "time forward 0.158714 sec\n",
      "loss time 0.001249 sec\n",
      "backward time 0.013450 sec\n",
      "optimizer time 0.026553 sec\n",
      "training time in round 12 cost 0.41109585762023926 sec\n",
      "loss 132227.308451, train acc 0.093149\n",
      "round 13\n",
      "time to device 0.006626 sec\n",
      "time forward 0.170858 sec\n",
      "loss time 0.001105 sec\n",
      "backward time 0.012299 sec\n",
      "optimizer time 0.026755 sec\n",
      "training time in round 13 cost 0.3961069583892822 sec\n",
      "loss 122855.234295, train acc 0.094308\n",
      "round 14\n",
      "time to device 0.007174 sec\n",
      "time forward 0.183702 sec\n",
      "loss time 0.001038 sec\n",
      "backward time 0.011339 sec\n",
      "optimizer time 0.029077 sec\n",
      "training time in round 14 cost 0.4006168842315674 sec\n",
      "loss 114719.034329, train acc 0.094271\n",
      "round 15\n",
      "time to device 0.003577 sec\n",
      "time forward 0.198703 sec\n",
      "loss time 0.001964 sec\n",
      "backward time 0.016450 sec\n",
      "optimizer time 0.023987 sec\n",
      "training time in round 15 cost 0.39853787422180176 sec\n",
      "loss 107581.922869, train acc 0.095703\n",
      "round 16\n",
      "time to device 0.003651 sec\n",
      "time forward 0.210085 sec\n",
      "loss time 0.001167 sec\n",
      "backward time 0.014268 sec\n",
      "optimizer time 0.027393 sec\n",
      "training time in round 16 cost 0.390305757522583 sec\n",
      "loss 101269.008836, train acc 0.094669\n",
      "round 17\n",
      "time to device 0.004369 sec\n",
      "time forward 0.222566 sec\n",
      "loss time 0.001324 sec\n",
      "backward time 0.012833 sec\n",
      "optimizer time 0.027179 sec\n",
      "training time in round 17 cost 0.39157891273498535 sec\n",
      "loss 95648.094877, train acc 0.095052\n",
      "round 18\n",
      "time to device 0.004004 sec\n",
      "time forward 0.234063 sec\n",
      "loss time 0.001252 sec\n",
      "backward time 0.018523 sec\n",
      "optimizer time 0.032104 sec\n",
      "training time in round 18 cost 0.41655802726745605 sec\n",
      "loss 90615.279995, train acc 0.094984\n",
      "round 19\n",
      "time to device 0.003825 sec\n",
      "time forward 0.247628 sec\n",
      "loss time 0.001072 sec\n",
      "backward time 0.014886 sec\n",
      "optimizer time 0.026904 sec\n",
      "training time in round 19 cost 0.4398081302642822 sec\n",
      "loss 86085.280406, train acc 0.097266\n",
      "round 20\n",
      "time to device 0.004452 sec\n",
      "time forward 0.261332 sec\n",
      "loss time 0.001898 sec\n",
      "backward time 0.012027 sec\n",
      "optimizer time 0.034024 sec\n",
      "training time in round 20 cost 0.40060901641845703 sec\n",
      "loss 81987.579135, train acc 0.097470\n",
      "round 21\n",
      "time to device 0.007073 sec\n",
      "time forward 0.272418 sec\n",
      "loss time 0.001025 sec\n",
      "backward time 0.010684 sec\n",
      "optimizer time 0.020594 sec\n",
      "training time in round 21 cost 0.3879079818725586 sec\n",
      "loss 78261.445567, train acc 0.098011\n",
      "round 22\n",
      "time to device 0.006882 sec\n",
      "time forward 0.284820 sec\n",
      "loss time 0.001045 sec\n",
      "backward time 0.024516 sec\n",
      "optimizer time 0.022347 sec\n",
      "training time in round 22 cost 0.40415501594543457 sec\n",
      "loss 74859.179495, train acc 0.098845\n",
      "round 23\n",
      "time to device 0.007942 sec\n",
      "time forward 0.297370 sec\n",
      "loss time 0.001214 sec\n",
      "backward time 0.014049 sec\n",
      "optimizer time 0.025919 sec\n",
      "training time in round 23 cost 0.4069178104400635 sec\n",
      "loss 71741.679768, train acc 0.096680\n",
      "round 24\n",
      "time to device 0.008366 sec\n",
      "time forward 0.311482 sec\n",
      "loss time 0.001714 sec\n",
      "backward time 0.016591 sec\n",
      "optimizer time 0.022250 sec\n",
      "training time in round 24 cost 0.39992499351501465 sec\n",
      "loss 68872.655364, train acc 0.096562\n",
      "round 25\n",
      "time to device 0.007418 sec\n",
      "time forward 0.325049 sec\n",
      "loss time 0.001036 sec\n",
      "backward time 0.012002 sec\n",
      "optimizer time 0.026590 sec\n",
      "training time in round 25 cost 0.39395594596862793 sec\n",
      "loss 66224.682736, train acc 0.098858\n",
      "round 26\n",
      "time to device 0.008032 sec\n",
      "time forward 0.337709 sec\n",
      "loss time 0.001217 sec\n",
      "backward time 0.012499 sec\n",
      "optimizer time 0.026504 sec\n",
      "training time in round 26 cost 0.3907151222229004 sec\n",
      "loss 63772.484202, train acc 0.098958\n",
      "round 27\n",
      "time to device 0.004294 sec\n",
      "time forward 0.349769 sec\n",
      "loss time 0.001026 sec\n",
      "backward time 0.008982 sec\n",
      "optimizer time 0.021432 sec\n",
      "training time in round 27 cost 0.38083600997924805 sec\n",
      "loss 61495.256026, train acc 0.098772\n",
      "round 28\n",
      "time to device 0.003861 sec\n",
      "time forward 0.360760 sec\n",
      "loss time 0.001395 sec\n",
      "backward time 0.019824 sec\n",
      "optimizer time 0.013085 sec\n",
      "training time in round 28 cost 0.3776092529296875 sec\n",
      "loss 59375.028538, train acc 0.098869\n",
      "round 29\n",
      "time to device 0.005091 sec\n",
      "time forward 0.371965 sec\n",
      "loss time 0.001138 sec\n",
      "backward time 0.012727 sec\n",
      "optimizer time 0.024856 sec\n",
      "training time in round 29 cost 0.4676830768585205 sec\n",
      "loss 57396.001148, train acc 0.101562\n",
      "round 30\n",
      "time to device 0.006786 sec\n",
      "time forward 0.384744 sec\n",
      "loss time 0.001187 sec\n",
      "backward time 0.012363 sec\n",
      "optimizer time 0.034240 sec\n",
      "training time in round 30 cost 0.407473087310791 sec\n",
      "loss 55546.365891, train acc 0.101815\n",
      "round 31\n",
      "time to device 0.006966 sec\n",
      "time forward 0.397989 sec\n",
      "loss time 0.001221 sec\n",
      "backward time 0.010729 sec\n",
      "optimizer time 0.028614 sec\n",
      "training time in round 31 cost 0.40535807609558105 sec\n",
      "loss 53811.184837, train acc 0.102295\n",
      "round 32\n",
      "time to device 0.008080 sec\n",
      "time forward 0.410027 sec\n",
      "loss time 0.001069 sec\n",
      "backward time 0.011348 sec\n",
      "optimizer time 0.028333 sec\n",
      "training time in round 32 cost 0.39362478256225586 sec\n",
      "loss 52181.156298, train acc 0.103220\n",
      "round 33\n",
      "time to device 0.008594 sec\n",
      "time forward 0.422535 sec\n",
      "loss time 0.001258 sec\n",
      "backward time 0.021293 sec\n",
      "optimizer time 0.022838 sec\n",
      "training time in round 33 cost 0.4045748710632324 sec\n",
      "loss 50646.894175, train acc 0.103401\n",
      "round 34\n",
      "time to device 0.007378 sec\n",
      "time forward 0.437044 sec\n",
      "loss time 0.001177 sec\n",
      "backward time 0.013914 sec\n",
      "optimizer time 0.025529 sec\n",
      "training time in round 34 cost 0.4122939109802246 sec\n",
      "loss 49200.315980, train acc 0.104018\n",
      "round 35\n",
      "time to device 0.008069 sec\n",
      "time forward 0.450185 sec\n",
      "loss time 0.001477 sec\n",
      "backward time 0.013486 sec\n",
      "optimizer time 0.025472 sec\n",
      "training time in round 35 cost 0.41541504859924316 sec\n",
      "loss 47834.028652, train acc 0.104167\n",
      "round 36\n",
      "time to device 0.006966 sec\n",
      "time forward 0.462765 sec\n",
      "loss time 0.001599 sec\n",
      "backward time 0.015836 sec\n",
      "optimizer time 0.025508 sec\n",
      "training time in round 36 cost 0.4078841209411621 sec\n",
      "loss 46541.616003, train acc 0.104730\n",
      "round 37\n",
      "time to device 0.007284 sec\n",
      "time forward 0.475359 sec\n",
      "loss time 0.001605 sec\n",
      "backward time 0.011588 sec\n",
      "optimizer time 0.026174 sec\n",
      "training time in round 37 cost 0.4004237651824951 sec\n",
      "loss 45317.139124, train acc 0.105263\n",
      "round 38\n",
      "time to device 0.003542 sec\n",
      "time forward 0.489437 sec\n",
      "loss time 0.001778 sec\n",
      "backward time 0.009881 sec\n",
      "optimizer time 0.029156 sec\n",
      "training time in round 38 cost 0.40442800521850586 sec\n",
      "loss 44155.456784, train acc 0.106370\n",
      "round 39\n",
      "time to device 0.003876 sec\n",
      "time forward 0.502026 sec\n",
      "loss time 0.001807 sec\n",
      "backward time 0.011438 sec\n",
      "optimizer time 0.027664 sec\n",
      "training time in round 39 cost 0.39934206008911133 sec\n",
      "loss 43051.805671, train acc 0.106250\n",
      "round 40\n",
      "time to device 0.004120 sec\n",
      "time forward 0.513807 sec\n",
      "loss time 0.001034 sec\n",
      "backward time 0.016439 sec\n",
      "optimizer time 0.023021 sec\n",
      "training time in round 40 cost 0.39588499069213867 sec\n",
      "loss 42001.935143, train acc 0.107279\n",
      "round 41\n",
      "time to device 0.003930 sec\n",
      "time forward 0.527281 sec\n",
      "loss time 0.001245 sec\n",
      "backward time 0.011510 sec\n",
      "optimizer time 0.021504 sec\n",
      "training time in round 41 cost 0.39902281761169434 sec\n",
      "loss 41002.037319, train acc 0.106771\n",
      "round 42\n",
      "time to device 0.003506 sec\n",
      "time forward 0.541414 sec\n",
      "loss time 0.001053 sec\n",
      "backward time 0.023274 sec\n",
      "optimizer time 0.024447 sec\n",
      "training time in round 42 cost 0.4311239719390869 sec\n",
      "loss 40048.610149, train acc 0.108467\n",
      "round 43\n",
      "time to device 0.004095 sec\n",
      "time forward 0.553768 sec\n",
      "loss time 0.001948 sec\n",
      "backward time 0.009580 sec\n",
      "optimizer time 0.029217 sec\n",
      "training time in round 43 cost 0.40610814094543457 sec\n",
      "loss 39138.488758, train acc 0.109730\n",
      "round 44\n",
      "time to device 0.003586 sec\n",
      "time forward 0.566680 sec\n",
      "loss time 0.001068 sec\n",
      "backward time 0.012452 sec\n",
      "optimizer time 0.025194 sec\n",
      "training time in round 44 cost 0.3930528163909912 sec\n",
      "loss 38268.826337, train acc 0.109028\n",
      "round 45\n",
      "time to device 0.004334 sec\n",
      "time forward 0.578280 sec\n",
      "loss time 0.001934 sec\n",
      "backward time 0.010781 sec\n",
      "optimizer time 0.026303 sec\n",
      "training time in round 45 cost 0.3983120918273926 sec\n",
      "loss 37436.953491, train acc 0.108696\n",
      "round 46\n",
      "time to device 0.004095 sec\n",
      "time forward 0.590175 sec\n",
      "loss time 0.001411 sec\n",
      "backward time 0.011112 sec\n",
      "optimizer time 0.030145 sec\n",
      "training time in round 46 cost 0.39609599113464355 sec\n",
      "loss 36640.476987, train acc 0.109209\n",
      "round 47\n",
      "time to device 0.003518 sec\n",
      "time forward 0.600381 sec\n",
      "loss time 0.001419 sec\n",
      "backward time 0.011146 sec\n",
      "optimizer time 0.022050 sec\n",
      "training time in round 47 cost 0.38883399963378906 sec\n",
      "loss 35877.181571, train acc 0.110677\n",
      "round 48\n",
      "time to device 0.003812 sec\n",
      "time forward 0.614678 sec\n",
      "loss time 0.001262 sec\n",
      "backward time 0.016427 sec\n",
      "optimizer time 0.018248 sec\n",
      "training time in round 48 cost 0.44362783432006836 sec\n",
      "loss 35145.397475, train acc 0.111288\n",
      "round 49\n",
      "time to device 0.006619 sec\n",
      "time forward 0.626534 sec\n",
      "loss time 0.001477 sec\n",
      "backward time 0.017803 sec\n",
      "optimizer time 0.021570 sec\n",
      "training time in round 49 cost 0.4147660732269287 sec\n",
      "loss 34442.542588, train acc 0.112344\n",
      "round 50\n",
      "time to device 0.006795 sec\n",
      "time forward 0.641334 sec\n",
      "loss time 0.001128 sec\n",
      "backward time 0.012484 sec\n",
      "optimizer time 0.023238 sec\n",
      "training time in round 50 cost 0.4438662528991699 sec\n",
      "loss 33767.268848, train acc 0.112286\n",
      "round 51\n",
      "time to device 0.010264 sec\n",
      "time forward 0.655829 sec\n",
      "loss time 0.001230 sec\n",
      "backward time 0.013238 sec\n",
      "optimizer time 0.023501 sec\n",
      "training time in round 51 cost 0.4279327392578125 sec\n",
      "loss 33117.972271, train acc 0.113281\n",
      "round 52\n",
      "time to device 0.007111 sec\n",
      "time forward 0.667905 sec\n",
      "loss time 0.001014 sec\n",
      "backward time 0.017740 sec\n",
      "optimizer time 0.024497 sec\n",
      "training time in round 52 cost 0.4017338752746582 sec\n",
      "loss 32493.178113, train acc 0.115271\n",
      "round 53\n",
      "time to device 0.006940 sec\n",
      "time forward 0.679903 sec\n",
      "loss time 0.001366 sec\n",
      "backward time 0.011922 sec\n",
      "optimizer time 0.017508 sec\n",
      "training time in round 53 cost 0.39847278594970703 sec\n",
      "loss 31891.525351, train acc 0.115885\n",
      "round 54\n",
      "time to device 0.006509 sec\n",
      "time forward 0.691735 sec\n",
      "loss time 0.001252 sec\n",
      "backward time 0.012316 sec\n",
      "optimizer time 0.024300 sec\n",
      "training time in round 54 cost 0.3943207263946533 sec\n",
      "loss 31311.750718, train acc 0.116903\n",
      "round 55\n",
      "time to device 0.005953 sec\n",
      "time forward 0.703428 sec\n",
      "loss time 0.001402 sec\n",
      "backward time 0.015101 sec\n",
      "optimizer time 0.024954 sec\n",
      "training time in round 55 cost 0.39261698722839355 sec\n",
      "loss 30752.680104, train acc 0.117885\n",
      "round 56\n",
      "time to device 0.007260 sec\n",
      "time forward 0.716298 sec\n",
      "loss time 0.001541 sec\n",
      "backward time 0.010361 sec\n",
      "optimizer time 0.015046 sec\n",
      "training time in round 56 cost 0.39018797874450684 sec\n",
      "loss 30213.220598, train acc 0.118284\n",
      "round 57\n",
      "time to device 0.006734 sec\n",
      "time forward 0.729284 sec\n",
      "loss time 0.001800 sec\n",
      "backward time 0.011213 sec\n",
      "optimizer time 0.028823 sec\n",
      "training time in round 57 cost 0.3956129550933838 sec\n",
      "loss 29692.352624, train acc 0.117861\n",
      "round 58\n",
      "time to device 0.007416 sec\n",
      "time forward 0.736905 sec\n",
      "loss time 0.000872 sec\n",
      "backward time 0.007488 sec\n",
      "optimizer time 0.017832 sec\n",
      "training time in round 58 cost 0.40587282180786133 sec\n",
      "loss 29189.149683, train acc 0.116525\n",
      "round 59\n",
      "time to device 0.003721 sec\n",
      "time forward 0.748355 sec\n",
      "loss time 0.001103 sec\n",
      "backward time 0.013300 sec\n",
      "optimizer time 0.025333 sec\n",
      "training time in round 59 cost 0.3918290138244629 sec\n",
      "loss 28702.710364, train acc 0.116797\n",
      "round 60\n",
      "time to device 0.006529 sec\n",
      "time forward 0.761547 sec\n",
      "loss time 0.002048 sec\n",
      "backward time 0.015064 sec\n",
      "optimizer time 0.026424 sec\n",
      "training time in round 60 cost 0.4009411334991455 sec\n",
      "loss 28232.220864, train acc 0.117316\n",
      "round 61\n",
      "time to device 0.008692 sec\n",
      "time forward 0.775559 sec\n",
      "loss time 0.001623 sec\n",
      "backward time 0.014058 sec\n",
      "optimizer time 0.024730 sec\n",
      "training time in round 61 cost 0.40471601486206055 sec\n",
      "loss 27776.908794, train acc 0.117440\n",
      "round 62\n",
      "time to device 0.007642 sec\n",
      "time forward 0.787563 sec\n",
      "loss time 0.001205 sec\n",
      "backward time 0.013541 sec\n",
      "optimizer time 0.028951 sec\n",
      "training time in round 62 cost 0.4017348289489746 sec\n",
      "loss 27336.050788, train acc 0.117932\n",
      "round 63\n",
      "time to device 0.008257 sec\n",
      "time forward 0.802191 sec\n",
      "loss time 0.001837 sec\n",
      "backward time 0.015302 sec\n",
      "optimizer time 0.024521 sec\n",
      "training time in round 63 cost 0.40473508834838867 sec\n",
      "loss 26908.973282, train acc 0.118042\n",
      "round 64\n",
      "time to device 0.006697 sec\n",
      "time forward 0.815308 sec\n",
      "loss time 0.001790 sec\n",
      "backward time 0.015604 sec\n",
      "optimizer time 0.024907 sec\n",
      "training time in round 64 cost 0.401047945022583 sec\n",
      "loss 26495.025962, train acc 0.117668\n",
      "round 65\n",
      "time to device 0.006670 sec\n",
      "time forward 0.827463 sec\n",
      "loss time 0.001214 sec\n",
      "backward time 0.012431 sec\n",
      "optimizer time 0.029795 sec\n",
      "training time in round 65 cost 0.39383888244628906 sec\n",
      "loss 26093.627046, train acc 0.117779\n",
      "round 66\n",
      "time to device 0.007222 sec\n",
      "time forward 0.841229 sec\n",
      "loss time 0.001273 sec\n",
      "backward time 0.014171 sec\n",
      "optimizer time 0.018485 sec\n",
      "training time in round 66 cost 0.41261887550354004 sec\n",
      "loss 25704.205458, train acc 0.117654\n",
      "round 67\n",
      "time to device 0.008514 sec\n",
      "time forward 0.853895 sec\n",
      "loss time 0.000938 sec\n",
      "backward time 0.017552 sec\n",
      "optimizer time 0.016862 sec\n",
      "training time in round 67 cost 0.41155505180358887 sec\n",
      "loss 25326.242909, train acc 0.117417\n",
      "round 68\n",
      "time to device 0.010256 sec\n",
      "time forward 0.869847 sec\n",
      "loss time 0.001003 sec\n",
      "backward time 0.013519 sec\n",
      "optimizer time 0.017905 sec\n",
      "training time in round 68 cost 0.424576997756958 sec\n",
      "loss 24959.231960, train acc 0.116621\n",
      "round 69\n",
      "time to device 0.010151 sec\n",
      "time forward 0.884269 sec\n",
      "loss time 0.001037 sec\n",
      "backward time 0.011928 sec\n",
      "optimizer time 0.020868 sec\n",
      "training time in round 69 cost 0.41673994064331055 sec\n",
      "loss 24602.714092, train acc 0.116183\n",
      "round 70\n",
      "time to device 0.007017 sec\n",
      "time forward 0.897094 sec\n",
      "loss time 0.001108 sec\n",
      "backward time 0.012535 sec\n",
      "optimizer time 0.019902 sec\n",
      "training time in round 70 cost 0.414503812789917 sec\n",
      "loss 24256.241972, train acc 0.116857\n",
      "round 71\n",
      "time to device 0.007764 sec\n",
      "time forward 0.908528 sec\n",
      "loss time 0.001256 sec\n",
      "backward time 0.011167 sec\n",
      "optimizer time 0.018655 sec\n",
      "training time in round 71 cost 0.3991661071777344 sec\n",
      "loss 23919.382096, train acc 0.116645\n",
      "round 72\n",
      "time to device 0.007614 sec\n",
      "time forward 0.920884 sec\n",
      "loss time 0.001854 sec\n",
      "backward time 0.013926 sec\n",
      "optimizer time 0.020205 sec\n",
      "training time in round 72 cost 0.43845391273498535 sec\n",
      "loss 23591.761591, train acc 0.116652\n",
      "round 73\n",
      "time to device 0.009651 sec\n",
      "time forward 0.932372 sec\n",
      "loss time 0.000985 sec\n",
      "backward time 0.013549 sec\n",
      "optimizer time 0.025518 sec\n",
      "training time in round 73 cost 0.40580177307128906 sec\n",
      "loss 23272.989388, train acc 0.116660\n",
      "round 74\n",
      "time to device 0.007188 sec\n",
      "time forward 0.947430 sec\n",
      "loss time 0.001727 sec\n",
      "backward time 0.013548 sec\n",
      "optimizer time 0.019065 sec\n",
      "training time in round 74 cost 0.4181351661682129 sec\n",
      "loss 22962.718932, train acc 0.116667\n",
      "round 75\n",
      "time to device 0.004510 sec\n",
      "time forward 0.960213 sec\n",
      "loss time 0.001211 sec\n",
      "backward time 0.010918 sec\n",
      "optimizer time 0.028299 sec\n",
      "training time in round 75 cost 0.39780187606811523 sec\n",
      "loss 22660.611874, train acc 0.117290\n",
      "round 76\n",
      "time to device 0.003550 sec\n",
      "time forward 0.972683 sec\n",
      "loss time 0.002318 sec\n",
      "backward time 0.016038 sec\n",
      "optimizer time 0.025224 sec\n",
      "training time in round 76 cost 0.40970301628112793 sec\n",
      "loss 22366.349127, train acc 0.116782\n",
      "round 77\n",
      "time to device 0.004070 sec\n",
      "time forward 0.983370 sec\n",
      "loss time 0.001183 sec\n",
      "backward time 0.011409 sec\n",
      "optimizer time 0.027962 sec\n",
      "training time in round 77 cost 0.3946220874786377 sec\n",
      "loss 22079.634353, train acc 0.117087\n",
      "round 78\n",
      "time to device 0.004078 sec\n",
      "time forward 0.994970 sec\n",
      "loss time 0.001270 sec\n",
      "backward time 0.013038 sec\n",
      "optimizer time 0.026413 sec\n",
      "training time in round 78 cost 0.39609432220458984 sec\n",
      "loss 21800.178411, train acc 0.116693\n",
      "round 79\n",
      "time to device 0.003721 sec\n",
      "time forward 1.009749 sec\n",
      "loss time 0.001070 sec\n",
      "backward time 0.012494 sec\n",
      "optimizer time 0.020950 sec\n",
      "training time in round 79 cost 0.42086315155029297 sec\n",
      "loss 21527.705246, train acc 0.116211\n",
      "round 80\n",
      "time to device 0.002907 sec\n",
      "time forward 1.025461 sec\n",
      "loss time 0.001273 sec\n",
      "backward time 0.010916 sec\n",
      "optimizer time 0.018839 sec\n",
      "training time in round 80 cost 0.4230318069458008 sec\n",
      "loss 21261.960861, train acc 0.116416\n",
      "round 81\n",
      "time to device 0.003693 sec\n",
      "time forward 1.037622 sec\n",
      "loss time 0.001447 sec\n",
      "backward time 0.010810 sec\n",
      "optimizer time 0.022876 sec\n",
      "training time in round 81 cost 0.38979506492614746 sec\n",
      "loss 21002.696238, train acc 0.116616\n",
      "round 82\n",
      "time to device 0.007965 sec\n",
      "time forward 1.050715 sec\n",
      "loss time 0.001343 sec\n",
      "backward time 0.013049 sec\n",
      "optimizer time 0.026224 sec\n",
      "training time in round 82 cost 0.4069039821624756 sec\n",
      "loss 20749.684036, train acc 0.117188\n",
      "round 83\n",
      "time to device 0.006025 sec\n",
      "time forward 1.062463 sec\n",
      "loss time 0.001349 sec\n",
      "backward time 0.013861 sec\n",
      "optimizer time 0.028336 sec\n",
      "training time in round 83 cost 0.41802191734313965 sec\n",
      "loss 20502.694489, train acc 0.116629\n",
      "round 84\n",
      "time to device 0.006534 sec\n",
      "time forward 1.068530 sec\n",
      "loss time 0.000403 sec\n",
      "backward time 0.004084 sec\n",
      "optimizer time 0.013749 sec\n",
      "training time in round 84 cost 0.3679013252258301 sec\n",
      "loss 20261.516901, train acc 0.116360\n",
      "round 85\n",
      "time to device 0.007700 sec\n",
      "time forward 1.085286 sec\n",
      "loss time 0.001440 sec\n",
      "backward time 0.013316 sec\n",
      "optimizer time 0.023805 sec\n",
      "training time in round 85 cost 0.4126741886138916 sec\n",
      "loss 20025.945027, train acc 0.116097\n",
      "round 86\n",
      "time to device 0.007895 sec\n",
      "time forward 1.097280 sec\n",
      "loss time 0.001512 sec\n",
      "backward time 0.013103 sec\n",
      "optimizer time 0.020211 sec\n",
      "training time in round 86 cost 0.4198129177093506 sec\n",
      "loss 19795.788613, train acc 0.116200\n",
      "round 87\n",
      "time to device 0.007017 sec\n",
      "time forward 1.109902 sec\n",
      "loss time 0.001251 sec\n",
      "backward time 0.011254 sec\n",
      "optimizer time 0.022649 sec\n",
      "training time in round 87 cost 0.4006929397583008 sec\n",
      "loss 19570.863002, train acc 0.116300\n",
      "round 88\n",
      "time to device 0.007099 sec\n",
      "time forward 1.123315 sec\n",
      "loss time 0.001146 sec\n",
      "backward time 0.013156 sec\n",
      "optimizer time 0.017043 sec\n",
      "training time in round 88 cost 0.3947722911834717 sec\n",
      "loss 19350.991555, train acc 0.116310\n",
      "round 89\n",
      "time to device 0.008671 sec\n",
      "time forward 1.131035 sec\n",
      "loss time 0.000462 sec\n",
      "backward time 0.035260 sec\n",
      "optimizer time 0.020379 sec\n",
      "training time in round 89 cost 0.4115300178527832 sec\n",
      "loss 19136.008769, train acc 0.116059\n",
      "round 90\n",
      "time to device 0.007567 sec\n",
      "time forward 1.146222 sec\n",
      "loss time 0.001363 sec\n",
      "backward time 0.011900 sec\n",
      "optimizer time 0.029240 sec\n",
      "training time in round 90 cost 0.45044898986816406 sec\n",
      "loss 18925.749388, train acc 0.116243\n",
      "round 91\n",
      "time to device 0.006329 sec\n",
      "time forward 1.159713 sec\n",
      "loss time 0.001827 sec\n",
      "backward time 0.020490 sec\n",
      "optimizer time 0.021828 sec\n",
      "training time in round 91 cost 0.42295193672180176 sec\n",
      "loss 18720.062088, train acc 0.116084\n",
      "round 92\n",
      "time to device 0.007132 sec\n",
      "time forward 1.172071 sec\n",
      "loss time 0.001269 sec\n",
      "backward time 0.010091 sec\n",
      "optimizer time 0.028411 sec\n",
      "training time in round 92 cost 0.41173291206359863 sec\n",
      "loss 18518.796936, train acc 0.115759\n",
      "round 93\n",
      "time to device 0.007357 sec\n",
      "time forward 1.184885 sec\n",
      "loss time 0.001552 sec\n",
      "backward time 0.013798 sec\n",
      "optimizer time 0.025433 sec\n",
      "training time in round 93 cost 0.39579010009765625 sec\n",
      "loss 18321.813043, train acc 0.116024\n",
      "round 94\n",
      "time to device 0.030983 sec\n",
      "time forward 1.193721 sec\n",
      "loss time 0.000766 sec\n",
      "backward time 0.007031 sec\n",
      "optimizer time 0.018356 sec\n",
      "training time in round 94 cost 0.39570093154907227 sec\n",
      "loss 18128.977853, train acc 0.115625\n",
      "round 95\n",
      "time to device 0.009248 sec\n",
      "time forward 1.206371 sec\n",
      "loss time 0.001761 sec\n",
      "backward time 0.021541 sec\n",
      "optimizer time 0.021155 sec\n",
      "training time in round 95 cost 0.41138505935668945 sec\n",
      "loss 17940.159719, train acc 0.115397\n",
      "round 96\n",
      "time to device 0.006419 sec\n",
      "time forward 1.218519 sec\n",
      "loss time 0.001852 sec\n",
      "backward time 0.012615 sec\n",
      "optimizer time 0.025436 sec\n",
      "training time in round 96 cost 0.40500712394714355 sec\n",
      "loss 17755.233766, train acc 0.115335\n",
      "round 97\n",
      "time to device 0.006530 sec\n",
      "time forward 1.228021 sec\n",
      "loss time 0.000397 sec\n",
      "backward time 0.003954 sec\n",
      "optimizer time 0.011298 sec\n",
      "training time in round 97 cost 0.3601412773132324 sec\n",
      "loss 17574.080812, train acc 0.114955\n",
      "round 98\n",
      "time to device 0.006570 sec\n",
      "time forward 1.241786 sec\n",
      "loss time 0.001014 sec\n",
      "backward time 0.016243 sec\n",
      "optimizer time 0.026192 sec\n",
      "training time in round 98 cost 0.44846105575561523 sec\n",
      "loss 17396.587759, train acc 0.115215\n",
      "round 99\n",
      "time to device 0.007163 sec\n",
      "time forward 1.255053 sec\n",
      "loss time 0.001033 sec\n",
      "backward time 0.012178 sec\n",
      "optimizer time 0.031968 sec\n",
      "training time in round 99 cost 0.4065968990325928 sec\n",
      "loss 17222.645875, train acc 0.115937\n",
      "round 100\n",
      "time to device 0.009247 sec\n",
      "time forward 1.268881 sec\n",
      "loss time 0.001092 sec\n",
      "backward time 0.012340 sec\n",
      "optimizer time 0.025701 sec\n",
      "training time in round 100 cost 0.4004542827606201 sec\n",
      "loss 17052.146592, train acc 0.115950\n",
      "round 101\n",
      "time to device 0.008673 sec\n",
      "time forward 1.284229 sec\n",
      "loss time 0.001352 sec\n",
      "backward time 0.014161 sec\n",
      "optimizer time 0.026122 sec\n",
      "training time in round 101 cost 0.41234326362609863 sec\n",
      "loss 16884.994525, train acc 0.116039\n",
      "round 102\n",
      "time to device 0.007458 sec\n",
      "time forward 1.296215 sec\n",
      "loss time 0.001899 sec\n",
      "backward time 0.014941 sec\n",
      "optimizer time 0.026927 sec\n",
      "training time in round 102 cost 0.40157532691955566 sec\n",
      "loss 16721.087443, train acc 0.115898\n",
      "round 103\n",
      "time to device 0.003515 sec\n",
      "time forward 1.309609 sec\n",
      "loss time 0.001607 sec\n",
      "backward time 0.012056 sec\n",
      "optimizer time 0.022314 sec\n",
      "training time in round 103 cost 0.3948171138763428 sec\n",
      "loss 16560.330452, train acc 0.116136\n",
      "round 104\n",
      "time to device 0.004158 sec\n",
      "time forward 1.321090 sec\n",
      "loss time 0.001266 sec\n",
      "backward time 0.010411 sec\n",
      "optimizer time 0.022357 sec\n",
      "training time in round 104 cost 0.3768918514251709 sec\n",
      "loss 16402.636437, train acc 0.116071\n",
      "round 105\n",
      "time to device 0.004675 sec\n",
      "time forward 1.334382 sec\n",
      "loss time 0.001402 sec\n",
      "backward time 0.013771 sec\n",
      "optimizer time 0.023400 sec\n",
      "training time in round 105 cost 0.4324460029602051 sec\n",
      "loss 16247.918099, train acc 0.116156\n",
      "round 106\n",
      "time to device 0.009643 sec\n",
      "time forward 1.348209 sec\n",
      "loss time 0.001119 sec\n",
      "backward time 0.009629 sec\n",
      "optimizer time 0.022993 sec\n",
      "training time in round 106 cost 0.41032886505126953 sec\n",
      "loss 16096.090425, train acc 0.116238\n",
      "round 107\n",
      "time to device 0.007913 sec\n",
      "time forward 1.366493 sec\n",
      "loss time 0.001043 sec\n",
      "backward time 0.009667 sec\n",
      "optimizer time 0.023144 sec\n",
      "training time in round 107 cost 0.41824984550476074 sec\n",
      "loss 15947.073538, train acc 0.117260\n",
      "round 108\n",
      "time to device 0.009345 sec\n",
      "time forward 1.379700 sec\n",
      "loss time 0.002287 sec\n",
      "backward time 0.011501 sec\n",
      "optimizer time 0.021143 sec\n",
      "training time in round 108 cost 0.40437912940979004 sec\n",
      "loss 15800.791721, train acc 0.117331\n",
      "round 109\n",
      "time to device 0.008883 sec\n",
      "time forward 1.393510 sec\n",
      "loss time 0.001400 sec\n",
      "backward time 0.009709 sec\n",
      "optimizer time 0.017174 sec\n",
      "training time in round 109 cost 0.3949909210205078 sec\n",
      "loss 15657.168732, train acc 0.117259\n",
      "round 110\n",
      "time to device 0.003927 sec\n",
      "time forward 1.405449 sec\n",
      "loss time 0.001819 sec\n",
      "backward time 0.013870 sec\n",
      "optimizer time 0.020298 sec\n",
      "training time in round 110 cost 0.391970157623291 sec\n",
      "loss 15516.133630, train acc 0.117680\n",
      "round 111\n",
      "time to device 0.003734 sec\n",
      "time forward 1.418996 sec\n",
      "loss time 0.001797 sec\n",
      "backward time 0.013300 sec\n",
      "optimizer time 0.021560 sec\n",
      "training time in round 111 cost 0.39900994300842285 sec\n",
      "loss 15377.617801, train acc 0.118513\n",
      "round 112\n",
      "time to device 0.004620 sec\n",
      "time forward 1.430851 sec\n",
      "loss time 0.002074 sec\n",
      "backward time 0.014401 sec\n",
      "optimizer time 0.025599 sec\n",
      "training time in round 112 cost 0.3940739631652832 sec\n",
      "loss 15241.553735, train acc 0.118501\n",
      "round 113\n",
      "time to device 0.003757 sec\n",
      "time forward 1.444070 sec\n",
      "loss time 0.001203 sec\n",
      "backward time 0.013434 sec\n",
      "optimizer time 0.018426 sec\n",
      "training time in round 113 cost 0.39704132080078125 sec\n",
      "loss 15107.909328, train acc 0.118490\n",
      "round 114\n",
      "time to device 0.003808 sec\n",
      "time forward 1.461127 sec\n",
      "loss time 0.001124 sec\n",
      "backward time 0.016149 sec\n",
      "optimizer time 0.030868 sec\n",
      "training time in round 114 cost 0.46114373207092285 sec\n",
      "loss 14976.560740, train acc 0.118546\n",
      "round 115\n",
      "time to device 0.003964 sec\n",
      "time forward 1.473215 sec\n",
      "loss time 0.002313 sec\n",
      "backward time 0.013974 sec\n",
      "optimizer time 0.017873 sec\n",
      "training time in round 115 cost 0.38333892822265625 sec\n",
      "loss 14847.479767, train acc 0.118198\n",
      "round 116\n",
      "time to device 0.003403 sec\n",
      "time forward 1.480256 sec\n",
      "loss time 0.000584 sec\n",
      "backward time 0.005236 sec\n",
      "optimizer time 0.013750 sec\n",
      "training time in round 116 cost 0.3560309410095215 sec\n",
      "loss 14720.602333, train acc 0.118056\n",
      "round 117\n",
      "time to device 0.004056 sec\n",
      "time forward 1.492387 sec\n",
      "loss time 0.000982 sec\n",
      "backward time 0.010646 sec\n",
      "optimizer time 0.029929 sec\n",
      "training time in round 117 cost 0.39376187324523926 sec\n",
      "loss 14595.871986, train acc 0.118181\n",
      "round 118\n",
      "time to device 0.003817 sec\n",
      "time forward 1.505564 sec\n",
      "loss time 0.001412 sec\n",
      "backward time 0.014691 sec\n",
      "optimizer time 0.023653 sec\n",
      "training time in round 118 cost 0.3962738513946533 sec\n",
      "loss 14473.238861, train acc 0.118304\n",
      "round 119\n",
      "time to device 0.004400 sec\n",
      "time forward 1.516488 sec\n",
      "loss time 0.001187 sec\n",
      "backward time 0.013359 sec\n",
      "optimizer time 0.026713 sec\n",
      "training time in round 119 cost 0.4060521125793457 sec\n",
      "loss 14352.651699, train acc 0.118229\n",
      "round 120\n",
      "time to device 0.004151 sec\n",
      "time forward 1.528811 sec\n",
      "loss time 0.001377 sec\n",
      "backward time 0.012476 sec\n",
      "optimizer time 0.029725 sec\n",
      "training time in round 120 cost 0.3936431407928467 sec\n",
      "loss 14234.060576, train acc 0.117833\n",
      "round 121\n",
      "time to device 0.003758 sec\n",
      "time forward 1.536943 sec\n",
      "loss time 0.001110 sec\n",
      "backward time 0.009343 sec\n",
      "optimizer time 0.016691 sec\n",
      "training time in round 121 cost 0.36440324783325195 sec\n",
      "loss 14117.408624, train acc 0.117572\n",
      "round 122\n",
      "time to device 0.004538 sec\n",
      "time forward 1.550498 sec\n",
      "loss time 0.001478 sec\n",
      "backward time 0.014118 sec\n",
      "optimizer time 0.021649 sec\n",
      "training time in round 122 cost 0.457460880279541 sec\n",
      "loss 14002.656677, train acc 0.117378\n",
      "round 123\n",
      "time to device 0.004234 sec\n",
      "time forward 1.563136 sec\n",
      "loss time 0.000922 sec\n",
      "backward time 0.018539 sec\n",
      "optimizer time 0.025751 sec\n",
      "training time in round 123 cost 0.4071629047393799 sec\n",
      "loss 13889.757110, train acc 0.117377\n",
      "round 124\n",
      "time to device 0.003252 sec\n",
      "time forward 1.575567 sec\n",
      "loss time 0.001102 sec\n",
      "backward time 0.013156 sec\n",
      "optimizer time 0.026521 sec\n",
      "training time in round 124 cost 0.4035789966583252 sec\n",
      "loss 13778.670348, train acc 0.117313\n",
      "round 125\n",
      "time to device 0.003061 sec\n",
      "time forward 1.586916 sec\n",
      "loss time 0.001173 sec\n",
      "backward time 0.012738 sec\n",
      "optimizer time 0.028119 sec\n",
      "training time in round 125 cost 0.4106178283691406 sec\n",
      "loss 13669.348780, train acc 0.117188\n",
      "round 126\n",
      "time to device 0.003825 sec\n",
      "time forward 1.601699 sec\n",
      "loss time 0.001139 sec\n",
      "backward time 0.012087 sec\n",
      "optimizer time 0.017912 sec\n",
      "training time in round 126 cost 0.4406411647796631 sec\n",
      "loss 13561.740434, train acc 0.116941\n",
      "round 127\n",
      "time to device 0.007262 sec\n",
      "time forward 1.614644 sec\n",
      "loss time 0.001488 sec\n",
      "backward time 0.016212 sec\n",
      "optimizer time 0.020810 sec\n",
      "training time in round 127 cost 0.4116389751434326 sec\n",
      "loss 13455.811216, train acc 0.116516\n",
      "round 128\n",
      "time to device 0.008557 sec\n",
      "time forward 1.627569 sec\n",
      "loss time 0.001170 sec\n",
      "backward time 0.014803 sec\n",
      "optimizer time 0.026003 sec\n",
      "training time in round 128 cost 0.40906500816345215 sec\n",
      "loss 13351.526581, train acc 0.116521\n",
      "round 129\n",
      "time to device 0.006958 sec\n",
      "time forward 1.639867 sec\n",
      "loss time 0.001034 sec\n",
      "backward time 0.014160 sec\n",
      "optimizer time 0.024916 sec\n",
      "training time in round 129 cost 0.38968515396118164 sec\n",
      "loss 13248.845456, train acc 0.116226\n",
      "round 130\n",
      "time to device 0.007668 sec\n",
      "time forward 1.652147 sec\n",
      "loss time 0.001220 sec\n",
      "backward time 0.015218 sec\n",
      "optimizer time 0.027245 sec\n",
      "training time in round 130 cost 0.4386751651763916 sec\n",
      "loss 13147.751096, train acc 0.116054\n",
      "round 131\n",
      "time to device 0.007545 sec\n",
      "time forward 1.663965 sec\n",
      "loss time 0.000988 sec\n",
      "backward time 0.012557 sec\n",
      "optimizer time 0.024649 sec\n",
      "training time in round 131 cost 0.3986997604370117 sec\n",
      "loss 13048.167014, train acc 0.116004\n",
      "round 132\n",
      "time to device 0.008918 sec\n",
      "time forward 1.675415 sec\n",
      "loss time 0.001844 sec\n",
      "backward time 0.015037 sec\n",
      "optimizer time 0.024799 sec\n",
      "training time in round 132 cost 0.4165680408477783 sec\n",
      "loss 12950.093564, train acc 0.115484\n",
      "round 133\n",
      "time to device 0.007050 sec\n",
      "time forward 1.683760 sec\n",
      "loss time 0.000363 sec\n",
      "backward time 0.007299 sec\n",
      "optimizer time 0.011702 sec\n",
      "training time in round 133 cost 0.3976156711578369 sec\n",
      "loss 12853.476779, train acc 0.115788\n",
      "round 134\n",
      "time to device 0.008253 sec\n",
      "time forward 1.693605 sec\n",
      "loss time 0.000911 sec\n",
      "backward time 0.008657 sec\n",
      "optimizer time 0.019719 sec\n",
      "training time in round 134 cost 0.41852712631225586 sec\n",
      "loss 12758.290020, train acc 0.115567\n",
      "round 135\n",
      "time to device 0.009037 sec\n",
      "time forward 1.705820 sec\n",
      "loss time 0.001075 sec\n",
      "backward time 0.023642 sec\n",
      "optimizer time 0.012968 sec\n",
      "training time in round 135 cost 0.39223194122314453 sec\n",
      "loss 12664.499967, train acc 0.115234\n",
      "round 136\n",
      "time to device 0.007768 sec\n",
      "time forward 1.719065 sec\n",
      "loss time 0.001234 sec\n",
      "backward time 0.013458 sec\n",
      "optimizer time 0.024073 sec\n",
      "training time in round 136 cost 0.39509010314941406 sec\n",
      "loss 12572.077371, train acc 0.115363\n",
      "round 137\n",
      "time to device 0.006407 sec\n",
      "time forward 1.731823 sec\n",
      "loss time 0.001070 sec\n",
      "backward time 0.011612 sec\n",
      "optimizer time 0.024136 sec\n",
      "training time in round 137 cost 0.4102210998535156 sec\n",
      "loss 12480.993645, train acc 0.115376\n",
      "round 138\n",
      "time to device 0.007124 sec\n",
      "time forward 1.743294 sec\n",
      "loss time 0.001761 sec\n",
      "backward time 0.010127 sec\n",
      "optimizer time 0.034815 sec\n",
      "training time in round 138 cost 0.42923808097839355 sec\n",
      "loss 12391.226607, train acc 0.115501\n",
      "round 139\n",
      "time to device 0.007920 sec\n",
      "time forward 1.754950 sec\n",
      "loss time 0.001267 sec\n",
      "backward time 0.012688 sec\n",
      "optimizer time 0.026953 sec\n",
      "training time in round 139 cost 0.4131920337677002 sec\n",
      "loss 12302.738101, train acc 0.115402\n",
      "round 140\n",
      "time to device 0.007560 sec\n",
      "time forward 1.771331 sec\n",
      "loss time 0.001023 sec\n",
      "backward time 0.017785 sec\n",
      "optimizer time 0.027980 sec\n",
      "training time in round 140 cost 0.419597864151001 sec\n",
      "loss 12215.513513, train acc 0.115470\n",
      "round 141\n",
      "time to device 0.008588 sec\n",
      "time forward 1.784657 sec\n",
      "loss time 0.001470 sec\n",
      "backward time 0.012743 sec\n",
      "optimizer time 0.026825 sec\n",
      "training time in round 141 cost 0.40509891510009766 sec\n",
      "loss 12129.507157, train acc 0.115482\n",
      "round 142\n",
      "time to device 0.003454 sec\n",
      "time forward 1.791449 sec\n",
      "loss time 0.000847 sec\n",
      "backward time 0.007736 sec\n",
      "optimizer time 0.017799 sec\n",
      "training time in round 142 cost 0.34827613830566406 sec\n",
      "loss 12044.703474, train acc 0.115767\n",
      "round 143\n",
      "time to device 0.004060 sec\n",
      "time forward 1.803562 sec\n",
      "loss time 0.001180 sec\n",
      "backward time 0.011774 sec\n",
      "optimizer time 0.029252 sec\n",
      "training time in round 143 cost 0.3923678398132324 sec\n",
      "loss 11961.076881, train acc 0.115723\n",
      "round 144\n",
      "time to device 0.003329 sec\n",
      "time forward 1.814218 sec\n",
      "loss time 0.001563 sec\n",
      "backward time 0.017030 sec\n",
      "optimizer time 0.024098 sec\n",
      "training time in round 144 cost 0.407940149307251 sec\n",
      "loss 11878.604665, train acc 0.115248\n",
      "round 145\n",
      "time to device 0.004221 sec\n",
      "time forward 1.829134 sec\n",
      "loss time 0.001095 sec\n",
      "backward time 0.013788 sec\n",
      "optimizer time 0.026586 sec\n",
      "training time in round 145 cost 0.4925661087036133 sec\n",
      "loss 11797.264779, train acc 0.114940\n",
      "round 146\n",
      "time to device 0.008100 sec\n",
      "time forward 1.841853 sec\n",
      "loss time 0.001146 sec\n",
      "backward time 0.011135 sec\n",
      "optimizer time 0.041392 sec\n",
      "training time in round 146 cost 0.4113168716430664 sec\n",
      "loss 11717.028233, train acc 0.114636\n",
      "round 147\n",
      "time to device 0.011125 sec\n",
      "time forward 1.854359 sec\n",
      "loss time 0.001051 sec\n",
      "backward time 0.020370 sec\n",
      "optimizer time 0.016697 sec\n",
      "training time in round 147 cost 0.43279099464416504 sec\n",
      "loss 11637.878266, train acc 0.114707\n",
      "round 148\n",
      "time to device 0.007180 sec\n",
      "time forward 1.873604 sec\n",
      "loss time 0.001853 sec\n",
      "backward time 0.013060 sec\n",
      "optimizer time 0.020526 sec\n",
      "training time in round 148 cost 0.44019317626953125 sec\n",
      "loss 11559.788632, train acc 0.114828\n",
      "round 149\n",
      "time to device 0.006354 sec\n",
      "time forward 1.886683 sec\n",
      "loss time 0.001797 sec\n",
      "backward time 0.015561 sec\n",
      "optimizer time 0.021314 sec\n",
      "training time in round 149 cost 0.4961819648742676 sec\n",
      "loss 11482.739504, train acc 0.114687\n",
      "round 150\n",
      "time to device 0.008446 sec\n",
      "time forward 1.898996 sec\n",
      "loss time 0.001112 sec\n",
      "backward time 0.009561 sec\n",
      "optimizer time 0.039421 sec\n",
      "training time in round 150 cost 0.4159409999847412 sec\n",
      "loss 11406.712076, train acc 0.114652\n",
      "round 151\n",
      "time to device 0.006329 sec\n",
      "time forward 1.910911 sec\n",
      "loss time 0.001152 sec\n",
      "backward time 0.010471 sec\n",
      "optimizer time 0.032439 sec\n",
      "training time in round 151 cost 0.39426493644714355 sec\n",
      "loss 11331.685030, train acc 0.114566\n",
      "round 152\n",
      "time to device 0.007459 sec\n",
      "time forward 1.929388 sec\n",
      "loss time 0.001524 sec\n",
      "backward time 0.012421 sec\n",
      "optimizer time 0.029162 sec\n",
      "training time in round 152 cost 0.4197700023651123 sec\n",
      "loss 11257.638649, train acc 0.114430\n",
      "round 153\n",
      "time to device 0.008858 sec\n",
      "time forward 1.940876 sec\n",
      "loss time 0.001107 sec\n",
      "backward time 0.012715 sec\n",
      "optimizer time 0.028440 sec\n",
      "training time in round 153 cost 0.3956489562988281 sec\n",
      "loss 11184.552186, train acc 0.114194\n",
      "round 154\n",
      "time to device 0.007507 sec\n",
      "time forward 1.952713 sec\n",
      "loss time 0.001450 sec\n",
      "backward time 0.014676 sec\n",
      "optimizer time 0.026271 sec\n",
      "training time in round 154 cost 0.39432287216186523 sec\n",
      "loss 11112.408959, train acc 0.114012\n",
      "round 155\n",
      "time to device 0.006261 sec\n",
      "time forward 1.964353 sec\n",
      "loss time 0.000917 sec\n",
      "backward time 0.008674 sec\n",
      "optimizer time 0.011495 sec\n",
      "training time in round 155 cost 0.38571906089782715 sec\n",
      "loss 11041.190885, train acc 0.113782\n",
      "round 156\n",
      "time to device 0.008629 sec\n",
      "time forward 1.972217 sec\n",
      "loss time 0.000449 sec\n",
      "backward time 0.005249 sec\n",
      "optimizer time 0.012807 sec\n",
      "training time in round 156 cost 0.37101173400878906 sec\n",
      "loss 10970.879449, train acc 0.113654\n",
      "round 157\n",
      "time to device 0.003389 sec\n",
      "time forward 1.984503 sec\n",
      "loss time 0.001534 sec\n",
      "backward time 0.014498 sec\n",
      "optimizer time 0.018446 sec\n",
      "training time in round 157 cost 0.43366003036499023 sec\n",
      "loss 10901.458428, train acc 0.113776\n",
      "round 158\n",
      "time to device 0.006221 sec\n",
      "time forward 1.992963 sec\n",
      "loss time 0.000565 sec\n",
      "backward time 0.005339 sec\n",
      "optimizer time 0.014297 sec\n",
      "training time in round 158 cost 0.36977386474609375 sec\n",
      "loss 10832.910674, train acc 0.113945\n",
      "round 159\n",
      "time to device 0.006240 sec\n",
      "time forward 2.004972 sec\n",
      "loss time 0.001517 sec\n",
      "backward time 0.019068 sec\n",
      "optimizer time 0.018972 sec\n",
      "training time in round 159 cost 0.41237974166870117 sec\n",
      "loss 10765.219846, train acc 0.113770\n",
      "round 160\n",
      "time to device 0.007086 sec\n",
      "time forward 2.021368 sec\n",
      "loss time 0.001079 sec\n",
      "backward time 0.013636 sec\n",
      "optimizer time 0.027062 sec\n",
      "training time in round 160 cost 0.42452287673950195 sec\n",
      "loss 10698.369446, train acc 0.113985\n",
      "round 161\n",
      "time to device 0.008152 sec\n",
      "time forward 2.034468 sec\n",
      "loss time 0.001166 sec\n",
      "backward time 0.011821 sec\n",
      "optimizer time 0.024688 sec\n",
      "training time in round 161 cost 0.4565119743347168 sec\n",
      "loss 10632.345734, train acc 0.113667\n",
      "round 162\n",
      "time to device 0.006929 sec\n",
      "time forward 2.047326 sec\n",
      "loss time 0.001109 sec\n",
      "backward time 0.011945 sec\n",
      "optimizer time 0.027520 sec\n",
      "training time in round 162 cost 0.40834712982177734 sec\n",
      "loss 10567.132172, train acc 0.113497\n",
      "round 163\n",
      "time to device 0.008555 sec\n",
      "time forward 2.063025 sec\n",
      "loss time 0.001501 sec\n",
      "backward time 0.010299 sec\n",
      "optimizer time 0.026976 sec\n",
      "training time in round 163 cost 0.419374942779541 sec\n",
      "loss 10502.715149, train acc 0.113234\n",
      "round 164\n",
      "time to device 0.007376 sec\n",
      "time forward 2.076801 sec\n",
      "loss time 0.001481 sec\n",
      "backward time 0.011967 sec\n",
      "optimizer time 0.028458 sec\n",
      "training time in round 164 cost 0.44993019104003906 sec\n",
      "loss 10439.075979, train acc 0.113589\n",
      "round 165\n",
      "time to device 0.008963 sec\n",
      "time forward 2.089136 sec\n",
      "loss time 0.001866 sec\n",
      "backward time 0.020529 sec\n",
      "optimizer time 0.024735 sec\n",
      "training time in round 165 cost 0.41163182258605957 sec\n",
      "loss 10376.204281, train acc 0.113422\n",
      "round 166\n",
      "time to device 0.006576 sec\n",
      "time forward 2.103026 sec\n",
      "loss time 0.001449 sec\n",
      "backward time 0.013617 sec\n",
      "optimizer time 0.024776 sec\n",
      "training time in round 166 cost 0.41839170455932617 sec\n",
      "loss 10314.085503, train acc 0.113118\n",
      "round 167\n",
      "time to device 0.007859 sec\n",
      "time forward 2.120237 sec\n",
      "loss time 0.001212 sec\n",
      "backward time 0.015237 sec\n",
      "optimizer time 0.028201 sec\n",
      "training time in round 167 cost 0.41997814178466797 sec\n",
      "loss 10252.706981, train acc 0.113002\n",
      "round 168\n",
      "time to device 0.007561 sec\n",
      "time forward 2.131882 sec\n",
      "loss time 0.001183 sec\n",
      "backward time 0.012305 sec\n",
      "optimizer time 0.029015 sec\n",
      "training time in round 168 cost 0.39557671546936035 sec\n",
      "loss 10192.053934, train acc 0.113027\n",
      "round 169\n",
      "time to device 0.010323 sec\n",
      "time forward 2.140253 sec\n",
      "loss time 0.001050 sec\n",
      "backward time 0.008594 sec\n",
      "optimizer time 0.018255 sec\n",
      "training time in round 169 cost 0.37064313888549805 sec\n",
      "loss 10132.117266, train acc 0.112914\n",
      "round 170\n",
      "time to device 0.003473 sec\n",
      "time forward 2.154546 sec\n",
      "loss time 0.001954 sec\n",
      "backward time 0.024173 sec\n",
      "optimizer time 0.024069 sec\n",
      "training time in round 170 cost 0.4127371311187744 sec\n",
      "loss 10072.879223, train acc 0.112619\n",
      "round 171\n",
      "time to device 0.003782 sec\n",
      "time forward 2.166132 sec\n",
      "loss time 0.001738 sec\n",
      "backward time 0.012283 sec\n",
      "optimizer time 0.022871 sec\n",
      "training time in round 171 cost 0.3927900791168213 sec\n",
      "loss 10014.329604, train acc 0.112600\n",
      "round 172\n",
      "time to device 0.004396 sec\n",
      "time forward 2.178973 sec\n",
      "loss time 0.001733 sec\n",
      "backward time 0.011301 sec\n",
      "optimizer time 0.021336 sec\n",
      "training time in round 172 cost 0.40090417861938477 sec\n",
      "loss 9956.457108, train acc 0.112717\n",
      "round 173\n",
      "time to device 0.003586 sec\n",
      "time forward 2.194574 sec\n",
      "loss time 0.000990 sec\n",
      "backward time 0.013518 sec\n",
      "optimizer time 0.019798 sec\n",
      "training time in round 173 cost 0.43503403663635254 sec\n",
      "loss 9899.249201, train acc 0.113147\n",
      "round 174\n",
      "time to device 0.003569 sec\n",
      "time forward 2.207919 sec\n",
      "loss time 0.001089 sec\n",
      "backward time 0.017021 sec\n",
      "optimizer time 0.019581 sec\n",
      "training time in round 174 cost 0.40511536598205566 sec\n",
      "loss 9842.695582, train acc 0.112991\n",
      "round 175\n",
      "time to device 0.006608 sec\n",
      "time forward 2.219550 sec\n",
      "loss time 0.000929 sec\n",
      "backward time 0.012503 sec\n",
      "optimizer time 0.019954 sec\n",
      "training time in round 175 cost 0.4777190685272217 sec\n",
      "loss 9786.785124, train acc 0.112660\n",
      "round 176\n",
      "time to device 0.008711 sec\n",
      "time forward 2.229980 sec\n",
      "loss time 0.001150 sec\n",
      "backward time 0.009769 sec\n",
      "optimizer time 0.036620 sec\n",
      "training time in round 176 cost 0.4200282096862793 sec\n",
      "loss 9731.506292, train acc 0.112774\n",
      "round 177\n",
      "time to device 0.007874 sec\n",
      "time forward 2.245070 sec\n",
      "loss time 0.001259 sec\n",
      "backward time 0.012402 sec\n",
      "optimizer time 0.020355 sec\n",
      "training time in round 177 cost 0.41490888595581055 sec\n",
      "loss 9676.848185, train acc 0.113062\n",
      "round 178\n",
      "time to device 0.007432 sec\n",
      "time forward 2.256937 sec\n",
      "loss time 0.001825 sec\n",
      "backward time 0.015852 sec\n",
      "optimizer time 0.023984 sec\n",
      "training time in round 178 cost 0.39658594131469727 sec\n",
      "loss 9622.800734, train acc 0.113216\n",
      "round 179\n",
      "time to device 0.010142 sec\n",
      "time forward 2.268787 sec\n",
      "loss time 0.001218 sec\n",
      "backward time 0.011934 sec\n",
      "optimizer time 0.023755 sec\n",
      "training time in round 179 cost 0.4062819480895996 sec\n",
      "loss 9569.353718, train acc 0.113194\n",
      "round 180\n",
      "time to device 0.007311 sec\n",
      "time forward 2.279767 sec\n",
      "loss time 0.001037 sec\n",
      "backward time 0.021258 sec\n",
      "optimizer time 0.016015 sec\n",
      "training time in round 180 cost 0.41962718963623047 sec\n",
      "loss 9516.497532, train acc 0.113217\n",
      "round 181\n",
      "time to device 0.006540 sec\n",
      "time forward 2.292109 sec\n",
      "loss time 0.001235 sec\n",
      "backward time 0.012594 sec\n",
      "optimizer time 0.017632 sec\n",
      "training time in round 181 cost 0.43089795112609863 sec\n",
      "loss 9464.221767, train acc 0.112938\n",
      "round 182\n",
      "time to device 0.006915 sec\n",
      "time forward 2.300527 sec\n",
      "loss time 0.000667 sec\n",
      "backward time 0.006971 sec\n",
      "optimizer time 0.021545 sec\n",
      "training time in round 182 cost 0.42743396759033203 sec\n",
      "loss 9412.518287, train acc 0.112662\n",
      "round 183\n",
      "time to device 0.007947 sec\n",
      "time forward 2.312375 sec\n",
      "loss time 0.001073 sec\n",
      "backward time 0.013280 sec\n",
      "optimizer time 0.031958 sec\n",
      "training time in round 183 cost 0.4002869129180908 sec\n",
      "loss 9361.376125, train acc 0.112602\n",
      "round 184\n",
      "time to device 0.007307 sec\n",
      "time forward 2.323894 sec\n",
      "loss time 0.001877 sec\n",
      "backward time 0.016753 sec\n",
      "optimizer time 0.029062 sec\n",
      "training time in round 184 cost 0.43308496475219727 sec\n",
      "loss 9310.786488, train acc 0.112542\n",
      "round 185\n",
      "time to device 0.007196 sec\n",
      "time forward 2.340476 sec\n",
      "loss time 0.001209 sec\n",
      "backward time 0.011334 sec\n",
      "optimizer time 0.019160 sec\n",
      "training time in round 185 cost 0.4234497547149658 sec\n",
      "loss 9260.741863, train acc 0.112567\n",
      "round 186\n",
      "time to device 0.007618 sec\n",
      "time forward 2.351959 sec\n",
      "loss time 0.000946 sec\n",
      "backward time 0.011441 sec\n",
      "optimizer time 0.026558 sec\n",
      "training time in round 186 cost 0.46186399459838867 sec\n",
      "loss 9211.231809, train acc 0.112675\n",
      "round 187\n",
      "time to device 0.006518 sec\n",
      "time forward 2.363403 sec\n",
      "loss time 0.001097 sec\n",
      "backward time 0.015252 sec\n",
      "optimizer time 0.032640 sec\n",
      "training time in round 187 cost 0.40285205841064453 sec\n",
      "loss 9162.248447, train acc 0.112783\n",
      "round 188\n",
      "time to device 0.007063 sec\n",
      "time forward 2.374569 sec\n",
      "loss time 0.001230 sec\n",
      "backward time 0.011220 sec\n",
      "optimizer time 0.019378 sec\n",
      "training time in round 188 cost 0.4188868999481201 sec\n",
      "loss 9113.783930, train acc 0.112599\n",
      "round 189\n",
      "time to device 0.007049 sec\n",
      "time forward 2.388729 sec\n",
      "loss time 0.001828 sec\n",
      "backward time 0.012388 sec\n",
      "optimizer time 0.028419 sec\n",
      "training time in round 189 cost 0.4118993282318115 sec\n",
      "loss 9065.829379, train acc 0.112459\n",
      "round 190\n",
      "time to device 0.006955 sec\n",
      "time forward 2.399634 sec\n",
      "loss time 0.001152 sec\n",
      "backward time 0.022706 sec\n",
      "optimizer time 0.018510 sec\n",
      "training time in round 190 cost 0.4007081985473633 sec\n",
      "loss 9018.376397, train acc 0.112238\n",
      "round 191\n",
      "time to device 0.006521 sec\n",
      "time forward 2.409815 sec\n",
      "loss time 0.001752 sec\n",
      "backward time 0.009832 sec\n",
      "optimizer time 0.028950 sec\n",
      "training time in round 191 cost 0.3897237777709961 sec\n",
      "loss 8971.418523, train acc 0.112142\n",
      "round 192\n",
      "time to device 0.006575 sec\n",
      "time forward 2.421126 sec\n",
      "loss time 0.001355 sec\n",
      "backward time 0.014291 sec\n",
      "optimizer time 0.016392 sec\n",
      "training time in round 192 cost 0.4058380126953125 sec\n",
      "loss 8924.946616, train acc 0.111925\n",
      "round 193\n",
      "time to device 0.007017 sec\n",
      "time forward 2.431137 sec\n",
      "loss time 0.001474 sec\n",
      "backward time 0.013406 sec\n",
      "optimizer time 0.020450 sec\n",
      "training time in round 193 cost 0.39841389656066895 sec\n",
      "loss 8878.953792, train acc 0.111751\n",
      "round 194\n",
      "time to device 0.005445 sec\n",
      "time forward 2.442430 sec\n",
      "loss time 0.001305 sec\n",
      "backward time 0.012585 sec\n",
      "optimizer time 0.021076 sec\n",
      "training time in round 194 cost 0.41594910621643066 sec\n",
      "loss 8833.434010, train acc 0.111498\n",
      "round 195\n",
      "time to device 0.007223 sec\n",
      "time forward 2.454749 sec\n",
      "loss time 0.003124 sec\n",
      "backward time 0.012636 sec\n",
      "optimizer time 0.020627 sec\n",
      "training time in round 195 cost 0.4363541603088379 sec\n",
      "loss 8788.377543, train acc 0.111248\n",
      "round 196\n",
      "time to device 0.007236 sec\n",
      "time forward 2.468722 sec\n",
      "loss time 0.001292 sec\n",
      "backward time 0.010864 sec\n",
      "optimizer time 0.027304 sec\n",
      "training time in round 196 cost 0.46701860427856445 sec\n",
      "loss 8743.778006, train acc 0.111239\n",
      "round 197\n",
      "time to device 0.008211 sec\n",
      "time forward 2.479956 sec\n",
      "loss time 0.001199 sec\n",
      "backward time 0.011557 sec\n",
      "optimizer time 0.021982 sec\n",
      "training time in round 197 cost 0.4524238109588623 sec\n",
      "loss 8699.629372, train acc 0.111111\n",
      "round 198\n",
      "time to device 0.008089 sec\n",
      "time forward 2.494861 sec\n",
      "loss time 0.001123 sec\n",
      "backward time 0.012888 sec\n",
      "optimizer time 0.022566 sec\n",
      "training time in round 198 cost 0.45070409774780273 sec\n",
      "loss 8655.924461, train acc 0.111181\n",
      "round 199\n",
      "time to device 0.006687 sec\n",
      "time forward 2.508661 sec\n",
      "loss time 0.001076 sec\n",
      "backward time 0.011357 sec\n",
      "optimizer time 0.019152 sec\n",
      "training time in round 199 cost 0.4277520179748535 sec\n",
      "loss 8612.656895, train acc 0.110977\n",
      "round 200\n",
      "time to device 0.007509 sec\n",
      "time forward 2.523292 sec\n",
      "loss time 0.001302 sec\n",
      "backward time 0.012958 sec\n",
      "optimizer time 0.013770 sec\n",
      "training time in round 200 cost 0.42133188247680664 sec\n",
      "loss 8569.820001, train acc 0.110774\n",
      "round 201\n",
      "time to device 0.007090 sec\n",
      "time forward 2.535290 sec\n",
      "loss time 0.001109 sec\n",
      "backward time 0.010990 sec\n",
      "optimizer time 0.018972 sec\n",
      "training time in round 201 cost 0.41556715965270996 sec\n",
      "loss 8527.406732, train acc 0.110729\n",
      "round 202\n",
      "time to device 0.008452 sec\n",
      "time forward 2.548243 sec\n",
      "loss time 0.002899 sec\n",
      "backward time 0.025803 sec\n",
      "optimizer time 0.028420 sec\n",
      "training time in round 202 cost 0.4725489616394043 sec\n",
      "loss 8485.411268, train acc 0.110799\n",
      "round 203\n",
      "time to device 0.008257 sec\n",
      "time forward 2.563940 sec\n",
      "loss time 0.001167 sec\n",
      "backward time 0.095606 sec\n",
      "optimizer time 0.091455 sec\n",
      "training time in round 203 cost 0.5843429565429688 sec\n",
      "loss 8443.828614, train acc 0.110600\n",
      "round 204\n",
      "time to device 0.007124 sec\n",
      "time forward 2.568848 sec\n",
      "loss time 0.000504 sec\n",
      "backward time 0.004100 sec\n",
      "optimizer time 0.012523 sec\n",
      "training time in round 204 cost 0.3558797836303711 sec\n",
      "loss 8402.650621, train acc 0.110404\n",
      "round 205\n",
      "time to device 0.007894 sec\n",
      "time forward 2.578064 sec\n",
      "loss time 0.000411 sec\n",
      "backward time 0.004155 sec\n",
      "optimizer time 0.013084 sec\n",
      "training time in round 205 cost 0.4032721519470215 sec\n",
      "loss 8361.872309, train acc 0.110247\n",
      "round 206\n",
      "time to device 0.007113 sec\n",
      "time forward 2.588227 sec\n",
      "loss time 0.001256 sec\n",
      "backward time 0.005695 sec\n",
      "optimizer time 0.025366 sec\n",
      "training time in round 206 cost 0.45807886123657227 sec\n",
      "loss 8321.489638, train acc 0.110130\n",
      "round 207\n",
      "time to device 0.008126 sec\n",
      "time forward 2.598366 sec\n",
      "loss time 0.000860 sec\n",
      "backward time 0.003806 sec\n",
      "optimizer time 0.020673 sec\n",
      "training time in round 207 cost 0.4690558910369873 sec\n",
      "loss 8281.493484, train acc 0.110089\n",
      "round 208\n",
      "time to device 0.007042 sec\n",
      "time forward 2.610946 sec\n",
      "loss time 0.000534 sec\n",
      "backward time 0.006176 sec\n",
      "optimizer time 0.021969 sec\n",
      "training time in round 208 cost 0.462050199508667 sec\n",
      "loss 8241.880599, train acc 0.109973\n",
      "round 209\n",
      "time to device 0.005718 sec\n",
      "time forward 2.617179 sec\n",
      "loss time 0.000430 sec\n",
      "backward time 0.004075 sec\n",
      "optimizer time 0.016093 sec\n",
      "training time in round 209 cost 0.4279778003692627 sec\n",
      "loss 8202.645224, train acc 0.109933\n",
      "round 210\n",
      "time to device 0.006239 sec\n",
      "time forward 2.623326 sec\n",
      "loss time 0.000504 sec\n",
      "backward time 0.004383 sec\n",
      "optimizer time 0.013033 sec\n",
      "training time in round 210 cost 0.38295412063598633 sec\n",
      "loss 8163.781526, train acc 0.109782\n",
      "round 211\n",
      "time to device 0.004697 sec\n",
      "time forward 2.630084 sec\n",
      "loss time 0.000879 sec\n",
      "backward time 0.008280 sec\n",
      "optimizer time 0.019338 sec\n",
      "training time in round 211 cost 0.3728749752044678 sec\n",
      "loss 8125.284205, train acc 0.109670\n",
      "round 212\n",
      "time to device 0.004531 sec\n",
      "time forward 2.637851 sec\n",
      "loss time 0.000886 sec\n",
      "backward time 0.008313 sec\n",
      "optimizer time 0.019609 sec\n",
      "training time in round 212 cost 0.3811659812927246 sec\n",
      "loss 8087.148794, train acc 0.109705\n",
      "round 213\n",
      "time to device 0.006610 sec\n",
      "time forward 2.648756 sec\n",
      "loss time 0.000424 sec\n",
      "backward time 0.004190 sec\n",
      "optimizer time 0.014587 sec\n",
      "training time in round 213 cost 0.39248108863830566 sec\n",
      "loss 8049.369210, train acc 0.109777\n",
      "round 214\n",
      "time to device 0.005096 sec\n",
      "time forward 2.653805 sec\n",
      "loss time 0.000529 sec\n",
      "backward time 0.004577 sec\n",
      "optimizer time 0.013397 sec\n",
      "training time in round 214 cost 0.35721802711486816 sec\n",
      "loss 8011.943622, train acc 0.109738\n",
      "round 215\n",
      "time to device 0.005842 sec\n",
      "time forward 2.662250 sec\n",
      "loss time 0.000611 sec\n",
      "backward time 0.003552 sec\n",
      "optimizer time 0.013948 sec\n",
      "training time in round 215 cost 0.4090430736541748 sec\n",
      "loss 7974.862230, train acc 0.109556\n",
      "round 216\n",
      "time to device 0.005414 sec\n",
      "time forward 2.669514 sec\n",
      "loss time 0.000423 sec\n",
      "backward time 0.003501 sec\n",
      "optimizer time 0.016281 sec\n",
      "training time in round 216 cost 0.4231600761413574 sec\n",
      "loss 7938.122766, train acc 0.109555\n",
      "round 217\n",
      "time to device 0.006607 sec\n",
      "time forward 2.675924 sec\n",
      "loss time 0.000515 sec\n",
      "backward time 0.003885 sec\n",
      "optimizer time 0.012880 sec\n",
      "training time in round 217 cost 0.3974111080169678 sec\n",
      "loss 7901.720538, train acc 0.109411\n",
      "round 218\n",
      "time to device 0.006748 sec\n",
      "time forward 2.682367 sec\n",
      "loss time 0.000564 sec\n",
      "backward time 0.003625 sec\n",
      "optimizer time 0.018605 sec\n",
      "training time in round 218 cost 0.4174778461456299 sec\n",
      "loss 7865.651803, train acc 0.109304\n",
      "round 219\n",
      "time to device 0.008135 sec\n",
      "time forward 2.688676 sec\n",
      "loss time 0.000371 sec\n",
      "backward time 0.003767 sec\n",
      "optimizer time 0.015253 sec\n",
      "training time in round 219 cost 0.38279199600219727 sec\n",
      "loss 7829.909601, train acc 0.109411\n",
      "round 220\n",
      "time to device 0.006317 sec\n",
      "time forward 2.697024 sec\n",
      "loss time 0.001084 sec\n",
      "backward time 0.008073 sec\n",
      "optimizer time 0.020720 sec\n",
      "training time in round 220 cost 0.36002492904663086 sec\n",
      "loss 7794.491089, train acc 0.109410\n",
      "round 221\n",
      "time to device 0.007946 sec\n",
      "time forward 2.702214 sec\n",
      "loss time 0.000569 sec\n",
      "backward time 0.005157 sec\n",
      "optimizer time 0.015225 sec\n",
      "training time in round 221 cost 0.3498702049255371 sec\n",
      "loss 7759.391201, train acc 0.109340\n",
      "round 222\n",
      "time to device 0.006904 sec\n",
      "time forward 2.707510 sec\n",
      "loss time 0.000507 sec\n",
      "backward time 0.004501 sec\n",
      "optimizer time 0.013367 sec\n",
      "training time in round 222 cost 0.373187780380249 sec\n",
      "loss 7724.606134, train acc 0.109410\n",
      "round 223\n",
      "time to device 0.006970 sec\n",
      "time forward 2.714262 sec\n",
      "loss time 0.000422 sec\n",
      "backward time 0.005659 sec\n",
      "optimizer time 0.016791 sec\n",
      "training time in round 223 cost 0.39895200729370117 sec\n",
      "loss 7690.131572, train acc 0.109340\n",
      "round 224\n",
      "time to device 0.006768 sec\n",
      "time forward 2.721955 sec\n",
      "loss time 0.001312 sec\n",
      "backward time 0.009406 sec\n",
      "optimizer time 0.014134 sec\n",
      "training time in round 224 cost 0.41970205307006836 sec\n",
      "loss 7655.963427, train acc 0.109271\n",
      "round 225\n",
      "time to device 0.006059 sec\n",
      "time forward 2.727587 sec\n",
      "loss time 0.000395 sec\n",
      "backward time 0.004075 sec\n",
      "optimizer time 0.011876 sec\n",
      "training time in round 225 cost 0.3989748954772949 sec\n",
      "loss 7622.097915, train acc 0.109306\n",
      "round 226\n",
      "time to device 0.006678 sec\n",
      "time forward 2.733772 sec\n",
      "loss time 0.000624 sec\n",
      "backward time 0.004833 sec\n",
      "optimizer time 0.014061 sec\n",
      "training time in round 226 cost 0.3727729320526123 sec\n",
      "loss 7588.531166, train acc 0.109341\n",
      "round 227\n",
      "time to device 0.004456 sec\n",
      "time forward 2.741449 sec\n",
      "loss time 0.000394 sec\n",
      "backward time 0.005583 sec\n",
      "optimizer time 0.014717 sec\n",
      "training time in round 227 cost 0.39456892013549805 sec\n",
      "loss 7555.258622, train acc 0.109238\n",
      "round 228\n",
      "time to device 0.005710 sec\n",
      "time forward 2.746317 sec\n",
      "loss time 0.000459 sec\n",
      "backward time 0.004221 sec\n",
      "optimizer time 0.012235 sec\n",
      "training time in round 228 cost 0.3366539478302002 sec\n",
      "loss 7522.276452, train acc 0.109068\n",
      "round 229\n",
      "time to device 0.005056 sec\n",
      "time forward 2.752105 sec\n",
      "loss time 0.000760 sec\n",
      "backward time 0.006174 sec\n",
      "optimizer time 0.016591 sec\n",
      "training time in round 229 cost 0.34702491760253906 sec\n",
      "loss 7489.581431, train acc 0.109035\n",
      "round 230\n",
      "time to device 0.009586 sec\n",
      "time forward 2.757881 sec\n",
      "loss time 0.000795 sec\n",
      "backward time 0.006784 sec\n",
      "optimizer time 0.015274 sec\n",
      "training time in round 230 cost 0.37017083168029785 sec\n",
      "loss 7457.169112, train acc 0.108969\n",
      "round 231\n",
      "time to device 0.005269 sec\n",
      "time forward 2.762660 sec\n",
      "loss time 0.000517 sec\n",
      "backward time 0.004497 sec\n",
      "optimizer time 0.013602 sec\n",
      "training time in round 231 cost 0.3326880931854248 sec\n",
      "loss 7425.036277, train acc 0.108870\n",
      "round 232\n",
      "time to device 0.006486 sec\n",
      "time forward 2.768883 sec\n",
      "loss time 0.000656 sec\n",
      "backward time 0.011988 sec\n",
      "optimizer time 0.014732 sec\n",
      "training time in round 232 cost 0.3611891269683838 sec\n",
      "loss 7393.179137, train acc 0.108839\n",
      "round 233\n",
      "time to device 0.006765 sec\n",
      "time forward 2.774853 sec\n",
      "loss time 0.000609 sec\n",
      "backward time 0.005401 sec\n",
      "optimizer time 0.014712 sec\n",
      "training time in round 233 cost 0.34864306449890137 sec\n",
      "loss 7361.594335, train acc 0.108841\n",
      "round 234\n",
      "time to device 0.004669 sec\n",
      "time forward 2.781497 sec\n",
      "loss time 0.001031 sec\n",
      "backward time 0.006635 sec\n",
      "optimizer time 0.021163 sec\n",
      "training time in round 234 cost 0.35203003883361816 sec\n",
      "loss 7330.278330, train acc 0.108743\n",
      "round 235\n",
      "time to device 0.006199 sec\n",
      "time forward 2.787606 sec\n",
      "loss time 0.000525 sec\n",
      "backward time 0.005742 sec\n",
      "optimizer time 0.015216 sec\n",
      "training time in round 235 cost 0.40021395683288574 sec\n",
      "loss 7299.227546, train acc 0.108614\n",
      "round 236\n",
      "time to device 0.002147 sec\n",
      "time forward 2.793344 sec\n",
      "loss time 0.000460 sec\n",
      "backward time 0.004317 sec\n",
      "optimizer time 0.012428 sec\n",
      "training time in round 236 cost 0.3571350574493408 sec\n",
      "loss 7268.438996, train acc 0.108485\n",
      "round 237\n",
      "time to device 0.003791 sec\n",
      "time forward 2.800580 sec\n",
      "loss time 0.000702 sec\n",
      "backward time 0.005480 sec\n",
      "optimizer time 0.023122 sec\n",
      "training time in round 237 cost 0.3512692451477051 sec\n",
      "loss 7237.909081, train acc 0.108587\n",
      "round 238\n",
      "time to device 0.003077 sec\n",
      "time forward 2.810322 sec\n",
      "loss time 0.000927 sec\n",
      "backward time 0.008608 sec\n",
      "optimizer time 0.027071 sec\n",
      "training time in round 238 cost 0.39969515800476074 sec\n",
      "loss 7207.634505, train acc 0.108558\n",
      "round 239\n",
      "time to device 0.006339 sec\n",
      "time forward 2.817971 sec\n",
      "loss time 0.000629 sec\n",
      "backward time 0.006347 sec\n",
      "optimizer time 0.019052 sec\n",
      "training time in round 239 cost 0.3538696765899658 sec\n",
      "loss 7177.612304, train acc 0.108301\n",
      "round 240\n",
      "time to device 0.006356 sec\n",
      "time forward 2.827034 sec\n",
      "loss time 0.000369 sec\n",
      "backward time 0.003879 sec\n",
      "optimizer time 0.012615 sec\n",
      "training time in round 240 cost 0.39859700202941895 sec\n",
      "loss 7147.839328, train acc 0.108402\n",
      "round 241\n",
      "time to device 0.007037 sec\n",
      "time forward 2.833509 sec\n",
      "loss time 0.000516 sec\n",
      "backward time 0.003857 sec\n",
      "optimizer time 0.012981 sec\n",
      "training time in round 241 cost 0.3686189651489258 sec\n",
      "loss 7118.312332, train acc 0.108148\n",
      "round 242\n",
      "time to device 0.004976 sec\n",
      "time forward 2.839910 sec\n",
      "loss time 0.000495 sec\n",
      "backward time 0.003886 sec\n",
      "optimizer time 0.011137 sec\n",
      "training time in round 242 cost 0.37014079093933105 sec\n",
      "loss 7089.028393, train acc 0.108185\n",
      "round 243\n",
      "time to device 0.006036 sec\n",
      "time forward 2.847387 sec\n",
      "loss time 0.000899 sec\n",
      "backward time 0.008799 sec\n",
      "optimizer time 0.027602 sec\n",
      "training time in round 243 cost 0.3707292079925537 sec\n",
      "loss 7059.984644, train acc 0.108126\n",
      "round 244\n",
      "time to device 0.006869 sec\n",
      "time forward 2.852931 sec\n",
      "loss time 0.000422 sec\n",
      "backward time 0.004013 sec\n",
      "optimizer time 0.011451 sec\n",
      "training time in round 244 cost 0.3676280975341797 sec\n",
      "loss 7031.178343, train acc 0.107972\n",
      "round 245\n",
      "time to device 0.006638 sec\n",
      "time forward 2.858796 sec\n",
      "loss time 0.000410 sec\n",
      "backward time 0.005672 sec\n",
      "optimizer time 0.011699 sec\n",
      "training time in round 245 cost 0.35239291191101074 sec\n",
      "loss 7002.605808, train acc 0.107946\n",
      "round 246\n",
      "time to device 0.004705 sec\n",
      "time forward 2.863322 sec\n",
      "loss time 0.000624 sec\n",
      "backward time 0.005413 sec\n",
      "optimizer time 0.013692 sec\n",
      "training time in round 246 cost 0.3380239009857178 sec\n",
      "loss 6974.264388, train acc 0.107952\n",
      "round 247\n",
      "time to device 0.003814 sec\n",
      "time forward 2.868516 sec\n",
      "loss time 0.000466 sec\n",
      "backward time 0.003843 sec\n",
      "optimizer time 0.011888 sec\n",
      "training time in round 247 cost 0.32827281951904297 sec\n",
      "loss 6946.152052, train acc 0.107768\n",
      "round 248\n",
      "time to device 0.002428 sec\n",
      "time forward 2.873251 sec\n",
      "loss time 0.000464 sec\n",
      "backward time 0.004265 sec\n",
      "optimizer time 0.012227 sec\n",
      "training time in round 248 cost 0.3328230381011963 sec\n",
      "loss 6918.265300, train acc 0.107775\n",
      "round 249\n",
      "time to device 0.002589 sec\n",
      "time forward 2.878901 sec\n",
      "loss time 0.000459 sec\n",
      "backward time 0.003701 sec\n",
      "optimizer time 0.011630 sec\n",
      "training time in round 249 cost 0.3853328227996826 sec\n",
      "loss 6890.602005, train acc 0.107594\n",
      "round 250\n",
      "time to device 0.003895 sec\n",
      "time forward 2.885031 sec\n",
      "loss time 0.000883 sec\n",
      "backward time 0.007969 sec\n",
      "optimizer time 0.019133 sec\n",
      "training time in round 250 cost 0.34504175186157227 sec\n",
      "loss 6863.158642, train acc 0.107601\n",
      "round 251\n",
      "time to device 0.004700 sec\n",
      "time forward 2.893994 sec\n",
      "loss time 0.000578 sec\n",
      "backward time 0.006322 sec\n",
      "optimizer time 0.019161 sec\n",
      "training time in round 251 cost 0.4137389659881592 sec\n",
      "loss 6835.933399, train acc 0.107670\n",
      "round 252\n",
      "time to device 0.006297 sec\n",
      "time forward 2.899812 sec\n",
      "loss time 0.000760 sec\n",
      "backward time 0.007178 sec\n",
      "optimizer time 0.017212 sec\n",
      "training time in round 252 cost 0.3882601261138916 sec\n",
      "loss 6808.922995, train acc 0.107553\n",
      "round 253\n",
      "time to device 0.006427 sec\n",
      "time forward 2.910005 sec\n",
      "loss time 0.000883 sec\n",
      "backward time 0.008278 sec\n",
      "optimizer time 0.019510 sec\n",
      "training time in round 253 cost 0.4110572338104248 sec\n",
      "loss 6782.125382, train acc 0.107560\n",
      "round 254\n",
      "time to device 0.006949 sec\n",
      "time forward 2.917799 sec\n",
      "loss time 0.000509 sec\n",
      "backward time 0.004714 sec\n",
      "optimizer time 0.010193 sec\n",
      "training time in round 254 cost 0.35185885429382324 sec\n",
      "loss 6755.538420, train acc 0.107598\n",
      "round 255\n",
      "time to device 0.006786 sec\n",
      "time forward 2.927877 sec\n",
      "loss time 0.000958 sec\n",
      "backward time 0.008745 sec\n",
      "optimizer time 0.018200 sec\n",
      "training time in round 255 cost 0.37672877311706543 sec\n",
      "loss 6729.158721, train acc 0.107605\n",
      "round 256\n",
      "time to device 0.005386 sec\n",
      "time forward 2.934843 sec\n",
      "loss time 0.000559 sec\n",
      "backward time 0.005454 sec\n",
      "optimizer time 0.015080 sec\n",
      "training time in round 256 cost 0.3791959285736084 sec\n",
      "loss 6702.984599, train acc 0.107642\n",
      "round 257\n",
      "time to device 0.004832 sec\n",
      "time forward 2.941288 sec\n",
      "loss time 0.000853 sec\n",
      "backward time 0.005386 sec\n",
      "optimizer time 0.018516 sec\n",
      "training time in round 257 cost 0.3771040439605713 sec\n",
      "loss 6677.012942, train acc 0.107710\n",
      "round 258\n",
      "time to device 0.006068 sec\n",
      "time forward 2.946773 sec\n",
      "loss time 0.000437 sec\n",
      "backward time 0.006598 sec\n",
      "optimizer time 0.015615 sec\n",
      "training time in round 258 cost 0.35465002059936523 sec\n",
      "loss 6651.241880, train acc 0.107656\n",
      "round 259\n",
      "time to device 0.012744 sec\n",
      "time forward 2.958853 sec\n",
      "loss time 0.000552 sec\n",
      "backward time 0.004987 sec\n",
      "optimizer time 0.015359 sec\n",
      "training time in round 259 cost 0.38541603088378906 sec\n",
      "loss 6625.669153, train acc 0.107632\n",
      "round 260\n",
      "time to device 0.006607 sec\n",
      "time forward 2.965194 sec\n",
      "loss time 0.000478 sec\n",
      "backward time 0.004122 sec\n",
      "optimizer time 0.011881 sec\n",
      "training time in round 260 cost 0.34775662422180176 sec\n",
      "loss 6600.292596, train acc 0.107729\n",
      "round 261\n",
      "time to device 0.006726 sec\n",
      "time forward 2.971576 sec\n",
      "loss time 0.000449 sec\n",
      "backward time 0.004219 sec\n",
      "optimizer time 0.012492 sec\n",
      "training time in round 261 cost 0.37550997734069824 sec\n",
      "loss 6575.109583, train acc 0.107765\n",
      "round 262\n",
      "time to device 0.004356 sec\n",
      "time forward 2.977513 sec\n",
      "loss time 0.000725 sec\n",
      "backward time 0.006495 sec\n",
      "optimizer time 0.021597 sec\n",
      "training time in round 262 cost 0.3469521999359131 sec\n",
      "loss 6550.118669, train acc 0.107622\n",
      "round 263\n",
      "time to device 0.006645 sec\n",
      "time forward 2.987072 sec\n",
      "loss time 0.001066 sec\n",
      "backward time 0.015295 sec\n",
      "optimizer time 0.020843 sec\n",
      "training time in round 263 cost 0.3749511241912842 sec\n",
      "loss 6525.316348, train acc 0.107422\n",
      "round 264\n",
      "time to device 0.005182 sec\n",
      "time forward 2.992086 sec\n",
      "loss time 0.000452 sec\n",
      "backward time 0.004004 sec\n",
      "optimizer time 0.012410 sec\n",
      "training time in round 264 cost 0.34008121490478516 sec\n",
      "loss 6500.701333, train acc 0.107311\n",
      "round 265\n",
      "time to device 0.005124 sec\n",
      "time forward 2.997071 sec\n",
      "loss time 0.000412 sec\n",
      "backward time 0.003663 sec\n",
      "optimizer time 0.010836 sec\n",
      "training time in round 265 cost 0.3406636714935303 sec\n",
      "loss 6476.272204, train acc 0.107260\n",
      "round 266\n",
      "time to device 0.005291 sec\n",
      "time forward 3.006063 sec\n",
      "loss time 0.000471 sec\n",
      "backward time 0.004264 sec\n",
      "optimizer time 0.013865 sec\n",
      "training time in round 266 cost 0.3674352169036865 sec\n",
      "loss 6452.025307, train acc 0.107210\n",
      "round 267\n",
      "time to device 0.003892 sec\n",
      "time forward 3.014108 sec\n",
      "loss time 0.000859 sec\n",
      "backward time 0.008140 sec\n",
      "optimizer time 0.020248 sec\n",
      "training time in round 267 cost 0.35675907135009766 sec\n",
      "loss 6427.959300, train acc 0.107072\n",
      "round 268\n",
      "time to device 0.004539 sec\n",
      "time forward 3.022789 sec\n",
      "loss time 0.000483 sec\n",
      "backward time 0.004460 sec\n",
      "optimizer time 0.012075 sec\n",
      "training time in round 268 cost 0.3678438663482666 sec\n",
      "loss 6404.072260, train acc 0.106993\n",
      "round 269\n",
      "time to device 0.005980 sec\n",
      "time forward 3.027923 sec\n",
      "loss time 0.000523 sec\n",
      "backward time 0.004608 sec\n",
      "optimizer time 0.012385 sec\n",
      "training time in round 269 cost 0.35443711280822754 sec\n",
      "loss 6380.362642, train acc 0.106944\n",
      "round 270\n",
      "time to device 0.005224 sec\n",
      "time forward 3.032200 sec\n",
      "loss time 0.000572 sec\n",
      "backward time 0.005205 sec\n",
      "optimizer time 0.013533 sec\n",
      "training time in round 270 cost 0.3273162841796875 sec\n",
      "loss 6356.827425, train acc 0.106953\n",
      "round 271\n",
      "time to device 0.004127 sec\n",
      "time forward 3.036368 sec\n",
      "loss time 0.000393 sec\n",
      "backward time 0.003537 sec\n",
      "optimizer time 0.010568 sec\n",
      "training time in round 271 cost 0.32793092727661133 sec\n",
      "loss 6333.465209, train acc 0.106790\n",
      "round 272\n",
      "time to device 0.004697 sec\n",
      "time forward 3.042943 sec\n",
      "loss time 0.000743 sec\n",
      "backward time 0.006496 sec\n",
      "optimizer time 0.016357 sec\n",
      "training time in round 272 cost 0.34749507904052734 sec\n",
      "loss 6310.274180, train acc 0.106685\n",
      "round 273\n",
      "time to device 0.004882 sec\n",
      "time forward 3.051998 sec\n",
      "loss time 0.001083 sec\n",
      "backward time 0.008830 sec\n",
      "optimizer time 0.019862 sec\n",
      "training time in round 273 cost 0.37476301193237305 sec\n",
      "loss 6287.252361, train acc 0.106723\n",
      "round 274\n",
      "time to device 0.004899 sec\n",
      "time forward 3.058125 sec\n",
      "loss time 0.000579 sec\n",
      "backward time 0.005458 sec\n",
      "optimizer time 0.014510 sec\n",
      "training time in round 274 cost 0.3849809169769287 sec\n",
      "loss 6264.397996, train acc 0.106648\n",
      "round 275\n",
      "time to device 0.007383 sec\n",
      "time forward 3.067219 sec\n",
      "loss time 0.001095 sec\n",
      "backward time 0.004027 sec\n",
      "optimizer time 0.012101 sec\n",
      "training time in round 275 cost 0.36888623237609863 sec\n",
      "loss 6241.709288, train acc 0.106516\n",
      "round 276\n",
      "time to device 0.006754 sec\n",
      "time forward 3.075445 sec\n",
      "loss time 0.000863 sec\n",
      "backward time 0.008279 sec\n",
      "optimizer time 0.019676 sec\n",
      "training time in round 276 cost 0.3622150421142578 sec\n",
      "loss 6219.184369, train acc 0.106470\n",
      "round 277\n",
      "time to device 0.003956 sec\n",
      "time forward 3.083558 sec\n",
      "loss time 0.000393 sec\n",
      "backward time 0.003511 sec\n",
      "optimizer time 0.011402 sec\n",
      "training time in round 277 cost 0.36393189430236816 sec\n",
      "loss 6196.821499, train acc 0.106284\n",
      "round 278\n",
      "time to device 0.006189 sec\n",
      "time forward 3.092248 sec\n",
      "loss time 0.001323 sec\n",
      "backward time 0.004759 sec\n",
      "optimizer time 0.021283 sec\n",
      "training time in round 278 cost 0.3727428913116455 sec\n",
      "loss 6174.618947, train acc 0.106295\n",
      "round 279\n",
      "time to device 0.004565 sec\n",
      "time forward 3.102651 sec\n",
      "loss time 0.000674 sec\n",
      "backward time 0.009660 sec\n",
      "optimizer time 0.020365 sec\n",
      "training time in round 279 cost 0.4290289878845215 sec\n",
      "loss 6152.575269, train acc 0.106222\n",
      "round 280\n",
      "time to device 0.004773 sec\n",
      "time forward 3.107712 sec\n",
      "loss time 0.000423 sec\n",
      "backward time 0.003484 sec\n",
      "optimizer time 0.011821 sec\n",
      "training time in round 280 cost 0.3446009159088135 sec\n",
      "loss 6130.688178, train acc 0.106206\n",
      "round 281\n",
      "time to device 0.005492 sec\n",
      "time forward 3.113199 sec\n",
      "loss time 0.000525 sec\n",
      "backward time 0.004867 sec\n",
      "optimizer time 0.013675 sec\n",
      "training time in round 281 cost 0.3666539192199707 sec\n",
      "loss 6108.956529, train acc 0.106051\n",
      "round 282\n",
      "time to device 0.006614 sec\n",
      "time forward 3.119735 sec\n",
      "loss time 0.000850 sec\n",
      "backward time 0.007133 sec\n",
      "optimizer time 0.018429 sec\n",
      "training time in round 282 cost 0.3432028293609619 sec\n",
      "loss 6087.378320, train acc 0.106007\n",
      "round 283\n",
      "time to device 0.007784 sec\n",
      "time forward 3.127377 sec\n",
      "loss time 0.001394 sec\n",
      "backward time 0.010601 sec\n",
      "optimizer time 0.021461 sec\n",
      "training time in round 283 cost 0.3744850158691406 sec\n",
      "loss 6065.952040, train acc 0.105991\n",
      "round 284\n",
      "time to device 0.004705 sec\n",
      "time forward 3.133477 sec\n",
      "loss time 0.000643 sec\n",
      "backward time 0.005386 sec\n",
      "optimizer time 0.012548 sec\n",
      "training time in round 284 cost 0.36240077018737793 sec\n",
      "loss 6044.676042, train acc 0.105894\n",
      "round 285\n",
      "time to device 0.006435 sec\n",
      "time forward 3.143705 sec\n",
      "loss time 0.000599 sec\n",
      "backward time 0.004205 sec\n",
      "optimizer time 0.015613 sec\n",
      "training time in round 285 cost 0.3925759792327881 sec\n",
      "loss 6023.548855, train acc 0.105797\n",
      "round 286\n",
      "time to device 0.004272 sec\n",
      "time forward 3.148734 sec\n",
      "loss time 0.000478 sec\n",
      "backward time 0.004156 sec\n",
      "optimizer time 0.013684 sec\n",
      "training time in round 286 cost 0.334867000579834 sec\n",
      "loss 6002.568944, train acc 0.105809\n",
      "round 287\n",
      "time to device 0.005701 sec\n",
      "time forward 3.157559 sec\n",
      "loss time 0.001250 sec\n",
      "backward time 0.003851 sec\n",
      "optimizer time 0.013667 sec\n",
      "training time in round 287 cost 0.4103851318359375 sec\n",
      "loss 5981.734823, train acc 0.105659\n",
      "round 288\n",
      "time to device 0.006480 sec\n",
      "time forward 3.166329 sec\n",
      "loss time 0.000874 sec\n",
      "backward time 0.008182 sec\n",
      "optimizer time 0.019539 sec\n",
      "training time in round 288 cost 0.3617227077484131 sec\n",
      "loss 5961.044747, train acc 0.105699\n",
      "round 289\n",
      "time to device 0.005587 sec\n",
      "time forward 3.178577 sec\n",
      "loss time 0.000437 sec\n",
      "backward time 0.003704 sec\n",
      "optimizer time 0.012291 sec\n",
      "training time in round 289 cost 0.3687269687652588 sec\n",
      "loss 5940.497655, train acc 0.105684\n",
      "round 290\n",
      "time to device 0.007250 sec\n",
      "time forward 3.190026 sec\n",
      "loss time 0.001327 sec\n",
      "backward time 0.009829 sec\n",
      "optimizer time 0.019404 sec\n",
      "training time in round 290 cost 0.37835001945495605 sec\n",
      "loss 5920.091716, train acc 0.105616\n",
      "round 291\n",
      "time to device 0.007588 sec\n",
      "time forward 3.201250 sec\n",
      "loss time 0.001134 sec\n",
      "backward time 0.008498 sec\n",
      "optimizer time 0.019565 sec\n",
      "training time in round 291 cost 0.37491583824157715 sec\n",
      "loss 5899.825577, train acc 0.105442\n",
      "round 292\n",
      "time to device 0.007003 sec\n",
      "time forward 3.210721 sec\n",
      "loss time 0.001308 sec\n",
      "backward time 0.009652 sec\n",
      "optimizer time 0.020123 sec\n",
      "training time in round 292 cost 0.37914323806762695 sec\n",
      "loss 5879.697700, train acc 0.105215\n",
      "round 293\n",
      "time to device 0.007447 sec\n",
      "time forward 3.221824 sec\n",
      "loss time 0.001132 sec\n",
      "backward time 0.008200 sec\n",
      "optimizer time 0.019374 sec\n",
      "training time in round 293 cost 0.38542795181274414 sec\n",
      "loss 5859.706569, train acc 0.105150\n",
      "round 294\n",
      "time to device 0.007851 sec\n",
      "time forward 3.229088 sec\n",
      "loss time 0.000420 sec\n",
      "backward time 0.004196 sec\n",
      "optimizer time 0.012450 sec\n",
      "training time in round 294 cost 0.363192081451416 sec\n",
      "loss 5839.850966, train acc 0.105005\n",
      "round 295\n",
      "time to device 0.004234 sec\n",
      "time forward 3.237010 sec\n",
      "loss time 0.001215 sec\n",
      "backward time 0.008573 sec\n",
      "optimizer time 0.020340 sec\n",
      "training time in round 295 cost 0.38191819190979004 sec\n",
      "loss 5820.129547, train acc 0.105126\n",
      "round 296\n",
      "time to device 0.004540 sec\n",
      "time forward 3.241815 sec\n",
      "loss time 0.000458 sec\n",
      "backward time 0.003825 sec\n",
      "optimizer time 0.012816 sec\n",
      "training time in round 296 cost 0.35381507873535156 sec\n",
      "loss 5800.540864, train acc 0.105087\n",
      "round 297\n",
      "time to device 0.006460 sec\n",
      "time forward 3.251313 sec\n",
      "loss time 0.000553 sec\n",
      "backward time 0.004432 sec\n",
      "optimizer time 0.015347 sec\n",
      "training time in round 297 cost 0.3835029602050781 sec\n",
      "loss 5781.083774, train acc 0.105023\n",
      "round 298\n",
      "time to device 0.006506 sec\n",
      "time forward 3.256333 sec\n",
      "loss time 0.000385 sec\n",
      "backward time 0.005454 sec\n",
      "optimizer time 0.012236 sec\n",
      "training time in round 298 cost 0.34665822982788086 sec\n",
      "loss 5761.756741, train acc 0.104933\n",
      "round 299\n",
      "time to device 0.004777 sec\n",
      "time forward 3.264316 sec\n",
      "loss time 0.001071 sec\n",
      "backward time 0.008785 sec\n",
      "optimizer time 0.021259 sec\n",
      "training time in round 299 cost 0.3659629821777344 sec\n",
      "loss 5742.558699, train acc 0.105052\n",
      "round 300\n",
      "time to device 0.005203 sec\n",
      "time forward 3.270231 sec\n",
      "loss time 0.000411 sec\n",
      "backward time 0.004202 sec\n",
      "optimizer time 0.012780 sec\n",
      "training time in round 300 cost 0.40472412109375 sec\n",
      "loss 5723.488254, train acc 0.105326\n",
      "round 301\n",
      "time to device 0.004602 sec\n",
      "time forward 3.275578 sec\n",
      "loss time 0.000599 sec\n",
      "backward time 0.005619 sec\n",
      "optimizer time 0.016110 sec\n",
      "training time in round 301 cost 0.3411428928375244 sec\n",
      "loss 5704.543942, train acc 0.105236\n",
      "round 302\n",
      "time to device 0.004505 sec\n",
      "time forward 3.280048 sec\n",
      "loss time 0.000458 sec\n",
      "backward time 0.003957 sec\n",
      "optimizer time 0.012221 sec\n",
      "training time in round 302 cost 0.34635186195373535 sec\n",
      "loss 5685.724748, train acc 0.105301\n",
      "round 303\n",
      "time to device 0.007035 sec\n",
      "time forward 3.286373 sec\n",
      "loss time 0.000351 sec\n",
      "backward time 0.004111 sec\n",
      "optimizer time 0.010743 sec\n",
      "training time in round 303 cost 0.37344789505004883 sec\n",
      "loss 5667.029772, train acc 0.105289\n",
      "round 304\n",
      "time to device 0.004356 sec\n",
      "time forward 3.292810 sec\n",
      "loss time 0.000888 sec\n",
      "backward time 0.003875 sec\n",
      "optimizer time 0.023702 sec\n",
      "training time in round 304 cost 0.3927428722381592 sec\n",
      "loss 5648.457092, train acc 0.105379\n",
      "round 305\n",
      "time to device 0.006395 sec\n",
      "time forward 3.298068 sec\n",
      "loss time 0.000399 sec\n",
      "backward time 0.003908 sec\n",
      "optimizer time 0.013502 sec\n",
      "training time in round 305 cost 0.398698091506958 sec\n",
      "loss 5630.005518, train acc 0.105418\n",
      "round 306\n",
      "time to device 0.004330 sec\n",
      "time forward 3.306314 sec\n",
      "loss time 0.000437 sec\n",
      "backward time 0.003628 sec\n",
      "optimizer time 0.013717 sec\n",
      "training time in round 306 cost 0.36087703704833984 sec\n",
      "loss 5611.674242, train acc 0.105380\n",
      "round 307\n",
      "time to device 0.004392 sec\n",
      "time forward 3.313009 sec\n",
      "loss time 0.001033 sec\n",
      "backward time 0.010472 sec\n",
      "optimizer time 0.019968 sec\n",
      "training time in round 307 cost 0.3520340919494629 sec\n",
      "loss 5593.462402, train acc 0.105342\n",
      "round 308\n",
      "time to device 0.005012 sec\n",
      "time forward 3.321173 sec\n",
      "loss time 0.000483 sec\n",
      "backward time 0.004074 sec\n",
      "optimizer time 0.012762 sec\n",
      "training time in round 308 cost 0.357572078704834 sec\n",
      "loss 5575.368227, train acc 0.105153\n",
      "round 309\n",
      "time to device 0.006829 sec\n",
      "time forward 3.327354 sec\n",
      "loss time 0.000480 sec\n",
      "backward time 0.004201 sec\n",
      "optimizer time 0.012791 sec\n",
      "training time in round 309 cost 0.40213990211486816 sec\n",
      "loss 5557.390721, train acc 0.105166\n",
      "round 310\n",
      "time to device 0.007190 sec\n",
      "time forward 3.338066 sec\n",
      "loss time 0.000962 sec\n",
      "backward time 0.008614 sec\n",
      "optimizer time 0.021693 sec\n",
      "training time in round 310 cost 0.39469480514526367 sec\n",
      "loss 5539.528978, train acc 0.105155\n",
      "round 311\n",
      "time to device 0.006806 sec\n",
      "time forward 3.349016 sec\n",
      "loss time 0.001113 sec\n",
      "backward time 0.008406 sec\n",
      "optimizer time 0.019683 sec\n",
      "training time in round 311 cost 0.3794708251953125 sec\n",
      "loss 5521.781904, train acc 0.105218\n",
      "round 312\n",
      "time to device 0.005407 sec\n",
      "time forward 3.358112 sec\n",
      "loss time 0.001059 sec\n",
      "backward time 0.008463 sec\n",
      "optimizer time 0.019566 sec\n",
      "training time in round 312 cost 0.361954927444458 sec\n",
      "loss 5504.147838, train acc 0.105132\n",
      "round 313\n",
      "time to device 0.007060 sec\n",
      "time forward 3.366570 sec\n",
      "loss time 0.001065 sec\n",
      "backward time 0.008394 sec\n",
      "optimizer time 0.020123 sec\n",
      "training time in round 313 cost 0.4138319492340088 sec\n",
      "loss 5486.626065, train acc 0.105071\n",
      "round 314\n",
      "time to device 0.007001 sec\n",
      "time forward 3.375307 sec\n",
      "loss time 0.001054 sec\n",
      "backward time 0.008168 sec\n",
      "optimizer time 0.020172 sec\n",
      "training time in round 314 cost 0.3598017692565918 sec\n",
      "loss 5469.215571, train acc 0.105010\n",
      "round 315\n",
      "time to device 0.007062 sec\n",
      "time forward 3.384435 sec\n",
      "loss time 0.001055 sec\n",
      "backward time 0.008218 sec\n",
      "optimizer time 0.019602 sec\n",
      "training time in round 315 cost 0.361907958984375 sec\n",
      "loss 5451.915255, train acc 0.104999\n",
      "round 316\n",
      "time to device 0.007842 sec\n",
      "time forward 3.389416 sec\n",
      "loss time 0.000499 sec\n",
      "backward time 0.004417 sec\n",
      "optimizer time 0.013035 sec\n",
      "training time in round 316 cost 0.34381699562072754 sec\n",
      "loss 5434.724047, train acc 0.104890\n",
      "round 317\n",
      "time to device 0.006853 sec\n",
      "time forward 3.399941 sec\n",
      "loss time 0.000889 sec\n",
      "backward time 0.006942 sec\n",
      "optimizer time 0.017646 sec\n",
      "training time in round 317 cost 0.36754679679870605 sec\n",
      "loss 5417.641011, train acc 0.104928\n",
      "round 318\n",
      "time to device 0.012727 sec\n",
      "time forward 3.411885 sec\n",
      "loss time 0.001500 sec\n",
      "backward time 0.009257 sec\n",
      "optimizer time 0.020271 sec\n",
      "training time in round 318 cost 0.3887932300567627 sec\n",
      "loss 5400.665087, train acc 0.105138\n",
      "round 319\n",
      "time to device 0.006984 sec\n",
      "time forward 3.422780 sec\n",
      "loss time 0.001209 sec\n",
      "backward time 0.009455 sec\n",
      "optimizer time 0.020727 sec\n",
      "training time in round 319 cost 0.3754727840423584 sec\n",
      "loss 5383.795198, train acc 0.104980\n",
      "round 320\n",
      "time to device 0.006460 sec\n",
      "time forward 3.431248 sec\n",
      "loss time 0.001272 sec\n",
      "backward time 0.009164 sec\n",
      "optimizer time 0.020449 sec\n",
      "training time in round 320 cost 0.38021016120910645 sec\n",
      "loss 5367.030532, train acc 0.104945\n",
      "round 321\n",
      "time to device 0.007077 sec\n",
      "time forward 3.441044 sec\n",
      "loss time 0.001211 sec\n",
      "backward time 0.003664 sec\n",
      "optimizer time 0.011039 sec\n",
      "training time in round 321 cost 0.356611967086792 sec\n",
      "loss 5350.369921, train acc 0.104838\n",
      "round 322\n",
      "time to device 0.005239 sec\n",
      "time forward 3.451835 sec\n",
      "loss time 0.000844 sec\n",
      "backward time 0.008243 sec\n",
      "optimizer time 0.020291 sec\n",
      "training time in round 322 cost 0.37467312812805176 sec\n",
      "loss 5333.812664, train acc 0.104852\n",
      "round 323\n",
      "time to device 0.006584 sec\n",
      "time forward 3.460847 sec\n",
      "loss time 0.001225 sec\n",
      "backward time 0.009355 sec\n",
      "optimizer time 0.020842 sec\n",
      "training time in round 323 cost 0.37113380432128906 sec\n",
      "loss 5317.357413, train acc 0.104962\n",
      "round 324\n",
      "time to device 0.006507 sec\n",
      "time forward 3.468485 sec\n",
      "loss time 0.001095 sec\n",
      "backward time 0.009053 sec\n",
      "optimizer time 0.020132 sec\n",
      "training time in round 324 cost 0.3743000030517578 sec\n",
      "loss 5301.003929, train acc 0.104856\n",
      "round 325\n",
      "time to device 0.006475 sec\n",
      "time forward 3.480078 sec\n",
      "loss time 0.001087 sec\n",
      "backward time 0.008726 sec\n",
      "optimizer time 0.020469 sec\n",
      "training time in round 325 cost 0.37752294540405273 sec\n",
      "loss 5284.750328, train acc 0.104774\n",
      "round 326\n",
      "time to device 0.006711 sec\n",
      "time forward 3.490459 sec\n",
      "loss time 0.000933 sec\n",
      "backward time 0.005416 sec\n",
      "optimizer time 0.012502 sec\n",
      "training time in round 326 cost 0.3901381492614746 sec\n",
      "loss 5268.596030, train acc 0.104644\n",
      "round 327\n",
      "time to device 0.006460 sec\n",
      "time forward 3.504103 sec\n",
      "loss time 0.001183 sec\n",
      "backward time 0.008402 sec\n",
      "optimizer time 0.019984 sec\n",
      "training time in round 327 cost 0.3803281784057617 sec\n",
      "loss 5252.540383, train acc 0.104635\n",
      "round 328\n",
      "time to device 0.007128 sec\n",
      "time forward 3.511732 sec\n",
      "loss time 0.001052 sec\n",
      "backward time 0.008226 sec\n",
      "optimizer time 0.020066 sec\n",
      "training time in round 328 cost 0.3779580593109131 sec\n",
      "loss 5236.582290, train acc 0.104578\n",
      "round 329\n",
      "time to device 0.006333 sec\n",
      "time forward 3.522724 sec\n",
      "loss time 0.000836 sec\n",
      "backward time 0.008170 sec\n",
      "optimizer time 0.019343 sec\n",
      "training time in round 329 cost 0.3787670135498047 sec\n",
      "loss 5220.721100, train acc 0.104616\n",
      "round 330\n",
      "time to device 0.003852 sec\n",
      "time forward 3.537588 sec\n",
      "loss time 0.001900 sec\n",
      "backward time 0.009337 sec\n",
      "optimizer time 0.020597 sec\n",
      "training time in round 330 cost 0.3889610767364502 sec\n",
      "loss 5204.955778, train acc 0.104536\n",
      "round 331\n",
      "time to device 0.003778 sec\n",
      "time forward 3.547240 sec\n",
      "loss time 0.001085 sec\n",
      "backward time 0.008667 sec\n",
      "optimizer time 0.019820 sec\n",
      "training time in round 331 cost 0.35983991622924805 sec\n",
      "loss 5189.285237, train acc 0.104692\n",
      "round 332\n",
      "time to device 0.005692 sec\n",
      "time forward 3.555616 sec\n",
      "loss time 0.000601 sec\n",
      "backward time 0.005764 sec\n",
      "optimizer time 0.016020 sec\n",
      "training time in round 332 cost 0.3767058849334717 sec\n",
      "loss 5173.708867, train acc 0.104636\n",
      "round 333\n",
      "time to device 0.007006 sec\n",
      "time forward 3.562523 sec\n",
      "loss time 0.000555 sec\n",
      "backward time 0.005647 sec\n",
      "optimizer time 0.020508 sec\n",
      "training time in round 333 cost 0.4637320041656494 sec\n",
      "loss 5158.226414, train acc 0.104720\n",
      "round 334\n",
      "time to device 0.008035 sec\n",
      "time forward 3.575875 sec\n",
      "loss time 0.001152 sec\n",
      "backward time 0.012195 sec\n",
      "optimizer time 0.029021 sec\n",
      "training time in round 334 cost 0.5532209873199463 sec\n",
      "loss 5142.835630, train acc 0.104734\n",
      "round 335\n",
      "time to device 0.007467 sec\n",
      "time forward 3.588015 sec\n",
      "loss time 0.002072 sec\n",
      "backward time 0.015428 sec\n",
      "optimizer time 0.027956 sec\n",
      "training time in round 335 cost 0.4374079704284668 sec\n",
      "loss 5127.536478, train acc 0.104701\n",
      "round 336\n",
      "time to device 0.010242 sec\n",
      "time forward 3.605843 sec\n",
      "loss time 0.011058 sec\n",
      "backward time 0.005348 sec\n",
      "optimizer time 0.028468 sec\n",
      "training time in round 336 cost 0.4871187210083008 sec\n",
      "loss 5112.328108, train acc 0.104739\n",
      "round 337\n",
      "time to device 0.008839 sec\n",
      "time forward 3.624326 sec\n",
      "loss time 0.001550 sec\n",
      "backward time 0.019801 sec\n",
      "optimizer time 0.026308 sec\n",
      "training time in round 337 cost 0.48749279975891113 sec\n",
      "loss 5097.209729, train acc 0.104614\n",
      "round 338\n",
      "time to device 0.010518 sec\n",
      "time forward 3.634710 sec\n",
      "loss time 0.000604 sec\n",
      "backward time 0.007881 sec\n",
      "optimizer time 0.016524 sec\n",
      "training time in round 338 cost 0.37857580184936523 sec\n",
      "loss 5082.180749, train acc 0.104628\n",
      "round 339\n",
      "time to device 0.009974 sec\n",
      "time forward 3.642952 sec\n",
      "loss time 0.000769 sec\n",
      "backward time 0.006614 sec\n",
      "optimizer time 0.020370 sec\n",
      "training time in round 339 cost 0.6445262432098389 sec\n",
      "loss 5067.240055, train acc 0.104665\n",
      "round 340\n",
      "time to device 0.008209 sec\n",
      "time forward 3.659190 sec\n",
      "loss time 0.001108 sec\n",
      "backward time 0.012000 sec\n",
      "optimizer time 0.021212 sec\n",
      "training time in round 340 cost 0.466480016708374 sec\n",
      "loss 5052.387477, train acc 0.104678\n",
      "round 341\n",
      "time to device 0.006751 sec\n",
      "time forward 3.672393 sec\n",
      "loss time 0.001127 sec\n",
      "backward time 0.013540 sec\n",
      "optimizer time 0.019207 sec\n",
      "training time in round 341 cost 0.43198204040527344 sec\n",
      "loss 5037.621181, train acc 0.104669\n",
      "round 342\n",
      "time to device 0.007553 sec\n",
      "time forward 3.683936 sec\n",
      "loss time 0.000902 sec\n",
      "backward time 0.010268 sec\n",
      "optimizer time 0.037454 sec\n",
      "training time in round 342 cost 0.45214223861694336 sec\n",
      "loss 5022.940954, train acc 0.104615\n",
      "round 343\n",
      "time to device 0.009576 sec\n",
      "time forward 3.695248 sec\n",
      "loss time 0.001608 sec\n",
      "backward time 0.015430 sec\n",
      "optimizer time 0.025503 sec\n",
      "training time in round 343 cost 0.4181251525878906 sec\n",
      "loss 5008.346127, train acc 0.104538\n",
      "round 344\n",
      "time to device 0.008579 sec\n",
      "time forward 3.702771 sec\n",
      "loss time 0.000397 sec\n",
      "backward time 0.003754 sec\n",
      "optimizer time 0.012942 sec\n",
      "training time in round 344 cost 0.37615299224853516 sec\n",
      "loss 4993.835867, train acc 0.104642\n",
      "round 345\n",
      "time to device 0.006781 sec\n",
      "time forward 3.713839 sec\n",
      "loss time 0.000982 sec\n",
      "backward time 0.012878 sec\n",
      "optimizer time 0.031835 sec\n",
      "training time in round 345 cost 0.40856003761291504 sec\n",
      "loss 4979.409870, train acc 0.104701\n",
      "round 346\n",
      "time to device 0.009729 sec\n",
      "time forward 3.726324 sec\n",
      "loss time 0.001115 sec\n",
      "backward time 0.009755 sec\n",
      "optimizer time 0.026140 sec\n",
      "training time in round 346 cost 0.40259218215942383 sec\n",
      "loss 4965.066623, train acc 0.104624\n",
      "round 347\n",
      "time to device 0.009297 sec\n",
      "time forward 3.738939 sec\n",
      "loss time 0.002281 sec\n",
      "backward time 0.012039 sec\n",
      "optimizer time 0.016806 sec\n",
      "training time in round 347 cost 0.42179012298583984 sec\n",
      "loss 4950.805823, train acc 0.104661\n",
      "round 348\n",
      "time to device 0.008842 sec\n",
      "time forward 3.752850 sec\n",
      "loss time 0.001135 sec\n",
      "backward time 0.012301 sec\n",
      "optimizer time 0.021019 sec\n",
      "training time in round 348 cost 0.38808393478393555 sec\n",
      "loss 4936.626733, train acc 0.104562\n",
      "round 349\n",
      "time to device 0.006894 sec\n",
      "time forward 3.766790 sec\n",
      "loss time 0.001735 sec\n",
      "backward time 0.015837 sec\n",
      "optimizer time 0.026738 sec\n",
      "training time in round 349 cost 0.4054262638092041 sec\n",
      "loss 4922.528724, train acc 0.104576\n",
      "round 350\n",
      "time to device 0.009301 sec\n",
      "time forward 3.788934 sec\n",
      "loss time 0.001199 sec\n",
      "backward time 0.010311 sec\n",
      "optimizer time 0.015585 sec\n",
      "training time in round 350 cost 0.40844082832336426 sec\n",
      "loss 4908.510983, train acc 0.104567\n",
      "round 351\n",
      "time to device 0.006694 sec\n",
      "time forward 3.800936 sec\n",
      "loss time 0.001265 sec\n",
      "backward time 0.011084 sec\n",
      "optimizer time 0.015797 sec\n",
      "training time in round 351 cost 0.38109397888183594 sec\n",
      "loss 4894.572995, train acc 0.104470\n",
      "round 352\n",
      "time to device 0.004226 sec\n",
      "time forward 3.807400 sec\n",
      "loss time 0.000465 sec\n",
      "backward time 0.004082 sec\n",
      "optimizer time 0.011844 sec\n",
      "training time in round 352 cost 0.35719919204711914 sec\n",
      "loss 4880.713961, train acc 0.104417\n",
      "round 353\n",
      "time to device 0.011113 sec\n",
      "time forward 3.817836 sec\n",
      "loss time 0.003125 sec\n",
      "backward time 0.011383 sec\n",
      "optimizer time 0.021869 sec\n",
      "training time in round 353 cost 0.43120408058166504 sec\n",
      "loss 4866.933139, train acc 0.104409\n",
      "round 354\n",
      "time to device 0.007723 sec\n",
      "time forward 3.825736 sec\n",
      "loss time 0.000455 sec\n",
      "backward time 0.004267 sec\n",
      "optimizer time 0.018650 sec\n",
      "training time in round 354 cost 0.4252967834472656 sec\n",
      "loss 4853.229958, train acc 0.104291\n",
      "round 355\n",
      "time to device 0.007716 sec\n",
      "time forward 3.841187 sec\n",
      "loss time 0.001322 sec\n",
      "backward time 0.016675 sec\n",
      "optimizer time 0.019270 sec\n",
      "training time in round 355 cost 0.43172717094421387 sec\n",
      "loss 4839.603753, train acc 0.104350\n",
      "round 356\n",
      "time to device 0.011136 sec\n",
      "time forward 3.858876 sec\n",
      "loss time 0.002074 sec\n",
      "backward time 0.037441 sec\n",
      "optimizer time 0.018020 sec\n",
      "training time in round 356 cost 0.46381306648254395 sec\n",
      "loss 4826.053964, train acc 0.104254\n",
      "round 357\n",
      "time to device 0.012600 sec\n",
      "time forward 3.884678 sec\n",
      "loss time 0.001004 sec\n",
      "backward time 0.015908 sec\n",
      "optimizer time 0.021270 sec\n",
      "training time in round 357 cost 0.4198911190032959 sec\n",
      "loss 4812.580139, train acc 0.104312\n",
      "round 358\n",
      "time to device 0.007433 sec\n",
      "time forward 3.893389 sec\n",
      "loss time 0.001092 sec\n",
      "backward time 0.008288 sec\n",
      "optimizer time 0.019994 sec\n",
      "training time in round 358 cost 0.38483715057373047 sec\n",
      "loss 4799.181026, train acc 0.104435\n",
      "round 359\n",
      "time to device 0.007020 sec\n",
      "time forward 3.908174 sec\n",
      "loss time 0.000982 sec\n",
      "backward time 0.012122 sec\n",
      "optimizer time 0.027883 sec\n",
      "training time in round 359 cost 0.4158191680908203 sec\n",
      "loss 4785.856365, train acc 0.104384\n",
      "round 360\n",
      "time to device 0.008320 sec\n",
      "time forward 3.920937 sec\n",
      "loss time 0.001068 sec\n",
      "backward time 0.011547 sec\n",
      "optimizer time 0.024373 sec\n",
      "training time in round 360 cost 0.4503021240234375 sec\n",
      "loss 4772.605563, train acc 0.104203\n",
      "round 361\n",
      "time to device 0.008150 sec\n",
      "time forward 3.931702 sec\n",
      "loss time 0.001157 sec\n",
      "backward time 0.012200 sec\n",
      "optimizer time 0.025643 sec\n",
      "training time in round 361 cost 0.419497013092041 sec\n",
      "loss 4759.428075, train acc 0.104217\n",
      "round 362\n",
      "time to device 0.008082 sec\n",
      "time forward 3.945512 sec\n",
      "loss time 0.001572 sec\n",
      "backward time 0.010591 sec\n",
      "optimizer time 0.021343 sec\n",
      "training time in round 362 cost 0.41390180587768555 sec\n",
      "loss 4746.323149, train acc 0.104167\n",
      "round 363\n",
      "time to device 0.006609 sec\n",
      "time forward 3.959922 sec\n",
      "loss time 0.001153 sec\n",
      "backward time 0.011905 sec\n",
      "optimizer time 0.028243 sec\n",
      "training time in round 363 cost 0.41235995292663574 sec\n",
      "loss 4733.290100, train acc 0.104117\n",
      "round 364\n",
      "time to device 0.006873 sec\n",
      "time forward 3.971260 sec\n",
      "loss time 0.001063 sec\n",
      "backward time 0.010328 sec\n",
      "optimizer time 0.029616 sec\n",
      "training time in round 364 cost 0.4033210277557373 sec\n",
      "loss 4720.328538, train acc 0.104110\n",
      "round 365\n",
      "time to device 0.007346 sec\n",
      "time forward 3.983468 sec\n",
      "loss time 0.001124 sec\n",
      "backward time 0.011659 sec\n",
      "optimizer time 0.028556 sec\n",
      "training time in round 365 cost 0.3976309299468994 sec\n",
      "loss 4707.438284, train acc 0.103975\n",
      "round 366\n",
      "time to device 0.007247 sec\n",
      "time forward 3.990985 sec\n",
      "loss time 0.001181 sec\n",
      "backward time 0.005206 sec\n",
      "optimizer time 0.016361 sec\n",
      "training time in round 366 cost 0.36804819107055664 sec\n",
      "loss 4694.617742, train acc 0.103947\n",
      "round 367\n",
      "time to device 0.006479 sec\n",
      "time forward 4.002312 sec\n",
      "loss time 0.001340 sec\n",
      "backward time 0.011716 sec\n",
      "optimizer time 0.024619 sec\n",
      "training time in round 367 cost 0.39118099212646484 sec\n",
      "loss 4681.866884, train acc 0.103919\n",
      "round 368\n",
      "time to device 0.007230 sec\n",
      "time forward 4.013727 sec\n",
      "loss time 0.001101 sec\n",
      "backward time 0.011403 sec\n",
      "optimizer time 0.027293 sec\n",
      "training time in round 368 cost 0.3970191478729248 sec\n",
      "loss 4669.185112, train acc 0.103849\n",
      "round 369\n",
      "time to device 0.007582 sec\n",
      "time forward 4.026209 sec\n",
      "loss time 0.001032 sec\n",
      "backward time 0.013561 sec\n",
      "optimizer time 0.026900 sec\n",
      "training time in round 369 cost 0.4161510467529297 sec\n",
      "loss 4656.571951, train acc 0.103737\n",
      "round 370\n",
      "time to device 0.003741 sec\n",
      "time forward 4.039659 sec\n",
      "loss time 0.001693 sec\n",
      "backward time 0.014273 sec\n",
      "optimizer time 0.020271 sec\n",
      "training time in round 370 cost 0.44301295280456543 sec\n",
      "loss 4644.026731, train acc 0.103753\n",
      "round 371\n",
      "time to device 0.003492 sec\n",
      "time forward 4.051824 sec\n",
      "loss time 0.001153 sec\n",
      "backward time 0.012549 sec\n",
      "optimizer time 0.034664 sec\n",
      "training time in round 371 cost 0.4055440425872803 sec\n",
      "loss 4631.548985, train acc 0.103705\n",
      "round 372\n",
      "time to device 0.003408 sec\n",
      "time forward 4.060352 sec\n",
      "loss time 0.000831 sec\n",
      "backward time 0.007023 sec\n",
      "optimizer time 0.021479 sec\n",
      "training time in round 372 cost 0.37568092346191406 sec\n",
      "loss 4619.138530, train acc 0.103699\n",
      "round 373\n",
      "time to device 0.003265 sec\n",
      "time forward 4.072459 sec\n",
      "loss time 0.001176 sec\n",
      "backward time 0.012404 sec\n",
      "optimizer time 0.022940 sec\n",
      "training time in round 373 cost 0.39363884925842285 sec\n",
      "loss 4606.794132, train acc 0.103714\n",
      "round 374\n",
      "time to device 0.004192 sec\n",
      "time forward 4.085014 sec\n",
      "loss time 0.000963 sec\n",
      "backward time 0.010272 sec\n",
      "optimizer time 0.025739 sec\n",
      "training time in round 374 cost 0.41365885734558105 sec\n",
      "loss 4594.515507, train acc 0.103646\n",
      "round 375\n",
      "time to device 0.004599 sec\n",
      "time forward 4.096642 sec\n",
      "loss time 0.000998 sec\n",
      "backward time 0.010493 sec\n",
      "optimizer time 0.023707 sec\n",
      "training time in round 375 cost 0.40786004066467285 sec\n",
      "loss 4582.302652, train acc 0.103578\n",
      "round 376\n",
      "time to device 0.003631 sec\n",
      "time forward 4.112407 sec\n",
      "loss time 0.001350 sec\n",
      "backward time 0.012005 sec\n",
      "optimizer time 0.024575 sec\n",
      "training time in round 376 cost 0.40397000312805176 sec\n",
      "loss 4570.154128, train acc 0.103448\n",
      "round 377\n",
      "time to device 0.006540 sec\n",
      "time forward 4.119506 sec\n",
      "loss time 0.000538 sec\n",
      "backward time 0.004870 sec\n",
      "optimizer time 0.016272 sec\n",
      "training time in round 377 cost 0.3749241828918457 sec\n",
      "loss 4558.069997, train acc 0.103443\n",
      "round 378\n",
      "time to device 0.003307 sec\n",
      "time forward 4.132265 sec\n",
      "loss time 0.001148 sec\n",
      "backward time 0.010240 sec\n",
      "optimizer time 0.027836 sec\n",
      "training time in round 378 cost 0.39178013801574707 sec\n",
      "loss 4546.049634, train acc 0.103418\n",
      "round 379\n",
      "time to device 0.002971 sec\n",
      "time forward 4.142852 sec\n",
      "loss time 0.001044 sec\n",
      "backward time 0.016494 sec\n",
      "optimizer time 0.023934 sec\n",
      "training time in round 379 cost 0.39311909675598145 sec\n",
      "loss 4534.092504, train acc 0.103413\n",
      "round 380\n",
      "time to device 0.003831 sec\n",
      "time forward 4.154479 sec\n",
      "loss time 0.001051 sec\n",
      "backward time 0.011991 sec\n",
      "optimizer time 0.024095 sec\n",
      "training time in round 380 cost 0.3956029415130615 sec\n",
      "loss 4522.198019, train acc 0.103367\n",
      "round 381\n",
      "time to device 0.003455 sec\n",
      "time forward 4.165076 sec\n",
      "loss time 0.001074 sec\n",
      "backward time 0.012680 sec\n",
      "optimizer time 0.027534 sec\n",
      "training time in round 381 cost 0.39267492294311523 sec\n",
      "loss 4510.365837, train acc 0.103424\n",
      "round 382\n",
      "time to device 0.003543 sec\n",
      "time forward 4.178729 sec\n",
      "loss time 0.001123 sec\n",
      "backward time 0.011963 sec\n",
      "optimizer time 0.025988 sec\n",
      "training time in round 382 cost 0.38689684867858887 sec\n",
      "loss 4498.596549, train acc 0.103317\n",
      "round 383\n",
      "time to device 0.003348 sec\n",
      "time forward 4.189620 sec\n",
      "loss time 0.001023 sec\n",
      "backward time 0.012455 sec\n",
      "optimizer time 0.029825 sec\n",
      "training time in round 383 cost 0.3989267349243164 sec\n",
      "loss 4486.887481, train acc 0.103373\n",
      "round 384\n",
      "time to device 0.003425 sec\n",
      "time forward 4.199858 sec\n",
      "loss time 0.000996 sec\n",
      "backward time 0.011040 sec\n",
      "optimizer time 0.026944 sec\n",
      "training time in round 384 cost 0.39012908935546875 sec\n",
      "loss 4475.239588, train acc 0.103328\n",
      "round 385\n",
      "time to device 0.003643 sec\n",
      "time forward 4.212668 sec\n",
      "loss time 0.001483 sec\n",
      "backward time 0.010263 sec\n",
      "optimizer time 0.031659 sec\n",
      "training time in round 385 cost 0.39516329765319824 sec\n",
      "loss 4463.651642, train acc 0.103283\n",
      "round 386\n",
      "time to device 0.004465 sec\n",
      "time forward 4.221724 sec\n",
      "loss time 0.001202 sec\n",
      "backward time 0.007281 sec\n",
      "optimizer time 0.017898 sec\n",
      "training time in round 386 cost 0.37247800827026367 sec\n",
      "loss 4452.123653, train acc 0.103319\n",
      "round 387\n",
      "time to device 0.003203 sec\n",
      "time forward 4.231814 sec\n",
      "loss time 0.000921 sec\n",
      "backward time 0.010219 sec\n",
      "optimizer time 0.016635 sec\n",
      "training time in round 387 cost 0.3755500316619873 sec\n",
      "loss 4440.655042, train acc 0.103375\n",
      "round 388\n",
      "time to device 0.004235 sec\n",
      "time forward 4.252244 sec\n",
      "loss time 0.001059 sec\n",
      "backward time 0.012694 sec\n",
      "optimizer time 0.027994 sec\n",
      "training time in round 388 cost 0.41141510009765625 sec\n",
      "loss 4429.245391, train acc 0.103450\n",
      "round 389\n",
      "time to device 0.003351 sec\n",
      "time forward 4.263279 sec\n",
      "loss time 0.001017 sec\n",
      "backward time 0.012513 sec\n",
      "optimizer time 0.027315 sec\n",
      "training time in round 389 cost 0.38721394538879395 sec\n",
      "loss 4417.894291, train acc 0.103345\n",
      "round 390\n",
      "time to device 0.003728 sec\n",
      "time forward 4.274410 sec\n",
      "loss time 0.001071 sec\n",
      "backward time 0.012677 sec\n",
      "optimizer time 0.027955 sec\n",
      "training time in round 390 cost 0.3965320587158203 sec\n",
      "loss 4406.601236, train acc 0.103421\n",
      "round 391\n",
      "time to device 0.003406 sec\n",
      "time forward 4.286393 sec\n",
      "loss time 0.001818 sec\n",
      "backward time 0.011898 sec\n",
      "optimizer time 0.027517 sec\n",
      "training time in round 391 cost 0.3942289352416992 sec\n",
      "loss 4395.365785, train acc 0.103276\n",
      "round 392\n",
      "time to device 0.003682 sec\n",
      "time forward 4.297209 sec\n",
      "loss time 0.001023 sec\n",
      "backward time 0.012165 sec\n",
      "optimizer time 0.026829 sec\n",
      "training time in round 392 cost 0.3899381160736084 sec\n",
      "loss 4384.187524, train acc 0.103153\n",
      "round 393\n",
      "time to device 0.003240 sec\n",
      "time forward 4.308680 sec\n",
      "loss time 0.000999 sec\n",
      "backward time 0.011043 sec\n",
      "optimizer time 0.028215 sec\n",
      "training time in round 393 cost 0.392869234085083 sec\n",
      "loss 4373.066042, train acc 0.103129\n",
      "round 394\n",
      "time to device 0.003330 sec\n",
      "time forward 4.319592 sec\n",
      "loss time 0.001163 sec\n",
      "backward time 0.010392 sec\n",
      "optimizer time 0.028150 sec\n",
      "training time in round 394 cost 0.38822102546691895 sec\n",
      "loss 4362.000795, train acc 0.103145\n",
      "round 395\n",
      "time to device 0.004133 sec\n",
      "time forward 4.330663 sec\n",
      "loss time 0.001453 sec\n",
      "backward time 0.009997 sec\n",
      "optimizer time 0.025539 sec\n",
      "training time in round 395 cost 0.38820600509643555 sec\n",
      "loss 4350.991602, train acc 0.103161\n",
      "round 396\n",
      "time to device 0.003522 sec\n",
      "time forward 4.341332 sec\n",
      "loss time 0.001016 sec\n",
      "backward time 0.010670 sec\n",
      "optimizer time 0.032182 sec\n",
      "training time in round 396 cost 0.39263105392456055 sec\n",
      "loss 4340.037737, train acc 0.103176\n",
      "round 397\n",
      "time to device 0.003996 sec\n",
      "time forward 4.352200 sec\n",
      "loss time 0.001222 sec\n",
      "backward time 0.009713 sec\n",
      "optimizer time 0.028569 sec\n",
      "training time in round 397 cost 0.3941969871520996 sec\n",
      "loss 4329.138911, train acc 0.103054\n",
      "round 398\n",
      "time to device 0.004010 sec\n",
      "time forward 4.363520 sec\n",
      "loss time 0.001226 sec\n",
      "backward time 0.010589 sec\n",
      "optimizer time 0.029102 sec\n",
      "training time in round 398 cost 0.39634203910827637 sec\n",
      "loss 4318.294799, train acc 0.103090\n",
      "round 399\n",
      "time to device 0.003246 sec\n",
      "time forward 4.371727 sec\n",
      "loss time 0.000788 sec\n",
      "backward time 0.007074 sec\n",
      "optimizer time 0.017159 sec\n",
      "training time in round 399 cost 0.3688051700592041 sec\n",
      "loss 4307.504857, train acc 0.103086\n",
      "round 400\n",
      "time to device 0.002513 sec\n",
      "time forward 4.381860 sec\n",
      "loss time 0.001006 sec\n",
      "backward time 0.012825 sec\n",
      "optimizer time 0.027251 sec\n",
      "training time in round 400 cost 0.3875539302825928 sec\n",
      "loss 4296.768919, train acc 0.103199\n",
      "round 401\n",
      "time to device 0.003398 sec\n",
      "time forward 4.391280 sec\n",
      "loss time 0.000474 sec\n",
      "backward time 0.005129 sec\n",
      "optimizer time 0.021621 sec\n",
      "training time in round 401 cost 0.3871347904205322 sec\n",
      "loss 4286.086163, train acc 0.103078\n",
      "round 402\n",
      "time to device 0.003432 sec\n",
      "time forward 4.402509 sec\n",
      "loss time 0.001225 sec\n",
      "backward time 0.012973 sec\n",
      "optimizer time 0.026857 sec\n",
      "training time in round 402 cost 0.38815999031066895 sec\n",
      "loss 4275.456409, train acc 0.103036\n",
      "round 403\n",
      "time to device 0.003441 sec\n",
      "time forward 4.415177 sec\n",
      "loss time 0.001019 sec\n",
      "backward time 0.010215 sec\n",
      "optimizer time 0.027245 sec\n",
      "training time in round 403 cost 0.3911600112915039 sec\n",
      "loss 4264.879388, train acc 0.102935\n",
      "round 404\n",
      "time to device 0.003742 sec\n",
      "time forward 4.426269 sec\n",
      "loss time 0.001213 sec\n",
      "backward time 0.011809 sec\n",
      "optimizer time 0.029468 sec\n",
      "training time in round 404 cost 0.3915431499481201 sec\n",
      "loss 4254.354526, train acc 0.102932\n",
      "round 405\n",
      "time to device 0.003077 sec\n",
      "time forward 4.436838 sec\n",
      "loss time 0.000999 sec\n",
      "backward time 0.009962 sec\n",
      "optimizer time 0.027442 sec\n",
      "training time in round 405 cost 0.3838331699371338 sec\n",
      "loss 4243.881539, train acc 0.102929\n",
      "round 406\n",
      "time to device 0.003182 sec\n",
      "time forward 4.448309 sec\n",
      "loss time 0.001332 sec\n",
      "backward time 0.010566 sec\n",
      "optimizer time 0.027650 sec\n",
      "training time in round 406 cost 0.3882911205291748 sec\n",
      "loss 4233.460024, train acc 0.102849\n",
      "round 407\n",
      "time to device 0.003654 sec\n",
      "time forward 4.459659 sec\n",
      "loss time 0.001274 sec\n",
      "backward time 0.011471 sec\n",
      "optimizer time 0.027278 sec\n",
      "training time in round 407 cost 0.3873331546783447 sec\n",
      "loss 4223.089744, train acc 0.102941\n",
      "round 408\n",
      "time to device 0.003955 sec\n",
      "time forward 4.468797 sec\n",
      "loss time 0.000840 sec\n",
      "backward time 0.006804 sec\n",
      "optimizer time 0.016912 sec\n",
      "training time in round 408 cost 0.3762969970703125 sec\n",
      "loss 4212.770097, train acc 0.102995\n",
      "round 409\n",
      "time to device 0.003821 sec\n",
      "time forward 4.479956 sec\n",
      "loss time 0.001853 sec\n",
      "backward time 0.012178 sec\n",
      "optimizer time 0.017664 sec\n",
      "training time in round 409 cost 0.4256269931793213 sec\n",
      "loss 4202.500642, train acc 0.103011\n",
      "round 410\n",
      "time to device 0.005108 sec\n",
      "time forward 4.491374 sec\n",
      "loss time 0.000996 sec\n",
      "backward time 0.010980 sec\n",
      "optimizer time 0.025364 sec\n",
      "training time in round 410 cost 0.39699625968933105 sec\n",
      "loss 4192.281291, train acc 0.103026\n",
      "round 411\n",
      "time to device 0.003409 sec\n",
      "time forward 4.501720 sec\n",
      "loss time 0.001003 sec\n",
      "backward time 0.011659 sec\n",
      "optimizer time 0.028092 sec\n",
      "training time in round 411 cost 0.39210009574890137 sec\n",
      "loss 4182.111582, train acc 0.102928\n",
      "round 412\n",
      "time to device 0.003421 sec\n",
      "time forward 4.512917 sec\n",
      "loss time 0.001384 sec\n",
      "backward time 0.016005 sec\n",
      "optimizer time 0.028326 sec\n",
      "training time in round 412 cost 0.3939340114593506 sec\n",
      "loss 4171.991393, train acc 0.102811\n",
      "round 413\n",
      "time to device 0.003904 sec\n",
      "time forward 4.524149 sec\n",
      "loss time 0.001051 sec\n",
      "backward time 0.010735 sec\n",
      "optimizer time 0.028019 sec\n",
      "training time in round 413 cost 0.39424896240234375 sec\n",
      "loss 4161.919703, train acc 0.102732\n",
      "round 414\n",
      "time to device 0.003800 sec\n",
      "time forward 4.536134 sec\n",
      "loss time 0.001078 sec\n",
      "backward time 0.011393 sec\n",
      "optimizer time 0.028273 sec\n",
      "training time in round 414 cost 0.3937051296234131 sec\n",
      "loss 4151.896551, train acc 0.102692\n",
      "round 415\n",
      "time to device 0.004518 sec\n",
      "time forward 4.548270 sec\n",
      "loss time 0.001802 sec\n",
      "backward time 0.012172 sec\n",
      "optimizer time 0.019889 sec\n",
      "training time in round 415 cost 0.40457797050476074 sec\n",
      "loss 4141.921570, train acc 0.102708\n",
      "round 416\n",
      "time to device 0.003492 sec\n",
      "time forward 4.559168 sec\n",
      "loss time 0.001027 sec\n",
      "backward time 0.010264 sec\n",
      "optimizer time 0.026491 sec\n",
      "training time in round 416 cost 0.3861351013183594 sec\n",
      "loss 4131.994433, train acc 0.102724\n",
      "round 417\n",
      "time to device 0.003580 sec\n",
      "time forward 4.569975 sec\n",
      "loss time 0.000992 sec\n",
      "backward time 0.012288 sec\n",
      "optimizer time 0.024911 sec\n",
      "training time in round 417 cost 0.3864262104034424 sec\n",
      "loss 4122.114810, train acc 0.102740\n",
      "round 418\n",
      "time to device 0.003732 sec\n",
      "time forward 4.578503 sec\n",
      "loss time 0.000911 sec\n",
      "backward time 0.008545 sec\n",
      "optimizer time 0.020650 sec\n",
      "training time in round 418 cost 0.4139699935913086 sec\n",
      "loss 4112.282310, train acc 0.102737\n",
      "round 419\n",
      "time to device 0.004225 sec\n",
      "time forward 4.590540 sec\n",
      "loss time 0.001197 sec\n",
      "backward time 0.013157 sec\n",
      "optimizer time 0.029603 sec\n",
      "training time in round 419 cost 0.4229257106781006 sec\n",
      "loss 4102.496647, train acc 0.102641\n",
      "round 420\n",
      "time to device 0.006926 sec\n",
      "time forward 4.603426 sec\n",
      "loss time 0.001413 sec\n",
      "backward time 0.017863 sec\n",
      "optimizer time 0.025027 sec\n",
      "training time in round 420 cost 0.40631604194641113 sec\n",
      "loss 4092.757576, train acc 0.102583\n",
      "round 421\n",
      "time to device 0.006755 sec\n",
      "time forward 4.614741 sec\n",
      "loss time 0.001145 sec\n",
      "backward time 0.012369 sec\n",
      "optimizer time 0.026705 sec\n",
      "training time in round 421 cost 0.40752100944519043 sec\n",
      "loss 4083.064561, train acc 0.102451\n",
      "round 422\n",
      "time to device 0.006674 sec\n",
      "time forward 4.622880 sec\n",
      "loss time 0.000854 sec\n",
      "backward time 0.010527 sec\n",
      "optimizer time 0.019660 sec\n",
      "training time in round 422 cost 0.37240076065063477 sec\n",
      "loss 4073.417415, train acc 0.102467\n",
      "round 423\n",
      "time to device 0.004938 sec\n",
      "time forward 4.634892 sec\n",
      "loss time 0.001039 sec\n",
      "backward time 0.009440 sec\n",
      "optimizer time 0.028212 sec\n",
      "training time in round 423 cost 0.40610671043395996 sec\n",
      "loss 4063.815808, train acc 0.102410\n",
      "round 424\n",
      "time to device 0.006170 sec\n",
      "time forward 4.647450 sec\n",
      "loss time 0.001555 sec\n",
      "backward time 0.013195 sec\n",
      "optimizer time 0.028242 sec\n",
      "training time in round 424 cost 0.4055368900299072 sec\n",
      "loss 4054.259344, train acc 0.102426\n",
      "round 425\n",
      "time to device 0.006476 sec\n",
      "time forward 4.660263 sec\n",
      "loss time 0.001209 sec\n",
      "backward time 0.010634 sec\n",
      "optimizer time 0.028380 sec\n",
      "training time in round 425 cost 0.4107701778411865 sec\n",
      "loss 4044.747832, train acc 0.102534\n",
      "round 426\n",
      "time to device 0.006503 sec\n",
      "time forward 4.671183 sec\n",
      "loss time 0.000999 sec\n",
      "backward time 0.011713 sec\n",
      "optimizer time 0.027676 sec\n",
      "training time in round 426 cost 0.4081130027770996 sec\n",
      "loss 4035.280803, train acc 0.102441\n",
      "round 427\n",
      "time to device 0.003114 sec\n",
      "time forward 4.679560 sec\n",
      "loss time 0.000733 sec\n",
      "backward time 0.008788 sec\n",
      "optimizer time 0.016775 sec\n",
      "training time in round 427 cost 0.3769683837890625 sec\n",
      "loss 4025.857954, train acc 0.102457\n",
      "round 428\n",
      "time to device 0.003621 sec\n",
      "time forward 4.691520 sec\n",
      "loss time 0.001234 sec\n",
      "backward time 0.011168 sec\n",
      "optimizer time 0.027322 sec\n",
      "training time in round 428 cost 0.4097142219543457 sec\n",
      "loss 4016.479045, train acc 0.102455\n",
      "round 429\n",
      "time to device 0.003938 sec\n",
      "time forward 4.704971 sec\n",
      "loss time 0.001093 sec\n",
      "backward time 0.012798 sec\n",
      "optimizer time 0.028834 sec\n",
      "training time in round 429 cost 0.45690321922302246 sec\n",
      "loss 4007.143815, train acc 0.102398\n",
      "round 430\n",
      "time to device 0.006870 sec\n",
      "time forward 4.716037 sec\n",
      "loss time 0.001201 sec\n",
      "backward time 0.011259 sec\n",
      "optimizer time 0.033171 sec\n",
      "training time in round 430 cost 0.3934900760650635 sec\n",
      "loss 3997.851841, train acc 0.102360\n",
      "round 431\n",
      "time to device 0.006978 sec\n",
      "time forward 4.731229 sec\n",
      "loss time 0.001014 sec\n",
      "backward time 0.012145 sec\n",
      "optimizer time 0.030636 sec\n",
      "training time in round 431 cost 0.4127929210662842 sec\n",
      "loss 3988.602923, train acc 0.102394\n",
      "round 432\n",
      "time to device 0.005837 sec\n",
      "time forward 4.743440 sec\n",
      "loss time 0.001117 sec\n",
      "backward time 0.012289 sec\n",
      "optimizer time 0.027430 sec\n",
      "training time in round 432 cost 0.39280200004577637 sec\n",
      "loss 3979.396679, train acc 0.102429\n",
      "round 433\n",
      "time to device 0.003894 sec\n",
      "time forward 4.754843 sec\n",
      "loss time 0.000959 sec\n",
      "backward time 0.012617 sec\n",
      "optimizer time 0.027169 sec\n",
      "training time in round 433 cost 0.3875441551208496 sec\n",
      "loss 3970.232876, train acc 0.102517\n",
      "round 434\n",
      "time to device 0.003136 sec\n",
      "time forward 4.767207 sec\n",
      "loss time 0.001359 sec\n",
      "backward time 0.010472 sec\n",
      "optimizer time 0.027052 sec\n",
      "training time in round 434 cost 0.3981320858001709 sec\n",
      "loss 3961.111207, train acc 0.102425\n",
      "round 435\n",
      "time to device 0.003566 sec\n",
      "time forward 4.775234 sec\n",
      "loss time 0.000756 sec\n",
      "backward time 0.006721 sec\n",
      "optimizer time 0.016830 sec\n",
      "training time in round 435 cost 0.3715989589691162 sec\n",
      "loss 3952.031373, train acc 0.102351\n",
      "round 436\n",
      "time to device 0.003498 sec\n",
      "time forward 4.786503 sec\n",
      "loss time 0.001250 sec\n",
      "backward time 0.011607 sec\n",
      "optimizer time 0.026995 sec\n",
      "training time in round 436 cost 0.39101195335388184 sec\n",
      "loss 3942.993087, train acc 0.102349\n",
      "round 437\n",
      "time to device 0.003312 sec\n",
      "time forward 4.798569 sec\n",
      "loss time 0.001055 sec\n",
      "backward time 0.011642 sec\n",
      "optimizer time 0.026556 sec\n",
      "training time in round 437 cost 0.3941178321838379 sec\n",
      "loss 3933.996136, train acc 0.102276\n",
      "round 438\n",
      "time to device 0.003568 sec\n",
      "time forward 4.809528 sec\n",
      "loss time 0.001082 sec\n",
      "backward time 0.010877 sec\n",
      "optimizer time 0.027060 sec\n",
      "training time in round 438 cost 0.3885481357574463 sec\n",
      "loss 3925.040264, train acc 0.102310\n",
      "round 439\n",
      "time to device 0.003360 sec\n",
      "time forward 4.820985 sec\n",
      "loss time 0.001300 sec\n",
      "backward time 0.010342 sec\n",
      "optimizer time 0.027092 sec\n",
      "training time in round 439 cost 0.39211106300354004 sec\n",
      "loss 3916.125535, train acc 0.102148\n",
      "round 440\n",
      "time to device 0.003690 sec\n",
      "time forward 4.830209 sec\n",
      "loss time 0.000926 sec\n",
      "backward time 0.010124 sec\n",
      "optimizer time 0.020712 sec\n",
      "training time in round 440 cost 0.3883788585662842 sec\n",
      "loss 3907.250706, train acc 0.102147\n",
      "round 441\n",
      "time to device 0.003074 sec\n",
      "time forward 4.841600 sec\n",
      "loss time 0.001578 sec\n",
      "backward time 0.009358 sec\n",
      "optimizer time 0.028313 sec\n",
      "training time in round 441 cost 0.3878300189971924 sec\n",
      "loss 3898.416023, train acc 0.102110\n",
      "round 442\n",
      "time to device 0.004337 sec\n",
      "time forward 4.851781 sec\n",
      "loss time 0.001150 sec\n",
      "backward time 0.012513 sec\n",
      "optimizer time 0.026464 sec\n",
      "training time in round 442 cost 0.38869714736938477 sec\n",
      "loss 3889.621346, train acc 0.102127\n",
      "round 443\n",
      "time to device 0.003194 sec\n",
      "time forward 4.863471 sec\n",
      "loss time 0.001024 sec\n",
      "backward time 0.009283 sec\n",
      "optimizer time 0.027777 sec\n",
      "training time in round 443 cost 0.38714599609375 sec\n",
      "loss 3880.866394, train acc 0.102038\n",
      "round 444\n",
      "time to device 0.003208 sec\n",
      "time forward 4.874467 sec\n",
      "loss time 0.001196 sec\n",
      "backward time 0.010123 sec\n",
      "optimizer time 0.029630 sec\n",
      "training time in round 444 cost 0.38965296745300293 sec\n",
      "loss 3872.150539, train acc 0.102037\n",
      "round 445\n",
      "time to device 0.003911 sec\n",
      "time forward 4.883820 sec\n",
      "loss time 0.001080 sec\n",
      "backward time 0.005740 sec\n",
      "optimizer time 0.016649 sec\n",
      "training time in round 445 cost 0.37378787994384766 sec\n",
      "loss 3863.473846, train acc 0.102088\n",
      "round 446\n",
      "time to device 0.004141 sec\n",
      "time forward 4.894711 sec\n",
      "loss time 0.001254 sec\n",
      "backward time 0.010699 sec\n",
      "optimizer time 0.028371 sec\n",
      "training time in round 446 cost 0.38922595977783203 sec\n",
      "loss 3854.835777, train acc 0.102192\n",
      "round 447\n",
      "time to device 0.003350 sec\n",
      "time forward 4.905032 sec\n",
      "loss time 0.001078 sec\n",
      "backward time 0.012386 sec\n",
      "optimizer time 0.026528 sec\n",
      "training time in round 447 cost 0.3879668712615967 sec\n",
      "loss 3846.236771, train acc 0.102243\n",
      "round 448\n",
      "time to device 0.003237 sec\n",
      "time forward 4.916129 sec\n",
      "loss time 0.001187 sec\n",
      "backward time 0.010065 sec\n",
      "optimizer time 0.027669 sec\n",
      "training time in round 448 cost 0.38836073875427246 sec\n",
      "loss 3837.675773, train acc 0.102137\n",
      "round 449\n",
      "time to device 0.004152 sec\n",
      "time forward 4.926741 sec\n",
      "loss time 0.001112 sec\n",
      "backward time 0.011496 sec\n",
      "optimizer time 0.022203 sec\n",
      "training time in round 449 cost 0.38501501083374023 sec\n",
      "loss 3829.152734, train acc 0.102083\n",
      "round 450\n",
      "time to device 0.003587 sec\n",
      "time forward 4.937974 sec\n",
      "loss time 0.001521 sec\n",
      "backward time 0.008969 sec\n",
      "optimizer time 0.024622 sec\n",
      "training time in round 450 cost 0.3882102966308594 sec\n",
      "loss 3820.667527, train acc 0.102100\n",
      "round 451\n",
      "time to device 0.003909 sec\n",
      "time forward 4.950159 sec\n",
      "loss time 0.001762 sec\n",
      "backward time 0.013332 sec\n",
      "optimizer time 0.026318 sec\n",
      "training time in round 451 cost 0.4043271541595459 sec\n",
      "loss 3812.219820, train acc 0.102116\n",
      "round 452\n",
      "time to device 0.003783 sec\n",
      "time forward 4.962741 sec\n",
      "loss time 0.001003 sec\n",
      "backward time 0.009434 sec\n",
      "optimizer time 0.029700 sec\n",
      "training time in round 452 cost 0.44913697242736816 sec\n",
      "loss 3803.809605, train acc 0.102132\n",
      "round 453\n",
      "time to device 0.003501 sec\n",
      "time forward 4.971490 sec\n",
      "loss time 0.001031 sec\n",
      "backward time 0.008326 sec\n",
      "optimizer time 0.019018 sec\n",
      "training time in round 453 cost 0.37457990646362305 sec\n",
      "loss 3795.436215, train acc 0.102268\n",
      "round 454\n",
      "time to device 0.006860 sec\n",
      "time forward 4.986472 sec\n",
      "loss time 0.001148 sec\n",
      "backward time 0.012867 sec\n",
      "optimizer time 0.021783 sec\n",
      "training time in round 454 cost 0.40355992317199707 sec\n",
      "loss 3787.099724, train acc 0.102301\n",
      "round 455\n",
      "time to device 0.006573 sec\n",
      "time forward 4.996197 sec\n",
      "loss time 0.001017 sec\n",
      "backward time 0.010451 sec\n",
      "optimizer time 0.020803 sec\n",
      "training time in round 455 cost 0.38163208961486816 sec\n",
      "loss 3778.799739, train acc 0.102299\n",
      "round 456\n",
      "time to device 0.006376 sec\n",
      "time forward 5.007259 sec\n",
      "loss time 0.000904 sec\n",
      "backward time 0.009435 sec\n",
      "optimizer time 0.018734 sec\n",
      "training time in round 456 cost 0.3765697479248047 sec\n",
      "loss 3770.536120, train acc 0.102280\n",
      "round 457\n",
      "time to device 0.005992 sec\n",
      "time forward 5.019036 sec\n",
      "loss time 0.001263 sec\n",
      "backward time 0.012066 sec\n",
      "optimizer time 0.027436 sec\n",
      "training time in round 457 cost 0.40999889373779297 sec\n",
      "loss 3762.308583, train acc 0.102194\n",
      "round 458\n",
      "time to device 0.002392 sec\n",
      "time forward 5.030347 sec\n",
      "loss time 0.001345 sec\n",
      "backward time 0.011726 sec\n",
      "optimizer time 0.027612 sec\n",
      "training time in round 458 cost 0.38848090171813965 sec\n",
      "loss 3754.116855, train acc 0.102158\n",
      "round 459\n",
      "time to device 0.002949 sec\n",
      "time forward 5.041413 sec\n",
      "loss time 0.001586 sec\n",
      "backward time 0.010934 sec\n",
      "optimizer time 0.038581 sec\n",
      "training time in round 459 cost 0.3967468738555908 sec\n",
      "loss 3745.961141, train acc 0.102089\n",
      "round 460\n",
      "time to device 0.003331 sec\n",
      "time forward 5.053759 sec\n",
      "loss time 0.001234 sec\n",
      "backward time 0.010173 sec\n",
      "optimizer time 0.027738 sec\n",
      "training time in round 460 cost 0.38507819175720215 sec\n",
      "loss 3737.840405, train acc 0.102071\n",
      "round 461\n",
      "time to device 0.002796 sec\n",
      "time forward 5.065842 sec\n",
      "loss time 0.001118 sec\n",
      "backward time 0.009358 sec\n",
      "optimizer time 0.021563 sec\n",
      "training time in round 461 cost 0.3903770446777344 sec\n",
      "loss 3729.754832, train acc 0.102087\n",
      "round 462\n",
      "time to device 0.003460 sec\n",
      "time forward 5.076795 sec\n",
      "loss time 0.001756 sec\n",
      "backward time 0.012186 sec\n",
      "optimizer time 0.024030 sec\n",
      "training time in round 462 cost 0.3824121952056885 sec\n",
      "loss 3721.704237, train acc 0.102119\n",
      "round 463\n",
      "time to device 0.003154 sec\n",
      "time forward 5.088730 sec\n",
      "loss time 0.001129 sec\n",
      "backward time 0.011101 sec\n",
      "optimizer time 0.028399 sec\n",
      "training time in round 463 cost 0.3860650062561035 sec\n",
      "loss 3713.688392, train acc 0.102169\n",
      "round 464\n",
      "time to device 0.003271 sec\n",
      "time forward 5.099984 sec\n",
      "loss time 0.000984 sec\n",
      "backward time 0.011789 sec\n",
      "optimizer time 0.029003 sec\n",
      "training time in round 464 cost 0.39079809188842773 sec\n",
      "loss 3705.706919, train acc 0.102100\n",
      "round 465\n",
      "time to device 0.003299 sec\n",
      "time forward 5.111222 sec\n",
      "loss time 0.001588 sec\n",
      "backward time 0.009472 sec\n",
      "optimizer time 0.028355 sec\n",
      "training time in round 465 cost 0.38686704635620117 sec\n",
      "loss 3697.759741, train acc 0.102099\n",
      "round 466\n",
      "time to device 0.003908 sec\n",
      "time forward 5.122236 sec\n",
      "loss time 0.001002 sec\n",
      "backward time 0.011812 sec\n",
      "optimizer time 0.030702 sec\n",
      "training time in round 466 cost 0.390491247177124 sec\n",
      "loss 3689.846561, train acc 0.102064\n",
      "round 467\n",
      "time to device 0.003152 sec\n",
      "time forward 5.134257 sec\n",
      "loss time 0.001271 sec\n",
      "backward time 0.011107 sec\n",
      "optimizer time 0.026863 sec\n",
      "training time in round 467 cost 0.38731813430786133 sec\n",
      "loss 3681.967167, train acc 0.102047\n",
      "round 468\n",
      "time to device 0.002651 sec\n",
      "time forward 5.151852 sec\n",
      "loss time 0.001588 sec\n",
      "backward time 0.019014 sec\n",
      "optimizer time 0.021563 sec\n",
      "training time in round 468 cost 0.3443632125854492 sec\n",
      "loss 3676.079673, train acc 0.102067\n",
      "test acc is 0.100000\n",
      "epoch 0, time 439.207272 sec\n",
      "epoch 2\n",
      "round 0\n",
      "time to device 0.044657 sec\n",
      "time forward 0.009538 sec\n",
      "loss time 0.001373 sec\n",
      "backward time 0.010590 sec\n",
      "optimizer time 0.037946 sec\n",
      "training time in round 0 cost 0.5263071060180664 sec\n",
      "loss 2.321484, train acc 0.101562\n",
      "round 1\n",
      "time to device 0.008667 sec\n",
      "time forward 0.017790 sec\n",
      "loss time 0.000678 sec\n",
      "backward time 0.004781 sec\n",
      "optimizer time 0.012924 sec\n",
      "training time in round 1 cost 0.38216090202331543 sec\n",
      "loss 2.335198, train acc 0.105469\n",
      "round 2\n",
      "time to device 0.006965 sec\n",
      "time forward 0.029485 sec\n",
      "loss time 0.001142 sec\n",
      "backward time 0.012476 sec\n",
      "optimizer time 0.033746 sec\n",
      "training time in round 2 cost 0.4068930149078369 sec\n",
      "loss 2.323459, train acc 0.117188\n",
      "round 3\n",
      "time to device 0.007384 sec\n",
      "time forward 0.044086 sec\n",
      "loss time 0.001960 sec\n",
      "backward time 0.012870 sec\n",
      "optimizer time 0.024321 sec\n",
      "training time in round 3 cost 0.4067709445953369 sec\n",
      "loss 2.327942, train acc 0.111328\n",
      "round 4\n",
      "time to device 0.007198 sec\n",
      "time forward 0.050098 sec\n",
      "loss time 0.000566 sec\n",
      "backward time 0.005192 sec\n",
      "optimizer time 0.014316 sec\n",
      "training time in round 4 cost 0.3606300354003906 sec\n",
      "loss 2.324903, train acc 0.109375\n",
      "round 5\n",
      "time to device 0.009466 sec\n",
      "time forward 0.060825 sec\n",
      "loss time 0.001362 sec\n",
      "backward time 0.012078 sec\n",
      "optimizer time 0.017777 sec\n",
      "training time in round 5 cost 0.39910387992858887 sec\n",
      "loss 2.319137, train acc 0.105469\n",
      "round 6\n",
      "time to device 0.007451 sec\n",
      "time forward 0.070751 sec\n",
      "loss time 0.001021 sec\n",
      "backward time 0.010342 sec\n",
      "optimizer time 0.026106 sec\n",
      "training time in round 6 cost 0.436413049697876 sec\n",
      "loss 2.316863, train acc 0.107143\n",
      "round 7\n",
      "time to device 0.006804 sec\n",
      "time forward 0.081643 sec\n",
      "loss time 0.000923 sec\n",
      "backward time 0.010570 sec\n",
      "optimizer time 0.032520 sec\n",
      "training time in round 7 cost 0.39717888832092285 sec\n",
      "loss 2.315547, train acc 0.102539\n",
      "round 8\n",
      "time to device 0.006961 sec\n",
      "time forward 0.094566 sec\n",
      "loss time 0.001360 sec\n",
      "backward time 0.012329 sec\n",
      "optimizer time 0.029740 sec\n",
      "training time in round 8 cost 0.4088261127471924 sec\n",
      "loss 2.313744, train acc 0.103299\n",
      "round 9\n",
      "time to device 0.006535 sec\n",
      "time forward 0.107108 sec\n",
      "loss time 0.001335 sec\n",
      "backward time 0.012623 sec\n",
      "optimizer time 0.026831 sec\n",
      "training time in round 9 cost 0.41630005836486816 sec\n",
      "loss 2.319885, train acc 0.107031\n",
      "round 10\n",
      "time to device 0.006538 sec\n",
      "time forward 0.117848 sec\n",
      "loss time 0.001356 sec\n",
      "backward time 0.016967 sec\n",
      "optimizer time 0.024898 sec\n",
      "training time in round 10 cost 0.39636898040771484 sec\n",
      "loss 2.319388, train acc 0.107955\n",
      "round 11\n",
      "time to device 0.006591 sec\n",
      "time forward 0.129888 sec\n",
      "loss time 0.001077 sec\n",
      "backward time 0.009608 sec\n",
      "optimizer time 0.033861 sec\n",
      "training time in round 11 cost 0.4021310806274414 sec\n",
      "loss 2.317745, train acc 0.108073\n",
      "round 12\n",
      "time to device 0.006345 sec\n",
      "time forward 0.141056 sec\n",
      "loss time 0.001334 sec\n",
      "backward time 0.011193 sec\n",
      "optimizer time 0.029088 sec\n",
      "training time in round 12 cost 0.39557719230651855 sec\n",
      "loss 2.317094, train acc 0.106971\n",
      "round 13\n",
      "time to device 0.007851 sec\n",
      "time forward 0.153788 sec\n",
      "loss time 0.001031 sec\n",
      "backward time 0.007110 sec\n",
      "optimizer time 0.018151 sec\n",
      "training time in round 13 cost 0.3847622871398926 sec\n",
      "loss 2.323743, train acc 0.107701\n",
      "round 14\n",
      "time to device 0.006405 sec\n",
      "time forward 0.166113 sec\n",
      "loss time 0.001001 sec\n",
      "backward time 0.011756 sec\n",
      "optimizer time 0.025680 sec\n",
      "training time in round 14 cost 0.39793920516967773 sec\n",
      "loss 2.323202, train acc 0.109375\n",
      "round 15\n",
      "time to device 0.007619 sec\n",
      "time forward 0.178290 sec\n",
      "loss time 0.000925 sec\n",
      "backward time 0.013307 sec\n",
      "optimizer time 0.021375 sec\n",
      "training time in round 15 cost 0.4141120910644531 sec\n",
      "loss 2.322075, train acc 0.109863\n",
      "round 16\n",
      "time to device 0.006714 sec\n",
      "time forward 0.190078 sec\n",
      "loss time 0.001047 sec\n",
      "backward time 0.010878 sec\n",
      "optimizer time 0.027082 sec\n",
      "training time in round 16 cost 0.4207768440246582 sec\n",
      "loss 2.320737, train acc 0.112592\n",
      "round 17\n",
      "time to device 0.006153 sec\n",
      "time forward 0.201289 sec\n",
      "loss time 0.001414 sec\n",
      "backward time 0.010626 sec\n",
      "optimizer time 0.031349 sec\n",
      "training time in round 17 cost 0.3995339870452881 sec\n",
      "loss 2.320323, train acc 0.112413\n",
      "round 18\n",
      "time to device 0.006402 sec\n",
      "time forward 0.213160 sec\n",
      "loss time 0.001266 sec\n",
      "backward time 0.010669 sec\n",
      "optimizer time 0.029667 sec\n",
      "training time in round 18 cost 0.40517091751098633 sec\n",
      "loss 2.321058, train acc 0.112664\n",
      "round 19\n",
      "time to device 0.006621 sec\n",
      "time forward 0.228575 sec\n",
      "loss time 0.001448 sec\n",
      "backward time 0.010411 sec\n",
      "optimizer time 0.027399 sec\n",
      "training time in round 19 cost 0.41103315353393555 sec\n",
      "loss 2.327632, train acc 0.112500\n",
      "round 20\n",
      "time to device 0.006975 sec\n",
      "time forward 0.240032 sec\n",
      "loss time 0.001154 sec\n",
      "backward time 0.009654 sec\n",
      "optimizer time 0.029211 sec\n",
      "training time in round 20 cost 0.39478278160095215 sec\n",
      "loss 2.326803, train acc 0.110119\n",
      "round 21\n",
      "time to device 0.006938 sec\n",
      "time forward 0.250097 sec\n",
      "loss time 0.001480 sec\n",
      "backward time 0.011948 sec\n",
      "optimizer time 0.025696 sec\n",
      "training time in round 21 cost 0.4176828861236572 sec\n",
      "loss 2.326078, train acc 0.108665\n",
      "round 22\n",
      "time to device 0.007467 sec\n",
      "time forward 0.262787 sec\n",
      "loss time 0.001062 sec\n",
      "backward time 0.012016 sec\n",
      "optimizer time 0.023315 sec\n",
      "training time in round 22 cost 0.3931598663330078 sec\n",
      "loss 2.325287, train acc 0.109375\n",
      "round 23\n",
      "time to device 0.006582 sec\n",
      "time forward 0.275493 sec\n",
      "loss time 0.000994 sec\n",
      "backward time 0.010896 sec\n",
      "optimizer time 0.033054 sec\n",
      "training time in round 23 cost 0.40856409072875977 sec\n",
      "loss 2.324396, train acc 0.108724\n",
      "round 24\n",
      "time to device 0.005992 sec\n",
      "time forward 0.290452 sec\n",
      "loss time 0.001090 sec\n",
      "backward time 0.013872 sec\n",
      "optimizer time 0.026132 sec\n",
      "training time in round 24 cost 0.43050289154052734 sec\n",
      "loss 2.323582, train acc 0.108750\n",
      "round 25\n",
      "time to device 0.007336 sec\n",
      "time forward 0.302240 sec\n",
      "loss time 0.001084 sec\n",
      "backward time 0.011290 sec\n",
      "optimizer time 0.027930 sec\n",
      "training time in round 25 cost 0.40878725051879883 sec\n",
      "loss 2.322342, train acc 0.108173\n",
      "round 26\n",
      "time to device 0.006229 sec\n",
      "time forward 0.313535 sec\n",
      "loss time 0.001047 sec\n",
      "backward time 0.010172 sec\n",
      "optimizer time 0.027514 sec\n",
      "training time in round 26 cost 0.41437792778015137 sec\n",
      "loss 2.321486, train acc 0.109086\n",
      "round 27\n",
      "time to device 0.003543 sec\n",
      "time forward 0.325574 sec\n",
      "loss time 0.001147 sec\n",
      "backward time 0.009912 sec\n",
      "optimizer time 0.019266 sec\n",
      "training time in round 27 cost 0.4319589138031006 sec\n",
      "loss 2.320454, train acc 0.109933\n",
      "round 28\n",
      "time to device 0.009413 sec\n",
      "time forward 0.338747 sec\n",
      "loss time 0.002251 sec\n",
      "backward time 0.014336 sec\n",
      "optimizer time 0.023516 sec\n",
      "training time in round 28 cost 0.43252992630004883 sec\n",
      "loss 2.319364, train acc 0.109644\n",
      "round 29\n",
      "time to device 0.011739 sec\n",
      "time forward 0.349647 sec\n",
      "loss time 0.000696 sec\n",
      "backward time 0.005643 sec\n",
      "optimizer time 0.018939 sec\n",
      "training time in round 29 cost 0.4544241428375244 sec\n",
      "loss 2.318748, train acc 0.109115\n",
      "round 30\n",
      "time to device 0.005083 sec\n",
      "time forward 0.354917 sec\n",
      "loss time 0.000468 sec\n",
      "backward time 0.003839 sec\n",
      "optimizer time 0.012276 sec\n",
      "training time in round 30 cost 0.37782716751098633 sec\n",
      "loss 2.318602, train acc 0.110887\n",
      "round 31\n",
      "time to device 0.005410 sec\n",
      "time forward 0.361301 sec\n",
      "loss time 0.000431 sec\n",
      "backward time 0.003615 sec\n",
      "optimizer time 0.012432 sec\n",
      "training time in round 31 cost 0.38137292861938477 sec\n",
      "loss 2.318018, train acc 0.112061\n",
      "round 32\n",
      "time to device 0.005343 sec\n",
      "time forward 0.367026 sec\n",
      "loss time 0.000566 sec\n",
      "backward time 0.004229 sec\n",
      "optimizer time 0.014482 sec\n",
      "training time in round 32 cost 0.40384697914123535 sec\n",
      "loss 2.317448, train acc 0.112216\n",
      "round 33\n",
      "time to device 0.007867 sec\n",
      "time forward 0.379031 sec\n",
      "loss time 0.000649 sec\n",
      "backward time 0.004043 sec\n",
      "optimizer time 0.012036 sec\n",
      "training time in round 33 cost 0.3716399669647217 sec\n",
      "loss 2.317817, train acc 0.111443\n",
      "round 34\n",
      "time to device 0.006978 sec\n",
      "time forward 0.389314 sec\n",
      "loss time 0.001125 sec\n",
      "backward time 0.009313 sec\n",
      "optimizer time 0.020274 sec\n",
      "training time in round 34 cost 0.37109923362731934 sec\n",
      "loss 2.317883, train acc 0.111384\n",
      "round 35\n",
      "time to device 0.007194 sec\n",
      "time forward 0.396133 sec\n",
      "loss time 0.000927 sec\n",
      "backward time 0.007460 sec\n",
      "optimizer time 0.018528 sec\n",
      "training time in round 35 cost 0.35846710205078125 sec\n",
      "loss 2.320720, train acc 0.110460\n",
      "round 36\n",
      "time to device 0.006705 sec\n",
      "time forward 0.409167 sec\n",
      "loss time 0.001066 sec\n",
      "backward time 0.012298 sec\n",
      "optimizer time 0.021918 sec\n",
      "training time in round 36 cost 0.39946579933166504 sec\n",
      "loss 2.321376, train acc 0.110008\n",
      "round 37\n",
      "time to device 0.006806 sec\n",
      "time forward 0.419781 sec\n",
      "loss time 0.000919 sec\n",
      "backward time 0.008154 sec\n",
      "optimizer time 0.019272 sec\n",
      "training time in round 37 cost 0.37885093688964844 sec\n",
      "loss 2.321345, train acc 0.109375\n",
      "round 38\n",
      "time to device 0.005816 sec\n",
      "time forward 0.425201 sec\n",
      "loss time 0.000446 sec\n",
      "backward time 0.004016 sec\n",
      "optimizer time 0.012056 sec\n",
      "training time in round 38 cost 0.3802521228790283 sec\n",
      "loss 2.321156, train acc 0.107572\n",
      "round 39\n",
      "time to device 0.005553 sec\n",
      "time forward 0.433433 sec\n",
      "loss time 0.000531 sec\n",
      "backward time 0.004764 sec\n",
      "optimizer time 0.014959 sec\n",
      "training time in round 39 cost 0.35640811920166016 sec\n",
      "loss 2.321182, train acc 0.106836\n",
      "round 40\n",
      "time to device 0.006596 sec\n",
      "time forward 0.444550 sec\n",
      "loss time 0.001112 sec\n",
      "backward time 0.008891 sec\n",
      "optimizer time 0.020107 sec\n",
      "training time in round 40 cost 0.37665510177612305 sec\n",
      "loss 2.321071, train acc 0.107851\n",
      "round 41\n",
      "time to device 0.004751 sec\n",
      "time forward 0.449342 sec\n",
      "loss time 0.000526 sec\n",
      "backward time 0.004518 sec\n",
      "optimizer time 0.013152 sec\n",
      "training time in round 41 cost 0.3599119186401367 sec\n",
      "loss 2.321347, train acc 0.107887\n",
      "round 42\n",
      "time to device 0.005604 sec\n",
      "time forward 0.455136 sec\n",
      "loss time 0.000556 sec\n",
      "backward time 0.006244 sec\n",
      "optimizer time 0.014793 sec\n",
      "training time in round 42 cost 0.3423030376434326 sec\n",
      "loss 2.321610, train acc 0.107013\n",
      "round 43\n",
      "time to device 0.007883 sec\n",
      "time forward 0.463163 sec\n",
      "loss time 0.001104 sec\n",
      "backward time 0.008638 sec\n",
      "optimizer time 0.021145 sec\n",
      "training time in round 43 cost 0.35948610305786133 sec\n",
      "loss 2.321041, train acc 0.106357\n",
      "round 44\n",
      "time to device 0.006394 sec\n",
      "time forward 0.471870 sec\n",
      "loss time 0.000505 sec\n",
      "backward time 0.004678 sec\n",
      "optimizer time 0.013277 sec\n",
      "training time in round 44 cost 0.3676910400390625 sec\n",
      "loss 2.320558, train acc 0.107292\n",
      "round 45\n",
      "time to device 0.006473 sec\n",
      "time forward 0.479766 sec\n",
      "loss time 0.000935 sec\n",
      "backward time 0.007086 sec\n",
      "optimizer time 0.018619 sec\n",
      "training time in round 45 cost 0.35518622398376465 sec\n",
      "loss 2.320088, train acc 0.107167\n",
      "round 46\n",
      "time to device 0.007067 sec\n",
      "time forward 0.496588 sec\n",
      "loss time 0.001135 sec\n",
      "backward time 0.010946 sec\n",
      "optimizer time 0.020115 sec\n",
      "training time in round 46 cost 0.3790550231933594 sec\n",
      "loss 2.319935, train acc 0.107214\n",
      "round 47\n",
      "time to device 0.005217 sec\n",
      "time forward 0.502081 sec\n",
      "loss time 0.000569 sec\n",
      "backward time 0.005019 sec\n",
      "optimizer time 0.014744 sec\n",
      "training time in round 47 cost 0.3860342502593994 sec\n",
      "loss 2.319569, train acc 0.106608\n",
      "round 48\n",
      "time to device 0.004415 sec\n",
      "time forward 0.507632 sec\n",
      "loss time 0.000450 sec\n",
      "backward time 0.004070 sec\n",
      "optimizer time 0.014252 sec\n",
      "training time in round 48 cost 0.3802509307861328 sec\n",
      "loss 2.319943, train acc 0.106186\n",
      "round 49\n",
      "time to device 0.006354 sec\n",
      "time forward 0.512868 sec\n",
      "loss time 0.000566 sec\n",
      "backward time 0.004902 sec\n",
      "optimizer time 0.014569 sec\n",
      "training time in round 49 cost 0.35973191261291504 sec\n",
      "loss 2.320810, train acc 0.106563\n",
      "round 50\n",
      "time to device 0.006629 sec\n",
      "time forward 0.521450 sec\n",
      "loss time 0.001103 sec\n",
      "backward time 0.008650 sec\n",
      "optimizer time 0.020154 sec\n",
      "training time in round 50 cost 0.3661460876464844 sec\n",
      "loss 2.320462, train acc 0.106924\n",
      "round 51\n",
      "time to device 0.005489 sec\n",
      "time forward 0.529508 sec\n",
      "loss time 0.001116 sec\n",
      "backward time 0.008901 sec\n",
      "optimizer time 0.020017 sec\n",
      "training time in round 51 cost 0.37923192977905273 sec\n",
      "loss 2.320048, train acc 0.107272\n",
      "round 52\n",
      "time to device 0.006706 sec\n",
      "time forward 0.535910 sec\n",
      "loss time 0.000432 sec\n",
      "backward time 0.003690 sec\n",
      "optimizer time 0.012222 sec\n",
      "training time in round 52 cost 0.3766789436340332 sec\n",
      "loss 2.319737, train acc 0.107311\n",
      "round 53\n",
      "time to device 0.004721 sec\n",
      "time forward 0.540836 sec\n",
      "loss time 0.000462 sec\n",
      "backward time 0.004586 sec\n",
      "optimizer time 0.012818 sec\n",
      "training time in round 53 cost 0.36887121200561523 sec\n",
      "loss 2.319791, train acc 0.106771\n",
      "round 54\n",
      "time to device 0.004942 sec\n",
      "time forward 0.550423 sec\n",
      "loss time 0.000548 sec\n",
      "backward time 0.003757 sec\n",
      "optimizer time 0.013069 sec\n",
      "training time in round 54 cost 0.35569190979003906 sec\n",
      "loss 2.322161, train acc 0.106392\n",
      "round 55\n",
      "time to device 0.010191 sec\n",
      "time forward 0.557416 sec\n",
      "loss time 0.000900 sec\n",
      "backward time 0.008293 sec\n",
      "optimizer time 0.020434 sec\n",
      "training time in round 55 cost 0.37155771255493164 sec\n",
      "loss 2.321804, train acc 0.106166\n",
      "round 56\n",
      "time to device 0.006820 sec\n",
      "time forward 0.562777 sec\n",
      "loss time 0.000557 sec\n",
      "backward time 0.005078 sec\n",
      "optimizer time 0.014396 sec\n",
      "training time in round 56 cost 0.35895609855651855 sec\n",
      "loss 2.321598, train acc 0.105811\n",
      "round 57\n",
      "time to device 0.006218 sec\n",
      "time forward 0.572527 sec\n",
      "loss time 0.000368 sec\n",
      "backward time 0.003503 sec\n",
      "optimizer time 0.011609 sec\n",
      "training time in round 57 cost 0.3842291831970215 sec\n",
      "loss 2.321266, train acc 0.105873\n",
      "round 58\n",
      "time to device 0.007042 sec\n",
      "time forward 0.579065 sec\n",
      "loss time 0.000401 sec\n",
      "backward time 0.003697 sec\n",
      "optimizer time 0.012919 sec\n",
      "training time in round 58 cost 0.39824604988098145 sec\n",
      "loss 2.321077, train acc 0.105270\n",
      "round 59\n",
      "time to device 0.006082 sec\n",
      "time forward 0.588134 sec\n",
      "loss time 0.000594 sec\n",
      "backward time 0.004891 sec\n",
      "optimizer time 0.015275 sec\n",
      "training time in round 59 cost 0.36667323112487793 sec\n",
      "loss 2.321877, train acc 0.105599\n",
      "round 60\n",
      "time to device 0.004831 sec\n",
      "time forward 0.593116 sec\n",
      "loss time 0.000540 sec\n",
      "backward time 0.003810 sec\n",
      "optimizer time 0.010667 sec\n",
      "training time in round 60 cost 0.34066200256347656 sec\n",
      "loss 2.321724, train acc 0.104892\n",
      "round 61\n",
      "time to device 0.006911 sec\n",
      "time forward 0.602792 sec\n",
      "loss time 0.000844 sec\n",
      "backward time 0.006179 sec\n",
      "optimizer time 0.015429 sec\n",
      "training time in round 61 cost 0.35508298873901367 sec\n",
      "loss 2.322085, train acc 0.103957\n",
      "round 62\n",
      "time to device 0.004715 sec\n",
      "time forward 0.608566 sec\n",
      "loss time 0.000470 sec\n",
      "backward time 0.004107 sec\n",
      "optimizer time 0.013453 sec\n",
      "training time in round 62 cost 0.36412596702575684 sec\n",
      "loss 2.322733, train acc 0.104167\n",
      "round 63\n",
      "time to device 0.005725 sec\n",
      "time forward 0.619151 sec\n",
      "loss time 0.000680 sec\n",
      "backward time 0.006165 sec\n",
      "optimizer time 0.016562 sec\n",
      "training time in round 63 cost 0.36230897903442383 sec\n",
      "loss 2.322527, train acc 0.104004\n",
      "round 64\n",
      "time to device 0.006188 sec\n",
      "time forward 0.629249 sec\n",
      "loss time 0.001263 sec\n",
      "backward time 0.009388 sec\n",
      "optimizer time 0.020343 sec\n",
      "training time in round 64 cost 0.3677370548248291 sec\n",
      "loss 2.322205, train acc 0.104567\n",
      "round 65\n",
      "time to device 0.006941 sec\n",
      "time forward 0.639692 sec\n",
      "loss time 0.001112 sec\n",
      "backward time 0.008764 sec\n",
      "optimizer time 0.021985 sec\n",
      "training time in round 65 cost 0.3840348720550537 sec\n",
      "loss 2.322002, train acc 0.103930\n",
      "round 66\n",
      "time to device 0.006871 sec\n",
      "time forward 0.650087 sec\n",
      "loss time 0.001062 sec\n",
      "backward time 0.010889 sec\n",
      "optimizer time 0.020052 sec\n",
      "training time in round 66 cost 0.3666412830352783 sec\n",
      "loss 2.321729, train acc 0.104128\n",
      "round 67\n",
      "time to device 0.007118 sec\n",
      "time forward 0.656047 sec\n",
      "loss time 0.000363 sec\n",
      "backward time 0.004536 sec\n",
      "optimizer time 0.011394 sec\n",
      "training time in round 67 cost 0.3690609931945801 sec\n",
      "loss 2.321411, train acc 0.104779\n",
      "round 68\n",
      "time to device 0.005160 sec\n",
      "time forward 0.668663 sec\n",
      "loss time 0.001330 sec\n",
      "backward time 0.012564 sec\n",
      "optimizer time 0.026520 sec\n",
      "training time in round 68 cost 0.4462440013885498 sec\n",
      "loss 2.321164, train acc 0.104846\n",
      "round 69\n",
      "time to device 0.007131 sec\n",
      "time forward 0.679480 sec\n",
      "loss time 0.001011 sec\n",
      "backward time 0.011565 sec\n",
      "optimizer time 0.038068 sec\n",
      "training time in round 69 cost 0.43587803840637207 sec\n",
      "loss 2.320926, train acc 0.104464\n",
      "round 70\n",
      "time to device 0.007887 sec\n",
      "time forward 0.690687 sec\n",
      "loss time 0.001059 sec\n",
      "backward time 0.011184 sec\n",
      "optimizer time 0.031852 sec\n",
      "training time in round 70 cost 0.43040013313293457 sec\n",
      "loss 2.320659, train acc 0.104313\n",
      "round 71\n",
      "time to device 0.008189 sec\n",
      "time forward 0.702740 sec\n",
      "loss time 0.000829 sec\n",
      "backward time 0.005819 sec\n",
      "optimizer time 0.015169 sec\n",
      "training time in round 71 cost 0.39568495750427246 sec\n",
      "loss 2.320470, train acc 0.104275\n",
      "round 72\n",
      "time to device 0.007926 sec\n",
      "time forward 0.718710 sec\n",
      "loss time 0.001084 sec\n",
      "backward time 0.022723 sec\n",
      "optimizer time 0.020437 sec\n",
      "training time in round 72 cost 0.47979092597961426 sec\n",
      "loss 2.320230, train acc 0.103596\n",
      "round 73\n",
      "time to device 0.006508 sec\n",
      "time forward 0.730264 sec\n",
      "loss time 0.001862 sec\n",
      "backward time 0.011538 sec\n",
      "optimizer time 0.031700 sec\n",
      "training time in round 73 cost 0.4394040107727051 sec\n",
      "loss 2.320480, train acc 0.103885\n",
      "round 74\n",
      "time to device 0.007724 sec\n",
      "time forward 0.746032 sec\n",
      "loss time 0.000668 sec\n",
      "backward time 0.005423 sec\n",
      "optimizer time 0.018252 sec\n",
      "training time in round 74 cost 0.4125511646270752 sec\n",
      "loss 2.320045, train acc 0.103854\n",
      "round 75\n",
      "time to device 0.005019 sec\n",
      "time forward 0.755977 sec\n",
      "loss time 0.001241 sec\n",
      "backward time 0.010633 sec\n",
      "optimizer time 0.033677 sec\n",
      "training time in round 75 cost 0.4263179302215576 sec\n",
      "loss 2.319613, train acc 0.103618\n",
      "round 76\n",
      "time to device 0.006735 sec\n",
      "time forward 0.764979 sec\n",
      "loss time 0.001284 sec\n",
      "backward time 0.012181 sec\n",
      "optimizer time 0.023358 sec\n",
      "training time in round 76 cost 0.4111449718475342 sec\n",
      "loss 2.319234, train acc 0.104099\n",
      "round 77\n",
      "time to device 0.006824 sec\n",
      "time forward 0.776294 sec\n",
      "loss time 0.000943 sec\n",
      "backward time 0.011844 sec\n",
      "optimizer time 0.028959 sec\n",
      "training time in round 77 cost 0.43157386779785156 sec\n",
      "loss 2.319038, train acc 0.104067\n",
      "round 78\n",
      "time to device 0.006819 sec\n",
      "time forward 0.783764 sec\n",
      "loss time 0.000598 sec\n",
      "backward time 0.005279 sec\n",
      "optimizer time 0.016793 sec\n",
      "training time in round 78 cost 0.39153409004211426 sec\n",
      "loss 2.318847, train acc 0.103837\n",
      "round 79\n",
      "time to device 0.007036 sec\n",
      "time forward 0.801030 sec\n",
      "loss time 0.001863 sec\n",
      "backward time 0.025290 sec\n",
      "optimizer time 0.022270 sec\n",
      "training time in round 79 cost 0.4364469051361084 sec\n",
      "loss 2.318651, train acc 0.104199\n",
      "round 80\n",
      "time to device 0.009202 sec\n",
      "time forward 0.814852 sec\n",
      "loss time 0.001114 sec\n",
      "backward time 0.011113 sec\n",
      "optimizer time 0.028520 sec\n",
      "training time in round 80 cost 0.41359806060791016 sec\n",
      "loss 2.318328, train acc 0.104745\n",
      "round 81\n",
      "time to device 0.007857 sec\n",
      "time forward 0.827833 sec\n",
      "loss time 0.001132 sec\n",
      "backward time 0.013457 sec\n",
      "optimizer time 0.023627 sec\n",
      "training time in round 81 cost 0.42034101486206055 sec\n",
      "loss 2.318512, train acc 0.104707\n",
      "round 82\n",
      "time to device 0.007246 sec\n",
      "time forward 0.835210 sec\n",
      "loss time 0.000739 sec\n",
      "backward time 0.006981 sec\n",
      "optimizer time 0.017973 sec\n",
      "training time in round 82 cost 0.3878049850463867 sec\n",
      "loss 2.318318, train acc 0.104480\n",
      "round 83\n",
      "time to device 0.007553 sec\n",
      "time forward 0.846440 sec\n",
      "loss time 0.001053 sec\n",
      "backward time 0.015394 sec\n",
      "optimizer time 0.035866 sec\n",
      "training time in round 83 cost 0.4337961673736572 sec\n",
      "loss 2.318094, train acc 0.104539\n",
      "round 84\n",
      "time to device 0.007726 sec\n",
      "time forward 0.856961 sec\n",
      "loss time 0.001618 sec\n",
      "backward time 0.009880 sec\n",
      "optimizer time 0.029201 sec\n",
      "training time in round 84 cost 0.4162430763244629 sec\n",
      "loss 2.317899, train acc 0.104136\n",
      "round 85\n",
      "time to device 0.006756 sec\n",
      "time forward 0.867211 sec\n",
      "loss time 0.001018 sec\n",
      "backward time 0.012197 sec\n",
      "optimizer time 0.030178 sec\n",
      "training time in round 85 cost 0.4144911766052246 sec\n",
      "loss 2.317885, train acc 0.104379\n",
      "round 86\n",
      "time to device 0.007565 sec\n",
      "time forward 0.877453 sec\n",
      "loss time 0.000743 sec\n",
      "backward time 0.007147 sec\n",
      "optimizer time 0.018041 sec\n",
      "training time in round 86 cost 0.38976001739501953 sec\n",
      "loss 2.317719, train acc 0.104436\n",
      "round 87\n",
      "time to device 0.006271 sec\n",
      "time forward 0.888299 sec\n",
      "loss time 0.001054 sec\n",
      "backward time 0.010176 sec\n",
      "optimizer time 0.027066 sec\n",
      "training time in round 87 cost 0.39073991775512695 sec\n",
      "loss 2.317680, train acc 0.104137\n",
      "round 88\n",
      "time to device 0.004504 sec\n",
      "time forward 0.900323 sec\n",
      "loss time 0.001127 sec\n",
      "backward time 0.009635 sec\n",
      "optimizer time 0.030107 sec\n",
      "training time in round 88 cost 0.39469218254089355 sec\n",
      "loss 2.317753, train acc 0.104108\n",
      "round 89\n",
      "time to device 0.006522 sec\n",
      "time forward 0.912499 sec\n",
      "loss time 0.001062 sec\n",
      "backward time 0.011739 sec\n",
      "optimizer time 0.026974 sec\n",
      "training time in round 89 cost 0.39928102493286133 sec\n",
      "loss 2.317468, train acc 0.104167\n",
      "round 90\n",
      "time to device 0.003738 sec\n",
      "time forward 0.920438 sec\n",
      "loss time 0.000801 sec\n",
      "backward time 0.006710 sec\n",
      "optimizer time 0.016456 sec\n",
      "training time in round 90 cost 0.3647940158843994 sec\n",
      "loss 2.317163, train acc 0.103623\n",
      "round 91\n",
      "time to device 0.004077 sec\n",
      "time forward 0.931370 sec\n",
      "loss time 0.001045 sec\n",
      "backward time 0.011377 sec\n",
      "optimizer time 0.031186 sec\n",
      "training time in round 91 cost 0.42823195457458496 sec\n",
      "loss 2.317430, train acc 0.103091\n",
      "round 92\n",
      "time to device 0.003700 sec\n",
      "time forward 0.942613 sec\n",
      "loss time 0.001114 sec\n",
      "backward time 0.019522 sec\n",
      "optimizer time 0.024758 sec\n",
      "training time in round 92 cost 0.39975500106811523 sec\n",
      "loss 2.317392, train acc 0.103159\n",
      "round 93\n",
      "time to device 0.006520 sec\n",
      "time forward 0.954192 sec\n",
      "loss time 0.000747 sec\n",
      "backward time 0.007129 sec\n",
      "optimizer time 0.017077 sec\n",
      "training time in round 93 cost 0.4068279266357422 sec\n",
      "loss 2.318591, train acc 0.102726\n",
      "round 94\n",
      "time to device 0.006050 sec\n",
      "time forward 0.962356 sec\n",
      "loss time 0.000783 sec\n",
      "backward time 0.006830 sec\n",
      "optimizer time 0.016785 sec\n",
      "training time in round 94 cost 0.3850820064544678 sec\n",
      "loss 2.318191, train acc 0.102796\n",
      "round 95\n",
      "time to device 0.005735 sec\n",
      "time forward 0.973445 sec\n",
      "loss time 0.001150 sec\n",
      "backward time 0.025654 sec\n",
      "optimizer time 0.027439 sec\n",
      "training time in round 95 cost 0.4094579219818115 sec\n",
      "loss 2.319597, train acc 0.102946\n",
      "round 96\n",
      "time to device 0.006727 sec\n",
      "time forward 0.987159 sec\n",
      "loss time 0.001023 sec\n",
      "backward time 0.011016 sec\n",
      "optimizer time 0.027990 sec\n",
      "training time in round 96 cost 0.4690113067626953 sec\n",
      "loss 2.319958, train acc 0.103254\n",
      "round 97\n",
      "time to device 0.007539 sec\n",
      "time forward 0.998251 sec\n",
      "loss time 0.001015 sec\n",
      "backward time 0.010945 sec\n",
      "optimizer time 0.032663 sec\n",
      "training time in round 97 cost 0.4094419479370117 sec\n",
      "loss 2.320364, train acc 0.103715\n",
      "round 98\n",
      "time to device 0.007331 sec\n",
      "time forward 1.007660 sec\n",
      "loss time 0.000771 sec\n",
      "backward time 0.006943 sec\n",
      "optimizer time 0.018588 sec\n",
      "training time in round 98 cost 0.38765525817871094 sec\n",
      "loss 2.320316, train acc 0.103693\n",
      "round 99\n",
      "time to device 0.007443 sec\n",
      "time forward 1.019453 sec\n",
      "loss time 0.001081 sec\n",
      "backward time 0.013336 sec\n",
      "optimizer time 0.023963 sec\n",
      "training time in round 99 cost 0.4145169258117676 sec\n",
      "loss 2.320646, train acc 0.103594\n",
      "round 100\n",
      "time to device 0.006114 sec\n",
      "time forward 1.036987 sec\n",
      "loss time 0.000951 sec\n",
      "backward time 0.011547 sec\n",
      "optimizer time 0.022875 sec\n",
      "training time in round 100 cost 0.4095168113708496 sec\n",
      "loss 2.323674, train acc 0.103342\n",
      "round 101\n",
      "time to device 0.007534 sec\n",
      "time forward 1.047595 sec\n",
      "loss time 0.001299 sec\n",
      "backward time 0.013401 sec\n",
      "optimizer time 0.023064 sec\n",
      "training time in round 101 cost 0.40194272994995117 sec\n",
      "loss 2.323649, train acc 0.103171\n",
      "round 102\n",
      "time to device 0.007057 sec\n",
      "time forward 1.055037 sec\n",
      "loss time 0.000775 sec\n",
      "backward time 0.006946 sec\n",
      "optimizer time 0.018944 sec\n",
      "training time in round 102 cost 0.37871718406677246 sec\n",
      "loss 2.323459, train acc 0.103004\n",
      "round 103\n",
      "time to device 0.006391 sec\n",
      "time forward 1.065975 sec\n",
      "loss time 0.000998 sec\n",
      "backward time 0.009779 sec\n",
      "optimizer time 0.032516 sec\n",
      "training time in round 103 cost 0.41391992568969727 sec\n",
      "loss 2.323210, train acc 0.103065\n",
      "round 104\n",
      "time to device 0.006552 sec\n",
      "time forward 1.078026 sec\n",
      "loss time 0.001262 sec\n",
      "backward time 0.009660 sec\n",
      "optimizer time 0.033178 sec\n",
      "training time in round 104 cost 0.4037508964538574 sec\n",
      "loss 2.324743, train acc 0.102827\n",
      "round 105\n",
      "time to device 0.006492 sec\n",
      "time forward 1.088000 sec\n",
      "loss time 0.001117 sec\n",
      "backward time 0.011730 sec\n",
      "optimizer time 0.018378 sec\n",
      "training time in round 105 cost 0.41952013969421387 sec\n",
      "loss 2.324942, train acc 0.102742\n",
      "round 106\n",
      "time to device 0.006828 sec\n",
      "time forward 1.095176 sec\n",
      "loss time 0.000558 sec\n",
      "backward time 0.004696 sec\n",
      "optimizer time 0.017674 sec\n",
      "training time in round 106 cost 0.3670940399169922 sec\n",
      "loss 2.325158, train acc 0.102731\n",
      "round 107\n",
      "time to device 0.006814 sec\n",
      "time forward 1.115062 sec\n",
      "loss time 0.001055 sec\n",
      "backward time 0.010806 sec\n",
      "optimizer time 0.027936 sec\n",
      "training time in round 107 cost 0.4140951633453369 sec\n",
      "loss 2.324983, train acc 0.102792\n",
      "round 108\n",
      "time to device 0.006262 sec\n",
      "time forward 1.125933 sec\n",
      "loss time 0.001207 sec\n",
      "backward time 0.010236 sec\n",
      "optimizer time 0.025285 sec\n",
      "training time in round 108 cost 0.38597702980041504 sec\n",
      "loss 2.324821, train acc 0.102351\n",
      "round 109\n",
      "time to device 0.006275 sec\n",
      "time forward 1.137203 sec\n",
      "loss time 0.001258 sec\n",
      "backward time 0.010674 sec\n",
      "optimizer time 0.031782 sec\n",
      "training time in round 109 cost 0.4009053707122803 sec\n",
      "loss 2.324628, train acc 0.102344\n",
      "round 110\n",
      "time to device 0.007152 sec\n",
      "time forward 1.145402 sec\n",
      "loss time 0.000802 sec\n",
      "backward time 0.006686 sec\n",
      "optimizer time 0.017550 sec\n",
      "training time in round 110 cost 0.37264466285705566 sec\n",
      "loss 2.324748, train acc 0.102548\n",
      "round 111\n",
      "time to device 0.006842 sec\n",
      "time forward 1.156027 sec\n",
      "loss time 0.000867 sec\n",
      "backward time 0.007798 sec\n",
      "optimizer time 0.019594 sec\n",
      "training time in round 111 cost 0.382587194442749 sec\n",
      "loss 2.324570, train acc 0.102400\n",
      "round 112\n",
      "time to device 0.005939 sec\n",
      "time forward 1.167847 sec\n",
      "loss time 0.001196 sec\n",
      "backward time 0.014076 sec\n",
      "optimizer time 0.025610 sec\n",
      "training time in round 112 cost 0.39403510093688965 sec\n",
      "loss 2.324383, train acc 0.102530\n",
      "round 113\n",
      "time to device 0.006340 sec\n",
      "time forward 1.179164 sec\n",
      "loss time 0.001274 sec\n",
      "backward time 0.010891 sec\n",
      "optimizer time 0.029125 sec\n",
      "training time in round 113 cost 0.39954471588134766 sec\n",
      "loss 2.324153, train acc 0.102522\n",
      "round 114\n",
      "time to device 0.006059 sec\n",
      "time forward 1.190042 sec\n",
      "loss time 0.000988 sec\n",
      "backward time 0.010740 sec\n",
      "optimizer time 0.028570 sec\n",
      "training time in round 114 cost 0.3943929672241211 sec\n",
      "loss 2.324333, train acc 0.102785\n",
      "round 115\n",
      "time to device 0.006120 sec\n",
      "time forward 1.201179 sec\n",
      "loss time 0.001273 sec\n",
      "backward time 0.011481 sec\n",
      "optimizer time 0.029206 sec\n",
      "training time in round 115 cost 0.3937718868255615 sec\n",
      "loss 2.324160, train acc 0.102438\n",
      "round 116\n",
      "time to device 0.005672 sec\n",
      "time forward 1.212747 sec\n",
      "loss time 0.001067 sec\n",
      "backward time 0.010138 sec\n",
      "optimizer time 0.029509 sec\n",
      "training time in round 116 cost 0.3957819938659668 sec\n",
      "loss 2.323915, train acc 0.102698\n",
      "round 117\n",
      "time to device 0.003275 sec\n",
      "time forward 1.224718 sec\n",
      "loss time 0.001287 sec\n",
      "backward time 0.010822 sec\n",
      "optimizer time 0.030943 sec\n",
      "training time in round 117 cost 0.3985409736633301 sec\n",
      "loss 2.323808, train acc 0.102556\n",
      "round 118\n",
      "time to device 0.003318 sec\n",
      "time forward 1.236001 sec\n",
      "loss time 0.001064 sec\n",
      "backward time 0.009441 sec\n",
      "optimizer time 0.028689 sec\n",
      "training time in round 118 cost 0.39092111587524414 sec\n",
      "loss 2.323816, train acc 0.102547\n",
      "round 119\n",
      "time to device 0.003940 sec\n",
      "time forward 1.247210 sec\n",
      "loss time 0.001456 sec\n",
      "backward time 0.011351 sec\n",
      "optimizer time 0.027408 sec\n",
      "training time in round 119 cost 0.3897261619567871 sec\n",
      "loss 2.324186, train acc 0.102148\n",
      "round 120\n",
      "time to device 0.003815 sec\n",
      "time forward 1.258399 sec\n",
      "loss time 0.001645 sec\n",
      "backward time 0.010808 sec\n",
      "optimizer time 0.026912 sec\n",
      "training time in round 120 cost 0.38571810722351074 sec\n",
      "loss 2.324360, train acc 0.102273\n",
      "round 121\n",
      "time to device 0.003418 sec\n",
      "time forward 1.268942 sec\n",
      "loss time 0.001395 sec\n",
      "backward time 0.010280 sec\n",
      "optimizer time 0.028063 sec\n",
      "training time in round 121 cost 0.3849198818206787 sec\n",
      "loss 2.324209, train acc 0.102331\n",
      "round 122\n",
      "time to device 0.003662 sec\n",
      "time forward 1.280246 sec\n",
      "loss time 0.001361 sec\n",
      "backward time 0.011767 sec\n",
      "optimizer time 0.027058 sec\n",
      "training time in round 122 cost 0.40048789978027344 sec\n",
      "loss 2.324419, train acc 0.102007\n",
      "round 123\n",
      "time to device 0.003259 sec\n",
      "time forward 1.291189 sec\n",
      "loss time 0.001095 sec\n",
      "backward time 0.011843 sec\n",
      "optimizer time 0.025266 sec\n",
      "training time in round 123 cost 0.3895599842071533 sec\n",
      "loss 2.324260, train acc 0.102193\n",
      "round 124\n",
      "time to device 0.003372 sec\n",
      "time forward 1.302169 sec\n",
      "loss time 0.001096 sec\n",
      "backward time 0.011783 sec\n",
      "optimizer time 0.028553 sec\n",
      "training time in round 124 cost 0.39284777641296387 sec\n",
      "loss 2.324228, train acc 0.101938\n",
      "round 125\n",
      "time to device 0.003345 sec\n",
      "time forward 1.314317 sec\n",
      "loss time 0.001169 sec\n",
      "backward time 0.009414 sec\n",
      "optimizer time 0.028988 sec\n",
      "training time in round 125 cost 0.39438605308532715 sec\n",
      "loss 2.324094, train acc 0.101935\n",
      "round 126\n",
      "time to device 0.003278 sec\n",
      "time forward 1.327881 sec\n",
      "loss time 0.001279 sec\n",
      "backward time 0.013711 sec\n",
      "optimizer time 0.027751 sec\n",
      "training time in round 126 cost 0.4073200225830078 sec\n",
      "loss 2.323929, train acc 0.102485\n",
      "round 127\n",
      "time to device 0.003714 sec\n",
      "time forward 1.338645 sec\n",
      "loss time 0.001031 sec\n",
      "backward time 0.012830 sec\n",
      "optimizer time 0.028606 sec\n",
      "training time in round 127 cost 0.3870198726654053 sec\n",
      "loss 2.323828, train acc 0.102295\n",
      "round 128\n",
      "time to device 0.006867 sec\n",
      "time forward 1.350637 sec\n",
      "loss time 0.001219 sec\n",
      "backward time 0.009674 sec\n",
      "optimizer time 0.021651 sec\n",
      "training time in round 128 cost 0.39506101608276367 sec\n",
      "loss 2.323813, train acc 0.102108\n",
      "round 129\n",
      "time to device 0.006813 sec\n",
      "time forward 1.361836 sec\n",
      "loss time 0.000983 sec\n",
      "backward time 0.012719 sec\n",
      "optimizer time 0.027328 sec\n",
      "training time in round 129 cost 0.39398193359375 sec\n",
      "loss 2.323650, train acc 0.102464\n",
      "round 130\n",
      "time to device 0.006363 sec\n",
      "time forward 1.374345 sec\n",
      "loss time 0.001091 sec\n",
      "backward time 0.013365 sec\n",
      "optimizer time 0.024009 sec\n",
      "training time in round 130 cost 0.40796494483947754 sec\n",
      "loss 2.323483, train acc 0.102397\n",
      "round 131\n",
      "time to device 0.007120 sec\n",
      "time forward 1.390942 sec\n",
      "loss time 0.001647 sec\n",
      "backward time 0.014140 sec\n",
      "optimizer time 0.025211 sec\n",
      "training time in round 131 cost 0.41849303245544434 sec\n",
      "loss 2.323365, train acc 0.102214\n",
      "round 132\n",
      "time to device 0.006882 sec\n",
      "time forward 1.402318 sec\n",
      "loss time 0.001969 sec\n",
      "backward time 0.010750 sec\n",
      "optimizer time 0.028658 sec\n",
      "training time in round 132 cost 0.3926229476928711 sec\n",
      "loss 2.323313, train acc 0.102326\n",
      "round 133\n",
      "time to device 0.006955 sec\n",
      "time forward 1.413763 sec\n",
      "loss time 0.001072 sec\n",
      "backward time 0.010928 sec\n",
      "optimizer time 0.028796 sec\n",
      "training time in round 133 cost 0.3913850784301758 sec\n",
      "loss 2.323293, train acc 0.102379\n",
      "round 134\n",
      "time to device 0.005814 sec\n",
      "time forward 1.424452 sec\n",
      "loss time 0.001181 sec\n",
      "backward time 0.012032 sec\n",
      "optimizer time 0.026325 sec\n",
      "training time in round 134 cost 0.38985586166381836 sec\n",
      "loss 2.323259, train acc 0.102373\n",
      "round 135\n",
      "time to device 0.006789 sec\n",
      "time forward 1.435962 sec\n",
      "loss time 0.001312 sec\n",
      "backward time 0.012024 sec\n",
      "optimizer time 0.017748 sec\n",
      "training time in round 135 cost 0.38634610176086426 sec\n",
      "loss 2.323343, train acc 0.102482\n",
      "round 136\n",
      "time to device 0.003442 sec\n",
      "time forward 1.447000 sec\n",
      "loss time 0.001191 sec\n",
      "backward time 0.011924 sec\n",
      "optimizer time 0.028848 sec\n",
      "training time in round 136 cost 0.3891258239746094 sec\n",
      "loss 2.323537, train acc 0.102418\n",
      "round 137\n",
      "time to device 0.002952 sec\n",
      "time forward 1.458569 sec\n",
      "loss time 0.001225 sec\n",
      "backward time 0.013408 sec\n",
      "optimizer time 0.026957 sec\n",
      "training time in round 137 cost 0.39188313484191895 sec\n",
      "loss 2.323576, train acc 0.102242\n",
      "round 138\n",
      "time to device 0.003614 sec\n",
      "time forward 1.469661 sec\n",
      "loss time 0.001396 sec\n",
      "backward time 0.010432 sec\n",
      "optimizer time 0.025758 sec\n",
      "training time in round 138 cost 0.38872194290161133 sec\n",
      "loss 2.323476, train acc 0.102349\n",
      "round 139\n",
      "time to device 0.003616 sec\n",
      "time forward 1.480437 sec\n",
      "loss time 0.001235 sec\n",
      "backward time 0.010099 sec\n",
      "optimizer time 0.028937 sec\n",
      "training time in round 139 cost 0.3933260440826416 sec\n",
      "loss 2.323367, train acc 0.102400\n",
      "round 140\n",
      "time to device 0.003004 sec\n",
      "time forward 1.491010 sec\n",
      "loss time 0.001567 sec\n",
      "backward time 0.010379 sec\n",
      "optimizer time 0.028389 sec\n",
      "training time in round 140 cost 0.3889949321746826 sec\n",
      "loss 2.323336, train acc 0.102227\n",
      "round 141\n",
      "time to device 0.003198 sec\n",
      "time forward 1.501845 sec\n",
      "loss time 0.001259 sec\n",
      "backward time 0.013038 sec\n",
      "optimizer time 0.033631 sec\n",
      "training time in round 141 cost 0.39567017555236816 sec\n",
      "loss 2.323270, train acc 0.102388\n",
      "round 142\n",
      "time to device 0.003624 sec\n",
      "time forward 1.513131 sec\n",
      "loss time 0.001064 sec\n",
      "backward time 0.011902 sec\n",
      "optimizer time 0.026569 sec\n",
      "training time in round 142 cost 0.38897109031677246 sec\n",
      "loss 2.323024, train acc 0.102655\n",
      "round 143\n",
      "time to device 0.003371 sec\n",
      "time forward 1.523994 sec\n",
      "loss time 0.001754 sec\n",
      "backward time 0.010165 sec\n",
      "optimizer time 0.028390 sec\n",
      "training time in round 143 cost 0.3899109363555908 sec\n",
      "loss 2.323118, train acc 0.102539\n",
      "round 144\n",
      "time to device 0.003381 sec\n",
      "time forward 1.534246 sec\n",
      "loss time 0.001172 sec\n",
      "backward time 0.010723 sec\n",
      "optimizer time 0.027934 sec\n",
      "training time in round 144 cost 0.38881492614746094 sec\n",
      "loss 2.323531, train acc 0.102532\n",
      "round 145\n",
      "time to device 0.003793 sec\n",
      "time forward 1.545855 sec\n",
      "loss time 0.001080 sec\n",
      "backward time 0.010788 sec\n",
      "optimizer time 0.028231 sec\n",
      "training time in round 145 cost 0.3885009288787842 sec\n",
      "loss 2.323375, train acc 0.102579\n",
      "round 146\n",
      "time to device 0.003423 sec\n",
      "time forward 1.557182 sec\n",
      "loss time 0.000988 sec\n",
      "backward time 0.012012 sec\n",
      "optimizer time 0.027553 sec\n",
      "training time in round 146 cost 0.38957810401916504 sec\n",
      "loss 2.323294, train acc 0.102360\n",
      "round 147\n",
      "time to device 0.003517 sec\n",
      "time forward 1.571461 sec\n",
      "loss time 0.001318 sec\n",
      "backward time 0.011089 sec\n",
      "optimizer time 0.022966 sec\n",
      "training time in round 147 cost 0.46281909942626953 sec\n",
      "loss 2.323076, train acc 0.102460\n",
      "round 148\n",
      "time to device 0.003660 sec\n",
      "time forward 1.582526 sec\n",
      "loss time 0.001481 sec\n",
      "backward time 0.017511 sec\n",
      "optimizer time 0.025440 sec\n",
      "training time in round 148 cost 0.409451961517334 sec\n",
      "loss 2.323486, train acc 0.102401\n",
      "round 149\n",
      "time to device 0.003259 sec\n",
      "time forward 1.593491 sec\n",
      "loss time 0.001093 sec\n",
      "backward time 0.011507 sec\n",
      "optimizer time 0.026511 sec\n",
      "training time in round 149 cost 0.4147529602050781 sec\n",
      "loss 2.324352, train acc 0.102292\n",
      "round 150\n",
      "time to device 0.003400 sec\n",
      "time forward 1.605808 sec\n",
      "loss time 0.001187 sec\n",
      "backward time 0.011620 sec\n",
      "optimizer time 0.027571 sec\n",
      "training time in round 150 cost 0.39163899421691895 sec\n",
      "loss 2.324102, train acc 0.102183\n",
      "round 151\n",
      "time to device 0.004181 sec\n",
      "time forward 1.616778 sec\n",
      "loss time 0.001089 sec\n",
      "backward time 0.011356 sec\n",
      "optimizer time 0.029138 sec\n",
      "training time in round 151 cost 0.393021821975708 sec\n",
      "loss 2.323898, train acc 0.102179\n",
      "round 152\n",
      "time to device 0.003376 sec\n",
      "time forward 1.627570 sec\n",
      "loss time 0.000948 sec\n",
      "backward time 0.011541 sec\n",
      "optimizer time 0.026458 sec\n",
      "training time in round 152 cost 0.39019083976745605 sec\n",
      "loss 2.323770, train acc 0.102379\n",
      "round 153\n",
      "time to device 0.003486 sec\n",
      "time forward 1.634937 sec\n",
      "loss time 0.000567 sec\n",
      "backward time 0.004609 sec\n",
      "optimizer time 0.013269 sec\n",
      "training time in round 153 cost 0.4072120189666748 sec\n",
      "loss 2.323714, train acc 0.102222\n",
      "round 154\n",
      "time to device 0.004306 sec\n",
      "time forward 1.647752 sec\n",
      "loss time 0.001058 sec\n",
      "backward time 0.009721 sec\n",
      "optimizer time 0.028926 sec\n",
      "training time in round 154 cost 0.414215087890625 sec\n",
      "loss 2.323760, train acc 0.102319\n",
      "round 155\n",
      "time to device 0.003640 sec\n",
      "time forward 1.659719 sec\n",
      "loss time 0.001004 sec\n",
      "backward time 0.012778 sec\n",
      "optimizer time 0.031726 sec\n",
      "training time in round 155 cost 0.3978271484375 sec\n",
      "loss 2.324160, train acc 0.102214\n",
      "round 156\n",
      "time to device 0.006263 sec\n",
      "time forward 1.671824 sec\n",
      "loss time 0.001256 sec\n",
      "backward time 0.011232 sec\n",
      "optimizer time 0.030936 sec\n",
      "training time in round 156 cost 0.4021720886230469 sec\n",
      "loss 2.324069, train acc 0.102259\n",
      "round 157\n",
      "time to device 0.007942 sec\n",
      "time forward 1.690404 sec\n",
      "loss time 0.001279 sec\n",
      "backward time 0.011349 sec\n",
      "optimizer time 0.029658 sec\n",
      "training time in round 157 cost 0.41176295280456543 sec\n",
      "loss 2.323953, train acc 0.102156\n",
      "round 158\n",
      "time to device 0.006812 sec\n",
      "time forward 1.701052 sec\n",
      "loss time 0.001230 sec\n",
      "backward time 0.011207 sec\n",
      "optimizer time 0.027266 sec\n",
      "training time in round 158 cost 0.39055728912353516 sec\n",
      "loss 2.323818, train acc 0.102250\n",
      "round 159\n",
      "time to device 0.006973 sec\n",
      "time forward 1.711750 sec\n",
      "loss time 0.001092 sec\n",
      "backward time 0.012194 sec\n",
      "optimizer time 0.026074 sec\n",
      "training time in round 159 cost 0.3908209800720215 sec\n",
      "loss 2.323821, train acc 0.102051\n",
      "round 160\n",
      "time to device 0.006330 sec\n",
      "time forward 1.722692 sec\n",
      "loss time 0.001295 sec\n",
      "backward time 0.012667 sec\n",
      "optimizer time 0.027522 sec\n",
      "training time in round 160 cost 0.3930208683013916 sec\n",
      "loss 2.323849, train acc 0.101999\n",
      "round 161\n",
      "time to device 0.003208 sec\n",
      "time forward 1.733846 sec\n",
      "loss time 0.000898 sec\n",
      "backward time 0.010237 sec\n",
      "optimizer time 0.027701 sec\n",
      "training time in round 161 cost 0.3905022144317627 sec\n",
      "loss 2.323704, train acc 0.101948\n",
      "round 162\n",
      "time to device 0.003536 sec\n",
      "time forward 1.744694 sec\n",
      "loss time 0.001068 sec\n",
      "backward time 0.013812 sec\n",
      "optimizer time 0.029043 sec\n",
      "training time in round 162 cost 0.3934803009033203 sec\n",
      "loss 2.323576, train acc 0.101946\n",
      "round 163\n",
      "time to device 0.006638 sec\n",
      "time forward 1.762969 sec\n",
      "loss time 0.001594 sec\n",
      "backward time 0.019529 sec\n",
      "optimizer time 0.021877 sec\n",
      "training time in round 163 cost 0.4412498474121094 sec\n",
      "loss 2.323633, train acc 0.101753\n",
      "round 164\n",
      "time to device 0.007669 sec\n",
      "time forward 1.774211 sec\n",
      "loss time 0.000968 sec\n",
      "backward time 0.010042 sec\n",
      "optimizer time 0.026095 sec\n",
      "training time in round 164 cost 0.42101383209228516 sec\n",
      "loss 2.323634, train acc 0.101705\n",
      "round 165\n",
      "time to device 0.006582 sec\n",
      "time forward 1.785875 sec\n",
      "loss time 0.001492 sec\n",
      "backward time 0.010723 sec\n",
      "optimizer time 0.018186 sec\n",
      "training time in round 165 cost 0.4740421772003174 sec\n",
      "loss 2.323681, train acc 0.101657\n",
      "round 166\n",
      "time to device 0.009613 sec\n",
      "time forward 1.803617 sec\n",
      "loss time 0.000946 sec\n",
      "backward time 0.012722 sec\n",
      "optimizer time 0.020225 sec\n",
      "training time in round 166 cost 0.4314749240875244 sec\n",
      "loss 2.323503, train acc 0.101562\n",
      "round 167\n",
      "time to device 0.006760 sec\n",
      "time forward 1.814855 sec\n",
      "loss time 0.001320 sec\n",
      "backward time 0.024183 sec\n",
      "optimizer time 0.015480 sec\n",
      "training time in round 167 cost 0.4402809143066406 sec\n",
      "loss 2.323363, train acc 0.101935\n",
      "round 168\n",
      "time to device 0.007921 sec\n",
      "time forward 1.825481 sec\n",
      "loss time 0.001044 sec\n",
      "backward time 0.011799 sec\n",
      "optimizer time 0.021357 sec\n",
      "training time in round 168 cost 0.41299891471862793 sec\n",
      "loss 2.323254, train acc 0.101840\n",
      "round 169\n",
      "time to device 0.007385 sec\n",
      "time forward 1.836760 sec\n",
      "loss time 0.000418 sec\n",
      "backward time 0.004734 sec\n",
      "optimizer time 0.014583 sec\n",
      "training time in round 169 cost 0.46254396438598633 sec\n",
      "loss 2.323163, train acc 0.101838\n",
      "round 170\n",
      "time to device 0.006376 sec\n",
      "time forward 1.844377 sec\n",
      "loss time 0.000461 sec\n",
      "backward time 0.004144 sec\n",
      "optimizer time 0.019047 sec\n",
      "training time in round 170 cost 0.42464566230773926 sec\n",
      "loss 2.323008, train acc 0.101654\n",
      "round 171\n",
      "time to device 0.005544 sec\n",
      "time forward 1.855767 sec\n",
      "loss time 0.000890 sec\n",
      "backward time 0.014410 sec\n",
      "optimizer time 0.021529 sec\n",
      "training time in round 171 cost 0.42356133460998535 sec\n",
      "loss 2.322972, train acc 0.101245\n",
      "round 172\n",
      "time to device 0.007145 sec\n",
      "time forward 1.867724 sec\n",
      "loss time 0.001048 sec\n",
      "backward time 0.006628 sec\n",
      "optimizer time 0.020459 sec\n",
      "training time in round 172 cost 0.4180450439453125 sec\n",
      "loss 2.322888, train acc 0.100975\n",
      "round 173\n",
      "time to device 0.006258 sec\n",
      "time forward 1.881443 sec\n",
      "loss time 0.000511 sec\n",
      "backward time 0.005127 sec\n",
      "optimizer time 0.014165 sec\n",
      "training time in round 173 cost 0.5023438930511475 sec\n",
      "loss 2.323013, train acc 0.100665\n",
      "round 174\n",
      "time to device 0.005990 sec\n",
      "time forward 1.891190 sec\n",
      "loss time 0.001157 sec\n",
      "backward time 0.008372 sec\n",
      "optimizer time 0.023251 sec\n",
      "training time in round 174 cost 0.41490602493286133 sec\n",
      "loss 2.322899, train acc 0.100848\n",
      "round 175\n",
      "time to device 0.006946 sec\n",
      "time forward 1.903374 sec\n",
      "loss time 0.000809 sec\n",
      "backward time 0.007046 sec\n",
      "optimizer time 0.021065 sec\n",
      "training time in round 175 cost 0.3801758289337158 sec\n",
      "loss 2.322791, train acc 0.100630\n",
      "round 176\n",
      "time to device 0.006423 sec\n",
      "time forward 1.913622 sec\n",
      "loss time 0.000552 sec\n",
      "backward time 0.004898 sec\n",
      "optimizer time 0.015236 sec\n",
      "training time in round 176 cost 0.3627200126647949 sec\n",
      "loss 2.322675, train acc 0.100680\n",
      "round 177\n",
      "time to device 0.006853 sec\n",
      "time forward 1.927158 sec\n",
      "loss time 0.000807 sec\n",
      "backward time 0.007335 sec\n",
      "optimizer time 0.021107 sec\n",
      "training time in round 177 cost 0.3840200901031494 sec\n",
      "loss 2.322560, train acc 0.100641\n",
      "round 178\n",
      "time to device 0.006948 sec\n",
      "time forward 1.938089 sec\n",
      "loss time 0.001066 sec\n",
      "backward time 0.008575 sec\n",
      "optimizer time 0.021145 sec\n",
      "training time in round 178 cost 0.3852510452270508 sec\n",
      "loss 2.322434, train acc 0.100733\n",
      "round 179\n",
      "time to device 0.007100 sec\n",
      "time forward 1.947958 sec\n",
      "loss time 0.000778 sec\n",
      "backward time 0.006169 sec\n",
      "optimizer time 0.018301 sec\n",
      "training time in round 179 cost 0.38912296295166016 sec\n",
      "loss 2.322293, train acc 0.100651\n",
      "round 180\n",
      "time to device 0.006820 sec\n",
      "time forward 1.958023 sec\n",
      "loss time 0.001124 sec\n",
      "backward time 0.008867 sec\n",
      "optimizer time 0.020441 sec\n",
      "training time in round 180 cost 0.3875260353088379 sec\n",
      "loss 2.322643, train acc 0.100742\n",
      "round 181\n",
      "time to device 0.007030 sec\n",
      "time forward 1.968007 sec\n",
      "loss time 0.001145 sec\n",
      "backward time 0.006542 sec\n",
      "optimizer time 0.020403 sec\n",
      "training time in round 181 cost 0.39206695556640625 sec\n",
      "loss 2.322550, train acc 0.100618\n",
      "round 182\n",
      "time to device 0.006368 sec\n",
      "time forward 1.974849 sec\n",
      "loss time 0.000630 sec\n",
      "backward time 0.005325 sec\n",
      "optimizer time 0.015446 sec\n",
      "training time in round 182 cost 0.3737063407897949 sec\n",
      "loss 2.322548, train acc 0.100538\n",
      "round 183\n",
      "time to device 0.006857 sec\n",
      "time forward 1.986407 sec\n",
      "loss time 0.001041 sec\n",
      "backward time 0.010368 sec\n",
      "optimizer time 0.026705 sec\n",
      "training time in round 183 cost 0.38445591926574707 sec\n",
      "loss 2.322466, train acc 0.100586\n",
      "round 184\n",
      "time to device 0.007195 sec\n",
      "time forward 1.997947 sec\n",
      "loss time 0.001203 sec\n",
      "backward time 0.008147 sec\n",
      "optimizer time 0.019643 sec\n",
      "training time in round 184 cost 0.3868980407714844 sec\n",
      "loss 2.322373, train acc 0.100591\n",
      "round 185\n",
      "time to device 0.006786 sec\n",
      "time forward 2.009795 sec\n",
      "loss time 0.001203 sec\n",
      "backward time 0.008619 sec\n",
      "optimizer time 0.019684 sec\n",
      "training time in round 185 cost 0.3750278949737549 sec\n",
      "loss 2.322280, train acc 0.100554\n",
      "round 186\n",
      "time to device 0.003119 sec\n",
      "time forward 2.018852 sec\n",
      "loss time 0.001090 sec\n",
      "backward time 0.008297 sec\n",
      "optimizer time 0.019578 sec\n",
      "training time in round 186 cost 0.3744392395019531 sec\n",
      "loss 2.322197, train acc 0.100602\n",
      "round 187\n",
      "time to device 0.003621 sec\n",
      "time forward 2.030380 sec\n",
      "loss time 0.001153 sec\n",
      "backward time 0.008769 sec\n",
      "optimizer time 0.020460 sec\n",
      "training time in round 187 cost 0.3692128658294678 sec\n",
      "loss 2.322145, train acc 0.100482\n",
      "round 188\n",
      "time to device 0.006379 sec\n",
      "time forward 2.044939 sec\n",
      "loss time 0.001114 sec\n",
      "backward time 0.008266 sec\n",
      "optimizer time 0.019338 sec\n",
      "training time in round 188 cost 0.3819611072540283 sec\n",
      "loss 2.322047, train acc 0.100529\n",
      "round 189\n",
      "time to device 0.003817 sec\n",
      "time forward 2.055016 sec\n",
      "loss time 0.000605 sec\n",
      "backward time 0.006456 sec\n",
      "optimizer time 0.017835 sec\n",
      "training time in round 189 cost 0.36128902435302734 sec\n",
      "loss 2.322024, train acc 0.100370\n",
      "round 190\n",
      "time to device 0.006235 sec\n",
      "time forward 2.064775 sec\n",
      "loss time 0.000890 sec\n",
      "backward time 0.016905 sec\n",
      "optimizer time 0.018073 sec\n",
      "training time in round 190 cost 0.37578487396240234 sec\n",
      "loss 2.321917, train acc 0.100458\n",
      "round 191\n",
      "time to device 0.006686 sec\n",
      "time forward 2.075456 sec\n",
      "loss time 0.001925 sec\n",
      "backward time 0.009974 sec\n",
      "optimizer time 0.020299 sec\n",
      "training time in round 191 cost 0.38812994956970215 sec\n",
      "loss 2.322290, train acc 0.100545\n",
      "round 192\n",
      "time to device 0.003781 sec\n",
      "time forward 2.081377 sec\n",
      "loss time 0.000445 sec\n",
      "backward time 0.003588 sec\n",
      "optimizer time 0.017724 sec\n",
      "training time in round 192 cost 0.3404958248138428 sec\n",
      "loss 2.322179, train acc 0.100510\n",
      "round 193\n",
      "time to device 0.005911 sec\n",
      "time forward 2.087376 sec\n",
      "loss time 0.000450 sec\n",
      "backward time 0.004015 sec\n",
      "optimizer time 0.012530 sec\n",
      "training time in round 193 cost 0.3620491027832031 sec\n",
      "loss 2.321997, train acc 0.100636\n",
      "round 194\n",
      "time to device 0.009009 sec\n",
      "time forward 2.107735 sec\n",
      "loss time 0.001233 sec\n",
      "backward time 0.009725 sec\n",
      "optimizer time 0.027008 sec\n",
      "training time in round 194 cost 0.4286181926727295 sec\n",
      "loss 2.321858, train acc 0.100801\n",
      "round 195\n",
      "time to device 0.007804 sec\n",
      "time forward 2.119775 sec\n",
      "loss time 0.001498 sec\n",
      "backward time 0.015522 sec\n",
      "optimizer time 0.028145 sec\n",
      "training time in round 195 cost 0.426008939743042 sec\n",
      "loss 2.321791, train acc 0.100805\n",
      "round 196\n",
      "time to device 0.007534 sec\n",
      "time forward 2.137647 sec\n",
      "loss time 0.001675 sec\n",
      "backward time 0.015983 sec\n",
      "optimizer time 0.023572 sec\n",
      "training time in round 196 cost 0.4320347309112549 sec\n",
      "loss 2.322384, train acc 0.100809\n",
      "round 197\n",
      "time to device 0.007200 sec\n",
      "time forward 2.143809 sec\n",
      "loss time 0.000865 sec\n",
      "backward time 0.007492 sec\n",
      "optimizer time 0.018091 sec\n",
      "training time in round 197 cost 0.37001562118530273 sec\n",
      "loss 2.322380, train acc 0.100616\n",
      "round 198\n",
      "time to device 0.006379 sec\n",
      "time forward 2.152682 sec\n",
      "loss time 0.000389 sec\n",
      "backward time 0.003726 sec\n",
      "optimizer time 0.012942 sec\n",
      "training time in round 198 cost 0.3956472873687744 sec\n",
      "loss 2.322355, train acc 0.100620\n",
      "round 199\n",
      "time to device 0.007968 sec\n",
      "time forward 2.164140 sec\n",
      "loss time 0.000717 sec\n",
      "backward time 0.003782 sec\n",
      "optimizer time 0.012777 sec\n",
      "training time in round 199 cost 0.555034875869751 sec\n",
      "loss 2.322232, train acc 0.100508\n",
      "round 200\n",
      "time to device 0.004391 sec\n",
      "time forward 2.174226 sec\n",
      "loss time 0.000884 sec\n",
      "backward time 0.003814 sec\n",
      "optimizer time 0.011078 sec\n",
      "training time in round 200 cost 0.40249085426330566 sec\n",
      "loss 2.322164, train acc 0.100552\n",
      "round 201\n",
      "time to device 0.006420 sec\n",
      "time forward 2.184662 sec\n",
      "loss time 0.000992 sec\n",
      "backward time 0.005936 sec\n",
      "optimizer time 0.017123 sec\n",
      "training time in round 201 cost 0.4768948554992676 sec\n",
      "loss 2.322304, train acc 0.100518\n",
      "round 202\n",
      "time to device 0.007285 sec\n",
      "time forward 2.197064 sec\n",
      "loss time 0.001076 sec\n",
      "backward time 0.010946 sec\n",
      "optimizer time 0.022848 sec\n",
      "training time in round 202 cost 0.40584301948547363 sec\n",
      "loss 2.322268, train acc 0.100523\n",
      "round 203\n",
      "time to device 0.007272 sec\n",
      "time forward 2.209284 sec\n",
      "loss time 0.000932 sec\n",
      "backward time 0.011326 sec\n",
      "optimizer time 0.015608 sec\n",
      "training time in round 203 cost 0.4580271244049072 sec\n",
      "loss 2.322167, train acc 0.100643\n",
      "round 204\n",
      "time to device 0.007062 sec\n",
      "time forward 2.218075 sec\n",
      "loss time 0.000757 sec\n",
      "backward time 0.006623 sec\n",
      "optimizer time 0.015914 sec\n",
      "training time in round 204 cost 0.37442898750305176 sec\n",
      "loss 2.322072, train acc 0.100648\n",
      "round 205\n",
      "time to device 0.007646 sec\n",
      "time forward 2.233146 sec\n",
      "loss time 0.002205 sec\n",
      "backward time 0.012909 sec\n",
      "optimizer time 0.026804 sec\n",
      "training time in round 205 cost 0.47461891174316406 sec\n",
      "loss 2.321996, train acc 0.100576\n",
      "round 206\n",
      "time to device 0.008350 sec\n",
      "time forward 2.245448 sec\n",
      "loss time 0.001223 sec\n",
      "backward time 0.011852 sec\n",
      "optimizer time 0.022974 sec\n",
      "training time in round 206 cost 0.4051039218902588 sec\n",
      "loss 2.321939, train acc 0.100543\n",
      "round 207\n",
      "time to device 0.010417 sec\n",
      "time forward 2.253268 sec\n",
      "loss time 0.000671 sec\n",
      "backward time 0.006224 sec\n",
      "optimizer time 0.018293 sec\n",
      "training time in round 207 cost 0.38997483253479004 sec\n",
      "loss 2.321749, train acc 0.100398\n",
      "round 208\n",
      "time to device 0.007403 sec\n",
      "time forward 2.263245 sec\n",
      "loss time 0.001252 sec\n",
      "backward time 0.011414 sec\n",
      "optimizer time 0.030934 sec\n",
      "training time in round 208 cost 0.40955281257629395 sec\n",
      "loss 2.321847, train acc 0.100591\n",
      "round 209\n",
      "time to device 0.010892 sec\n",
      "time forward 2.273844 sec\n",
      "loss time 0.001476 sec\n",
      "backward time 0.013352 sec\n",
      "optimizer time 0.021188 sec\n",
      "training time in round 209 cost 0.44905877113342285 sec\n",
      "loss 2.321890, train acc 0.100446\n",
      "round 210\n",
      "time to device 0.007542 sec\n",
      "time forward 2.288612 sec\n",
      "loss time 0.001504 sec\n",
      "backward time 0.012983 sec\n",
      "optimizer time 0.020233 sec\n",
      "training time in round 210 cost 0.491591215133667 sec\n",
      "loss 2.321785, train acc 0.100341\n",
      "round 211\n",
      "time to device 0.006785 sec\n",
      "time forward 2.300643 sec\n",
      "loss time 0.000986 sec\n",
      "backward time 0.009859 sec\n",
      "optimizer time 0.020457 sec\n",
      "training time in round 211 cost 0.43747782707214355 sec\n",
      "loss 2.321697, train acc 0.100457\n",
      "round 212\n",
      "time to device 0.009925 sec\n",
      "time forward 2.312609 sec\n",
      "loss time 0.001092 sec\n",
      "backward time 0.016555 sec\n",
      "optimizer time 0.027225 sec\n",
      "training time in round 212 cost 0.4256761074066162 sec\n",
      "loss 2.321700, train acc 0.100205\n",
      "round 213\n",
      "time to device 0.007455 sec\n",
      "time forward 2.325216 sec\n",
      "loss time 0.001201 sec\n",
      "backward time 0.011873 sec\n",
      "optimizer time 0.028151 sec\n",
      "training time in round 213 cost 0.4290611743927002 sec\n",
      "loss 2.321615, train acc 0.099993\n",
      "round 214\n",
      "time to device 0.007703 sec\n",
      "time forward 2.337428 sec\n",
      "loss time 0.001539 sec\n",
      "backward time 0.021265 sec\n",
      "optimizer time 0.031551 sec\n",
      "training time in round 214 cost 0.4453558921813965 sec\n",
      "loss 2.321519, train acc 0.100109\n",
      "round 215\n",
      "time to device 0.007487 sec\n",
      "time forward 2.349562 sec\n",
      "loss time 0.000949 sec\n",
      "backward time 0.007884 sec\n",
      "optimizer time 0.019729 sec\n",
      "training time in round 215 cost 0.4032480716705322 sec\n",
      "loss 2.321515, train acc 0.100080\n",
      "round 216\n",
      "time to device 0.008883 sec\n",
      "time forward 2.363838 sec\n",
      "loss time 0.001266 sec\n",
      "backward time 0.016091 sec\n",
      "optimizer time 0.026539 sec\n",
      "training time in round 216 cost 0.4199056625366211 sec\n",
      "loss 2.321460, train acc 0.100014\n",
      "round 217\n",
      "time to device 0.008618 sec\n",
      "time forward 2.377513 sec\n",
      "loss time 0.001881 sec\n",
      "backward time 0.015497 sec\n",
      "optimizer time 0.024993 sec\n",
      "training time in round 217 cost 0.40483689308166504 sec\n",
      "loss 2.321413, train acc 0.100022\n",
      "round 218\n",
      "time to device 0.006804 sec\n",
      "time forward 2.393485 sec\n",
      "loss time 0.001633 sec\n",
      "backward time 0.016594 sec\n",
      "optimizer time 0.022638 sec\n",
      "training time in round 218 cost 0.4485621452331543 sec\n",
      "loss 2.321352, train acc 0.100171\n",
      "round 219\n",
      "time to device 0.007140 sec\n",
      "time forward 2.407154 sec\n",
      "loss time 0.001351 sec\n",
      "backward time 0.014587 sec\n",
      "optimizer time 0.025564 sec\n",
      "training time in round 219 cost 0.46550512313842773 sec\n",
      "loss 2.321265, train acc 0.100036\n",
      "round 220\n",
      "time to device 0.006856 sec\n",
      "time forward 2.425940 sec\n",
      "loss time 0.001084 sec\n",
      "backward time 0.013447 sec\n",
      "optimizer time 0.023947 sec\n",
      "training time in round 220 cost 0.42527198791503906 sec\n",
      "loss 2.321325, train acc 0.100361\n",
      "round 221\n",
      "time to device 0.008178 sec\n",
      "time forward 2.437261 sec\n",
      "loss time 0.001250 sec\n",
      "backward time 0.011139 sec\n",
      "optimizer time 0.026931 sec\n",
      "training time in round 221 cost 0.41205906867980957 sec\n",
      "loss 2.321268, train acc 0.100190\n",
      "round 222\n",
      "time to device 0.010632 sec\n",
      "time forward 2.454804 sec\n",
      "loss time 0.001096 sec\n",
      "backward time 0.011588 sec\n",
      "optimizer time 0.017436 sec\n",
      "training time in round 222 cost 0.41661739349365234 sec\n",
      "loss 2.321267, train acc 0.100371\n",
      "round 223\n",
      "time to device 0.011029 sec\n",
      "time forward 2.461255 sec\n",
      "loss time 0.000527 sec\n",
      "backward time 0.004912 sec\n",
      "optimizer time 0.013958 sec\n",
      "training time in round 223 cost 0.39482593536376953 sec\n",
      "loss 2.321134, train acc 0.100481\n",
      "round 224\n",
      "time to device 0.007141 sec\n",
      "time forward 2.473460 sec\n",
      "loss time 0.001027 sec\n",
      "backward time 0.010118 sec\n",
      "optimizer time 0.050689 sec\n",
      "training time in round 224 cost 0.4868800640106201 sec\n",
      "loss 2.321064, train acc 0.100451\n",
      "round 225\n",
      "time to device 0.006529 sec\n",
      "time forward 2.485795 sec\n",
      "loss time 0.001222 sec\n",
      "backward time 0.012934 sec\n",
      "optimizer time 0.027893 sec\n",
      "training time in round 225 cost 0.43624019622802734 sec\n",
      "loss 2.321010, train acc 0.100387\n",
      "round 226\n",
      "time to device 0.008416 sec\n",
      "time forward 2.495764 sec\n",
      "loss time 0.001468 sec\n",
      "backward time 0.012840 sec\n",
      "optimizer time 0.031116 sec\n",
      "training time in round 226 cost 0.4251701831817627 sec\n",
      "loss 2.320925, train acc 0.100461\n",
      "round 227\n",
      "time to device 0.008344 sec\n",
      "time forward 2.506681 sec\n",
      "loss time 0.001032 sec\n",
      "backward time 0.015301 sec\n",
      "optimizer time 0.027275 sec\n",
      "training time in round 227 cost 0.4062631130218506 sec\n",
      "loss 2.320862, train acc 0.100466\n",
      "round 228\n",
      "time to device 0.007192 sec\n",
      "time forward 2.518322 sec\n",
      "loss time 0.001446 sec\n",
      "backward time 0.010682 sec\n",
      "optimizer time 0.027493 sec\n",
      "training time in round 228 cost 0.405681848526001 sec\n",
      "loss 2.320776, train acc 0.100505\n",
      "round 229\n",
      "time to device 0.010489 sec\n",
      "time forward 2.533256 sec\n",
      "loss time 0.001118 sec\n",
      "backward time 0.010828 sec\n",
      "optimizer time 0.028840 sec\n",
      "training time in round 229 cost 0.44991207122802734 sec\n",
      "loss 2.320684, train acc 0.100374\n",
      "round 230\n",
      "time to device 0.006626 sec\n",
      "time forward 2.551333 sec\n",
      "loss time 0.001152 sec\n",
      "backward time 0.016173 sec\n",
      "optimizer time 0.026799 sec\n",
      "training time in round 230 cost 0.4176018238067627 sec\n",
      "loss 2.320624, train acc 0.100277\n",
      "round 231\n",
      "time to device 0.006816 sec\n",
      "time forward 2.560009 sec\n",
      "loss time 0.000883 sec\n",
      "backward time 0.007083 sec\n",
      "optimizer time 0.017157 sec\n",
      "training time in round 231 cost 0.38030099868774414 sec\n",
      "loss 2.320549, train acc 0.100216\n",
      "round 232\n",
      "time to device 0.006497 sec\n",
      "time forward 2.572470 sec\n",
      "loss time 0.001381 sec\n",
      "backward time 0.015021 sec\n",
      "optimizer time 0.013296 sec\n",
      "training time in round 232 cost 0.3825681209564209 sec\n",
      "loss 2.320495, train acc 0.100221\n",
      "round 233\n",
      "time to device 0.006474 sec\n",
      "time forward 2.586542 sec\n",
      "loss time 0.001536 sec\n",
      "backward time 0.014559 sec\n",
      "optimizer time 0.027985 sec\n",
      "training time in round 233 cost 0.4461641311645508 sec\n",
      "loss 2.320417, train acc 0.100194\n",
      "round 234\n",
      "time to device 0.006068 sec\n",
      "time forward 2.595712 sec\n",
      "loss time 0.000939 sec\n",
      "backward time 0.007901 sec\n",
      "optimizer time 0.020584 sec\n",
      "training time in round 234 cost 0.37935400009155273 sec\n",
      "loss 2.320355, train acc 0.100100\n",
      "round 235\n",
      "time to device 0.006300 sec\n",
      "time forward 2.607506 sec\n",
      "loss time 0.001239 sec\n",
      "backward time 0.012852 sec\n",
      "optimizer time 0.030779 sec\n",
      "training time in round 235 cost 0.4013800621032715 sec\n",
      "loss 2.320284, train acc 0.100238\n",
      "round 236\n",
      "time to device 0.008605 sec\n",
      "time forward 2.622944 sec\n",
      "loss time 0.001037 sec\n",
      "backward time 0.011497 sec\n",
      "optimizer time 0.024678 sec\n",
      "training time in round 236 cost 0.4146561622619629 sec\n",
      "loss 2.320220, train acc 0.100112\n",
      "round 237\n",
      "time to device 0.007062 sec\n",
      "time forward 2.633976 sec\n",
      "loss time 0.000964 sec\n",
      "backward time 0.011802 sec\n",
      "optimizer time 0.026846 sec\n",
      "training time in round 237 cost 0.41217613220214844 sec\n",
      "loss 2.320155, train acc 0.100184\n",
      "round 238\n",
      "time to device 0.005808 sec\n",
      "time forward 2.646007 sec\n",
      "loss time 0.000925 sec\n",
      "backward time 0.011708 sec\n",
      "optimizer time 0.026993 sec\n",
      "training time in round 238 cost 0.39228200912475586 sec\n",
      "loss 2.320084, train acc 0.100320\n",
      "round 239\n",
      "time to device 0.003508 sec\n",
      "time forward 2.656550 sec\n",
      "loss time 0.001107 sec\n",
      "backward time 0.009114 sec\n",
      "optimizer time 0.028983 sec\n",
      "training time in round 239 cost 0.3898608684539795 sec\n",
      "loss 2.320006, train acc 0.100326\n",
      "round 240\n",
      "time to device 0.005077 sec\n",
      "time forward 2.666866 sec\n",
      "loss time 0.001057 sec\n",
      "backward time 0.011664 sec\n",
      "optimizer time 0.025705 sec\n",
      "training time in round 240 cost 0.3874189853668213 sec\n",
      "loss 2.319930, train acc 0.100331\n",
      "round 241\n",
      "time to device 0.003440 sec\n",
      "time forward 2.678063 sec\n",
      "loss time 0.001945 sec\n",
      "backward time 0.013067 sec\n",
      "optimizer time 0.027534 sec\n",
      "training time in round 241 cost 0.39928412437438965 sec\n",
      "loss 2.319912, train acc 0.100045\n",
      "round 242\n",
      "time to device 0.005503 sec\n",
      "time forward 2.688056 sec\n",
      "loss time 0.001013 sec\n",
      "backward time 0.014192 sec\n",
      "optimizer time 0.029376 sec\n",
      "training time in round 242 cost 0.3932838439941406 sec\n",
      "loss 2.319825, train acc 0.100116\n",
      "round 243\n",
      "time to device 0.005487 sec\n",
      "time forward 2.701823 sec\n",
      "loss time 0.001283 sec\n",
      "backward time 0.015741 sec\n",
      "optimizer time 0.026347 sec\n",
      "training time in round 243 cost 0.41303491592407227 sec\n",
      "loss 2.319742, train acc 0.100154\n",
      "round 244\n",
      "time to device 0.003884 sec\n",
      "time forward 2.710674 sec\n",
      "loss time 0.000854 sec\n",
      "backward time 0.007516 sec\n",
      "optimizer time 0.018061 sec\n",
      "training time in round 244 cost 0.3699338436126709 sec\n",
      "loss 2.319710, train acc 0.100128\n",
      "round 245\n",
      "time to device 0.003436 sec\n",
      "time forward 2.722601 sec\n",
      "loss time 0.001160 sec\n",
      "backward time 0.010939 sec\n",
      "optimizer time 0.029516 sec\n",
      "training time in round 245 cost 0.40211033821105957 sec\n",
      "loss 2.319645, train acc 0.100165\n",
      "round 246\n",
      "time to device 0.003623 sec\n",
      "time forward 2.734450 sec\n",
      "loss time 0.001111 sec\n",
      "backward time 0.012471 sec\n",
      "optimizer time 0.027966 sec\n",
      "training time in round 246 cost 0.3929741382598877 sec\n",
      "loss 2.319942, train acc 0.100108\n",
      "round 247\n",
      "time to device 0.003458 sec\n",
      "time forward 2.746083 sec\n",
      "loss time 0.001012 sec\n",
      "backward time 0.010673 sec\n",
      "optimizer time 0.029321 sec\n",
      "training time in round 247 cost 0.3944830894470215 sec\n",
      "loss 2.319858, train acc 0.099987\n",
      "round 248\n",
      "time to device 0.006097 sec\n",
      "time forward 2.758930 sec\n",
      "loss time 0.001474 sec\n",
      "backward time 0.013973 sec\n",
      "optimizer time 0.024542 sec\n",
      "training time in round 248 cost 0.40070581436157227 sec\n",
      "loss 2.319784, train acc 0.100182\n",
      "round 249\n",
      "time to device 0.003539 sec\n",
      "time forward 2.770918 sec\n",
      "loss time 0.001557 sec\n",
      "backward time 0.014204 sec\n",
      "optimizer time 0.025445 sec\n",
      "training time in round 249 cost 0.4420328140258789 sec\n",
      "loss 2.319713, train acc 0.100375\n",
      "round 250\n",
      "time to device 0.003468 sec\n",
      "time forward 2.784523 sec\n",
      "loss time 0.001207 sec\n",
      "backward time 0.010356 sec\n",
      "optimizer time 0.029224 sec\n",
      "training time in round 250 cost 0.40415382385253906 sec\n",
      "loss 2.319615, train acc 0.100317\n",
      "round 251\n",
      "time to device 0.006379 sec\n",
      "time forward 2.796362 sec\n",
      "loss time 0.000841 sec\n",
      "backward time 0.007029 sec\n",
      "optimizer time 0.017065 sec\n",
      "training time in round 251 cost 0.3874480724334717 sec\n",
      "loss 2.319541, train acc 0.100260\n",
      "round 252\n",
      "time to device 0.007314 sec\n",
      "time forward 2.808025 sec\n",
      "loss time 0.001737 sec\n",
      "backward time 0.010254 sec\n",
      "optimizer time 0.029131 sec\n",
      "training time in round 252 cost 0.40026211738586426 sec\n",
      "loss 2.319478, train acc 0.100358\n",
      "round 253\n",
      "time to device 0.006980 sec\n",
      "time forward 2.816579 sec\n",
      "loss time 0.000769 sec\n",
      "backward time 0.006281 sec\n",
      "optimizer time 0.017950 sec\n",
      "training time in round 253 cost 0.3782327175140381 sec\n",
      "loss 2.319441, train acc 0.100394\n",
      "round 254\n",
      "time to device 0.006276 sec\n",
      "time forward 2.825066 sec\n",
      "loss time 0.000841 sec\n",
      "backward time 0.007555 sec\n",
      "optimizer time 0.016731 sec\n",
      "training time in round 254 cost 0.36977386474609375 sec\n",
      "loss 2.319356, train acc 0.100337\n",
      "round 255\n",
      "time to device 0.004707 sec\n",
      "time forward 2.835880 sec\n",
      "loss time 0.001028 sec\n",
      "backward time 0.012304 sec\n",
      "optimizer time 0.029123 sec\n",
      "training time in round 255 cost 0.39810705184936523 sec\n",
      "loss 2.319320, train acc 0.100189\n",
      "round 256\n",
      "time to device 0.003064 sec\n",
      "time forward 2.847312 sec\n",
      "loss time 0.001066 sec\n",
      "backward time 0.014152 sec\n",
      "optimizer time 0.025637 sec\n",
      "training time in round 256 cost 0.3928251266479492 sec\n",
      "loss 2.319285, train acc 0.100255\n",
      "round 257\n",
      "time to device 0.003181 sec\n",
      "time forward 2.857899 sec\n",
      "loss time 0.001348 sec\n",
      "backward time 0.013113 sec\n",
      "optimizer time 0.026056 sec\n",
      "training time in round 257 cost 0.39046502113342285 sec\n",
      "loss 2.319266, train acc 0.100139\n",
      "round 258\n",
      "time to device 0.003205 sec\n",
      "time forward 2.869434 sec\n",
      "loss time 0.001082 sec\n",
      "backward time 0.012659 sec\n",
      "optimizer time 0.025541 sec\n",
      "training time in round 258 cost 0.38531041145324707 sec\n",
      "loss 2.319312, train acc 0.100235\n",
      "round 259\n",
      "time to device 0.003761 sec\n",
      "time forward 2.880909 sec\n",
      "loss time 0.001171 sec\n",
      "backward time 0.014197 sec\n",
      "optimizer time 0.028165 sec\n",
      "training time in round 259 cost 0.39458203315734863 sec\n",
      "loss 2.319264, train acc 0.100240\n",
      "round 260\n",
      "time to device 0.003071 sec\n",
      "time forward 2.892075 sec\n",
      "loss time 0.001176 sec\n",
      "backward time 0.013618 sec\n",
      "optimizer time 0.029537 sec\n",
      "training time in round 260 cost 0.3948960304260254 sec\n",
      "loss 2.319215, train acc 0.100305\n",
      "round 261\n",
      "time to device 0.004722 sec\n",
      "time forward 2.900681 sec\n",
      "loss time 0.000719 sec\n",
      "backward time 0.006680 sec\n",
      "optimizer time 0.016459 sec\n",
      "training time in round 261 cost 0.3679192066192627 sec\n",
      "loss 2.319163, train acc 0.100250\n",
      "round 262\n",
      "time to device 0.003352 sec\n",
      "time forward 2.911074 sec\n",
      "loss time 0.001084 sec\n",
      "backward time 0.010471 sec\n",
      "optimizer time 0.029877 sec\n",
      "training time in round 262 cost 0.3886110782623291 sec\n",
      "loss 2.319848, train acc 0.100285\n",
      "round 263\n",
      "time to device 0.003608 sec\n",
      "time forward 2.922668 sec\n",
      "loss time 0.001180 sec\n",
      "backward time 0.011378 sec\n",
      "optimizer time 0.027894 sec\n",
      "training time in round 263 cost 0.3963789939880371 sec\n",
      "loss 2.319758, train acc 0.100379\n",
      "round 264\n",
      "time to device 0.003946 sec\n",
      "time forward 2.931104 sec\n",
      "loss time 0.000893 sec\n",
      "backward time 0.007339 sec\n",
      "optimizer time 0.018033 sec\n",
      "training time in round 264 cost 0.40237879753112793 sec\n",
      "loss 2.319689, train acc 0.100295\n",
      "round 265\n",
      "time to device 0.005038 sec\n",
      "time forward 2.942339 sec\n",
      "loss time 0.000965 sec\n",
      "backward time 0.012465 sec\n",
      "optimizer time 0.040426 sec\n",
      "training time in round 265 cost 0.40596485137939453 sec\n",
      "loss 2.319700, train acc 0.100300\n",
      "round 266\n",
      "time to device 0.006204 sec\n",
      "time forward 2.955839 sec\n",
      "loss time 0.001043 sec\n",
      "backward time 0.011493 sec\n",
      "optimizer time 0.012065 sec\n",
      "training time in round 266 cost 0.39104294776916504 sec\n",
      "loss 2.319641, train acc 0.100275\n",
      "round 267\n",
      "time to device 0.006860 sec\n",
      "time forward 2.966571 sec\n",
      "loss time 0.001302 sec\n",
      "backward time 0.009910 sec\n",
      "optimizer time 0.027174 sec\n",
      "training time in round 267 cost 0.39052820205688477 sec\n",
      "loss 2.319592, train acc 0.100396\n",
      "round 268\n",
      "time to device 0.006241 sec\n",
      "time forward 2.976891 sec\n",
      "loss time 0.001336 sec\n",
      "backward time 0.011813 sec\n",
      "optimizer time 0.028954 sec\n",
      "training time in round 268 cost 0.3969228267669678 sec\n",
      "loss 2.319541, train acc 0.100343\n",
      "round 269\n",
      "time to device 0.007585 sec\n",
      "time forward 2.988111 sec\n",
      "loss time 0.001036 sec\n",
      "backward time 0.009921 sec\n",
      "optimizer time 0.029944 sec\n",
      "training time in round 269 cost 0.3935837745666504 sec\n",
      "loss 2.319498, train acc 0.100376\n",
      "round 270\n",
      "time to device 0.007012 sec\n",
      "time forward 2.999882 sec\n",
      "loss time 0.001184 sec\n",
      "backward time 0.010680 sec\n",
      "optimizer time 0.028248 sec\n",
      "training time in round 270 cost 0.39312100410461426 sec\n",
      "loss 2.319413, train acc 0.100409\n",
      "round 271\n",
      "time to device 0.006234 sec\n",
      "time forward 3.006778 sec\n",
      "loss time 0.000560 sec\n",
      "backward time 0.004368 sec\n",
      "optimizer time 0.012606 sec\n",
      "training time in round 271 cost 0.38044214248657227 sec\n",
      "loss 2.319684, train acc 0.100442\n",
      "round 272\n",
      "time to device 0.002728 sec\n",
      "time forward 3.015841 sec\n",
      "loss time 0.001063 sec\n",
      "backward time 0.016732 sec\n",
      "optimizer time 0.024327 sec\n",
      "training time in round 272 cost 0.4003419876098633 sec\n",
      "loss 2.319618, train acc 0.100361\n",
      "round 273\n",
      "time to device 0.003648 sec\n",
      "time forward 3.026003 sec\n",
      "loss time 0.000975 sec\n",
      "backward time 0.010404 sec\n",
      "optimizer time 0.028392 sec\n",
      "training time in round 273 cost 0.4542808532714844 sec\n",
      "loss 2.319764, train acc 0.100251\n",
      "round 274\n",
      "time to device 0.006389 sec\n",
      "time forward 3.038145 sec\n",
      "loss time 0.001225 sec\n",
      "backward time 0.012110 sec\n",
      "optimizer time 0.022778 sec\n",
      "training time in round 274 cost 0.4075620174407959 sec\n",
      "loss 2.319691, train acc 0.100142\n",
      "round 275\n",
      "time to device 0.005872 sec\n",
      "time forward 3.049946 sec\n",
      "loss time 0.001184 sec\n",
      "backward time 0.018593 sec\n",
      "optimizer time 0.018744 sec\n",
      "training time in round 275 cost 0.405484676361084 sec\n",
      "loss 2.319622, train acc 0.100062\n",
      "round 276\n",
      "time to device 0.006087 sec\n",
      "time forward 3.060708 sec\n",
      "loss time 0.001142 sec\n",
      "backward time 0.013474 sec\n",
      "optimizer time 0.025602 sec\n",
      "training time in round 276 cost 0.41303110122680664 sec\n",
      "loss 2.319610, train acc 0.099898\n",
      "round 277\n",
      "time to device 0.007340 sec\n",
      "time forward 3.072224 sec\n",
      "loss time 0.001038 sec\n",
      "backward time 0.013562 sec\n",
      "optimizer time 0.027671 sec\n",
      "training time in round 277 cost 0.4039938449859619 sec\n",
      "loss 2.319553, train acc 0.099736\n",
      "round 278\n",
      "time to device 0.006541 sec\n",
      "time forward 3.084031 sec\n",
      "loss time 0.000955 sec\n",
      "backward time 0.014627 sec\n",
      "optimizer time 0.025133 sec\n",
      "training time in round 278 cost 0.40506911277770996 sec\n",
      "loss 2.319502, train acc 0.099826\n",
      "round 279\n",
      "time to device 0.007283 sec\n",
      "time forward 3.096591 sec\n",
      "loss time 0.001075 sec\n",
      "backward time 0.012837 sec\n",
      "optimizer time 0.029549 sec\n",
      "training time in round 279 cost 0.41646885871887207 sec\n",
      "loss 2.319468, train acc 0.099805\n",
      "round 280\n",
      "time to device 0.007428 sec\n",
      "time forward 3.108825 sec\n",
      "loss time 0.001004 sec\n",
      "backward time 0.013849 sec\n",
      "optimizer time 0.024755 sec\n",
      "training time in round 280 cost 0.400083065032959 sec\n",
      "loss 2.319414, train acc 0.099783\n",
      "round 281\n",
      "time to device 0.006274 sec\n",
      "time forward 3.119013 sec\n",
      "loss time 0.001036 sec\n",
      "backward time 0.011932 sec\n",
      "optimizer time 0.038749 sec\n",
      "training time in round 281 cost 0.42330002784729004 sec\n",
      "loss 2.319536, train acc 0.099845\n",
      "round 282\n",
      "time to device 0.007100 sec\n",
      "time forward 3.131215 sec\n",
      "loss time 0.000976 sec\n",
      "backward time 0.012091 sec\n",
      "optimizer time 0.028694 sec\n",
      "training time in round 282 cost 0.4032418727874756 sec\n",
      "loss 2.319454, train acc 0.099851\n",
      "round 283\n",
      "time to device 0.006071 sec\n",
      "time forward 3.144027 sec\n",
      "loss time 0.001127 sec\n",
      "backward time 0.015713 sec\n",
      "optimizer time 0.028142 sec\n",
      "training time in round 283 cost 0.40813612937927246 sec\n",
      "loss 2.319445, train acc 0.099719\n",
      "round 284\n",
      "time to device 0.007133 sec\n",
      "time forward 3.155677 sec\n",
      "loss time 0.001246 sec\n",
      "backward time 0.011629 sec\n",
      "optimizer time 0.026659 sec\n",
      "training time in round 284 cost 0.39850401878356934 sec\n",
      "loss 2.319435, train acc 0.099698\n",
      "round 285\n",
      "time to device 0.006327 sec\n",
      "time forward 3.167250 sec\n",
      "loss time 0.001812 sec\n",
      "backward time 0.010222 sec\n",
      "optimizer time 0.033511 sec\n",
      "training time in round 285 cost 0.40247011184692383 sec\n",
      "loss 2.319481, train acc 0.099623\n",
      "round 286\n",
      "time to device 0.006158 sec\n",
      "time forward 3.181555 sec\n",
      "loss time 0.001089 sec\n",
      "backward time 0.011343 sec\n",
      "optimizer time 0.026981 sec\n",
      "training time in round 286 cost 0.4116799831390381 sec\n",
      "loss 2.319439, train acc 0.099521\n",
      "round 287\n",
      "time to device 0.007943 sec\n",
      "time forward 3.193707 sec\n",
      "loss time 0.001273 sec\n",
      "backward time 0.009231 sec\n",
      "optimizer time 0.036908 sec\n",
      "training time in round 287 cost 0.407088041305542 sec\n",
      "loss 2.319392, train acc 0.099392\n",
      "round 288\n",
      "time to device 0.006961 sec\n",
      "time forward 3.209207 sec\n",
      "loss time 0.001213 sec\n",
      "backward time 0.014316 sec\n",
      "optimizer time 0.028406 sec\n",
      "training time in round 288 cost 0.41964006423950195 sec\n",
      "loss 2.319340, train acc 0.099265\n",
      "round 289\n",
      "time to device 0.006679 sec\n",
      "time forward 3.220307 sec\n",
      "loss time 0.001024 sec\n",
      "backward time 0.010783 sec\n",
      "optimizer time 0.028017 sec\n",
      "training time in round 289 cost 0.39116406440734863 sec\n",
      "loss 2.319331, train acc 0.099219\n",
      "round 290\n",
      "time to device 0.006440 sec\n",
      "time forward 3.227206 sec\n",
      "loss time 0.000503 sec\n",
      "backward time 0.004629 sec\n",
      "optimizer time 0.014789 sec\n",
      "training time in round 290 cost 0.36327409744262695 sec\n",
      "loss 2.319280, train acc 0.099066\n",
      "round 291\n",
      "time to device 0.007151 sec\n",
      "time forward 3.238170 sec\n",
      "loss time 0.000971 sec\n",
      "backward time 0.011888 sec\n",
      "optimizer time 0.029815 sec\n",
      "training time in round 291 cost 0.39621400833129883 sec\n",
      "loss 2.319284, train acc 0.099074\n",
      "round 292\n",
      "time to device 0.003837 sec\n",
      "time forward 3.248693 sec\n",
      "loss time 0.001298 sec\n",
      "backward time 0.009957 sec\n",
      "optimizer time 0.028056 sec\n",
      "training time in round 292 cost 0.38765430450439453 sec\n",
      "loss 2.319304, train acc 0.099083\n",
      "round 293\n",
      "time to device 0.003297 sec\n",
      "time forward 3.260192 sec\n",
      "loss time 0.001089 sec\n",
      "backward time 0.011164 sec\n",
      "optimizer time 0.027476 sec\n",
      "training time in round 293 cost 0.38791918754577637 sec\n",
      "loss 2.319309, train acc 0.099091\n",
      "round 294\n",
      "time to device 0.003581 sec\n",
      "time forward 3.271106 sec\n",
      "loss time 0.001094 sec\n",
      "backward time 0.012638 sec\n",
      "optimizer time 0.029032 sec\n",
      "training time in round 294 cost 0.39266085624694824 sec\n",
      "loss 2.319334, train acc 0.099020\n",
      "round 295\n",
      "time to device 0.003451 sec\n",
      "time forward 3.282960 sec\n",
      "loss time 0.001055 sec\n",
      "backward time 0.011160 sec\n",
      "optimizer time 0.028615 sec\n",
      "training time in round 295 cost 0.3892989158630371 sec\n",
      "loss 2.319283, train acc 0.098976\n",
      "round 296\n",
      "time to device 0.004280 sec\n",
      "time forward 3.293793 sec\n",
      "loss time 0.001362 sec\n",
      "backward time 0.012816 sec\n",
      "optimizer time 0.027179 sec\n",
      "training time in round 296 cost 0.39021897315979004 sec\n",
      "loss 2.319227, train acc 0.098958\n",
      "round 297\n",
      "time to device 0.005955 sec\n",
      "time forward 3.301465 sec\n",
      "loss time 0.000773 sec\n",
      "backward time 0.006706 sec\n",
      "optimizer time 0.017264 sec\n",
      "training time in round 297 cost 0.36714696884155273 sec\n",
      "loss 2.319261, train acc 0.098836\n",
      "round 298\n",
      "time to device 0.003751 sec\n",
      "time forward 3.328643 sec\n",
      "loss time 0.001367 sec\n",
      "backward time 0.012778 sec\n",
      "optimizer time 0.026018 sec\n",
      "training time in round 298 cost 0.4109671115875244 sec\n",
      "loss 2.319197, train acc 0.098976\n",
      "round 299\n",
      "time to device 0.003262 sec\n",
      "time forward 3.340112 sec\n",
      "loss time 0.001334 sec\n",
      "backward time 0.013516 sec\n",
      "optimizer time 0.014039 sec\n",
      "training time in round 299 cost 0.3800790309906006 sec\n",
      "loss 2.319184, train acc 0.098984\n",
      "round 300\n",
      "time to device 0.004032 sec\n",
      "time forward 3.349430 sec\n",
      "loss time 0.001088 sec\n",
      "backward time 0.008643 sec\n",
      "optimizer time 0.018889 sec\n",
      "training time in round 300 cost 0.37987804412841797 sec\n",
      "loss 2.319181, train acc 0.099097\n",
      "round 301\n",
      "time to device 0.003543 sec\n",
      "time forward 3.358472 sec\n",
      "loss time 0.000382 sec\n",
      "backward time 0.003572 sec\n",
      "optimizer time 0.010028 sec\n",
      "training time in round 301 cost 0.37508702278137207 sec\n",
      "loss 2.319124, train acc 0.099131\n",
      "round 302\n",
      "time to device 0.004020 sec\n",
      "time forward 3.369516 sec\n",
      "loss time 0.001034 sec\n",
      "backward time 0.009893 sec\n",
      "optimizer time 0.027666 sec\n",
      "training time in round 302 cost 0.3932459354400635 sec\n",
      "loss 2.319251, train acc 0.099087\n",
      "round 303\n",
      "time to device 0.004077 sec\n",
      "time forward 3.380447 sec\n",
      "loss time 0.000943 sec\n",
      "backward time 0.012362 sec\n",
      "optimizer time 0.028116 sec\n",
      "training time in round 303 cost 0.39096593856811523 sec\n",
      "loss 2.319187, train acc 0.099095\n",
      "round 304\n",
      "time to device 0.003594 sec\n",
      "time forward 3.390826 sec\n",
      "loss time 0.001011 sec\n",
      "backward time 0.012341 sec\n",
      "optimizer time 0.026882 sec\n",
      "training time in round 304 cost 0.38759779930114746 sec\n",
      "loss 2.319154, train acc 0.099155\n",
      "round 305\n",
      "time to device 0.003721 sec\n",
      "time forward 3.403478 sec\n",
      "loss time 0.001123 sec\n",
      "backward time 0.011953 sec\n",
      "optimizer time 0.026305 sec\n",
      "training time in round 305 cost 0.3928718566894531 sec\n",
      "loss 2.319139, train acc 0.099035\n",
      "round 306\n",
      "time to device 0.003585 sec\n",
      "time forward 3.408856 sec\n",
      "loss time 0.000551 sec\n",
      "backward time 0.004884 sec\n",
      "optimizer time 0.013277 sec\n",
      "training time in round 306 cost 0.3406028747558594 sec\n",
      "loss 2.319146, train acc 0.099170\n",
      "round 307\n",
      "time to device 0.003595 sec\n",
      "time forward 3.419977 sec\n",
      "loss time 0.000978 sec\n",
      "backward time 0.011274 sec\n",
      "optimizer time 0.024073 sec\n",
      "training time in round 307 cost 0.3960840702056885 sec\n",
      "loss 2.319098, train acc 0.099102\n",
      "round 308\n",
      "time to device 0.003503 sec\n",
      "time forward 3.432861 sec\n",
      "loss time 0.001204 sec\n",
      "backward time 0.013638 sec\n",
      "optimizer time 0.028153 sec\n",
      "training time in round 308 cost 0.4408540725708008 sec\n",
      "loss 2.319047, train acc 0.099034\n",
      "round 309\n",
      "time to device 0.003391 sec\n",
      "time forward 3.443449 sec\n",
      "loss time 0.001211 sec\n",
      "backward time 0.011094 sec\n",
      "optimizer time 0.030002 sec\n",
      "training time in round 309 cost 0.4030768871307373 sec\n",
      "loss 2.319031, train acc 0.098942\n",
      "round 310\n",
      "time to device 0.006577 sec\n",
      "time forward 3.458916 sec\n",
      "loss time 0.001027 sec\n",
      "backward time 0.012831 sec\n",
      "optimizer time 0.029418 sec\n",
      "training time in round 310 cost 0.4138610363006592 sec\n",
      "loss 2.318987, train acc 0.098900\n",
      "round 311\n",
      "time to device 0.007262 sec\n",
      "time forward 3.470791 sec\n",
      "loss time 0.001030 sec\n",
      "backward time 0.011639 sec\n",
      "optimizer time 0.026410 sec\n",
      "training time in round 311 cost 0.404094934463501 sec\n",
      "loss 2.318934, train acc 0.098758\n",
      "round 312\n",
      "time to device 0.009586 sec\n",
      "time forward 3.483211 sec\n",
      "loss time 0.001143 sec\n",
      "backward time 0.011051 sec\n",
      "optimizer time 0.027104 sec\n",
      "training time in round 312 cost 0.40427184104919434 sec\n",
      "loss 2.318951, train acc 0.098792\n",
      "round 313\n",
      "time to device 0.006633 sec\n",
      "time forward 3.495082 sec\n",
      "loss time 0.001058 sec\n",
      "backward time 0.011715 sec\n",
      "optimizer time 0.026117 sec\n",
      "training time in round 313 cost 0.3941681385040283 sec\n",
      "loss 2.318896, train acc 0.098726\n",
      "round 314\n",
      "time to device 0.003379 sec\n",
      "time forward 3.506080 sec\n",
      "loss time 0.001065 sec\n",
      "backward time 0.009969 sec\n",
      "optimizer time 0.028656 sec\n",
      "training time in round 314 cost 0.38892102241516113 sec\n",
      "loss 2.318849, train acc 0.098611\n",
      "round 315\n",
      "time to device 0.003919 sec\n",
      "time forward 3.517653 sec\n",
      "loss time 0.000986 sec\n",
      "backward time 0.014828 sec\n",
      "optimizer time 0.029169 sec\n",
      "training time in round 315 cost 0.3988039493560791 sec\n",
      "loss 2.318797, train acc 0.098596\n",
      "round 316\n",
      "time to device 0.003796 sec\n",
      "time forward 3.529726 sec\n",
      "loss time 0.001112 sec\n",
      "backward time 0.018172 sec\n",
      "optimizer time 0.022424 sec\n",
      "training time in round 316 cost 0.40059494972229004 sec\n",
      "loss 2.318790, train acc 0.098679\n",
      "round 317\n",
      "time to device 0.004764 sec\n",
      "time forward 3.543043 sec\n",
      "loss time 0.001046 sec\n",
      "backward time 0.018144 sec\n",
      "optimizer time 0.026894 sec\n",
      "training time in round 317 cost 0.47820186614990234 sec\n",
      "loss 2.318736, train acc 0.098762\n",
      "round 318\n",
      "time to device 0.008012 sec\n",
      "time forward 3.553871 sec\n",
      "loss time 0.000948 sec\n",
      "backward time 0.010943 sec\n",
      "optimizer time 0.032386 sec\n",
      "training time in round 318 cost 0.3946099281311035 sec\n",
      "loss 2.318716, train acc 0.098673\n",
      "round 319\n",
      "time to device 0.008503 sec\n",
      "time forward 3.570689 sec\n",
      "loss time 0.001000 sec\n",
      "backward time 0.015054 sec\n",
      "optimizer time 0.027542 sec\n",
      "training time in round 319 cost 0.4173901081085205 sec\n",
      "loss 2.318663, train acc 0.098730\n",
      "round 320\n",
      "time to device 0.006686 sec\n",
      "time forward 3.582378 sec\n",
      "loss time 0.001283 sec\n",
      "backward time 0.010468 sec\n",
      "optimizer time 0.027841 sec\n",
      "training time in round 320 cost 0.39005589485168457 sec\n",
      "loss 2.318610, train acc 0.098764\n",
      "round 321\n",
      "time to device 0.009207 sec\n",
      "time forward 3.594688 sec\n",
      "loss time 0.001127 sec\n",
      "backward time 0.014855 sec\n",
      "optimizer time 0.018496 sec\n",
      "training time in round 321 cost 0.39794421195983887 sec\n",
      "loss 2.318601, train acc 0.098845\n",
      "round 322\n",
      "time to device 0.006347 sec\n",
      "time forward 3.606869 sec\n",
      "loss time 0.001032 sec\n",
      "backward time 0.012702 sec\n",
      "optimizer time 0.029696 sec\n",
      "training time in round 322 cost 0.39958906173706055 sec\n",
      "loss 2.318540, train acc 0.098974\n",
      "round 323\n",
      "time to device 0.006226 sec\n",
      "time forward 3.619276 sec\n",
      "loss time 0.001625 sec\n",
      "backward time 0.014035 sec\n",
      "optimizer time 0.015489 sec\n",
      "training time in round 323 cost 0.39177393913269043 sec\n",
      "loss 2.318477, train acc 0.099007\n",
      "round 324\n",
      "time to device 0.006898 sec\n",
      "time forward 3.632325 sec\n",
      "loss time 0.000980 sec\n",
      "backward time 0.011726 sec\n",
      "optimizer time 0.030498 sec\n",
      "training time in round 324 cost 0.42865610122680664 sec\n",
      "loss 2.318425, train acc 0.099062\n",
      "round 325\n",
      "time to device 0.006865 sec\n",
      "time forward 3.645059 sec\n",
      "loss time 0.001065 sec\n",
      "backward time 0.017618 sec\n",
      "optimizer time 0.029621 sec\n",
      "training time in round 325 cost 0.40908217430114746 sec\n",
      "loss 2.318399, train acc 0.099118\n",
      "round 326\n",
      "time to device 0.003612 sec\n",
      "time forward 3.652950 sec\n",
      "loss time 0.001071 sec\n",
      "backward time 0.006815 sec\n",
      "optimizer time 0.017597 sec\n",
      "training time in round 326 cost 0.3772706985473633 sec\n",
      "loss 2.318336, train acc 0.099149\n",
      "round 327\n",
      "time to device 0.004700 sec\n",
      "time forward 3.664818 sec\n",
      "loss time 0.001457 sec\n",
      "backward time 0.009435 sec\n",
      "optimizer time 0.030016 sec\n",
      "training time in round 327 cost 0.39598798751831055 sec\n",
      "loss 2.318309, train acc 0.099181\n",
      "round 328\n",
      "time to device 0.005467 sec\n",
      "time forward 3.676318 sec\n",
      "loss time 0.001339 sec\n",
      "backward time 0.011343 sec\n",
      "optimizer time 0.026420 sec\n",
      "training time in round 328 cost 0.3900589942932129 sec\n",
      "loss 2.318265, train acc 0.099235\n",
      "round 329\n",
      "time to device 0.003335 sec\n",
      "time forward 3.688598 sec\n",
      "loss time 0.001033 sec\n",
      "backward time 0.012177 sec\n",
      "optimizer time 0.026422 sec\n",
      "training time in round 329 cost 0.38950490951538086 sec\n",
      "loss 2.318249, train acc 0.099171\n",
      "round 330\n",
      "time to device 0.003753 sec\n",
      "time forward 3.699747 sec\n",
      "loss time 0.000949 sec\n",
      "backward time 0.014232 sec\n",
      "optimizer time 0.029774 sec\n",
      "training time in round 330 cost 0.39696717262268066 sec\n",
      "loss 2.318289, train acc 0.099297\n",
      "round 331\n",
      "time to device 0.003204 sec\n",
      "time forward 3.710746 sec\n",
      "loss time 0.001029 sec\n",
      "backward time 0.013725 sec\n",
      "optimizer time 0.028682 sec\n",
      "training time in round 331 cost 0.3959920406341553 sec\n",
      "loss 2.318284, train acc 0.099115\n",
      "round 332\n",
      "time to device 0.004055 sec\n",
      "time forward 3.722245 sec\n",
      "loss time 0.002437 sec\n",
      "backward time 0.010958 sec\n",
      "optimizer time 0.028090 sec\n",
      "training time in round 332 cost 0.39653515815734863 sec\n",
      "loss 2.318240, train acc 0.099052\n",
      "round 333\n",
      "time to device 0.004105 sec\n",
      "time forward 3.733365 sec\n",
      "loss time 0.001154 sec\n",
      "backward time 0.009692 sec\n",
      "optimizer time 0.016673 sec\n",
      "training time in round 333 cost 0.38201212882995605 sec\n",
      "loss 2.318195, train acc 0.098990\n",
      "round 334\n",
      "time to device 0.003807 sec\n",
      "time forward 3.746666 sec\n",
      "loss time 0.000939 sec\n",
      "backward time 0.013178 sec\n",
      "optimizer time 0.027107 sec\n",
      "training time in round 334 cost 0.402695894241333 sec\n",
      "loss 2.318186, train acc 0.098881\n",
      "round 335\n",
      "time to device 0.004470 sec\n",
      "time forward 3.755476 sec\n",
      "loss time 0.001071 sec\n",
      "backward time 0.008480 sec\n",
      "optimizer time 0.019307 sec\n",
      "training time in round 335 cost 0.4311497211456299 sec\n",
      "loss 2.318133, train acc 0.098912\n",
      "round 336\n",
      "time to device 0.007360 sec\n",
      "time forward 3.767204 sec\n",
      "loss time 0.001053 sec\n",
      "backward time 0.009910 sec\n",
      "optimizer time 0.033347 sec\n",
      "training time in round 336 cost 0.40009188652038574 sec\n",
      "loss 2.318067, train acc 0.098920\n",
      "round 337\n",
      "time to device 0.006245 sec\n",
      "time forward 3.783473 sec\n",
      "loss time 0.001008 sec\n",
      "backward time 0.012627 sec\n",
      "optimizer time 0.028164 sec\n",
      "training time in round 337 cost 0.4165048599243164 sec\n",
      "loss 2.318025, train acc 0.098974\n",
      "round 338\n",
      "time to device 0.007077 sec\n",
      "time forward 3.795079 sec\n",
      "loss time 0.000952 sec\n",
      "backward time 0.014215 sec\n",
      "optimizer time 0.025535 sec\n",
      "training time in round 338 cost 0.3928859233856201 sec\n",
      "loss 2.318054, train acc 0.098981\n",
      "round 339\n",
      "time to device 0.006359 sec\n",
      "time forward 3.806057 sec\n",
      "loss time 0.001078 sec\n",
      "backward time 0.012671 sec\n",
      "optimizer time 0.027465 sec\n",
      "training time in round 339 cost 0.40487122535705566 sec\n",
      "loss 2.317991, train acc 0.098966\n",
      "round 340\n",
      "time to device 0.006928 sec\n",
      "time forward 3.815564 sec\n",
      "loss time 0.000898 sec\n",
      "backward time 0.007777 sec\n",
      "optimizer time 0.017957 sec\n",
      "training time in round 340 cost 0.3727700710296631 sec\n",
      "loss 2.317964, train acc 0.099042\n",
      "round 341\n",
      "time to device 0.003247 sec\n",
      "time forward 3.826416 sec\n",
      "loss time 0.001202 sec\n",
      "backward time 0.011108 sec\n",
      "optimizer time 0.027888 sec\n",
      "training time in round 341 cost 0.3865170478820801 sec\n",
      "loss 2.317954, train acc 0.099073\n",
      "round 342\n",
      "time to device 0.003355 sec\n",
      "time forward 3.836779 sec\n",
      "loss time 0.001043 sec\n",
      "backward time 0.011958 sec\n",
      "optimizer time 0.025594 sec\n",
      "training time in round 342 cost 0.3839879035949707 sec\n",
      "loss 2.318273, train acc 0.098920\n",
      "round 343\n",
      "time to device 0.003104 sec\n",
      "time forward 3.848233 sec\n",
      "loss time 0.000950 sec\n",
      "backward time 0.010987 sec\n",
      "optimizer time 0.026542 sec\n",
      "training time in round 343 cost 0.3871591091156006 sec\n",
      "loss 2.318255, train acc 0.098860\n",
      "round 344\n",
      "time to device 0.003385 sec\n",
      "time forward 3.858171 sec\n",
      "loss time 0.000953 sec\n",
      "backward time 0.011217 sec\n",
      "optimizer time 0.027751 sec\n",
      "training time in round 344 cost 0.38342976570129395 sec\n",
      "loss 2.318323, train acc 0.098890\n",
      "round 345\n",
      "time to device 0.007573 sec\n",
      "time forward 3.866209 sec\n",
      "loss time 0.000748 sec\n",
      "backward time 0.006297 sec\n",
      "optimizer time 0.016163 sec\n",
      "training time in round 345 cost 0.38686108589172363 sec\n",
      "loss 2.318277, train acc 0.098898\n",
      "round 346\n",
      "time to device 0.004126 sec\n",
      "time forward 3.876302 sec\n",
      "loss time 0.001009 sec\n",
      "backward time 0.013656 sec\n",
      "optimizer time 0.027483 sec\n",
      "training time in round 346 cost 0.39122629165649414 sec\n",
      "loss 2.318227, train acc 0.098996\n",
      "round 347\n",
      "time to device 0.003611 sec\n",
      "time forward 3.887515 sec\n",
      "loss time 0.001104 sec\n",
      "backward time 0.011050 sec\n",
      "optimizer time 0.026751 sec\n",
      "training time in round 347 cost 0.386368989944458 sec\n",
      "loss 2.318186, train acc 0.098936\n",
      "round 348\n",
      "time to device 0.003234 sec\n",
      "time forward 3.898311 sec\n",
      "loss time 0.001168 sec\n",
      "backward time 0.012858 sec\n",
      "optimizer time 0.030928 sec\n",
      "training time in round 348 cost 0.40465807914733887 sec\n",
      "loss 2.318130, train acc 0.099011\n",
      "round 349\n",
      "time to device 0.003348 sec\n",
      "time forward 3.907234 sec\n",
      "loss time 0.000774 sec\n",
      "backward time 0.006996 sec\n",
      "optimizer time 0.018811 sec\n",
      "training time in round 349 cost 0.3734130859375 sec\n",
      "loss 2.318087, train acc 0.098906\n",
      "round 350\n",
      "time to device 0.006074 sec\n",
      "time forward 3.920280 sec\n",
      "loss time 0.001489 sec\n",
      "backward time 0.015526 sec\n",
      "optimizer time 0.024987 sec\n",
      "training time in round 350 cost 0.400615930557251 sec\n",
      "loss 2.318119, train acc 0.098958\n",
      "round 351\n",
      "time to device 0.008813 sec\n",
      "time forward 3.933292 sec\n",
      "loss time 0.001546 sec\n",
      "backward time 0.013634 sec\n",
      "optimizer time 0.026923 sec\n",
      "training time in round 351 cost 0.413801908493042 sec\n",
      "loss 2.318093, train acc 0.099121\n",
      "round 352\n",
      "time to device 0.006895 sec\n",
      "time forward 3.953030 sec\n",
      "loss time 0.001317 sec\n",
      "backward time 0.012904 sec\n",
      "optimizer time 0.026903 sec\n",
      "training time in round 352 cost 0.4302678108215332 sec\n",
      "loss 2.318047, train acc 0.099084\n",
      "round 353\n",
      "time to device 0.006973 sec\n",
      "time forward 3.964365 sec\n",
      "loss time 0.001277 sec\n",
      "backward time 0.010804 sec\n",
      "optimizer time 0.026574 sec\n",
      "training time in round 353 cost 0.4054691791534424 sec\n",
      "loss 2.317990, train acc 0.099179\n",
      "round 354\n",
      "time to device 0.007724 sec\n",
      "time forward 3.975349 sec\n",
      "loss time 0.001026 sec\n",
      "backward time 0.010109 sec\n",
      "optimizer time 0.028430 sec\n",
      "training time in round 354 cost 0.3915979862213135 sec\n",
      "loss 2.317982, train acc 0.099054\n",
      "round 355\n",
      "time to device 0.007121 sec\n",
      "time forward 3.986190 sec\n",
      "loss time 0.001008 sec\n",
      "backward time 0.012581 sec\n",
      "optimizer time 0.026691 sec\n",
      "training time in round 355 cost 0.38711094856262207 sec\n",
      "loss 2.317911, train acc 0.099170\n",
      "round 356\n",
      "time to device 0.007022 sec\n",
      "time forward 3.997129 sec\n",
      "loss time 0.001091 sec\n",
      "backward time 0.011686 sec\n",
      "optimizer time 0.021909 sec\n",
      "training time in round 356 cost 0.38892626762390137 sec\n",
      "loss 2.317861, train acc 0.099243\n",
      "round 357\n",
      "time to device 0.004394 sec\n",
      "time forward 4.007431 sec\n",
      "loss time 0.000972 sec\n",
      "backward time 0.012458 sec\n",
      "optimizer time 0.030241 sec\n",
      "training time in round 357 cost 0.4034128189086914 sec\n",
      "loss 2.317845, train acc 0.099293\n",
      "round 358\n",
      "time to device 0.003660 sec\n",
      "time forward 4.017392 sec\n",
      "loss time 0.001079 sec\n",
      "backward time 0.011193 sec\n",
      "optimizer time 0.028372 sec\n",
      "training time in round 358 cost 0.39086008071899414 sec\n",
      "loss 2.317847, train acc 0.099408\n",
      "round 359\n",
      "time to device 0.003769 sec\n",
      "time forward 4.025048 sec\n",
      "loss time 0.000479 sec\n",
      "backward time 0.007406 sec\n",
      "optimizer time 0.016652 sec\n",
      "training time in round 359 cost 0.43738317489624023 sec\n",
      "loss 2.317788, train acc 0.099306\n",
      "round 360\n",
      "time to device 0.006789 sec\n",
      "time forward 4.036239 sec\n",
      "loss time 0.001485 sec\n",
      "backward time 0.011032 sec\n",
      "optimizer time 0.030039 sec\n",
      "training time in round 360 cost 0.4632859230041504 sec\n",
      "loss 2.317741, train acc 0.099290\n",
      "round 361\n",
      "time to device 0.006873 sec\n",
      "time forward 4.047513 sec\n",
      "loss time 0.001477 sec\n",
      "backward time 0.011571 sec\n",
      "optimizer time 0.029143 sec\n",
      "training time in round 361 cost 0.4218928813934326 sec\n",
      "loss 2.317652, train acc 0.099383\n",
      "round 362\n",
      "time to device 0.006297 sec\n",
      "time forward 4.057745 sec\n",
      "loss time 0.001014 sec\n",
      "backward time 0.016651 sec\n",
      "optimizer time 0.026596 sec\n",
      "training time in round 362 cost 0.4015927314758301 sec\n",
      "loss 2.317624, train acc 0.099432\n",
      "round 363\n",
      "time to device 0.006890 sec\n",
      "time forward 4.067725 sec\n",
      "loss time 0.000733 sec\n",
      "backward time 0.006175 sec\n",
      "optimizer time 0.015940 sec\n",
      "training time in round 363 cost 0.40976977348327637 sec\n",
      "loss 2.317572, train acc 0.099395\n",
      "round 364\n",
      "time to device 0.006902 sec\n",
      "time forward 4.079008 sec\n",
      "loss time 0.001020 sec\n",
      "backward time 0.015156 sec\n",
      "optimizer time 0.033413 sec\n",
      "training time in round 364 cost 0.4411749839782715 sec\n",
      "loss 2.317568, train acc 0.099379\n",
      "round 365\n",
      "time to device 0.007409 sec\n",
      "time forward 4.092741 sec\n",
      "loss time 0.001317 sec\n",
      "backward time 0.016615 sec\n",
      "optimizer time 0.029746 sec\n",
      "training time in round 365 cost 0.4078490734100342 sec\n",
      "loss 2.318124, train acc 0.099364\n",
      "round 366\n",
      "time to device 0.008276 sec\n",
      "time forward 4.104849 sec\n",
      "loss time 0.001164 sec\n",
      "backward time 0.013370 sec\n",
      "optimizer time 0.028968 sec\n",
      "training time in round 366 cost 0.4209892749786377 sec\n",
      "loss 2.318132, train acc 0.099519\n",
      "round 367\n",
      "time to device 0.006780 sec\n",
      "time forward 4.115026 sec\n",
      "loss time 0.001121 sec\n",
      "backward time 0.016780 sec\n",
      "optimizer time 0.026450 sec\n",
      "training time in round 367 cost 0.3942830562591553 sec\n",
      "loss 2.318052, train acc 0.099546\n",
      "round 368\n",
      "time to device 0.006476 sec\n",
      "time forward 4.123222 sec\n",
      "loss time 0.000546 sec\n",
      "backward time 0.011354 sec\n",
      "optimizer time 0.014424 sec\n",
      "training time in round 368 cost 0.3707621097564697 sec\n",
      "loss 2.318057, train acc 0.099593\n",
      "round 369\n",
      "time to device 0.006794 sec\n",
      "time forward 4.135046 sec\n",
      "loss time 0.001181 sec\n",
      "backward time 0.012579 sec\n",
      "optimizer time 0.027528 sec\n",
      "training time in round 369 cost 0.39436984062194824 sec\n",
      "loss 2.318159, train acc 0.099451\n",
      "round 370\n",
      "time to device 0.007354 sec\n",
      "time forward 4.148951 sec\n",
      "loss time 0.001445 sec\n",
      "backward time 0.016125 sec\n",
      "optimizer time 0.029986 sec\n",
      "training time in round 370 cost 0.41458606719970703 sec\n",
      "loss 2.318125, train acc 0.099478\n",
      "round 371\n",
      "time to device 0.010877 sec\n",
      "time forward 4.160359 sec\n",
      "loss time 0.001218 sec\n",
      "backward time 0.011514 sec\n",
      "optimizer time 0.034762 sec\n",
      "training time in round 371 cost 0.4290146827697754 sec\n",
      "loss 2.318702, train acc 0.099441\n",
      "round 372\n",
      "time to device 0.006741 sec\n",
      "time forward 4.171617 sec\n",
      "loss time 0.001098 sec\n",
      "backward time 0.010727 sec\n",
      "optimizer time 0.029466 sec\n",
      "training time in round 372 cost 0.4140758514404297 sec\n",
      "loss 2.318743, train acc 0.099510\n",
      "round 373\n",
      "time to device 0.008041 sec\n",
      "time forward 4.182299 sec\n",
      "loss time 0.001078 sec\n",
      "backward time 0.012011 sec\n",
      "optimizer time 0.028768 sec\n",
      "training time in round 373 cost 0.4205949306488037 sec\n",
      "loss 2.318738, train acc 0.099682\n",
      "round 374\n",
      "time to device 0.007349 sec\n",
      "time forward 4.194754 sec\n",
      "loss time 0.003360 sec\n",
      "backward time 0.012774 sec\n",
      "optimizer time 0.026345 sec\n",
      "training time in round 374 cost 0.449099063873291 sec\n",
      "loss 2.318771, train acc 0.099667\n",
      "round 375\n",
      "time to device 0.007092 sec\n",
      "time forward 4.213255 sec\n",
      "loss time 0.001697 sec\n",
      "backward time 0.016391 sec\n",
      "optimizer time 0.026482 sec\n",
      "training time in round 375 cost 0.43588781356811523 sec\n",
      "loss 2.318680, train acc 0.099776\n",
      "round 376\n",
      "time to device 0.007286 sec\n",
      "time forward 4.224600 sec\n",
      "loss time 0.001069 sec\n",
      "backward time 0.012915 sec\n",
      "optimizer time 0.029867 sec\n",
      "training time in round 376 cost 0.42247819900512695 sec\n",
      "loss 2.318879, train acc 0.099843\n",
      "round 377\n",
      "time to device 0.007237 sec\n",
      "time forward 4.231312 sec\n",
      "loss time 0.000689 sec\n",
      "backward time 0.006026 sec\n",
      "optimizer time 0.016718 sec\n",
      "training time in round 377 cost 0.3861730098724365 sec\n",
      "loss 2.318913, train acc 0.099971\n",
      "round 378\n",
      "time to device 0.006986 sec\n",
      "time forward 4.248422 sec\n",
      "loss time 0.001120 sec\n",
      "backward time 0.012702 sec\n",
      "optimizer time 0.026510 sec\n",
      "training time in round 378 cost 0.4202549457550049 sec\n",
      "loss 2.319109, train acc 0.099893\n",
      "round 379\n",
      "time to device 0.007891 sec\n",
      "time forward 4.259583 sec\n",
      "loss time 0.001171 sec\n",
      "backward time 0.012623 sec\n",
      "optimizer time 0.022172 sec\n",
      "training time in round 379 cost 0.398226261138916 sec\n",
      "loss 2.319662, train acc 0.099877\n",
      "round 380\n",
      "time to device 0.006901 sec\n",
      "time forward 4.272008 sec\n",
      "loss time 0.001400 sec\n",
      "backward time 0.019330 sec\n",
      "optimizer time 0.024986 sec\n",
      "training time in round 380 cost 0.43509984016418457 sec\n",
      "loss 2.319883, train acc 0.099943\n",
      "round 381\n",
      "time to device 0.008901 sec\n",
      "time forward 4.286762 sec\n",
      "loss time 0.001920 sec\n",
      "backward time 0.015825 sec\n",
      "optimizer time 0.032819 sec\n",
      "training time in round 381 cost 0.488757848739624 sec\n",
      "loss 2.319933, train acc 0.100029\n",
      "round 382\n",
      "time to device 0.006472 sec\n",
      "time forward 4.299151 sec\n",
      "loss time 0.001238 sec\n",
      "backward time 0.017545 sec\n",
      "optimizer time 0.024767 sec\n",
      "training time in round 382 cost 0.4175729751586914 sec\n",
      "loss 2.319879, train acc 0.100155\n",
      "round 383\n",
      "time to device 0.008086 sec\n",
      "time forward 4.315519 sec\n",
      "loss time 0.001201 sec\n",
      "backward time 0.013626 sec\n",
      "optimizer time 0.026957 sec\n",
      "training time in round 383 cost 0.416259765625 sec\n",
      "loss 2.319943, train acc 0.100098\n",
      "round 384\n",
      "time to device 0.006666 sec\n",
      "time forward 4.326905 sec\n",
      "loss time 0.001021 sec\n",
      "backward time 0.012878 sec\n",
      "optimizer time 0.024020 sec\n",
      "training time in round 384 cost 0.4274611473083496 sec\n",
      "loss 2.319980, train acc 0.100020\n",
      "round 385\n",
      "time to device 0.008365 sec\n",
      "time forward 4.337827 sec\n",
      "loss time 0.001162 sec\n",
      "backward time 0.013911 sec\n",
      "optimizer time 0.028674 sec\n",
      "training time in round 385 cost 0.42226314544677734 sec\n",
      "loss 2.319930, train acc 0.100085\n",
      "round 386\n",
      "time to device 0.007198 sec\n",
      "time forward 4.351691 sec\n",
      "loss time 0.001139 sec\n",
      "backward time 0.010184 sec\n",
      "optimizer time 0.028834 sec\n",
      "training time in round 386 cost 0.4149010181427002 sec\n",
      "loss 2.319971, train acc 0.100089\n",
      "round 387\n",
      "time to device 0.006572 sec\n",
      "time forward 4.362473 sec\n",
      "loss time 0.001068 sec\n",
      "backward time 0.014706 sec\n",
      "optimizer time 0.029744 sec\n",
      "training time in round 387 cost 0.4339559078216553 sec\n",
      "loss 2.320037, train acc 0.100133\n",
      "round 388\n",
      "time to device 0.007834 sec\n",
      "time forward 4.379919 sec\n",
      "loss time 0.001088 sec\n",
      "backward time 0.013215 sec\n",
      "optimizer time 0.026441 sec\n",
      "training time in round 388 cost 0.4180920124053955 sec\n",
      "loss 2.320043, train acc 0.100137\n",
      "round 389\n",
      "time to device 0.006752 sec\n",
      "time forward 4.391134 sec\n",
      "loss time 0.001052 sec\n",
      "backward time 0.013841 sec\n",
      "optimizer time 0.029640 sec\n",
      "training time in round 389 cost 0.4008750915527344 sec\n",
      "loss 2.320125, train acc 0.100120\n",
      "round 390\n",
      "time to device 0.007129 sec\n",
      "time forward 4.403973 sec\n",
      "loss time 0.001011 sec\n",
      "backward time 0.013971 sec\n",
      "optimizer time 0.020811 sec\n",
      "training time in round 390 cost 0.43712496757507324 sec\n",
      "loss 2.320077, train acc 0.100064\n",
      "round 391\n",
      "time to device 0.006441 sec\n",
      "time forward 4.410864 sec\n",
      "loss time 0.000755 sec\n",
      "backward time 0.006312 sec\n",
      "optimizer time 0.016928 sec\n",
      "training time in round 391 cost 0.38234591484069824 sec\n",
      "loss 2.320055, train acc 0.100147\n",
      "round 392\n",
      "time to device 0.006619 sec\n",
      "time forward 4.422294 sec\n",
      "loss time 0.001174 sec\n",
      "backward time 0.020146 sec\n",
      "optimizer time 0.023695 sec\n",
      "training time in round 392 cost 0.4161820411682129 sec\n",
      "loss 2.320144, train acc 0.100111\n",
      "round 393\n",
      "time to device 0.007063 sec\n",
      "time forward 4.434255 sec\n",
      "loss time 0.001013 sec\n",
      "backward time 0.013439 sec\n",
      "optimizer time 0.027146 sec\n",
      "training time in round 393 cost 0.4144551753997803 sec\n",
      "loss 2.320178, train acc 0.100056\n",
      "round 394\n",
      "time to device 0.006701 sec\n",
      "time forward 4.446160 sec\n",
      "loss time 0.001113 sec\n",
      "backward time 0.015343 sec\n",
      "optimizer time 0.029054 sec\n",
      "training time in round 394 cost 0.4436826705932617 sec\n",
      "loss 2.320151, train acc 0.100000\n",
      "round 395\n",
      "time to device 0.006549 sec\n",
      "time forward 4.454583 sec\n",
      "loss time 0.000803 sec\n",
      "backward time 0.006783 sec\n",
      "optimizer time 0.020076 sec\n",
      "training time in round 395 cost 0.3672451972961426 sec\n",
      "loss 2.320079, train acc 0.100201\n",
      "round 396\n",
      "time to device 0.007828 sec\n",
      "time forward 4.471683 sec\n",
      "loss time 0.001650 sec\n",
      "backward time 0.018011 sec\n",
      "optimizer time 0.025355 sec\n",
      "training time in round 396 cost 0.422346830368042 sec\n",
      "loss 2.320144, train acc 0.100264\n",
      "round 397\n",
      "time to device 0.006652 sec\n",
      "time forward 4.483460 sec\n",
      "loss time 0.001123 sec\n",
      "backward time 0.015309 sec\n",
      "optimizer time 0.027343 sec\n",
      "training time in round 397 cost 0.4134101867675781 sec\n",
      "loss 2.320142, train acc 0.100130\n",
      "round 398\n",
      "time to device 0.007669 sec\n",
      "time forward 4.496253 sec\n",
      "loss time 0.001021 sec\n",
      "backward time 0.012833 sec\n",
      "optimizer time 0.026298 sec\n",
      "training time in round 398 cost 0.3967423439025879 sec\n",
      "loss 2.320253, train acc 0.100153\n",
      "round 399\n",
      "time to device 0.005871 sec\n",
      "time forward 4.507652 sec\n",
      "loss time 0.000965 sec\n",
      "backward time 0.012642 sec\n",
      "optimizer time 0.015961 sec\n",
      "training time in round 399 cost 0.38620972633361816 sec\n",
      "loss 2.320398, train acc 0.100215\n",
      "round 400\n",
      "time to device 0.003280 sec\n",
      "time forward 4.516966 sec\n",
      "loss time 0.001091 sec\n",
      "backward time 0.008744 sec\n",
      "optimizer time 0.019671 sec\n",
      "training time in round 400 cost 0.3805809020996094 sec\n",
      "loss 2.320378, train acc 0.100218\n",
      "round 401\n",
      "time to device 0.002586 sec\n",
      "time forward 4.527928 sec\n",
      "loss time 0.001173 sec\n",
      "backward time 0.017132 sec\n",
      "optimizer time 0.018533 sec\n",
      "training time in round 401 cost 0.404451847076416 sec\n",
      "loss 2.320591, train acc 0.100183\n",
      "round 402\n",
      "time to device 0.006852 sec\n",
      "time forward 4.540751 sec\n",
      "loss time 0.001470 sec\n",
      "backward time 0.015973 sec\n",
      "optimizer time 0.025030 sec\n",
      "training time in round 402 cost 0.42343616485595703 sec\n",
      "loss 2.320551, train acc 0.100264\n",
      "round 403\n",
      "time to device 0.007445 sec\n",
      "time forward 4.552468 sec\n",
      "loss time 0.001028 sec\n",
      "backward time 0.012083 sec\n",
      "optimizer time 0.029282 sec\n",
      "training time in round 403 cost 0.41797685623168945 sec\n",
      "loss 2.320503, train acc 0.100248\n",
      "round 404\n",
      "time to device 0.005141 sec\n",
      "time forward 4.565233 sec\n",
      "loss time 0.001061 sec\n",
      "backward time 0.013235 sec\n",
      "optimizer time 0.022142 sec\n",
      "training time in round 404 cost 0.3937489986419678 sec\n",
      "loss 2.320531, train acc 0.100405\n",
      "round 405\n",
      "time to device 0.006908 sec\n",
      "time forward 4.578939 sec\n",
      "loss time 0.001107 sec\n",
      "backward time 0.010885 sec\n",
      "optimizer time 0.027581 sec\n",
      "training time in round 405 cost 0.43697094917297363 sec\n",
      "loss 2.320469, train acc 0.100331\n",
      "round 406\n",
      "time to device 0.006908 sec\n",
      "time forward 4.590604 sec\n",
      "loss time 0.001123 sec\n",
      "backward time 0.012440 sec\n",
      "optimizer time 0.028138 sec\n",
      "training time in round 406 cost 0.40952396392822266 sec\n",
      "loss 2.320398, train acc 0.100315\n",
      "round 407\n",
      "time to device 0.007448 sec\n",
      "time forward 4.604587 sec\n",
      "loss time 0.001492 sec\n",
      "backward time 0.012656 sec\n",
      "optimizer time 0.021796 sec\n",
      "training time in round 407 cost 0.4052579402923584 sec\n",
      "loss 2.320363, train acc 0.100318\n",
      "round 408\n",
      "time to device 0.006556 sec\n",
      "time forward 4.616682 sec\n",
      "loss time 0.001067 sec\n",
      "backward time 0.012297 sec\n",
      "optimizer time 0.027972 sec\n",
      "training time in round 408 cost 0.398029088973999 sec\n",
      "loss 2.320488, train acc 0.100283\n",
      "round 409\n",
      "time to device 0.006536 sec\n",
      "time forward 4.628348 sec\n",
      "loss time 0.001490 sec\n",
      "backward time 0.012745 sec\n",
      "optimizer time 0.023257 sec\n",
      "training time in round 409 cost 0.3945279121398926 sec\n",
      "loss 2.320402, train acc 0.100324\n",
      "round 410\n",
      "time to device 0.003737 sec\n",
      "time forward 4.639241 sec\n",
      "loss time 0.001168 sec\n",
      "backward time 0.013994 sec\n",
      "optimizer time 0.027584 sec\n",
      "training time in round 410 cost 0.39353394508361816 sec\n",
      "loss 2.320453, train acc 0.100156\n",
      "round 411\n",
      "time to device 0.003403 sec\n",
      "time forward 4.647564 sec\n",
      "loss time 0.000742 sec\n",
      "backward time 0.006984 sec\n",
      "optimizer time 0.017175 sec\n",
      "training time in round 411 cost 0.3696303367614746 sec\n",
      "loss 2.320431, train acc 0.100159\n",
      "round 412\n",
      "time to device 0.003256 sec\n",
      "time forward 4.658589 sec\n",
      "loss time 0.001137 sec\n",
      "backward time 0.011857 sec\n",
      "optimizer time 0.040490 sec\n",
      "training time in round 412 cost 0.4344961643218994 sec\n",
      "loss 2.320423, train acc 0.100125\n",
      "round 413\n",
      "time to device 0.004022 sec\n",
      "time forward 4.672432 sec\n",
      "loss time 0.001068 sec\n",
      "backward time 0.012267 sec\n",
      "optimizer time 0.030911 sec\n",
      "training time in round 413 cost 0.4104487895965576 sec\n",
      "loss 2.320464, train acc 0.099996\n",
      "round 414\n",
      "time to device 0.007772 sec\n",
      "time forward 4.681701 sec\n",
      "loss time 0.000765 sec\n",
      "backward time 0.007150 sec\n",
      "optimizer time 0.017989 sec\n",
      "training time in round 414 cost 0.37596583366394043 sec\n",
      "loss 2.320487, train acc 0.100000\n",
      "round 415\n",
      "time to device 0.007403 sec\n",
      "time forward 4.695010 sec\n",
      "loss time 0.001194 sec\n",
      "backward time 0.010148 sec\n",
      "optimizer time 0.029118 sec\n",
      "training time in round 415 cost 0.41359400749206543 sec\n",
      "loss 2.320466, train acc 0.100004\n",
      "round 416\n",
      "time to device 0.006487 sec\n",
      "time forward 4.706530 sec\n",
      "loss time 0.001036 sec\n",
      "backward time 0.011391 sec\n",
      "optimizer time 0.027226 sec\n",
      "training time in round 416 cost 0.39363980293273926 sec\n",
      "loss 2.320409, train acc 0.099951\n",
      "round 417\n",
      "time to device 0.006572 sec\n",
      "time forward 4.714373 sec\n",
      "loss time 0.000724 sec\n",
      "backward time 0.006974 sec\n",
      "optimizer time 0.017751 sec\n",
      "training time in round 417 cost 0.39216017723083496 sec\n",
      "loss 2.320500, train acc 0.099862\n",
      "round 418\n",
      "time to device 0.006484 sec\n",
      "time forward 4.725762 sec\n",
      "loss time 0.001306 sec\n",
      "backward time 0.015017 sec\n",
      "optimizer time 0.029076 sec\n",
      "training time in round 418 cost 0.39691686630249023 sec\n",
      "loss 2.320434, train acc 0.099884\n",
      "round 419\n",
      "time to device 0.006515 sec\n",
      "time forward 4.736454 sec\n",
      "loss time 0.001233 sec\n",
      "backward time 0.012144 sec\n",
      "optimizer time 0.029248 sec\n",
      "training time in round 419 cost 0.4126448631286621 sec\n",
      "loss 2.320442, train acc 0.099926\n",
      "round 420\n",
      "time to device 0.006797 sec\n",
      "time forward 4.746813 sec\n",
      "loss time 0.001082 sec\n",
      "backward time 0.011685 sec\n",
      "optimizer time 0.033486 sec\n",
      "training time in round 420 cost 0.39995288848876953 sec\n",
      "loss 2.320829, train acc 0.099911\n",
      "round 421\n",
      "time to device 0.007429 sec\n",
      "time forward 4.756293 sec\n",
      "loss time 0.000975 sec\n",
      "backward time 0.012525 sec\n",
      "optimizer time 0.029479 sec\n",
      "training time in round 421 cost 0.4254789352416992 sec\n",
      "loss 2.320901, train acc 0.099915\n",
      "round 422\n",
      "time to device 0.007205 sec\n",
      "time forward 4.767559 sec\n",
      "loss time 0.001780 sec\n",
      "backward time 0.009715 sec\n",
      "optimizer time 0.032897 sec\n",
      "training time in round 422 cost 0.3970377445220947 sec\n",
      "loss 2.320849, train acc 0.099993\n",
      "round 423\n",
      "time to device 0.007014 sec\n",
      "time forward 4.778582 sec\n",
      "loss time 0.001225 sec\n",
      "backward time 0.018568 sec\n",
      "optimizer time 0.023813 sec\n",
      "training time in round 423 cost 0.39809679985046387 sec\n",
      "loss 2.320800, train acc 0.099996\n",
      "round 424\n",
      "time to device 0.006445 sec\n",
      "time forward 4.794585 sec\n",
      "loss time 0.001030 sec\n",
      "backward time 0.017583 sec\n",
      "optimizer time 0.026744 sec\n",
      "training time in round 424 cost 0.41623401641845703 sec\n",
      "loss 2.320765, train acc 0.099982\n",
      "round 425\n",
      "time to device 0.006899 sec\n",
      "time forward 4.806256 sec\n",
      "loss time 0.001041 sec\n",
      "backward time 0.009693 sec\n",
      "optimizer time 0.028129 sec\n",
      "training time in round 425 cost 0.3935718536376953 sec\n",
      "loss 2.320724, train acc 0.099875\n",
      "round 426\n",
      "time to device 0.005601 sec\n",
      "time forward 4.817770 sec\n",
      "loss time 0.000987 sec\n",
      "backward time 0.013352 sec\n",
      "optimizer time 0.026080 sec\n",
      "training time in round 426 cost 0.3892390727996826 sec\n",
      "loss 2.320652, train acc 0.099843\n",
      "round 427\n",
      "time to device 0.006476 sec\n",
      "time forward 4.828419 sec\n",
      "loss time 0.001094 sec\n",
      "backward time 0.009602 sec\n",
      "optimizer time 0.029474 sec\n",
      "training time in round 427 cost 0.4079420566558838 sec\n",
      "loss 2.320610, train acc 0.099865\n",
      "round 428\n",
      "time to device 0.006282 sec\n",
      "time forward 4.840209 sec\n",
      "loss time 0.000909 sec\n",
      "backward time 0.011334 sec\n",
      "optimizer time 0.016769 sec\n",
      "training time in round 428 cost 0.5403900146484375 sec\n",
      "loss 2.320566, train acc 0.099778\n",
      "round 429\n",
      "time to device 0.007315 sec\n",
      "time forward 4.853030 sec\n",
      "loss time 0.001445 sec\n",
      "backward time 0.018488 sec\n",
      "optimizer time 0.023325 sec\n",
      "training time in round 429 cost 0.4385390281677246 sec\n",
      "loss 2.320516, train acc 0.099764\n",
      "round 430\n",
      "time to device 0.007612 sec\n",
      "time forward 4.863293 sec\n",
      "loss time 0.001042 sec\n",
      "backward time 0.010593 sec\n",
      "optimizer time 0.031973 sec\n",
      "training time in round 430 cost 0.4254910945892334 sec\n",
      "loss 2.320475, train acc 0.099804\n",
      "round 431\n",
      "time to device 0.006888 sec\n",
      "time forward 4.870603 sec\n",
      "loss time 0.000746 sec\n",
      "backward time 0.007008 sec\n",
      "optimizer time 0.017207 sec\n",
      "training time in round 431 cost 0.3889591693878174 sec\n",
      "loss 2.320461, train acc 0.099700\n",
      "round 432\n",
      "time to device 0.006452 sec\n",
      "time forward 4.885129 sec\n",
      "loss time 0.001044 sec\n",
      "backward time 0.013254 sec\n",
      "optimizer time 0.026591 sec\n",
      "training time in round 432 cost 0.4207007884979248 sec\n",
      "loss 2.320374, train acc 0.099740\n",
      "round 433\n",
      "time to device 0.006707 sec\n",
      "time forward 4.900860 sec\n",
      "loss time 0.001118 sec\n",
      "backward time 0.015573 sec\n",
      "optimizer time 0.033745 sec\n",
      "training time in round 433 cost 0.4773719310760498 sec\n",
      "loss 2.320342, train acc 0.099690\n",
      "round 434\n",
      "time to device 0.007229 sec\n",
      "time forward 4.908474 sec\n",
      "loss time 0.000661 sec\n",
      "backward time 0.005053 sec\n",
      "optimizer time 0.062039 sec\n",
      "training time in round 434 cost 0.4832170009613037 sec\n",
      "loss 2.320398, train acc 0.099623\n",
      "round 435\n",
      "time to device 0.005887 sec\n",
      "time forward 4.918094 sec\n",
      "loss time 0.000967 sec\n",
      "backward time 0.006402 sec\n",
      "optimizer time 0.018168 sec\n",
      "training time in round 435 cost 0.384174108505249 sec\n",
      "loss 2.320389, train acc 0.099663\n",
      "round 436\n",
      "time to device 0.005622 sec\n",
      "time forward 4.923666 sec\n",
      "loss time 0.000501 sec\n",
      "backward time 0.004844 sec\n",
      "optimizer time 0.014141 sec\n",
      "training time in round 436 cost 0.36599183082580566 sec\n",
      "loss 2.320424, train acc 0.099667\n",
      "round 437\n",
      "time to device 0.007640 sec\n",
      "time forward 4.934705 sec\n",
      "loss time 0.000524 sec\n",
      "backward time 0.004672 sec\n",
      "optimizer time 0.012892 sec\n",
      "training time in round 437 cost 0.3942718505859375 sec\n",
      "loss 2.320481, train acc 0.099672\n",
      "round 438\n",
      "time to device 0.005495 sec\n",
      "time forward 4.941138 sec\n",
      "loss time 0.000750 sec\n",
      "backward time 0.006739 sec\n",
      "optimizer time 0.016593 sec\n",
      "training time in round 438 cost 0.3673536777496338 sec\n",
      "loss 2.320418, train acc 0.099641\n",
      "round 439\n",
      "time to device 0.007113 sec\n",
      "time forward 4.947040 sec\n",
      "loss time 0.000630 sec\n",
      "backward time 0.005383 sec\n",
      "optimizer time 0.017266 sec\n",
      "training time in round 439 cost 0.41792774200439453 sec\n",
      "loss 2.320532, train acc 0.099663\n",
      "round 440\n",
      "time to device 0.008547 sec\n",
      "time forward 4.960886 sec\n",
      "loss time 0.000762 sec\n",
      "backward time 0.007180 sec\n",
      "optimizer time 0.020916 sec\n",
      "training time in round 440 cost 0.42532801628112793 sec\n",
      "loss 2.321131, train acc 0.099649\n",
      "round 441\n",
      "time to device 0.007692 sec\n",
      "time forward 4.972630 sec\n",
      "loss time 0.000945 sec\n",
      "backward time 0.007352 sec\n",
      "optimizer time 0.018287 sec\n",
      "training time in round 441 cost 0.38712501525878906 sec\n",
      "loss 2.321122, train acc 0.099671\n",
      "round 442\n",
      "time to device 0.008018 sec\n",
      "time forward 4.979986 sec\n",
      "loss time 0.000396 sec\n",
      "backward time 0.003820 sec\n",
      "optimizer time 0.012687 sec\n",
      "training time in round 442 cost 0.37169909477233887 sec\n",
      "loss 2.321092, train acc 0.099676\n",
      "round 443\n",
      "time to device 0.006303 sec\n",
      "time forward 4.987950 sec\n",
      "loss time 0.000860 sec\n",
      "backward time 0.008165 sec\n",
      "optimizer time 0.019275 sec\n",
      "training time in round 443 cost 0.3804318904876709 sec\n",
      "loss 2.321062, train acc 0.099627\n",
      "round 444\n",
      "time to device 0.007598 sec\n",
      "time forward 4.994004 sec\n",
      "loss time 0.000587 sec\n",
      "backward time 0.005293 sec\n",
      "optimizer time 0.014638 sec\n",
      "training time in round 444 cost 0.3582170009613037 sec\n",
      "loss 2.321019, train acc 0.099561\n",
      "round 445\n",
      "time to device 0.005864 sec\n",
      "time forward 5.003870 sec\n",
      "loss time 0.000557 sec\n",
      "backward time 0.004705 sec\n",
      "optimizer time 0.013723 sec\n",
      "training time in round 445 cost 0.3568248748779297 sec\n",
      "loss 2.321021, train acc 0.099566\n",
      "round 446\n",
      "time to device 0.006361 sec\n",
      "time forward 5.008393 sec\n",
      "loss time 0.000443 sec\n",
      "backward time 0.004221 sec\n",
      "optimizer time 0.015836 sec\n",
      "training time in round 446 cost 0.3549950122833252 sec\n",
      "loss 2.320987, train acc 0.099570\n",
      "round 447\n",
      "time to device 0.005958 sec\n",
      "time forward 5.022331 sec\n",
      "loss time 0.001582 sec\n",
      "backward time 0.014001 sec\n",
      "optimizer time 0.070150 sec\n",
      "training time in round 447 cost 0.4595677852630615 sec\n",
      "loss 2.320942, train acc 0.099505\n",
      "round 448\n",
      "time to device 0.011463 sec\n",
      "time forward 5.034544 sec\n",
      "loss time 0.001172 sec\n",
      "backward time 0.010028 sec\n",
      "optimizer time 0.021911 sec\n",
      "training time in round 448 cost 0.40440797805786133 sec\n",
      "loss 2.320894, train acc 0.099596\n",
      "round 449\n",
      "time to device 0.007926 sec\n",
      "time forward 5.044794 sec\n",
      "loss time 0.001619 sec\n",
      "backward time 0.017730 sec\n",
      "optimizer time 0.026037 sec\n",
      "training time in round 449 cost 0.4090089797973633 sec\n",
      "loss 2.320859, train acc 0.099549\n",
      "round 450\n",
      "time to device 0.010831 sec\n",
      "time forward 5.066285 sec\n",
      "loss time 0.001173 sec\n",
      "backward time 0.012104 sec\n",
      "optimizer time 0.013473 sec\n",
      "training time in round 450 cost 0.4858267307281494 sec\n",
      "loss 2.320807, train acc 0.099536\n",
      "round 451\n",
      "time to device 0.007879 sec\n",
      "time forward 5.078797 sec\n",
      "loss time 0.001238 sec\n",
      "backward time 0.016891 sec\n",
      "optimizer time 0.021888 sec\n",
      "training time in round 451 cost 0.451383113861084 sec\n",
      "loss 2.320779, train acc 0.099523\n",
      "round 452\n",
      "time to device 0.011637 sec\n",
      "time forward 5.093568 sec\n",
      "loss time 0.001130 sec\n",
      "backward time 0.012025 sec\n",
      "optimizer time 0.021292 sec\n",
      "training time in round 452 cost 0.46250486373901367 sec\n",
      "loss 2.320734, train acc 0.099545\n",
      "round 453\n",
      "time to device 0.007167 sec\n",
      "time forward 5.103895 sec\n",
      "loss time 0.001330 sec\n",
      "backward time 0.013325 sec\n",
      "optimizer time 0.023696 sec\n",
      "training time in round 453 cost 0.41318511962890625 sec\n",
      "loss 2.320694, train acc 0.099601\n",
      "round 454\n",
      "time to device 0.007965 sec\n",
      "time forward 5.115661 sec\n",
      "loss time 0.001053 sec\n",
      "backward time 0.017953 sec\n",
      "optimizer time 0.022701 sec\n",
      "training time in round 454 cost 0.4049100875854492 sec\n",
      "loss 2.320679, train acc 0.099657\n",
      "round 455\n",
      "time to device 0.008762 sec\n",
      "time forward 5.130544 sec\n",
      "loss time 0.001003 sec\n",
      "backward time 0.016719 sec\n",
      "optimizer time 0.028110 sec\n",
      "training time in round 455 cost 0.4253230094909668 sec\n",
      "loss 2.320661, train acc 0.099695\n",
      "round 456\n",
      "time to device 0.007079 sec\n",
      "time forward 5.147994 sec\n",
      "loss time 0.001036 sec\n",
      "backward time 0.011645 sec\n",
      "optimizer time 0.023694 sec\n",
      "training time in round 456 cost 0.40715789794921875 sec\n",
      "loss 2.320619, train acc 0.099716\n",
      "round 457\n",
      "time to device 0.008781 sec\n",
      "time forward 5.160193 sec\n",
      "loss time 0.002008 sec\n",
      "backward time 0.011706 sec\n",
      "optimizer time 0.026929 sec\n",
      "training time in round 457 cost 0.4119112491607666 sec\n",
      "loss 2.320586, train acc 0.099601\n",
      "round 458\n",
      "time to device 0.007458 sec\n",
      "time forward 5.171946 sec\n",
      "loss time 0.001159 sec\n",
      "backward time 0.011274 sec\n",
      "optimizer time 0.025109 sec\n",
      "training time in round 458 cost 0.4192938804626465 sec\n",
      "loss 2.320547, train acc 0.099639\n",
      "round 459\n",
      "time to device 0.008915 sec\n",
      "time forward 5.184779 sec\n",
      "loss time 0.000949 sec\n",
      "backward time 0.014481 sec\n",
      "optimizer time 0.018273 sec\n",
      "training time in round 459 cost 0.41823315620422363 sec\n",
      "loss 2.320514, train acc 0.099677\n",
      "round 460\n",
      "time to device 0.008398 sec\n",
      "time forward 5.199918 sec\n",
      "loss time 0.001529 sec\n",
      "backward time 0.018810 sec\n",
      "optimizer time 0.022877 sec\n",
      "training time in round 460 cost 0.4225180149078369 sec\n",
      "loss 2.320474, train acc 0.099681\n",
      "round 461\n",
      "time to device 0.009278 sec\n",
      "time forward 5.213631 sec\n",
      "loss time 0.001089 sec\n",
      "backward time 0.019319 sec\n",
      "optimizer time 0.025948 sec\n",
      "training time in round 461 cost 0.43610596656799316 sec\n",
      "loss 2.320436, train acc 0.099685\n",
      "round 462\n",
      "time to device 0.008057 sec\n",
      "time forward 5.230503 sec\n",
      "loss time 0.001349 sec\n",
      "backward time 0.012845 sec\n",
      "optimizer time 0.029066 sec\n",
      "training time in round 462 cost 0.42146897315979004 sec\n",
      "loss 2.320405, train acc 0.099639\n",
      "round 463\n",
      "time to device 0.006799 sec\n",
      "time forward 5.245984 sec\n",
      "loss time 0.001158 sec\n",
      "backward time 0.013975 sec\n",
      "optimizer time 0.024767 sec\n",
      "training time in round 463 cost 0.4084138870239258 sec\n",
      "loss 2.320364, train acc 0.099677\n",
      "round 464\n",
      "time to device 0.010624 sec\n",
      "time forward 5.259676 sec\n",
      "loss time 0.001007 sec\n",
      "backward time 0.012484 sec\n",
      "optimizer time 0.024689 sec\n",
      "training time in round 464 cost 0.40574002265930176 sec\n",
      "loss 2.320329, train acc 0.099614\n",
      "round 465\n",
      "time to device 0.005020 sec\n",
      "time forward 5.271452 sec\n",
      "loss time 0.001375 sec\n",
      "backward time 0.010506 sec\n",
      "optimizer time 0.018340 sec\n",
      "training time in round 465 cost 0.3826901912689209 sec\n",
      "loss 2.320287, train acc 0.099467\n",
      "round 466\n",
      "time to device 0.003980 sec\n",
      "time forward 5.285405 sec\n",
      "loss time 0.000919 sec\n",
      "backward time 0.011708 sec\n",
      "optimizer time 0.016201 sec\n",
      "training time in round 466 cost 0.4204680919647217 sec\n",
      "loss 2.320253, train acc 0.099438\n",
      "round 467\n",
      "time to device 0.006505 sec\n",
      "time forward 5.302879 sec\n",
      "loss time 0.001678 sec\n",
      "backward time 0.013497 sec\n",
      "optimizer time 0.027344 sec\n",
      "training time in round 467 cost 0.5112721920013428 sec\n",
      "loss 2.320213, train acc 0.099476\n",
      "round 468\n",
      "time to device 0.005086 sec\n",
      "time forward 5.321287 sec\n",
      "loss time 0.002857 sec\n",
      "backward time 0.022544 sec\n",
      "optimizer time 0.017859 sec\n",
      "training time in round 468 cost 0.37844371795654297 sec\n",
      "loss 2.320188, train acc 0.099467\n",
      "test acc is 0.100000\n",
      "epoch 1, time 880.324958 sec\n",
      "epoch 3\n",
      "round 0\n",
      "time to device 0.061218 sec\n",
      "time forward 0.017360 sec\n",
      "loss time 0.002328 sec\n",
      "backward time 0.017678 sec\n",
      "optimizer time 0.075897 sec\n",
      "training time in round 0 cost 0.6352131366729736 sec\n",
      "loss 2.305936, train acc 0.070312\n",
      "round 1\n",
      "time to device 0.006636 sec\n",
      "time forward 0.028304 sec\n",
      "loss time 0.001251 sec\n",
      "backward time 0.011811 sec\n",
      "optimizer time 0.028231 sec\n",
      "training time in round 1 cost 0.41344380378723145 sec\n",
      "loss 2.301410, train acc 0.074219\n",
      "round 2\n",
      "time to device 0.007373 sec\n",
      "time forward 0.040255 sec\n",
      "loss time 0.001437 sec\n",
      "backward time 0.012407 sec\n",
      "optimizer time 0.029855 sec\n",
      "training time in round 2 cost 0.41304588317871094 sec\n",
      "loss 2.300382, train acc 0.072917\n",
      "round 3\n",
      "time to device 0.007171 sec\n",
      "time forward 0.057495 sec\n",
      "loss time 0.001409 sec\n",
      "backward time 0.010252 sec\n",
      "optimizer time 0.033746 sec\n",
      "training time in round 3 cost 0.41669487953186035 sec\n",
      "loss 2.300168, train acc 0.082031\n",
      "round 4\n",
      "time to device 0.004670 sec\n",
      "time forward 0.069854 sec\n",
      "loss time 0.001684 sec\n",
      "backward time 0.013813 sec\n",
      "optimizer time 0.031342 sec\n",
      "training time in round 4 cost 0.40494632720947266 sec\n",
      "loss 2.299675, train acc 0.090625\n",
      "round 5\n",
      "time to device 0.006365 sec\n",
      "time forward 0.080442 sec\n",
      "loss time 0.001184 sec\n",
      "backward time 0.011984 sec\n",
      "optimizer time 0.030100 sec\n",
      "training time in round 5 cost 0.4132809638977051 sec\n",
      "loss 2.299916, train acc 0.083333\n",
      "round 6\n",
      "time to device 0.006997 sec\n",
      "time forward 0.094789 sec\n",
      "loss time 0.001167 sec\n",
      "backward time 0.014166 sec\n",
      "optimizer time 0.029024 sec\n",
      "training time in round 6 cost 0.41565895080566406 sec\n",
      "loss 2.300857, train acc 0.085938\n",
      "round 7\n",
      "time to device 0.006275 sec\n",
      "time forward 0.106812 sec\n",
      "loss time 0.001123 sec\n",
      "backward time 0.015093 sec\n",
      "optimizer time 0.028013 sec\n",
      "training time in round 7 cost 0.4169189929962158 sec\n",
      "loss 2.300562, train acc 0.088867\n",
      "round 8\n",
      "time to device 0.006697 sec\n",
      "time forward 0.115315 sec\n",
      "loss time 0.000947 sec\n",
      "backward time 0.007154 sec\n",
      "optimizer time 0.018202 sec\n",
      "training time in round 8 cost 0.42672300338745117 sec\n",
      "loss 2.300557, train acc 0.094618\n",
      "round 9\n",
      "time to device 0.006963 sec\n",
      "time forward 0.126383 sec\n",
      "loss time 0.000915 sec\n",
      "backward time 0.020751 sec\n",
      "optimizer time 0.012456 sec\n",
      "training time in round 9 cost 0.3927640914916992 sec\n",
      "loss 2.304181, train acc 0.096094\n",
      "round 10\n",
      "time to device 0.007216 sec\n",
      "time forward 0.141976 sec\n",
      "loss time 0.001333 sec\n",
      "backward time 0.012414 sec\n",
      "optimizer time 0.018812 sec\n",
      "training time in round 10 cost 0.4370148181915283 sec\n",
      "loss 2.305408, train acc 0.093750\n",
      "round 11\n",
      "time to device 0.007062 sec\n",
      "time forward 0.154449 sec\n",
      "loss time 0.001005 sec\n",
      "backward time 0.013965 sec\n",
      "optimizer time 0.027077 sec\n",
      "training time in round 11 cost 0.44579100608825684 sec\n",
      "loss 2.308684, train acc 0.095703\n",
      "round 12\n",
      "time to device 0.007599 sec\n",
      "time forward 0.162323 sec\n",
      "loss time 0.000748 sec\n",
      "backward time 0.006829 sec\n",
      "optimizer time 0.017683 sec\n",
      "training time in round 12 cost 0.38256287574768066 sec\n",
      "loss 2.309263, train acc 0.094351\n",
      "round 13\n",
      "time to device 0.006624 sec\n",
      "time forward 0.176160 sec\n",
      "loss time 0.001003 sec\n",
      "backward time 0.010934 sec\n",
      "optimizer time 0.048682 sec\n",
      "training time in round 13 cost 0.44328999519348145 sec\n",
      "loss 2.307502, train acc 0.094308\n",
      "round 14\n",
      "time to device 0.006855 sec\n",
      "time forward 0.187183 sec\n",
      "loss time 0.000972 sec\n",
      "backward time 0.011563 sec\n",
      "optimizer time 0.028221 sec\n",
      "training time in round 14 cost 0.4160897731781006 sec\n",
      "loss 2.307475, train acc 0.091146\n",
      "round 15\n",
      "time to device 0.007547 sec\n",
      "time forward 0.201482 sec\n",
      "loss time 0.000910 sec\n",
      "backward time 0.021223 sec\n",
      "optimizer time 0.014374 sec\n",
      "training time in round 15 cost 0.43369483947753906 sec\n",
      "loss 2.307836, train acc 0.092285\n",
      "round 16\n",
      "time to device 0.006584 sec\n",
      "time forward 0.213263 sec\n",
      "loss time 0.001162 sec\n",
      "backward time 0.012227 sec\n",
      "optimizer time 0.024993 sec\n",
      "training time in round 16 cost 0.39365696907043457 sec\n",
      "loss 2.311501, train acc 0.090533\n",
      "round 17\n",
      "time to device 0.006391 sec\n",
      "time forward 0.221400 sec\n",
      "loss time 0.000856 sec\n",
      "backward time 0.007077 sec\n",
      "optimizer time 0.018123 sec\n",
      "training time in round 17 cost 0.3732328414916992 sec\n",
      "loss 2.310976, train acc 0.091146\n",
      "round 18\n",
      "time to device 0.006996 sec\n",
      "time forward 0.232878 sec\n",
      "loss time 0.001080 sec\n",
      "backward time 0.011440 sec\n",
      "optimizer time 0.027896 sec\n",
      "training time in round 18 cost 0.395139217376709 sec\n",
      "loss 2.310350, train acc 0.091694\n",
      "round 19\n",
      "time to device 0.005822 sec\n",
      "time forward 0.249874 sec\n",
      "loss time 0.001305 sec\n",
      "backward time 0.012420 sec\n",
      "optimizer time 0.028426 sec\n",
      "training time in round 19 cost 0.41524505615234375 sec\n",
      "loss 2.309938, train acc 0.093359\n",
      "round 20\n",
      "time to device 0.003694 sec\n",
      "time forward 0.263337 sec\n",
      "loss time 0.001193 sec\n",
      "backward time 0.012566 sec\n",
      "optimizer time 0.026460 sec\n",
      "training time in round 20 cost 0.40404701232910156 sec\n",
      "loss 2.310216, train acc 0.096354\n",
      "round 21\n",
      "time to device 0.005489 sec\n",
      "time forward 0.274995 sec\n",
      "loss time 0.001428 sec\n",
      "backward time 0.010021 sec\n",
      "optimizer time 0.030992 sec\n",
      "training time in round 21 cost 0.4399571418762207 sec\n",
      "loss 2.309472, train acc 0.095170\n",
      "round 22\n",
      "time to device 0.007214 sec\n",
      "time forward 0.282231 sec\n",
      "loss time 0.000773 sec\n",
      "backward time 0.006557 sec\n",
      "optimizer time 0.016557 sec\n",
      "training time in round 22 cost 0.38090968132019043 sec\n",
      "loss 2.309182, train acc 0.095788\n",
      "round 23\n",
      "time to device 0.006587 sec\n",
      "time forward 0.296631 sec\n",
      "loss time 0.001104 sec\n",
      "backward time 0.017669 sec\n",
      "optimizer time 0.024531 sec\n",
      "training time in round 23 cost 0.4152262210845947 sec\n",
      "loss 2.308753, train acc 0.098307\n",
      "round 24\n",
      "time to device 0.006472 sec\n",
      "time forward 0.307799 sec\n",
      "loss time 0.000959 sec\n",
      "backward time 0.013102 sec\n",
      "optimizer time 0.027470 sec\n",
      "training time in round 24 cost 0.41353392601013184 sec\n",
      "loss 2.308551, train acc 0.099062\n",
      "round 25\n",
      "time to device 0.007147 sec\n",
      "time forward 0.323488 sec\n",
      "loss time 0.001387 sec\n",
      "backward time 0.019984 sec\n",
      "optimizer time 0.023902 sec\n",
      "training time in round 25 cost 0.4223041534423828 sec\n",
      "loss 2.308353, train acc 0.097957\n",
      "round 26\n",
      "time to device 0.007748 sec\n",
      "time forward 0.336455 sec\n",
      "loss time 0.001295 sec\n",
      "backward time 0.013500 sec\n",
      "optimizer time 0.033295 sec\n",
      "training time in round 26 cost 0.4644320011138916 sec\n",
      "loss 2.308195, train acc 0.096933\n",
      "round 27\n",
      "time to device 0.007470 sec\n",
      "time forward 0.345909 sec\n",
      "loss time 0.000883 sec\n",
      "backward time 0.012694 sec\n",
      "optimizer time 0.017191 sec\n",
      "training time in round 27 cost 0.38239216804504395 sec\n",
      "loss 2.307984, train acc 0.096540\n",
      "round 28\n",
      "time to device 0.007233 sec\n",
      "time forward 0.356974 sec\n",
      "loss time 0.001138 sec\n",
      "backward time 0.013812 sec\n",
      "optimizer time 0.029071 sec\n",
      "training time in round 28 cost 0.4111199378967285 sec\n",
      "loss 2.307767, train acc 0.096983\n",
      "round 29\n",
      "time to device 0.006818 sec\n",
      "time forward 0.368381 sec\n",
      "loss time 0.001035 sec\n",
      "backward time 0.020796 sec\n",
      "optimizer time 0.024154 sec\n",
      "training time in round 29 cost 0.4031698703765869 sec\n",
      "loss 2.307679, train acc 0.097135\n",
      "round 30\n",
      "time to device 0.003686 sec\n",
      "time forward 0.382268 sec\n",
      "loss time 0.001116 sec\n",
      "backward time 0.013171 sec\n",
      "optimizer time 0.027884 sec\n",
      "training time in round 30 cost 0.4169158935546875 sec\n",
      "loss 2.307551, train acc 0.097278\n",
      "round 31\n",
      "time to device 0.003291 sec\n",
      "time forward 0.395550 sec\n",
      "loss time 0.001016 sec\n",
      "backward time 0.011343 sec\n",
      "optimizer time 0.027665 sec\n",
      "training time in round 31 cost 0.41673779487609863 sec\n",
      "loss 2.307368, train acc 0.096924\n",
      "round 32\n",
      "time to device 0.003381 sec\n",
      "time forward 0.403720 sec\n",
      "loss time 0.000858 sec\n",
      "backward time 0.008003 sec\n",
      "optimizer time 0.019086 sec\n",
      "training time in round 32 cost 0.3766791820526123 sec\n",
      "loss 2.307257, train acc 0.097301\n",
      "round 33\n",
      "time to device 0.003701 sec\n",
      "time forward 0.414438 sec\n",
      "loss time 0.001382 sec\n",
      "backward time 0.009579 sec\n",
      "optimizer time 0.028658 sec\n",
      "training time in round 33 cost 0.38740992546081543 sec\n",
      "loss 2.307126, train acc 0.097886\n",
      "round 34\n",
      "time to device 0.004097 sec\n",
      "time forward 0.427879 sec\n",
      "loss time 0.001013 sec\n",
      "backward time 0.012959 sec\n",
      "optimizer time 0.022548 sec\n",
      "training time in round 34 cost 0.4023458957672119 sec\n",
      "loss 2.306910, train acc 0.098214\n",
      "round 35\n",
      "time to device 0.003108 sec\n",
      "time forward 0.440527 sec\n",
      "loss time 0.001141 sec\n",
      "backward time 0.012320 sec\n",
      "optimizer time 0.030405 sec\n",
      "training time in round 35 cost 0.4517519474029541 sec\n",
      "loss 2.307042, train acc 0.099609\n",
      "round 36\n",
      "time to device 0.006270 sec\n",
      "time forward 0.452113 sec\n",
      "loss time 0.001812 sec\n",
      "backward time 0.010274 sec\n",
      "optimizer time 0.033245 sec\n",
      "training time in round 36 cost 0.4007151126861572 sec\n",
      "loss 2.306935, train acc 0.099240\n",
      "round 37\n",
      "time to device 0.007178 sec\n",
      "time forward 0.461059 sec\n",
      "loss time 0.000407 sec\n",
      "backward time 0.003719 sec\n",
      "optimizer time 0.013099 sec\n",
      "training time in round 37 cost 0.37515711784362793 sec\n",
      "loss 2.306883, train acc 0.098479\n",
      "round 38\n",
      "time to device 0.008195 sec\n",
      "time forward 0.473368 sec\n",
      "loss time 0.001145 sec\n",
      "backward time 0.013615 sec\n",
      "optimizer time 0.028151 sec\n",
      "training time in round 38 cost 0.4136021137237549 sec\n",
      "loss 2.306770, train acc 0.098157\n",
      "round 39\n",
      "time to device 0.007065 sec\n",
      "time forward 0.488670 sec\n",
      "loss time 0.001135 sec\n",
      "backward time 0.014296 sec\n",
      "optimizer time 0.026635 sec\n",
      "training time in round 39 cost 0.41543126106262207 sec\n",
      "loss 2.306706, train acc 0.097656\n",
      "round 40\n",
      "time to device 0.006831 sec\n",
      "time forward 0.501127 sec\n",
      "loss time 0.001020 sec\n",
      "backward time 0.010599 sec\n",
      "optimizer time 0.027533 sec\n",
      "training time in round 40 cost 0.393190860748291 sec\n",
      "loss 2.306521, train acc 0.096989\n",
      "round 41\n",
      "time to device 0.006829 sec\n",
      "time forward 0.512187 sec\n",
      "loss time 0.001371 sec\n",
      "backward time 0.015003 sec\n",
      "optimizer time 0.025025 sec\n",
      "training time in round 41 cost 0.3955380916595459 sec\n",
      "loss 2.306475, train acc 0.097284\n",
      "round 42\n",
      "time to device 0.007497 sec\n",
      "time forward 0.519713 sec\n",
      "loss time 0.000735 sec\n",
      "backward time 0.007085 sec\n",
      "optimizer time 0.016357 sec\n",
      "training time in round 42 cost 0.3653080463409424 sec\n",
      "loss 2.306251, train acc 0.097565\n",
      "round 43\n",
      "time to device 0.005319 sec\n",
      "time forward 0.530993 sec\n",
      "loss time 0.001064 sec\n",
      "backward time 0.013571 sec\n",
      "optimizer time 0.022022 sec\n",
      "training time in round 43 cost 0.38956594467163086 sec\n",
      "loss 2.306148, train acc 0.097656\n",
      "round 44\n",
      "time to device 0.003483 sec\n",
      "time forward 0.540332 sec\n",
      "loss time 0.000930 sec\n",
      "backward time 0.012399 sec\n",
      "optimizer time 0.025639 sec\n",
      "training time in round 44 cost 0.38199877738952637 sec\n",
      "loss 2.305922, train acc 0.097569\n",
      "round 45\n",
      "time to device 0.003789 sec\n",
      "time forward 0.551479 sec\n",
      "loss time 0.000998 sec\n",
      "backward time 0.012298 sec\n",
      "optimizer time 0.029284 sec\n",
      "training time in round 45 cost 0.39060306549072266 sec\n",
      "loss 2.305723, train acc 0.099185\n",
      "round 46\n",
      "time to device 0.004229 sec\n",
      "time forward 0.565600 sec\n",
      "loss time 0.001467 sec\n",
      "backward time 0.013878 sec\n",
      "optimizer time 0.026369 sec\n",
      "training time in round 46 cost 0.41100335121154785 sec\n",
      "loss 2.305443, train acc 0.098072\n",
      "round 47\n",
      "time to device 0.003823 sec\n",
      "time forward 0.573456 sec\n",
      "loss time 0.000871 sec\n",
      "backward time 0.007105 sec\n",
      "optimizer time 0.017998 sec\n",
      "training time in round 47 cost 0.37274718284606934 sec\n",
      "loss 2.305466, train acc 0.097819\n",
      "round 48\n",
      "time to device 0.003898 sec\n",
      "time forward 0.586730 sec\n",
      "loss time 0.001242 sec\n",
      "backward time 0.012054 sec\n",
      "optimizer time 0.028376 sec\n",
      "training time in round 48 cost 0.4054856300354004 sec\n",
      "loss 2.305324, train acc 0.097736\n",
      "round 49\n",
      "time to device 0.003705 sec\n",
      "time forward 0.598743 sec\n",
      "loss time 0.001227 sec\n",
      "backward time 0.015798 sec\n",
      "optimizer time 0.025179 sec\n",
      "training time in round 49 cost 0.40224623680114746 sec\n",
      "loss 2.305444, train acc 0.097344\n",
      "round 50\n",
      "time to device 0.003903 sec\n",
      "time forward 0.611490 sec\n",
      "loss time 0.000995 sec\n",
      "backward time 0.010283 sec\n",
      "optimizer time 0.030392 sec\n",
      "training time in round 50 cost 0.4362030029296875 sec\n",
      "loss 2.305356, train acc 0.097733\n",
      "round 51\n",
      "time to device 0.005702 sec\n",
      "time forward 0.622104 sec\n",
      "loss time 0.001166 sec\n",
      "backward time 0.012093 sec\n",
      "optimizer time 0.027701 sec\n",
      "training time in round 51 cost 0.3917398452758789 sec\n",
      "loss 2.305308, train acc 0.098257\n",
      "round 52\n",
      "time to device 0.007990 sec\n",
      "time forward 0.634584 sec\n",
      "loss time 0.000867 sec\n",
      "backward time 0.008274 sec\n",
      "optimizer time 0.018542 sec\n",
      "training time in round 52 cost 0.39051103591918945 sec\n",
      "loss 2.305977, train acc 0.098614\n",
      "round 53\n",
      "time to device 0.006640 sec\n",
      "time forward 0.647006 sec\n",
      "loss time 0.001807 sec\n",
      "backward time 0.010890 sec\n",
      "optimizer time 0.025425 sec\n",
      "training time in round 53 cost 0.3947319984436035 sec\n",
      "loss 2.306034, train acc 0.098235\n",
      "round 54\n",
      "time to device 0.006381 sec\n",
      "time forward 0.658295 sec\n",
      "loss time 0.001088 sec\n",
      "backward time 0.011881 sec\n",
      "optimizer time 0.026649 sec\n",
      "training time in round 54 cost 0.39286088943481445 sec\n",
      "loss 2.305935, train acc 0.098722\n",
      "round 55\n",
      "time to device 0.006178 sec\n",
      "time forward 0.672728 sec\n",
      "loss time 0.001280 sec\n",
      "backward time 0.010557 sec\n",
      "optimizer time 0.027148 sec\n",
      "training time in round 55 cost 0.3969600200653076 sec\n",
      "loss 2.305984, train acc 0.098493\n",
      "round 56\n",
      "time to device 0.006308 sec\n",
      "time forward 0.684474 sec\n",
      "loss time 0.001019 sec\n",
      "backward time 0.011360 sec\n",
      "optimizer time 0.027371 sec\n",
      "training time in round 56 cost 0.3970370292663574 sec\n",
      "loss 2.305897, train acc 0.098821\n",
      "round 57\n",
      "time to device 0.003432 sec\n",
      "time forward 0.692491 sec\n",
      "loss time 0.000894 sec\n",
      "backward time 0.008873 sec\n",
      "optimizer time 0.018976 sec\n",
      "training time in round 57 cost 0.3753020763397217 sec\n",
      "loss 2.306120, train acc 0.098734\n",
      "round 58\n",
      "time to device 0.003289 sec\n",
      "time forward 0.699765 sec\n",
      "loss time 0.000822 sec\n",
      "backward time 0.005883 sec\n",
      "optimizer time 0.015945 sec\n",
      "training time in round 58 cost 0.37343621253967285 sec\n",
      "loss 2.306089, train acc 0.098782\n",
      "round 59\n",
      "time to device 0.003342 sec\n",
      "time forward 0.710994 sec\n",
      "loss time 0.001477 sec\n",
      "backward time 0.015643 sec\n",
      "optimizer time 0.022813 sec\n",
      "training time in round 59 cost 0.3890559673309326 sec\n",
      "loss 2.305749, train acc 0.099349\n",
      "round 60\n",
      "time to device 0.003564 sec\n",
      "time forward 0.723281 sec\n",
      "loss time 0.000999 sec\n",
      "backward time 0.012202 sec\n",
      "optimizer time 0.025685 sec\n",
      "training time in round 60 cost 0.3932790756225586 sec\n",
      "loss 2.305676, train acc 0.099385\n",
      "round 61\n",
      "time to device 0.003385 sec\n",
      "time forward 0.732190 sec\n",
      "loss time 0.001103 sec\n",
      "backward time 0.008134 sec\n",
      "optimizer time 0.019913 sec\n",
      "training time in round 61 cost 0.36756300926208496 sec\n",
      "loss 2.305727, train acc 0.099420\n",
      "round 62\n",
      "time to device 0.003320 sec\n",
      "time forward 0.740104 sec\n",
      "loss time 0.001016 sec\n",
      "backward time 0.008237 sec\n",
      "optimizer time 0.020036 sec\n",
      "training time in round 62 cost 0.3864710330963135 sec\n",
      "loss 2.305596, train acc 0.099082\n",
      "round 63\n",
      "time to device 0.002926 sec\n",
      "time forward 0.751372 sec\n",
      "loss time 0.000994 sec\n",
      "backward time 0.012734 sec\n",
      "optimizer time 0.024691 sec\n",
      "training time in round 63 cost 0.38884973526000977 sec\n",
      "loss 2.305595, train acc 0.098633\n",
      "round 64\n",
      "time to device 0.003346 sec\n",
      "time forward 0.763895 sec\n",
      "loss time 0.001318 sec\n",
      "backward time 0.011169 sec\n",
      "optimizer time 0.028113 sec\n",
      "training time in round 64 cost 0.4032249450683594 sec\n",
      "loss 2.305489, train acc 0.098918\n",
      "round 65\n",
      "time to device 0.004049 sec\n",
      "time forward 0.777604 sec\n",
      "loss time 0.001223 sec\n",
      "backward time 0.015312 sec\n",
      "optimizer time 0.027258 sec\n",
      "training time in round 65 cost 0.4706568717956543 sec\n",
      "loss 2.305366, train acc 0.098722\n",
      "round 66\n",
      "time to device 0.003629 sec\n",
      "time forward 0.788521 sec\n",
      "loss time 0.001919 sec\n",
      "backward time 0.009753 sec\n",
      "optimizer time 0.033133 sec\n",
      "training time in round 66 cost 0.3946702480316162 sec\n",
      "loss 2.305318, train acc 0.098531\n",
      "round 67\n",
      "time to device 0.007139 sec\n",
      "time forward 0.801648 sec\n",
      "loss time 0.000894 sec\n",
      "backward time 0.007619 sec\n",
      "optimizer time 0.017566 sec\n",
      "training time in round 67 cost 0.3849160671234131 sec\n",
      "loss 2.305376, train acc 0.098346\n",
      "round 68\n",
      "time to device 0.006179 sec\n",
      "time forward 0.812448 sec\n",
      "loss time 0.001357 sec\n",
      "backward time 0.010024 sec\n",
      "optimizer time 0.027460 sec\n",
      "training time in round 68 cost 0.3891880512237549 sec\n",
      "loss 2.305332, train acc 0.098619\n",
      "round 69\n",
      "time to device 0.006786 sec\n",
      "time forward 0.823930 sec\n",
      "loss time 0.001018 sec\n",
      "backward time 0.012897 sec\n",
      "optimizer time 0.026224 sec\n",
      "training time in round 69 cost 0.39340686798095703 sec\n",
      "loss 2.305327, train acc 0.098661\n",
      "round 70\n",
      "time to device 0.006442 sec\n",
      "time forward 0.835235 sec\n",
      "loss time 0.001279 sec\n",
      "backward time 0.009650 sec\n",
      "optimizer time 0.028160 sec\n",
      "training time in round 70 cost 0.3898289203643799 sec\n",
      "loss 2.305364, train acc 0.098702\n",
      "round 71\n",
      "time to device 0.007798 sec\n",
      "time forward 0.846302 sec\n",
      "loss time 0.001483 sec\n",
      "backward time 0.011514 sec\n",
      "optimizer time 0.028477 sec\n",
      "training time in round 71 cost 0.3929147720336914 sec\n",
      "loss 2.305401, train acc 0.098741\n",
      "round 72\n",
      "time to device 0.006174 sec\n",
      "time forward 0.856784 sec\n",
      "loss time 0.000901 sec\n",
      "backward time 0.008160 sec\n",
      "optimizer time 0.018255 sec\n",
      "training time in round 72 cost 0.38596415519714355 sec\n",
      "loss 2.305765, train acc 0.098780\n",
      "round 73\n",
      "time to device 0.003497 sec\n",
      "time forward 0.868763 sec\n",
      "loss time 0.001033 sec\n",
      "backward time 0.012190 sec\n",
      "optimizer time 0.029282 sec\n",
      "training time in round 73 cost 0.43483710289001465 sec\n",
      "loss 2.305547, train acc 0.098923\n",
      "round 74\n",
      "time to device 0.006798 sec\n",
      "time forward 0.883011 sec\n",
      "loss time 0.001256 sec\n",
      "backward time 0.021784 sec\n",
      "optimizer time 0.023925 sec\n",
      "training time in round 74 cost 0.412006139755249 sec\n",
      "loss 2.305563, train acc 0.099583\n",
      "round 75\n",
      "time to device 0.003643 sec\n",
      "time forward 0.894720 sec\n",
      "loss time 0.001177 sec\n",
      "backward time 0.012748 sec\n",
      "optimizer time 0.029640 sec\n",
      "training time in round 75 cost 0.40522027015686035 sec\n",
      "loss 2.305944, train acc 0.099609\n",
      "round 76\n",
      "time to device 0.003372 sec\n",
      "time forward 0.904644 sec\n",
      "loss time 0.001172 sec\n",
      "backward time 0.011481 sec\n",
      "optimizer time 0.016720 sec\n",
      "training time in round 76 cost 0.37482118606567383 sec\n",
      "loss 2.306390, train acc 0.099635\n",
      "round 77\n",
      "time to device 0.005177 sec\n",
      "time forward 0.913980 sec\n",
      "loss time 0.000945 sec\n",
      "backward time 0.008120 sec\n",
      "optimizer time 0.019516 sec\n",
      "training time in round 77 cost 0.3753702640533447 sec\n",
      "loss 2.306688, train acc 0.099960\n",
      "round 78\n",
      "time to device 0.003434 sec\n",
      "time forward 0.927498 sec\n",
      "loss time 0.001284 sec\n",
      "backward time 0.013476 sec\n",
      "optimizer time 0.028399 sec\n",
      "training time in round 78 cost 0.40463805198669434 sec\n",
      "loss 2.306848, train acc 0.099980\n",
      "round 79\n",
      "time to device 0.010700 sec\n",
      "time forward 0.941982 sec\n",
      "loss time 0.001437 sec\n",
      "backward time 0.010178 sec\n",
      "optimizer time 0.029719 sec\n",
      "training time in round 79 cost 0.4643280506134033 sec\n",
      "loss 2.306804, train acc 0.100098\n",
      "round 80\n",
      "time to device 0.006388 sec\n",
      "time forward 0.953482 sec\n",
      "loss time 0.001052 sec\n",
      "backward time 0.010488 sec\n",
      "optimizer time 0.030680 sec\n",
      "training time in round 80 cost 0.3961308002471924 sec\n",
      "loss 2.306931, train acc 0.099537\n",
      "round 81\n",
      "time to device 0.007068 sec\n",
      "time forward 0.964123 sec\n",
      "loss time 0.001171 sec\n",
      "backward time 0.010627 sec\n",
      "optimizer time 0.031359 sec\n",
      "training time in round 81 cost 0.42418408393859863 sec\n",
      "loss 2.306890, train acc 0.099371\n",
      "round 82\n",
      "time to device 0.006775 sec\n",
      "time forward 0.972351 sec\n",
      "loss time 0.000883 sec\n",
      "backward time 0.007018 sec\n",
      "optimizer time 0.017747 sec\n",
      "training time in round 82 cost 0.3669252395629883 sec\n",
      "loss 2.307076, train acc 0.099492\n",
      "round 83\n",
      "time to device 0.007427 sec\n",
      "time forward 0.982301 sec\n",
      "loss time 0.000985 sec\n",
      "backward time 0.013368 sec\n",
      "optimizer time 0.028892 sec\n",
      "training time in round 83 cost 0.40833282470703125 sec\n",
      "loss 2.307026, train acc 0.099423\n",
      "round 84\n",
      "time to device 0.006021 sec\n",
      "time forward 0.993011 sec\n",
      "loss time 0.001047 sec\n",
      "backward time 0.010949 sec\n",
      "optimizer time 0.034436 sec\n",
      "training time in round 84 cost 0.3993957042694092 sec\n",
      "loss 2.306938, train acc 0.099540\n",
      "round 85\n",
      "time to device 0.006749 sec\n",
      "time forward 1.003911 sec\n",
      "loss time 0.001211 sec\n",
      "backward time 0.013471 sec\n",
      "optimizer time 0.029722 sec\n",
      "training time in round 85 cost 0.4167609214782715 sec\n",
      "loss 2.306922, train acc 0.099382\n",
      "round 86\n",
      "time to device 0.006752 sec\n",
      "time forward 1.015687 sec\n",
      "loss time 0.001131 sec\n",
      "backward time 0.010903 sec\n",
      "optimizer time 0.029322 sec\n",
      "training time in round 86 cost 0.3916490077972412 sec\n",
      "loss 2.306864, train acc 0.099407\n",
      "round 87\n",
      "time to device 0.006340 sec\n",
      "time forward 1.024884 sec\n",
      "loss time 0.001106 sec\n",
      "backward time 0.008712 sec\n",
      "optimizer time 0.022677 sec\n",
      "training time in round 87 cost 0.38916492462158203 sec\n",
      "loss 2.306891, train acc 0.098810\n",
      "round 88\n",
      "time to device 0.006645 sec\n",
      "time forward 1.035308 sec\n",
      "loss time 0.001047 sec\n",
      "backward time 0.009962 sec\n",
      "optimizer time 0.028138 sec\n",
      "training time in round 88 cost 0.3913688659667969 sec\n",
      "loss 2.306778, train acc 0.099017\n",
      "round 89\n",
      "time to device 0.006956 sec\n",
      "time forward 1.047233 sec\n",
      "loss time 0.001078 sec\n",
      "backward time 0.014992 sec\n",
      "optimizer time 0.027893 sec\n",
      "training time in round 89 cost 0.40313100814819336 sec\n",
      "loss 2.306721, train acc 0.099132\n",
      "round 90\n",
      "time to device 0.009501 sec\n",
      "time forward 1.057713 sec\n",
      "loss time 0.001474 sec\n",
      "backward time 0.009688 sec\n",
      "optimizer time 0.027629 sec\n",
      "training time in round 90 cost 0.41254615783691406 sec\n",
      "loss 2.306631, train acc 0.099245\n",
      "round 91\n",
      "time to device 0.007330 sec\n",
      "time forward 1.069221 sec\n",
      "loss time 0.001892 sec\n",
      "backward time 0.014760 sec\n",
      "optimizer time 0.030989 sec\n",
      "training time in round 91 cost 0.40358686447143555 sec\n",
      "loss 2.306555, train acc 0.099440\n",
      "round 92\n",
      "time to device 0.007952 sec\n",
      "time forward 1.082385 sec\n",
      "loss time 0.001055 sec\n",
      "backward time 0.008206 sec\n",
      "optimizer time 0.020143 sec\n",
      "training time in round 92 cost 0.4004087448120117 sec\n",
      "loss 2.306520, train acc 0.099630\n",
      "round 93\n",
      "time to device 0.007771 sec\n",
      "time forward 1.089700 sec\n",
      "loss time 0.000374 sec\n",
      "backward time 0.005897 sec\n",
      "optimizer time 0.010597 sec\n",
      "training time in round 93 cost 0.38293981552124023 sec\n",
      "loss 2.306495, train acc 0.099651\n",
      "round 94\n",
      "time to device 0.008451 sec\n",
      "time forward 1.102094 sec\n",
      "loss time 0.001237 sec\n",
      "backward time 0.014734 sec\n",
      "optimizer time 0.026337 sec\n",
      "training time in round 94 cost 0.42185497283935547 sec\n",
      "loss 2.306423, train acc 0.099671\n",
      "round 95\n",
      "time to device 0.006477 sec\n",
      "time forward 1.112561 sec\n",
      "loss time 0.001060 sec\n",
      "backward time 0.018916 sec\n",
      "optimizer time 0.027704 sec\n",
      "training time in round 95 cost 0.40518689155578613 sec\n",
      "loss 2.307149, train acc 0.099528\n",
      "round 96\n",
      "time to device 0.007100 sec\n",
      "time forward 1.123580 sec\n",
      "loss time 0.001022 sec\n",
      "backward time 0.011995 sec\n",
      "optimizer time 0.028597 sec\n",
      "training time in round 96 cost 0.40613889694213867 sec\n",
      "loss 2.307246, train acc 0.099388\n",
      "round 97\n",
      "time to device 0.006901 sec\n",
      "time forward 1.130729 sec\n",
      "loss time 0.000719 sec\n",
      "backward time 0.006968 sec\n",
      "optimizer time 0.017445 sec\n",
      "training time in round 97 cost 0.3788580894470215 sec\n",
      "loss 2.307187, train acc 0.099091\n",
      "round 98\n",
      "time to device 0.006449 sec\n",
      "time forward 1.144778 sec\n",
      "loss time 0.001311 sec\n",
      "backward time 0.012791 sec\n",
      "optimizer time 0.027890 sec\n",
      "training time in round 98 cost 0.44101405143737793 sec\n",
      "loss 2.307187, train acc 0.098564\n",
      "round 99\n",
      "time to device 0.006397 sec\n",
      "time forward 1.159240 sec\n",
      "loss time 0.001049 sec\n",
      "backward time 0.018863 sec\n",
      "optimizer time 0.024340 sec\n",
      "training time in round 99 cost 0.41023993492126465 sec\n",
      "loss 2.307123, train acc 0.098750\n",
      "round 100\n",
      "time to device 0.006296 sec\n",
      "time forward 1.171801 sec\n",
      "loss time 0.001148 sec\n",
      "backward time 0.015210 sec\n",
      "optimizer time 0.024245 sec\n",
      "training time in round 100 cost 0.41045188903808594 sec\n",
      "loss 2.307043, train acc 0.099087\n",
      "round 101\n",
      "time to device 0.006518 sec\n",
      "time forward 1.182295 sec\n",
      "loss time 0.001262 sec\n",
      "backward time 0.011099 sec\n",
      "optimizer time 0.029601 sec\n",
      "training time in round 101 cost 0.39629292488098145 sec\n",
      "loss 2.307019, train acc 0.099265\n",
      "round 102\n",
      "time to device 0.008826 sec\n",
      "time forward 1.192410 sec\n",
      "loss time 0.000741 sec\n",
      "backward time 0.007048 sec\n",
      "optimizer time 0.016817 sec\n",
      "training time in round 102 cost 0.3794410228729248 sec\n",
      "loss 2.306969, train acc 0.099059\n",
      "round 103\n",
      "time to device 0.003348 sec\n",
      "time forward 1.204466 sec\n",
      "loss time 0.001050 sec\n",
      "backward time 0.011247 sec\n",
      "optimizer time 0.026439 sec\n",
      "training time in round 103 cost 0.38836193084716797 sec\n",
      "loss 2.306915, train acc 0.099459\n",
      "round 104\n",
      "time to device 0.003252 sec\n",
      "time forward 1.211634 sec\n",
      "loss time 0.000760 sec\n",
      "backward time 0.006584 sec\n",
      "optimizer time 0.018894 sec\n",
      "training time in round 104 cost 0.374082088470459 sec\n",
      "loss 2.306973, train acc 0.099479\n",
      "round 105\n",
      "time to device 0.003654 sec\n",
      "time forward 1.222731 sec\n",
      "loss time 0.001082 sec\n",
      "backward time 0.012387 sec\n",
      "optimizer time 0.023368 sec\n",
      "training time in round 105 cost 0.38718104362487793 sec\n",
      "loss 2.306912, train acc 0.099499\n",
      "round 106\n",
      "time to device 0.003974 sec\n",
      "time forward 1.234232 sec\n",
      "loss time 0.001126 sec\n",
      "backward time 0.010191 sec\n",
      "optimizer time 0.028519 sec\n",
      "training time in round 106 cost 0.3951230049133301 sec\n",
      "loss 2.306890, train acc 0.099664\n",
      "round 107\n",
      "time to device 0.003606 sec\n",
      "time forward 1.241932 sec\n",
      "loss time 0.000736 sec\n",
      "backward time 0.006916 sec\n",
      "optimizer time 0.016603 sec\n",
      "training time in round 107 cost 0.3679769039154053 sec\n",
      "loss 2.306838, train acc 0.099682\n",
      "round 108\n",
      "time to device 0.003540 sec\n",
      "time forward 1.253719 sec\n",
      "loss time 0.002374 sec\n",
      "backward time 0.012687 sec\n",
      "optimizer time 0.028717 sec\n",
      "training time in round 108 cost 0.4036898612976074 sec\n",
      "loss 2.306849, train acc 0.100129\n",
      "round 109\n",
      "time to device 0.003825 sec\n",
      "time forward 1.267593 sec\n",
      "loss time 0.001584 sec\n",
      "backward time 0.016745 sec\n",
      "optimizer time 0.029019 sec\n",
      "training time in round 109 cost 0.4523460865020752 sec\n",
      "loss 2.306651, train acc 0.100142\n",
      "round 110\n",
      "time to device 0.006010 sec\n",
      "time forward 1.277852 sec\n",
      "loss time 0.001113 sec\n",
      "backward time 0.012883 sec\n",
      "optimizer time 0.023689 sec\n",
      "training time in round 110 cost 0.3885769844055176 sec\n",
      "loss 2.307025, train acc 0.100155\n",
      "round 111\n",
      "time to device 0.007543 sec\n",
      "time forward 1.293546 sec\n",
      "loss time 0.001153 sec\n",
      "backward time 0.007656 sec\n",
      "optimizer time 0.020124 sec\n",
      "training time in round 111 cost 0.4012758731842041 sec\n",
      "loss 2.306920, train acc 0.100656\n",
      "round 112\n",
      "time to device 0.007015 sec\n",
      "time forward 1.301040 sec\n",
      "loss time 0.000924 sec\n",
      "backward time 0.007767 sec\n",
      "optimizer time 0.018365 sec\n",
      "training time in round 112 cost 0.3699018955230713 sec\n",
      "loss 2.306839, train acc 0.100802\n",
      "round 113\n",
      "time to device 0.006069 sec\n",
      "time forward 1.312122 sec\n",
      "loss time 0.000953 sec\n",
      "backward time 0.012652 sec\n",
      "optimizer time 0.029410 sec\n",
      "training time in round 113 cost 0.39774394035339355 sec\n",
      "loss 2.306799, train acc 0.100603\n",
      "round 114\n",
      "time to device 0.007435 sec\n",
      "time forward 1.323566 sec\n",
      "loss time 0.001009 sec\n",
      "backward time 0.011333 sec\n",
      "optimizer time 0.028702 sec\n",
      "training time in round 114 cost 0.4009120464324951 sec\n",
      "loss 2.306761, train acc 0.100883\n",
      "round 115\n",
      "time to device 0.006685 sec\n",
      "time forward 1.334380 sec\n",
      "loss time 0.001130 sec\n",
      "backward time 0.012058 sec\n",
      "optimizer time 0.027943 sec\n",
      "training time in round 115 cost 0.3920719623565674 sec\n",
      "loss 2.306739, train acc 0.100754\n",
      "round 116\n",
      "time to device 0.006427 sec\n",
      "time forward 1.348109 sec\n",
      "loss time 0.001063 sec\n",
      "backward time 0.010116 sec\n",
      "optimizer time 0.028412 sec\n",
      "training time in round 116 cost 0.4167060852050781 sec\n",
      "loss 2.307786, train acc 0.100828\n",
      "round 117\n",
      "time to device 0.006547 sec\n",
      "time forward 1.356633 sec\n",
      "loss time 0.000926 sec\n",
      "backward time 0.007423 sec\n",
      "optimizer time 0.018750 sec\n",
      "training time in round 117 cost 0.4115641117095947 sec\n",
      "loss 2.307779, train acc 0.100768\n",
      "round 118\n",
      "time to device 0.006771 sec\n",
      "time forward 1.368178 sec\n",
      "loss time 0.000982 sec\n",
      "backward time 0.018640 sec\n",
      "optimizer time 0.030092 sec\n",
      "training time in round 118 cost 0.4079291820526123 sec\n",
      "loss 2.307735, train acc 0.100709\n",
      "round 119\n",
      "time to device 0.006933 sec\n",
      "time forward 1.378693 sec\n",
      "loss time 0.002377 sec\n",
      "backward time 0.006117 sec\n",
      "optimizer time 0.015717 sec\n",
      "training time in round 119 cost 0.4047279357910156 sec\n",
      "loss 2.307816, train acc 0.100846\n",
      "round 120\n",
      "time to device 0.006893 sec\n",
      "time forward 1.392026 sec\n",
      "loss time 0.001211 sec\n",
      "backward time 0.011725 sec\n",
      "optimizer time 0.018911 sec\n",
      "training time in round 120 cost 0.4286167621612549 sec\n",
      "loss 2.307799, train acc 0.100917\n",
      "round 121\n",
      "time to device 0.007260 sec\n",
      "time forward 1.400271 sec\n",
      "loss time 0.000461 sec\n",
      "backward time 0.004654 sec\n",
      "optimizer time 0.021756 sec\n",
      "training time in round 121 cost 0.40979719161987305 sec\n",
      "loss 2.308127, train acc 0.101050\n",
      "round 122\n",
      "time to device 0.006613 sec\n",
      "time forward 1.414507 sec\n",
      "loss time 0.001119 sec\n",
      "backward time 0.014596 sec\n",
      "optimizer time 0.031605 sec\n",
      "training time in round 122 cost 0.4163951873779297 sec\n",
      "loss 2.308111, train acc 0.100927\n",
      "round 123\n",
      "time to device 0.006708 sec\n",
      "time forward 1.427031 sec\n",
      "loss time 0.001381 sec\n",
      "backward time 0.009593 sec\n",
      "optimizer time 0.028617 sec\n",
      "training time in round 123 cost 0.3982560634613037 sec\n",
      "loss 2.308065, train acc 0.100743\n",
      "round 124\n",
      "time to device 0.006542 sec\n",
      "time forward 1.434824 sec\n",
      "loss time 0.000678 sec\n",
      "backward time 0.005886 sec\n",
      "optimizer time 0.017886 sec\n",
      "training time in round 124 cost 0.3757650852203369 sec\n",
      "loss 2.308963, train acc 0.100500\n",
      "round 125\n",
      "time to device 0.006053 sec\n",
      "time forward 1.442209 sec\n",
      "loss time 0.000555 sec\n",
      "backward time 0.005605 sec\n",
      "optimizer time 0.013543 sec\n",
      "training time in round 125 cost 0.3665449619293213 sec\n",
      "loss 2.308970, train acc 0.100632\n",
      "round 126\n",
      "time to device 0.005997 sec\n",
      "time forward 1.454125 sec\n",
      "loss time 0.001077 sec\n",
      "backward time 0.011508 sec\n",
      "optimizer time 0.027475 sec\n",
      "training time in round 126 cost 0.4414823055267334 sec\n",
      "loss 2.308936, train acc 0.100640\n",
      "round 127\n",
      "time to device 0.007076 sec\n",
      "time forward 1.468137 sec\n",
      "loss time 0.001218 sec\n",
      "backward time 0.011608 sec\n",
      "optimizer time 0.027977 sec\n",
      "training time in round 127 cost 0.4106748104095459 sec\n",
      "loss 2.308868, train acc 0.100830\n",
      "round 128\n",
      "time to device 0.006963 sec\n",
      "time forward 1.479606 sec\n",
      "loss time 0.001116 sec\n",
      "backward time 0.012055 sec\n",
      "optimizer time 0.027338 sec\n",
      "training time in round 128 cost 0.40723705291748047 sec\n",
      "loss 2.308868, train acc 0.100775\n",
      "round 129\n",
      "time to device 0.007070 sec\n",
      "time forward 1.487781 sec\n",
      "loss time 0.000881 sec\n",
      "backward time 0.007858 sec\n",
      "optimizer time 0.017978 sec\n",
      "training time in round 129 cost 0.40262603759765625 sec\n",
      "loss 2.308802, train acc 0.100781\n",
      "round 130\n",
      "time to device 0.007633 sec\n",
      "time forward 1.498166 sec\n",
      "loss time 0.001120 sec\n",
      "backward time 0.011238 sec\n",
      "optimizer time 0.038203 sec\n",
      "training time in round 130 cost 0.4035031795501709 sec\n",
      "loss 2.308743, train acc 0.101145\n",
      "round 131\n",
      "time to device 0.006450 sec\n",
      "time forward 1.509790 sec\n",
      "loss time 0.000989 sec\n",
      "backward time 0.013638 sec\n",
      "optimizer time 0.031627 sec\n",
      "training time in round 131 cost 0.40422773361206055 sec\n",
      "loss 2.308727, train acc 0.100852\n",
      "round 132\n",
      "time to device 0.006690 sec\n",
      "time forward 1.527060 sec\n",
      "loss time 0.000974 sec\n",
      "backward time 0.013514 sec\n",
      "optimizer time 0.028677 sec\n",
      "training time in round 132 cost 0.4178750514984131 sec\n",
      "loss 2.308689, train acc 0.101034\n",
      "round 133\n",
      "time to device 0.006539 sec\n",
      "time forward 1.538500 sec\n",
      "loss time 0.001164 sec\n",
      "backward time 0.013192 sec\n",
      "optimizer time 0.027634 sec\n",
      "training time in round 133 cost 0.3964121341705322 sec\n",
      "loss 2.308642, train acc 0.100863\n",
      "round 134\n",
      "time to device 0.006556 sec\n",
      "time forward 1.546906 sec\n",
      "loss time 0.000907 sec\n",
      "backward time 0.007928 sec\n",
      "optimizer time 0.018193 sec\n",
      "training time in round 134 cost 0.37429332733154297 sec\n",
      "loss 2.308612, train acc 0.100984\n",
      "round 135\n",
      "time to device 0.006467 sec\n",
      "time forward 1.558219 sec\n",
      "loss time 0.001658 sec\n",
      "backward time 0.010085 sec\n",
      "optimizer time 0.028447 sec\n",
      "training time in round 135 cost 0.39113712310791016 sec\n",
      "loss 2.308520, train acc 0.101103\n",
      "round 136\n",
      "time to device 0.005365 sec\n",
      "time forward 1.569401 sec\n",
      "loss time 0.001358 sec\n",
      "backward time 0.011449 sec\n",
      "optimizer time 0.025384 sec\n",
      "training time in round 136 cost 0.3860361576080322 sec\n",
      "loss 2.308488, train acc 0.100992\n",
      "round 137\n",
      "time to device 0.003732 sec\n",
      "time forward 1.580534 sec\n",
      "loss time 0.001205 sec\n",
      "backward time 0.015175 sec\n",
      "optimizer time 0.021554 sec\n",
      "training time in round 137 cost 0.39493608474731445 sec\n",
      "loss 2.308397, train acc 0.100940\n",
      "round 138\n",
      "time to device 0.003825 sec\n",
      "time forward 1.592246 sec\n",
      "loss time 0.000933 sec\n",
      "backward time 0.011238 sec\n",
      "optimizer time 0.035908 sec\n",
      "training time in round 138 cost 0.43300700187683105 sec\n",
      "loss 2.308357, train acc 0.101113\n",
      "round 139\n",
      "time to device 0.008020 sec\n",
      "time forward 1.598527 sec\n",
      "loss time 0.000584 sec\n",
      "backward time 0.004405 sec\n",
      "optimizer time 0.015462 sec\n",
      "training time in round 139 cost 0.38248181343078613 sec\n",
      "loss 2.308334, train acc 0.101116\n",
      "round 140\n",
      "time to device 0.007814 sec\n",
      "time forward 1.613058 sec\n",
      "loss time 0.001452 sec\n",
      "backward time 0.010416 sec\n",
      "optimizer time 0.020717 sec\n",
      "training time in round 140 cost 0.40215516090393066 sec\n",
      "loss 2.308273, train acc 0.101452\n",
      "round 141\n",
      "time to device 0.006200 sec\n",
      "time forward 1.629004 sec\n",
      "loss time 0.001072 sec\n",
      "backward time 0.011565 sec\n",
      "optimizer time 0.017947 sec\n",
      "training time in round 141 cost 0.41376495361328125 sec\n",
      "loss 2.308259, train acc 0.101287\n",
      "round 142\n",
      "time to device 0.006579 sec\n",
      "time forward 1.646209 sec\n",
      "loss time 0.001248 sec\n",
      "backward time 0.017402 sec\n",
      "optimizer time 0.032982 sec\n",
      "training time in round 142 cost 0.43430089950561523 sec\n",
      "loss 2.308223, train acc 0.101453\n",
      "round 143\n",
      "time to device 0.006852 sec\n",
      "time forward 1.657675 sec\n",
      "loss time 0.001048 sec\n",
      "backward time 0.011474 sec\n",
      "optimizer time 0.021497 sec\n",
      "training time in round 143 cost 0.40485405921936035 sec\n",
      "loss 2.308178, train acc 0.101671\n",
      "round 144\n",
      "time to device 0.007519 sec\n",
      "time forward 1.664405 sec\n",
      "loss time 0.000760 sec\n",
      "backward time 0.007156 sec\n",
      "optimizer time 0.017148 sec\n",
      "training time in round 144 cost 0.37808895111083984 sec\n",
      "loss 2.308144, train acc 0.101778\n",
      "round 145\n",
      "time to device 0.007181 sec\n",
      "time forward 1.677791 sec\n",
      "loss time 0.000966 sec\n",
      "backward time 0.013763 sec\n",
      "optimizer time 0.030351 sec\n",
      "training time in round 145 cost 0.4125790596008301 sec\n",
      "loss 2.308082, train acc 0.101777\n",
      "round 146\n",
      "time to device 0.006894 sec\n",
      "time forward 1.689423 sec\n",
      "loss time 0.000566 sec\n",
      "backward time 0.005286 sec\n",
      "optimizer time 0.014014 sec\n",
      "training time in round 146 cost 0.37889885902404785 sec\n",
      "loss 2.308045, train acc 0.101775\n",
      "round 147\n",
      "time to device 0.006559 sec\n",
      "time forward 1.701201 sec\n",
      "loss time 0.001011 sec\n",
      "backward time 0.012823 sec\n",
      "optimizer time 0.027945 sec\n",
      "training time in round 147 cost 0.39373183250427246 sec\n",
      "loss 2.308074, train acc 0.101615\n",
      "round 148\n",
      "time to device 0.007042 sec\n",
      "time forward 1.712148 sec\n",
      "loss time 0.000952 sec\n",
      "backward time 0.013152 sec\n",
      "optimizer time 0.026901 sec\n",
      "training time in round 148 cost 0.38969969749450684 sec\n",
      "loss 2.308051, train acc 0.101772\n",
      "round 149\n",
      "time to device 0.006547 sec\n",
      "time forward 1.719835 sec\n",
      "loss time 0.000714 sec\n",
      "backward time 0.006613 sec\n",
      "optimizer time 0.016216 sec\n",
      "training time in round 149 cost 0.3661060333251953 sec\n",
      "loss 2.308016, train acc 0.101823\n",
      "round 150\n",
      "time to device 0.005752 sec\n",
      "time forward 1.733818 sec\n",
      "loss time 0.001186 sec\n",
      "backward time 0.013441 sec\n",
      "optimizer time 0.026688 sec\n",
      "training time in round 150 cost 0.4058949947357178 sec\n",
      "loss 2.308015, train acc 0.101666\n",
      "round 151\n",
      "time to device 0.003268 sec\n",
      "time forward 1.744462 sec\n",
      "loss time 0.001067 sec\n",
      "backward time 0.012167 sec\n",
      "optimizer time 0.025541 sec\n",
      "training time in round 151 cost 0.390427827835083 sec\n",
      "loss 2.308014, train acc 0.101562\n",
      "round 152\n",
      "time to device 0.003582 sec\n",
      "time forward 1.756550 sec\n",
      "loss time 0.001504 sec\n",
      "backward time 0.024832 sec\n",
      "optimizer time 0.012082 sec\n",
      "training time in round 152 cost 0.46685099601745605 sec\n",
      "loss 2.308005, train acc 0.101460\n",
      "round 153\n",
      "time to device 0.006728 sec\n",
      "time forward 1.767089 sec\n",
      "loss time 0.001307 sec\n",
      "backward time 0.010739 sec\n",
      "optimizer time 0.028479 sec\n",
      "training time in round 153 cost 0.4194040298461914 sec\n",
      "loss 2.307967, train acc 0.101461\n",
      "round 154\n",
      "time to device 0.006885 sec\n",
      "time forward 1.774832 sec\n",
      "loss time 0.000778 sec\n",
      "backward time 0.007037 sec\n",
      "optimizer time 0.020371 sec\n",
      "training time in round 154 cost 0.3782658576965332 sec\n",
      "loss 2.307963, train acc 0.101411\n",
      "round 155\n",
      "time to device 0.006305 sec\n",
      "time forward 1.786062 sec\n",
      "loss time 0.000971 sec\n",
      "backward time 0.013427 sec\n",
      "optimizer time 0.034688 sec\n",
      "training time in round 155 cost 0.40020203590393066 sec\n",
      "loss 2.307957, train acc 0.101362\n",
      "round 156\n",
      "time to device 0.006266 sec\n",
      "time forward 1.796644 sec\n",
      "loss time 0.001051 sec\n",
      "backward time 0.013006 sec\n",
      "optimizer time 0.027795 sec\n",
      "training time in round 156 cost 0.38982391357421875 sec\n",
      "loss 2.308010, train acc 0.101015\n",
      "round 157\n",
      "time to device 0.006300 sec\n",
      "time forward 1.808441 sec\n",
      "loss time 0.000968 sec\n",
      "backward time 0.011912 sec\n",
      "optimizer time 0.027035 sec\n",
      "training time in round 157 cost 0.40836668014526367 sec\n",
      "loss 2.308023, train acc 0.100870\n",
      "round 158\n",
      "time to device 0.007166 sec\n",
      "time forward 1.823449 sec\n",
      "loss time 0.000981 sec\n",
      "backward time 0.011828 sec\n",
      "optimizer time 0.026444 sec\n",
      "training time in round 158 cost 0.4186701774597168 sec\n",
      "loss 2.307974, train acc 0.100973\n",
      "round 159\n",
      "time to device 0.007571 sec\n",
      "time forward 1.832208 sec\n",
      "loss time 0.000703 sec\n",
      "backward time 0.009688 sec\n",
      "optimizer time 0.033755 sec\n",
      "training time in round 159 cost 0.40146803855895996 sec\n",
      "loss 2.307936, train acc 0.101074\n",
      "round 160\n",
      "time to device 0.006508 sec\n",
      "time forward 1.844796 sec\n",
      "loss time 0.001643 sec\n",
      "backward time 0.011250 sec\n",
      "optimizer time 0.028575 sec\n",
      "training time in round 160 cost 0.45429182052612305 sec\n",
      "loss 2.307886, train acc 0.100980\n",
      "round 161\n",
      "time to device 0.006435 sec\n",
      "time forward 1.855641 sec\n",
      "loss time 0.001259 sec\n",
      "backward time 0.018998 sec\n",
      "optimizer time 0.024796 sec\n",
      "training time in round 161 cost 0.39879608154296875 sec\n",
      "loss 2.307867, train acc 0.100694\n",
      "round 162\n",
      "time to device 0.006514 sec\n",
      "time forward 1.866975 sec\n",
      "loss time 0.001258 sec\n",
      "backward time 0.013945 sec\n",
      "optimizer time 0.029699 sec\n",
      "training time in round 162 cost 0.3972742557525635 sec\n",
      "loss 2.307832, train acc 0.100891\n",
      "round 163\n",
      "time to device 0.006582 sec\n",
      "time forward 1.877815 sec\n",
      "loss time 0.001043 sec\n",
      "backward time 0.010356 sec\n",
      "optimizer time 0.029057 sec\n",
      "training time in round 163 cost 0.42833995819091797 sec\n",
      "loss 2.307791, train acc 0.101038\n",
      "round 164\n",
      "time to device 0.007155 sec\n",
      "time forward 1.885441 sec\n",
      "loss time 0.000736 sec\n",
      "backward time 0.006676 sec\n",
      "optimizer time 0.016922 sec\n",
      "training time in round 164 cost 0.36725807189941406 sec\n",
      "loss 2.307770, train acc 0.100900\n",
      "round 165\n",
      "time to device 0.006606 sec\n",
      "time forward 1.897358 sec\n",
      "loss time 0.001184 sec\n",
      "backward time 0.014693 sec\n",
      "optimizer time 0.025975 sec\n",
      "training time in round 165 cost 0.39832615852355957 sec\n",
      "loss 2.307729, train acc 0.100809\n",
      "round 166\n",
      "time to device 0.006366 sec\n",
      "time forward 1.914832 sec\n",
      "loss time 0.001064 sec\n",
      "backward time 0.010956 sec\n",
      "optimizer time 0.031493 sec\n",
      "training time in round 166 cost 0.42105603218078613 sec\n",
      "loss 2.307650, train acc 0.100767\n",
      "round 167\n",
      "time to device 0.006755 sec\n",
      "time forward 1.922347 sec\n",
      "loss time 0.000496 sec\n",
      "backward time 0.003818 sec\n",
      "optimizer time 0.011712 sec\n",
      "training time in round 167 cost 0.3603379726409912 sec\n",
      "loss 2.307648, train acc 0.100632\n",
      "round 168\n",
      "time to device 0.006172 sec\n",
      "time forward 1.934147 sec\n",
      "loss time 0.001032 sec\n",
      "backward time 0.010836 sec\n",
      "optimizer time 0.029988 sec\n",
      "training time in round 168 cost 0.3979990482330322 sec\n",
      "loss 2.307622, train acc 0.100869\n",
      "round 169\n",
      "time to device 0.006359 sec\n",
      "time forward 1.943340 sec\n",
      "loss time 0.001104 sec\n",
      "backward time 0.008434 sec\n",
      "optimizer time 0.019009 sec\n",
      "training time in round 169 cost 0.3762838840484619 sec\n",
      "loss 2.307607, train acc 0.100827\n",
      "round 170\n",
      "time to device 0.003136 sec\n",
      "time forward 1.954899 sec\n",
      "loss time 0.001139 sec\n",
      "backward time 0.010126 sec\n",
      "optimizer time 0.028416 sec\n",
      "training time in round 170 cost 0.3893892765045166 sec\n",
      "loss 2.307532, train acc 0.101014\n",
      "round 171\n",
      "time to device 0.004156 sec\n",
      "time forward 1.964995 sec\n",
      "loss time 0.000988 sec\n",
      "backward time 0.012414 sec\n",
      "optimizer time 0.026913 sec\n",
      "training time in round 171 cost 0.38643813133239746 sec\n",
      "loss 2.307533, train acc 0.100927\n",
      "round 172\n",
      "time to device 0.003283 sec\n",
      "time forward 1.976335 sec\n",
      "loss time 0.001170 sec\n",
      "backward time 0.012754 sec\n",
      "optimizer time 0.027931 sec\n",
      "training time in round 172 cost 0.3937809467315674 sec\n",
      "loss 2.307514, train acc 0.100795\n",
      "round 173\n",
      "time to device 0.004084 sec\n",
      "time forward 1.987495 sec\n",
      "loss time 0.001118 sec\n",
      "backward time 0.009483 sec\n",
      "optimizer time 0.029904 sec\n",
      "training time in round 173 cost 0.3908562660217285 sec\n",
      "loss 2.307559, train acc 0.101069\n",
      "round 174\n",
      "time to device 0.003618 sec\n",
      "time forward 1.995730 sec\n",
      "loss time 0.000763 sec\n",
      "backward time 0.006765 sec\n",
      "optimizer time 0.017372 sec\n",
      "training time in round 174 cost 0.3658928871154785 sec\n",
      "loss 2.307520, train acc 0.101295\n",
      "round 175\n",
      "time to device 0.004248 sec\n",
      "time forward 2.007906 sec\n",
      "loss time 0.000993 sec\n",
      "backward time 0.012053 sec\n",
      "optimizer time 0.027412 sec\n",
      "training time in round 175 cost 0.394503116607666 sec\n",
      "loss 2.307526, train acc 0.101074\n",
      "round 176\n",
      "time to device 0.004098 sec\n",
      "time forward 2.017691 sec\n",
      "loss time 0.000978 sec\n",
      "backward time 0.010219 sec\n",
      "optimizer time 0.022038 sec\n",
      "training time in round 176 cost 0.3791511058807373 sec\n",
      "loss 2.307485, train acc 0.100945\n",
      "round 177\n",
      "time to device 0.004144 sec\n",
      "time forward 2.030464 sec\n",
      "loss time 0.001160 sec\n",
      "backward time 0.022380 sec\n",
      "optimizer time 0.015254 sec\n",
      "training time in round 177 cost 0.43515706062316895 sec\n",
      "loss 2.307490, train acc 0.100948\n",
      "round 178\n",
      "time to device 0.006503 sec\n",
      "time forward 2.041832 sec\n",
      "loss time 0.001562 sec\n",
      "backward time 0.012805 sec\n",
      "optimizer time 0.018966 sec\n",
      "training time in round 178 cost 0.393496036529541 sec\n",
      "loss 2.307469, train acc 0.100951\n",
      "round 179\n",
      "time to device 0.006482 sec\n",
      "time forward 2.050630 sec\n",
      "loss time 0.000907 sec\n",
      "backward time 0.007023 sec\n",
      "optimizer time 0.017095 sec\n",
      "training time in round 179 cost 0.3855459690093994 sec\n",
      "loss 2.307424, train acc 0.101085\n",
      "round 180\n",
      "time to device 0.007240 sec\n",
      "time forward 2.061512 sec\n",
      "loss time 0.000972 sec\n",
      "backward time 0.013647 sec\n",
      "optimizer time 0.027251 sec\n",
      "training time in round 180 cost 0.4275779724121094 sec\n",
      "loss 2.307385, train acc 0.101174\n",
      "round 181\n",
      "time to device 0.007319 sec\n",
      "time forward 2.071591 sec\n",
      "loss time 0.000877 sec\n",
      "backward time 0.007185 sec\n",
      "optimizer time 0.017124 sec\n",
      "training time in round 181 cost 0.38287997245788574 sec\n",
      "loss 2.307344, train acc 0.100962\n",
      "round 182\n",
      "time to device 0.007776 sec\n",
      "time forward 2.083813 sec\n",
      "loss time 0.001135 sec\n",
      "backward time 0.018512 sec\n",
      "optimizer time 0.021246 sec\n",
      "training time in round 182 cost 0.4132668972015381 sec\n",
      "loss 2.307368, train acc 0.100965\n",
      "round 183\n",
      "time to device 0.006727 sec\n",
      "time forward 2.094687 sec\n",
      "loss time 0.001859 sec\n",
      "backward time 0.009494 sec\n",
      "optimizer time 0.027764 sec\n",
      "training time in round 183 cost 0.4034411907196045 sec\n",
      "loss 2.307310, train acc 0.101138\n",
      "round 184\n",
      "time to device 0.007354 sec\n",
      "time forward 2.108663 sec\n",
      "loss time 0.000920 sec\n",
      "backward time 0.011880 sec\n",
      "optimizer time 0.027966 sec\n",
      "training time in round 184 cost 0.4139389991760254 sec\n",
      "loss 2.307247, train acc 0.101014\n",
      "round 185\n",
      "time to device 0.007300 sec\n",
      "time forward 2.120579 sec\n",
      "loss time 0.001415 sec\n",
      "backward time 0.011714 sec\n",
      "optimizer time 0.024823 sec\n",
      "training time in round 185 cost 0.39072108268737793 sec\n",
      "loss 2.307171, train acc 0.101016\n",
      "round 186\n",
      "time to device 0.006626 sec\n",
      "time forward 2.128542 sec\n",
      "loss time 0.000836 sec\n",
      "backward time 0.006951 sec\n",
      "optimizer time 0.017252 sec\n",
      "training time in round 186 cost 0.37737083435058594 sec\n",
      "loss 2.307197, train acc 0.100769\n",
      "round 187\n",
      "time to device 0.003684 sec\n",
      "time forward 2.139696 sec\n",
      "loss time 0.001000 sec\n",
      "backward time 0.012286 sec\n",
      "optimizer time 0.026564 sec\n",
      "training time in round 187 cost 0.38926196098327637 sec\n",
      "loss 2.307199, train acc 0.101022\n",
      "round 188\n",
      "time to device 0.003283 sec\n",
      "time forward 2.148669 sec\n",
      "loss time 0.000635 sec\n",
      "backward time 0.005752 sec\n",
      "optimizer time 0.015319 sec\n",
      "training time in round 188 cost 0.3696939945220947 sec\n",
      "loss 2.307145, train acc 0.101190\n",
      "round 189\n",
      "time to device 0.004020 sec\n",
      "time forward 2.159738 sec\n",
      "loss time 0.001073 sec\n",
      "backward time 0.016149 sec\n",
      "optimizer time 0.026039 sec\n",
      "training time in round 189 cost 0.3992881774902344 sec\n",
      "loss 2.307116, train acc 0.101192\n",
      "round 190\n",
      "time to device 0.004467 sec\n",
      "time forward 2.174029 sec\n",
      "loss time 0.001812 sec\n",
      "backward time 0.011259 sec\n",
      "optimizer time 0.029225 sec\n",
      "training time in round 190 cost 0.47771191596984863 sec\n",
      "loss 2.306999, train acc 0.101317\n",
      "round 191\n",
      "time to device 0.007644 sec\n",
      "time forward 2.185003 sec\n",
      "loss time 0.000960 sec\n",
      "backward time 0.008726 sec\n",
      "optimizer time 0.018587 sec\n",
      "training time in round 191 cost 0.3907201290130615 sec\n",
      "loss 2.307047, train acc 0.101318\n",
      "round 192\n",
      "time to device 0.006385 sec\n",
      "time forward 2.196301 sec\n",
      "loss time 0.000995 sec\n",
      "backward time 0.011974 sec\n",
      "optimizer time 0.029327 sec\n",
      "training time in round 192 cost 0.41483521461486816 sec\n",
      "loss 2.306989, train acc 0.101441\n",
      "round 193\n",
      "time to device 0.006091 sec\n",
      "time forward 2.208354 sec\n",
      "loss time 0.001413 sec\n",
      "backward time 0.010715 sec\n",
      "optimizer time 0.028292 sec\n",
      "training time in round 193 cost 0.397996187210083 sec\n",
      "loss 2.306986, train acc 0.101442\n",
      "round 194\n",
      "time to device 0.006924 sec\n",
      "time forward 2.222804 sec\n",
      "loss time 0.001563 sec\n",
      "backward time 0.013338 sec\n",
      "optimizer time 0.029046 sec\n",
      "training time in round 194 cost 0.4318709373474121 sec\n",
      "loss 2.306948, train acc 0.101522\n",
      "round 195\n",
      "time to device 0.008894 sec\n",
      "time forward 2.234532 sec\n",
      "loss time 0.001072 sec\n",
      "backward time 0.010246 sec\n",
      "optimizer time 0.026380 sec\n",
      "training time in round 195 cost 0.42898106575012207 sec\n",
      "loss 2.307173, train acc 0.101363\n",
      "round 196\n",
      "time to device 0.007783 sec\n",
      "time forward 2.252303 sec\n",
      "loss time 0.001200 sec\n",
      "backward time 0.007800 sec\n",
      "optimizer time 0.014556 sec\n",
      "training time in round 196 cost 0.4243030548095703 sec\n",
      "loss 2.307525, train acc 0.101523\n",
      "round 197\n",
      "time to device 0.008519 sec\n",
      "time forward 2.262448 sec\n",
      "loss time 0.000943 sec\n",
      "backward time 0.011023 sec\n",
      "optimizer time 0.023880 sec\n",
      "training time in round 197 cost 0.4039177894592285 sec\n",
      "loss 2.307499, train acc 0.101444\n",
      "round 198\n",
      "time to device 0.008594 sec\n",
      "time forward 2.275350 sec\n",
      "loss time 0.001694 sec\n",
      "backward time 0.013619 sec\n",
      "optimizer time 0.022868 sec\n",
      "training time in round 198 cost 0.3990447521209717 sec\n",
      "loss 2.307469, train acc 0.101445\n",
      "round 199\n",
      "time to device 0.006680 sec\n",
      "time forward 2.286456 sec\n",
      "loss time 0.002049 sec\n",
      "backward time 0.016076 sec\n",
      "optimizer time 0.030080 sec\n",
      "training time in round 199 cost 0.42084598541259766 sec\n",
      "loss 2.307473, train acc 0.101445\n",
      "round 200\n",
      "time to device 0.008554 sec\n",
      "time forward 2.296941 sec\n",
      "loss time 0.001021 sec\n",
      "backward time 0.012524 sec\n",
      "optimizer time 0.019823 sec\n",
      "training time in round 200 cost 0.46728515625 sec\n",
      "loss 2.307474, train acc 0.101096\n",
      "round 201\n",
      "time to device 0.007304 sec\n",
      "time forward 2.309098 sec\n",
      "loss time 0.001011 sec\n",
      "backward time 0.014457 sec\n",
      "optimizer time 0.017540 sec\n",
      "training time in round 201 cost 0.4714949131011963 sec\n",
      "loss 2.307605, train acc 0.101060\n",
      "round 202\n",
      "time to device 0.008108 sec\n",
      "time forward 2.325400 sec\n",
      "loss time 0.001362 sec\n",
      "backward time 0.022339 sec\n",
      "optimizer time 0.015638 sec\n",
      "training time in round 202 cost 0.43538618087768555 sec\n",
      "loss 2.307572, train acc 0.100908\n",
      "round 203\n",
      "time to device 0.007927 sec\n",
      "time forward 2.338001 sec\n",
      "loss time 0.001340 sec\n",
      "backward time 0.014079 sec\n",
      "optimizer time 0.022093 sec\n",
      "training time in round 203 cost 0.4821949005126953 sec\n",
      "loss 2.307551, train acc 0.100758\n",
      "round 204\n",
      "time to device 0.006634 sec\n",
      "time forward 2.354728 sec\n",
      "loss time 0.001220 sec\n",
      "backward time 0.007725 sec\n",
      "optimizer time 0.017525 sec\n",
      "training time in round 204 cost 0.426074743270874 sec\n",
      "loss 2.307558, train acc 0.100534\n",
      "round 205\n",
      "time to device 0.006818 sec\n",
      "time forward 2.370896 sec\n",
      "loss time 0.001137 sec\n",
      "backward time 0.010037 sec\n",
      "optimizer time 0.027927 sec\n",
      "training time in round 205 cost 0.41757917404174805 sec\n",
      "loss 2.307547, train acc 0.100539\n",
      "round 206\n",
      "time to device 0.005368 sec\n",
      "time forward 2.376717 sec\n",
      "loss time 0.000697 sec\n",
      "backward time 0.005452 sec\n",
      "optimizer time 0.016578 sec\n",
      "training time in round 206 cost 0.3854560852050781 sec\n",
      "loss 2.307562, train acc 0.100430\n",
      "round 207\n",
      "time to device 0.015235 sec\n",
      "time forward 2.387020 sec\n",
      "loss time 0.000465 sec\n",
      "backward time 0.005437 sec\n",
      "optimizer time 0.011887 sec\n",
      "training time in round 207 cost 0.42360496520996094 sec\n",
      "loss 2.307549, train acc 0.100361\n",
      "round 208\n",
      "time to device 0.006700 sec\n",
      "time forward 2.393958 sec\n",
      "loss time 0.000424 sec\n",
      "backward time 0.003817 sec\n",
      "optimizer time 0.012800 sec\n",
      "training time in round 208 cost 0.3957839012145996 sec\n",
      "loss 2.307534, train acc 0.100292\n",
      "round 209\n",
      "time to device 0.005608 sec\n",
      "time forward 2.399827 sec\n",
      "loss time 0.000481 sec\n",
      "backward time 0.004315 sec\n",
      "optimizer time 0.014488 sec\n",
      "training time in round 209 cost 0.3766148090362549 sec\n",
      "loss 2.307506, train acc 0.100446\n",
      "round 210\n",
      "time to device 0.006926 sec\n",
      "time forward 2.409203 sec\n",
      "loss time 0.000890 sec\n",
      "backward time 0.007585 sec\n",
      "optimizer time 0.019918 sec\n",
      "training time in round 210 cost 0.4179971218109131 sec\n",
      "loss 2.307473, train acc 0.100415\n",
      "round 211\n",
      "time to device 0.013885 sec\n",
      "time forward 2.419199 sec\n",
      "loss time 0.000910 sec\n",
      "backward time 0.008682 sec\n",
      "optimizer time 0.021551 sec\n",
      "training time in round 211 cost 0.4180259704589844 sec\n",
      "loss 2.307483, train acc 0.100310\n",
      "round 212\n",
      "time to device 0.008009 sec\n",
      "time forward 2.431319 sec\n",
      "loss time 0.001017 sec\n",
      "backward time 0.008185 sec\n",
      "optimizer time 0.020201 sec\n",
      "training time in round 212 cost 0.3950767517089844 sec\n",
      "loss 2.307441, train acc 0.100169\n",
      "round 213\n",
      "time to device 0.006782 sec\n",
      "time forward 2.437765 sec\n",
      "loss time 0.000658 sec\n",
      "backward time 0.005552 sec\n",
      "optimizer time 0.016209 sec\n",
      "training time in round 213 cost 0.3888227939605713 sec\n",
      "loss 2.307432, train acc 0.100321\n",
      "round 214\n",
      "time to device 0.004962 sec\n",
      "time forward 2.443671 sec\n",
      "loss time 0.000428 sec\n",
      "backward time 0.004362 sec\n",
      "optimizer time 0.012844 sec\n",
      "training time in round 214 cost 0.3704040050506592 sec\n",
      "loss 2.307417, train acc 0.100254\n",
      "round 215\n",
      "time to device 0.005309 sec\n",
      "time forward 2.449126 sec\n",
      "loss time 0.000569 sec\n",
      "backward time 0.004807 sec\n",
      "optimizer time 0.014564 sec\n",
      "training time in round 215 cost 0.36722517013549805 sec\n",
      "loss 2.307395, train acc 0.100369\n",
      "round 216\n",
      "time to device 0.007091 sec\n",
      "time forward 2.456236 sec\n",
      "loss time 0.000480 sec\n",
      "backward time 0.005696 sec\n",
      "optimizer time 0.013529 sec\n",
      "training time in round 216 cost 0.3661320209503174 sec\n",
      "loss 2.307367, train acc 0.100446\n",
      "round 217\n",
      "time to device 0.009860 sec\n",
      "time forward 2.463756 sec\n",
      "loss time 0.000618 sec\n",
      "backward time 0.005968 sec\n",
      "optimizer time 0.018012 sec\n",
      "training time in round 217 cost 0.5044019222259521 sec\n",
      "loss 2.307339, train acc 0.100523\n",
      "round 218\n",
      "time to device 0.007663 sec\n",
      "time forward 2.481709 sec\n",
      "loss time 0.003380 sec\n",
      "backward time 0.020056 sec\n",
      "optimizer time 0.029898 sec\n",
      "training time in round 218 cost 0.4391610622406006 sec\n",
      "loss 2.307349, train acc 0.100421\n",
      "round 219\n",
      "time to device 0.009304 sec\n",
      "time forward 2.494140 sec\n",
      "loss time 0.001530 sec\n",
      "backward time 0.014382 sec\n",
      "optimizer time 0.023312 sec\n",
      "training time in round 219 cost 0.4094548225402832 sec\n",
      "loss 2.307300, train acc 0.100533\n",
      "round 220\n",
      "time to device 0.008087 sec\n",
      "time forward 2.517013 sec\n",
      "loss time 0.000413 sec\n",
      "backward time 0.003964 sec\n",
      "optimizer time 0.012647 sec\n",
      "training time in round 220 cost 0.39783287048339844 sec\n",
      "loss 2.307251, train acc 0.100537\n",
      "round 221\n",
      "time to device 0.006709 sec\n",
      "time forward 2.530360 sec\n",
      "loss time 0.003835 sec\n",
      "backward time 0.018364 sec\n",
      "optimizer time 0.025170 sec\n",
      "training time in round 221 cost 0.4756910800933838 sec\n",
      "loss 2.307251, train acc 0.100401\n",
      "round 222\n",
      "time to device 0.007225 sec\n",
      "time forward 2.543366 sec\n",
      "loss time 0.002063 sec\n",
      "backward time 0.027004 sec\n",
      "optimizer time 0.020653 sec\n",
      "training time in round 222 cost 0.4129040241241455 sec\n",
      "loss 2.307221, train acc 0.100371\n",
      "round 223\n",
      "time to device 0.006294 sec\n",
      "time forward 2.554722 sec\n",
      "loss time 0.001726 sec\n",
      "backward time 0.022977 sec\n",
      "optimizer time 0.025500 sec\n",
      "training time in round 223 cost 0.4390079975128174 sec\n",
      "loss 2.307221, train acc 0.100342\n",
      "round 224\n",
      "time to device 0.009309 sec\n",
      "time forward 2.566972 sec\n",
      "loss time 0.001551 sec\n",
      "backward time 0.015913 sec\n",
      "optimizer time 0.024535 sec\n",
      "training time in round 224 cost 0.479694128036499 sec\n",
      "loss 2.307202, train acc 0.100208\n",
      "round 225\n",
      "time to device 0.009672 sec\n",
      "time forward 2.577333 sec\n",
      "loss time 0.000934 sec\n",
      "backward time 0.010743 sec\n",
      "optimizer time 0.021235 sec\n",
      "training time in round 225 cost 0.4018690586090088 sec\n",
      "loss 2.307165, train acc 0.100318\n",
      "round 226\n",
      "time to device 0.008941 sec\n",
      "time forward 2.588708 sec\n",
      "loss time 0.001077 sec\n",
      "backward time 0.012421 sec\n",
      "optimizer time 0.027492 sec\n",
      "training time in round 226 cost 0.4130871295928955 sec\n",
      "loss 2.307151, train acc 0.100117\n",
      "round 227\n",
      "time to device 0.009459 sec\n",
      "time forward 2.595826 sec\n",
      "loss time 0.000740 sec\n",
      "backward time 0.006710 sec\n",
      "optimizer time 0.016472 sec\n",
      "training time in round 227 cost 0.3700852394104004 sec\n",
      "loss 2.307146, train acc 0.100260\n",
      "round 228\n",
      "time to device 0.009345 sec\n",
      "time forward 2.610475 sec\n",
      "loss time 0.001077 sec\n",
      "backward time 0.017574 sec\n",
      "optimizer time 0.021147 sec\n",
      "training time in round 228 cost 0.4040250778198242 sec\n",
      "loss 2.307134, train acc 0.100334\n",
      "round 229\n",
      "time to device 0.006948 sec\n",
      "time forward 2.623700 sec\n",
      "loss time 0.001296 sec\n",
      "backward time 0.014057 sec\n",
      "optimizer time 0.026805 sec\n",
      "training time in round 229 cost 0.40793299674987793 sec\n",
      "loss 2.307124, train acc 0.100374\n",
      "round 230\n",
      "time to device 0.007200 sec\n",
      "time forward 2.636410 sec\n",
      "loss time 0.001873 sec\n",
      "backward time 0.014859 sec\n",
      "optimizer time 0.026040 sec\n",
      "training time in round 230 cost 0.4058675765991211 sec\n",
      "loss 2.307119, train acc 0.100244\n",
      "round 231\n",
      "time to device 0.007452 sec\n",
      "time forward 2.645985 sec\n",
      "loss time 0.000738 sec\n",
      "backward time 0.006623 sec\n",
      "optimizer time 0.016279 sec\n",
      "training time in round 231 cost 0.3622398376464844 sec\n",
      "loss 2.307131, train acc 0.100283\n",
      "round 232\n",
      "time to device 0.007146 sec\n",
      "time forward 2.661313 sec\n",
      "loss time 0.002452 sec\n",
      "backward time 0.015726 sec\n",
      "optimizer time 0.027740 sec\n",
      "training time in round 232 cost 0.4537637233734131 sec\n",
      "loss 2.307094, train acc 0.100389\n",
      "round 233\n",
      "time to device 0.006802 sec\n",
      "time forward 2.672365 sec\n",
      "loss time 0.001504 sec\n",
      "backward time 0.011209 sec\n",
      "optimizer time 0.021048 sec\n",
      "training time in round 233 cost 0.3943970203399658 sec\n",
      "loss 2.307073, train acc 0.100361\n",
      "round 234\n",
      "time to device 0.009449 sec\n",
      "time forward 2.685122 sec\n",
      "loss time 0.001310 sec\n",
      "backward time 0.019830 sec\n",
      "optimizer time 0.023384 sec\n",
      "training time in round 234 cost 0.40410900115966797 sec\n",
      "loss 2.307042, train acc 0.100465\n",
      "round 235\n",
      "time to device 0.006558 sec\n",
      "time forward 2.692860 sec\n",
      "loss time 0.000411 sec\n",
      "backward time 0.003772 sec\n",
      "optimizer time 0.010930 sec\n",
      "training time in round 235 cost 0.3705179691314697 sec\n",
      "loss 2.306996, train acc 0.100305\n",
      "round 236\n",
      "time to device 0.003544 sec\n",
      "time forward 2.707146 sec\n",
      "loss time 0.001229 sec\n",
      "backward time 0.012090 sec\n",
      "optimizer time 0.023456 sec\n",
      "training time in round 236 cost 0.39057207107543945 sec\n",
      "loss 2.306973, train acc 0.100475\n",
      "round 237\n",
      "time to device 0.003881 sec\n",
      "time forward 2.719512 sec\n",
      "loss time 0.000739 sec\n",
      "backward time 0.007378 sec\n",
      "optimizer time 0.030614 sec\n",
      "training time in round 237 cost 0.3944828510284424 sec\n",
      "loss 2.306950, train acc 0.100381\n",
      "round 238\n",
      "time to device 0.004189 sec\n",
      "time forward 2.733195 sec\n",
      "loss time 0.001639 sec\n",
      "backward time 0.011999 sec\n",
      "optimizer time 0.024997 sec\n",
      "training time in round 238 cost 0.3950982093811035 sec\n",
      "loss 2.306939, train acc 0.100320\n",
      "round 239\n",
      "time to device 0.003526 sec\n",
      "time forward 2.747000 sec\n",
      "loss time 0.002261 sec\n",
      "backward time 0.014140 sec\n",
      "optimizer time 0.027269 sec\n",
      "training time in round 239 cost 0.39386606216430664 sec\n",
      "loss 2.306899, train acc 0.100293\n",
      "round 240\n",
      "time to device 0.003932 sec\n",
      "time forward 2.760745 sec\n",
      "loss time 0.001977 sec\n",
      "backward time 0.014658 sec\n",
      "optimizer time 0.025345 sec\n",
      "training time in round 240 cost 0.39764904975891113 sec\n",
      "loss 2.306878, train acc 0.100363\n",
      "round 241\n",
      "time to device 0.003909 sec\n",
      "time forward 2.775340 sec\n",
      "loss time 0.001219 sec\n",
      "backward time 0.012434 sec\n",
      "optimizer time 0.025892 sec\n",
      "training time in round 241 cost 0.39459991455078125 sec\n",
      "loss 2.306858, train acc 0.100336\n",
      "round 242\n",
      "time to device 0.003244 sec\n",
      "time forward 2.787496 sec\n",
      "loss time 0.001855 sec\n",
      "backward time 0.011694 sec\n",
      "optimizer time 0.022711 sec\n",
      "training time in round 242 cost 0.3828549385070801 sec\n",
      "loss 2.306833, train acc 0.100373\n",
      "round 243\n",
      "time to device 0.002876 sec\n",
      "time forward 2.801456 sec\n",
      "loss time 0.001863 sec\n",
      "backward time 0.013293 sec\n",
      "optimizer time 0.023219 sec\n",
      "training time in round 243 cost 0.39629268646240234 sec\n",
      "loss 2.306839, train acc 0.100410\n",
      "round 244\n",
      "time to device 0.002987 sec\n",
      "time forward 2.809189 sec\n",
      "loss time 0.001082 sec\n",
      "backward time 0.009267 sec\n",
      "optimizer time 0.019582 sec\n",
      "training time in round 244 cost 0.35619497299194336 sec\n",
      "loss 2.306800, train acc 0.100383\n",
      "round 245\n",
      "time to device 0.004616 sec\n",
      "time forward 2.823596 sec\n",
      "loss time 0.002316 sec\n",
      "backward time 0.016121 sec\n",
      "optimizer time 0.028390 sec\n",
      "training time in round 245 cost 0.4352421760559082 sec\n",
      "loss 2.306792, train acc 0.100356\n",
      "round 246\n",
      "time to device 0.003494 sec\n",
      "time forward 2.838289 sec\n",
      "loss time 0.001233 sec\n",
      "backward time 0.014495 sec\n",
      "optimizer time 0.032847 sec\n",
      "training time in round 246 cost 0.4007909297943115 sec\n",
      "loss 2.306836, train acc 0.100487\n",
      "round 247\n",
      "time to device 0.009329 sec\n",
      "time forward 2.846468 sec\n",
      "loss time 0.000533 sec\n",
      "backward time 0.004775 sec\n",
      "optimizer time 0.013968 sec\n",
      "training time in round 247 cost 0.3510560989379883 sec\n",
      "loss 2.306805, train acc 0.100680\n",
      "round 248\n",
      "time to device 0.008857 sec\n",
      "time forward 2.860691 sec\n",
      "loss time 0.001952 sec\n",
      "backward time 0.013619 sec\n",
      "optimizer time 0.026235 sec\n",
      "training time in round 248 cost 0.4148859977722168 sec\n",
      "loss 2.306785, train acc 0.100747\n",
      "round 249\n",
      "time to device 0.007862 sec\n",
      "time forward 2.873586 sec\n",
      "loss time 0.001137 sec\n",
      "backward time 0.010683 sec\n",
      "optimizer time 0.029649 sec\n",
      "training time in round 249 cost 0.393176794052124 sec\n",
      "loss 2.306760, train acc 0.100844\n",
      "round 250\n",
      "time to device 0.008779 sec\n",
      "time forward 2.881000 sec\n",
      "loss time 0.000735 sec\n",
      "backward time 0.006891 sec\n",
      "optimizer time 0.016971 sec\n",
      "training time in round 250 cost 0.3709239959716797 sec\n",
      "loss 2.306778, train acc 0.100940\n",
      "round 251\n",
      "time to device 0.009214 sec\n",
      "time forward 2.891994 sec\n",
      "loss time 0.000999 sec\n",
      "backward time 0.011747 sec\n",
      "optimizer time 0.021040 sec\n",
      "training time in round 251 cost 0.39020514488220215 sec\n",
      "loss 2.306766, train acc 0.100849\n",
      "round 252\n",
      "time to device 0.006966 sec\n",
      "time forward 2.900089 sec\n",
      "loss time 0.000873 sec\n",
      "backward time 0.007359 sec\n",
      "optimizer time 0.018422 sec\n",
      "training time in round 252 cost 0.36113786697387695 sec\n",
      "loss 2.306711, train acc 0.101285\n",
      "round 253\n",
      "time to device 0.007574 sec\n",
      "time forward 2.910755 sec\n",
      "loss time 0.000618 sec\n",
      "backward time 0.005896 sec\n",
      "optimizer time 0.015616 sec\n",
      "training time in round 253 cost 0.3649289608001709 sec\n",
      "loss 2.306729, train acc 0.101347\n",
      "round 254\n",
      "time to device 0.007887 sec\n",
      "time forward 2.920507 sec\n",
      "loss time 0.001352 sec\n",
      "backward time 0.011131 sec\n",
      "optimizer time 0.021646 sec\n",
      "training time in round 254 cost 0.3749198913574219 sec\n",
      "loss 2.306736, train acc 0.101256\n",
      "round 255\n",
      "time to device 0.008351 sec\n",
      "time forward 2.933492 sec\n",
      "loss time 0.001907 sec\n",
      "backward time 0.023162 sec\n",
      "optimizer time 0.014318 sec\n",
      "training time in round 255 cost 0.47876524925231934 sec\n",
      "loss 2.306789, train acc 0.101227\n",
      "round 256\n",
      "time to device 0.007471 sec\n",
      "time forward 2.944980 sec\n",
      "loss time 0.001163 sec\n",
      "backward time 0.011991 sec\n",
      "optimizer time 0.019757 sec\n",
      "training time in round 256 cost 0.42136096954345703 sec\n",
      "loss 2.306837, train acc 0.101289\n",
      "round 257\n",
      "time to device 0.009003 sec\n",
      "time forward 2.960078 sec\n",
      "loss time 0.001863 sec\n",
      "backward time 0.011010 sec\n",
      "optimizer time 0.029043 sec\n",
      "training time in round 257 cost 0.4015219211578369 sec\n",
      "loss 2.306838, train acc 0.101229\n",
      "round 258\n",
      "time to device 0.007161 sec\n",
      "time forward 2.978822 sec\n",
      "loss time 0.000471 sec\n",
      "backward time 0.006163 sec\n",
      "optimizer time 0.016233 sec\n",
      "training time in round 258 cost 0.44341516494750977 sec\n",
      "loss 2.306845, train acc 0.101291\n",
      "round 259\n",
      "time to device 0.006950 sec\n",
      "time forward 2.994565 sec\n",
      "loss time 0.003081 sec\n",
      "backward time 0.017138 sec\n",
      "optimizer time 0.037043 sec\n",
      "training time in round 259 cost 0.4959681034088135 sec\n",
      "loss 2.306849, train acc 0.101142\n",
      "round 260\n",
      "time to device 0.008997 sec\n",
      "time forward 3.006737 sec\n",
      "loss time 0.001168 sec\n",
      "backward time 0.017379 sec\n",
      "optimizer time 0.026134 sec\n",
      "training time in round 260 cost 0.420928955078125 sec\n",
      "loss 2.306840, train acc 0.101024\n",
      "round 261\n",
      "time to device 0.009062 sec\n",
      "time forward 3.015892 sec\n",
      "loss time 0.001229 sec\n",
      "backward time 0.010598 sec\n",
      "optimizer time 0.021805 sec\n",
      "training time in round 261 cost 0.3906400203704834 sec\n",
      "loss 2.306820, train acc 0.100996\n",
      "round 262\n",
      "time to device 0.009663 sec\n",
      "time forward 3.026422 sec\n",
      "loss time 0.001114 sec\n",
      "backward time 0.009572 sec\n",
      "optimizer time 0.014515 sec\n",
      "training time in round 262 cost 0.3943953514099121 sec\n",
      "loss 2.306796, train acc 0.100968\n",
      "round 263\n",
      "time to device 0.006765 sec\n",
      "time forward 3.038645 sec\n",
      "loss time 0.001117 sec\n",
      "backward time 0.011890 sec\n",
      "optimizer time 0.027330 sec\n",
      "training time in round 263 cost 0.4115629196166992 sec\n",
      "loss 2.306775, train acc 0.101000\n",
      "round 264\n",
      "time to device 0.008879 sec\n",
      "time forward 3.049509 sec\n",
      "loss time 0.002991 sec\n",
      "backward time 0.018264 sec\n",
      "optimizer time 0.010909 sec\n",
      "training time in round 264 cost 0.4070119857788086 sec\n",
      "loss 2.306751, train acc 0.101032\n",
      "round 265\n",
      "time to device 0.007561 sec\n",
      "time forward 3.063693 sec\n",
      "loss time 0.001449 sec\n",
      "backward time 0.017618 sec\n",
      "optimizer time 0.027545 sec\n",
      "training time in round 265 cost 0.4523611068725586 sec\n",
      "loss 2.306750, train acc 0.101034\n",
      "round 266\n",
      "time to device 0.006503 sec\n",
      "time forward 3.075464 sec\n",
      "loss time 0.001212 sec\n",
      "backward time 0.015156 sec\n",
      "optimizer time 0.025971 sec\n",
      "training time in round 266 cost 0.4071023464202881 sec\n",
      "loss 2.306711, train acc 0.101124\n",
      "round 267\n",
      "time to device 0.009554 sec\n",
      "time forward 3.089212 sec\n",
      "loss time 0.001303 sec\n",
      "backward time 0.010480 sec\n",
      "optimizer time 0.022941 sec\n",
      "training time in round 267 cost 0.41904592514038086 sec\n",
      "loss 2.306703, train acc 0.101154\n",
      "round 268\n",
      "time to device 0.007232 sec\n",
      "time forward 3.100533 sec\n",
      "loss time 0.000723 sec\n",
      "backward time 0.006214 sec\n",
      "optimizer time 0.015864 sec\n",
      "training time in round 268 cost 0.36969685554504395 sec\n",
      "loss 2.306697, train acc 0.101156\n",
      "round 269\n",
      "time to device 0.007618 sec\n",
      "time forward 3.109716 sec\n",
      "loss time 0.000469 sec\n",
      "backward time 0.006245 sec\n",
      "optimizer time 0.029886 sec\n",
      "training time in round 269 cost 0.3956758975982666 sec\n",
      "loss 2.306709, train acc 0.100926\n",
      "round 270\n",
      "time to device 0.008906 sec\n",
      "time forward 3.123461 sec\n",
      "loss time 0.001961 sec\n",
      "backward time 0.015121 sec\n",
      "optimizer time 0.027181 sec\n",
      "training time in round 270 cost 0.4159243106842041 sec\n",
      "loss 2.306710, train acc 0.100871\n",
      "round 271\n",
      "time to device 0.008064 sec\n",
      "time forward 3.139281 sec\n",
      "loss time 0.001578 sec\n",
      "backward time 0.014069 sec\n",
      "optimizer time 0.028008 sec\n",
      "training time in round 271 cost 0.41430187225341797 sec\n",
      "loss 2.306693, train acc 0.100873\n",
      "round 272\n",
      "time to device 0.006628 sec\n",
      "time forward 3.166598 sec\n",
      "loss time 0.001184 sec\n",
      "backward time 0.013782 sec\n",
      "optimizer time 0.026713 sec\n",
      "training time in round 272 cost 0.40803098678588867 sec\n",
      "loss 2.306672, train acc 0.101047\n",
      "round 273\n",
      "time to device 0.009077 sec\n",
      "time forward 3.180625 sec\n",
      "loss time 0.002142 sec\n",
      "backward time 0.010813 sec\n",
      "optimizer time 0.024412 sec\n",
      "training time in round 273 cost 0.3959789276123047 sec\n",
      "loss 2.306586, train acc 0.101078\n",
      "round 274\n",
      "time to device 0.007126 sec\n",
      "time forward 3.192610 sec\n",
      "loss time 0.001279 sec\n",
      "backward time 0.015513 sec\n",
      "optimizer time 0.024823 sec\n",
      "training time in round 274 cost 0.3948659896850586 sec\n",
      "loss 2.306587, train acc 0.101051\n",
      "round 275\n",
      "time to device 0.003965 sec\n",
      "time forward 3.206219 sec\n",
      "loss time 0.001580 sec\n",
      "backward time 0.012843 sec\n",
      "optimizer time 0.027395 sec\n",
      "training time in round 275 cost 0.3986697196960449 sec\n",
      "loss 2.306568, train acc 0.101110\n",
      "round 276\n",
      "time to device 0.003308 sec\n",
      "time forward 3.218025 sec\n",
      "loss time 0.000914 sec\n",
      "backward time 0.033857 sec\n",
      "optimizer time 0.012746 sec\n",
      "training time in round 276 cost 0.42243075370788574 sec\n",
      "loss 2.306562, train acc 0.100970\n",
      "round 277\n",
      "time to device 0.009308 sec\n",
      "time forward 3.230763 sec\n",
      "loss time 0.001614 sec\n",
      "backward time 0.014122 sec\n",
      "optimizer time 0.028765 sec\n",
      "training time in round 277 cost 0.5037052631378174 sec\n",
      "loss 2.306518, train acc 0.101085\n",
      "round 278\n",
      "time to device 0.030415 sec\n",
      "time forward 3.244009 sec\n",
      "loss time 0.001074 sec\n",
      "backward time 0.013468 sec\n",
      "optimizer time 0.044107 sec\n",
      "training time in round 278 cost 0.4910299777984619 sec\n",
      "loss 2.306498, train acc 0.101086\n",
      "round 279\n",
      "time to device 0.008552 sec\n",
      "time forward 3.250517 sec\n",
      "loss time 0.000415 sec\n",
      "backward time 0.006299 sec\n",
      "optimizer time 0.019260 sec\n",
      "training time in round 279 cost 0.41874194145202637 sec\n",
      "loss 2.306497, train acc 0.100949\n",
      "round 280\n",
      "time to device 0.008554 sec\n",
      "time forward 3.263243 sec\n",
      "loss time 0.001360 sec\n",
      "backward time 0.017147 sec\n",
      "optimizer time 0.022831 sec\n",
      "training time in round 280 cost 0.46437978744506836 sec\n",
      "loss 2.306487, train acc 0.100867\n",
      "round 281\n",
      "time to device 0.005394 sec\n",
      "time forward 3.277192 sec\n",
      "loss time 0.001486 sec\n",
      "backward time 0.012601 sec\n",
      "optimizer time 0.030057 sec\n",
      "training time in round 281 cost 0.4043247699737549 sec\n",
      "loss 2.306487, train acc 0.100953\n",
      "round 282\n",
      "time to device 0.008567 sec\n",
      "time forward 3.287331 sec\n",
      "loss time 0.001085 sec\n",
      "backward time 0.011886 sec\n",
      "optimizer time 0.028225 sec\n",
      "training time in round 282 cost 0.4000833034515381 sec\n",
      "loss 2.306496, train acc 0.100845\n",
      "round 283\n",
      "time to device 0.007266 sec\n",
      "time forward 3.299047 sec\n",
      "loss time 0.000946 sec\n",
      "backward time 0.017924 sec\n",
      "optimizer time 0.026464 sec\n",
      "training time in round 283 cost 0.41405582427978516 sec\n",
      "loss 2.306468, train acc 0.100655\n",
      "round 284\n",
      "time to device 0.009111 sec\n",
      "time forward 3.306881 sec\n",
      "loss time 0.000638 sec\n",
      "backward time 0.006057 sec\n",
      "optimizer time 0.016903 sec\n",
      "training time in round 284 cost 0.3974881172180176 sec\n",
      "loss 2.306515, train acc 0.100521\n",
      "round 285\n",
      "time to device 0.007440 sec\n",
      "time forward 3.319780 sec\n",
      "loss time 0.001658 sec\n",
      "backward time 0.020948 sec\n",
      "optimizer time 0.023444 sec\n",
      "training time in round 285 cost 0.46982789039611816 sec\n",
      "loss 2.306487, train acc 0.100579\n",
      "round 286\n",
      "time to device 0.009584 sec\n",
      "time forward 3.333052 sec\n",
      "loss time 0.001069 sec\n",
      "backward time 0.014256 sec\n",
      "optimizer time 0.035192 sec\n",
      "training time in round 286 cost 0.43486785888671875 sec\n",
      "loss 2.306470, train acc 0.100446\n",
      "round 287\n",
      "time to device 0.006398 sec\n",
      "time forward 3.347054 sec\n",
      "loss time 0.000990 sec\n",
      "backward time 0.012166 sec\n",
      "optimizer time 0.025228 sec\n",
      "training time in round 287 cost 0.39220499992370605 sec\n",
      "loss 2.306434, train acc 0.100586\n",
      "round 288\n",
      "time to device 0.007617 sec\n",
      "time forward 3.357300 sec\n",
      "loss time 0.001248 sec\n",
      "backward time 0.010041 sec\n",
      "optimizer time 0.022847 sec\n",
      "training time in round 288 cost 0.4129903316497803 sec\n",
      "loss 2.306500, train acc 0.100697\n",
      "round 289\n",
      "time to device 0.007444 sec\n",
      "time forward 3.367869 sec\n",
      "loss time 0.001096 sec\n",
      "backward time 0.013773 sec\n",
      "optimizer time 0.023773 sec\n",
      "training time in round 289 cost 0.4199199676513672 sec\n",
      "loss 2.306495, train acc 0.100566\n",
      "round 290\n",
      "time to device 0.007839 sec\n",
      "time forward 3.385393 sec\n",
      "loss time 0.000969 sec\n",
      "backward time 0.014674 sec\n",
      "optimizer time 0.036199 sec\n",
      "training time in round 290 cost 0.42411088943481445 sec\n",
      "loss 2.306486, train acc 0.100623\n",
      "round 291\n",
      "time to device 0.007360 sec\n",
      "time forward 3.396487 sec\n",
      "loss time 0.001612 sec\n",
      "backward time 0.011121 sec\n",
      "optimizer time 0.024773 sec\n",
      "training time in round 291 cost 0.3980832099914551 sec\n",
      "loss 2.306465, train acc 0.100599\n",
      "round 292\n",
      "time to device 0.005862 sec\n",
      "time forward 3.406766 sec\n",
      "loss time 0.000920 sec\n",
      "backward time 0.017884 sec\n",
      "optimizer time 0.012597 sec\n",
      "training time in round 292 cost 0.3824779987335205 sec\n",
      "loss 2.306479, train acc 0.100416\n",
      "round 293\n",
      "time to device 0.006604 sec\n",
      "time forward 3.417992 sec\n",
      "loss time 0.001004 sec\n",
      "backward time 0.010837 sec\n",
      "optimizer time 0.029036 sec\n",
      "training time in round 293 cost 0.40031003952026367 sec\n",
      "loss 2.306474, train acc 0.100367\n",
      "round 294\n",
      "time to device 0.003302 sec\n",
      "time forward 3.430490 sec\n",
      "loss time 0.001414 sec\n",
      "backward time 0.013920 sec\n",
      "optimizer time 0.034480 sec\n",
      "training time in round 294 cost 0.4003009796142578 sec\n",
      "loss 2.306462, train acc 0.100318\n",
      "round 295\n",
      "time to device 0.003560 sec\n",
      "time forward 3.442981 sec\n",
      "loss time 0.001052 sec\n",
      "backward time 0.027539 sec\n",
      "optimizer time 0.014589 sec\n",
      "training time in round 295 cost 0.42360591888427734 sec\n",
      "loss 2.306444, train acc 0.100269\n",
      "round 296\n",
      "time to device 0.006624 sec\n",
      "time forward 3.454913 sec\n",
      "loss time 0.001359 sec\n",
      "backward time 0.017019 sec\n",
      "optimizer time 0.023592 sec\n",
      "training time in round 296 cost 0.4516329765319824 sec\n",
      "loss 2.306428, train acc 0.100221\n",
      "round 297\n",
      "time to device 0.006405 sec\n",
      "time forward 3.467070 sec\n",
      "loss time 0.000960 sec\n",
      "backward time 0.020083 sec\n",
      "optimizer time 0.020938 sec\n",
      "training time in round 297 cost 0.4097919464111328 sec\n",
      "loss 2.306429, train acc 0.100173\n",
      "round 298\n",
      "time to device 0.007638 sec\n",
      "time forward 3.480820 sec\n",
      "loss time 0.001243 sec\n",
      "backward time 0.009848 sec\n",
      "optimizer time 0.026874 sec\n",
      "training time in round 298 cost 0.41046810150146484 sec\n",
      "loss 2.306414, train acc 0.100204\n",
      "round 299\n",
      "time to device 0.008227 sec\n",
      "time forward 3.492013 sec\n",
      "loss time 0.002265 sec\n",
      "backward time 0.011392 sec\n",
      "optimizer time 0.022382 sec\n",
      "training time in round 299 cost 0.4326150417327881 sec\n",
      "loss 2.306409, train acc 0.100312\n",
      "round 300\n",
      "time to device 0.007113 sec\n",
      "time forward 3.504427 sec\n",
      "loss time 0.001271 sec\n",
      "backward time 0.017710 sec\n",
      "optimizer time 0.032883 sec\n",
      "training time in round 300 cost 0.4043850898742676 sec\n",
      "loss 2.306392, train acc 0.100498\n",
      "round 301\n",
      "time to device 0.009143 sec\n",
      "time forward 3.512268 sec\n",
      "loss time 0.000598 sec\n",
      "backward time 0.004985 sec\n",
      "optimizer time 0.016180 sec\n",
      "training time in round 301 cost 0.36510419845581055 sec\n",
      "loss 2.306372, train acc 0.100528\n",
      "round 302\n",
      "time to device 0.006643 sec\n",
      "time forward 3.526570 sec\n",
      "loss time 0.001182 sec\n",
      "backward time 0.013344 sec\n",
      "optimizer time 0.026588 sec\n",
      "training time in round 302 cost 0.41524600982666016 sec\n",
      "loss 2.306370, train acc 0.100454\n",
      "round 303\n",
      "time to device 0.007741 sec\n",
      "time forward 3.536742 sec\n",
      "loss time 0.001497 sec\n",
      "backward time 0.013166 sec\n",
      "optimizer time 0.029648 sec\n",
      "training time in round 303 cost 0.3910839557647705 sec\n",
      "loss 2.306361, train acc 0.100457\n",
      "round 304\n",
      "time to device 0.008371 sec\n",
      "time forward 3.547742 sec\n",
      "loss time 0.001832 sec\n",
      "backward time 0.013762 sec\n",
      "optimizer time 0.020350 sec\n",
      "training time in round 304 cost 0.4100222587585449 sec\n",
      "loss 2.306359, train acc 0.100538\n",
      "round 305\n",
      "time to device 0.007048 sec\n",
      "time forward 3.554855 sec\n",
      "loss time 0.000757 sec\n",
      "backward time 0.006265 sec\n",
      "optimizer time 0.015782 sec\n",
      "training time in round 305 cost 0.35865187644958496 sec\n",
      "loss 2.306340, train acc 0.100516\n",
      "round 306\n",
      "time to device 0.007163 sec\n",
      "time forward 3.565557 sec\n",
      "loss time 0.001207 sec\n",
      "backward time 0.016502 sec\n",
      "optimizer time 0.028442 sec\n",
      "training time in round 306 cost 0.392686128616333 sec\n",
      "loss 2.306353, train acc 0.100494\n",
      "round 307\n",
      "time to device 0.006586 sec\n",
      "time forward 3.577924 sec\n",
      "loss time 0.001578 sec\n",
      "backward time 0.012199 sec\n",
      "optimizer time 0.030387 sec\n",
      "training time in round 307 cost 0.40587902069091797 sec\n",
      "loss 2.306338, train acc 0.100446\n",
      "round 308\n",
      "time to device 0.003448 sec\n",
      "time forward 3.585583 sec\n",
      "loss time 0.000739 sec\n",
      "backward time 0.006245 sec\n",
      "optimizer time 0.015761 sec\n",
      "training time in round 308 cost 0.3576219081878662 sec\n",
      "loss 2.306315, train acc 0.100501\n",
      "round 309\n",
      "time to device 0.003285 sec\n",
      "time forward 3.596640 sec\n",
      "loss time 0.000883 sec\n",
      "backward time 0.012297 sec\n",
      "optimizer time 0.016307 sec\n",
      "training time in round 309 cost 0.3842029571533203 sec\n",
      "loss 2.306306, train acc 0.100479\n",
      "round 310\n",
      "time to device 0.003356 sec\n",
      "time forward 3.608903 sec\n",
      "loss time 0.001217 sec\n",
      "backward time 0.019884 sec\n",
      "optimizer time 0.022391 sec\n",
      "training time in round 310 cost 0.40144777297973633 sec\n",
      "loss 2.306286, train acc 0.100507\n",
      "round 311\n",
      "time to device 0.003500 sec\n",
      "time forward 3.616366 sec\n",
      "loss time 0.000563 sec\n",
      "backward time 0.005569 sec\n",
      "optimizer time 0.014147 sec\n",
      "training time in round 311 cost 0.4233088493347168 sec\n",
      "loss 2.306271, train acc 0.100536\n",
      "round 312\n",
      "time to device 0.006292 sec\n",
      "time forward 3.631355 sec\n",
      "loss time 0.001158 sec\n",
      "backward time 0.012367 sec\n",
      "optimizer time 0.031823 sec\n",
      "training time in round 312 cost 0.42006802558898926 sec\n",
      "loss 2.306256, train acc 0.100539\n",
      "round 313\n",
      "time to device 0.007073 sec\n",
      "time forward 3.645295 sec\n",
      "loss time 0.001941 sec\n",
      "backward time 0.018006 sec\n",
      "optimizer time 0.028109 sec\n",
      "training time in round 313 cost 0.4013981819152832 sec\n",
      "loss 2.306250, train acc 0.100468\n",
      "round 314\n",
      "time to device 0.007838 sec\n",
      "time forward 3.652602 sec\n",
      "loss time 0.000757 sec\n",
      "backward time 0.006997 sec\n",
      "optimizer time 0.017478 sec\n",
      "training time in round 314 cost 0.36205315589904785 sec\n",
      "loss 2.306253, train acc 0.100273\n",
      "round 315\n",
      "time to device 0.006315 sec\n",
      "time forward 3.670090 sec\n",
      "loss time 0.001224 sec\n",
      "backward time 0.011734 sec\n",
      "optimizer time 0.025550 sec\n",
      "training time in round 315 cost 0.4193401336669922 sec\n",
      "loss 2.306234, train acc 0.100203\n",
      "round 316\n",
      "time to device 0.007180 sec\n",
      "time forward 3.680252 sec\n",
      "loss time 0.001418 sec\n",
      "backward time 0.012594 sec\n",
      "optimizer time 0.028823 sec\n",
      "training time in round 316 cost 0.45094895362854004 sec\n",
      "loss 2.306235, train acc 0.100133\n",
      "round 317\n",
      "time to device 0.008069 sec\n",
      "time forward 3.692093 sec\n",
      "loss time 0.001767 sec\n",
      "backward time 0.026093 sec\n",
      "optimizer time 0.021848 sec\n",
      "training time in round 317 cost 0.4097583293914795 sec\n",
      "loss 2.306256, train acc 0.100039\n",
      "round 318\n",
      "time to device 0.007080 sec\n",
      "time forward 3.706167 sec\n",
      "loss time 0.001757 sec\n",
      "backward time 0.016999 sec\n",
      "optimizer time 0.022071 sec\n",
      "training time in round 318 cost 0.42987704277038574 sec\n",
      "loss 2.306237, train acc 0.100069\n",
      "round 319\n",
      "time to device 0.007913 sec\n",
      "time forward 3.717006 sec\n",
      "loss time 0.001415 sec\n",
      "backward time 0.012111 sec\n",
      "optimizer time 0.028245 sec\n",
      "training time in round 319 cost 0.42571592330932617 sec\n",
      "loss 2.306210, train acc 0.100098\n",
      "round 320\n",
      "time to device 0.007171 sec\n",
      "time forward 3.727876 sec\n",
      "loss time 0.000667 sec\n",
      "backward time 0.005702 sec\n",
      "optimizer time 0.015730 sec\n",
      "training time in round 320 cost 0.4193990230560303 sec\n",
      "loss 2.306208, train acc 0.100078\n",
      "round 321\n",
      "time to device 0.006931 sec\n",
      "time forward 3.740597 sec\n",
      "loss time 0.001437 sec\n",
      "backward time 0.016858 sec\n",
      "optimizer time 0.030601 sec\n",
      "training time in round 321 cost 0.4012460708618164 sec\n",
      "loss 2.306236, train acc 0.100010\n",
      "round 322\n",
      "time to device 0.008372 sec\n",
      "time forward 3.751983 sec\n",
      "loss time 0.001431 sec\n",
      "backward time 0.011112 sec\n",
      "optimizer time 0.029554 sec\n",
      "training time in round 322 cost 0.3957951068878174 sec\n",
      "loss 2.306209, train acc 0.099990\n",
      "round 323\n",
      "time to device 0.007173 sec\n",
      "time forward 3.768334 sec\n",
      "loss time 0.001016 sec\n",
      "backward time 0.011297 sec\n",
      "optimizer time 0.020113 sec\n",
      "training time in round 323 cost 0.40723514556884766 sec\n",
      "loss 2.306183, train acc 0.099971\n",
      "round 324\n",
      "time to device 0.007524 sec\n",
      "time forward 3.780279 sec\n",
      "loss time 0.001879 sec\n",
      "backward time 0.015262 sec\n",
      "optimizer time 0.026718 sec\n",
      "training time in round 324 cost 0.39924097061157227 sec\n",
      "loss 2.306177, train acc 0.099976\n",
      "round 325\n",
      "time to device 0.007362 sec\n",
      "time forward 3.794283 sec\n",
      "loss time 0.002030 sec\n",
      "backward time 0.016167 sec\n",
      "optimizer time 0.034289 sec\n",
      "training time in round 325 cost 0.4119222164154053 sec\n",
      "loss 2.306141, train acc 0.099981\n",
      "round 326\n",
      "time to device 0.005997 sec\n",
      "time forward 3.806018 sec\n",
      "loss time 0.001391 sec\n",
      "backward time 0.011017 sec\n",
      "optimizer time 0.028410 sec\n",
      "training time in round 326 cost 0.39386916160583496 sec\n",
      "loss 2.306138, train acc 0.099890\n",
      "round 327\n",
      "time to device 0.009124 sec\n",
      "time forward 3.820268 sec\n",
      "loss time 0.001016 sec\n",
      "backward time 0.013789 sec\n",
      "optimizer time 0.026277 sec\n",
      "training time in round 327 cost 0.4076499938964844 sec\n",
      "loss 2.306141, train acc 0.099848\n",
      "round 328\n",
      "time to device 0.006162 sec\n",
      "time forward 3.834979 sec\n",
      "loss time 0.001932 sec\n",
      "backward time 0.020265 sec\n",
      "optimizer time 0.023007 sec\n",
      "training time in round 328 cost 0.4147970676422119 sec\n",
      "loss 2.306134, train acc 0.099924\n",
      "round 329\n",
      "time to device 0.003866 sec\n",
      "time forward 3.847739 sec\n",
      "loss time 0.001256 sec\n",
      "backward time 0.015817 sec\n",
      "optimizer time 0.023713 sec\n",
      "training time in round 329 cost 0.4031970500946045 sec\n",
      "loss 2.306111, train acc 0.099787\n",
      "round 330\n",
      "time to device 0.003952 sec\n",
      "time forward 3.859734 sec\n",
      "loss time 0.001948 sec\n",
      "backward time 0.018293 sec\n",
      "optimizer time 0.026159 sec\n",
      "training time in round 330 cost 0.3910248279571533 sec\n",
      "loss 2.306132, train acc 0.099769\n",
      "round 331\n",
      "time to device 0.002868 sec\n",
      "time forward 3.870562 sec\n",
      "loss time 0.001436 sec\n",
      "backward time 0.011701 sec\n",
      "optimizer time 0.021669 sec\n",
      "training time in round 331 cost 0.4078671932220459 sec\n",
      "loss 2.306113, train acc 0.099939\n",
      "round 332\n",
      "time to device 0.003273 sec\n",
      "time forward 3.884588 sec\n",
      "loss time 0.001566 sec\n",
      "backward time 0.016120 sec\n",
      "optimizer time 0.027692 sec\n",
      "training time in round 332 cost 0.40346503257751465 sec\n",
      "loss 2.306093, train acc 0.099873\n",
      "round 333\n",
      "time to device 0.003310 sec\n",
      "time forward 3.900347 sec\n",
      "loss time 0.001289 sec\n",
      "backward time 0.017069 sec\n",
      "optimizer time 0.025141 sec\n",
      "training time in round 333 cost 0.4042019844055176 sec\n",
      "loss 2.306071, train acc 0.099785\n",
      "round 334\n",
      "time to device 0.003895 sec\n",
      "time forward 3.912714 sec\n",
      "loss time 0.001211 sec\n",
      "backward time 0.013501 sec\n",
      "optimizer time 0.027892 sec\n",
      "training time in round 334 cost 0.39198899269104004 sec\n",
      "loss 2.306080, train acc 0.099790\n",
      "round 335\n",
      "time to device 0.006709 sec\n",
      "time forward 3.923858 sec\n",
      "loss time 0.001276 sec\n",
      "backward time 0.013427 sec\n",
      "optimizer time 0.025650 sec\n",
      "training time in round 335 cost 0.3909938335418701 sec\n",
      "loss 2.306050, train acc 0.099888\n",
      "round 336\n",
      "time to device 0.009873 sec\n",
      "time forward 3.934958 sec\n",
      "loss time 0.001415 sec\n",
      "backward time 0.011061 sec\n",
      "optimizer time 0.029650 sec\n",
      "training time in round 336 cost 0.40159106254577637 sec\n",
      "loss 2.306042, train acc 0.099870\n",
      "round 337\n",
      "time to device 0.006483 sec\n",
      "time forward 3.943213 sec\n",
      "loss time 0.000852 sec\n",
      "backward time 0.007405 sec\n",
      "optimizer time 0.018016 sec\n",
      "training time in round 337 cost 0.3828132152557373 sec\n",
      "loss 2.306022, train acc 0.099852\n",
      "round 338\n",
      "time to device 0.007156 sec\n",
      "time forward 3.957000 sec\n",
      "loss time 0.001396 sec\n",
      "backward time 0.013829 sec\n",
      "optimizer time 0.028840 sec\n",
      "training time in round 338 cost 0.40564393997192383 sec\n",
      "loss 2.305988, train acc 0.099880\n",
      "round 339\n",
      "time to device 0.007012 sec\n",
      "time forward 3.966563 sec\n",
      "loss time 0.000723 sec\n",
      "backward time 0.006812 sec\n",
      "optimizer time 0.017298 sec\n",
      "training time in round 339 cost 0.3834190368652344 sec\n",
      "loss 2.305996, train acc 0.099724\n",
      "round 340\n",
      "time to device 0.007695 sec\n",
      "time forward 3.978930 sec\n",
      "loss time 0.001117 sec\n",
      "backward time 0.010213 sec\n",
      "optimizer time 0.039777 sec\n",
      "training time in round 340 cost 0.4105949401855469 sec\n",
      "loss 2.305972, train acc 0.099638\n",
      "round 341\n",
      "time to device 0.006639 sec\n",
      "time forward 3.985971 sec\n",
      "loss time 0.000397 sec\n",
      "backward time 0.003618 sec\n",
      "optimizer time 0.012009 sec\n",
      "training time in round 341 cost 0.37293577194213867 sec\n",
      "loss 2.305967, train acc 0.099621\n",
      "round 342\n",
      "time to device 0.007175 sec\n",
      "time forward 3.999826 sec\n",
      "loss time 0.001249 sec\n",
      "backward time 0.025793 sec\n",
      "optimizer time 0.021607 sec\n",
      "training time in round 342 cost 0.42174816131591797 sec\n",
      "loss 2.305923, train acc 0.099604\n",
      "round 343\n",
      "time to device 0.008298 sec\n",
      "time forward 4.009626 sec\n",
      "loss time 0.001018 sec\n",
      "backward time 0.010464 sec\n",
      "optimizer time 0.019212 sec\n",
      "training time in round 343 cost 0.38633275032043457 sec\n",
      "loss 2.305930, train acc 0.099564\n",
      "round 344\n",
      "time to device 0.009724 sec\n",
      "time forward 4.017787 sec\n",
      "loss time 0.000767 sec\n",
      "backward time 0.006757 sec\n",
      "optimizer time 0.017050 sec\n",
      "training time in round 344 cost 0.37084388732910156 sec\n",
      "loss 2.305985, train acc 0.099592\n",
      "round 345\n",
      "time to device 0.008392 sec\n",
      "time forward 4.028714 sec\n",
      "loss time 0.001234 sec\n",
      "backward time 0.013719 sec\n",
      "optimizer time 0.030229 sec\n",
      "training time in round 345 cost 0.3973560333251953 sec\n",
      "loss 2.305950, train acc 0.099576\n",
      "round 346\n",
      "time to device 0.007444 sec\n",
      "time forward 4.044265 sec\n",
      "loss time 0.001066 sec\n",
      "backward time 0.017266 sec\n",
      "optimizer time 0.022246 sec\n",
      "training time in round 346 cost 0.4081149101257324 sec\n",
      "loss 2.305906, train acc 0.099424\n",
      "round 347\n",
      "time to device 0.007458 sec\n",
      "time forward 4.055535 sec\n",
      "loss time 0.001221 sec\n",
      "backward time 0.011697 sec\n",
      "optimizer time 0.027155 sec\n",
      "training time in round 347 cost 0.38825535774230957 sec\n",
      "loss 2.305898, train acc 0.099587\n",
      "round 348\n",
      "time to device 0.006895 sec\n",
      "time forward 4.063855 sec\n",
      "loss time 0.000759 sec\n",
      "backward time 0.006711 sec\n",
      "optimizer time 0.017328 sec\n",
      "training time in round 348 cost 0.3671760559082031 sec\n",
      "loss 2.305852, train acc 0.099615\n",
      "round 349\n",
      "time to device 0.006932 sec\n",
      "time forward 4.074826 sec\n",
      "loss time 0.000992 sec\n",
      "backward time 0.010837 sec\n",
      "optimizer time 0.027192 sec\n",
      "training time in round 349 cost 0.4071309566497803 sec\n",
      "loss 2.305821, train acc 0.099621\n",
      "round 350\n",
      "time to device 0.007570 sec\n",
      "time forward 4.086890 sec\n",
      "loss time 0.001564 sec\n",
      "backward time 0.014428 sec\n",
      "optimizer time 0.024592 sec\n",
      "training time in round 350 cost 0.4105229377746582 sec\n",
      "loss 2.305837, train acc 0.099604\n",
      "round 351\n",
      "time to device 0.006927 sec\n",
      "time forward 4.100931 sec\n",
      "loss time 0.001378 sec\n",
      "backward time 0.013937 sec\n",
      "optimizer time 0.025669 sec\n",
      "training time in round 351 cost 0.4111950397491455 sec\n",
      "loss 2.305808, train acc 0.099698\n",
      "round 352\n",
      "time to device 0.006508 sec\n",
      "time forward 4.112173 sec\n",
      "loss time 0.001113 sec\n",
      "backward time 0.010832 sec\n",
      "optimizer time 0.030397 sec\n",
      "training time in round 352 cost 0.4557759761810303 sec\n",
      "loss 2.305783, train acc 0.099748\n",
      "round 353\n",
      "time to device 0.006739 sec\n",
      "time forward 4.125565 sec\n",
      "loss time 0.001021 sec\n",
      "backward time 0.010128 sec\n",
      "optimizer time 0.039264 sec\n",
      "training time in round 353 cost 0.4098188877105713 sec\n",
      "loss 2.305763, train acc 0.099841\n",
      "round 354\n",
      "time to device 0.007175 sec\n",
      "time forward 4.137414 sec\n",
      "loss time 0.001440 sec\n",
      "backward time 0.013900 sec\n",
      "optimizer time 0.034021 sec\n",
      "training time in round 354 cost 0.395859956741333 sec\n",
      "loss 2.305750, train acc 0.099868\n",
      "round 355\n",
      "time to device 0.007365 sec\n",
      "time forward 4.148377 sec\n",
      "loss time 0.001413 sec\n",
      "backward time 0.015686 sec\n",
      "optimizer time 0.022614 sec\n",
      "training time in round 355 cost 0.40332889556884766 sec\n",
      "loss 2.305764, train acc 0.099807\n",
      "round 356\n",
      "time to device 0.009199 sec\n",
      "time forward 4.159981 sec\n",
      "loss time 0.001335 sec\n",
      "backward time 0.012776 sec\n",
      "optimizer time 0.032248 sec\n",
      "training time in round 356 cost 0.4010961055755615 sec\n",
      "loss 2.305675, train acc 0.099856\n",
      "round 357\n",
      "time to device 0.008441 sec\n",
      "time forward 4.171148 sec\n",
      "loss time 0.001001 sec\n",
      "backward time 0.013899 sec\n",
      "optimizer time 0.024140 sec\n",
      "training time in round 357 cost 0.404130220413208 sec\n",
      "loss 2.305591, train acc 0.099839\n",
      "round 358\n",
      "time to device 0.006118 sec\n",
      "time forward 4.181520 sec\n",
      "loss time 0.001161 sec\n",
      "backward time 0.012280 sec\n",
      "optimizer time 0.031211 sec\n",
      "training time in round 358 cost 0.3885030746459961 sec\n",
      "loss 2.305559, train acc 0.099865\n",
      "round 359\n",
      "time to device 0.009157 sec\n",
      "time forward 4.188133 sec\n",
      "loss time 0.000718 sec\n",
      "backward time 0.006782 sec\n",
      "optimizer time 0.016874 sec\n",
      "training time in round 359 cost 0.38541626930236816 sec\n",
      "loss 2.305520, train acc 0.099761\n",
      "round 360\n",
      "time to device 0.005925 sec\n",
      "time forward 4.199197 sec\n",
      "loss time 0.000633 sec\n",
      "backward time 0.006133 sec\n",
      "optimizer time 0.015793 sec\n",
      "training time in round 360 cost 0.39538002014160156 sec\n",
      "loss 2.305415, train acc 0.099939\n",
      "round 361\n",
      "time to device 0.008006 sec\n",
      "time forward 4.214279 sec\n",
      "loss time 0.001094 sec\n",
      "backward time 0.011608 sec\n",
      "optimizer time 0.023413 sec\n",
      "training time in round 361 cost 0.4831728935241699 sec\n",
      "loss 2.305349, train acc 0.099922\n",
      "round 362\n",
      "time to device 0.006634 sec\n",
      "time forward 4.225785 sec\n",
      "loss time 0.000737 sec\n",
      "backward time 0.006284 sec\n",
      "optimizer time 0.017357 sec\n",
      "training time in round 362 cost 0.4370098114013672 sec\n",
      "loss 2.305314, train acc 0.099884\n",
      "round 363\n",
      "time to device 0.005916 sec\n",
      "time forward 4.238078 sec\n",
      "loss time 0.001047 sec\n",
      "backward time 0.013478 sec\n",
      "optimizer time 0.019738 sec\n",
      "training time in round 363 cost 0.5203330516815186 sec\n",
      "loss 2.305272, train acc 0.099888\n",
      "round 364\n",
      "time to device 0.008597 sec\n",
      "time forward 4.250595 sec\n",
      "loss time 0.001549 sec\n",
      "backward time 0.009975 sec\n",
      "optimizer time 0.021709 sec\n",
      "training time in round 364 cost 0.43528318405151367 sec\n",
      "loss 2.305170, train acc 0.099914\n",
      "round 365\n",
      "time to device 0.012971 sec\n",
      "time forward 4.263971 sec\n",
      "loss time 0.000950 sec\n",
      "backward time 0.012096 sec\n",
      "optimizer time 0.024238 sec\n",
      "training time in round 365 cost 0.45671892166137695 sec\n",
      "loss 2.305144, train acc 0.099812\n",
      "round 366\n",
      "time to device 0.012963 sec\n",
      "time forward 4.276855 sec\n",
      "loss time 0.001202 sec\n",
      "backward time 0.013612 sec\n",
      "optimizer time 0.017580 sec\n",
      "training time in round 366 cost 0.44981884956359863 sec\n",
      "loss 2.305046, train acc 0.099902\n",
      "round 367\n",
      "time to device 0.008332 sec\n",
      "time forward 4.289391 sec\n",
      "loss time 0.000895 sec\n",
      "backward time 0.013315 sec\n",
      "optimizer time 0.050897 sec\n",
      "training time in round 367 cost 0.48960018157958984 sec\n",
      "loss 2.305004, train acc 0.099885\n",
      "round 368\n",
      "time to device 0.006783 sec\n",
      "time forward 4.303871 sec\n",
      "loss time 0.000923 sec\n",
      "backward time 0.011068 sec\n",
      "optimizer time 0.021015 sec\n",
      "training time in round 368 cost 0.4139220714569092 sec\n",
      "loss 2.304922, train acc 0.099932\n",
      "round 369\n",
      "time to device 0.006713 sec\n",
      "time forward 4.321999 sec\n",
      "loss time 0.001335 sec\n",
      "backward time 0.011558 sec\n",
      "optimizer time 0.018558 sec\n",
      "training time in round 369 cost 0.43300819396972656 sec\n",
      "loss 2.304926, train acc 0.099958\n",
      "round 370\n",
      "time to device 0.006971 sec\n",
      "time forward 4.333527 sec\n",
      "loss time 0.001607 sec\n",
      "backward time 0.010513 sec\n",
      "optimizer time 0.014310 sec\n",
      "training time in round 370 cost 0.4071211814880371 sec\n",
      "loss 2.304836, train acc 0.099920\n",
      "round 371\n",
      "time to device 0.009683 sec\n",
      "time forward 4.340031 sec\n",
      "loss time 0.000423 sec\n",
      "backward time 0.003884 sec\n",
      "optimizer time 0.011993 sec\n",
      "training time in round 371 cost 0.3730919361114502 sec\n",
      "loss 2.304817, train acc 0.099945\n",
      "round 372\n",
      "time to device 0.011269 sec\n",
      "time forward 4.353842 sec\n",
      "loss time 0.001081 sec\n",
      "backward time 0.012276 sec\n",
      "optimizer time 0.019428 sec\n",
      "training time in round 372 cost 0.41312098503112793 sec\n",
      "loss 2.304769, train acc 0.099992\n",
      "round 373\n",
      "time to device 0.008005 sec\n",
      "time forward 4.365130 sec\n",
      "loss time 0.001094 sec\n",
      "backward time 0.010898 sec\n",
      "optimizer time 0.018733 sec\n",
      "training time in round 373 cost 0.41989612579345703 sec\n",
      "loss 2.304657, train acc 0.100079\n",
      "round 374\n",
      "time to device 0.007702 sec\n",
      "time forward 4.380389 sec\n",
      "loss time 0.000961 sec\n",
      "backward time 0.010979 sec\n",
      "optimizer time 0.017062 sec\n",
      "training time in round 374 cost 0.40420103073120117 sec\n",
      "loss 2.304479, train acc 0.100167\n",
      "round 375\n",
      "time to device 0.009764 sec\n",
      "time forward 4.389284 sec\n",
      "loss time 0.000387 sec\n",
      "backward time 0.003643 sec\n",
      "optimizer time 0.010804 sec\n",
      "training time in round 375 cost 0.3550536632537842 sec\n",
      "loss 2.304397, train acc 0.100191\n",
      "round 376\n",
      "time to device 0.006939 sec\n",
      "time forward 4.402536 sec\n",
      "loss time 0.001815 sec\n",
      "backward time 0.012930 sec\n",
      "optimizer time 0.025013 sec\n",
      "training time in round 376 cost 0.4241349697113037 sec\n",
      "loss 2.304257, train acc 0.100257\n",
      "round 377\n",
      "time to device 0.007779 sec\n",
      "time forward 4.413957 sec\n",
      "loss time 0.000940 sec\n",
      "backward time 0.013732 sec\n",
      "optimizer time 0.016184 sec\n",
      "training time in round 377 cost 0.3887491226196289 sec\n",
      "loss 2.304097, train acc 0.100343\n",
      "round 378\n",
      "time to device 0.006990 sec\n",
      "time forward 4.422125 sec\n",
      "loss time 0.000695 sec\n",
      "backward time 0.006145 sec\n",
      "optimizer time 0.016822 sec\n",
      "training time in round 378 cost 0.36492323875427246 sec\n",
      "loss 2.303937, train acc 0.100367\n",
      "round 379\n",
      "time to device 0.006726 sec\n",
      "time forward 4.432999 sec\n",
      "loss time 0.001090 sec\n",
      "backward time 0.010086 sec\n",
      "optimizer time 0.018657 sec\n",
      "training time in round 379 cost 0.4500908851623535 sec\n",
      "loss 2.303849, train acc 0.100432\n",
      "round 380\n",
      "time to device 0.006198 sec\n",
      "time forward 4.443628 sec\n",
      "loss time 0.000901 sec\n",
      "backward time 0.011868 sec\n",
      "optimizer time 0.017093 sec\n",
      "training time in round 380 cost 0.40082216262817383 sec\n",
      "loss 2.303690, train acc 0.100537\n",
      "round 381\n",
      "time to device 0.006626 sec\n",
      "time forward 4.450316 sec\n",
      "loss time 0.000404 sec\n",
      "backward time 0.003859 sec\n",
      "optimizer time 0.014020 sec\n",
      "training time in round 381 cost 0.3724191188812256 sec\n",
      "loss 2.303391, train acc 0.100560\n",
      "round 382\n",
      "time to device 0.006172 sec\n",
      "time forward 4.464847 sec\n",
      "loss time 0.001599 sec\n",
      "backward time 0.007524 sec\n",
      "optimizer time 0.022133 sec\n",
      "training time in round 382 cost 0.4004940986633301 sec\n",
      "loss 2.303314, train acc 0.100624\n",
      "round 383\n",
      "time to device 0.007044 sec\n",
      "time forward 4.475168 sec\n",
      "loss time 0.001126 sec\n",
      "backward time 0.015777 sec\n",
      "optimizer time 0.016539 sec\n",
      "training time in round 383 cost 0.40314388275146484 sec\n",
      "loss 2.303163, train acc 0.100667\n",
      "round 384\n",
      "time to device 0.006730 sec\n",
      "time forward 4.484475 sec\n",
      "loss time 0.001206 sec\n",
      "backward time 0.006045 sec\n",
      "optimizer time 0.015718 sec\n",
      "training time in round 384 cost 0.3684871196746826 sec\n",
      "loss 2.303084, train acc 0.100731\n",
      "round 385\n",
      "time to device 0.007969 sec\n",
      "time forward 4.496367 sec\n",
      "loss time 0.001169 sec\n",
      "backward time 0.014140 sec\n",
      "optimizer time 0.030892 sec\n",
      "training time in round 385 cost 0.4115488529205322 sec\n",
      "loss 2.303081, train acc 0.100834\n",
      "round 386\n",
      "time to device 0.006052 sec\n",
      "time forward 4.509052 sec\n",
      "loss time 0.001026 sec\n",
      "backward time 0.012556 sec\n",
      "optimizer time 0.019097 sec\n",
      "training time in round 386 cost 0.4110701084136963 sec\n",
      "loss 2.303087, train acc 0.100795\n",
      "round 387\n",
      "time to device 0.006924 sec\n",
      "time forward 4.521325 sec\n",
      "loss time 0.001255 sec\n",
      "backward time 0.011835 sec\n",
      "optimizer time 0.018286 sec\n",
      "training time in round 387 cost 0.44981980323791504 sec\n",
      "loss 2.302997, train acc 0.100858\n",
      "round 388\n",
      "time to device 0.006748 sec\n",
      "time forward 4.538383 sec\n",
      "loss time 0.002404 sec\n",
      "backward time 0.025921 sec\n",
      "optimizer time 0.042173 sec\n",
      "training time in round 388 cost 0.5691051483154297 sec\n",
      "loss 2.302908, train acc 0.100940\n",
      "round 389\n",
      "time to device 0.006483 sec\n",
      "time forward 4.551076 sec\n",
      "loss time 0.001072 sec\n",
      "backward time 0.011761 sec\n",
      "optimizer time 0.024185 sec\n",
      "training time in round 389 cost 0.48094677925109863 sec\n",
      "loss 2.302801, train acc 0.101062\n",
      "round 390\n",
      "time to device 0.007089 sec\n",
      "time forward 4.566839 sec\n",
      "loss time 0.001122 sec\n",
      "backward time 0.007077 sec\n",
      "optimizer time 0.016229 sec\n",
      "training time in round 390 cost 0.4396681785583496 sec\n",
      "loss 2.302683, train acc 0.101183\n",
      "round 391\n",
      "time to device 0.023564 sec\n",
      "time forward 4.577829 sec\n",
      "loss time 0.001401 sec\n",
      "backward time 0.012679 sec\n",
      "optimizer time 0.021097 sec\n",
      "training time in round 391 cost 0.46789097785949707 sec\n",
      "loss 2.302629, train acc 0.101164\n",
      "round 392\n",
      "time to device 0.007985 sec\n",
      "time forward 4.587980 sec\n",
      "loss time 0.000559 sec\n",
      "backward time 0.004218 sec\n",
      "optimizer time 0.014454 sec\n",
      "training time in round 392 cost 0.4059641361236572 sec\n",
      "loss 2.302464, train acc 0.101205\n",
      "round 393\n",
      "time to device 0.007254 sec\n",
      "time forward 4.597651 sec\n",
      "loss time 0.001118 sec\n",
      "backward time 0.009901 sec\n",
      "optimizer time 0.015810 sec\n",
      "training time in round 393 cost 0.4082632064819336 sec\n",
      "loss 2.302314, train acc 0.101245\n",
      "round 394\n",
      "time to device 0.007371 sec\n",
      "time forward 4.608993 sec\n",
      "loss time 0.000937 sec\n",
      "backward time 0.010845 sec\n",
      "optimizer time 0.021238 sec\n",
      "training time in round 394 cost 0.46736812591552734 sec\n",
      "loss 2.302211, train acc 0.101325\n",
      "round 395\n",
      "time to device 0.007553 sec\n",
      "time forward 4.620708 sec\n",
      "loss time 0.001153 sec\n",
      "backward time 0.014032 sec\n",
      "optimizer time 0.021991 sec\n",
      "training time in round 395 cost 0.3945281505584717 sec\n",
      "loss 2.302235, train acc 0.101484\n",
      "round 396\n",
      "time to device 0.007664 sec\n",
      "time forward 4.632751 sec\n",
      "loss time 0.001253 sec\n",
      "backward time 0.012589 sec\n",
      "optimizer time 0.027387 sec\n",
      "training time in round 396 cost 0.45412611961364746 sec\n",
      "loss 2.302136, train acc 0.101425\n",
      "round 397\n",
      "time to device 0.006937 sec\n",
      "time forward 4.644843 sec\n",
      "loss time 0.001154 sec\n",
      "backward time 0.017506 sec\n",
      "optimizer time 0.017723 sec\n",
      "training time in round 397 cost 0.4455599784851074 sec\n",
      "loss 2.301937, train acc 0.101484\n",
      "round 398\n",
      "time to device 0.007350 sec\n",
      "time forward 4.659279 sec\n",
      "loss time 0.001551 sec\n",
      "backward time 0.011024 sec\n",
      "optimizer time 0.022817 sec\n",
      "training time in round 398 cost 0.4233090877532959 sec\n",
      "loss 2.301836, train acc 0.101562\n",
      "round 399\n",
      "time to device 0.008011 sec\n",
      "time forward 4.674249 sec\n",
      "loss time 0.001331 sec\n",
      "backward time 0.011028 sec\n",
      "optimizer time 0.021655 sec\n",
      "training time in round 399 cost 0.4460477828979492 sec\n",
      "loss 2.301673, train acc 0.101621\n",
      "round 400\n",
      "time to device 0.006807 sec\n",
      "time forward 4.685490 sec\n",
      "loss time 0.001358 sec\n",
      "backward time 0.004062 sec\n",
      "optimizer time 0.015512 sec\n",
      "training time in round 400 cost 0.40813684463500977 sec\n",
      "loss 2.301618, train acc 0.101543\n",
      "round 401\n",
      "time to device 0.006051 sec\n",
      "time forward 4.696771 sec\n",
      "loss time 0.001165 sec\n",
      "backward time 0.012586 sec\n",
      "optimizer time 0.015017 sec\n",
      "training time in round 401 cost 0.4325098991394043 sec\n",
      "loss 2.301369, train acc 0.101699\n",
      "round 402\n",
      "time to device 0.018629 sec\n",
      "time forward 4.711963 sec\n",
      "loss time 0.002643 sec\n",
      "backward time 0.028414 sec\n",
      "optimizer time 0.022517 sec\n",
      "training time in round 402 cost 0.5275063514709473 sec\n",
      "loss 2.301247, train acc 0.101834\n",
      "round 403\n",
      "time to device 0.005996 sec\n",
      "time forward 4.719396 sec\n",
      "loss time 0.000602 sec\n",
      "backward time 0.004969 sec\n",
      "optimizer time 0.016565 sec\n",
      "training time in round 403 cost 0.4109492301940918 sec\n",
      "loss 2.301103, train acc 0.101814\n",
      "round 404\n",
      "time to device 0.008168 sec\n",
      "time forward 4.729365 sec\n",
      "loss time 0.000659 sec\n",
      "backward time 0.006070 sec\n",
      "optimizer time 0.016217 sec\n",
      "training time in round 404 cost 0.3923933506011963 sec\n",
      "loss 2.300868, train acc 0.101852\n",
      "round 405\n",
      "time to device 0.009018 sec\n",
      "time forward 4.738616 sec\n",
      "loss time 0.001572 sec\n",
      "backward time 0.005666 sec\n",
      "optimizer time 0.023985 sec\n",
      "training time in round 405 cost 0.4617908000946045 sec\n",
      "loss 2.300725, train acc 0.102024\n",
      "round 406\n",
      "time to device 0.007734 sec\n",
      "time forward 4.752401 sec\n",
      "loss time 0.001098 sec\n",
      "backward time 0.012663 sec\n",
      "optimizer time 0.028942 sec\n",
      "training time in round 406 cost 0.45147013664245605 sec\n",
      "loss 2.300560, train acc 0.102119\n",
      "round 407\n",
      "time to device 0.006406 sec\n",
      "time forward 4.759928 sec\n",
      "loss time 0.000443 sec\n",
      "backward time 0.004604 sec\n",
      "optimizer time 0.014842 sec\n",
      "training time in round 407 cost 0.40923500061035156 sec\n",
      "loss 2.300321, train acc 0.102252\n",
      "round 408\n",
      "time to device 0.006256 sec\n",
      "time forward 4.771349 sec\n",
      "loss time 0.001954 sec\n",
      "backward time 0.022607 sec\n",
      "optimizer time 0.016946 sec\n",
      "training time in round 408 cost 0.43891096115112305 sec\n",
      "loss 2.300087, train acc 0.102403\n",
      "round 409\n",
      "time to device 0.007319 sec\n",
      "time forward 4.782473 sec\n",
      "loss time 0.001600 sec\n",
      "backward time 0.012352 sec\n",
      "optimizer time 0.013824 sec\n",
      "training time in round 409 cost 0.46251702308654785 sec\n",
      "loss 2.299810, train acc 0.102496\n",
      "round 410\n",
      "time to device 0.006991 sec\n",
      "time forward 4.795466 sec\n",
      "loss time 0.000410 sec\n",
      "backward time 0.003699 sec\n",
      "optimizer time 0.012504 sec\n",
      "training time in round 410 cost 0.3731551170349121 sec\n",
      "loss 2.299671, train acc 0.102570\n",
      "round 411\n",
      "time to device 0.006859 sec\n",
      "time forward 4.807850 sec\n",
      "loss time 0.001282 sec\n",
      "backward time 0.016634 sec\n",
      "optimizer time 0.030181 sec\n",
      "training time in round 411 cost 0.4157891273498535 sec\n",
      "loss 2.299379, train acc 0.102624\n",
      "round 412\n",
      "time to device 0.007988 sec\n",
      "time forward 4.822552 sec\n",
      "loss time 0.001188 sec\n",
      "backward time 0.015381 sec\n",
      "optimizer time 0.028131 sec\n",
      "training time in round 412 cost 0.4189927577972412 sec\n",
      "loss 2.299070, train acc 0.102906\n",
      "round 413\n",
      "time to device 0.006500 sec\n",
      "time forward 4.833235 sec\n",
      "loss time 0.001207 sec\n",
      "backward time 0.010334 sec\n",
      "optimizer time 0.015146 sec\n",
      "training time in round 413 cost 0.39125490188598633 sec\n",
      "loss 2.298578, train acc 0.103110\n",
      "round 414\n",
      "time to device 0.009568 sec\n",
      "time forward 4.844364 sec\n",
      "loss time 0.002495 sec\n",
      "backward time 0.013551 sec\n",
      "optimizer time 0.025259 sec\n",
      "training time in round 414 cost 0.4099869728088379 sec\n",
      "loss 2.299356, train acc 0.103106\n",
      "round 415\n",
      "time to device 0.008329 sec\n",
      "time forward 4.856826 sec\n",
      "loss time 0.001157 sec\n",
      "backward time 0.011800 sec\n",
      "optimizer time 0.025051 sec\n",
      "training time in round 415 cost 0.4033958911895752 sec\n",
      "loss 2.299145, train acc 0.103084\n",
      "round 416\n",
      "time to device 0.007460 sec\n",
      "time forward 4.864302 sec\n",
      "loss time 0.000438 sec\n",
      "backward time 0.004026 sec\n",
      "optimizer time 0.012643 sec\n",
      "training time in round 416 cost 0.3643207550048828 sec\n",
      "loss 2.298744, train acc 0.103249\n",
      "round 417\n",
      "time to device 0.008165 sec\n",
      "time forward 4.876468 sec\n",
      "loss time 0.001060 sec\n",
      "backward time 0.011160 sec\n",
      "optimizer time 0.017218 sec\n",
      "training time in round 417 cost 0.40335988998413086 sec\n",
      "loss 2.298818, train acc 0.103207\n",
      "round 418\n",
      "time to device 0.006500 sec\n",
      "time forward 4.889518 sec\n",
      "loss time 0.001137 sec\n",
      "backward time 0.013215 sec\n",
      "optimizer time 0.017431 sec\n",
      "training time in round 418 cost 0.44252514839172363 sec\n",
      "loss 2.298779, train acc 0.103203\n",
      "round 419\n",
      "time to device 0.007609 sec\n",
      "time forward 4.902839 sec\n",
      "loss time 0.001018 sec\n",
      "backward time 0.015172 sec\n",
      "optimizer time 0.024594 sec\n",
      "training time in round 419 cost 0.40827298164367676 sec\n",
      "loss 2.298498, train acc 0.103181\n",
      "round 420\n",
      "time to device 0.007597 sec\n",
      "time forward 4.918313 sec\n",
      "loss time 0.001976 sec\n",
      "backward time 0.016234 sec\n",
      "optimizer time 0.023252 sec\n",
      "training time in round 420 cost 0.451566219329834 sec\n",
      "loss 2.298427, train acc 0.103177\n",
      "round 421\n",
      "time to device 0.007472 sec\n",
      "time forward 4.932831 sec\n",
      "loss time 0.001551 sec\n",
      "backward time 0.010934 sec\n",
      "optimizer time 0.022380 sec\n",
      "training time in round 421 cost 0.3917222023010254 sec\n",
      "loss 2.298205, train acc 0.103303\n",
      "round 422\n",
      "time to device 0.007528 sec\n",
      "time forward 4.944822 sec\n",
      "loss time 0.001005 sec\n",
      "backward time 0.013561 sec\n",
      "optimizer time 0.018003 sec\n",
      "training time in round 422 cost 0.3858051300048828 sec\n",
      "loss 2.298267, train acc 0.103409\n",
      "round 423\n",
      "time to device 0.007860 sec\n",
      "time forward 4.961551 sec\n",
      "loss time 0.002071 sec\n",
      "backward time 0.016110 sec\n",
      "optimizer time 0.024850 sec\n",
      "training time in round 423 cost 0.4162931442260742 sec\n",
      "loss 2.298083, train acc 0.103497\n",
      "round 424\n",
      "time to device 0.008999 sec\n",
      "time forward 4.973605 sec\n",
      "loss time 0.001240 sec\n",
      "backward time 0.011821 sec\n",
      "optimizer time 0.037631 sec\n",
      "training time in round 424 cost 0.405040979385376 sec\n",
      "loss 2.297974, train acc 0.103585\n",
      "round 425\n",
      "time to device 0.006989 sec\n",
      "time forward 4.985393 sec\n",
      "loss time 0.001139 sec\n",
      "backward time 0.010647 sec\n",
      "optimizer time 0.029004 sec\n",
      "training time in round 425 cost 0.3992769718170166 sec\n",
      "loss 2.297766, train acc 0.103708\n",
      "round 426\n",
      "time to device 0.011237 sec\n",
      "time forward 4.996428 sec\n",
      "loss time 0.001090 sec\n",
      "backward time 0.011339 sec\n",
      "optimizer time 0.031649 sec\n",
      "training time in round 426 cost 0.3968338966369629 sec\n",
      "loss 2.297572, train acc 0.103941\n",
      "round 427\n",
      "time to device 0.007742 sec\n",
      "time forward 5.007903 sec\n",
      "loss time 0.002100 sec\n",
      "backward time 0.016462 sec\n",
      "optimizer time 0.025373 sec\n",
      "training time in round 427 cost 0.3927490711212158 sec\n",
      "loss 2.297366, train acc 0.104136\n",
      "round 428\n",
      "time to device 0.007290 sec\n",
      "time forward 5.019014 sec\n",
      "loss time 0.001421 sec\n",
      "backward time 0.013813 sec\n",
      "optimizer time 0.027476 sec\n",
      "training time in round 428 cost 0.39188408851623535 sec\n",
      "loss 2.297196, train acc 0.104258\n",
      "round 429\n",
      "time to device 0.006691 sec\n",
      "time forward 5.032143 sec\n",
      "loss time 0.001740 sec\n",
      "backward time 0.013452 sec\n",
      "optimizer time 0.027851 sec\n",
      "training time in round 429 cost 0.4007909297943115 sec\n",
      "loss 2.297075, train acc 0.104161\n",
      "round 430\n",
      "time to device 0.007158 sec\n",
      "time forward 5.047151 sec\n",
      "loss time 0.001250 sec\n",
      "backward time 0.014958 sec\n",
      "optimizer time 0.024901 sec\n",
      "training time in round 430 cost 0.40608906745910645 sec\n",
      "loss 2.296977, train acc 0.104300\n",
      "round 431\n",
      "time to device 0.009402 sec\n",
      "time forward 5.058282 sec\n",
      "loss time 0.001063 sec\n",
      "backward time 0.013976 sec\n",
      "optimizer time 0.028439 sec\n",
      "training time in round 431 cost 0.39354586601257324 sec\n",
      "loss 2.296844, train acc 0.104311\n",
      "round 432\n",
      "time to device 0.008029 sec\n",
      "time forward 5.071656 sec\n",
      "loss time 0.001260 sec\n",
      "backward time 0.014008 sec\n",
      "optimizer time 0.025377 sec\n",
      "training time in round 432 cost 0.4015769958496094 sec\n",
      "loss 2.296654, train acc 0.104359\n",
      "round 433\n",
      "time to device 0.007358 sec\n",
      "time forward 5.085643 sec\n",
      "loss time 0.001243 sec\n",
      "backward time 0.012531 sec\n",
      "optimizer time 0.019749 sec\n",
      "training time in round 433 cost 0.40480589866638184 sec\n",
      "loss 2.296536, train acc 0.104371\n",
      "round 434\n",
      "time to device 0.009403 sec\n",
      "time forward 5.097367 sec\n",
      "loss time 0.001480 sec\n",
      "backward time 0.013571 sec\n",
      "optimizer time 0.027903 sec\n",
      "training time in round 434 cost 0.4287700653076172 sec\n",
      "loss 2.296401, train acc 0.104508\n",
      "round 435\n",
      "time to device 0.007104 sec\n",
      "time forward 5.108872 sec\n",
      "loss time 0.001245 sec\n",
      "backward time 0.017503 sec\n",
      "optimizer time 0.025455 sec\n",
      "training time in round 435 cost 0.3948390483856201 sec\n",
      "loss 2.296211, train acc 0.104555\n",
      "round 436\n",
      "time to device 0.007224 sec\n",
      "time forward 5.116208 sec\n",
      "loss time 0.000511 sec\n",
      "backward time 0.007938 sec\n",
      "optimizer time 0.013157 sec\n",
      "training time in round 436 cost 0.36548590660095215 sec\n",
      "loss 2.296055, train acc 0.104602\n",
      "round 437\n",
      "time to device 0.004650 sec\n",
      "time forward 5.131544 sec\n",
      "loss time 0.001221 sec\n",
      "backward time 0.011762 sec\n",
      "optimizer time 0.027320 sec\n",
      "training time in round 437 cost 0.3917369842529297 sec\n",
      "loss 2.295887, train acc 0.104720\n",
      "round 438\n",
      "time to device 0.006700 sec\n",
      "time forward 5.143019 sec\n",
      "loss time 0.001588 sec\n",
      "backward time 0.012480 sec\n",
      "optimizer time 0.016014 sec\n",
      "training time in round 438 cost 0.41255903244018555 sec\n",
      "loss 2.295747, train acc 0.104748\n",
      "round 439\n",
      "time to device 0.004114 sec\n",
      "time forward 5.154892 sec\n",
      "loss time 0.001195 sec\n",
      "backward time 0.013124 sec\n",
      "optimizer time 0.027747 sec\n",
      "training time in round 439 cost 0.39945387840270996 sec\n",
      "loss 2.295635, train acc 0.104705\n",
      "round 440\n",
      "time to device 0.002831 sec\n",
      "time forward 5.167240 sec\n",
      "loss time 0.001055 sec\n",
      "backward time 0.013948 sec\n",
      "optimizer time 0.014212 sec\n",
      "training time in round 440 cost 0.38727498054504395 sec\n",
      "loss 2.295411, train acc 0.104928\n",
      "round 441\n",
      "time to device 0.003976 sec\n",
      "time forward 5.182456 sec\n",
      "loss time 0.001180 sec\n",
      "backward time 0.010211 sec\n",
      "optimizer time 0.013400 sec\n",
      "training time in round 441 cost 0.426342248916626 sec\n",
      "loss 2.295214, train acc 0.104868\n",
      "round 442\n",
      "time to device 0.004277 sec\n",
      "time forward 5.193898 sec\n",
      "loss time 0.001416 sec\n",
      "backward time 0.014207 sec\n",
      "optimizer time 0.027120 sec\n",
      "training time in round 442 cost 0.3923981189727783 sec\n",
      "loss 2.295158, train acc 0.104931\n",
      "round 443\n",
      "time to device 0.003400 sec\n",
      "time forward 5.208700 sec\n",
      "loss time 0.001775 sec\n",
      "backward time 0.031254 sec\n",
      "optimizer time 0.026271 sec\n",
      "training time in round 443 cost 0.43305492401123047 sec\n",
      "loss 2.295119, train acc 0.105082\n",
      "round 444\n",
      "time to device 0.002407 sec\n",
      "time forward 5.221022 sec\n",
      "loss time 0.001281 sec\n",
      "backward time 0.014998 sec\n",
      "optimizer time 0.028627 sec\n",
      "training time in round 444 cost 0.47527074813842773 sec\n",
      "loss 2.294828, train acc 0.105144\n",
      "round 445\n",
      "time to device 0.009254 sec\n",
      "time forward 5.229068 sec\n",
      "loss time 0.000637 sec\n",
      "backward time 0.005197 sec\n",
      "optimizer time 0.036134 sec\n",
      "training time in round 445 cost 0.38039278984069824 sec\n",
      "loss 2.294751, train acc 0.105311\n",
      "round 446\n",
      "time to device 0.007898 sec\n",
      "time forward 5.240091 sec\n",
      "loss time 0.000505 sec\n",
      "backward time 0.004499 sec\n",
      "optimizer time 0.012386 sec\n",
      "training time in round 446 cost 0.37853574752807617 sec\n",
      "loss 2.294486, train acc 0.105373\n",
      "round 447\n",
      "time to device 0.007122 sec\n",
      "time forward 5.253381 sec\n",
      "loss time 0.001545 sec\n",
      "backward time 0.015462 sec\n",
      "optimizer time 0.025425 sec\n",
      "training time in round 447 cost 0.4046790599822998 sec\n",
      "loss 2.294214, train acc 0.105364\n",
      "round 448\n",
      "time to device 0.007746 sec\n",
      "time forward 5.264474 sec\n",
      "loss time 0.001515 sec\n",
      "backward time 0.015047 sec\n",
      "optimizer time 0.025206 sec\n",
      "training time in round 448 cost 0.39369916915893555 sec\n",
      "loss 2.294031, train acc 0.105390\n",
      "round 449\n",
      "time to device 0.007128 sec\n",
      "time forward 5.275847 sec\n",
      "loss time 0.001356 sec\n",
      "backward time 0.013492 sec\n",
      "optimizer time 0.028927 sec\n",
      "training time in round 449 cost 0.398270845413208 sec\n",
      "loss 2.293854, train acc 0.105469\n",
      "round 450\n",
      "time to device 0.011204 sec\n",
      "time forward 5.287130 sec\n",
      "loss time 0.001471 sec\n",
      "backward time 0.009735 sec\n",
      "optimizer time 0.021005 sec\n",
      "training time in round 450 cost 0.3859899044036865 sec\n",
      "loss 2.293604, train acc 0.105529\n",
      "round 451\n",
      "time to device 0.007397 sec\n",
      "time forward 5.299204 sec\n",
      "loss time 0.001466 sec\n",
      "backward time 0.014707 sec\n",
      "optimizer time 0.025931 sec\n",
      "training time in round 451 cost 0.3923499584197998 sec\n",
      "loss 2.293432, train acc 0.105659\n",
      "round 452\n",
      "time to device 0.003111 sec\n",
      "time forward 5.311388 sec\n",
      "loss time 0.001644 sec\n",
      "backward time 0.013414 sec\n",
      "optimizer time 0.025877 sec\n",
      "training time in round 452 cost 0.387937068939209 sec\n",
      "loss 2.293188, train acc 0.105702\n",
      "round 453\n",
      "time to device 0.005779 sec\n",
      "time forward 5.329824 sec\n",
      "loss time 0.001270 sec\n",
      "backward time 0.014913 sec\n",
      "optimizer time 0.023203 sec\n",
      "training time in round 453 cost 0.46762537956237793 sec\n",
      "loss 2.292976, train acc 0.105744\n",
      "round 454\n",
      "time to device 0.009303 sec\n",
      "time forward 5.341967 sec\n",
      "loss time 0.000993 sec\n",
      "backward time 0.013338 sec\n",
      "optimizer time 0.035274 sec\n",
      "training time in round 454 cost 0.42753100395202637 sec\n",
      "loss 2.292788, train acc 0.105769\n",
      "round 455\n",
      "time to device 0.007754 sec\n",
      "time forward 5.354078 sec\n",
      "loss time 0.001117 sec\n",
      "backward time 0.018795 sec\n",
      "optimizer time 0.028063 sec\n",
      "training time in round 455 cost 0.4223060607910156 sec\n",
      "loss 2.292587, train acc 0.105829\n",
      "round 456\n",
      "time to device 0.077110 sec\n",
      "time forward 5.404298 sec\n",
      "loss time 0.001101 sec\n",
      "backward time 0.009263 sec\n",
      "optimizer time 0.011759 sec\n",
      "training time in round 456 cost 0.5749402046203613 sec\n",
      "loss 2.292379, train acc 0.105836\n",
      "round 457\n",
      "time to device 0.007675 sec\n",
      "time forward 5.419724 sec\n",
      "loss time 0.002472 sec\n",
      "backward time 0.018573 sec\n",
      "optimizer time 0.027241 sec\n",
      "training time in round 457 cost 0.506525993347168 sec\n",
      "loss 2.292025, train acc 0.105946\n",
      "round 458\n",
      "time to device 0.006828 sec\n",
      "time forward 5.432190 sec\n",
      "loss time 0.001522 sec\n",
      "backward time 0.013533 sec\n",
      "optimizer time 0.028280 sec\n",
      "training time in round 458 cost 0.41799187660217285 sec\n",
      "loss 2.291832, train acc 0.105988\n",
      "round 459\n",
      "time to device 0.007543 sec\n",
      "time forward 5.443637 sec\n",
      "loss time 0.001204 sec\n",
      "backward time 0.015959 sec\n",
      "optimizer time 0.026669 sec\n",
      "training time in round 459 cost 0.40857601165771484 sec\n",
      "loss 2.291591, train acc 0.106063\n",
      "round 460\n",
      "time to device 0.008656 sec\n",
      "time forward 5.454911 sec\n",
      "loss time 0.001034 sec\n",
      "backward time 0.016974 sec\n",
      "optimizer time 0.024998 sec\n",
      "training time in round 460 cost 0.41420483589172363 sec\n",
      "loss 2.291264, train acc 0.106223\n",
      "round 461\n",
      "time to device 0.006536 sec\n",
      "time forward 5.468379 sec\n",
      "loss time 0.001310 sec\n",
      "backward time 0.010973 sec\n",
      "optimizer time 0.030528 sec\n",
      "training time in round 461 cost 0.44643402099609375 sec\n",
      "loss 2.291035, train acc 0.106280\n",
      "round 462\n",
      "time to device 0.006197 sec\n",
      "time forward 5.480731 sec\n",
      "loss time 0.001301 sec\n",
      "backward time 0.028746 sec\n",
      "optimizer time 0.016718 sec\n",
      "training time in round 462 cost 0.4122128486633301 sec\n",
      "loss 2.290882, train acc 0.106237\n",
      "round 463\n",
      "time to device 0.006955 sec\n",
      "time forward 5.493662 sec\n",
      "loss time 0.000972 sec\n",
      "backward time 0.014212 sec\n",
      "optimizer time 0.025943 sec\n",
      "training time in round 463 cost 0.39838695526123047 sec\n",
      "loss 2.290660, train acc 0.106395\n",
      "round 464\n",
      "time to device 0.006417 sec\n",
      "time forward 5.505710 sec\n",
      "loss time 0.001004 sec\n",
      "backward time 0.020663 sec\n",
      "optimizer time 0.014387 sec\n",
      "training time in round 464 cost 0.39865899085998535 sec\n",
      "loss 2.290509, train acc 0.106384\n",
      "round 465\n",
      "time to device 0.006405 sec\n",
      "time forward 5.514433 sec\n",
      "loss time 0.000494 sec\n",
      "backward time 0.004040 sec\n",
      "optimizer time 0.012476 sec\n",
      "training time in round 465 cost 0.39310503005981445 sec\n",
      "loss 2.290181, train acc 0.106408\n",
      "round 466\n",
      "time to device 0.006913 sec\n",
      "time forward 5.527725 sec\n",
      "loss time 0.001619 sec\n",
      "backward time 0.018909 sec\n",
      "optimizer time 0.023214 sec\n",
      "training time in round 466 cost 0.4099159240722656 sec\n",
      "loss 2.289924, train acc 0.106565\n",
      "round 467\n",
      "time to device 0.006396 sec\n",
      "time forward 5.540754 sec\n",
      "loss time 0.001423 sec\n",
      "backward time 0.013818 sec\n",
      "optimizer time 0.024332 sec\n",
      "training time in round 467 cost 0.3947141170501709 sec\n",
      "loss 2.294825, train acc 0.106604\n",
      "round 468\n",
      "time to device 0.006010 sec\n",
      "time forward 5.559304 sec\n",
      "loss time 0.002166 sec\n",
      "backward time 0.026562 sec\n",
      "optimizer time 0.020403 sec\n",
      "training time in round 468 cost 0.35230493545532227 sec\n",
      "loss 2.294672, train acc 0.106717\n",
      "test acc is 0.203400\n",
      "epoch 2, time 1323.150018 sec\n",
      "epoch 4\n",
      "round 0\n",
      "time to device 0.051627 sec\n",
      "time forward 0.018159 sec\n",
      "loss time 0.001688 sec\n",
      "backward time 0.013703 sec\n",
      "optimizer time 0.045169 sec\n",
      "training time in round 0 cost 0.576106071472168 sec\n",
      "loss 2.220439, train acc 0.140625\n",
      "round 1\n",
      "time to device 0.007431 sec\n",
      "time forward 0.037605 sec\n",
      "loss time 0.001805 sec\n",
      "backward time 0.015019 sec\n",
      "optimizer time 0.019307 sec\n",
      "training time in round 1 cost 0.6636936664581299 sec\n",
      "loss 2.273645, train acc 0.140625\n",
      "round 2\n",
      "time to device 0.006848 sec\n",
      "time forward 0.054171 sec\n",
      "loss time 0.001181 sec\n",
      "backward time 0.011496 sec\n",
      "optimizer time 0.027797 sec\n",
      "training time in round 2 cost 0.4293808937072754 sec\n",
      "loss 2.284543, train acc 0.156250\n",
      "round 3\n",
      "time to device 0.011089 sec\n",
      "time forward 0.068205 sec\n",
      "loss time 0.001114 sec\n",
      "backward time 0.009122 sec\n",
      "optimizer time 0.022111 sec\n",
      "training time in round 3 cost 0.41974711418151855 sec\n",
      "loss 2.342934, train acc 0.160156\n",
      "round 4\n",
      "time to device 0.008700 sec\n",
      "time forward 0.090386 sec\n",
      "loss time 0.000541 sec\n",
      "backward time 0.004957 sec\n",
      "optimizer time 0.019438 sec\n",
      "training time in round 4 cost 0.46355724334716797 sec\n",
      "loss 2.329759, train acc 0.148438\n",
      "round 5\n",
      "time to device 0.007732 sec\n",
      "time forward 0.096931 sec\n",
      "loss time 0.000395 sec\n",
      "backward time 0.003733 sec\n",
      "optimizer time 0.014504 sec\n",
      "training time in round 5 cost 0.42563700675964355 sec\n",
      "loss 2.308042, train acc 0.153646\n",
      "round 6\n",
      "time to device 0.005871 sec\n",
      "time forward 0.105451 sec\n",
      "loss time 0.001617 sec\n",
      "backward time 0.006639 sec\n",
      "optimizer time 0.019005 sec\n",
      "training time in round 6 cost 0.39499998092651367 sec\n",
      "loss 2.303183, train acc 0.149554\n",
      "round 7\n",
      "time to device 0.007312 sec\n",
      "time forward 0.111534 sec\n",
      "loss time 0.000723 sec\n",
      "backward time 0.006224 sec\n",
      "optimizer time 0.018548 sec\n",
      "training time in round 7 cost 0.3888208866119385 sec\n",
      "loss 2.299211, train acc 0.144531\n",
      "round 8\n",
      "time to device 0.006395 sec\n",
      "time forward 0.117533 sec\n",
      "loss time 0.000414 sec\n",
      "backward time 0.025306 sec\n",
      "optimizer time 0.021802 sec\n",
      "training time in round 8 cost 0.4129009246826172 sec\n",
      "loss 2.304833, train acc 0.138889\n",
      "round 9\n",
      "time to device 0.006433 sec\n",
      "time forward 0.127541 sec\n",
      "loss time 0.001204 sec\n",
      "backward time 0.014551 sec\n",
      "optimizer time 0.063342 sec\n",
      "training time in round 9 cost 0.5051248073577881 sec\n",
      "loss 2.301103, train acc 0.134375\n",
      "round 10\n",
      "time to device 0.004548 sec\n",
      "time forward 0.141709 sec\n",
      "loss time 0.001078 sec\n",
      "backward time 0.012915 sec\n",
      "optimizer time 0.048002 sec\n",
      "training time in round 10 cost 0.49779796600341797 sec\n",
      "loss 2.293895, train acc 0.132812\n",
      "round 11\n",
      "time to device 0.015180 sec\n",
      "time forward 0.151412 sec\n",
      "loss time 0.001064 sec\n",
      "backward time 0.010581 sec\n",
      "optimizer time 0.067167 sec\n",
      "training time in round 11 cost 0.45430612564086914 sec\n",
      "loss 2.300957, train acc 0.132812\n",
      "round 12\n",
      "time to device 0.005072 sec\n",
      "time forward 0.157642 sec\n",
      "loss time 0.000417 sec\n",
      "backward time 0.003815 sec\n",
      "optimizer time 0.020613 sec\n",
      "training time in round 12 cost 0.39827609062194824 sec\n",
      "loss 2.295874, train acc 0.131010\n",
      "round 13\n",
      "time to device 0.007003 sec\n",
      "time forward 0.173137 sec\n",
      "loss time 0.000415 sec\n",
      "backward time 0.003612 sec\n",
      "optimizer time 0.012070 sec\n",
      "training time in round 13 cost 0.40333986282348633 sec\n",
      "loss 2.291374, train acc 0.132812\n",
      "round 14\n",
      "time to device 0.008473 sec\n",
      "time forward 0.181107 sec\n",
      "loss time 0.001096 sec\n",
      "backward time 0.005727 sec\n",
      "optimizer time 0.020395 sec\n",
      "training time in round 14 cost 0.3962101936340332 sec\n",
      "loss 2.290650, train acc 0.135417\n",
      "round 15\n",
      "time to device 0.007060 sec\n",
      "time forward 0.186753 sec\n",
      "loss time 0.000436 sec\n",
      "backward time 0.004086 sec\n",
      "optimizer time 0.014893 sec\n",
      "training time in round 15 cost 0.38704919815063477 sec\n",
      "loss 2.293808, train acc 0.133789\n",
      "round 16\n",
      "time to device 0.011642 sec\n",
      "time forward 0.193654 sec\n",
      "loss time 0.001105 sec\n",
      "backward time 0.008753 sec\n",
      "optimizer time 0.021315 sec\n",
      "training time in round 16 cost 0.38315606117248535 sec\n",
      "loss 2.293985, train acc 0.131434\n",
      "round 17\n",
      "time to device 0.013305 sec\n",
      "time forward 0.198484 sec\n",
      "loss time 0.001484 sec\n",
      "backward time 0.005601 sec\n",
      "optimizer time 0.023927 sec\n",
      "training time in round 17 cost 0.3959159851074219 sec\n",
      "loss 2.290326, train acc 0.131510\n",
      "round 18\n",
      "time to device 0.007937 sec\n",
      "time forward 0.206551 sec\n",
      "loss time 0.000434 sec\n",
      "backward time 0.004415 sec\n",
      "optimizer time 0.015640 sec\n",
      "training time in round 18 cost 0.4117598533630371 sec\n",
      "loss 2.288111, train acc 0.131579\n",
      "round 19\n",
      "time to device 0.006181 sec\n",
      "time forward 0.212603 sec\n",
      "loss time 0.000427 sec\n",
      "backward time 0.003771 sec\n",
      "optimizer time 0.011364 sec\n",
      "training time in round 19 cost 0.4220120906829834 sec\n",
      "loss 2.291410, train acc 0.128516\n",
      "round 20\n",
      "time to device 0.005257 sec\n",
      "time forward 0.222823 sec\n",
      "loss time 0.000486 sec\n",
      "backward time 0.003587 sec\n",
      "optimizer time 0.013184 sec\n",
      "training time in round 20 cost 0.3941380977630615 sec\n",
      "loss 2.296956, train acc 0.127976\n",
      "round 21\n",
      "time to device 0.006186 sec\n",
      "time forward 0.234562 sec\n",
      "loss time 0.000415 sec\n",
      "backward time 0.004178 sec\n",
      "optimizer time 0.012854 sec\n",
      "training time in round 21 cost 0.37239789962768555 sec\n",
      "loss 2.302005, train acc 0.125355\n",
      "round 22\n",
      "time to device 0.007319 sec\n",
      "time forward 0.241648 sec\n",
      "loss time 0.000463 sec\n",
      "backward time 0.004714 sec\n",
      "optimizer time 0.013537 sec\n",
      "training time in round 22 cost 0.38887596130371094 sec\n",
      "loss 2.301344, train acc 0.124321\n",
      "round 23\n",
      "time to device 0.005076 sec\n",
      "time forward 0.251726 sec\n",
      "loss time 0.000554 sec\n",
      "backward time 0.003693 sec\n",
      "optimizer time 0.012097 sec\n",
      "training time in round 23 cost 0.39705705642700195 sec\n",
      "loss 2.298507, train acc 0.125000\n",
      "round 24\n",
      "time to device 0.007254 sec\n",
      "time forward 0.257496 sec\n",
      "loss time 0.000728 sec\n",
      "backward time 0.006718 sec\n",
      "optimizer time 0.020189 sec\n",
      "training time in round 24 cost 0.37207698822021484 sec\n",
      "loss 2.294540, train acc 0.128438\n",
      "round 25\n",
      "time to device 0.004726 sec\n",
      "time forward 0.263388 sec\n",
      "loss time 0.000356 sec\n",
      "backward time 0.003395 sec\n",
      "optimizer time 0.011114 sec\n",
      "training time in round 25 cost 0.3854391574859619 sec\n",
      "loss 2.292780, train acc 0.129808\n",
      "round 26\n",
      "time to device 0.007313 sec\n",
      "time forward 0.269501 sec\n",
      "loss time 0.000427 sec\n",
      "backward time 0.005655 sec\n",
      "optimizer time 0.013502 sec\n",
      "training time in round 26 cost 0.3955190181732178 sec\n",
      "loss 2.291892, train acc 0.129051\n",
      "round 27\n",
      "time to device 0.005153 sec\n",
      "time forward 0.282417 sec\n",
      "loss time 0.001167 sec\n",
      "backward time 0.005412 sec\n",
      "optimizer time 0.021413 sec\n",
      "training time in round 27 cost 0.47788286209106445 sec\n",
      "loss 2.290250, train acc 0.129185\n",
      "round 28\n",
      "time to device 0.007589 sec\n",
      "time forward 0.291513 sec\n",
      "loss time 0.001198 sec\n",
      "backward time 0.004899 sec\n",
      "optimizer time 0.013188 sec\n",
      "training time in round 28 cost 0.3863790035247803 sec\n",
      "loss 2.288439, train acc 0.129849\n",
      "round 29\n",
      "time to device 0.005399 sec\n",
      "time forward 0.300994 sec\n",
      "loss time 0.000519 sec\n",
      "backward time 0.003992 sec\n",
      "optimizer time 0.013444 sec\n",
      "training time in round 29 cost 0.3566761016845703 sec\n",
      "loss 2.285186, train acc 0.128646\n",
      "round 30\n",
      "time to device 0.008190 sec\n",
      "time forward 0.308919 sec\n",
      "loss time 0.000924 sec\n",
      "backward time 0.008051 sec\n",
      "optimizer time 0.019407 sec\n",
      "training time in round 30 cost 0.38315701484680176 sec\n",
      "loss 2.282694, train acc 0.128276\n",
      "round 31\n",
      "time to device 0.017537 sec\n",
      "time forward 0.317153 sec\n",
      "loss time 0.000664 sec\n",
      "backward time 0.004850 sec\n",
      "optimizer time 0.015994 sec\n",
      "training time in round 31 cost 0.4112813472747803 sec\n",
      "loss 2.281403, train acc 0.127686\n",
      "round 32\n",
      "time to device 0.006196 sec\n",
      "time forward 0.322332 sec\n",
      "loss time 0.000528 sec\n",
      "backward time 0.003777 sec\n",
      "optimizer time 0.017430 sec\n",
      "training time in round 32 cost 0.37053894996643066 sec\n",
      "loss 2.277958, train acc 0.128078\n",
      "round 33\n",
      "time to device 0.005637 sec\n",
      "time forward 0.328745 sec\n",
      "loss time 0.000477 sec\n",
      "backward time 0.003730 sec\n",
      "optimizer time 0.013595 sec\n",
      "training time in round 33 cost 0.39893364906311035 sec\n",
      "loss 2.275645, train acc 0.128217\n",
      "round 34\n",
      "time to device 0.004774 sec\n",
      "time forward 0.335077 sec\n",
      "loss time 0.000451 sec\n",
      "backward time 0.003549 sec\n",
      "optimizer time 0.013340 sec\n",
      "training time in round 34 cost 0.39794278144836426 sec\n",
      "loss 2.273387, train acc 0.127902\n",
      "round 35\n",
      "time to device 0.005319 sec\n",
      "time forward 0.339844 sec\n",
      "loss time 0.000469 sec\n",
      "backward time 0.005704 sec\n",
      "optimizer time 0.013386 sec\n",
      "training time in round 35 cost 0.33835601806640625 sec\n",
      "loss 2.270780, train acc 0.128689\n",
      "round 36\n",
      "time to device 0.005166 sec\n",
      "time forward 0.346502 sec\n",
      "loss time 0.000612 sec\n",
      "backward time 0.005545 sec\n",
      "optimizer time 0.015561 sec\n",
      "training time in round 36 cost 0.40390920639038086 sec\n",
      "loss 2.270332, train acc 0.128378\n",
      "round 37\n",
      "time to device 0.007097 sec\n",
      "time forward 0.354357 sec\n",
      "loss time 0.000383 sec\n",
      "backward time 0.003284 sec\n",
      "optimizer time 0.009969 sec\n",
      "training time in round 37 cost 0.3839998245239258 sec\n",
      "loss 2.269161, train acc 0.127467\n",
      "round 38\n",
      "time to device 0.006501 sec\n",
      "time forward 0.359688 sec\n",
      "loss time 0.000459 sec\n",
      "backward time 0.003709 sec\n",
      "optimizer time 0.011927 sec\n",
      "training time in round 38 cost 0.36386990547180176 sec\n",
      "loss 2.267489, train acc 0.127804\n",
      "round 39\n",
      "time to device 0.006020 sec\n",
      "time forward 0.368585 sec\n",
      "loss time 0.000457 sec\n",
      "backward time 0.004523 sec\n",
      "optimizer time 0.012908 sec\n",
      "training time in round 39 cost 0.3560450077056885 sec\n",
      "loss 2.265580, train acc 0.129102\n",
      "round 40\n",
      "time to device 0.007035 sec\n",
      "time forward 0.375853 sec\n",
      "loss time 0.000552 sec\n",
      "backward time 0.005274 sec\n",
      "optimizer time 0.014720 sec\n",
      "training time in round 40 cost 0.3544011116027832 sec\n",
      "loss 2.264793, train acc 0.128620\n",
      "round 41\n",
      "time to device 0.012436 sec\n",
      "time forward 0.382068 sec\n",
      "loss time 0.001393 sec\n",
      "backward time 0.009017 sec\n",
      "optimizer time 0.025301 sec\n",
      "training time in round 41 cost 0.38521814346313477 sec\n",
      "loss 2.263496, train acc 0.128162\n",
      "round 42\n",
      "time to device 0.006422 sec\n",
      "time forward 0.388358 sec\n",
      "loss time 0.000380 sec\n",
      "backward time 0.003536 sec\n",
      "optimizer time 0.012115 sec\n",
      "training time in round 42 cost 0.3995790481567383 sec\n",
      "loss 2.261791, train acc 0.129179\n",
      "round 43\n",
      "time to device 0.004754 sec\n",
      "time forward 0.394276 sec\n",
      "loss time 0.000424 sec\n",
      "backward time 0.003431 sec\n",
      "optimizer time 0.015551 sec\n",
      "training time in round 43 cost 0.38998866081237793 sec\n",
      "loss 2.260286, train acc 0.129439\n",
      "round 44\n",
      "time to device 0.006445 sec\n",
      "time forward 0.399464 sec\n",
      "loss time 0.000495 sec\n",
      "backward time 0.003799 sec\n",
      "optimizer time 0.013743 sec\n",
      "training time in round 44 cost 0.3687460422515869 sec\n",
      "loss 2.259539, train acc 0.128472\n",
      "round 45\n",
      "time to device 0.004891 sec\n",
      "time forward 0.406148 sec\n",
      "loss time 0.000940 sec\n",
      "backward time 0.007153 sec\n",
      "optimizer time 0.018420 sec\n",
      "training time in round 45 cost 0.3880958557128906 sec\n",
      "loss 2.257839, train acc 0.128397\n",
      "round 46\n",
      "time to device 0.005642 sec\n",
      "time forward 0.416231 sec\n",
      "loss time 0.000676 sec\n",
      "backward time 0.005409 sec\n",
      "optimizer time 0.015217 sec\n",
      "training time in round 46 cost 0.35843873023986816 sec\n",
      "loss 2.255750, train acc 0.127660\n",
      "round 47\n",
      "time to device 0.004330 sec\n",
      "time forward 0.425643 sec\n",
      "loss time 0.000516 sec\n",
      "backward time 0.004878 sec\n",
      "optimizer time 0.014501 sec\n",
      "training time in round 47 cost 0.3623983860015869 sec\n",
      "loss 2.254091, train acc 0.127930\n",
      "round 48\n",
      "time to device 0.004962 sec\n",
      "time forward 0.430881 sec\n",
      "loss time 0.000447 sec\n",
      "backward time 0.004142 sec\n",
      "optimizer time 0.012473 sec\n",
      "training time in round 48 cost 0.3675870895385742 sec\n",
      "loss 2.253373, train acc 0.128667\n",
      "round 49\n",
      "time to device 0.004891 sec\n",
      "time forward 0.438205 sec\n",
      "loss time 0.000711 sec\n",
      "backward time 0.005125 sec\n",
      "optimizer time 0.012675 sec\n",
      "training time in round 49 cost 0.43932485580444336 sec\n",
      "loss 2.251999, train acc 0.128594\n",
      "round 50\n",
      "time to device 0.005177 sec\n",
      "time forward 0.448157 sec\n",
      "loss time 0.001214 sec\n",
      "backward time 0.005935 sec\n",
      "optimizer time 0.071581 sec\n",
      "training time in round 50 cost 0.5023970603942871 sec\n",
      "loss 2.250013, train acc 0.130974\n",
      "round 51\n",
      "time to device 0.004703 sec\n",
      "time forward 0.454078 sec\n",
      "loss time 0.000590 sec\n",
      "backward time 0.005307 sec\n",
      "optimizer time 0.017557 sec\n",
      "training time in round 51 cost 0.35882115364074707 sec\n",
      "loss 2.248600, train acc 0.130709\n",
      "round 52\n",
      "time to device 0.016546 sec\n",
      "time forward 0.467512 sec\n",
      "loss time 0.001193 sec\n",
      "backward time 0.007203 sec\n",
      "optimizer time 0.014279 sec\n",
      "training time in round 52 cost 0.43703389167785645 sec\n",
      "loss 2.247493, train acc 0.132075\n",
      "round 53\n",
      "time to device 0.009891 sec\n",
      "time forward 0.480325 sec\n",
      "loss time 0.001035 sec\n",
      "backward time 0.010867 sec\n",
      "optimizer time 0.020364 sec\n",
      "training time in round 53 cost 0.4540579319000244 sec\n",
      "loss 2.245677, train acc 0.132523\n",
      "round 54\n",
      "time to device 0.007190 sec\n",
      "time forward 0.492917 sec\n",
      "loss time 0.001226 sec\n",
      "backward time 0.012305 sec\n",
      "optimizer time 0.019951 sec\n",
      "training time in round 54 cost 0.4162411689758301 sec\n",
      "loss 2.243349, train acc 0.132528\n",
      "round 55\n",
      "time to device 0.008157 sec\n",
      "time forward 0.504529 sec\n",
      "loss time 0.001230 sec\n",
      "backward time 0.013635 sec\n",
      "optimizer time 0.025099 sec\n",
      "training time in round 55 cost 0.4248051643371582 sec\n",
      "loss 2.241950, train acc 0.132254\n",
      "round 56\n",
      "time to device 0.007105 sec\n",
      "time forward 0.517468 sec\n",
      "loss time 0.001124 sec\n",
      "backward time 0.012073 sec\n",
      "optimizer time 0.022421 sec\n",
      "training time in round 56 cost 0.40564990043640137 sec\n",
      "loss 2.239777, train acc 0.132127\n",
      "round 57\n",
      "time to device 0.007102 sec\n",
      "time forward 0.529418 sec\n",
      "loss time 0.000950 sec\n",
      "backward time 0.011727 sec\n",
      "optimizer time 0.024203 sec\n",
      "training time in round 57 cost 0.4009220600128174 sec\n",
      "loss 2.238594, train acc 0.132543\n",
      "round 58\n",
      "time to device 0.007815 sec\n",
      "time forward 0.541203 sec\n",
      "loss time 0.001328 sec\n",
      "backward time 0.010793 sec\n",
      "optimizer time 0.023377 sec\n",
      "training time in round 58 cost 0.40148091316223145 sec\n",
      "loss 2.238178, train acc 0.132018\n",
      "round 59\n",
      "time to device 0.006970 sec\n",
      "time forward 0.554058 sec\n",
      "loss time 0.001421 sec\n",
      "backward time 0.012511 sec\n",
      "optimizer time 0.024761 sec\n",
      "training time in round 59 cost 0.39716291427612305 sec\n",
      "loss 2.237592, train acc 0.131771\n",
      "round 60\n",
      "time to device 0.007404 sec\n",
      "time forward 0.567406 sec\n",
      "loss time 0.001542 sec\n",
      "backward time 0.014934 sec\n",
      "optimizer time 0.024670 sec\n",
      "training time in round 60 cost 0.3979783058166504 sec\n",
      "loss 2.237090, train acc 0.131916\n",
      "round 61\n",
      "time to device 0.008547 sec\n",
      "time forward 0.573929 sec\n",
      "loss time 0.000865 sec\n",
      "backward time 0.007897 sec\n",
      "optimizer time 0.019194 sec\n",
      "training time in round 61 cost 0.3854787349700928 sec\n",
      "loss 2.236541, train acc 0.131930\n",
      "round 62\n",
      "time to device 0.006528 sec\n",
      "time forward 0.583311 sec\n",
      "loss time 0.001426 sec\n",
      "backward time 0.012092 sec\n",
      "optimizer time 0.021434 sec\n",
      "training time in round 62 cost 0.3930511474609375 sec\n",
      "loss 2.234499, train acc 0.132192\n",
      "round 63\n",
      "time to device 0.013304 sec\n",
      "time forward 0.600760 sec\n",
      "loss time 0.001441 sec\n",
      "backward time 0.015141 sec\n",
      "optimizer time 0.023299 sec\n",
      "training time in round 63 cost 0.4225499629974365 sec\n",
      "loss 2.233636, train acc 0.132812\n",
      "round 64\n",
      "time to device 0.006235 sec\n",
      "time forward 0.608904 sec\n",
      "loss time 0.000740 sec\n",
      "backward time 0.006296 sec\n",
      "optimizer time 0.016934 sec\n",
      "training time in round 64 cost 0.36168980598449707 sec\n",
      "loss 2.234308, train acc 0.132692\n",
      "round 65\n",
      "time to device 0.006510 sec\n",
      "time forward 0.626661 sec\n",
      "loss time 0.001629 sec\n",
      "backward time 0.013474 sec\n",
      "optimizer time 0.025459 sec\n",
      "training time in round 65 cost 0.41937708854675293 sec\n",
      "loss 2.232191, train acc 0.132457\n",
      "round 66\n",
      "time to device 0.007099 sec\n",
      "time forward 0.638685 sec\n",
      "loss time 0.006027 sec\n",
      "backward time 0.015160 sec\n",
      "optimizer time 0.022808 sec\n",
      "training time in round 66 cost 0.4108259677886963 sec\n",
      "loss 2.231735, train acc 0.132812\n",
      "round 67\n",
      "time to device 0.009143 sec\n",
      "time forward 0.646152 sec\n",
      "loss time 0.000807 sec\n",
      "backward time 0.006686 sec\n",
      "optimizer time 0.016906 sec\n",
      "training time in round 67 cost 0.364912748336792 sec\n",
      "loss 2.230432, train acc 0.132927\n",
      "round 68\n",
      "time to device 0.007565 sec\n",
      "time forward 0.657410 sec\n",
      "loss time 0.001447 sec\n",
      "backward time 0.014281 sec\n",
      "optimizer time 0.026783 sec\n",
      "training time in round 68 cost 0.4102919101715088 sec\n",
      "loss 2.229059, train acc 0.133265\n",
      "round 69\n",
      "time to device 0.006287 sec\n",
      "time forward 0.673321 sec\n",
      "loss time 0.001228 sec\n",
      "backward time 0.016106 sec\n",
      "optimizer time 0.024881 sec\n",
      "training time in round 69 cost 0.42818617820739746 sec\n",
      "loss 2.226736, train acc 0.134040\n",
      "round 70\n",
      "time to device 0.005420 sec\n",
      "time forward 0.688042 sec\n",
      "loss time 0.001564 sec\n",
      "backward time 0.012731 sec\n",
      "optimizer time 0.027519 sec\n",
      "training time in round 70 cost 0.4254300594329834 sec\n",
      "loss 2.225130, train acc 0.134793\n",
      "round 71\n",
      "time to device 0.004271 sec\n",
      "time forward 0.700718 sec\n",
      "loss time 0.001174 sec\n",
      "backward time 0.009863 sec\n",
      "optimizer time 0.028525 sec\n",
      "training time in round 71 cost 0.39165806770324707 sec\n",
      "loss 2.223918, train acc 0.135091\n",
      "round 72\n",
      "time to device 0.003590 sec\n",
      "time forward 0.708451 sec\n",
      "loss time 0.000721 sec\n",
      "backward time 0.006664 sec\n",
      "optimizer time 0.016417 sec\n",
      "training time in round 72 cost 0.3555159568786621 sec\n",
      "loss 2.222422, train acc 0.135060\n",
      "round 73\n",
      "time to device 0.004491 sec\n",
      "time forward 0.719010 sec\n",
      "loss time 0.001051 sec\n",
      "backward time 0.013008 sec\n",
      "optimizer time 0.027671 sec\n",
      "training time in round 73 cost 0.3807191848754883 sec\n",
      "loss 2.221666, train acc 0.135135\n",
      "round 74\n",
      "time to device 0.003423 sec\n",
      "time forward 0.732411 sec\n",
      "loss time 0.001161 sec\n",
      "backward time 0.014477 sec\n",
      "optimizer time 0.025320 sec\n",
      "training time in round 74 cost 0.3976120948791504 sec\n",
      "loss 2.220637, train acc 0.135521\n",
      "round 75\n",
      "time to device 0.003624 sec\n",
      "time forward 0.744720 sec\n",
      "loss time 0.001080 sec\n",
      "backward time 0.011636 sec\n",
      "optimizer time 0.023580 sec\n",
      "training time in round 75 cost 0.4323909282684326 sec\n",
      "loss 2.219988, train acc 0.135896\n",
      "round 76\n",
      "time to device 0.004546 sec\n",
      "time forward 0.759367 sec\n",
      "loss time 0.001171 sec\n",
      "backward time 0.014069 sec\n",
      "optimizer time 0.029644 sec\n",
      "training time in round 76 cost 0.40607213973999023 sec\n",
      "loss 2.219362, train acc 0.136059\n",
      "round 77\n",
      "time to device 0.007364 sec\n",
      "time forward 0.773140 sec\n",
      "loss time 0.001244 sec\n",
      "backward time 0.014306 sec\n",
      "optimizer time 0.024773 sec\n",
      "training time in round 77 cost 0.39956188201904297 sec\n",
      "loss 2.218899, train acc 0.137019\n",
      "round 78\n",
      "time to device 0.006857 sec\n",
      "time forward 0.780819 sec\n",
      "loss time 0.000783 sec\n",
      "backward time 0.006892 sec\n",
      "optimizer time 0.016840 sec\n",
      "training time in round 78 cost 0.3604400157928467 sec\n",
      "loss 2.217937, train acc 0.137164\n",
      "round 79\n",
      "time to device 0.010919 sec\n",
      "time forward 0.793547 sec\n",
      "loss time 0.001867 sec\n",
      "backward time 0.011143 sec\n",
      "optimizer time 0.030127 sec\n",
      "training time in round 79 cost 0.40372395515441895 sec\n",
      "loss 2.217205, train acc 0.138184\n",
      "round 80\n",
      "time to device 0.011837 sec\n",
      "time forward 0.804865 sec\n",
      "loss time 0.001150 sec\n",
      "backward time 0.016419 sec\n",
      "optimizer time 0.024480 sec\n",
      "training time in round 80 cost 0.42005109786987305 sec\n",
      "loss 2.216815, train acc 0.138407\n",
      "round 81\n",
      "time to device 0.006157 sec\n",
      "time forward 0.814083 sec\n",
      "loss time 0.001322 sec\n",
      "backward time 0.014155 sec\n",
      "optimizer time 0.027530 sec\n",
      "training time in round 81 cost 0.40047478675842285 sec\n",
      "loss 2.216643, train acc 0.138529\n",
      "round 82\n",
      "time to device 0.008533 sec\n",
      "time forward 0.830102 sec\n",
      "loss time 0.001588 sec\n",
      "backward time 0.017831 sec\n",
      "optimizer time 0.022156 sec\n",
      "training time in round 82 cost 0.4124617576599121 sec\n",
      "loss 2.215588, train acc 0.138178\n",
      "round 83\n",
      "time to device 0.007534 sec\n",
      "time forward 0.839340 sec\n",
      "loss time 0.000832 sec\n",
      "backward time 0.003695 sec\n",
      "optimizer time 0.014695 sec\n",
      "training time in round 83 cost 0.3638620376586914 sec\n",
      "loss 2.214477, train acc 0.138672\n",
      "round 84\n",
      "time to device 0.008614 sec\n",
      "time forward 0.850764 sec\n",
      "loss time 0.000795 sec\n",
      "backward time 0.006304 sec\n",
      "optimizer time 0.019632 sec\n",
      "training time in round 84 cost 0.37944793701171875 sec\n",
      "loss 2.215257, train acc 0.138971\n",
      "round 85\n",
      "time to device 0.003211 sec\n",
      "time forward 0.859539 sec\n",
      "loss time 0.000838 sec\n",
      "backward time 0.008150 sec\n",
      "optimizer time 0.018172 sec\n",
      "training time in round 85 cost 0.3722727298736572 sec\n",
      "loss 2.214237, train acc 0.139262\n",
      "round 86\n",
      "time to device 0.003446 sec\n",
      "time forward 0.877154 sec\n",
      "loss time 0.001285 sec\n",
      "backward time 0.018492 sec\n",
      "optimizer time 0.024471 sec\n",
      "training time in round 86 cost 0.47283291816711426 sec\n",
      "loss 2.213801, train acc 0.138919\n",
      "round 87\n",
      "time to device 0.008329 sec\n",
      "time forward 0.888116 sec\n",
      "loss time 0.000698 sec\n",
      "backward time 0.006812 sec\n",
      "optimizer time 0.016577 sec\n",
      "training time in round 87 cost 0.37230396270751953 sec\n",
      "loss 2.212901, train acc 0.138938\n",
      "round 88\n",
      "time to device 0.006169 sec\n",
      "time forward 0.895687 sec\n",
      "loss time 0.000564 sec\n",
      "backward time 0.005135 sec\n",
      "optimizer time 0.014548 sec\n",
      "training time in round 88 cost 0.35959410667419434 sec\n",
      "loss 2.211195, train acc 0.139308\n",
      "round 89\n",
      "time to device 0.006436 sec\n",
      "time forward 0.902992 sec\n",
      "loss time 0.000722 sec\n",
      "backward time 0.006908 sec\n",
      "optimizer time 0.016806 sec\n",
      "training time in round 89 cost 0.35688281059265137 sec\n",
      "loss 2.210584, train acc 0.139670\n",
      "round 90\n",
      "time to device 0.003910 sec\n",
      "time forward 0.916384 sec\n",
      "loss time 0.001771 sec\n",
      "backward time 0.015863 sec\n",
      "optimizer time 0.026914 sec\n",
      "training time in round 90 cost 0.4072139263153076 sec\n",
      "loss 2.209558, train acc 0.139766\n",
      "round 91\n",
      "time to device 0.003983 sec\n",
      "time forward 0.928453 sec\n",
      "loss time 0.001939 sec\n",
      "backward time 0.015075 sec\n",
      "optimizer time 0.025597 sec\n",
      "training time in round 91 cost 0.3936600685119629 sec\n",
      "loss 2.207998, train acc 0.139946\n",
      "round 92\n",
      "time to device 0.003829 sec\n",
      "time forward 0.940680 sec\n",
      "loss time 0.001212 sec\n",
      "backward time 0.011736 sec\n",
      "optimizer time 0.027900 sec\n",
      "training time in round 92 cost 0.38997602462768555 sec\n",
      "loss 2.206326, train acc 0.140541\n",
      "round 93\n",
      "time to device 0.003276 sec\n",
      "time forward 0.955770 sec\n",
      "loss time 0.002358 sec\n",
      "backward time 0.016528 sec\n",
      "optimizer time 0.023627 sec\n",
      "training time in round 93 cost 0.4175088405609131 sec\n",
      "loss 2.206378, train acc 0.140376\n",
      "round 94\n",
      "time to device 0.003845 sec\n",
      "time forward 0.967956 sec\n",
      "loss time 0.001759 sec\n",
      "backward time 0.016042 sec\n",
      "optimizer time 0.026274 sec\n",
      "training time in round 94 cost 0.4323711395263672 sec\n",
      "loss 2.205492, train acc 0.140049\n",
      "round 95\n",
      "time to device 0.008523 sec\n",
      "time forward 0.980997 sec\n",
      "loss time 0.001385 sec\n",
      "backward time 0.020255 sec\n",
      "optimizer time 0.023023 sec\n",
      "training time in round 95 cost 0.4079000949859619 sec\n",
      "loss 2.204563, train acc 0.140381\n",
      "round 96\n",
      "time to device 0.006852 sec\n",
      "time forward 0.994322 sec\n",
      "loss time 0.001289 sec\n",
      "backward time 0.013179 sec\n",
      "optimizer time 0.027498 sec\n",
      "training time in round 96 cost 0.40915799140930176 sec\n",
      "loss 2.203699, train acc 0.140222\n",
      "round 97\n",
      "time to device 0.003621 sec\n",
      "time forward 1.005688 sec\n",
      "loss time 0.001127 sec\n",
      "backward time 0.013843 sec\n",
      "optimizer time 0.027642 sec\n",
      "training time in round 97 cost 0.387131929397583 sec\n",
      "loss 2.202400, train acc 0.140226\n",
      "round 98\n",
      "time to device 0.003609 sec\n",
      "time forward 1.015229 sec\n",
      "loss time 0.001173 sec\n",
      "backward time 0.015052 sec\n",
      "optimizer time 0.023510 sec\n",
      "training time in round 98 cost 0.392103910446167 sec\n",
      "loss 2.200422, train acc 0.141256\n",
      "round 99\n",
      "time to device 0.008477 sec\n",
      "time forward 1.023133 sec\n",
      "loss time 0.000485 sec\n",
      "backward time 0.004198 sec\n",
      "optimizer time 0.011803 sec\n",
      "training time in round 99 cost 0.3642399311065674 sec\n",
      "loss 2.199688, train acc 0.141172\n",
      "round 100\n",
      "time to device 0.007617 sec\n",
      "time forward 1.037762 sec\n",
      "loss time 0.001988 sec\n",
      "backward time 0.014089 sec\n",
      "optimizer time 0.025157 sec\n",
      "training time in round 100 cost 0.4044189453125 sec\n",
      "loss 2.198915, train acc 0.141244\n",
      "round 101\n",
      "time to device 0.007292 sec\n",
      "time forward 1.051238 sec\n",
      "loss time 0.001435 sec\n",
      "backward time 0.013735 sec\n",
      "optimizer time 0.025444 sec\n",
      "training time in round 101 cost 0.46210289001464844 sec\n",
      "loss 2.197638, train acc 0.142080\n",
      "round 102\n",
      "time to device 0.007443 sec\n",
      "time forward 1.064470 sec\n",
      "loss time 0.002534 sec\n",
      "backward time 0.012556 sec\n",
      "optimizer time 0.026841 sec\n",
      "training time in round 102 cost 0.3972160816192627 sec\n",
      "loss 2.196289, train acc 0.142294\n",
      "round 103\n",
      "time to device 0.007197 sec\n",
      "time forward 1.077062 sec\n",
      "loss time 0.001867 sec\n",
      "backward time 0.016315 sec\n",
      "optimizer time 0.025546 sec\n",
      "training time in round 103 cost 0.4011709690093994 sec\n",
      "loss 2.195265, train acc 0.142428\n",
      "round 104\n",
      "time to device 0.006840 sec\n",
      "time forward 1.089247 sec\n",
      "loss time 0.001293 sec\n",
      "backward time 0.018620 sec\n",
      "optimizer time 0.023735 sec\n",
      "training time in round 104 cost 0.41533803939819336 sec\n",
      "loss 2.194366, train acc 0.142560\n",
      "round 105\n",
      "time to device 0.007241 sec\n",
      "time forward 1.100075 sec\n",
      "loss time 0.001033 sec\n",
      "backward time 0.010791 sec\n",
      "optimizer time 0.033122 sec\n",
      "training time in round 105 cost 0.3933439254760742 sec\n",
      "loss 2.193114, train acc 0.142836\n",
      "round 106\n",
      "time to device 0.007160 sec\n",
      "time forward 1.112381 sec\n",
      "loss time 0.001241 sec\n",
      "backward time 0.011793 sec\n",
      "optimizer time 0.028888 sec\n",
      "training time in round 106 cost 0.3949911594390869 sec\n",
      "loss 2.191866, train acc 0.143180\n",
      "round 107\n",
      "time to device 0.007132 sec\n",
      "time forward 1.120441 sec\n",
      "loss time 0.000736 sec\n",
      "backward time 0.006814 sec\n",
      "optimizer time 0.018308 sec\n",
      "training time in round 107 cost 0.3628380298614502 sec\n",
      "loss 2.192229, train acc 0.143591\n",
      "round 108\n",
      "time to device 0.007895 sec\n",
      "time forward 1.130453 sec\n",
      "loss time 0.002235 sec\n",
      "backward time 0.011948 sec\n",
      "optimizer time 0.020145 sec\n",
      "training time in round 108 cost 0.4010450839996338 sec\n",
      "loss 2.191782, train acc 0.143635\n",
      "round 109\n",
      "time to device 0.007908 sec\n",
      "time forward 1.143060 sec\n",
      "loss time 0.001082 sec\n",
      "backward time 0.020204 sec\n",
      "optimizer time 0.023972 sec\n",
      "training time in round 109 cost 0.412581205368042 sec\n",
      "loss 2.190676, train acc 0.144176\n",
      "round 110\n",
      "time to device 0.006620 sec\n",
      "time forward 1.155273 sec\n",
      "loss time 0.001257 sec\n",
      "backward time 0.010779 sec\n",
      "optimizer time 0.020983 sec\n",
      "training time in round 110 cost 0.44159579277038574 sec\n",
      "loss 2.190090, train acc 0.144144\n",
      "round 111\n",
      "time to device 0.008286 sec\n",
      "time forward 1.167702 sec\n",
      "loss time 0.001059 sec\n",
      "backward time 0.010409 sec\n",
      "optimizer time 0.028204 sec\n",
      "training time in round 111 cost 0.39354491233825684 sec\n",
      "loss 2.189395, train acc 0.144601\n",
      "round 112\n",
      "time to device 0.008585 sec\n",
      "time forward 1.174957 sec\n",
      "loss time 0.000731 sec\n",
      "backward time 0.006768 sec\n",
      "optimizer time 0.016652 sec\n",
      "training time in round 112 cost 0.3612329959869385 sec\n",
      "loss 2.189819, train acc 0.144358\n",
      "round 113\n",
      "time to device 0.009935 sec\n",
      "time forward 1.193882 sec\n",
      "loss time 0.001225 sec\n",
      "backward time 0.017509 sec\n",
      "optimizer time 0.025702 sec\n",
      "training time in round 113 cost 0.4177098274230957 sec\n",
      "loss 2.188989, train acc 0.144600\n",
      "round 114\n",
      "time to device 0.007182 sec\n",
      "time forward 1.205768 sec\n",
      "loss time 0.001409 sec\n",
      "backward time 0.013013 sec\n",
      "optimizer time 0.022661 sec\n",
      "training time in round 114 cost 0.4093048572540283 sec\n",
      "loss 2.187720, train acc 0.144837\n",
      "round 115\n",
      "time to device 0.007479 sec\n",
      "time forward 1.212626 sec\n",
      "loss time 0.000558 sec\n",
      "backward time 0.005628 sec\n",
      "optimizer time 0.018864 sec\n",
      "training time in round 115 cost 0.35814499855041504 sec\n",
      "loss 2.186548, train acc 0.145474\n",
      "round 116\n",
      "time to device 0.007288 sec\n",
      "time forward 1.222621 sec\n",
      "loss time 0.000917 sec\n",
      "backward time 0.010901 sec\n",
      "optimizer time 0.021592 sec\n",
      "training time in round 116 cost 0.4048130512237549 sec\n",
      "loss 2.185236, train acc 0.146100\n",
      "round 117\n",
      "time to device 0.013847 sec\n",
      "time forward 1.229726 sec\n",
      "loss time 0.000450 sec\n",
      "backward time 0.004201 sec\n",
      "optimizer time 0.017143 sec\n",
      "training time in round 117 cost 0.40390920639038086 sec\n",
      "loss 2.184376, train acc 0.146451\n",
      "round 118\n",
      "time to device 0.046774 sec\n",
      "time forward 1.237684 sec\n",
      "loss time 0.000697 sec\n",
      "backward time 0.007371 sec\n",
      "optimizer time 0.027863 sec\n",
      "training time in round 118 cost 0.45458483695983887 sec\n",
      "loss 2.183567, train acc 0.146534\n",
      "round 119\n",
      "time to device 0.006606 sec\n",
      "time forward 1.242876 sec\n",
      "loss time 0.000397 sec\n",
      "backward time 0.004117 sec\n",
      "optimizer time 0.015060 sec\n",
      "training time in round 119 cost 0.3780338764190674 sec\n",
      "loss 2.182793, train acc 0.147135\n",
      "round 120\n",
      "time to device 0.006767 sec\n",
      "time forward 1.249079 sec\n",
      "loss time 0.000492 sec\n",
      "backward time 0.004452 sec\n",
      "optimizer time 0.015173 sec\n",
      "training time in round 120 cost 0.3730638027191162 sec\n",
      "loss 2.182723, train acc 0.147082\n",
      "round 121\n",
      "time to device 0.005644 sec\n",
      "time forward 1.258980 sec\n",
      "loss time 0.000843 sec\n",
      "backward time 0.007273 sec\n",
      "optimizer time 0.019497 sec\n",
      "training time in round 121 cost 0.3687019348144531 sec\n",
      "loss 2.181866, train acc 0.147669\n",
      "round 122\n",
      "time to device 0.008174 sec\n",
      "time forward 1.270412 sec\n",
      "loss time 0.000510 sec\n",
      "backward time 0.003524 sec\n",
      "optimizer time 0.012242 sec\n",
      "training time in round 122 cost 0.41275477409362793 sec\n",
      "loss 2.181187, train acc 0.147612\n",
      "round 123\n",
      "time to device 0.005353 sec\n",
      "time forward 1.278049 sec\n",
      "loss time 0.000913 sec\n",
      "backward time 0.007316 sec\n",
      "optimizer time 0.018368 sec\n",
      "training time in round 123 cost 0.3619520664215088 sec\n",
      "loss 2.179789, train acc 0.147744\n",
      "round 124\n",
      "time to device 0.013551 sec\n",
      "time forward 1.286714 sec\n",
      "loss time 0.000539 sec\n",
      "backward time 0.003767 sec\n",
      "optimizer time 0.012339 sec\n",
      "training time in round 124 cost 0.3785529136657715 sec\n",
      "loss 2.178315, train acc 0.148250\n",
      "round 125\n",
      "time to device 0.007051 sec\n",
      "time forward 1.291920 sec\n",
      "loss time 0.000514 sec\n",
      "backward time 0.004377 sec\n",
      "optimizer time 0.013558 sec\n",
      "training time in round 125 cost 0.36565184593200684 sec\n",
      "loss 2.177141, train acc 0.148375\n",
      "round 126\n",
      "time to device 0.005372 sec\n",
      "time forward 1.297612 sec\n",
      "loss time 0.000596 sec\n",
      "backward time 0.005589 sec\n",
      "optimizer time 0.024274 sec\n",
      "training time in round 126 cost 0.3852198123931885 sec\n",
      "loss 2.176196, train acc 0.148191\n",
      "round 127\n",
      "time to device 0.004814 sec\n",
      "time forward 1.303795 sec\n",
      "loss time 0.000564 sec\n",
      "backward time 0.004883 sec\n",
      "optimizer time 0.015040 sec\n",
      "training time in round 127 cost 0.36989307403564453 sec\n",
      "loss 2.175944, train acc 0.148010\n",
      "round 128\n",
      "time to device 0.004333 sec\n",
      "time forward 1.312816 sec\n",
      "loss time 0.000363 sec\n",
      "backward time 0.003316 sec\n",
      "optimizer time 0.010596 sec\n",
      "training time in round 128 cost 0.36261415481567383 sec\n",
      "loss 2.174661, train acc 0.148074\n",
      "round 129\n",
      "time to device 0.004243 sec\n",
      "time forward 1.317563 sec\n",
      "loss time 0.000350 sec\n",
      "backward time 0.003227 sec\n",
      "optimizer time 0.010608 sec\n",
      "training time in round 129 cost 0.34788012504577637 sec\n",
      "loss 2.173728, train acc 0.148197\n",
      "round 130\n",
      "time to device 0.004475 sec\n",
      "time forward 1.321104 sec\n",
      "loss time 0.000377 sec\n",
      "backward time 0.003465 sec\n",
      "optimizer time 0.010718 sec\n",
      "training time in round 130 cost 0.3424110412597656 sec\n",
      "loss 2.172332, train acc 0.148497\n",
      "round 131\n",
      "time to device 0.006679 sec\n",
      "time forward 1.330235 sec\n",
      "loss time 0.000496 sec\n",
      "backward time 0.004546 sec\n",
      "optimizer time 0.013760 sec\n",
      "training time in round 131 cost 0.3528780937194824 sec\n",
      "loss 2.172371, train acc 0.148497\n",
      "round 132\n",
      "time to device 0.007707 sec\n",
      "time forward 1.339819 sec\n",
      "loss time 0.000628 sec\n",
      "backward time 0.005502 sec\n",
      "optimizer time 0.015115 sec\n",
      "training time in round 132 cost 0.35826992988586426 sec\n",
      "loss 2.171531, train acc 0.148966\n",
      "round 133\n",
      "time to device 0.006069 sec\n",
      "time forward 1.349033 sec\n",
      "loss time 0.000464 sec\n",
      "backward time 0.004260 sec\n",
      "optimizer time 0.013973 sec\n",
      "training time in round 133 cost 0.35525083541870117 sec\n",
      "loss 2.170099, train acc 0.150012\n",
      "round 134\n",
      "time to device 0.006750 sec\n",
      "time forward 1.358665 sec\n",
      "loss time 0.000620 sec\n",
      "backward time 0.005800 sec\n",
      "optimizer time 0.015353 sec\n",
      "training time in round 134 cost 0.3616189956665039 sec\n",
      "loss 2.169169, train acc 0.150000\n",
      "round 135\n",
      "time to device 0.005114 sec\n",
      "time forward 1.366747 sec\n",
      "loss time 0.000410 sec\n",
      "backward time 0.004199 sec\n",
      "optimizer time 0.011817 sec\n",
      "training time in round 135 cost 0.35622692108154297 sec\n",
      "loss 2.168001, train acc 0.150506\n",
      "round 136\n",
      "time to device 0.008157 sec\n",
      "time forward 1.371638 sec\n",
      "loss time 0.000450 sec\n",
      "backward time 0.004168 sec\n",
      "optimizer time 0.013274 sec\n",
      "training time in round 136 cost 0.36028480529785156 sec\n",
      "loss 2.167254, train acc 0.150776\n",
      "round 137\n",
      "time to device 0.004921 sec\n",
      "time forward 1.376960 sec\n",
      "loss time 0.000491 sec\n",
      "backward time 0.004786 sec\n",
      "optimizer time 0.013521 sec\n",
      "training time in round 137 cost 0.36293697357177734 sec\n",
      "loss 2.165907, train acc 0.151664\n",
      "round 138\n",
      "time to device 0.006772 sec\n",
      "time forward 1.386248 sec\n",
      "loss time 0.001079 sec\n",
      "backward time 0.010204 sec\n",
      "optimizer time 0.019746 sec\n",
      "training time in round 138 cost 0.3663322925567627 sec\n",
      "loss 2.164367, train acc 0.152147\n",
      "round 139\n",
      "time to device 0.006958 sec\n",
      "time forward 1.393724 sec\n",
      "loss time 0.000696 sec\n",
      "backward time 0.004720 sec\n",
      "optimizer time 0.011537 sec\n",
      "training time in round 139 cost 0.35268688201904297 sec\n",
      "loss 2.163056, train acc 0.152734\n",
      "round 140\n",
      "time to device 0.007690 sec\n",
      "time forward 1.399847 sec\n",
      "loss time 0.000789 sec\n",
      "backward time 0.003813 sec\n",
      "optimizer time 0.011927 sec\n",
      "training time in round 140 cost 0.3915140628814697 sec\n",
      "loss 2.162069, train acc 0.152870\n",
      "round 141\n",
      "time to device 0.004529 sec\n",
      "time forward 1.407669 sec\n",
      "loss time 0.000867 sec\n",
      "backward time 0.008151 sec\n",
      "optimizer time 0.019773 sec\n",
      "training time in round 141 cost 0.38123178482055664 sec\n",
      "loss 2.161340, train acc 0.153004\n",
      "round 142\n",
      "time to device 0.006698 sec\n",
      "time forward 1.418326 sec\n",
      "loss time 0.001324 sec\n",
      "backward time 0.009958 sec\n",
      "optimizer time 0.022777 sec\n",
      "training time in round 142 cost 0.378676176071167 sec\n",
      "loss 2.159819, train acc 0.153573\n",
      "round 143\n",
      "time to device 0.007247 sec\n",
      "time forward 1.424887 sec\n",
      "loss time 0.000630 sec\n",
      "backward time 0.005559 sec\n",
      "optimizer time 0.015479 sec\n",
      "training time in round 143 cost 0.34829115867614746 sec\n",
      "loss 2.158747, train acc 0.153809\n",
      "round 144\n",
      "time to device 0.004678 sec\n",
      "time forward 1.430125 sec\n",
      "loss time 0.000431 sec\n",
      "backward time 0.005132 sec\n",
      "optimizer time 0.016352 sec\n",
      "training time in round 144 cost 0.4217550754547119 sec\n",
      "loss 2.158157, train acc 0.154095\n",
      "round 145\n",
      "time to device 0.005117 sec\n",
      "time forward 1.434571 sec\n",
      "loss time 0.000421 sec\n",
      "backward time 0.004346 sec\n",
      "optimizer time 0.012594 sec\n",
      "training time in round 145 cost 0.3571779727935791 sec\n",
      "loss 2.157026, train acc 0.154217\n",
      "round 146\n",
      "time to device 0.004850 sec\n",
      "time forward 1.439380 sec\n",
      "loss time 0.000439 sec\n",
      "backward time 0.004569 sec\n",
      "optimizer time 0.011453 sec\n",
      "training time in round 146 cost 0.33682775497436523 sec\n",
      "loss 2.155942, train acc 0.154602\n",
      "round 147\n",
      "time to device 0.005938 sec\n",
      "time forward 1.447626 sec\n",
      "loss time 0.000535 sec\n",
      "backward time 0.003767 sec\n",
      "optimizer time 0.011177 sec\n",
      "training time in round 147 cost 0.3646540641784668 sec\n",
      "loss 2.154960, train acc 0.154930\n",
      "round 148\n",
      "time to device 0.006876 sec\n",
      "time forward 1.453922 sec\n",
      "loss time 0.000419 sec\n",
      "backward time 0.003790 sec\n",
      "optimizer time 0.011537 sec\n",
      "training time in round 148 cost 0.41402101516723633 sec\n",
      "loss 2.153781, train acc 0.154887\n",
      "round 149\n",
      "time to device 0.006021 sec\n",
      "time forward 1.463327 sec\n",
      "loss time 0.000394 sec\n",
      "backward time 0.003780 sec\n",
      "optimizer time 0.019293 sec\n",
      "training time in round 149 cost 0.3868436813354492 sec\n",
      "loss 2.152482, train acc 0.155365\n",
      "round 150\n",
      "time to device 0.005280 sec\n",
      "time forward 1.472169 sec\n",
      "loss time 0.000608 sec\n",
      "backward time 0.004557 sec\n",
      "optimizer time 0.021196 sec\n",
      "training time in round 150 cost 0.43326735496520996 sec\n",
      "loss 2.151294, train acc 0.155733\n",
      "round 151\n",
      "time to device 0.005118 sec\n",
      "time forward 1.479624 sec\n",
      "loss time 0.003983 sec\n",
      "backward time 0.008961 sec\n",
      "optimizer time 0.022624 sec\n",
      "training time in round 151 cost 0.42061686515808105 sec\n",
      "loss 2.152108, train acc 0.155685\n",
      "round 152\n",
      "time to device 0.005302 sec\n",
      "time forward 1.493299 sec\n",
      "loss time 0.000546 sec\n",
      "backward time 0.003791 sec\n",
      "optimizer time 0.021132 sec\n",
      "training time in round 152 cost 0.40677905082702637 sec\n",
      "loss 2.150791, train acc 0.156148\n",
      "round 153\n",
      "time to device 0.006045 sec\n",
      "time forward 1.499975 sec\n",
      "loss time 0.000877 sec\n",
      "backward time 0.008215 sec\n",
      "optimizer time 0.019632 sec\n",
      "training time in round 153 cost 0.3724331855773926 sec\n",
      "loss 2.149294, train acc 0.156453\n",
      "round 154\n",
      "time to device 0.004844 sec\n",
      "time forward 1.511026 sec\n",
      "loss time 0.000417 sec\n",
      "backward time 0.003707 sec\n",
      "optimizer time 0.012859 sec\n",
      "training time in round 154 cost 0.36011695861816406 sec\n",
      "loss 2.148446, train acc 0.156502\n",
      "round 155\n",
      "time to device 0.004941 sec\n",
      "time forward 1.517238 sec\n",
      "loss time 0.000697 sec\n",
      "backward time 0.005032 sec\n",
      "optimizer time 0.014637 sec\n",
      "training time in round 155 cost 0.3712930679321289 sec\n",
      "loss 2.147732, train acc 0.156651\n",
      "round 156\n",
      "time to device 0.004943 sec\n",
      "time forward 1.522461 sec\n",
      "loss time 0.000508 sec\n",
      "backward time 0.004745 sec\n",
      "optimizer time 0.013683 sec\n",
      "training time in round 156 cost 0.3719649314880371 sec\n",
      "loss 2.146079, train acc 0.157295\n",
      "round 157\n",
      "time to device 0.008218 sec\n",
      "time forward 1.529856 sec\n",
      "loss time 0.000535 sec\n",
      "backward time 0.004421 sec\n",
      "optimizer time 0.015882 sec\n",
      "training time in round 157 cost 0.3777320384979248 sec\n",
      "loss 2.146224, train acc 0.157338\n",
      "round 158\n",
      "time to device 0.005555 sec\n",
      "time forward 1.538634 sec\n",
      "loss time 0.000378 sec\n",
      "backward time 0.003519 sec\n",
      "optimizer time 0.011807 sec\n",
      "training time in round 158 cost 0.3828279972076416 sec\n",
      "loss 2.145637, train acc 0.157773\n",
      "round 159\n",
      "time to device 0.004596 sec\n",
      "time forward 1.544171 sec\n",
      "loss time 0.000506 sec\n",
      "backward time 0.003805 sec\n",
      "optimizer time 0.012713 sec\n",
      "training time in round 159 cost 0.3756129741668701 sec\n",
      "loss 2.149237, train acc 0.158398\n",
      "round 160\n",
      "time to device 0.005020 sec\n",
      "time forward 1.549068 sec\n",
      "loss time 0.000420 sec\n",
      "backward time 0.003879 sec\n",
      "optimizer time 0.011819 sec\n",
      "training time in round 160 cost 0.36115407943725586 sec\n",
      "loss 2.185261, train acc 0.158240\n",
      "round 161\n",
      "time to device 0.006252 sec\n",
      "time forward 1.558160 sec\n",
      "loss time 0.000570 sec\n",
      "backward time 0.003516 sec\n",
      "optimizer time 0.010700 sec\n",
      "training time in round 161 cost 0.4010601043701172 sec\n",
      "loss 2.186299, train acc 0.158420\n",
      "round 162\n",
      "time to device 0.006707 sec\n",
      "time forward 1.564681 sec\n",
      "loss time 0.000572 sec\n",
      "backward time 0.005297 sec\n",
      "optimizer time 0.015126 sec\n",
      "training time in round 162 cost 0.36446213722229004 sec\n",
      "loss 2.187974, train acc 0.158167\n",
      "round 163\n",
      "time to device 0.004761 sec\n",
      "time forward 1.570221 sec\n",
      "loss time 0.000368 sec\n",
      "backward time 0.003763 sec\n",
      "optimizer time 0.013085 sec\n",
      "training time in round 163 cost 0.36522603034973145 sec\n",
      "loss 2.188510, train acc 0.158346\n",
      "round 164\n",
      "time to device 0.008212 sec\n",
      "time forward 1.577259 sec\n",
      "loss time 0.000459 sec\n",
      "backward time 0.004146 sec\n",
      "optimizer time 0.012580 sec\n",
      "training time in round 164 cost 0.3860468864440918 sec\n",
      "loss 2.192930, train acc 0.158286\n",
      "round 165\n",
      "time to device 0.004466 sec\n",
      "time forward 1.583233 sec\n",
      "loss time 0.000658 sec\n",
      "backward time 0.005767 sec\n",
      "optimizer time 0.015425 sec\n",
      "training time in round 165 cost 0.35189294815063477 sec\n",
      "loss 2.255877, train acc 0.157991\n",
      "round 166\n",
      "time to device 0.008136 sec\n",
      "time forward 1.588037 sec\n",
      "loss time 0.000448 sec\n",
      "backward time 0.004144 sec\n",
      "optimizer time 0.012318 sec\n",
      "training time in round 166 cost 0.3649458885192871 sec\n",
      "loss 2.266186, train acc 0.157747\n",
      "round 167\n",
      "time to device 0.005969 sec\n",
      "time forward 1.592794 sec\n",
      "loss time 0.000362 sec\n",
      "backward time 0.003590 sec\n",
      "optimizer time 0.012030 sec\n",
      "training time in round 167 cost 0.360821008682251 sec\n",
      "loss 2.269189, train acc 0.157599\n",
      "round 168\n",
      "time to device 0.011773 sec\n",
      "time forward 1.598098 sec\n",
      "loss time 0.000807 sec\n",
      "backward time 0.006674 sec\n",
      "optimizer time 0.017487 sec\n",
      "training time in round 168 cost 0.3834819793701172 sec\n",
      "loss 2.275208, train acc 0.157221\n",
      "round 169\n",
      "time to device 0.008007 sec\n",
      "time forward 1.607673 sec\n",
      "loss time 0.000390 sec\n",
      "backward time 0.003997 sec\n",
      "optimizer time 0.011958 sec\n",
      "training time in round 169 cost 0.35492587089538574 sec\n",
      "loss 2.276492, train acc 0.157077\n",
      "round 170\n",
      "time to device 0.004642 sec\n",
      "time forward 1.612871 sec\n",
      "loss time 0.000353 sec\n",
      "backward time 0.003316 sec\n",
      "optimizer time 0.010594 sec\n",
      "training time in round 170 cost 0.3497748374938965 sec\n",
      "loss 2.278039, train acc 0.156753\n",
      "round 171\n",
      "time to device 0.016683 sec\n",
      "time forward 1.618050 sec\n",
      "loss time 0.000441 sec\n",
      "backward time 0.003998 sec\n",
      "optimizer time 0.014080 sec\n",
      "training time in round 171 cost 0.3883509635925293 sec\n",
      "loss 2.528437, train acc 0.156477\n",
      "round 172\n",
      "time to device 0.008438 sec\n",
      "time forward 1.626886 sec\n",
      "loss time 0.000508 sec\n",
      "backward time 0.007894 sec\n",
      "optimizer time 0.013363 sec\n",
      "training time in round 172 cost 0.3816041946411133 sec\n",
      "loss 2.562420, train acc 0.156205\n",
      "round 173\n",
      "time to device 0.015468 sec\n",
      "time forward 1.634193 sec\n",
      "loss time 0.000452 sec\n",
      "backward time 0.003630 sec\n",
      "optimizer time 0.012110 sec\n",
      "training time in round 173 cost 0.42137980461120605 sec\n",
      "loss 2.667804, train acc 0.155577\n",
      "round 174\n",
      "time to device 0.004412 sec\n",
      "time forward 1.638802 sec\n",
      "loss time 0.000469 sec\n",
      "backward time 0.004269 sec\n",
      "optimizer time 0.013020 sec\n",
      "training time in round 174 cost 0.3525409698486328 sec\n",
      "loss 2.760268, train acc 0.155446\n",
      "round 175\n",
      "time to device 0.004496 sec\n",
      "time forward 1.644768 sec\n",
      "loss time 0.000435 sec\n",
      "backward time 0.003975 sec\n",
      "optimizer time 0.011739 sec\n",
      "training time in round 175 cost 0.3702659606933594 sec\n",
      "loss 3.098960, train acc 0.155318\n",
      "round 176\n",
      "time to device 0.009317 sec\n",
      "time forward 1.650956 sec\n",
      "loss time 0.000731 sec\n",
      "backward time 0.004700 sec\n",
      "optimizer time 0.015375 sec\n",
      "training time in round 176 cost 0.3942830562591553 sec\n",
      "loss 3.317696, train acc 0.155411\n",
      "round 177\n",
      "time to device 0.006595 sec\n",
      "time forward 1.658670 sec\n",
      "loss time 0.001359 sec\n",
      "backward time 0.009827 sec\n",
      "optimizer time 0.023994 sec\n",
      "training time in round 177 cost 0.3873300552368164 sec\n",
      "loss 3.451293, train acc 0.155065\n",
      "round 178\n",
      "time to device 0.007126 sec\n",
      "time forward 1.670365 sec\n",
      "loss time 0.001330 sec\n",
      "backward time 0.008685 sec\n",
      "optimizer time 0.020401 sec\n",
      "training time in round 178 cost 0.36907386779785156 sec\n",
      "loss 3.519052, train acc 0.154810\n",
      "round 179\n",
      "time to device 0.006750 sec\n",
      "time forward 1.682425 sec\n",
      "loss time 0.000840 sec\n",
      "backward time 0.007565 sec\n",
      "optimizer time 0.020671 sec\n",
      "training time in round 179 cost 0.37995314598083496 sec\n",
      "loss 3.619847, train acc 0.154253\n",
      "round 180\n",
      "time to device 0.006615 sec\n",
      "time forward 1.693497 sec\n",
      "loss time 0.001058 sec\n",
      "backward time 0.008231 sec\n",
      "optimizer time 0.019320 sec\n",
      "training time in round 180 cost 0.3704397678375244 sec\n",
      "loss 3.680230, train acc 0.154006\n",
      "round 181\n",
      "time to device 0.006554 sec\n",
      "time forward 1.703652 sec\n",
      "loss time 0.000866 sec\n",
      "backward time 0.007949 sec\n",
      "optimizer time 0.019099 sec\n",
      "training time in round 181 cost 0.36824917793273926 sec\n",
      "loss 3.757839, train acc 0.153846\n",
      "round 182\n",
      "time to device 0.007302 sec\n",
      "time forward 1.708817 sec\n",
      "loss time 0.000510 sec\n",
      "backward time 0.004775 sec\n",
      "optimizer time 0.013706 sec\n",
      "training time in round 182 cost 0.36904406547546387 sec\n",
      "loss 3.899840, train acc 0.153646\n",
      "round 183\n",
      "time to device 0.006626 sec\n",
      "time forward 1.714684 sec\n",
      "loss time 0.000560 sec\n",
      "backward time 0.005381 sec\n",
      "optimizer time 0.014712 sec\n",
      "training time in round 183 cost 0.3636438846588135 sec\n",
      "loss 4.007893, train acc 0.153320\n",
      "round 184\n",
      "time to device 0.006894 sec\n",
      "time forward 1.725343 sec\n",
      "loss time 0.001463 sec\n",
      "backward time 0.006851 sec\n",
      "optimizer time 0.011718 sec\n",
      "training time in round 184 cost 0.36984801292419434 sec\n",
      "loss 4.240318, train acc 0.152998\n",
      "round 185\n",
      "time to device 0.007992 sec\n",
      "time forward 1.734659 sec\n",
      "loss time 0.001178 sec\n",
      "backward time 0.007881 sec\n",
      "optimizer time 0.018408 sec\n",
      "training time in round 185 cost 0.3709421157836914 sec\n",
      "loss 4.403060, train acc 0.152722\n",
      "round 186\n",
      "time to device 0.006390 sec\n",
      "time forward 1.743763 sec\n",
      "loss time 0.001175 sec\n",
      "backward time 0.008601 sec\n",
      "optimizer time 0.020620 sec\n",
      "training time in round 186 cost 0.3646988868713379 sec\n",
      "loss 4.877782, train acc 0.152365\n",
      "round 187\n",
      "time to device 0.006793 sec\n",
      "time forward 1.763372 sec\n",
      "loss time 0.001412 sec\n",
      "backward time 0.010016 sec\n",
      "optimizer time 0.020418 sec\n",
      "training time in round 187 cost 0.39108991622924805 sec\n",
      "loss 4.936866, train acc 0.152178\n",
      "round 188\n",
      "time to device 0.006314 sec\n",
      "time forward 1.775463 sec\n",
      "loss time 0.001290 sec\n",
      "backward time 0.008252 sec\n",
      "optimizer time 0.019678 sec\n",
      "training time in round 188 cost 0.38274097442626953 sec\n",
      "loss 4.952259, train acc 0.151868\n",
      "round 189\n",
      "time to device 0.007100 sec\n",
      "time forward 1.785129 sec\n",
      "loss time 0.000982 sec\n",
      "backward time 0.008078 sec\n",
      "optimizer time 0.019723 sec\n",
      "training time in round 189 cost 0.37676334381103516 sec\n",
      "loss 5.033561, train acc 0.151727\n",
      "round 190\n",
      "time to device 0.006853 sec\n",
      "time forward 1.791327 sec\n",
      "loss time 0.000560 sec\n",
      "backward time 0.005188 sec\n",
      "optimizer time 0.014176 sec\n",
      "training time in round 190 cost 0.3439137935638428 sec\n",
      "loss 5.132833, train acc 0.151301\n",
      "round 191\n",
      "time to device 0.005697 sec\n",
      "time forward 1.801766 sec\n",
      "loss time 0.001401 sec\n",
      "backward time 0.008796 sec\n",
      "optimizer time 0.019754 sec\n",
      "training time in round 191 cost 0.3698689937591553 sec\n",
      "loss 5.177218, train acc 0.151082\n",
      "round 192\n",
      "time to device 0.003128 sec\n",
      "time forward 1.811303 sec\n",
      "loss time 0.001065 sec\n",
      "backward time 0.008360 sec\n",
      "optimizer time 0.019614 sec\n",
      "training time in round 192 cost 0.36834287643432617 sec\n",
      "loss 5.174868, train acc 0.150745\n",
      "round 193\n",
      "time to device 0.003451 sec\n",
      "time forward 1.817422 sec\n",
      "loss time 0.000600 sec\n",
      "backward time 0.005361 sec\n",
      "optimizer time 0.015286 sec\n",
      "training time in round 193 cost 0.37836289405822754 sec\n",
      "loss 5.190535, train acc 0.150532\n",
      "round 194\n",
      "time to device 0.006615 sec\n",
      "time forward 1.833094 sec\n",
      "loss time 0.000877 sec\n",
      "backward time 0.008652 sec\n",
      "optimizer time 0.019143 sec\n",
      "training time in round 194 cost 0.3987090587615967 sec\n",
      "loss 5.274368, train acc 0.150361\n",
      "round 195\n",
      "time to device 0.003190 sec\n",
      "time forward 1.838494 sec\n",
      "loss time 0.000579 sec\n",
      "backward time 0.004980 sec\n",
      "optimizer time 0.016165 sec\n",
      "training time in round 195 cost 0.3742220401763916 sec\n",
      "loss 5.300271, train acc 0.150311\n",
      "round 196\n",
      "time to device 0.083117 sec\n",
      "time forward 1.850549 sec\n",
      "loss time 0.001552 sec\n",
      "backward time 0.013188 sec\n",
      "optimizer time 0.050980 sec\n",
      "training time in round 196 cost 0.6973803043365479 sec\n",
      "loss 5.321398, train acc 0.150182\n",
      "round 197\n",
      "time to device 0.034909 sec\n",
      "time forward 1.861820 sec\n",
      "loss time 0.000418 sec\n",
      "backward time 0.003866 sec\n",
      "optimizer time 0.037207 sec\n",
      "training time in round 197 cost 0.5011880397796631 sec\n",
      "loss 5.315384, train acc 0.150016\n",
      "round 198\n",
      "time to device 0.009247 sec\n",
      "time forward 1.867706 sec\n",
      "loss time 0.000759 sec\n",
      "backward time 0.005762 sec\n",
      "optimizer time 0.018729 sec\n",
      "training time in round 198 cost 0.3783602714538574 sec\n",
      "loss 5.331654, train acc 0.149655\n",
      "round 199\n",
      "time to device 0.006273 sec\n",
      "time forward 1.874054 sec\n",
      "loss time 0.000610 sec\n",
      "backward time 0.006277 sec\n",
      "optimizer time 0.016447 sec\n",
      "training time in round 199 cost 0.523597002029419 sec\n",
      "loss 5.351656, train acc 0.149414\n",
      "round 200\n",
      "time to device 0.007154 sec\n",
      "time forward 1.883738 sec\n",
      "loss time 0.000692 sec\n",
      "backward time 0.005870 sec\n",
      "optimizer time 0.019608 sec\n",
      "training time in round 200 cost 0.46987104415893555 sec\n",
      "loss 5.351502, train acc 0.149059\n",
      "round 201\n",
      "time to device 0.006822 sec\n",
      "time forward 1.893089 sec\n",
      "loss time 0.000601 sec\n",
      "backward time 0.005322 sec\n",
      "optimizer time 0.020235 sec\n",
      "training time in round 201 cost 0.46030688285827637 sec\n",
      "loss 5.345397, train acc 0.148863\n",
      "round 202\n",
      "time to device 0.007778 sec\n",
      "time forward 1.909927 sec\n",
      "loss time 0.001555 sec\n",
      "backward time 0.020795 sec\n",
      "optimizer time 0.014459 sec\n",
      "training time in round 202 cost 0.4771609306335449 sec\n",
      "loss 5.334936, train acc 0.148591\n",
      "round 203\n",
      "time to device 0.012575 sec\n",
      "time forward 1.918573 sec\n",
      "loss time 0.000966 sec\n",
      "backward time 0.007058 sec\n",
      "optimizer time 0.019202 sec\n",
      "training time in round 203 cost 0.47830986976623535 sec\n",
      "loss 5.325085, train acc 0.148284\n",
      "round 204\n",
      "time to device 0.014839 sec\n",
      "time forward 1.933155 sec\n",
      "loss time 0.001468 sec\n",
      "backward time 0.012134 sec\n",
      "optimizer time 0.022270 sec\n",
      "training time in round 204 cost 0.42351222038269043 sec\n",
      "loss 5.314503, train acc 0.147866\n",
      "round 205\n",
      "time to device 0.008358 sec\n",
      "time forward 1.951194 sec\n",
      "loss time 0.001462 sec\n",
      "backward time 0.022806 sec\n",
      "optimizer time 0.021408 sec\n",
      "training time in round 205 cost 0.4249119758605957 sec\n",
      "loss 5.304152, train acc 0.147755\n",
      "round 206\n",
      "time to device 0.009396 sec\n",
      "time forward 1.965944 sec\n",
      "loss time 0.001182 sec\n",
      "backward time 0.020055 sec\n",
      "optimizer time 0.023769 sec\n",
      "training time in round 206 cost 0.4163949489593506 sec\n",
      "loss 5.292493, train acc 0.147494\n",
      "round 207\n",
      "time to device 0.008484 sec\n",
      "time forward 1.972910 sec\n",
      "loss time 0.000580 sec\n",
      "backward time 0.005252 sec\n",
      "optimizer time 0.015125 sec\n",
      "training time in round 207 cost 0.3599109649658203 sec\n",
      "loss 5.285712, train acc 0.147273\n",
      "round 208\n",
      "time to device 0.010115 sec\n",
      "time forward 1.986262 sec\n",
      "loss time 0.001350 sec\n",
      "backward time 0.015184 sec\n",
      "optimizer time 0.020568 sec\n",
      "training time in round 208 cost 0.4694530963897705 sec\n",
      "loss 5.372013, train acc 0.147241\n",
      "round 209\n",
      "time to device 0.006801 sec\n",
      "time forward 2.004856 sec\n",
      "loss time 0.001455 sec\n",
      "backward time 0.010933 sec\n",
      "optimizer time 0.023003 sec\n",
      "training time in round 209 cost 0.43193793296813965 sec\n",
      "loss 5.360584, train acc 0.147135\n",
      "round 210\n",
      "time to device 0.007324 sec\n",
      "time forward 2.015048 sec\n",
      "loss time 0.001178 sec\n",
      "backward time 0.012498 sec\n",
      "optimizer time 0.023268 sec\n",
      "training time in round 210 cost 0.3951296806335449 sec\n",
      "loss 5.376178, train acc 0.146919\n",
      "round 211\n",
      "time to device 0.009129 sec\n",
      "time forward 2.027614 sec\n",
      "loss time 0.001195 sec\n",
      "backward time 0.014979 sec\n",
      "optimizer time 0.028568 sec\n",
      "training time in round 211 cost 0.5185520648956299 sec\n",
      "loss 5.377276, train acc 0.146779\n",
      "round 212\n",
      "time to device 0.007087 sec\n",
      "time forward 2.040083 sec\n",
      "loss time 0.001386 sec\n",
      "backward time 0.014156 sec\n",
      "optimizer time 0.028577 sec\n",
      "training time in round 212 cost 0.43535900115966797 sec\n",
      "loss 5.388679, train acc 0.146384\n",
      "round 213\n",
      "time to device 0.007428 sec\n",
      "time forward 2.051017 sec\n",
      "loss time 0.001138 sec\n",
      "backward time 0.013837 sec\n",
      "optimizer time 0.028764 sec\n",
      "training time in round 213 cost 0.4273946285247803 sec\n",
      "loss 5.389479, train acc 0.146211\n",
      "round 214\n",
      "time to device 0.007389 sec\n",
      "time forward 2.057031 sec\n",
      "loss time 0.000492 sec\n",
      "backward time 0.005254 sec\n",
      "optimizer time 0.015724 sec\n",
      "training time in round 214 cost 0.37720704078674316 sec\n",
      "loss 5.398759, train acc 0.145785\n",
      "round 215\n",
      "time to device 0.008014 sec\n",
      "time forward 2.071585 sec\n",
      "loss time 0.001514 sec\n",
      "backward time 0.011974 sec\n",
      "optimizer time 0.026783 sec\n",
      "training time in round 215 cost 0.40018510818481445 sec\n",
      "loss 5.437487, train acc 0.145652\n",
      "round 216\n",
      "time to device 0.007983 sec\n",
      "time forward 2.082678 sec\n",
      "loss time 0.002601 sec\n",
      "backward time 0.012855 sec\n",
      "optimizer time 0.014297 sec\n",
      "training time in round 216 cost 0.3843100070953369 sec\n",
      "loss 5.635239, train acc 0.145665\n",
      "round 217\n",
      "time to device 0.006853 sec\n",
      "time forward 2.099346 sec\n",
      "loss time 0.001037 sec\n",
      "backward time 0.008884 sec\n",
      "optimizer time 0.019257 sec\n",
      "training time in round 217 cost 0.4310171604156494 sec\n",
      "loss 5.625658, train acc 0.145391\n",
      "round 218\n",
      "time to device 0.005061 sec\n",
      "time forward 2.111132 sec\n",
      "loss time 0.001717 sec\n",
      "backward time 0.013982 sec\n",
      "optimizer time 0.031222 sec\n",
      "training time in round 218 cost 0.4328877925872803 sec\n",
      "loss 5.629827, train acc 0.145191\n",
      "round 219\n",
      "time to device 0.007630 sec\n",
      "time forward 2.123227 sec\n",
      "loss time 0.001594 sec\n",
      "backward time 0.014383 sec\n",
      "optimizer time 0.024753 sec\n",
      "training time in round 219 cost 0.4125792980194092 sec\n",
      "loss 5.633250, train acc 0.144922\n",
      "round 220\n",
      "time to device 0.007397 sec\n",
      "time forward 2.140325 sec\n",
      "loss time 0.001940 sec\n",
      "backward time 0.008109 sec\n",
      "optimizer time 0.013118 sec\n",
      "training time in round 220 cost 0.39873790740966797 sec\n",
      "loss 5.624760, train acc 0.144796\n",
      "round 221\n",
      "time to device 0.012361 sec\n",
      "time forward 2.149852 sec\n",
      "loss time 0.000491 sec\n",
      "backward time 0.004520 sec\n",
      "optimizer time 0.012922 sec\n",
      "training time in round 221 cost 0.43309903144836426 sec\n",
      "loss 5.635430, train acc 0.144778\n",
      "round 222\n",
      "time to device 0.007982 sec\n",
      "time forward 2.157087 sec\n",
      "loss time 0.000600 sec\n",
      "backward time 0.005577 sec\n",
      "optimizer time 0.015173 sec\n",
      "training time in round 222 cost 0.4552171230316162 sec\n",
      "loss 5.645918, train acc 0.144689\n",
      "round 223\n",
      "time to device 0.007500 sec\n",
      "time forward 2.164293 sec\n",
      "loss time 0.000859 sec\n",
      "backward time 0.007457 sec\n",
      "optimizer time 0.017652 sec\n",
      "training time in round 223 cost 0.39934587478637695 sec\n",
      "loss 5.652253, train acc 0.144496\n",
      "round 224\n",
      "time to device 0.007676 sec\n",
      "time forward 2.177195 sec\n",
      "loss time 0.001879 sec\n",
      "backward time 0.013216 sec\n",
      "optimizer time 0.027078 sec\n",
      "training time in round 224 cost 0.4162459373474121 sec\n",
      "loss 5.647237, train acc 0.144236\n",
      "round 225\n",
      "time to device 0.009571 sec\n",
      "time forward 2.196276 sec\n",
      "loss time 0.001404 sec\n",
      "backward time 0.010315 sec\n",
      "optimizer time 0.022348 sec\n",
      "training time in round 225 cost 0.41567468643188477 sec\n",
      "loss 5.659587, train acc 0.144013\n",
      "round 226\n",
      "time to device 0.007695 sec\n",
      "time forward 2.208097 sec\n",
      "loss time 0.001052 sec\n",
      "backward time 0.010304 sec\n",
      "optimizer time 0.029516 sec\n",
      "training time in round 226 cost 0.430128812789917 sec\n",
      "loss 5.649954, train acc 0.143929\n",
      "round 227\n",
      "time to device 0.025634 sec\n",
      "time forward 2.220392 sec\n",
      "loss time 0.000439 sec\n",
      "backward time 0.007574 sec\n",
      "optimizer time 0.017385 sec\n",
      "training time in round 227 cost 0.5274150371551514 sec\n",
      "loss 5.648422, train acc 0.143949\n",
      "round 228\n",
      "time to device 0.007138 sec\n",
      "time forward 2.229275 sec\n",
      "loss time 0.001321 sec\n",
      "backward time 0.008463 sec\n",
      "optimizer time 0.022089 sec\n",
      "training time in round 228 cost 0.4576599597930908 sec\n",
      "loss 5.649773, train acc 0.143661\n",
      "round 229\n",
      "time to device 0.009337 sec\n",
      "time forward 2.240206 sec\n",
      "loss time 0.001067 sec\n",
      "backward time 0.015052 sec\n",
      "optimizer time 0.024709 sec\n",
      "training time in round 229 cost 0.42389583587646484 sec\n",
      "loss 5.671394, train acc 0.143546\n",
      "round 230\n",
      "time to device 0.007100 sec\n",
      "time forward 2.250934 sec\n",
      "loss time 0.001341 sec\n",
      "backward time 0.014033 sec\n",
      "optimizer time 0.027316 sec\n",
      "training time in round 230 cost 0.4221358299255371 sec\n",
      "loss 5.661967, train acc 0.143466\n",
      "round 231\n",
      "time to device 0.009267 sec\n",
      "time forward 2.262200 sec\n",
      "loss time 0.001350 sec\n",
      "backward time 0.012318 sec\n",
      "optimizer time 0.030219 sec\n",
      "training time in round 231 cost 0.4126720428466797 sec\n",
      "loss 5.651505, train acc 0.143420\n",
      "round 232\n",
      "time to device 0.008546 sec\n",
      "time forward 2.274724 sec\n",
      "loss time 0.001078 sec\n",
      "backward time 0.014190 sec\n",
      "optimizer time 0.025769 sec\n",
      "training time in round 232 cost 0.42244720458984375 sec\n",
      "loss 5.639424, train acc 0.143307\n",
      "round 233\n",
      "time to device 0.006561 sec\n",
      "time forward 2.289568 sec\n",
      "loss time 0.001168 sec\n",
      "backward time 0.014611 sec\n",
      "optimizer time 0.018069 sec\n",
      "training time in round 233 cost 0.4013078212738037 sec\n",
      "loss 5.703913, train acc 0.143129\n",
      "round 234\n",
      "time to device 0.007873 sec\n",
      "time forward 2.301013 sec\n",
      "loss time 0.000890 sec\n",
      "backward time 0.008286 sec\n",
      "optimizer time 0.019147 sec\n",
      "training time in round 234 cost 0.39093708992004395 sec\n",
      "loss 5.720244, train acc 0.142952\n",
      "round 235\n",
      "time to device 0.006317 sec\n",
      "time forward 2.312450 sec\n",
      "loss time 0.001404 sec\n",
      "backward time 0.011396 sec\n",
      "optimizer time 0.022454 sec\n",
      "training time in round 235 cost 0.4462769031524658 sec\n",
      "loss 5.714783, train acc 0.142810\n",
      "round 236\n",
      "time to device 0.007114 sec\n",
      "time forward 2.325956 sec\n",
      "loss time 0.001188 sec\n",
      "backward time 0.013596 sec\n",
      "optimizer time 0.019525 sec\n",
      "training time in round 236 cost 0.4116091728210449 sec\n",
      "loss 5.715014, train acc 0.142504\n",
      "round 237\n",
      "time to device 0.006850 sec\n",
      "time forward 2.339479 sec\n",
      "loss time 0.001144 sec\n",
      "backward time 0.014369 sec\n",
      "optimizer time 0.020448 sec\n",
      "training time in round 237 cost 0.411113977432251 sec\n",
      "loss 5.702969, train acc 0.142398\n",
      "round 238\n",
      "time to device 0.006396 sec\n",
      "time forward 2.347459 sec\n",
      "loss time 0.000402 sec\n",
      "backward time 0.004613 sec\n",
      "optimizer time 0.013918 sec\n",
      "training time in round 238 cost 0.3925817012786865 sec\n",
      "loss 5.691112, train acc 0.142096\n",
      "round 239\n",
      "time to device 0.007093 sec\n",
      "time forward 2.359809 sec\n",
      "loss time 0.000970 sec\n",
      "backward time 0.010054 sec\n",
      "optimizer time 0.019844 sec\n",
      "training time in round 239 cost 0.4194350242614746 sec\n",
      "loss 5.677785, train acc 0.142090\n",
      "round 240\n",
      "time to device 0.006298 sec\n",
      "time forward 2.371233 sec\n",
      "loss time 0.000933 sec\n",
      "backward time 0.010567 sec\n",
      "optimizer time 0.021751 sec\n",
      "training time in round 240 cost 0.41251301765441895 sec\n",
      "loss 5.671462, train acc 0.141695\n",
      "round 241\n",
      "time to device 0.010823 sec\n",
      "time forward 2.383221 sec\n",
      "loss time 0.001472 sec\n",
      "backward time 0.016684 sec\n",
      "optimizer time 0.024217 sec\n",
      "training time in round 241 cost 0.40802907943725586 sec\n",
      "loss 5.662249, train acc 0.141593\n",
      "round 242\n",
      "time to device 0.007554 sec\n",
      "time forward 2.390440 sec\n",
      "loss time 0.001608 sec\n",
      "backward time 0.005113 sec\n",
      "optimizer time 0.013937 sec\n",
      "training time in round 242 cost 0.37337374687194824 sec\n",
      "loss 5.652626, train acc 0.141493\n",
      "round 243\n",
      "time to device 0.007579 sec\n",
      "time forward 2.403009 sec\n",
      "loss time 0.002685 sec\n",
      "backward time 0.011815 sec\n",
      "optimizer time 0.022924 sec\n",
      "training time in round 243 cost 0.4391801357269287 sec\n",
      "loss 5.639711, train acc 0.141297\n",
      "round 244\n",
      "time to device 0.007730 sec\n",
      "time forward 2.415800 sec\n",
      "loss time 0.001096 sec\n",
      "backward time 0.016947 sec\n",
      "optimizer time 0.017806 sec\n",
      "training time in round 244 cost 0.4146451950073242 sec\n",
      "loss 5.627770, train acc 0.140944\n",
      "round 245\n",
      "time to device 0.010307 sec\n",
      "time forward 2.427042 sec\n",
      "loss time 0.001079 sec\n",
      "backward time 0.010495 sec\n",
      "optimizer time 0.028245 sec\n",
      "training time in round 245 cost 0.41742897033691406 sec\n",
      "loss 5.636203, train acc 0.140720\n",
      "round 246\n",
      "time to device 0.007172 sec\n",
      "time forward 2.434350 sec\n",
      "loss time 0.000633 sec\n",
      "backward time 0.005483 sec\n",
      "optimizer time 0.017646 sec\n",
      "training time in round 246 cost 0.39412999153137207 sec\n",
      "loss 5.625258, train acc 0.140340\n",
      "round 247\n",
      "time to device 0.006345 sec\n",
      "time forward 2.445897 sec\n",
      "loss time 0.000978 sec\n",
      "backward time 0.011105 sec\n",
      "optimizer time 0.023484 sec\n",
      "training time in round 247 cost 0.3996748924255371 sec\n",
      "loss 5.613826, train acc 0.140184\n",
      "round 248\n",
      "time to device 0.007143 sec\n",
      "time forward 2.458859 sec\n",
      "loss time 0.001669 sec\n",
      "backward time 0.032892 sec\n",
      "optimizer time 0.016799 sec\n",
      "training time in round 248 cost 0.4413290023803711 sec\n",
      "loss 5.639961, train acc 0.140186\n",
      "round 249\n",
      "time to device 0.006773 sec\n",
      "time forward 2.469238 sec\n",
      "loss time 0.000633 sec\n",
      "backward time 0.005459 sec\n",
      "optimizer time 0.021116 sec\n",
      "training time in round 249 cost 0.4496431350708008 sec\n",
      "loss 5.629110, train acc 0.139875\n",
      "round 250\n",
      "time to device 0.006579 sec\n",
      "time forward 2.479319 sec\n",
      "loss time 0.000411 sec\n",
      "backward time 0.003874 sec\n",
      "optimizer time 0.014902 sec\n",
      "training time in round 250 cost 0.5591349601745605 sec\n",
      "loss 5.629260, train acc 0.139816\n",
      "round 251\n",
      "time to device 0.006893 sec\n",
      "time forward 2.486091 sec\n",
      "loss time 0.000733 sec\n",
      "backward time 0.006842 sec\n",
      "optimizer time 0.019495 sec\n",
      "training time in round 251 cost 0.42626309394836426 sec\n",
      "loss 5.618576, train acc 0.139695\n",
      "round 252\n",
      "time to device 0.006845 sec\n",
      "time forward 2.494442 sec\n",
      "loss time 0.000874 sec\n",
      "backward time 0.008268 sec\n",
      "optimizer time 0.019496 sec\n",
      "training time in round 252 cost 0.3825352191925049 sec\n",
      "loss 5.611169, train acc 0.139482\n",
      "round 253\n",
      "time to device 0.008035 sec\n",
      "time forward 2.501101 sec\n",
      "loss time 0.000782 sec\n",
      "backward time 0.007179 sec\n",
      "optimizer time 0.017672 sec\n",
      "training time in round 253 cost 0.37158918380737305 sec\n",
      "loss 5.598181, train acc 0.139210\n",
      "round 254\n",
      "time to device 0.005757 sec\n",
      "time forward 2.509919 sec\n",
      "loss time 0.000472 sec\n",
      "backward time 0.004336 sec\n",
      "optimizer time 0.014649 sec\n",
      "training time in round 254 cost 0.35605502128601074 sec\n",
      "loss 5.594340, train acc 0.139185\n",
      "round 255\n",
      "time to device 0.007345 sec\n",
      "time forward 2.524086 sec\n",
      "loss time 0.001071 sec\n",
      "backward time 0.008740 sec\n",
      "optimizer time 0.019715 sec\n",
      "training time in round 255 cost 0.389240026473999 sec\n",
      "loss 5.592265, train acc 0.139252\n",
      "round 256\n",
      "time to device 0.006677 sec\n",
      "time forward 2.532457 sec\n",
      "loss time 0.001287 sec\n",
      "backward time 0.008591 sec\n",
      "optimizer time 0.019791 sec\n",
      "training time in round 256 cost 0.3605680465698242 sec\n",
      "loss 5.584646, train acc 0.139105\n",
      "round 257\n",
      "time to device 0.006804 sec\n",
      "time forward 2.541479 sec\n",
      "loss time 0.001189 sec\n",
      "backward time 0.004973 sec\n",
      "optimizer time 0.014204 sec\n",
      "training time in round 257 cost 0.3641481399536133 sec\n",
      "loss 5.573594, train acc 0.138838\n",
      "round 258\n",
      "time to device 0.006515 sec\n",
      "time forward 2.550495 sec\n",
      "loss time 0.001132 sec\n",
      "backward time 0.009563 sec\n",
      "optimizer time 0.019848 sec\n",
      "training time in round 258 cost 0.42810797691345215 sec\n",
      "loss 5.566732, train acc 0.138694\n",
      "round 259\n",
      "time to device 0.006933 sec\n",
      "time forward 2.561018 sec\n",
      "loss time 0.000675 sec\n",
      "backward time 0.006721 sec\n",
      "optimizer time 0.023882 sec\n",
      "training time in round 259 cost 0.3902111053466797 sec\n",
      "loss 5.556993, train acc 0.138582\n",
      "round 260\n",
      "time to device 0.006668 sec\n",
      "time forward 2.572316 sec\n",
      "loss time 0.000971 sec\n",
      "backward time 0.007139 sec\n",
      "optimizer time 0.019457 sec\n",
      "training time in round 260 cost 0.3749969005584717 sec\n",
      "loss 5.547874, train acc 0.138350\n",
      "round 261\n",
      "time to device 0.007140 sec\n",
      "time forward 2.579081 sec\n",
      "loss time 0.000783 sec\n",
      "backward time 0.006421 sec\n",
      "optimizer time 0.016597 sec\n",
      "training time in round 261 cost 0.3531029224395752 sec\n",
      "loss 5.535513, train acc 0.138210\n",
      "round 262\n",
      "time to device 0.006869 sec\n",
      "time forward 2.588917 sec\n",
      "loss time 0.001098 sec\n",
      "backward time 0.008496 sec\n",
      "optimizer time 0.020687 sec\n",
      "training time in round 262 cost 0.3972799777984619 sec\n",
      "loss 5.524419, train acc 0.137952\n",
      "round 263\n",
      "time to device 0.006974 sec\n",
      "time forward 2.598891 sec\n",
      "loss time 0.001103 sec\n",
      "backward time 0.009592 sec\n",
      "optimizer time 0.019273 sec\n",
      "training time in round 263 cost 0.37142300605773926 sec\n",
      "loss 5.519096, train acc 0.137843\n",
      "round 264\n",
      "time to device 0.007139 sec\n",
      "time forward 2.605302 sec\n",
      "loss time 0.000374 sec\n",
      "backward time 0.003514 sec\n",
      "optimizer time 0.010594 sec\n",
      "training time in round 264 cost 0.35459089279174805 sec\n",
      "loss 5.508743, train acc 0.137765\n",
      "round 265\n",
      "time to device 0.007734 sec\n",
      "time forward 2.616108 sec\n",
      "loss time 0.001232 sec\n",
      "backward time 0.009418 sec\n",
      "optimizer time 0.020425 sec\n",
      "training time in round 265 cost 0.41438984870910645 sec\n",
      "loss 5.496692, train acc 0.137659\n",
      "round 266\n",
      "time to device 0.006835 sec\n",
      "time forward 2.627159 sec\n",
      "loss time 0.000952 sec\n",
      "backward time 0.009954 sec\n",
      "optimizer time 0.020564 sec\n",
      "training time in round 266 cost 0.37863612174987793 sec\n",
      "loss 5.500399, train acc 0.137553\n",
      "round 267\n",
      "time to device 0.006952 sec\n",
      "time forward 2.638469 sec\n",
      "loss time 0.001002 sec\n",
      "backward time 0.008030 sec\n",
      "optimizer time 0.019439 sec\n",
      "training time in round 267 cost 0.38909387588500977 sec\n",
      "loss 5.494503, train acc 0.137273\n",
      "round 268\n",
      "time to device 0.009442 sec\n",
      "time forward 2.650393 sec\n",
      "loss time 0.001472 sec\n",
      "backward time 0.009271 sec\n",
      "optimizer time 0.020511 sec\n",
      "training time in round 268 cost 0.389542818069458 sec\n",
      "loss 5.482824, train acc 0.137198\n",
      "round 269\n",
      "time to device 0.006726 sec\n",
      "time forward 2.663749 sec\n",
      "loss time 0.000677 sec\n",
      "backward time 0.004565 sec\n",
      "optimizer time 0.014868 sec\n",
      "training time in round 269 cost 0.3710322380065918 sec\n",
      "loss 5.471370, train acc 0.137008\n",
      "round 270\n",
      "time to device 0.006252 sec\n",
      "time forward 2.674766 sec\n",
      "loss time 0.001078 sec\n",
      "backward time 0.006233 sec\n",
      "optimizer time 0.014234 sec\n",
      "training time in round 270 cost 0.38820505142211914 sec\n",
      "loss 5.459900, train acc 0.137021\n",
      "round 271\n",
      "time to device 0.006680 sec\n",
      "time forward 2.681262 sec\n",
      "loss time 0.000668 sec\n",
      "backward time 0.010076 sec\n",
      "optimizer time 0.016600 sec\n",
      "training time in round 271 cost 0.36583399772644043 sec\n",
      "loss 5.448297, train acc 0.136834\n",
      "round 272\n",
      "time to device 0.006433 sec\n",
      "time forward 2.691961 sec\n",
      "loss time 0.001120 sec\n",
      "backward time 0.004709 sec\n",
      "optimizer time 0.013732 sec\n",
      "training time in round 272 cost 0.41922903060913086 sec\n",
      "loss 5.436902, train acc 0.136647\n",
      "round 273\n",
      "time to device 0.007297 sec\n",
      "time forward 2.701737 sec\n",
      "loss time 0.001142 sec\n",
      "backward time 0.009513 sec\n",
      "optimizer time 0.021217 sec\n",
      "training time in round 273 cost 0.37805724143981934 sec\n",
      "loss 5.425413, train acc 0.136719\n",
      "round 274\n",
      "time to device 0.005767 sec\n",
      "time forward 2.708181 sec\n",
      "loss time 0.000480 sec\n",
      "backward time 0.004149 sec\n",
      "optimizer time 0.014976 sec\n",
      "training time in round 274 cost 0.37503886222839355 sec\n",
      "loss 5.414054, train acc 0.136506\n",
      "round 275\n",
      "time to device 0.005099 sec\n",
      "time forward 2.713359 sec\n",
      "loss time 0.000447 sec\n",
      "backward time 0.005059 sec\n",
      "optimizer time 0.014930 sec\n",
      "training time in round 275 cost 0.37280893325805664 sec\n",
      "loss 5.402780, train acc 0.136322\n",
      "round 276\n",
      "time to device 0.006645 sec\n",
      "time forward 2.721920 sec\n",
      "loss time 0.000473 sec\n",
      "backward time 0.004947 sec\n",
      "optimizer time 0.013680 sec\n",
      "training time in round 276 cost 0.3512918949127197 sec\n",
      "loss 5.392633, train acc 0.136282\n",
      "round 277\n",
      "time to device 0.008970 sec\n",
      "time forward 2.728833 sec\n",
      "loss time 0.000522 sec\n",
      "backward time 0.005666 sec\n",
      "optimizer time 0.015522 sec\n",
      "training time in round 277 cost 0.4267261028289795 sec\n",
      "loss 5.385725, train acc 0.136016\n",
      "round 278\n",
      "time to device 0.004698 sec\n",
      "time forward 2.733670 sec\n",
      "loss time 0.000650 sec\n",
      "backward time 0.004413 sec\n",
      "optimizer time 0.015537 sec\n",
      "training time in round 278 cost 0.36757707595825195 sec\n",
      "loss 5.389821, train acc 0.135865\n",
      "round 279\n",
      "time to device 0.007409 sec\n",
      "time forward 2.744000 sec\n",
      "loss time 0.001046 sec\n",
      "backward time 0.008932 sec\n",
      "optimizer time 0.055196 sec\n",
      "training time in round 279 cost 0.43242526054382324 sec\n",
      "loss 5.384282, train acc 0.135658\n",
      "round 280\n",
      "time to device 0.008190 sec\n",
      "time forward 2.753116 sec\n",
      "loss time 0.000697 sec\n",
      "backward time 0.007276 sec\n",
      "optimizer time 0.013210 sec\n",
      "training time in round 280 cost 0.5475602149963379 sec\n",
      "loss 5.374334, train acc 0.135509\n",
      "round 281\n",
      "time to device 0.006965 sec\n",
      "time forward 2.771354 sec\n",
      "loss time 0.000788 sec\n",
      "backward time 0.017631 sec\n",
      "optimizer time 0.069992 sec\n",
      "training time in round 281 cost 0.5077269077301025 sec\n",
      "loss 5.365544, train acc 0.135278\n",
      "round 282\n",
      "time to device 0.006389 sec\n",
      "time forward 2.791725 sec\n",
      "loss time 0.001318 sec\n",
      "backward time 0.008714 sec\n",
      "optimizer time 0.022085 sec\n",
      "training time in round 282 cost 0.41489720344543457 sec\n",
      "loss 5.354735, train acc 0.135325\n",
      "round 283\n",
      "time to device 0.007341 sec\n",
      "time forward 2.797987 sec\n",
      "loss time 0.000793 sec\n",
      "backward time 0.005177 sec\n",
      "optimizer time 0.020597 sec\n",
      "training time in round 283 cost 0.38452720642089844 sec\n",
      "loss 5.344430, train acc 0.135123\n",
      "round 284\n",
      "time to device 0.008090 sec\n",
      "time forward 2.805054 sec\n",
      "loss time 0.001022 sec\n",
      "backward time 0.008201 sec\n",
      "optimizer time 0.020688 sec\n",
      "training time in round 284 cost 0.3808858394622803 sec\n",
      "loss 5.334444, train acc 0.135033\n",
      "round 285\n",
      "time to device 0.006361 sec\n",
      "time forward 2.811277 sec\n",
      "loss time 0.000723 sec\n",
      "backward time 0.007078 sec\n",
      "optimizer time 0.017691 sec\n",
      "training time in round 285 cost 0.3768022060394287 sec\n",
      "loss 5.326639, train acc 0.134889\n",
      "round 286\n",
      "time to device 0.005152 sec\n",
      "time forward 2.817276 sec\n",
      "loss time 0.000405 sec\n",
      "backward time 0.003714 sec\n",
      "optimizer time 0.012745 sec\n",
      "training time in round 286 cost 0.3739802837371826 sec\n",
      "loss 5.334888, train acc 0.134691\n",
      "round 287\n",
      "time to device 0.006547 sec\n",
      "time forward 2.823182 sec\n",
      "loss time 0.000574 sec\n",
      "backward time 0.005004 sec\n",
      "optimizer time 0.014643 sec\n",
      "training time in round 287 cost 0.3741612434387207 sec\n",
      "loss 5.324536, train acc 0.134494\n",
      "round 288\n",
      "time to device 0.006882 sec\n",
      "time forward 2.830280 sec\n",
      "loss time 0.000406 sec\n",
      "backward time 0.004634 sec\n",
      "optimizer time 0.012247 sec\n",
      "training time in round 288 cost 0.35794901847839355 sec\n",
      "loss 5.315134, train acc 0.134299\n",
      "round 289\n",
      "time to device 0.005397 sec\n",
      "time forward 2.838317 sec\n",
      "loss time 0.001167 sec\n",
      "backward time 0.004278 sec\n",
      "optimizer time 0.016287 sec\n",
      "training time in round 289 cost 0.4056820869445801 sec\n",
      "loss 5.304784, train acc 0.134106\n",
      "round 290\n",
      "time to device 0.005279 sec\n",
      "time forward 2.844568 sec\n",
      "loss time 0.000462 sec\n",
      "backward time 0.004504 sec\n",
      "optimizer time 0.013402 sec\n",
      "training time in round 290 cost 0.39062023162841797 sec\n",
      "loss 5.299169, train acc 0.134074\n",
      "round 291\n",
      "time to device 0.006729 sec\n",
      "time forward 2.854634 sec\n",
      "loss time 0.000862 sec\n",
      "backward time 0.008272 sec\n",
      "optimizer time 0.019305 sec\n",
      "training time in round 291 cost 0.3702540397644043 sec\n",
      "loss 5.291533, train acc 0.133856\n",
      "round 292\n",
      "time to device 0.007266 sec\n",
      "time forward 2.860347 sec\n",
      "loss time 0.000566 sec\n",
      "backward time 0.005125 sec\n",
      "optimizer time 0.014281 sec\n",
      "training time in round 292 cost 0.3434302806854248 sec\n",
      "loss 5.281494, train acc 0.133719\n",
      "round 293\n",
      "time to device 0.007161 sec\n",
      "time forward 2.871495 sec\n",
      "loss time 0.001282 sec\n",
      "backward time 0.009238 sec\n",
      "optimizer time 0.020651 sec\n",
      "training time in round 293 cost 0.384768009185791 sec\n",
      "loss 5.271377, train acc 0.133610\n",
      "round 294\n",
      "time to device 0.006984 sec\n",
      "time forward 2.877593 sec\n",
      "loss time 0.000644 sec\n",
      "backward time 0.006069 sec\n",
      "optimizer time 0.015628 sec\n",
      "training time in round 294 cost 0.3878169059753418 sec\n",
      "loss 5.261322, train acc 0.133422\n",
      "round 295\n",
      "time to device 0.007276 sec\n",
      "time forward 2.887930 sec\n",
      "loss time 0.000850 sec\n",
      "backward time 0.008358 sec\n",
      "optimizer time 0.019392 sec\n",
      "training time in round 295 cost 0.3733198642730713 sec\n",
      "loss 5.252440, train acc 0.133261\n",
      "round 296\n",
      "time to device 0.006670 sec\n",
      "time forward 2.898001 sec\n",
      "loss time 0.001354 sec\n",
      "backward time 0.006839 sec\n",
      "optimizer time 0.017472 sec\n",
      "training time in round 296 cost 0.402587890625 sec\n",
      "loss 5.249227, train acc 0.133128\n",
      "round 297\n",
      "time to device 0.005333 sec\n",
      "time forward 2.903316 sec\n",
      "loss time 0.000541 sec\n",
      "backward time 0.004512 sec\n",
      "optimizer time 0.013559 sec\n",
      "training time in round 297 cost 0.36608195304870605 sec\n",
      "loss 5.240621, train acc 0.132917\n",
      "round 298\n",
      "time to device 0.006176 sec\n",
      "time forward 2.913007 sec\n",
      "loss time 0.000483 sec\n",
      "backward time 0.009121 sec\n",
      "optimizer time 0.012766 sec\n",
      "training time in round 298 cost 0.37368106842041016 sec\n",
      "loss 5.230808, train acc 0.132682\n",
      "round 299\n",
      "time to device 0.005325 sec\n",
      "time forward 2.919993 sec\n",
      "loss time 0.000591 sec\n",
      "backward time 0.004132 sec\n",
      "optimizer time 0.012336 sec\n",
      "training time in round 299 cost 0.44364094734191895 sec\n",
      "loss 5.228873, train acc 0.132604\n",
      "round 300\n",
      "time to device 0.012323 sec\n",
      "time forward 2.926824 sec\n",
      "loss time 0.000416 sec\n",
      "backward time 0.003686 sec\n",
      "optimizer time 0.011499 sec\n",
      "training time in round 300 cost 0.40829896926879883 sec\n",
      "loss 5.219190, train acc 0.132527\n",
      "round 301\n",
      "time to device 0.005847 sec\n",
      "time forward 2.932364 sec\n",
      "loss time 0.000452 sec\n",
      "backward time 0.003982 sec\n",
      "optimizer time 0.014774 sec\n",
      "training time in round 301 cost 0.37791895866394043 sec\n",
      "loss 5.209582, train acc 0.132502\n",
      "round 302\n",
      "time to device 0.005702 sec\n",
      "time forward 2.938538 sec\n",
      "loss time 0.000838 sec\n",
      "backward time 0.006680 sec\n",
      "optimizer time 0.016828 sec\n",
      "training time in round 302 cost 0.36767005920410156 sec\n",
      "loss 5.200619, train acc 0.132297\n",
      "round 303\n",
      "time to device 0.007544 sec\n",
      "time forward 2.950938 sec\n",
      "loss time 0.000707 sec\n",
      "backward time 0.006077 sec\n",
      "optimizer time 0.022401 sec\n",
      "training time in round 303 cost 0.40221619606018066 sec\n",
      "loss 5.191036, train acc 0.132119\n",
      "round 304\n",
      "time to device 0.006840 sec\n",
      "time forward 2.957503 sec\n",
      "loss time 0.000405 sec\n",
      "backward time 0.003670 sec\n",
      "optimizer time 0.013465 sec\n",
      "training time in round 304 cost 0.37133264541625977 sec\n",
      "loss 5.182711, train acc 0.131916\n",
      "round 305\n",
      "time to device 0.005567 sec\n",
      "time forward 2.963678 sec\n",
      "loss time 0.000555 sec\n",
      "backward time 0.004705 sec\n",
      "optimizer time 0.015744 sec\n",
      "training time in round 305 cost 0.40569281578063965 sec\n",
      "loss 5.173503, train acc 0.131842\n",
      "round 306\n",
      "time to device 0.005434 sec\n",
      "time forward 2.978726 sec\n",
      "loss time 0.000875 sec\n",
      "backward time 0.005089 sec\n",
      "optimizer time 0.022841 sec\n",
      "training time in round 306 cost 0.43376588821411133 sec\n",
      "loss 5.171881, train acc 0.131871\n",
      "round 307\n",
      "time to device 0.007176 sec\n",
      "time forward 2.989591 sec\n",
      "loss time 0.000487 sec\n",
      "backward time 0.004974 sec\n",
      "optimizer time 0.017004 sec\n",
      "training time in round 307 cost 0.4851350784301758 sec\n",
      "loss 5.163968, train acc 0.131798\n",
      "round 308\n",
      "time to device 0.006172 sec\n",
      "time forward 3.002808 sec\n",
      "loss time 0.000577 sec\n",
      "backward time 0.004329 sec\n",
      "optimizer time 0.014025 sec\n",
      "training time in round 308 cost 0.4468848705291748 sec\n",
      "loss 5.154592, train acc 0.131776\n",
      "round 309\n",
      "time to device 0.005426 sec\n",
      "time forward 3.013771 sec\n",
      "loss time 0.000421 sec\n",
      "backward time 0.005051 sec\n",
      "optimizer time 0.013253 sec\n",
      "training time in round 309 cost 0.3764941692352295 sec\n",
      "loss 5.146119, train acc 0.131628\n",
      "round 310\n",
      "time to device 0.007304 sec\n",
      "time forward 3.019532 sec\n",
      "loss time 0.000426 sec\n",
      "backward time 0.004042 sec\n",
      "optimizer time 0.012099 sec\n",
      "training time in round 310 cost 0.3980741500854492 sec\n",
      "loss 5.137294, train acc 0.131531\n",
      "round 311\n",
      "time to device 0.004404 sec\n",
      "time forward 3.025682 sec\n",
      "loss time 0.000403 sec\n",
      "backward time 0.003804 sec\n",
      "optimizer time 0.013291 sec\n",
      "training time in round 311 cost 0.37932801246643066 sec\n",
      "loss 5.131327, train acc 0.131360\n",
      "round 312\n",
      "time to device 0.005167 sec\n",
      "time forward 3.031244 sec\n",
      "loss time 0.000592 sec\n",
      "backward time 0.005402 sec\n",
      "optimizer time 0.015432 sec\n",
      "training time in round 312 cost 0.35147809982299805 sec\n",
      "loss 5.122397, train acc 0.131140\n",
      "round 313\n",
      "time to device 0.006494 sec\n",
      "time forward 3.036682 sec\n",
      "loss time 0.000644 sec\n",
      "backward time 0.006079 sec\n",
      "optimizer time 0.016653 sec\n",
      "training time in round 313 cost 0.3565969467163086 sec\n",
      "loss 5.114811, train acc 0.131096\n",
      "round 314\n",
      "time to device 0.007163 sec\n",
      "time forward 3.044846 sec\n",
      "loss time 0.001149 sec\n",
      "backward time 0.008554 sec\n",
      "optimizer time 0.019866 sec\n",
      "training time in round 314 cost 0.3766319751739502 sec\n",
      "loss 5.105882, train acc 0.131052\n",
      "round 315\n",
      "time to device 0.006114 sec\n",
      "time forward 3.057194 sec\n",
      "loss time 0.001181 sec\n",
      "backward time 0.004390 sec\n",
      "optimizer time 0.010895 sec\n",
      "training time in round 315 cost 0.36545801162719727 sec\n",
      "loss 5.097013, train acc 0.130884\n",
      "round 316\n",
      "time to device 0.007384 sec\n",
      "time forward 3.067424 sec\n",
      "loss time 0.001065 sec\n",
      "backward time 0.008812 sec\n",
      "optimizer time 0.021296 sec\n",
      "training time in round 316 cost 0.3862028121948242 sec\n",
      "loss 5.092202, train acc 0.130792\n",
      "round 317\n",
      "time to device 0.004853 sec\n",
      "time forward 3.077634 sec\n",
      "loss time 0.001196 sec\n",
      "backward time 0.013047 sec\n",
      "optimizer time 0.020293 sec\n",
      "training time in round 317 cost 0.3794097900390625 sec\n",
      "loss 5.086161, train acc 0.130749\n",
      "round 318\n",
      "time to device 0.006711 sec\n",
      "time forward 3.089091 sec\n",
      "loss time 0.001291 sec\n",
      "backward time 0.009088 sec\n",
      "optimizer time 0.019964 sec\n",
      "training time in round 318 cost 0.3878319263458252 sec\n",
      "loss 5.078405, train acc 0.130535\n",
      "round 319\n",
      "time to device 0.005066 sec\n",
      "time forward 3.095056 sec\n",
      "loss time 0.000512 sec\n",
      "backward time 0.005120 sec\n",
      "optimizer time 0.015858 sec\n",
      "training time in round 319 cost 0.3624110221862793 sec\n",
      "loss 5.075174, train acc 0.130298\n",
      "round 320\n",
      "time to device 0.006624 sec\n",
      "time forward 3.102011 sec\n",
      "loss time 0.000564 sec\n",
      "backward time 0.005311 sec\n",
      "optimizer time 0.014588 sec\n",
      "training time in round 320 cost 0.3482029438018799 sec\n",
      "loss 5.068032, train acc 0.130208\n",
      "round 321\n",
      "time to device 0.005301 sec\n",
      "time forward 3.111351 sec\n",
      "loss time 0.000725 sec\n",
      "backward time 0.006902 sec\n",
      "optimizer time 0.032444 sec\n",
      "training time in round 321 cost 0.40154504776000977 sec\n",
      "loss 5.059443, train acc 0.130095\n",
      "round 322\n",
      "time to device 0.004719 sec\n",
      "time forward 3.119721 sec\n",
      "loss time 0.001073 sec\n",
      "backward time 0.008937 sec\n",
      "optimizer time 0.020045 sec\n",
      "training time in round 322 cost 0.38593482971191406 sec\n",
      "loss 5.050913, train acc 0.129886\n",
      "round 323\n",
      "time to device 0.006522 sec\n",
      "time forward 3.129685 sec\n",
      "loss time 0.001044 sec\n",
      "backward time 0.009201 sec\n",
      "optimizer time 0.020253 sec\n",
      "training time in round 323 cost 0.36513590812683105 sec\n",
      "loss 5.051773, train acc 0.129726\n",
      "round 324\n",
      "time to device 0.006759 sec\n",
      "time forward 3.139229 sec\n",
      "loss time 0.001082 sec\n",
      "backward time 0.008559 sec\n",
      "optimizer time 0.020054 sec\n",
      "training time in round 324 cost 0.37195396423339844 sec\n",
      "loss 5.047004, train acc 0.129760\n",
      "round 325\n",
      "time to device 0.007309 sec\n",
      "time forward 3.147067 sec\n",
      "loss time 0.000859 sec\n",
      "backward time 0.008123 sec\n",
      "optimizer time 0.019072 sec\n",
      "training time in round 325 cost 0.3763601779937744 sec\n",
      "loss 5.039459, train acc 0.129697\n",
      "round 326\n",
      "time to device 0.006404 sec\n",
      "time forward 3.158225 sec\n",
      "loss time 0.001586 sec\n",
      "backward time 0.006106 sec\n",
      "optimizer time 0.023789 sec\n",
      "training time in round 326 cost 0.37868785858154297 sec\n",
      "loss 5.031089, train acc 0.129563\n",
      "round 327\n",
      "time to device 0.006624 sec\n",
      "time forward 3.164968 sec\n",
      "loss time 0.000511 sec\n",
      "backward time 0.009596 sec\n",
      "optimizer time 0.012853 sec\n",
      "training time in round 327 cost 0.3594400882720947 sec\n",
      "loss 5.022775, train acc 0.129502\n",
      "round 328\n",
      "time to device 0.006470 sec\n",
      "time forward 3.176528 sec\n",
      "loss time 0.001094 sec\n",
      "backward time 0.008245 sec\n",
      "optimizer time 0.019272 sec\n",
      "training time in round 328 cost 0.37918829917907715 sec\n",
      "loss 5.014500, train acc 0.129488\n",
      "round 329\n",
      "time to device 0.007310 sec\n",
      "time forward 3.187512 sec\n",
      "loss time 0.001168 sec\n",
      "backward time 0.008380 sec\n",
      "optimizer time 0.019336 sec\n",
      "training time in round 329 cost 0.3800058364868164 sec\n",
      "loss 5.006887, train acc 0.129380\n",
      "round 330\n",
      "time to device 0.006408 sec\n",
      "time forward 3.194813 sec\n",
      "loss time 0.000759 sec\n",
      "backward time 0.006490 sec\n",
      "optimizer time 0.016336 sec\n",
      "training time in round 330 cost 0.3568549156188965 sec\n",
      "loss 5.001729, train acc 0.129201\n",
      "round 331\n",
      "time to device 0.006941 sec\n",
      "time forward 3.206019 sec\n",
      "loss time 0.000864 sec\n",
      "backward time 0.007924 sec\n",
      "optimizer time 0.018823 sec\n",
      "training time in round 331 cost 0.40115809440612793 sec\n",
      "loss 4.993952, train acc 0.129165\n",
      "round 332\n",
      "time to device 0.004306 sec\n",
      "time forward 3.213032 sec\n",
      "loss time 0.001095 sec\n",
      "backward time 0.008530 sec\n",
      "optimizer time 0.019857 sec\n",
      "training time in round 332 cost 0.3705599308013916 sec\n",
      "loss 4.985983, train acc 0.129012\n",
      "round 333\n",
      "time to device 0.006712 sec\n",
      "time forward 3.219713 sec\n",
      "loss time 0.000629 sec\n",
      "backward time 0.006057 sec\n",
      "optimizer time 0.015846 sec\n",
      "training time in round 333 cost 0.34784626960754395 sec\n",
      "loss 4.978189, train acc 0.128859\n",
      "round 334\n",
      "time to device 0.006990 sec\n",
      "time forward 3.228883 sec\n",
      "loss time 0.001070 sec\n",
      "backward time 0.008554 sec\n",
      "optimizer time 0.019721 sec\n",
      "training time in round 334 cost 0.3792531490325928 sec\n",
      "loss 4.970648, train acc 0.128801\n",
      "round 335\n",
      "time to device 0.007110 sec\n",
      "time forward 3.242551 sec\n",
      "loss time 0.000850 sec\n",
      "backward time 0.008054 sec\n",
      "optimizer time 0.018884 sec\n",
      "training time in round 335 cost 0.38257694244384766 sec\n",
      "loss 4.962775, train acc 0.128627\n",
      "round 336\n",
      "time to device 0.007333 sec\n",
      "time forward 3.249371 sec\n",
      "loss time 0.000761 sec\n",
      "backward time 0.006628 sec\n",
      "optimizer time 0.016520 sec\n",
      "training time in round 336 cost 0.3513009548187256 sec\n",
      "loss 4.954881, train acc 0.128477\n",
      "round 337\n",
      "time to device 0.007683 sec\n",
      "time forward 3.260304 sec\n",
      "loss time 0.001179 sec\n",
      "backward time 0.008160 sec\n",
      "optimizer time 0.019248 sec\n",
      "training time in round 337 cost 0.36899614334106445 sec\n",
      "loss 4.946999, train acc 0.128467\n",
      "round 338\n",
      "time to device 0.003007 sec\n",
      "time forward 3.265635 sec\n",
      "loss time 0.000705 sec\n",
      "backward time 0.006049 sec\n",
      "optimizer time 0.010467 sec\n",
      "training time in round 338 cost 0.3583850860595703 sec\n",
      "loss 4.939215, train acc 0.128365\n",
      "round 339\n",
      "time to device 0.006714 sec\n",
      "time forward 3.277213 sec\n",
      "loss time 0.001106 sec\n",
      "backward time 0.008116 sec\n",
      "optimizer time 0.019273 sec\n",
      "training time in round 339 cost 0.4399847984313965 sec\n",
      "loss 4.931465, train acc 0.128240\n",
      "round 340\n",
      "time to device 0.005169 sec\n",
      "time forward 3.289530 sec\n",
      "loss time 0.000883 sec\n",
      "backward time 0.043664 sec\n",
      "optimizer time 0.026801 sec\n",
      "training time in round 340 cost 0.49060893058776855 sec\n",
      "loss 4.923759, train acc 0.128139\n",
      "round 341\n",
      "time to device 0.004835 sec\n",
      "time forward 3.294800 sec\n",
      "loss time 0.000523 sec\n",
      "backward time 0.005283 sec\n",
      "optimizer time 0.013244 sec\n",
      "training time in round 341 cost 0.35460925102233887 sec\n",
      "loss 4.916100, train acc 0.127970\n",
      "round 342\n",
      "time to device 0.006203 sec\n",
      "time forward 3.304024 sec\n",
      "loss time 0.002456 sec\n",
      "backward time 0.008971 sec\n",
      "optimizer time 0.021539 sec\n",
      "training time in round 342 cost 0.4303450584411621 sec\n",
      "loss 4.912922, train acc 0.127893\n",
      "round 343\n",
      "time to device 0.004837 sec\n",
      "time forward 3.309367 sec\n",
      "loss time 0.000643 sec\n",
      "backward time 0.004999 sec\n",
      "optimizer time 0.014574 sec\n",
      "training time in round 343 cost 0.35768914222717285 sec\n",
      "loss 4.905496, train acc 0.127839\n",
      "round 344\n",
      "time to device 0.008931 sec\n",
      "time forward 3.321408 sec\n",
      "loss time 0.000917 sec\n",
      "backward time 0.008287 sec\n",
      "optimizer time 0.024679 sec\n",
      "training time in round 344 cost 0.3973958492279053 sec\n",
      "loss 4.898712, train acc 0.127853\n",
      "round 345\n",
      "time to device 0.008046 sec\n",
      "time forward 3.331507 sec\n",
      "loss time 0.001353 sec\n",
      "backward time 0.012693 sec\n",
      "optimizer time 0.022602 sec\n",
      "training time in round 345 cost 0.41460204124450684 sec\n",
      "loss 4.891216, train acc 0.127687\n",
      "round 346\n",
      "time to device 0.020321 sec\n",
      "time forward 3.347258 sec\n",
      "loss time 0.001439 sec\n",
      "backward time 0.016998 sec\n",
      "optimizer time 0.023568 sec\n",
      "training time in round 346 cost 0.45069098472595215 sec\n",
      "loss 4.883758, train acc 0.127679\n",
      "round 347\n",
      "time to device 0.008053 sec\n",
      "time forward 3.366012 sec\n",
      "loss time 0.001094 sec\n",
      "backward time 0.014164 sec\n",
      "optimizer time 0.029012 sec\n",
      "training time in round 347 cost 0.4406619071960449 sec\n",
      "loss 4.876317, train acc 0.127649\n",
      "round 348\n",
      "time to device 0.008284 sec\n",
      "time forward 3.385991 sec\n",
      "loss time 0.001144 sec\n",
      "backward time 0.012667 sec\n",
      "optimizer time 0.026152 sec\n",
      "training time in round 348 cost 0.44034910202026367 sec\n",
      "loss 4.868941, train acc 0.127641\n",
      "round 349\n",
      "time to device 0.007638 sec\n",
      "time forward 3.399419 sec\n",
      "loss time 0.001525 sec\n",
      "backward time 0.011868 sec\n",
      "optimizer time 0.022097 sec\n",
      "training time in round 349 cost 0.4212076663970947 sec\n",
      "loss 4.861673, train acc 0.127522\n",
      "round 350\n",
      "time to device 0.006871 sec\n",
      "time forward 3.410461 sec\n",
      "loss time 0.001378 sec\n",
      "backward time 0.013030 sec\n",
      "optimizer time 0.023367 sec\n",
      "training time in round 350 cost 0.42172694206237793 sec\n",
      "loss 4.854412, train acc 0.127493\n",
      "round 351\n",
      "time to device 0.008958 sec\n",
      "time forward 3.427774 sec\n",
      "loss time 0.001910 sec\n",
      "backward time 0.015455 sec\n",
      "optimizer time 0.021805 sec\n",
      "training time in round 351 cost 0.42285585403442383 sec\n",
      "loss 4.847169, train acc 0.127353\n",
      "round 352\n",
      "time to device 0.010457 sec\n",
      "time forward 3.435178 sec\n",
      "loss time 0.000737 sec\n",
      "backward time 0.006087 sec\n",
      "optimizer time 0.016829 sec\n",
      "training time in round 352 cost 0.37106895446777344 sec\n",
      "loss 4.839914, train acc 0.127302\n",
      "round 353\n",
      "time to device 0.007551 sec\n",
      "time forward 3.446792 sec\n",
      "loss time 0.001415 sec\n",
      "backward time 0.013762 sec\n",
      "optimizer time 0.023766 sec\n",
      "training time in round 353 cost 0.4064929485321045 sec\n",
      "loss 4.838204, train acc 0.127141\n",
      "round 354\n",
      "time to device 0.008416 sec\n",
      "time forward 3.460401 sec\n",
      "loss time 0.002102 sec\n",
      "backward time 0.013559 sec\n",
      "optimizer time 0.023787 sec\n",
      "training time in round 354 cost 0.40543627738952637 sec\n",
      "loss 4.831185, train acc 0.126915\n",
      "round 355\n",
      "time to device 0.007739 sec\n",
      "time forward 3.468115 sec\n",
      "loss time 0.000735 sec\n",
      "backward time 0.006980 sec\n",
      "optimizer time 0.017558 sec\n",
      "training time in round 355 cost 0.3710141181945801 sec\n",
      "loss 4.828172, train acc 0.126778\n",
      "round 356\n",
      "time to device 0.011116 sec\n",
      "time forward 3.479901 sec\n",
      "loss time 0.001446 sec\n",
      "backward time 0.013023 sec\n",
      "optimizer time 0.021666 sec\n",
      "training time in round 356 cost 0.40790295600891113 sec\n",
      "loss 4.825223, train acc 0.126751\n",
      "round 357\n",
      "time to device 0.007108 sec\n",
      "time forward 3.493269 sec\n",
      "loss time 0.001508 sec\n",
      "backward time 0.014399 sec\n",
      "optimizer time 0.024603 sec\n",
      "training time in round 357 cost 0.38855767250061035 sec\n",
      "loss 4.818984, train acc 0.126724\n",
      "round 358\n",
      "time to device 0.009954 sec\n",
      "time forward 3.500594 sec\n",
      "loss time 0.000938 sec\n",
      "backward time 0.007740 sec\n",
      "optimizer time 0.016073 sec\n",
      "training time in round 358 cost 0.3834340572357178 sec\n",
      "loss 4.812011, train acc 0.126784\n",
      "round 359\n",
      "time to device 0.009343 sec\n",
      "time forward 3.516831 sec\n",
      "loss time 0.002263 sec\n",
      "backward time 0.025118 sec\n",
      "optimizer time 0.022398 sec\n",
      "training time in round 359 cost 0.4324150085449219 sec\n",
      "loss 4.805041, train acc 0.126649\n",
      "round 360\n",
      "time to device 0.008738 sec\n",
      "time forward 3.536626 sec\n",
      "loss time 0.005162 sec\n",
      "backward time 0.021666 sec\n",
      "optimizer time 0.024031 sec\n",
      "training time in round 360 cost 0.43380308151245117 sec\n",
      "loss 4.798092, train acc 0.126688\n",
      "round 361\n",
      "time to device 0.007012 sec\n",
      "time forward 3.549389 sec\n",
      "loss time 0.000772 sec\n",
      "backward time 0.007179 sec\n",
      "optimizer time 0.017404 sec\n",
      "training time in round 361 cost 0.37847089767456055 sec\n",
      "loss 4.792311, train acc 0.126705\n",
      "round 362\n",
      "time to device 0.006707 sec\n",
      "time forward 3.562225 sec\n",
      "loss time 0.001261 sec\n",
      "backward time 0.012180 sec\n",
      "optimizer time 0.021493 sec\n",
      "training time in round 362 cost 0.40793490409851074 sec\n",
      "loss 4.787115, train acc 0.126743\n",
      "round 363\n",
      "time to device 0.007196 sec\n",
      "time forward 3.572572 sec\n",
      "loss time 0.001142 sec\n",
      "backward time 0.015761 sec\n",
      "optimizer time 0.024035 sec\n",
      "training time in round 363 cost 0.3955671787261963 sec\n",
      "loss 4.780288, train acc 0.126760\n",
      "round 364\n",
      "time to device 0.010962 sec\n",
      "time forward 3.586312 sec\n",
      "loss time 0.001287 sec\n",
      "backward time 0.012067 sec\n",
      "optimizer time 0.027316 sec\n",
      "training time in round 364 cost 0.40727877616882324 sec\n",
      "loss 4.773580, train acc 0.126691\n",
      "round 365\n",
      "time to device 0.008106 sec\n",
      "time forward 3.599355 sec\n",
      "loss time 0.001951 sec\n",
      "backward time 0.013788 sec\n",
      "optimizer time 0.029198 sec\n",
      "training time in round 365 cost 0.4141709804534912 sec\n",
      "loss 4.768008, train acc 0.126516\n",
      "round 366\n",
      "time to device 0.008756 sec\n",
      "time forward 3.612937 sec\n",
      "loss time 0.002970 sec\n",
      "backward time 0.018926 sec\n",
      "optimizer time 0.021764 sec\n",
      "training time in round 366 cost 0.4155569076538086 sec\n",
      "loss 4.761401, train acc 0.126490\n",
      "round 367\n",
      "time to device 0.008262 sec\n",
      "time forward 3.630136 sec\n",
      "loss time 0.002260 sec\n",
      "backward time 0.011240 sec\n",
      "optimizer time 0.024967 sec\n",
      "training time in round 367 cost 0.46359682083129883 sec\n",
      "loss 4.769213, train acc 0.126422\n",
      "round 368\n",
      "time to device 0.006870 sec\n",
      "time forward 3.641753 sec\n",
      "loss time 0.007542 sec\n",
      "backward time 0.015798 sec\n",
      "optimizer time 0.025640 sec\n",
      "training time in round 368 cost 0.4026830196380615 sec\n",
      "loss 4.762608, train acc 0.126355\n",
      "round 369\n",
      "time to device 0.006965 sec\n",
      "time forward 3.649066 sec\n",
      "loss time 0.000876 sec\n",
      "backward time 0.007293 sec\n",
      "optimizer time 0.017150 sec\n",
      "training time in round 369 cost 0.36875271797180176 sec\n",
      "loss 4.756425, train acc 0.126225\n",
      "round 370\n",
      "time to device 0.008109 sec\n",
      "time forward 3.666069 sec\n",
      "loss time 0.001375 sec\n",
      "backward time 0.013154 sec\n",
      "optimizer time 0.025296 sec\n",
      "training time in round 370 cost 0.43802714347839355 sec\n",
      "loss 4.750752, train acc 0.126116\n",
      "round 371\n",
      "time to device 0.007518 sec\n",
      "time forward 3.678932 sec\n",
      "loss time 0.001504 sec\n",
      "backward time 0.014910 sec\n",
      "optimizer time 0.027494 sec\n",
      "training time in round 371 cost 0.42458105087280273 sec\n",
      "loss 4.745773, train acc 0.126050\n",
      "round 372\n",
      "time to device 0.009875 sec\n",
      "time forward 3.686483 sec\n",
      "loss time 0.000733 sec\n",
      "backward time 0.006563 sec\n",
      "optimizer time 0.019907 sec\n",
      "training time in round 372 cost 0.36202192306518555 sec\n",
      "loss 4.739651, train acc 0.125922\n",
      "round 373\n",
      "time to device 0.013465 sec\n",
      "time forward 3.698117 sec\n",
      "loss time 0.001538 sec\n",
      "backward time 0.015599 sec\n",
      "optimizer time 0.023904 sec\n",
      "training time in round 373 cost 0.40151190757751465 sec\n",
      "loss 4.733465, train acc 0.125836\n",
      "round 374\n",
      "time to device 0.009733 sec\n",
      "time forward 3.712433 sec\n",
      "loss time 0.001313 sec\n",
      "backward time 0.028727 sec\n",
      "optimizer time 0.022979 sec\n",
      "training time in round 374 cost 0.41864800453186035 sec\n",
      "loss 4.727028, train acc 0.125854\n",
      "round 375\n",
      "time to device 0.008037 sec\n",
      "time forward 3.719773 sec\n",
      "loss time 0.000764 sec\n",
      "backward time 0.006684 sec\n",
      "optimizer time 0.016763 sec\n",
      "training time in round 375 cost 0.36484813690185547 sec\n",
      "loss 4.720542, train acc 0.125790\n",
      "round 376\n",
      "time to device 0.009304 sec\n",
      "time forward 3.730368 sec\n",
      "loss time 0.001610 sec\n",
      "backward time 0.012718 sec\n",
      "optimizer time 0.041627 sec\n",
      "training time in round 376 cost 0.4223611354827881 sec\n",
      "loss 4.714145, train acc 0.125705\n",
      "round 377\n",
      "time to device 0.008985 sec\n",
      "time forward 3.739092 sec\n",
      "loss time 0.001052 sec\n",
      "backward time 0.009084 sec\n",
      "optimizer time 0.019788 sec\n",
      "training time in round 377 cost 0.3753528594970703 sec\n",
      "loss 4.707770, train acc 0.125558\n",
      "round 378\n",
      "time to device 0.008216 sec\n",
      "time forward 3.748842 sec\n",
      "loss time 0.000857 sec\n",
      "backward time 0.007452 sec\n",
      "optimizer time 0.017531 sec\n",
      "training time in round 378 cost 0.3781740665435791 sec\n",
      "loss 4.701428, train acc 0.125453\n",
      "round 379\n",
      "time to device 0.008358 sec\n",
      "time forward 3.756746 sec\n",
      "loss time 0.000923 sec\n",
      "backward time 0.013862 sec\n",
      "optimizer time 0.022757 sec\n",
      "training time in round 379 cost 0.3724639415740967 sec\n",
      "loss 4.695112, train acc 0.125493\n",
      "round 380\n",
      "time to device 0.006479 sec\n",
      "time forward 3.765105 sec\n",
      "loss time 0.001097 sec\n",
      "backward time 0.009507 sec\n",
      "optimizer time 0.020147 sec\n",
      "training time in round 380 cost 0.4172511100769043 sec\n",
      "loss 4.688889, train acc 0.125431\n",
      "round 381\n",
      "time to device 0.007431 sec\n",
      "time forward 3.776984 sec\n",
      "loss time 0.002138 sec\n",
      "backward time 0.018504 sec\n",
      "optimizer time 0.027637 sec\n",
      "training time in round 381 cost 0.4077932834625244 sec\n",
      "loss 4.685102, train acc 0.125429\n",
      "round 382\n",
      "time to device 0.009271 sec\n",
      "time forward 3.788527 sec\n",
      "loss time 0.001804 sec\n",
      "backward time 0.015017 sec\n",
      "optimizer time 0.014848 sec\n",
      "training time in round 382 cost 0.38349318504333496 sec\n",
      "loss 4.678912, train acc 0.125265\n",
      "round 383\n",
      "time to device 0.006113 sec\n",
      "time forward 3.804855 sec\n",
      "loss time 0.002009 sec\n",
      "backward time 0.014591 sec\n",
      "optimizer time 0.025843 sec\n",
      "training time in round 383 cost 0.4453561305999756 sec\n",
      "loss 4.672723, train acc 0.125224\n",
      "round 384\n",
      "time to device 0.008191 sec\n",
      "time forward 3.817530 sec\n",
      "loss time 0.001923 sec\n",
      "backward time 0.019917 sec\n",
      "optimizer time 0.029055 sec\n",
      "training time in round 384 cost 0.4286210536956787 sec\n",
      "loss 4.666571, train acc 0.125223\n",
      "round 385\n",
      "time to device 0.006985 sec\n",
      "time forward 3.834265 sec\n",
      "loss time 0.004907 sec\n",
      "backward time 0.018618 sec\n",
      "optimizer time 0.021865 sec\n",
      "training time in round 385 cost 0.4582552909851074 sec\n",
      "loss 4.661882, train acc 0.125182\n",
      "round 386\n",
      "time to device 0.010093 sec\n",
      "time forward 3.848466 sec\n",
      "loss time 0.001463 sec\n",
      "backward time 0.018614 sec\n",
      "optimizer time 0.025190 sec\n",
      "training time in round 386 cost 0.4110751152038574 sec\n",
      "loss 4.655788, train acc 0.125081\n",
      "round 387\n",
      "time to device 0.007571 sec\n",
      "time forward 3.861317 sec\n",
      "loss time 0.001343 sec\n",
      "backward time 0.014254 sec\n",
      "optimizer time 0.024125 sec\n",
      "training time in round 387 cost 0.410219669342041 sec\n",
      "loss 4.650345, train acc 0.125000\n",
      "round 388\n",
      "time to device 0.007612 sec\n",
      "time forward 3.869920 sec\n",
      "loss time 0.000474 sec\n",
      "backward time 0.004304 sec\n",
      "optimizer time 0.012329 sec\n",
      "training time in round 388 cost 0.37274909019470215 sec\n",
      "loss 4.644376, train acc 0.124960\n",
      "round 389\n",
      "time to device 0.007032 sec\n",
      "time forward 3.882192 sec\n",
      "loss time 0.000488 sec\n",
      "backward time 0.009099 sec\n",
      "optimizer time 0.023675 sec\n",
      "training time in round 389 cost 0.4062800407409668 sec\n",
      "loss 4.638375, train acc 0.124900\n",
      "round 390\n",
      "time to device 0.007289 sec\n",
      "time forward 3.894441 sec\n",
      "loss time 0.001964 sec\n",
      "backward time 0.017815 sec\n",
      "optimizer time 0.015754 sec\n",
      "training time in round 390 cost 0.41555094718933105 sec\n",
      "loss 4.632713, train acc 0.124920\n",
      "round 391\n",
      "time to device 0.008463 sec\n",
      "time forward 3.906913 sec\n",
      "loss time 0.001138 sec\n",
      "backward time 0.014904 sec\n",
      "optimizer time 0.036478 sec\n",
      "training time in round 391 cost 0.42811083793640137 sec\n",
      "loss 4.626803, train acc 0.124841\n",
      "round 392\n",
      "time to device 0.008601 sec\n",
      "time forward 3.917933 sec\n",
      "loss time 0.000727 sec\n",
      "backward time 0.007064 sec\n",
      "optimizer time 0.016575 sec\n",
      "training time in round 392 cost 0.36998867988586426 sec\n",
      "loss 4.620888, train acc 0.124761\n",
      "round 393\n",
      "time to device 0.004432 sec\n",
      "time forward 3.929906 sec\n",
      "loss time 0.001558 sec\n",
      "backward time 0.012235 sec\n",
      "optimizer time 0.025281 sec\n",
      "training time in round 393 cost 0.44553613662719727 sec\n",
      "loss 4.615007, train acc 0.124722\n",
      "round 394\n",
      "time to device 0.009675 sec\n",
      "time forward 3.942097 sec\n",
      "loss time 0.001077 sec\n",
      "backward time 0.022771 sec\n",
      "optimizer time 0.025332 sec\n",
      "training time in round 394 cost 0.40805673599243164 sec\n",
      "loss 4.609156, train acc 0.124684\n",
      "round 395\n",
      "time to device 0.006824 sec\n",
      "time forward 3.948692 sec\n",
      "loss time 0.000651 sec\n",
      "backward time 0.006469 sec\n",
      "optimizer time 0.017156 sec\n",
      "training time in round 395 cost 0.3545651435852051 sec\n",
      "loss 4.603340, train acc 0.124487\n",
      "round 396\n",
      "time to device 0.007962 sec\n",
      "time forward 3.954555 sec\n",
      "loss time 0.000669 sec\n",
      "backward time 0.009795 sec\n",
      "optimizer time 0.015174 sec\n",
      "training time in round 396 cost 0.34687018394470215 sec\n",
      "loss 4.597534, train acc 0.124547\n",
      "round 397\n",
      "time to device 0.012037 sec\n",
      "time forward 3.968515 sec\n",
      "loss time 0.001849 sec\n",
      "backward time 0.016449 sec\n",
      "optimizer time 0.027355 sec\n",
      "training time in round 397 cost 0.4156150817871094 sec\n",
      "loss 4.593663, train acc 0.124529\n",
      "round 398\n",
      "time to device 0.007380 sec\n",
      "time forward 3.977913 sec\n",
      "loss time 0.000679 sec\n",
      "backward time 0.006478 sec\n",
      "optimizer time 0.018777 sec\n",
      "training time in round 398 cost 0.4207170009613037 sec\n",
      "loss 4.587920, train acc 0.124510\n",
      "round 399\n",
      "time to device 0.009496 sec\n",
      "time forward 3.991025 sec\n",
      "loss time 0.001070 sec\n",
      "backward time 0.016145 sec\n",
      "optimizer time 0.024744 sec\n",
      "training time in round 399 cost 0.4644806385040283 sec\n",
      "loss 4.582205, train acc 0.124512\n",
      "round 400\n",
      "time to device 0.028111 sec\n",
      "time forward 4.004774 sec\n",
      "loss time 0.001274 sec\n",
      "backward time 0.017395 sec\n",
      "optimizer time 0.028864 sec\n",
      "training time in round 400 cost 0.5405781269073486 sec\n",
      "loss 4.576484, train acc 0.124591\n",
      "round 401\n",
      "time to device 0.011575 sec\n",
      "time forward 4.016737 sec\n",
      "loss time 0.000856 sec\n",
      "backward time 0.006845 sec\n",
      "optimizer time 0.018281 sec\n",
      "training time in round 401 cost 0.38239574432373047 sec\n",
      "loss 4.570837, train acc 0.124436\n",
      "round 402\n",
      "time to device 0.008100 sec\n",
      "time forward 4.029116 sec\n",
      "loss time 0.001212 sec\n",
      "backward time 0.018975 sec\n",
      "optimizer time 0.024719 sec\n",
      "training time in round 402 cost 0.41920995712280273 sec\n",
      "loss 4.565286, train acc 0.124302\n",
      "round 403\n",
      "time to device 0.007066 sec\n",
      "time forward 4.043217 sec\n",
      "loss time 0.002070 sec\n",
      "backward time 0.016728 sec\n",
      "optimizer time 0.022341 sec\n",
      "training time in round 403 cost 0.43626999855041504 sec\n",
      "loss 4.559755, train acc 0.124226\n",
      "round 404\n",
      "time to device 0.008224 sec\n",
      "time forward 4.052422 sec\n",
      "loss time 0.000786 sec\n",
      "backward time 0.007995 sec\n",
      "optimizer time 0.017897 sec\n",
      "training time in round 404 cost 0.42757296562194824 sec\n",
      "loss 4.554722, train acc 0.124171\n",
      "round 405\n",
      "time to device 0.007022 sec\n",
      "time forward 4.064041 sec\n",
      "loss time 0.001181 sec\n",
      "backward time 0.008388 sec\n",
      "optimizer time 0.018421 sec\n",
      "training time in round 405 cost 0.3731849193572998 sec\n",
      "loss 4.551389, train acc 0.124076\n",
      "round 406\n",
      "time to device 0.007263 sec\n",
      "time forward 4.076266 sec\n",
      "loss time 0.001587 sec\n",
      "backward time 0.012900 sec\n",
      "optimizer time 0.027570 sec\n",
      "training time in round 406 cost 0.3981759548187256 sec\n",
      "loss 4.545814, train acc 0.124251\n",
      "round 407\n",
      "time to device 0.008542 sec\n",
      "time forward 4.088125 sec\n",
      "loss time 0.001365 sec\n",
      "backward time 0.019621 sec\n",
      "optimizer time 0.023746 sec\n",
      "training time in round 407 cost 0.39288902282714844 sec\n",
      "loss 4.540313, train acc 0.124157\n",
      "round 408\n",
      "time to device 0.007474 sec\n",
      "time forward 4.093675 sec\n",
      "loss time 0.000481 sec\n",
      "backward time 0.007482 sec\n",
      "optimizer time 0.016470 sec\n",
      "training time in round 408 cost 0.3529021739959717 sec\n",
      "loss 4.535932, train acc 0.124140\n",
      "round 409\n",
      "time to device 0.010399 sec\n",
      "time forward 4.107957 sec\n",
      "loss time 0.000717 sec\n",
      "backward time 0.005997 sec\n",
      "optimizer time 0.015747 sec\n",
      "training time in round 409 cost 0.4558541774749756 sec\n",
      "loss 4.531534, train acc 0.124143\n",
      "round 410\n",
      "time to device 0.008012 sec\n",
      "time forward 4.122176 sec\n",
      "loss time 0.001884 sec\n",
      "backward time 0.014243 sec\n",
      "optimizer time 0.024283 sec\n",
      "training time in round 410 cost 0.396514892578125 sec\n",
      "loss 4.526349, train acc 0.123993\n",
      "round 411\n",
      "time to device 0.008152 sec\n",
      "time forward 4.128701 sec\n",
      "loss time 0.000882 sec\n",
      "backward time 0.007291 sec\n",
      "optimizer time 0.018201 sec\n",
      "training time in round 411 cost 0.3450949192047119 sec\n",
      "loss 4.520945, train acc 0.124071\n",
      "round 412\n",
      "time to device 0.006673 sec\n",
      "time forward 4.139199 sec\n",
      "loss time 0.000731 sec\n",
      "backward time 0.007000 sec\n",
      "optimizer time 0.019614 sec\n",
      "training time in round 412 cost 0.38808703422546387 sec\n",
      "loss 4.516960, train acc 0.124054\n",
      "round 413\n",
      "time to device 0.007767 sec\n",
      "time forward 4.151379 sec\n",
      "loss time 0.001276 sec\n",
      "backward time 0.014893 sec\n",
      "optimizer time 0.037910 sec\n",
      "training time in round 413 cost 0.4233739376068115 sec\n",
      "loss 4.511873, train acc 0.123887\n",
      "round 414\n",
      "time to device 0.011481 sec\n",
      "time forward 4.165658 sec\n",
      "loss time 0.001391 sec\n",
      "backward time 0.010993 sec\n",
      "optimizer time 0.048216 sec\n",
      "training time in round 414 cost 0.5374231338500977 sec\n",
      "loss 4.507931, train acc 0.123908\n",
      "round 415\n",
      "time to device 0.006953 sec\n",
      "time forward 4.176556 sec\n",
      "loss time 0.001600 sec\n",
      "backward time 0.011710 sec\n",
      "optimizer time 0.027436 sec\n",
      "training time in round 415 cost 0.4172039031982422 sec\n",
      "loss 4.505508, train acc 0.123836\n",
      "round 416\n",
      "time to device 0.007120 sec\n",
      "time forward 4.193553 sec\n",
      "loss time 0.001551 sec\n",
      "backward time 0.016288 sec\n",
      "optimizer time 0.032635 sec\n",
      "training time in round 416 cost 0.4332611560821533 sec\n",
      "loss 4.501212, train acc 0.123651\n",
      "round 417\n",
      "time to device 0.008004 sec\n",
      "time forward 4.234048 sec\n",
      "loss time 0.001257 sec\n",
      "backward time 0.015814 sec\n",
      "optimizer time 0.020151 sec\n",
      "training time in round 417 cost 0.5219070911407471 sec\n",
      "loss 4.496055, train acc 0.123561\n",
      "round 418\n",
      "time to device 0.008607 sec\n",
      "time forward 4.247833 sec\n",
      "loss time 0.001242 sec\n",
      "backward time 0.012996 sec\n",
      "optimizer time 0.020643 sec\n",
      "training time in round 418 cost 0.47055912017822266 sec\n",
      "loss 4.490899, train acc 0.123359\n",
      "round 419\n",
      "time to device 0.008362 sec\n",
      "time forward 4.257216 sec\n",
      "loss time 0.001175 sec\n",
      "backward time 0.012781 sec\n",
      "optimizer time 0.024740 sec\n",
      "training time in round 419 cost 0.42987489700317383 sec\n",
      "loss 4.485996, train acc 0.123400\n",
      "round 420\n",
      "time to device 0.008398 sec\n",
      "time forward 4.263747 sec\n",
      "loss time 0.000620 sec\n",
      "backward time 0.005376 sec\n",
      "optimizer time 0.016837 sec\n",
      "training time in round 420 cost 0.3976471424102783 sec\n",
      "loss 4.481364, train acc 0.123330\n",
      "round 421\n",
      "time to device 0.006456 sec\n",
      "time forward 4.272974 sec\n",
      "loss time 0.002191 sec\n",
      "backward time 0.023884 sec\n",
      "optimizer time 0.026554 sec\n",
      "training time in round 421 cost 0.43129897117614746 sec\n",
      "loss 4.476625, train acc 0.123315\n",
      "round 422\n",
      "time to device 0.007839 sec\n",
      "time forward 4.280732 sec\n",
      "loss time 0.000658 sec\n",
      "backward time 0.006214 sec\n",
      "optimizer time 0.015100 sec\n",
      "training time in round 422 cost 0.3757357597351074 sec\n",
      "loss 4.471962, train acc 0.123245\n",
      "round 423\n",
      "time to device 0.007344 sec\n",
      "time forward 4.291872 sec\n",
      "loss time 0.001043 sec\n",
      "backward time 0.011444 sec\n",
      "optimizer time 0.039099 sec\n",
      "training time in round 423 cost 0.43204402923583984 sec\n",
      "loss 4.466844, train acc 0.123231\n",
      "round 424\n",
      "time to device 0.007798 sec\n",
      "time forward 4.307374 sec\n",
      "loss time 0.001968 sec\n",
      "backward time 0.015626 sec\n",
      "optimizer time 0.023256 sec\n",
      "training time in round 424 cost 0.4167649745941162 sec\n",
      "loss 4.462898, train acc 0.123162\n",
      "round 425\n",
      "time to device 0.006949 sec\n",
      "time forward 4.313779 sec\n",
      "loss time 0.000641 sec\n",
      "backward time 0.007090 sec\n",
      "optimizer time 0.015277 sec\n",
      "training time in round 425 cost 0.3594388961791992 sec\n",
      "loss 4.457865, train acc 0.123148\n",
      "round 426\n",
      "time to device 0.006353 sec\n",
      "time forward 4.324974 sec\n",
      "loss time 0.001462 sec\n",
      "backward time 0.012958 sec\n",
      "optimizer time 0.029109 sec\n",
      "training time in round 426 cost 0.40429067611694336 sec\n",
      "loss 4.452819, train acc 0.123079\n",
      "round 427\n",
      "time to device 0.006803 sec\n",
      "time forward 4.336865 sec\n",
      "loss time 0.001089 sec\n",
      "backward time 0.010392 sec\n",
      "optimizer time 0.025636 sec\n",
      "training time in round 427 cost 0.39736294746398926 sec\n",
      "loss 4.447805, train acc 0.122937\n",
      "round 428\n",
      "time to device 0.006463 sec\n",
      "time forward 4.349289 sec\n",
      "loss time 0.000969 sec\n",
      "backward time 0.007813 sec\n",
      "optimizer time 0.018052 sec\n",
      "training time in round 428 cost 0.39319896697998047 sec\n",
      "loss 4.443197, train acc 0.122869\n",
      "round 429\n",
      "time to device 0.016466 sec\n",
      "time forward 4.362956 sec\n",
      "loss time 0.001217 sec\n",
      "backward time 0.014559 sec\n",
      "optimizer time 0.026980 sec\n",
      "training time in round 429 cost 0.47201085090637207 sec\n",
      "loss 4.438345, train acc 0.122838\n",
      "round 430\n",
      "time to device 0.010094 sec\n",
      "time forward 4.371188 sec\n",
      "loss time 0.000500 sec\n",
      "backward time 0.004424 sec\n",
      "optimizer time 0.020055 sec\n",
      "training time in round 430 cost 0.396848201751709 sec\n",
      "loss 4.433440, train acc 0.122861\n",
      "round 431\n",
      "time to device 0.008798 sec\n",
      "time forward 4.379617 sec\n",
      "loss time 0.000765 sec\n",
      "backward time 0.007048 sec\n",
      "optimizer time 0.020150 sec\n",
      "training time in round 431 cost 0.39604806900024414 sec\n",
      "loss 4.428543, train acc 0.122812\n",
      "round 432\n",
      "time to device 0.006510 sec\n",
      "time forward 4.390800 sec\n",
      "loss time 0.001000 sec\n",
      "backward time 0.022645 sec\n",
      "optimizer time 0.044852 sec\n",
      "training time in round 432 cost 0.41988110542297363 sec\n",
      "loss 4.423635, train acc 0.122745\n",
      "round 433\n",
      "time to device 0.007025 sec\n",
      "time forward 4.405692 sec\n",
      "loss time 0.000945 sec\n",
      "backward time 0.014589 sec\n",
      "optimizer time 0.023166 sec\n",
      "training time in round 433 cost 0.4291970729827881 sec\n",
      "loss 4.418751, train acc 0.122768\n",
      "round 434\n",
      "time to device 0.005939 sec\n",
      "time forward 4.412896 sec\n",
      "loss time 0.000833 sec\n",
      "backward time 0.007964 sec\n",
      "optimizer time 0.017693 sec\n",
      "training time in round 434 cost 0.37201404571533203 sec\n",
      "loss 4.414727, train acc 0.122683\n",
      "round 435\n",
      "time to device 0.006780 sec\n",
      "time forward 4.427381 sec\n",
      "loss time 0.001086 sec\n",
      "backward time 0.011135 sec\n",
      "optimizer time 0.031501 sec\n",
      "training time in round 435 cost 0.4166240692138672 sec\n",
      "loss 4.409965, train acc 0.122653\n",
      "round 436\n",
      "time to device 0.007314 sec\n",
      "time forward 4.439597 sec\n",
      "loss time 0.001221 sec\n",
      "backward time 0.010699 sec\n",
      "optimizer time 0.027952 sec\n",
      "training time in round 436 cost 0.3904860019683838 sec\n",
      "loss 4.405147, train acc 0.122587\n",
      "round 437\n",
      "time to device 0.005639 sec\n",
      "time forward 4.446759 sec\n",
      "loss time 0.000747 sec\n",
      "backward time 0.006714 sec\n",
      "optimizer time 0.018048 sec\n",
      "training time in round 437 cost 0.3956301212310791 sec\n",
      "loss 4.400356, train acc 0.122432\n",
      "round 438\n",
      "time to device 0.009093 sec\n",
      "time forward 4.465175 sec\n",
      "loss time 0.001146 sec\n",
      "backward time 0.017980 sec\n",
      "optimizer time 0.026627 sec\n",
      "training time in round 438 cost 0.4262349605560303 sec\n",
      "loss 4.395646, train acc 0.122331\n",
      "round 439\n",
      "time to device 0.007336 sec\n",
      "time forward 4.476358 sec\n",
      "loss time 0.001169 sec\n",
      "backward time 0.013718 sec\n",
      "optimizer time 0.027037 sec\n",
      "training time in round 439 cost 0.39856386184692383 sec\n",
      "loss 4.390886, train acc 0.122319\n",
      "round 440\n",
      "time to device 0.006525 sec\n",
      "time forward 4.484911 sec\n",
      "loss time 0.000722 sec\n",
      "backward time 0.006451 sec\n",
      "optimizer time 0.019052 sec\n",
      "training time in round 440 cost 0.3786289691925049 sec\n",
      "loss 4.386155, train acc 0.122201\n",
      "round 441\n",
      "time to device 0.010440 sec\n",
      "time forward 4.497147 sec\n",
      "loss time 0.001243 sec\n",
      "backward time 0.011258 sec\n",
      "optimizer time 0.028466 sec\n",
      "training time in round 441 cost 0.4166550636291504 sec\n",
      "loss 4.381483, train acc 0.122119\n",
      "round 442\n",
      "time to device 0.007741 sec\n",
      "time forward 4.505729 sec\n",
      "loss time 0.000899 sec\n",
      "backward time 0.007351 sec\n",
      "optimizer time 0.019148 sec\n",
      "training time in round 442 cost 0.4355788230895996 sec\n",
      "loss 4.378660, train acc 0.122073\n",
      "round 443\n",
      "time to device 0.006997 sec\n",
      "time forward 4.513046 sec\n",
      "loss time 0.000627 sec\n",
      "backward time 0.007406 sec\n",
      "optimizer time 0.012386 sec\n",
      "training time in round 443 cost 0.3688819408416748 sec\n",
      "loss 4.373988, train acc 0.122062\n",
      "round 444\n",
      "time to device 0.007400 sec\n",
      "time forward 4.525371 sec\n",
      "loss time 0.001538 sec\n",
      "backward time 0.011707 sec\n",
      "optimizer time 0.027487 sec\n",
      "training time in round 444 cost 0.47369384765625 sec\n",
      "loss 4.369417, train acc 0.121963\n",
      "round 445\n",
      "time to device 0.006511 sec\n",
      "time forward 4.539174 sec\n",
      "loss time 0.001458 sec\n",
      "backward time 0.016487 sec\n",
      "optimizer time 0.028310 sec\n",
      "training time in round 445 cost 0.4063072204589844 sec\n",
      "loss 4.364982, train acc 0.121970\n",
      "round 446\n",
      "time to device 0.010841 sec\n",
      "time forward 4.551430 sec\n",
      "loss time 0.000849 sec\n",
      "backward time 0.007234 sec\n",
      "optimizer time 0.017156 sec\n",
      "training time in round 446 cost 0.38483309745788574 sec\n",
      "loss 4.360367, train acc 0.121941\n",
      "round 447\n",
      "time to device 0.006527 sec\n",
      "time forward 4.562779 sec\n",
      "loss time 0.001370 sec\n",
      "backward time 0.016778 sec\n",
      "optimizer time 0.028299 sec\n",
      "training time in round 447 cost 0.42654919624328613 sec\n",
      "loss 4.356192, train acc 0.121913\n",
      "round 448\n",
      "time to device 0.007717 sec\n",
      "time forward 4.572390 sec\n",
      "loss time 0.001098 sec\n",
      "backward time 0.015151 sec\n",
      "optimizer time 0.016979 sec\n",
      "training time in round 448 cost 0.3908238410949707 sec\n",
      "loss 4.351618, train acc 0.121833\n",
      "round 449\n",
      "time to device 0.006694 sec\n",
      "time forward 4.579839 sec\n",
      "loss time 0.000662 sec\n",
      "backward time 0.006123 sec\n",
      "optimizer time 0.013331 sec\n",
      "training time in round 449 cost 0.388355016708374 sec\n",
      "loss 4.347066, train acc 0.121823\n",
      "round 450\n",
      "time to device 0.007262 sec\n",
      "time forward 4.592003 sec\n",
      "loss time 0.001896 sec\n",
      "backward time 0.019393 sec\n",
      "optimizer time 0.021659 sec\n",
      "training time in round 450 cost 0.41939306259155273 sec\n",
      "loss 4.342520, train acc 0.121795\n",
      "round 451\n",
      "time to device 0.006482 sec\n",
      "time forward 4.600024 sec\n",
      "loss time 0.000581 sec\n",
      "backward time 0.005493 sec\n",
      "optimizer time 0.015008 sec\n",
      "training time in round 451 cost 0.4047811031341553 sec\n",
      "loss 4.338013, train acc 0.121751\n",
      "round 452\n",
      "time to device 0.006162 sec\n",
      "time forward 4.607877 sec\n",
      "loss time 0.000748 sec\n",
      "backward time 0.006748 sec\n",
      "optimizer time 0.016220 sec\n",
      "training time in round 452 cost 0.3626527786254883 sec\n",
      "loss 4.333529, train acc 0.121620\n",
      "round 453\n",
      "time to device 0.008366 sec\n",
      "time forward 4.620329 sec\n",
      "loss time 0.001129 sec\n",
      "backward time 0.014226 sec\n",
      "optimizer time 0.029193 sec\n",
      "training time in round 453 cost 0.4139590263366699 sec\n",
      "loss 4.329050, train acc 0.121421\n",
      "round 454\n",
      "time to device 0.006525 sec\n",
      "time forward 4.631238 sec\n",
      "loss time 0.001016 sec\n",
      "backward time 0.012711 sec\n",
      "optimizer time 0.026211 sec\n",
      "training time in round 454 cost 0.40935587882995605 sec\n",
      "loss 4.324963, train acc 0.121343\n",
      "round 455\n",
      "time to device 0.007187 sec\n",
      "time forward 4.638242 sec\n",
      "loss time 0.000386 sec\n",
      "backward time 0.003542 sec\n",
      "optimizer time 0.011218 sec\n",
      "training time in round 455 cost 0.3550419807434082 sec\n",
      "loss 4.320719, train acc 0.121334\n",
      "round 456\n",
      "time to device 0.007048 sec\n",
      "time forward 4.652259 sec\n",
      "loss time 0.000957 sec\n",
      "backward time 0.009989 sec\n",
      "optimizer time 0.020753 sec\n",
      "training time in round 456 cost 0.40328311920166016 sec\n",
      "loss 4.316298, train acc 0.121273\n",
      "round 457\n",
      "time to device 0.007237 sec\n",
      "time forward 4.662553 sec\n",
      "loss time 0.000957 sec\n",
      "backward time 0.010732 sec\n",
      "optimizer time 0.022563 sec\n",
      "training time in round 457 cost 0.38431310653686523 sec\n",
      "loss 4.311906, train acc 0.121230\n",
      "round 458\n",
      "time to device 0.007275 sec\n",
      "time forward 4.677702 sec\n",
      "loss time 0.001168 sec\n",
      "backward time 0.012800 sec\n",
      "optimizer time 0.020699 sec\n",
      "training time in round 458 cost 0.41037797927856445 sec\n",
      "loss 4.307524, train acc 0.121170\n",
      "round 459\n",
      "time to device 0.007277 sec\n",
      "time forward 4.684475 sec\n",
      "loss time 0.000431 sec\n",
      "backward time 0.003875 sec\n",
      "optimizer time 0.012080 sec\n",
      "training time in round 459 cost 0.36470699310302734 sec\n",
      "loss 4.303233, train acc 0.121094\n",
      "round 460\n",
      "time to device 0.006896 sec\n",
      "time forward 4.696850 sec\n",
      "loss time 0.000999 sec\n",
      "backward time 0.012133 sec\n",
      "optimizer time 0.028869 sec\n",
      "training time in round 460 cost 0.3963930606842041 sec\n",
      "loss 4.298889, train acc 0.121068\n",
      "round 461\n",
      "time to device 0.006844 sec\n",
      "time forward 4.706061 sec\n",
      "loss time 0.000858 sec\n",
      "backward time 0.007452 sec\n",
      "optimizer time 0.017344 sec\n",
      "training time in round 461 cost 0.3710970878601074 sec\n",
      "loss 4.294577, train acc 0.120958\n",
      "round 462\n",
      "time to device 0.006580 sec\n",
      "time forward 4.718847 sec\n",
      "loss time 0.001204 sec\n",
      "backward time 0.014436 sec\n",
      "optimizer time 0.027422 sec\n",
      "training time in round 462 cost 0.39774107933044434 sec\n",
      "loss 4.290570, train acc 0.120933\n",
      "round 463\n",
      "time to device 0.009209 sec\n",
      "time forward 4.728524 sec\n",
      "loss time 0.000907 sec\n",
      "backward time 0.008165 sec\n",
      "optimizer time 0.018246 sec\n",
      "training time in round 463 cost 0.3769190311431885 sec\n",
      "loss 4.286288, train acc 0.120858\n",
      "round 464\n",
      "time to device 0.003537 sec\n",
      "time forward 4.743312 sec\n",
      "loss time 0.001202 sec\n",
      "backward time 0.011808 sec\n",
      "optimizer time 0.029495 sec\n",
      "training time in round 464 cost 0.39979982376098633 sec\n",
      "loss 4.282030, train acc 0.120766\n",
      "round 465\n",
      "time to device 0.003439 sec\n",
      "time forward 4.753754 sec\n",
      "loss time 0.000845 sec\n",
      "backward time 0.008039 sec\n",
      "optimizer time 0.020268 sec\n",
      "training time in round 465 cost 0.3776979446411133 sec\n",
      "loss 4.278111, train acc 0.120708\n",
      "round 466\n",
      "time to device 0.003446 sec\n",
      "time forward 4.766322 sec\n",
      "loss time 0.001160 sec\n",
      "backward time 0.012832 sec\n",
      "optimizer time 0.024633 sec\n",
      "training time in round 466 cost 0.3885650634765625 sec\n",
      "loss 4.273948, train acc 0.120650\n",
      "round 467\n",
      "time to device 0.003503 sec\n",
      "time forward 4.774869 sec\n",
      "loss time 0.000991 sec\n",
      "backward time 0.004921 sec\n",
      "optimizer time 0.016203 sec\n",
      "training time in round 467 cost 0.3629920482635498 sec\n",
      "loss 4.269798, train acc 0.120693\n",
      "round 468\n",
      "time to device 0.003046 sec\n",
      "time forward 4.792361 sec\n",
      "loss time 0.001515 sec\n",
      "backward time 0.016385 sec\n",
      "optimizer time 0.020599 sec\n",
      "training time in round 468 cost 0.3351898193359375 sec\n",
      "loss 4.266649, train acc 0.120683\n",
      "test acc is 0.100000\n",
      "epoch 3, time 1764.401994 sec\n",
      "epoch 5\n",
      "round 0\n",
      "time to device 0.030552 sec\n",
      "time forward 0.013047 sec\n",
      "loss time 0.002076 sec\n",
      "backward time 0.012815 sec\n",
      "optimizer time 0.070602 sec\n",
      "training time in round 0 cost 0.6312830448150635 sec\n",
      "loss 2.312492, train acc 0.109375\n",
      "round 1\n",
      "time to device 0.006685 sec\n",
      "time forward 0.025850 sec\n",
      "loss time 0.001056 sec\n",
      "backward time 0.014140 sec\n",
      "optimizer time 0.019518 sec\n",
      "training time in round 1 cost 0.48833465576171875 sec\n",
      "loss 2.367430, train acc 0.089844\n",
      "round 2\n",
      "time to device 0.006924 sec\n",
      "time forward 0.041997 sec\n",
      "loss time 0.001084 sec\n",
      "backward time 0.014990 sec\n",
      "optimizer time 0.029226 sec\n",
      "training time in round 2 cost 0.42931103706359863 sec\n",
      "loss 2.345899, train acc 0.096354\n",
      "round 3\n",
      "time to device 0.007637 sec\n",
      "time forward 0.050661 sec\n",
      "loss time 0.000956 sec\n",
      "backward time 0.007725 sec\n",
      "optimizer time 0.018710 sec\n",
      "training time in round 3 cost 0.4230310916900635 sec\n",
      "loss 2.340447, train acc 0.101562\n",
      "round 4\n",
      "time to device 0.008142 sec\n",
      "time forward 0.063362 sec\n",
      "loss time 0.001033 sec\n",
      "backward time 0.010881 sec\n",
      "optimizer time 0.027848 sec\n",
      "training time in round 4 cost 0.4201667308807373 sec\n",
      "loss 2.332811, train acc 0.095312\n",
      "round 5\n",
      "time to device 0.006351 sec\n",
      "time forward 0.074230 sec\n",
      "loss time 0.000436 sec\n",
      "backward time 0.004438 sec\n",
      "optimizer time 0.013353 sec\n",
      "training time in round 5 cost 0.37511229515075684 sec\n",
      "loss 2.327955, train acc 0.102865\n",
      "round 6\n",
      "time to device 0.006619 sec\n",
      "time forward 0.082622 sec\n",
      "loss time 0.001040 sec\n",
      "backward time 0.007300 sec\n",
      "optimizer time 0.040923 sec\n",
      "training time in round 6 cost 0.4089491367340088 sec\n",
      "loss 2.324861, train acc 0.097098\n",
      "round 7\n",
      "time to device 0.006129 sec\n",
      "time forward 0.094962 sec\n",
      "loss time 0.001032 sec\n",
      "backward time 0.017670 sec\n",
      "optimizer time 0.027162 sec\n",
      "training time in round 7 cost 0.4312021732330322 sec\n",
      "loss 2.322253, train acc 0.092773\n",
      "round 8\n",
      "time to device 0.007976 sec\n",
      "time forward 0.105996 sec\n",
      "loss time 0.001793 sec\n",
      "backward time 0.010165 sec\n",
      "optimizer time 0.029845 sec\n",
      "training time in round 8 cost 0.4154696464538574 sec\n",
      "loss 2.320045, train acc 0.097222\n",
      "round 9\n",
      "time to device 0.006642 sec\n",
      "time forward 0.119473 sec\n",
      "loss time 0.001056 sec\n",
      "backward time 0.009304 sec\n",
      "optimizer time 0.020579 sec\n",
      "training time in round 9 cost 0.39972782135009766 sec\n",
      "loss 2.318763, train acc 0.095312\n",
      "round 10\n",
      "time to device 0.006287 sec\n",
      "time forward 0.131216 sec\n",
      "loss time 0.001396 sec\n",
      "backward time 0.013644 sec\n",
      "optimizer time 0.028559 sec\n",
      "training time in round 10 cost 0.4576413631439209 sec\n",
      "loss 2.331412, train acc 0.095881\n",
      "round 11\n",
      "time to device 0.007127 sec\n",
      "time forward 0.143151 sec\n",
      "loss time 0.001114 sec\n",
      "backward time 0.012578 sec\n",
      "optimizer time 0.020375 sec\n",
      "training time in round 11 cost 0.4122152328491211 sec\n",
      "loss 2.337905, train acc 0.097005\n",
      "round 12\n",
      "time to device 0.007087 sec\n",
      "time forward 0.156352 sec\n",
      "loss time 0.000914 sec\n",
      "backward time 0.007253 sec\n",
      "optimizer time 0.018053 sec\n",
      "training time in round 12 cost 0.38321495056152344 sec\n",
      "loss 2.335170, train acc 0.100962\n",
      "round 13\n",
      "time to device 0.006454 sec\n",
      "time forward 0.167192 sec\n",
      "loss time 0.000980 sec\n",
      "backward time 0.009777 sec\n",
      "optimizer time 0.026746 sec\n",
      "training time in round 13 cost 0.3951148986816406 sec\n",
      "loss 2.333043, train acc 0.098214\n",
      "round 14\n",
      "time to device 0.007696 sec\n",
      "time forward 0.182193 sec\n",
      "loss time 0.001586 sec\n",
      "backward time 0.018160 sec\n",
      "optimizer time 0.024453 sec\n",
      "training time in round 14 cost 0.45548415184020996 sec\n",
      "loss 2.331058, train acc 0.098437\n",
      "round 15\n",
      "time to device 0.007406 sec\n",
      "time forward 0.189562 sec\n",
      "loss time 0.000782 sec\n",
      "backward time 0.008796 sec\n",
      "optimizer time 0.016997 sec\n",
      "training time in round 15 cost 0.36600804328918457 sec\n",
      "loss 2.329708, train acc 0.098633\n",
      "round 16\n",
      "time to device 0.010812 sec\n",
      "time forward 0.201081 sec\n",
      "loss time 0.001212 sec\n",
      "backward time 0.014382 sec\n",
      "optimizer time 0.014772 sec\n",
      "training time in round 16 cost 0.41704392433166504 sec\n",
      "loss 2.328356, train acc 0.095588\n",
      "round 17\n",
      "time to device 0.007913 sec\n",
      "time forward 0.214535 sec\n",
      "loss time 0.000980 sec\n",
      "backward time 0.011787 sec\n",
      "optimizer time 0.021912 sec\n",
      "training time in round 17 cost 0.4156801700592041 sec\n",
      "loss 2.327237, train acc 0.095052\n",
      "round 18\n",
      "time to device 0.008902 sec\n",
      "time forward 0.221269 sec\n",
      "loss time 0.000662 sec\n",
      "backward time 0.006361 sec\n",
      "optimizer time 0.016965 sec\n",
      "training time in round 18 cost 0.38012218475341797 sec\n",
      "loss 2.325741, train acc 0.093750\n",
      "round 19\n",
      "time to device 0.006938 sec\n",
      "time forward 0.232261 sec\n",
      "loss time 0.001394 sec\n",
      "backward time 0.014121 sec\n",
      "optimizer time 0.022649 sec\n",
      "training time in round 19 cost 0.40381813049316406 sec\n",
      "loss 2.324443, train acc 0.095312\n",
      "round 20\n",
      "time to device 0.006933 sec\n",
      "time forward 0.246729 sec\n",
      "loss time 0.001832 sec\n",
      "backward time 0.016070 sec\n",
      "optimizer time 0.026826 sec\n",
      "training time in round 20 cost 0.4065120220184326 sec\n",
      "loss 2.342030, train acc 0.093006\n",
      "round 21\n",
      "time to device 0.007222 sec\n",
      "time forward 0.256214 sec\n",
      "loss time 0.000947 sec\n",
      "backward time 0.010154 sec\n",
      "optimizer time 0.012404 sec\n",
      "training time in round 21 cost 0.3999297618865967 sec\n",
      "loss 2.340244, train acc 0.093395\n",
      "round 22\n",
      "time to device 0.009385 sec\n",
      "time forward 0.262540 sec\n",
      "loss time 0.000507 sec\n",
      "backward time 0.004019 sec\n",
      "optimizer time 0.012360 sec\n",
      "training time in round 22 cost 0.3905479907989502 sec\n",
      "loss 2.338038, train acc 0.093750\n",
      "round 23\n",
      "time to device 0.006852 sec\n",
      "time forward 0.273939 sec\n",
      "loss time 0.001440 sec\n",
      "backward time 0.014993 sec\n",
      "optimizer time 0.020111 sec\n",
      "training time in round 23 cost 0.4067990779876709 sec\n",
      "loss 2.338596, train acc 0.093424\n",
      "round 24\n",
      "time to device 0.010604 sec\n",
      "time forward 0.280546 sec\n",
      "loss time 0.000851 sec\n",
      "backward time 0.008122 sec\n",
      "optimizer time 0.017912 sec\n",
      "training time in round 24 cost 0.3862619400024414 sec\n",
      "loss 2.337302, train acc 0.093125\n",
      "round 25\n",
      "time to device 0.007170 sec\n",
      "time forward 0.290778 sec\n",
      "loss time 0.001042 sec\n",
      "backward time 0.011408 sec\n",
      "optimizer time 0.022198 sec\n",
      "training time in round 25 cost 0.40593624114990234 sec\n",
      "loss 2.354983, train acc 0.091647\n",
      "round 26\n",
      "time to device 0.007058 sec\n",
      "time forward 0.303665 sec\n",
      "loss time 0.000981 sec\n",
      "backward time 0.012133 sec\n",
      "optimizer time 0.024985 sec\n",
      "training time in round 26 cost 0.41507506370544434 sec\n",
      "loss 2.353000, train acc 0.092882\n",
      "round 27\n",
      "time to device 0.007026 sec\n",
      "time forward 0.311788 sec\n",
      "loss time 0.001125 sec\n",
      "backward time 0.004810 sec\n",
      "optimizer time 0.011115 sec\n",
      "training time in round 27 cost 0.3845021724700928 sec\n",
      "loss 2.351259, train acc 0.091518\n",
      "round 28\n",
      "time to device 0.008784 sec\n",
      "time forward 0.325894 sec\n",
      "loss time 0.001135 sec\n",
      "backward time 0.012111 sec\n",
      "optimizer time 0.020790 sec\n",
      "training time in round 28 cost 0.4103720188140869 sec\n",
      "loss 2.350609, train acc 0.090248\n",
      "round 29\n",
      "time to device 0.007163 sec\n",
      "time forward 0.336915 sec\n",
      "loss time 0.001107 sec\n",
      "backward time 0.011501 sec\n",
      "optimizer time 0.019761 sec\n",
      "training time in round 29 cost 0.3866307735443115 sec\n",
      "loss 2.349004, train acc 0.091146\n",
      "round 30\n",
      "time to device 0.007734 sec\n",
      "time forward 0.347179 sec\n",
      "loss time 0.000932 sec\n",
      "backward time 0.008340 sec\n",
      "optimizer time 0.018863 sec\n",
      "training time in round 30 cost 0.3879673480987549 sec\n",
      "loss 2.347432, train acc 0.092742\n",
      "round 31\n",
      "time to device 0.006792 sec\n",
      "time forward 0.361993 sec\n",
      "loss time 0.001650 sec\n",
      "backward time 0.015608 sec\n",
      "optimizer time 0.022462 sec\n",
      "training time in round 31 cost 0.45522189140319824 sec\n",
      "loss 2.346040, train acc 0.092773\n",
      "round 32\n",
      "time to device 0.008672 sec\n",
      "time forward 0.378322 sec\n",
      "loss time 0.001857 sec\n",
      "backward time 0.013323 sec\n",
      "optimizer time 0.020193 sec\n",
      "training time in round 32 cost 0.40969300270080566 sec\n",
      "loss 2.344608, train acc 0.093987\n",
      "round 33\n",
      "time to device 0.008701 sec\n",
      "time forward 0.386055 sec\n",
      "loss time 0.000447 sec\n",
      "backward time 0.004616 sec\n",
      "optimizer time 0.014977 sec\n",
      "training time in round 33 cost 0.41490983963012695 sec\n",
      "loss 2.343512, train acc 0.093750\n",
      "round 34\n",
      "time to device 0.007466 sec\n",
      "time forward 0.397096 sec\n",
      "loss time 0.001449 sec\n",
      "backward time 0.017360 sec\n",
      "optimizer time 0.037251 sec\n",
      "training time in round 34 cost 0.43067431449890137 sec\n",
      "loss 2.342289, train acc 0.094643\n",
      "round 35\n",
      "time to device 0.006378 sec\n",
      "time forward 0.408389 sec\n",
      "loss time 0.000989 sec\n",
      "backward time 0.015499 sec\n",
      "optimizer time 0.026635 sec\n",
      "training time in round 35 cost 0.40500497817993164 sec\n",
      "loss 2.341235, train acc 0.093750\n",
      "round 36\n",
      "time to device 0.006859 sec\n",
      "time forward 0.415420 sec\n",
      "loss time 0.000431 sec\n",
      "backward time 0.003989 sec\n",
      "optimizer time 0.012867 sec\n",
      "training time in round 36 cost 0.3808128833770752 sec\n",
      "loss 2.340148, train acc 0.094172\n",
      "round 37\n",
      "time to device 0.008912 sec\n",
      "time forward 0.427552 sec\n",
      "loss time 0.001086 sec\n",
      "backward time 0.011237 sec\n",
      "optimizer time 0.027304 sec\n",
      "training time in round 37 cost 0.45578598976135254 sec\n",
      "loss 2.339176, train acc 0.094161\n",
      "round 38\n",
      "time to device 0.007249 sec\n",
      "time forward 0.437640 sec\n",
      "loss time 0.000999 sec\n",
      "backward time 0.011417 sec\n",
      "optimizer time 0.029505 sec\n",
      "training time in round 38 cost 0.41228318214416504 sec\n",
      "loss 2.338248, train acc 0.093950\n",
      "round 39\n",
      "time to device 0.009331 sec\n",
      "time forward 0.447416 sec\n",
      "loss time 0.000950 sec\n",
      "backward time 0.008479 sec\n",
      "optimizer time 0.018508 sec\n",
      "training time in round 39 cost 0.3879671096801758 sec\n",
      "loss 2.337176, train acc 0.094141\n",
      "round 40\n",
      "time to device 0.008093 sec\n",
      "time forward 0.458223 sec\n",
      "loss time 0.001445 sec\n",
      "backward time 0.012368 sec\n",
      "optimizer time 0.027312 sec\n",
      "training time in round 40 cost 0.42255401611328125 sec\n",
      "loss 2.340485, train acc 0.094322\n",
      "round 41\n",
      "time to device 0.007467 sec\n",
      "time forward 0.469423 sec\n",
      "loss time 0.000527 sec\n",
      "backward time 0.005037 sec\n",
      "optimizer time 0.013088 sec\n",
      "training time in round 41 cost 0.37954282760620117 sec\n",
      "loss 2.339507, train acc 0.094494\n",
      "round 42\n",
      "time to device 0.012671 sec\n",
      "time forward 0.477385 sec\n",
      "loss time 0.000739 sec\n",
      "backward time 0.006701 sec\n",
      "optimizer time 0.017023 sec\n",
      "training time in round 42 cost 0.3692197799682617 sec\n",
      "loss 2.338702, train acc 0.094295\n",
      "round 43\n",
      "time to device 0.012875 sec\n",
      "time forward 0.491029 sec\n",
      "loss time 0.001655 sec\n",
      "backward time 0.021181 sec\n",
      "optimizer time 0.024119 sec\n",
      "training time in round 43 cost 0.41153979301452637 sec\n",
      "loss 2.337873, train acc 0.093928\n",
      "round 44\n",
      "time to device 0.006404 sec\n",
      "time forward 0.504215 sec\n",
      "loss time 0.001585 sec\n",
      "backward time 0.010323 sec\n",
      "optimizer time 0.029943 sec\n",
      "training time in round 44 cost 0.4124741554260254 sec\n",
      "loss 2.337594, train acc 0.095312\n",
      "round 45\n",
      "time to device 0.007277 sec\n",
      "time forward 0.510582 sec\n",
      "loss time 0.000454 sec\n",
      "backward time 0.004210 sec\n",
      "optimizer time 0.013498 sec\n",
      "training time in round 45 cost 0.37029123306274414 sec\n",
      "loss 2.340354, train acc 0.094939\n",
      "round 46\n",
      "time to device 0.007465 sec\n",
      "time forward 0.521590 sec\n",
      "loss time 0.001460 sec\n",
      "backward time 0.010472 sec\n",
      "optimizer time 0.043284 sec\n",
      "training time in round 46 cost 0.4051380157470703 sec\n",
      "loss 2.341293, train acc 0.096243\n",
      "round 47\n",
      "time to device 0.005815 sec\n",
      "time forward 0.532621 sec\n",
      "loss time 0.000989 sec\n",
      "backward time 0.013219 sec\n",
      "optimizer time 0.017013 sec\n",
      "training time in round 47 cost 0.4175081253051758 sec\n",
      "loss 2.340262, train acc 0.097005\n",
      "round 48\n",
      "time to device 0.006865 sec\n",
      "time forward 0.540076 sec\n",
      "loss time 0.000895 sec\n",
      "backward time 0.007069 sec\n",
      "optimizer time 0.018161 sec\n",
      "training time in round 48 cost 0.36363697052001953 sec\n",
      "loss 2.339472, train acc 0.096939\n",
      "round 49\n",
      "time to device 0.009448 sec\n",
      "time forward 0.559998 sec\n",
      "loss time 0.001073 sec\n",
      "backward time 0.010885 sec\n",
      "optimizer time 0.032833 sec\n",
      "training time in round 49 cost 0.4156301021575928 sec\n",
      "loss 2.338699, train acc 0.097500\n",
      "round 50\n",
      "time to device 0.007652 sec\n",
      "time forward 0.567234 sec\n",
      "loss time 0.000678 sec\n",
      "backward time 0.005027 sec\n",
      "optimizer time 0.014390 sec\n",
      "training time in round 50 cost 0.37012505531311035 sec\n",
      "loss 2.337841, train acc 0.098192\n",
      "round 51\n",
      "time to device 0.006239 sec\n",
      "time forward 0.575433 sec\n",
      "loss time 0.001168 sec\n",
      "backward time 0.005868 sec\n",
      "optimizer time 0.013567 sec\n",
      "training time in round 51 cost 0.37158203125 sec\n",
      "loss 2.337658, train acc 0.097506\n",
      "round 52\n",
      "time to device 0.006374 sec\n",
      "time forward 0.585869 sec\n",
      "loss time 0.001052 sec\n",
      "backward time 0.012247 sec\n",
      "optimizer time 0.018886 sec\n",
      "training time in round 52 cost 0.38690781593322754 sec\n",
      "loss 2.338004, train acc 0.097288\n",
      "round 53\n",
      "time to device 0.006531 sec\n",
      "time forward 0.596758 sec\n",
      "loss time 0.001189 sec\n",
      "backward time 0.013993 sec\n",
      "optimizer time 0.024105 sec\n",
      "training time in round 53 cost 0.38819193840026855 sec\n",
      "loss 2.337372, train acc 0.097078\n",
      "round 54\n",
      "time to device 0.006815 sec\n",
      "time forward 0.607991 sec\n",
      "loss time 0.000872 sec\n",
      "backward time 0.008405 sec\n",
      "optimizer time 0.018511 sec\n",
      "training time in round 54 cost 0.3837718963623047 sec\n",
      "loss 2.336777, train acc 0.097159\n",
      "round 55\n",
      "time to device 0.003428 sec\n",
      "time forward 0.622177 sec\n",
      "loss time 0.001112 sec\n",
      "backward time 0.011518 sec\n",
      "optimizer time 0.017650 sec\n",
      "training time in round 55 cost 0.3971230983734131 sec\n",
      "loss 2.337519, train acc 0.097377\n",
      "round 56\n",
      "time to device 0.004825 sec\n",
      "time forward 0.633239 sec\n",
      "loss time 0.001516 sec\n",
      "backward time 0.014266 sec\n",
      "optimizer time 0.026831 sec\n",
      "training time in round 56 cost 0.39130401611328125 sec\n",
      "loss 2.337365, train acc 0.097314\n",
      "round 57\n",
      "time to device 0.007218 sec\n",
      "time forward 0.643529 sec\n",
      "loss time 0.001161 sec\n",
      "backward time 0.011718 sec\n",
      "optimizer time 0.020321 sec\n",
      "training time in round 57 cost 0.39794421195983887 sec\n",
      "loss 2.336631, train acc 0.096848\n",
      "round 58\n",
      "time to device 0.008244 sec\n",
      "time forward 0.656380 sec\n",
      "loss time 0.002233 sec\n",
      "backward time 0.010993 sec\n",
      "optimizer time 0.027213 sec\n",
      "training time in round 58 cost 0.4462141990661621 sec\n",
      "loss 2.336385, train acc 0.096796\n",
      "round 59\n",
      "time to device 0.007852 sec\n",
      "time forward 0.662101 sec\n",
      "loss time 0.000479 sec\n",
      "backward time 0.004447 sec\n",
      "optimizer time 0.015252 sec\n",
      "training time in round 59 cost 0.3794069290161133 sec\n",
      "loss 2.335743, train acc 0.096745\n",
      "round 60\n",
      "time to device 0.007111 sec\n",
      "time forward 0.668407 sec\n",
      "loss time 0.000348 sec\n",
      "backward time 0.005018 sec\n",
      "optimizer time 0.011010 sec\n",
      "training time in round 60 cost 0.35976696014404297 sec\n",
      "loss 2.335140, train acc 0.097592\n",
      "round 61\n",
      "time to device 0.007953 sec\n",
      "time forward 0.680567 sec\n",
      "loss time 0.001836 sec\n",
      "backward time 0.012927 sec\n",
      "optimizer time 0.027292 sec\n",
      "training time in round 61 cost 0.45287513732910156 sec\n",
      "loss 2.334950, train acc 0.097152\n",
      "round 62\n",
      "time to device 0.007845 sec\n",
      "time forward 0.686295 sec\n",
      "loss time 0.000676 sec\n",
      "backward time 0.005248 sec\n",
      "optimizer time 0.011765 sec\n",
      "training time in round 62 cost 0.34810400009155273 sec\n",
      "loss 2.335234, train acc 0.097718\n",
      "round 63\n",
      "time to device 0.006984 sec\n",
      "time forward 0.698242 sec\n",
      "loss time 0.001770 sec\n",
      "backward time 0.016296 sec\n",
      "optimizer time 0.025352 sec\n",
      "training time in round 63 cost 0.3980131149291992 sec\n",
      "loss 2.334752, train acc 0.097290\n",
      "round 64\n",
      "time to device 0.006614 sec\n",
      "time forward 0.708324 sec\n",
      "loss time 0.001020 sec\n",
      "backward time 0.007666 sec\n",
      "optimizer time 0.016033 sec\n",
      "training time in round 64 cost 0.3934941291809082 sec\n",
      "loss 2.334192, train acc 0.097957\n",
      "round 65\n",
      "time to device 0.006701 sec\n",
      "time forward 0.721424 sec\n",
      "loss time 0.003085 sec\n",
      "backward time 0.022378 sec\n",
      "optimizer time 0.024212 sec\n",
      "training time in round 65 cost 0.41144895553588867 sec\n",
      "loss 2.333743, train acc 0.098248\n",
      "round 66\n",
      "time to device 0.006235 sec\n",
      "time forward 0.729342 sec\n",
      "loss time 0.000890 sec\n",
      "backward time 0.007366 sec\n",
      "optimizer time 0.017592 sec\n",
      "training time in round 66 cost 0.3815178871154785 sec\n",
      "loss 2.333220, train acc 0.098997\n",
      "round 67\n",
      "time to device 0.006643 sec\n",
      "time forward 0.741530 sec\n",
      "loss time 0.001480 sec\n",
      "backward time 0.012713 sec\n",
      "optimizer time 0.022926 sec\n",
      "training time in round 67 cost 0.4297218322753906 sec\n",
      "loss 2.332765, train acc 0.099035\n",
      "round 68\n",
      "time to device 0.007463 sec\n",
      "time forward 0.748087 sec\n",
      "loss time 0.000387 sec\n",
      "backward time 0.005562 sec\n",
      "optimizer time 0.011068 sec\n",
      "training time in round 68 cost 0.37119317054748535 sec\n",
      "loss 2.332389, train acc 0.098845\n",
      "round 69\n",
      "time to device 0.008676 sec\n",
      "time forward 0.759225 sec\n",
      "loss time 0.001339 sec\n",
      "backward time 0.011723 sec\n",
      "optimizer time 0.023717 sec\n",
      "training time in round 69 cost 0.4481792449951172 sec\n",
      "loss 2.332042, train acc 0.097991\n",
      "round 70\n",
      "time to device 0.008167 sec\n",
      "time forward 0.774182 sec\n",
      "loss time 0.001428 sec\n",
      "backward time 0.013207 sec\n",
      "optimizer time 0.032292 sec\n",
      "training time in round 70 cost 0.41529107093811035 sec\n",
      "loss 2.331710, train acc 0.098592\n",
      "round 71\n",
      "time to device 0.006789 sec\n",
      "time forward 0.791359 sec\n",
      "loss time 0.001064 sec\n",
      "backward time 0.010631 sec\n",
      "optimizer time 0.016420 sec\n",
      "training time in round 71 cost 0.46599626541137695 sec\n",
      "loss 2.331345, train acc 0.098090\n",
      "round 72\n",
      "time to device 0.007427 sec\n",
      "time forward 0.807153 sec\n",
      "loss time 0.001535 sec\n",
      "backward time 0.013206 sec\n",
      "optimizer time 0.050712 sec\n",
      "training time in round 72 cost 0.4839320182800293 sec\n",
      "loss 2.330949, train acc 0.098138\n",
      "round 73\n",
      "time to device 0.008197 sec\n",
      "time forward 0.816757 sec\n",
      "loss time 0.001289 sec\n",
      "backward time 0.006369 sec\n",
      "optimizer time 0.014741 sec\n",
      "training time in round 73 cost 0.4372081756591797 sec\n",
      "loss 2.330678, train acc 0.097973\n",
      "round 74\n",
      "time to device 0.007120 sec\n",
      "time forward 0.827914 sec\n",
      "loss time 0.001113 sec\n",
      "backward time 0.014936 sec\n",
      "optimizer time 0.025187 sec\n",
      "training time in round 74 cost 0.424699068069458 sec\n",
      "loss 2.330313, train acc 0.098125\n",
      "round 75\n",
      "time to device 0.007059 sec\n",
      "time forward 0.841713 sec\n",
      "loss time 0.000605 sec\n",
      "backward time 0.005977 sec\n",
      "optimizer time 0.044540 sec\n",
      "training time in round 75 cost 0.433621883392334 sec\n",
      "loss 2.331740, train acc 0.098067\n",
      "round 76\n",
      "time to device 0.007351 sec\n",
      "time forward 0.858027 sec\n",
      "loss time 0.001446 sec\n",
      "backward time 0.012894 sec\n",
      "optimizer time 0.014274 sec\n",
      "training time in round 76 cost 0.4811079502105713 sec\n",
      "loss 2.331379, train acc 0.098011\n",
      "round 77\n",
      "time to device 0.007413 sec\n",
      "time forward 0.881888 sec\n",
      "loss time 0.001069 sec\n",
      "backward time 0.013412 sec\n",
      "optimizer time 0.022941 sec\n",
      "training time in round 77 cost 0.4313349723815918 sec\n",
      "loss 2.331039, train acc 0.097656\n",
      "round 78\n",
      "time to device 0.020968 sec\n",
      "time forward 0.898025 sec\n",
      "loss time 0.000946 sec\n",
      "backward time 0.011678 sec\n",
      "optimizer time 0.026460 sec\n",
      "training time in round 78 cost 0.4651341438293457 sec\n",
      "loss 2.330672, train acc 0.098002\n",
      "round 79\n",
      "time to device 0.007010 sec\n",
      "time forward 0.908197 sec\n",
      "loss time 0.001142 sec\n",
      "backward time 0.008956 sec\n",
      "optimizer time 0.022540 sec\n",
      "training time in round 79 cost 0.43648195266723633 sec\n",
      "loss 2.330125, train acc 0.098242\n",
      "round 80\n",
      "time to device 0.007586 sec\n",
      "time forward 0.924220 sec\n",
      "loss time 0.001005 sec\n",
      "backward time 0.014953 sec\n",
      "optimizer time 0.019241 sec\n",
      "training time in round 80 cost 0.4404721260070801 sec\n",
      "loss 2.329982, train acc 0.098283\n",
      "round 81\n",
      "time to device 0.010630 sec\n",
      "time forward 0.939366 sec\n",
      "loss time 0.001365 sec\n",
      "backward time 0.010411 sec\n",
      "optimizer time 0.033070 sec\n",
      "training time in round 81 cost 0.5721950531005859 sec\n",
      "loss 2.329686, train acc 0.098418\n",
      "round 82\n",
      "time to device 0.008711 sec\n",
      "time forward 0.951465 sec\n",
      "loss time 0.001509 sec\n",
      "backward time 0.012132 sec\n",
      "optimizer time 0.026050 sec\n",
      "training time in round 82 cost 0.4468660354614258 sec\n",
      "loss 2.329432, train acc 0.098080\n",
      "round 83\n",
      "time to device 0.006737 sec\n",
      "time forward 0.963561 sec\n",
      "loss time 0.001307 sec\n",
      "backward time 0.013264 sec\n",
      "optimizer time 0.019625 sec\n",
      "training time in round 83 cost 0.4019918441772461 sec\n",
      "loss 2.329140, train acc 0.098121\n",
      "round 84\n",
      "time to device 0.006392 sec\n",
      "time forward 0.979954 sec\n",
      "loss time 0.001191 sec\n",
      "backward time 0.011600 sec\n",
      "optimizer time 0.024823 sec\n",
      "training time in round 84 cost 0.4710850715637207 sec\n",
      "loss 2.330376, train acc 0.097886\n",
      "round 85\n",
      "time to device 0.009598 sec\n",
      "time forward 0.989048 sec\n",
      "loss time 0.000878 sec\n",
      "backward time 0.009403 sec\n",
      "optimizer time 0.017840 sec\n",
      "training time in round 85 cost 0.37691473960876465 sec\n",
      "loss 2.330074, train acc 0.098020\n",
      "round 86\n",
      "time to device 0.007277 sec\n",
      "time forward 1.000861 sec\n",
      "loss time 0.002034 sec\n",
      "backward time 0.010679 sec\n",
      "optimizer time 0.025756 sec\n",
      "training time in round 86 cost 0.3908867835998535 sec\n",
      "loss 2.329780, train acc 0.098330\n",
      "round 87\n",
      "time to device 0.007028 sec\n",
      "time forward 1.013578 sec\n",
      "loss time 0.001391 sec\n",
      "backward time 0.011730 sec\n",
      "optimizer time 0.025326 sec\n",
      "training time in round 87 cost 0.4416060447692871 sec\n",
      "loss 2.330640, train acc 0.098366\n",
      "round 88\n",
      "time to device 0.008832 sec\n",
      "time forward 1.021713 sec\n",
      "loss time 0.000749 sec\n",
      "backward time 0.006842 sec\n",
      "optimizer time 0.018029 sec\n",
      "training time in round 88 cost 0.38127684593200684 sec\n",
      "loss 2.330328, train acc 0.098666\n",
      "round 89\n",
      "time to device 0.006462 sec\n",
      "time forward 1.040311 sec\n",
      "loss time 0.001151 sec\n",
      "backward time 0.014363 sec\n",
      "optimizer time 0.026410 sec\n",
      "training time in round 89 cost 0.413693904876709 sec\n",
      "loss 2.329955, train acc 0.099219\n",
      "round 90\n",
      "time to device 0.006385 sec\n",
      "time forward 1.049981 sec\n",
      "loss time 0.001557 sec\n",
      "backward time 0.018731 sec\n",
      "optimizer time 0.020525 sec\n",
      "training time in round 90 cost 0.4319338798522949 sec\n",
      "loss 2.330350, train acc 0.099245\n",
      "round 91\n",
      "time to device 0.006608 sec\n",
      "time forward 1.058438 sec\n",
      "loss time 0.000906 sec\n",
      "backward time 0.006896 sec\n",
      "optimizer time 0.017329 sec\n",
      "training time in round 91 cost 0.3677489757537842 sec\n",
      "loss 2.333104, train acc 0.099524\n",
      "round 92\n",
      "time to device 0.008960 sec\n",
      "time forward 1.068838 sec\n",
      "loss time 0.001663 sec\n",
      "backward time 0.014555 sec\n",
      "optimizer time 0.025485 sec\n",
      "training time in round 92 cost 0.394730806350708 sec\n",
      "loss 2.332800, train acc 0.099210\n",
      "round 93\n",
      "time to device 0.006485 sec\n",
      "time forward 1.086329 sec\n",
      "loss time 0.001941 sec\n",
      "backward time 0.014764 sec\n",
      "optimizer time 0.024852 sec\n",
      "training time in round 93 cost 0.4236328601837158 sec\n",
      "loss 2.332715, train acc 0.098986\n",
      "round 94\n",
      "time to device 0.007058 sec\n",
      "time forward 1.093652 sec\n",
      "loss time 0.000672 sec\n",
      "backward time 0.006143 sec\n",
      "optimizer time 0.016708 sec\n",
      "training time in round 94 cost 0.39162492752075195 sec\n",
      "loss 2.332344, train acc 0.098849\n",
      "round 95\n",
      "time to device 0.006330 sec\n",
      "time forward 1.108294 sec\n",
      "loss time 0.001150 sec\n",
      "backward time 0.015060 sec\n",
      "optimizer time 0.027866 sec\n",
      "training time in round 95 cost 0.4163968563079834 sec\n",
      "loss 2.332031, train acc 0.098714\n",
      "round 96\n",
      "time to device 0.007195 sec\n",
      "time forward 1.117341 sec\n",
      "loss time 0.001153 sec\n",
      "backward time 0.011080 sec\n",
      "optimizer time 0.022113 sec\n",
      "training time in round 96 cost 0.4206101894378662 sec\n",
      "loss 2.331778, train acc 0.098260\n",
      "round 97\n",
      "time to device 0.007261 sec\n",
      "time forward 1.126462 sec\n",
      "loss time 0.000930 sec\n",
      "backward time 0.009920 sec\n",
      "optimizer time 0.018770 sec\n",
      "training time in round 97 cost 0.38886213302612305 sec\n",
      "loss 2.331494, train acc 0.098214\n",
      "round 98\n",
      "time to device 0.006959 sec\n",
      "time forward 1.138816 sec\n",
      "loss time 0.001556 sec\n",
      "backward time 0.010887 sec\n",
      "optimizer time 0.027700 sec\n",
      "training time in round 98 cost 0.41561388969421387 sec\n",
      "loss 2.331193, train acc 0.098643\n",
      "round 99\n",
      "time to device 0.007979 sec\n",
      "time forward 1.154863 sec\n",
      "loss time 0.001556 sec\n",
      "backward time 0.012133 sec\n",
      "optimizer time 0.021633 sec\n",
      "training time in round 99 cost 0.41209983825683594 sec\n",
      "loss 2.331062, train acc 0.098672\n",
      "round 100\n",
      "time to device 0.008629 sec\n",
      "time forward 1.167988 sec\n",
      "loss time 0.001608 sec\n",
      "backward time 0.014238 sec\n",
      "optimizer time 0.025145 sec\n",
      "training time in round 100 cost 0.40674686431884766 sec\n",
      "loss 2.330720, train acc 0.098855\n",
      "round 101\n",
      "time to device 0.008552 sec\n",
      "time forward 1.180945 sec\n",
      "loss time 0.001949 sec\n",
      "backward time 0.010810 sec\n",
      "optimizer time 0.023895 sec\n",
      "training time in round 101 cost 0.3926360607147217 sec\n",
      "loss 2.330434, train acc 0.098958\n",
      "round 102\n",
      "time to device 0.005877 sec\n",
      "time forward 1.189964 sec\n",
      "loss time 0.000668 sec\n",
      "backward time 0.007283 sec\n",
      "optimizer time 0.019348 sec\n",
      "training time in round 102 cost 0.3818471431732178 sec\n",
      "loss 2.330161, train acc 0.098756\n",
      "round 103\n",
      "time to device 0.003515 sec\n",
      "time forward 1.204177 sec\n",
      "loss time 0.001180 sec\n",
      "backward time 0.016303 sec\n",
      "optimizer time 0.034022 sec\n",
      "training time in round 103 cost 0.46869516372680664 sec\n",
      "loss 2.329891, train acc 0.098783\n",
      "round 104\n",
      "time to device 0.007027 sec\n",
      "time forward 1.215130 sec\n",
      "loss time 0.000712 sec\n",
      "backward time 0.004476 sec\n",
      "optimizer time 0.017762 sec\n",
      "training time in round 104 cost 0.4447329044342041 sec\n",
      "loss 2.329668, train acc 0.098512\n",
      "round 105\n",
      "time to device 0.006737 sec\n",
      "time forward 1.222926 sec\n",
      "loss time 0.000761 sec\n",
      "backward time 0.007783 sec\n",
      "optimizer time 0.020675 sec\n",
      "training time in round 105 cost 0.41953516006469727 sec\n",
      "loss 2.329452, train acc 0.098393\n",
      "round 106\n",
      "time to device 0.008304 sec\n",
      "time forward 1.237891 sec\n",
      "loss time 0.001113 sec\n",
      "backward time 0.010646 sec\n",
      "optimizer time 0.019442 sec\n",
      "training time in round 106 cost 0.44614481925964355 sec\n",
      "loss 2.329208, train acc 0.098277\n",
      "round 107\n",
      "time to device 0.013504 sec\n",
      "time forward 1.251299 sec\n",
      "loss time 0.001438 sec\n",
      "backward time 0.008503 sec\n",
      "optimizer time 0.017116 sec\n",
      "training time in round 107 cost 0.4422781467437744 sec\n",
      "loss 2.329068, train acc 0.097946\n",
      "round 108\n",
      "time to device 0.026024 sec\n",
      "time forward 1.257377 sec\n",
      "loss time 0.000679 sec\n",
      "backward time 0.006304 sec\n",
      "optimizer time 0.016851 sec\n",
      "training time in round 108 cost 0.4305262565612793 sec\n",
      "loss 2.328853, train acc 0.097979\n",
      "round 109\n",
      "time to device 0.006188 sec\n",
      "time forward 1.269737 sec\n",
      "loss time 0.001557 sec\n",
      "backward time 0.010223 sec\n",
      "optimizer time 0.024437 sec\n",
      "training time in round 109 cost 0.3937530517578125 sec\n",
      "loss 2.335653, train acc 0.098082\n",
      "round 110\n",
      "time to device 0.007832 sec\n",
      "time forward 1.281358 sec\n",
      "loss time 0.000916 sec\n",
      "backward time 0.008412 sec\n",
      "optimizer time 0.019987 sec\n",
      "training time in round 110 cost 0.37027597427368164 sec\n",
      "loss 2.335348, train acc 0.097973\n",
      "round 111\n",
      "time to device 0.006932 sec\n",
      "time forward 1.291427 sec\n",
      "loss time 0.000940 sec\n",
      "backward time 0.007587 sec\n",
      "optimizer time 0.019912 sec\n",
      "training time in round 111 cost 0.37920308113098145 sec\n",
      "loss 2.335351, train acc 0.097586\n",
      "round 112\n",
      "time to device 0.008796 sec\n",
      "time forward 1.297314 sec\n",
      "loss time 0.000577 sec\n",
      "backward time 0.005524 sec\n",
      "optimizer time 0.015074 sec\n",
      "training time in round 112 cost 0.35533690452575684 sec\n",
      "loss 2.335277, train acc 0.097553\n",
      "round 113\n",
      "time to device 0.006878 sec\n",
      "time forward 1.303982 sec\n",
      "loss time 0.000733 sec\n",
      "backward time 0.006008 sec\n",
      "optimizer time 0.016616 sec\n",
      "training time in round 113 cost 0.34670472145080566 sec\n",
      "loss 2.334982, train acc 0.097930\n",
      "round 114\n",
      "time to device 0.007338 sec\n",
      "time forward 1.314755 sec\n",
      "loss time 0.000882 sec\n",
      "backward time 0.008403 sec\n",
      "optimizer time 0.020115 sec\n",
      "training time in round 114 cost 0.3711709976196289 sec\n",
      "loss 2.335112, train acc 0.097758\n",
      "round 115\n",
      "time to device 0.004086 sec\n",
      "time forward 1.326075 sec\n",
      "loss time 0.001047 sec\n",
      "backward time 0.008465 sec\n",
      "optimizer time 0.020197 sec\n",
      "training time in round 115 cost 0.38275909423828125 sec\n",
      "loss 2.334851, train acc 0.097858\n",
      "round 116\n",
      "time to device 0.006849 sec\n",
      "time forward 1.336636 sec\n",
      "loss time 0.001361 sec\n",
      "backward time 0.009486 sec\n",
      "optimizer time 0.021070 sec\n",
      "training time in round 116 cost 0.38227128982543945 sec\n",
      "loss 2.334616, train acc 0.097489\n",
      "round 117\n",
      "time to device 0.006448 sec\n",
      "time forward 1.344845 sec\n",
      "loss time 0.000878 sec\n",
      "backward time 0.008205 sec\n",
      "optimizer time 0.019547 sec\n",
      "training time in round 117 cost 0.3793151378631592 sec\n",
      "loss 2.334338, train acc 0.097458\n",
      "round 118\n",
      "time to device 0.007106 sec\n",
      "time forward 1.350832 sec\n",
      "loss time 0.000643 sec\n",
      "backward time 0.005946 sec\n",
      "optimizer time 0.016592 sec\n",
      "training time in round 118 cost 0.34911608695983887 sec\n",
      "loss 2.334731, train acc 0.097164\n",
      "round 119\n",
      "time to device 0.006271 sec\n",
      "time forward 1.360494 sec\n",
      "loss time 0.001228 sec\n",
      "backward time 0.015448 sec\n",
      "optimizer time 0.019802 sec\n",
      "training time in round 119 cost 0.372938871383667 sec\n",
      "loss 2.334493, train acc 0.096745\n",
      "round 120\n",
      "time to device 0.006208 sec\n",
      "time forward 1.370845 sec\n",
      "loss time 0.001205 sec\n",
      "backward time 0.008407 sec\n",
      "optimizer time 0.019898 sec\n",
      "training time in round 120 cost 0.3683903217315674 sec\n",
      "loss 2.334232, train acc 0.096526\n",
      "round 121\n",
      "time to device 0.003944 sec\n",
      "time forward 1.383917 sec\n",
      "loss time 0.001558 sec\n",
      "backward time 0.009801 sec\n",
      "optimizer time 0.020710 sec\n",
      "training time in round 121 cost 0.3924260139465332 sec\n",
      "loss 2.333979, train acc 0.096952\n",
      "round 122\n",
      "time to device 0.005298 sec\n",
      "time forward 1.393887 sec\n",
      "loss time 0.001106 sec\n",
      "backward time 0.008286 sec\n",
      "optimizer time 0.019879 sec\n",
      "training time in round 122 cost 0.37133312225341797 sec\n",
      "loss 2.337147, train acc 0.096926\n",
      "round 123\n",
      "time to device 0.003754 sec\n",
      "time forward 1.404261 sec\n",
      "loss time 0.001387 sec\n",
      "backward time 0.009634 sec\n",
      "optimizer time 0.020681 sec\n",
      "training time in round 123 cost 0.3801870346069336 sec\n",
      "loss 2.336877, train acc 0.096585\n",
      "round 124\n",
      "time to device 0.003437 sec\n",
      "time forward 1.412553 sec\n",
      "loss time 0.000858 sec\n",
      "backward time 0.008225 sec\n",
      "optimizer time 0.019320 sec\n",
      "training time in round 124 cost 0.35632991790771484 sec\n",
      "loss 2.336623, train acc 0.096437\n",
      "round 125\n",
      "time to device 0.004237 sec\n",
      "time forward 1.423345 sec\n",
      "loss time 0.000874 sec\n",
      "backward time 0.008197 sec\n",
      "optimizer time 0.019480 sec\n",
      "training time in round 125 cost 0.37519001960754395 sec\n",
      "loss 2.336357, train acc 0.096354\n",
      "round 126\n",
      "time to device 0.003269 sec\n",
      "time forward 1.428608 sec\n",
      "loss time 0.000362 sec\n",
      "backward time 0.003220 sec\n",
      "optimizer time 0.010007 sec\n",
      "training time in round 126 cost 0.33310985565185547 sec\n",
      "loss 2.336088, train acc 0.096272\n",
      "round 127\n",
      "time to device 0.003829 sec\n",
      "time forward 1.439693 sec\n",
      "loss time 0.001290 sec\n",
      "backward time 0.009625 sec\n",
      "optimizer time 0.020320 sec\n",
      "training time in round 127 cost 0.37445688247680664 sec\n",
      "loss 2.335899, train acc 0.096741\n",
      "round 128\n",
      "time to device 0.004021 sec\n",
      "time forward 1.450490 sec\n",
      "loss time 0.001198 sec\n",
      "backward time 0.008344 sec\n",
      "optimizer time 0.019970 sec\n",
      "training time in round 128 cost 0.3737452030181885 sec\n",
      "loss 2.335630, train acc 0.097202\n",
      "round 129\n",
      "time to device 0.003954 sec\n",
      "time forward 1.464410 sec\n",
      "loss time 0.001443 sec\n",
      "backward time 0.010769 sec\n",
      "optimizer time 0.021122 sec\n",
      "training time in round 129 cost 0.38678622245788574 sec\n",
      "loss 2.335382, train acc 0.097596\n",
      "round 130\n",
      "time to device 0.002893 sec\n",
      "time forward 1.473540 sec\n",
      "loss time 0.000560 sec\n",
      "backward time 0.005381 sec\n",
      "optimizer time 0.014636 sec\n",
      "training time in round 130 cost 0.3730580806732178 sec\n",
      "loss 2.335138, train acc 0.097626\n",
      "round 131\n",
      "time to device 0.003860 sec\n",
      "time forward 1.480331 sec\n",
      "loss time 0.000657 sec\n",
      "backward time 0.005974 sec\n",
      "optimizer time 0.015739 sec\n",
      "training time in round 131 cost 0.34165501594543457 sec\n",
      "loss 2.334913, train acc 0.097775\n",
      "round 132\n",
      "time to device 0.004095 sec\n",
      "time forward 1.489790 sec\n",
      "loss time 0.000869 sec\n",
      "backward time 0.008041 sec\n",
      "optimizer time 0.018717 sec\n",
      "training time in round 132 cost 0.3619849681854248 sec\n",
      "loss 2.334678, train acc 0.097686\n",
      "round 133\n",
      "time to device 0.003648 sec\n",
      "time forward 1.496372 sec\n",
      "loss time 0.000711 sec\n",
      "backward time 0.005944 sec\n",
      "optimizer time 0.016104 sec\n",
      "training time in round 133 cost 0.3436250686645508 sec\n",
      "loss 2.334444, train acc 0.097540\n",
      "round 134\n",
      "time to device 0.003529 sec\n",
      "time forward 1.507299 sec\n",
      "loss time 0.001119 sec\n",
      "backward time 0.008807 sec\n",
      "optimizer time 0.019988 sec\n",
      "training time in round 134 cost 0.3668539524078369 sec\n",
      "loss 2.334179, train acc 0.097917\n",
      "round 135\n",
      "time to device 0.003305 sec\n",
      "time forward 1.516856 sec\n",
      "loss time 0.001060 sec\n",
      "backward time 0.008801 sec\n",
      "optimizer time 0.020116 sec\n",
      "training time in round 135 cost 0.36208200454711914 sec\n",
      "loss 2.333959, train acc 0.098001\n",
      "round 136\n",
      "time to device 0.003081 sec\n",
      "time forward 1.532052 sec\n",
      "loss time 0.001569 sec\n",
      "backward time 0.010881 sec\n",
      "optimizer time 0.023396 sec\n",
      "training time in round 136 cost 0.3922159671783447 sec\n",
      "loss 2.333967, train acc 0.097970\n",
      "round 137\n",
      "time to device 0.003864 sec\n",
      "time forward 1.538550 sec\n",
      "loss time 0.000652 sec\n",
      "backward time 0.005955 sec\n",
      "optimizer time 0.016033 sec\n",
      "training time in round 137 cost 0.3434879779815674 sec\n",
      "loss 2.335223, train acc 0.097769\n",
      "round 138\n",
      "time to device 0.002958 sec\n",
      "time forward 1.547241 sec\n",
      "loss time 0.001109 sec\n",
      "backward time 0.008418 sec\n",
      "optimizer time 0.019650 sec\n",
      "training time in round 138 cost 0.357058048248291 sec\n",
      "loss 2.335792, train acc 0.097684\n",
      "round 139\n",
      "time to device 0.003377 sec\n",
      "time forward 1.557408 sec\n",
      "loss time 0.001388 sec\n",
      "backward time 0.008775 sec\n",
      "optimizer time 0.020177 sec\n",
      "training time in round 139 cost 0.3646073341369629 sec\n",
      "loss 2.335531, train acc 0.098158\n",
      "round 140\n",
      "time to device 0.003363 sec\n",
      "time forward 1.563174 sec\n",
      "loss time 0.000396 sec\n",
      "backward time 0.003712 sec\n",
      "optimizer time 0.014258 sec\n",
      "training time in round 140 cost 0.3550090789794922 sec\n",
      "loss 2.339753, train acc 0.098016\n",
      "round 141\n",
      "time to device 0.003047 sec\n",
      "time forward 1.573116 sec\n",
      "loss time 0.001101 sec\n",
      "backward time 0.008479 sec\n",
      "optimizer time 0.020769 sec\n",
      "training time in round 141 cost 0.36472296714782715 sec\n",
      "loss 2.342820, train acc 0.098041\n",
      "round 142\n",
      "time to device 0.003648 sec\n",
      "time forward 1.580281 sec\n",
      "loss time 0.000754 sec\n",
      "backward time 0.006202 sec\n",
      "optimizer time 0.016356 sec\n",
      "training time in round 142 cost 0.34983396530151367 sec\n",
      "loss 2.342540, train acc 0.098066\n",
      "round 143\n",
      "time to device 0.003491 sec\n",
      "time forward 1.590312 sec\n",
      "loss time 0.001435 sec\n",
      "backward time 0.008712 sec\n",
      "optimizer time 0.020195 sec\n",
      "training time in round 143 cost 0.3655569553375244 sec\n",
      "loss 2.342285, train acc 0.097982\n",
      "round 144\n",
      "time to device 0.003484 sec\n",
      "time forward 1.600438 sec\n",
      "loss time 0.001099 sec\n",
      "backward time 0.008623 sec\n",
      "optimizer time 0.020084 sec\n",
      "training time in round 144 cost 0.36140871047973633 sec\n",
      "loss 2.341969, train acc 0.098006\n",
      "round 145\n",
      "time to device 0.003475 sec\n",
      "time forward 1.607036 sec\n",
      "loss time 0.000635 sec\n",
      "backward time 0.005902 sec\n",
      "optimizer time 0.015182 sec\n",
      "training time in round 145 cost 0.34243321418762207 sec\n",
      "loss 2.341680, train acc 0.098191\n",
      "round 146\n",
      "time to device 0.003435 sec\n",
      "time forward 1.617162 sec\n",
      "loss time 0.001015 sec\n",
      "backward time 0.009281 sec\n",
      "optimizer time 0.020255 sec\n",
      "training time in round 146 cost 0.36273884773254395 sec\n",
      "loss 2.342453, train acc 0.098002\n",
      "round 147\n",
      "time to device 0.003076 sec\n",
      "time forward 1.626902 sec\n",
      "loss time 0.000892 sec\n",
      "backward time 0.008222 sec\n",
      "optimizer time 0.019036 sec\n",
      "training time in round 147 cost 0.3609020709991455 sec\n",
      "loss 2.342679, train acc 0.098237\n",
      "round 148\n",
      "time to device 0.003385 sec\n",
      "time forward 1.633591 sec\n",
      "loss time 0.000641 sec\n",
      "backward time 0.005923 sec\n",
      "optimizer time 0.015846 sec\n",
      "training time in round 148 cost 0.3392808437347412 sec\n",
      "loss 2.344278, train acc 0.098154\n",
      "round 149\n",
      "time to device 0.003400 sec\n",
      "time forward 1.644406 sec\n",
      "loss time 0.001122 sec\n",
      "backward time 0.008899 sec\n",
      "optimizer time 0.020240 sec\n",
      "training time in round 149 cost 0.3654148578643799 sec\n",
      "loss 2.344010, train acc 0.098229\n",
      "round 150\n",
      "time to device 0.003669 sec\n",
      "time forward 1.654396 sec\n",
      "loss time 0.001373 sec\n",
      "backward time 0.008536 sec\n",
      "optimizer time 0.020087 sec\n",
      "training time in round 150 cost 0.3607010841369629 sec\n",
      "loss 2.343767, train acc 0.098044\n",
      "round 151\n",
      "time to device 0.007127 sec\n",
      "time forward 1.665057 sec\n",
      "loss time 0.001203 sec\n",
      "backward time 0.008640 sec\n",
      "optimizer time 0.019986 sec\n",
      "training time in round 151 cost 0.36791300773620605 sec\n",
      "loss 2.343523, train acc 0.097913\n",
      "round 152\n",
      "time to device 0.003516 sec\n",
      "time forward 1.675706 sec\n",
      "loss time 0.000884 sec\n",
      "backward time 0.008235 sec\n",
      "optimizer time 0.018991 sec\n",
      "training time in round 152 cost 0.3645350933074951 sec\n",
      "loss 2.344999, train acc 0.097835\n",
      "round 153\n",
      "time to device 0.003481 sec\n",
      "time forward 1.682017 sec\n",
      "loss time 0.000658 sec\n",
      "backward time 0.006156 sec\n",
      "optimizer time 0.015482 sec\n",
      "training time in round 153 cost 0.34058403968811035 sec\n",
      "loss 2.345016, train acc 0.098164\n",
      "round 154\n",
      "time to device 0.003716 sec\n",
      "time forward 1.692792 sec\n",
      "loss time 0.001195 sec\n",
      "backward time 0.009513 sec\n",
      "optimizer time 0.020970 sec\n",
      "training time in round 154 cost 0.36848020553588867 sec\n",
      "loss 2.344782, train acc 0.098236\n",
      "round 155\n",
      "time to device 0.003480 sec\n",
      "time forward 1.704011 sec\n",
      "loss time 0.001128 sec\n",
      "backward time 0.008572 sec\n",
      "optimizer time 0.020028 sec\n",
      "training time in round 155 cost 0.3673419952392578 sec\n",
      "loss 2.344521, train acc 0.098107\n",
      "round 156\n",
      "time to device 0.004148 sec\n",
      "time forward 1.710546 sec\n",
      "loss time 0.000635 sec\n",
      "backward time 0.006174 sec\n",
      "optimizer time 0.015473 sec\n",
      "training time in round 156 cost 0.34473609924316406 sec\n",
      "loss 2.344387, train acc 0.097980\n",
      "round 157\n",
      "time to device 0.003586 sec\n",
      "time forward 1.718784 sec\n",
      "loss time 0.000605 sec\n",
      "backward time 0.006181 sec\n",
      "optimizer time 0.014656 sec\n",
      "training time in round 157 cost 0.37783217430114746 sec\n",
      "loss 2.345423, train acc 0.098052\n",
      "round 158\n",
      "time to device 0.003936 sec\n",
      "time forward 1.729528 sec\n",
      "loss time 0.001051 sec\n",
      "backward time 0.009049 sec\n",
      "optimizer time 0.020895 sec\n",
      "training time in round 158 cost 0.3665618896484375 sec\n",
      "loss 2.345193, train acc 0.098467\n",
      "round 159\n",
      "time to device 0.003321 sec\n",
      "time forward 1.746450 sec\n",
      "loss time 0.000884 sec\n",
      "backward time 0.008505 sec\n",
      "optimizer time 0.020229 sec\n",
      "training time in round 159 cost 0.37632083892822266 sec\n",
      "loss 2.344946, train acc 0.098437\n",
      "round 160\n",
      "time to device 0.009485 sec\n",
      "time forward 1.755358 sec\n",
      "loss time 0.000728 sec\n",
      "backward time 0.007127 sec\n",
      "optimizer time 0.020123 sec\n",
      "training time in round 160 cost 0.3888740539550781 sec\n",
      "loss 2.344724, train acc 0.098408\n",
      "round 161\n",
      "time to device 0.007699 sec\n",
      "time forward 1.766002 sec\n",
      "loss time 0.000587 sec\n",
      "backward time 0.003352 sec\n",
      "optimizer time 0.012483 sec\n",
      "training time in round 161 cost 0.3586239814758301 sec\n",
      "loss 2.344482, train acc 0.098235\n",
      "round 162\n",
      "time to device 0.006656 sec\n",
      "time forward 1.775606 sec\n",
      "loss time 0.001341 sec\n",
      "backward time 0.010872 sec\n",
      "optimizer time 0.024523 sec\n",
      "training time in round 162 cost 0.39772701263427734 sec\n",
      "loss 2.345554, train acc 0.098399\n",
      "round 163\n",
      "time to device 0.006290 sec\n",
      "time forward 1.786089 sec\n",
      "loss time 0.001096 sec\n",
      "backward time 0.008532 sec\n",
      "optimizer time 0.020522 sec\n",
      "training time in round 163 cost 0.3891119956970215 sec\n",
      "loss 2.345302, train acc 0.098466\n",
      "round 164\n",
      "time to device 0.006651 sec\n",
      "time forward 1.797156 sec\n",
      "loss time 0.000887 sec\n",
      "backward time 0.008292 sec\n",
      "optimizer time 0.019734 sec\n",
      "training time in round 164 cost 0.3665430545806885 sec\n",
      "loss 2.345051, train acc 0.098248\n",
      "round 165\n",
      "time to device 0.004933 sec\n",
      "time forward 1.803001 sec\n",
      "loss time 0.000595 sec\n",
      "backward time 0.005537 sec\n",
      "optimizer time 0.014982 sec\n",
      "training time in round 165 cost 0.3539462089538574 sec\n",
      "loss 2.344880, train acc 0.098268\n",
      "round 166\n",
      "time to device 0.007580 sec\n",
      "time forward 1.811779 sec\n",
      "loss time 0.001070 sec\n",
      "backward time 0.008584 sec\n",
      "optimizer time 0.020473 sec\n",
      "training time in round 166 cost 0.37256908416748047 sec\n",
      "loss 2.344611, train acc 0.098568\n",
      "round 167\n",
      "time to device 0.006580 sec\n",
      "time forward 1.826021 sec\n",
      "loss time 0.001094 sec\n",
      "backward time 0.009532 sec\n",
      "optimizer time 0.021353 sec\n",
      "training time in round 167 cost 0.38065123558044434 sec\n",
      "loss 2.344387, train acc 0.098540\n",
      "round 168\n",
      "time to device 0.006932 sec\n",
      "time forward 1.832850 sec\n",
      "loss time 0.000638 sec\n",
      "backward time 0.006554 sec\n",
      "optimizer time 0.016375 sec\n",
      "training time in round 168 cost 0.3529939651489258 sec\n",
      "loss 2.344161, train acc 0.098373\n",
      "round 169\n",
      "time to device 0.007642 sec\n",
      "time forward 1.839404 sec\n",
      "loss time 0.000396 sec\n",
      "backward time 0.005132 sec\n",
      "optimizer time 0.011526 sec\n",
      "training time in round 169 cost 0.35933399200439453 sec\n",
      "loss 2.344046, train acc 0.098116\n",
      "round 170\n",
      "time to device 0.006561 sec\n",
      "time forward 1.849644 sec\n",
      "loss time 0.000965 sec\n",
      "backward time 0.008273 sec\n",
      "optimizer time 0.019279 sec\n",
      "training time in round 170 cost 0.3781759738922119 sec\n",
      "loss 2.343839, train acc 0.097862\n",
      "round 171\n",
      "time to device 0.006920 sec\n",
      "time forward 1.855973 sec\n",
      "loss time 0.000626 sec\n",
      "backward time 0.005622 sec\n",
      "optimizer time 0.015376 sec\n",
      "training time in round 171 cost 0.34888696670532227 sec\n",
      "loss 2.343619, train acc 0.097793\n",
      "round 172\n",
      "time to device 0.005489 sec\n",
      "time forward 1.865731 sec\n",
      "loss time 0.001126 sec\n",
      "backward time 0.004319 sec\n",
      "optimizer time 0.012450 sec\n",
      "training time in round 172 cost 0.3749380111694336 sec\n",
      "loss 2.343366, train acc 0.097589\n",
      "round 173\n",
      "time to device 0.003713 sec\n",
      "time forward 1.876579 sec\n",
      "loss time 0.001137 sec\n",
      "backward time 0.008526 sec\n",
      "optimizer time 0.020366 sec\n",
      "training time in round 173 cost 0.3715090751647949 sec\n",
      "loss 2.343556, train acc 0.097477\n",
      "round 174\n",
      "time to device 0.010494 sec\n",
      "time forward 1.887407 sec\n",
      "loss time 0.001111 sec\n",
      "backward time 0.008627 sec\n",
      "optimizer time 0.020406 sec\n",
      "training time in round 174 cost 0.37504100799560547 sec\n",
      "loss 2.343320, train acc 0.097500\n",
      "round 175\n",
      "time to device 0.003979 sec\n",
      "time forward 1.896637 sec\n",
      "loss time 0.000798 sec\n",
      "backward time 0.007107 sec\n",
      "optimizer time 0.020766 sec\n",
      "training time in round 175 cost 0.35952091217041016 sec\n",
      "loss 2.343190, train acc 0.097612\n",
      "round 176\n",
      "time to device 0.003921 sec\n",
      "time forward 1.904175 sec\n",
      "loss time 0.000837 sec\n",
      "backward time 0.006316 sec\n",
      "optimizer time 0.015724 sec\n",
      "training time in round 176 cost 0.3417978286743164 sec\n",
      "loss 2.342984, train acc 0.097546\n",
      "round 177\n",
      "time to device 0.003153 sec\n",
      "time forward 1.911519 sec\n",
      "loss time 0.000886 sec\n",
      "backward time 0.008631 sec\n",
      "optimizer time 0.019492 sec\n",
      "training time in round 177 cost 0.3602120876312256 sec\n",
      "loss 2.343428, train acc 0.097525\n",
      "round 178\n",
      "time to device 0.003057 sec\n",
      "time forward 1.916617 sec\n",
      "loss time 0.000460 sec\n",
      "backward time 0.004309 sec\n",
      "optimizer time 0.012683 sec\n",
      "training time in round 178 cost 0.33422398567199707 sec\n",
      "loss 2.343234, train acc 0.097416\n",
      "round 179\n",
      "time to device 0.004507 sec\n",
      "time forward 1.924300 sec\n",
      "loss time 0.000739 sec\n",
      "backward time 0.007456 sec\n",
      "optimizer time 0.020044 sec\n",
      "training time in round 179 cost 0.35418701171875 sec\n",
      "loss 2.343003, train acc 0.097526\n",
      "round 180\n",
      "time to device 0.003116 sec\n",
      "time forward 1.935530 sec\n",
      "loss time 0.000863 sec\n",
      "backward time 0.008105 sec\n",
      "optimizer time 0.019069 sec\n",
      "training time in round 180 cost 0.36894702911376953 sec\n",
      "loss 2.342784, train acc 0.097462\n",
      "round 181\n",
      "time to device 0.003247 sec\n",
      "time forward 1.945378 sec\n",
      "loss time 0.000855 sec\n",
      "backward time 0.007967 sec\n",
      "optimizer time 0.019222 sec\n",
      "training time in round 181 cost 0.3646581172943115 sec\n",
      "loss 2.342547, train acc 0.097184\n",
      "round 182\n",
      "time to device 0.002900 sec\n",
      "time forward 1.957919 sec\n",
      "loss time 0.000429 sec\n",
      "backward time 0.004383 sec\n",
      "optimizer time 0.012245 sec\n",
      "training time in round 182 cost 0.3823511600494385 sec\n",
      "loss 2.342384, train acc 0.097165\n",
      "round 183\n",
      "time to device 0.006690 sec\n",
      "time forward 1.971384 sec\n",
      "loss time 0.000987 sec\n",
      "backward time 0.007060 sec\n",
      "optimizer time 0.023381 sec\n",
      "training time in round 183 cost 0.43443799018859863 sec\n",
      "loss 2.342608, train acc 0.097189\n",
      "round 184\n",
      "time to device 0.004839 sec\n",
      "time forward 1.978488 sec\n",
      "loss time 0.000534 sec\n",
      "backward time 0.004045 sec\n",
      "optimizer time 0.013941 sec\n",
      "training time in round 184 cost 0.37053608894348145 sec\n",
      "loss 2.342387, train acc 0.097086\n",
      "round 185\n",
      "time to device 0.008757 sec\n",
      "time forward 1.991048 sec\n",
      "loss time 0.001047 sec\n",
      "backward time 0.012959 sec\n",
      "optimizer time 0.027815 sec\n",
      "training time in round 185 cost 0.4116027355194092 sec\n",
      "loss 2.342178, train acc 0.096900\n",
      "round 186\n",
      "time to device 0.008219 sec\n",
      "time forward 1.998043 sec\n",
      "loss time 0.000453 sec\n",
      "backward time 0.004222 sec\n",
      "optimizer time 0.015223 sec\n",
      "training time in round 186 cost 0.40704894065856934 sec\n",
      "loss 2.341973, train acc 0.096842\n",
      "round 187\n",
      "time to device 0.007691 sec\n",
      "time forward 2.016302 sec\n",
      "loss time 0.001176 sec\n",
      "backward time 0.014790 sec\n",
      "optimizer time 0.016468 sec\n",
      "training time in round 187 cost 0.4574429988861084 sec\n",
      "loss 2.341761, train acc 0.096950\n",
      "round 188\n",
      "time to device 0.006953 sec\n",
      "time forward 2.026122 sec\n",
      "loss time 0.000770 sec\n",
      "backward time 0.004998 sec\n",
      "optimizer time 0.017156 sec\n",
      "training time in round 188 cost 0.3753080368041992 sec\n",
      "loss 2.341591, train acc 0.096933\n",
      "round 189\n",
      "time to device 0.007467 sec\n",
      "time forward 2.036597 sec\n",
      "loss time 0.001069 sec\n",
      "backward time 0.010927 sec\n",
      "optimizer time 0.031157 sec\n",
      "training time in round 189 cost 0.4298820495605469 sec\n",
      "loss 2.341395, train acc 0.096916\n",
      "round 190\n",
      "time to device 0.006935 sec\n",
      "time forward 2.043171 sec\n",
      "loss time 0.000662 sec\n",
      "backward time 0.005679 sec\n",
      "optimizer time 0.018097 sec\n",
      "training time in round 190 cost 0.3810880184173584 sec\n",
      "loss 2.341200, train acc 0.096818\n",
      "round 191\n",
      "time to device 0.006804 sec\n",
      "time forward 2.054365 sec\n",
      "loss time 0.001421 sec\n",
      "backward time 0.017100 sec\n",
      "optimizer time 0.031523 sec\n",
      "training time in round 191 cost 0.43772220611572266 sec\n",
      "loss 2.340996, train acc 0.096883\n",
      "round 192\n",
      "time to device 0.007939 sec\n",
      "time forward 2.075391 sec\n",
      "loss time 0.001086 sec\n",
      "backward time 0.013206 sec\n",
      "optimizer time 0.021272 sec\n",
      "training time in round 192 cost 0.4510636329650879 sec\n",
      "loss 2.341794, train acc 0.096745\n",
      "round 193\n",
      "time to device 0.007660 sec\n",
      "time forward 2.089059 sec\n",
      "loss time 0.001112 sec\n",
      "backward time 0.005765 sec\n",
      "optimizer time 0.013648 sec\n",
      "training time in round 193 cost 0.4073219299316406 sec\n",
      "loss 2.341595, train acc 0.096488\n",
      "round 194\n",
      "time to device 0.006344 sec\n",
      "time forward 2.103815 sec\n",
      "loss time 0.000753 sec\n",
      "backward time 0.017216 sec\n",
      "optimizer time 0.021378 sec\n",
      "training time in round 194 cost 0.41159987449645996 sec\n",
      "loss 2.341385, train acc 0.096394\n",
      "round 195\n",
      "time to device 0.006936 sec\n",
      "time forward 2.115827 sec\n",
      "loss time 0.001071 sec\n",
      "backward time 0.009254 sec\n",
      "optimizer time 0.027149 sec\n",
      "training time in round 195 cost 0.42938780784606934 sec\n",
      "loss 2.341423, train acc 0.096500\n",
      "round 196\n",
      "time to device 0.007276 sec\n",
      "time forward 2.122949 sec\n",
      "loss time 0.000598 sec\n",
      "backward time 0.005999 sec\n",
      "optimizer time 0.019046 sec\n",
      "training time in round 196 cost 0.38962888717651367 sec\n",
      "loss 2.341225, train acc 0.096526\n",
      "round 197\n",
      "time to device 0.008062 sec\n",
      "time forward 2.136467 sec\n",
      "loss time 0.001836 sec\n",
      "backward time 0.014593 sec\n",
      "optimizer time 0.025396 sec\n",
      "training time in round 197 cost 0.42235279083251953 sec\n",
      "loss 2.343991, train acc 0.096591\n",
      "round 198\n",
      "time to device 0.009130 sec\n",
      "time forward 2.145030 sec\n",
      "loss time 0.000797 sec\n",
      "backward time 0.008285 sec\n",
      "optimizer time 0.017328 sec\n",
      "training time in round 198 cost 0.3714277744293213 sec\n",
      "loss 2.344111, train acc 0.096891\n",
      "round 199\n",
      "time to device 0.007668 sec\n",
      "time forward 2.155856 sec\n",
      "loss time 0.001085 sec\n",
      "backward time 0.010771 sec\n",
      "optimizer time 0.036605 sec\n",
      "training time in round 199 cost 0.42459702491760254 sec\n",
      "loss 2.343904, train acc 0.096914\n",
      "round 200\n",
      "time to device 0.008215 sec\n",
      "time forward 2.164571 sec\n",
      "loss time 0.000894 sec\n",
      "backward time 0.007066 sec\n",
      "optimizer time 0.017487 sec\n",
      "training time in round 200 cost 0.3711409568786621 sec\n",
      "loss 2.343694, train acc 0.096898\n",
      "round 201\n",
      "time to device 0.009330 sec\n",
      "time forward 2.179877 sec\n",
      "loss time 0.001171 sec\n",
      "backward time 0.013449 sec\n",
      "optimizer time 0.028499 sec\n",
      "training time in round 201 cost 0.4145691394805908 sec\n",
      "loss 2.343501, train acc 0.096728\n",
      "round 202\n",
      "time to device 0.008466 sec\n",
      "time forward 2.196157 sec\n",
      "loss time 0.001015 sec\n",
      "backward time 0.009726 sec\n",
      "optimizer time 0.020956 sec\n",
      "training time in round 202 cost 0.41771793365478516 sec\n",
      "loss 2.343315, train acc 0.096636\n",
      "round 203\n",
      "time to device 0.006636 sec\n",
      "time forward 2.209143 sec\n",
      "loss time 0.001819 sec\n",
      "backward time 0.014788 sec\n",
      "optimizer time 0.027423 sec\n",
      "training time in round 203 cost 0.4177730083465576 sec\n",
      "loss 2.343138, train acc 0.096737\n",
      "round 204\n",
      "time to device 0.004641 sec\n",
      "time forward 2.221138 sec\n",
      "loss time 0.001697 sec\n",
      "backward time 0.014415 sec\n",
      "optimizer time 0.026157 sec\n",
      "training time in round 204 cost 0.3983790874481201 sec\n",
      "loss 2.342979, train acc 0.096494\n",
      "round 205\n",
      "time to device 0.003982 sec\n",
      "time forward 2.229390 sec\n",
      "loss time 0.000810 sec\n",
      "backward time 0.006567 sec\n",
      "optimizer time 0.016413 sec\n",
      "training time in round 205 cost 0.3670198917388916 sec\n",
      "loss 2.342768, train acc 0.096822\n",
      "round 206\n",
      "time to device 0.003630 sec\n",
      "time forward 2.240644 sec\n",
      "loss time 0.001122 sec\n",
      "backward time 0.012237 sec\n",
      "optimizer time 0.028066 sec\n",
      "training time in round 206 cost 0.3930840492248535 sec\n",
      "loss 2.342561, train acc 0.097034\n",
      "round 207\n",
      "time to device 0.004134 sec\n",
      "time forward 2.253406 sec\n",
      "loss time 0.001888 sec\n",
      "backward time 0.013436 sec\n",
      "optimizer time 0.027131 sec\n",
      "training time in round 207 cost 0.3978917598724365 sec\n",
      "loss 2.343473, train acc 0.097055\n",
      "round 208\n",
      "time to device 0.003664 sec\n",
      "time forward 2.262419 sec\n",
      "loss time 0.000652 sec\n",
      "backward time 0.006264 sec\n",
      "optimizer time 0.018491 sec\n",
      "training time in round 208 cost 0.37591075897216797 sec\n",
      "loss 2.343278, train acc 0.097039\n",
      "round 209\n",
      "time to device 0.003894 sec\n",
      "time forward 2.274339 sec\n",
      "loss time 0.001240 sec\n",
      "backward time 0.011204 sec\n",
      "optimizer time 0.034726 sec\n",
      "training time in round 209 cost 0.40872907638549805 sec\n",
      "loss 2.343080, train acc 0.096987\n",
      "round 210\n",
      "time to device 0.008233 sec\n",
      "time forward 2.283343 sec\n",
      "loss time 0.000773 sec\n",
      "backward time 0.007356 sec\n",
      "optimizer time 0.019471 sec\n",
      "training time in round 210 cost 0.37637877464294434 sec\n",
      "loss 2.343942, train acc 0.096934\n",
      "round 211\n",
      "time to device 0.006608 sec\n",
      "time forward 2.297026 sec\n",
      "loss time 0.001981 sec\n",
      "backward time 0.014084 sec\n",
      "optimizer time 0.027415 sec\n",
      "training time in round 211 cost 0.4066197872161865 sec\n",
      "loss 2.343730, train acc 0.097030\n",
      "round 212\n",
      "time to device 0.005733 sec\n",
      "time forward 2.307796 sec\n",
      "loss time 0.002333 sec\n",
      "backward time 0.012718 sec\n",
      "optimizer time 0.028537 sec\n",
      "training time in round 212 cost 0.42376017570495605 sec\n",
      "loss 2.344541, train acc 0.096978\n",
      "round 213\n",
      "time to device 0.007308 sec\n",
      "time forward 2.319697 sec\n",
      "loss time 0.001830 sec\n",
      "backward time 0.014664 sec\n",
      "optimizer time 0.028424 sec\n",
      "training time in round 213 cost 0.403472900390625 sec\n",
      "loss 2.344434, train acc 0.097145\n",
      "round 214\n",
      "time to device 0.009935 sec\n",
      "time forward 2.326684 sec\n",
      "loss time 0.000552 sec\n",
      "backward time 0.004867 sec\n",
      "optimizer time 0.013783 sec\n",
      "training time in round 214 cost 0.3756580352783203 sec\n",
      "loss 2.344359, train acc 0.096984\n",
      "round 215\n",
      "time to device 0.007733 sec\n",
      "time forward 2.338017 sec\n",
      "loss time 0.001109 sec\n",
      "backward time 0.012681 sec\n",
      "optimizer time 0.028162 sec\n",
      "training time in round 215 cost 0.3928349018096924 sec\n",
      "loss 2.344352, train acc 0.097078\n",
      "round 216\n",
      "time to device 0.007787 sec\n",
      "time forward 2.347900 sec\n",
      "loss time 0.001121 sec\n",
      "backward time 0.011950 sec\n",
      "optimizer time 0.027831 sec\n",
      "training time in round 216 cost 0.4200630187988281 sec\n",
      "loss 2.345604, train acc 0.096918\n",
      "round 217\n",
      "time to device 0.007908 sec\n",
      "time forward 2.359068 sec\n",
      "loss time 0.001115 sec\n",
      "backward time 0.011950 sec\n",
      "optimizer time 0.027209 sec\n",
      "training time in round 217 cost 0.39493298530578613 sec\n",
      "loss 2.346127, train acc 0.096832\n",
      "round 218\n",
      "time to device 0.006197 sec\n",
      "time forward 2.373318 sec\n",
      "loss time 0.001087 sec\n",
      "backward time 0.013071 sec\n",
      "optimizer time 0.031936 sec\n",
      "training time in round 218 cost 0.41382718086242676 sec\n",
      "loss 2.351136, train acc 0.096925\n",
      "round 219\n",
      "time to device 0.006849 sec\n",
      "time forward 2.388690 sec\n",
      "loss time 0.001154 sec\n",
      "backward time 0.013126 sec\n",
      "optimizer time 0.028388 sec\n",
      "training time in round 219 cost 0.4267611503601074 sec\n",
      "loss 2.350900, train acc 0.097017\n",
      "round 220\n",
      "time to device 0.007072 sec\n",
      "time forward 2.401101 sec\n",
      "loss time 0.001678 sec\n",
      "backward time 0.014264 sec\n",
      "optimizer time 0.018403 sec\n",
      "training time in round 220 cost 0.3897829055786133 sec\n",
      "loss 2.350620, train acc 0.097144\n",
      "round 221\n",
      "time to device 0.008992 sec\n",
      "time forward 2.413098 sec\n",
      "loss time 0.001040 sec\n",
      "backward time 0.011525 sec\n",
      "optimizer time 0.028161 sec\n",
      "training time in round 221 cost 0.40151000022888184 sec\n",
      "loss 2.350930, train acc 0.097199\n",
      "round 222\n",
      "time to device 0.007925 sec\n",
      "time forward 2.427061 sec\n",
      "loss time 0.001119 sec\n",
      "backward time 0.011494 sec\n",
      "optimizer time 0.027872 sec\n",
      "training time in round 222 cost 0.4126451015472412 sec\n",
      "loss 2.350742, train acc 0.097218\n",
      "round 223\n",
      "time to device 0.006561 sec\n",
      "time forward 2.438453 sec\n",
      "loss time 0.001130 sec\n",
      "backward time 0.011971 sec\n",
      "optimizer time 0.022911 sec\n",
      "training time in round 223 cost 0.3930940628051758 sec\n",
      "loss 2.353743, train acc 0.097203\n",
      "round 224\n",
      "time to device 0.003134 sec\n",
      "time forward 2.450480 sec\n",
      "loss time 0.001014 sec\n",
      "backward time 0.015560 sec\n",
      "optimizer time 0.026798 sec\n",
      "training time in round 224 cost 0.3932332992553711 sec\n",
      "loss 2.353515, train acc 0.097153\n",
      "round 225\n",
      "time to device 0.004388 sec\n",
      "time forward 2.463915 sec\n",
      "loss time 0.001404 sec\n",
      "backward time 0.012269 sec\n",
      "optimizer time 0.022685 sec\n",
      "training time in round 225 cost 0.4009878635406494 sec\n",
      "loss 2.353287, train acc 0.097172\n",
      "round 226\n",
      "time to device 0.003587 sec\n",
      "time forward 2.475097 sec\n",
      "loss time 0.000955 sec\n",
      "backward time 0.010376 sec\n",
      "optimizer time 0.029868 sec\n",
      "training time in round 226 cost 0.39530301094055176 sec\n",
      "loss 2.353052, train acc 0.097157\n",
      "round 227\n",
      "time to device 0.004147 sec\n",
      "time forward 2.487052 sec\n",
      "loss time 0.001604 sec\n",
      "backward time 0.012403 sec\n",
      "optimizer time 0.024094 sec\n",
      "training time in round 227 cost 0.38904309272766113 sec\n",
      "loss 2.352870, train acc 0.097177\n",
      "round 228\n",
      "time to device 0.005955 sec\n",
      "time forward 2.495106 sec\n",
      "loss time 0.000375 sec\n",
      "backward time 0.003498 sec\n",
      "optimizer time 0.011094 sec\n",
      "training time in round 228 cost 0.36091017723083496 sec\n",
      "loss 2.352544, train acc 0.097127\n",
      "round 229\n",
      "time to device 0.003574 sec\n",
      "time forward 2.510678 sec\n",
      "loss time 0.001223 sec\n",
      "backward time 0.012753 sec\n",
      "optimizer time 0.030061 sec\n",
      "training time in round 229 cost 0.4242680072784424 sec\n",
      "loss 2.352345, train acc 0.097045\n",
      "round 230\n",
      "time to device 0.003982 sec\n",
      "time forward 2.520509 sec\n",
      "loss time 0.001085 sec\n",
      "backward time 0.009690 sec\n",
      "optimizer time 0.022424 sec\n",
      "training time in round 230 cost 0.4373171329498291 sec\n",
      "loss 2.352155, train acc 0.097064\n",
      "round 231\n",
      "time to device 0.007112 sec\n",
      "time forward 2.529438 sec\n",
      "loss time 0.000844 sec\n",
      "backward time 0.004140 sec\n",
      "optimizer time 0.014746 sec\n",
      "training time in round 231 cost 0.40051817893981934 sec\n",
      "loss 2.352256, train acc 0.096949\n",
      "round 232\n",
      "time to device 0.009955 sec\n",
      "time forward 2.539546 sec\n",
      "loss time 0.001297 sec\n",
      "backward time 0.011642 sec\n",
      "optimizer time 0.032634 sec\n",
      "training time in round 232 cost 0.425137996673584 sec\n",
      "loss 2.352151, train acc 0.096935\n",
      "round 233\n",
      "time to device 0.007450 sec\n",
      "time forward 2.548370 sec\n",
      "loss time 0.000534 sec\n",
      "backward time 0.006449 sec\n",
      "optimizer time 0.014307 sec\n",
      "training time in round 233 cost 0.3731350898742676 sec\n",
      "loss 2.352063, train acc 0.096955\n",
      "round 234\n",
      "time to device 0.006710 sec\n",
      "time forward 2.557313 sec\n",
      "loss time 0.000908 sec\n",
      "backward time 0.008056 sec\n",
      "optimizer time 0.018052 sec\n",
      "training time in round 234 cost 0.3985147476196289 sec\n",
      "loss 2.351868, train acc 0.096941\n",
      "round 235\n",
      "time to device 0.008208 sec\n",
      "time forward 2.572894 sec\n",
      "loss time 0.000810 sec\n",
      "backward time 0.007819 sec\n",
      "optimizer time 0.020226 sec\n",
      "training time in round 235 cost 0.3930790424346924 sec\n",
      "loss 2.351931, train acc 0.096696\n",
      "round 236\n",
      "time to device 0.007380 sec\n",
      "time forward 2.585985 sec\n",
      "loss time 0.001073 sec\n",
      "backward time 0.010469 sec\n",
      "optimizer time 0.031269 sec\n",
      "training time in round 236 cost 0.42809200286865234 sec\n",
      "loss 2.351738, train acc 0.096552\n",
      "round 237\n",
      "time to device 0.007054 sec\n",
      "time forward 2.597708 sec\n",
      "loss time 0.001164 sec\n",
      "backward time 0.019346 sec\n",
      "optimizer time 0.023864 sec\n",
      "training time in round 237 cost 0.4102358818054199 sec\n",
      "loss 2.351529, train acc 0.096475\n",
      "round 238\n",
      "time to device 0.007318 sec\n",
      "time forward 2.609066 sec\n",
      "loss time 0.001119 sec\n",
      "backward time 0.010843 sec\n",
      "optimizer time 0.022226 sec\n",
      "training time in round 238 cost 0.4220750331878662 sec\n",
      "loss 2.351335, train acc 0.096463\n",
      "round 239\n",
      "time to device 0.007094 sec\n",
      "time forward 2.619481 sec\n",
      "loss time 0.001027 sec\n",
      "backward time 0.010218 sec\n",
      "optimizer time 0.026308 sec\n",
      "training time in round 239 cost 0.418536901473999 sec\n",
      "loss 2.351148, train acc 0.096354\n",
      "round 240\n",
      "time to device 0.007190 sec\n",
      "time forward 2.632207 sec\n",
      "loss time 0.001157 sec\n",
      "backward time 0.011235 sec\n",
      "optimizer time 0.020967 sec\n",
      "training time in round 240 cost 0.43418312072753906 sec\n",
      "loss 2.350956, train acc 0.096343\n",
      "round 241\n",
      "time to device 0.006530 sec\n",
      "time forward 2.644582 sec\n",
      "loss time 0.001591 sec\n",
      "backward time 0.014436 sec\n",
      "optimizer time 0.032439 sec\n",
      "training time in round 241 cost 0.416121244430542 sec\n",
      "loss 2.350995, train acc 0.096365\n",
      "round 242\n",
      "time to device 0.008118 sec\n",
      "time forward 2.659838 sec\n",
      "loss time 0.001016 sec\n",
      "backward time 0.026439 sec\n",
      "optimizer time 0.016898 sec\n",
      "training time in round 242 cost 0.4441068172454834 sec\n",
      "loss 2.350897, train acc 0.096354\n",
      "round 243\n",
      "time to device 0.006309 sec\n",
      "time forward 2.671279 sec\n",
      "loss time 0.001054 sec\n",
      "backward time 0.012119 sec\n",
      "optimizer time 0.028718 sec\n",
      "training time in round 243 cost 0.3996260166168213 sec\n",
      "loss 2.350728, train acc 0.096247\n",
      "round 244\n",
      "time to device 0.006406 sec\n",
      "time forward 2.680801 sec\n",
      "loss time 0.000491 sec\n",
      "backward time 0.004453 sec\n",
      "optimizer time 0.012877 sec\n",
      "training time in round 244 cost 0.3743772506713867 sec\n",
      "loss 2.350522, train acc 0.096460\n",
      "round 245\n",
      "time to device 0.008459 sec\n",
      "time forward 2.692554 sec\n",
      "loss time 0.001826 sec\n",
      "backward time 0.016814 sec\n",
      "optimizer time 0.016020 sec\n",
      "training time in round 245 cost 0.421065092086792 sec\n",
      "loss 2.350326, train acc 0.096481\n",
      "round 246\n",
      "time to device 0.008293 sec\n",
      "time forward 2.700485 sec\n",
      "loss time 0.000657 sec\n",
      "backward time 0.004943 sec\n",
      "optimizer time 0.016280 sec\n",
      "training time in round 246 cost 0.40619516372680664 sec\n",
      "loss 2.350139, train acc 0.096407\n",
      "round 247\n",
      "time to device 0.007425 sec\n",
      "time forward 2.713650 sec\n",
      "loss time 0.001248 sec\n",
      "backward time 0.012848 sec\n",
      "optimizer time 0.018983 sec\n",
      "training time in round 247 cost 0.5312080383300781 sec\n",
      "loss 2.349953, train acc 0.096396\n",
      "round 248\n",
      "time to device 0.008175 sec\n",
      "time forward 2.721087 sec\n",
      "loss time 0.000403 sec\n",
      "backward time 0.004712 sec\n",
      "optimizer time 0.012014 sec\n",
      "training time in round 248 cost 0.4241042137145996 sec\n",
      "loss 2.349768, train acc 0.096386\n",
      "round 249\n",
      "time to device 0.006278 sec\n",
      "time forward 2.731959 sec\n",
      "loss time 0.001091 sec\n",
      "backward time 0.009881 sec\n",
      "optimizer time 0.057594 sec\n",
      "training time in round 249 cost 0.5133860111236572 sec\n",
      "loss 2.349734, train acc 0.096531\n",
      "round 250\n",
      "time to device 0.008363 sec\n",
      "time forward 2.741795 sec\n",
      "loss time 0.000933 sec\n",
      "backward time 0.007408 sec\n",
      "optimizer time 0.020243 sec\n",
      "training time in round 250 cost 0.4430551528930664 sec\n",
      "loss 2.349748, train acc 0.096551\n",
      "round 251\n",
      "time to device 0.007197 sec\n",
      "time forward 2.750849 sec\n",
      "loss time 0.001224 sec\n",
      "backward time 0.010459 sec\n",
      "optimizer time 0.022402 sec\n",
      "training time in round 251 cost 0.3989241123199463 sec\n",
      "loss 2.349678, train acc 0.096478\n",
      "round 252\n",
      "time to device 0.009784 sec\n",
      "time forward 2.765948 sec\n",
      "loss time 0.001122 sec\n",
      "backward time 0.013295 sec\n",
      "optimizer time 0.028067 sec\n",
      "training time in round 252 cost 0.41196107864379883 sec\n",
      "loss 2.349494, train acc 0.096467\n",
      "round 253\n",
      "time to device 0.007169 sec\n",
      "time forward 2.777344 sec\n",
      "loss time 0.001328 sec\n",
      "backward time 0.011394 sec\n",
      "optimizer time 0.021822 sec\n",
      "training time in round 253 cost 0.38684582710266113 sec\n",
      "loss 2.349296, train acc 0.096580\n",
      "round 254\n",
      "time to device 0.007758 sec\n",
      "time forward 2.789407 sec\n",
      "loss time 0.001440 sec\n",
      "backward time 0.019974 sec\n",
      "optimizer time 0.026852 sec\n",
      "training time in round 254 cost 0.40822887420654297 sec\n",
      "loss 2.349128, train acc 0.096446\n",
      "round 255\n",
      "time to device 0.006292 sec\n",
      "time forward 2.796796 sec\n",
      "loss time 0.000745 sec\n",
      "backward time 0.006536 sec\n",
      "optimizer time 0.016183 sec\n",
      "training time in round 255 cost 0.3623659610748291 sec\n",
      "loss 2.349099, train acc 0.096436\n",
      "round 256\n",
      "time to device 0.007782 sec\n",
      "time forward 2.807287 sec\n",
      "loss time 0.002132 sec\n",
      "backward time 0.019292 sec\n",
      "optimizer time 0.022787 sec\n",
      "training time in round 256 cost 0.4426138401031494 sec\n",
      "loss 2.349143, train acc 0.096547\n",
      "round 257\n",
      "time to device 0.008972 sec\n",
      "time forward 2.818466 sec\n",
      "loss time 0.000749 sec\n",
      "backward time 0.007474 sec\n",
      "optimizer time 0.017277 sec\n",
      "training time in round 257 cost 0.37807726860046387 sec\n",
      "loss 2.348971, train acc 0.096415\n",
      "round 258\n",
      "time to device 0.008872 sec\n",
      "time forward 2.832965 sec\n",
      "loss time 0.001158 sec\n",
      "backward time 0.016498 sec\n",
      "optimizer time 0.025614 sec\n",
      "training time in round 258 cost 0.44411373138427734 sec\n",
      "loss 2.348794, train acc 0.096435\n",
      "round 259\n",
      "time to device 0.007347 sec\n",
      "time forward 2.842449 sec\n",
      "loss time 0.000921 sec\n",
      "backward time 0.008017 sec\n",
      "optimizer time 0.018112 sec\n",
      "training time in round 259 cost 0.3762931823730469 sec\n",
      "loss 2.348632, train acc 0.096394\n",
      "round 260\n",
      "time to device 0.003800 sec\n",
      "time forward 2.854644 sec\n",
      "loss time 0.001398 sec\n",
      "backward time 0.012934 sec\n",
      "optimizer time 0.025836 sec\n",
      "training time in round 260 cost 0.39532899856567383 sec\n",
      "loss 2.348458, train acc 0.096414\n",
      "round 261\n",
      "time to device 0.003460 sec\n",
      "time forward 2.865824 sec\n",
      "loss time 0.001074 sec\n",
      "backward time 0.004467 sec\n",
      "optimizer time 0.011484 sec\n",
      "training time in round 261 cost 0.38941311836242676 sec\n",
      "loss 2.348285, train acc 0.096404\n",
      "round 262\n",
      "time to device 0.007406 sec\n",
      "time forward 2.877952 sec\n",
      "loss time 0.004634 sec\n",
      "backward time 0.006283 sec\n",
      "optimizer time 0.015784 sec\n",
      "training time in round 262 cost 0.3869750499725342 sec\n",
      "loss 2.348107, train acc 0.096542\n",
      "round 263\n",
      "time to device 0.006897 sec\n",
      "time forward 2.889687 sec\n",
      "loss time 0.000657 sec\n",
      "backward time 0.006303 sec\n",
      "optimizer time 0.018287 sec\n",
      "training time in round 263 cost 0.3816230297088623 sec\n",
      "loss 2.347928, train acc 0.096739\n",
      "round 264\n",
      "time to device 0.006794 sec\n",
      "time forward 2.897887 sec\n",
      "loss time 0.000780 sec\n",
      "backward time 0.006667 sec\n",
      "optimizer time 0.016281 sec\n",
      "training time in round 264 cost 0.36942577362060547 sec\n",
      "loss 2.347780, train acc 0.096904\n",
      "round 265\n",
      "time to device 0.007927 sec\n",
      "time forward 2.905879 sec\n",
      "loss time 0.000765 sec\n",
      "backward time 0.006509 sec\n",
      "optimizer time 0.016492 sec\n",
      "training time in round 265 cost 0.36939382553100586 sec\n",
      "loss 2.347606, train acc 0.096893\n",
      "round 266\n",
      "time to device 0.002463 sec\n",
      "time forward 2.912462 sec\n",
      "loss time 0.000483 sec\n",
      "backward time 0.004066 sec\n",
      "optimizer time 0.013769 sec\n",
      "training time in round 266 cost 0.3675508499145508 sec\n",
      "loss 2.347442, train acc 0.096939\n",
      "round 267\n",
      "time to device 0.004627 sec\n",
      "time forward 2.921320 sec\n",
      "loss time 0.000775 sec\n",
      "backward time 0.007112 sec\n",
      "optimizer time 0.017812 sec\n",
      "training time in round 267 cost 0.37667107582092285 sec\n",
      "loss 2.347294, train acc 0.096840\n",
      "round 268\n",
      "time to device 0.003346 sec\n",
      "time forward 2.928163 sec\n",
      "loss time 0.000440 sec\n",
      "backward time 0.005310 sec\n",
      "optimizer time 0.017665 sec\n",
      "training time in round 268 cost 0.3839256763458252 sec\n",
      "loss 2.347087, train acc 0.096945\n",
      "round 269\n",
      "time to device 0.002287 sec\n",
      "time forward 2.938418 sec\n",
      "loss time 0.001304 sec\n",
      "backward time 0.013164 sec\n",
      "optimizer time 0.028466 sec\n",
      "training time in round 269 cost 0.41890406608581543 sec\n",
      "loss 2.347015, train acc 0.096875\n",
      "round 270\n",
      "time to device 0.008098 sec\n",
      "time forward 2.947201 sec\n",
      "loss time 0.000772 sec\n",
      "backward time 0.006987 sec\n",
      "optimizer time 0.018017 sec\n",
      "training time in round 270 cost 0.3809628486633301 sec\n",
      "loss 2.346849, train acc 0.096892\n",
      "round 271\n",
      "time to device 0.006291 sec\n",
      "time forward 2.959182 sec\n",
      "loss time 0.001155 sec\n",
      "backward time 0.011904 sec\n",
      "optimizer time 0.025479 sec\n",
      "training time in round 271 cost 0.39946699142456055 sec\n",
      "loss 2.346689, train acc 0.096996\n",
      "round 272\n",
      "time to device 0.009147 sec\n",
      "time forward 2.967303 sec\n",
      "loss time 0.000758 sec\n",
      "backward time 0.008676 sec\n",
      "optimizer time 0.018091 sec\n",
      "training time in round 272 cost 0.3722238540649414 sec\n",
      "loss 2.346524, train acc 0.096869\n",
      "round 273\n",
      "time to device 0.007758 sec\n",
      "time forward 2.974810 sec\n",
      "loss time 0.000893 sec\n",
      "backward time 0.007293 sec\n",
      "optimizer time 0.017305 sec\n",
      "training time in round 273 cost 0.37369704246520996 sec\n",
      "loss 2.346364, train acc 0.096943\n",
      "round 274\n",
      "time to device 0.008872 sec\n",
      "time forward 2.981937 sec\n",
      "loss time 0.000721 sec\n",
      "backward time 0.006556 sec\n",
      "optimizer time 0.016047 sec\n",
      "training time in round 274 cost 0.3554370403289795 sec\n",
      "loss 2.346213, train acc 0.096847\n",
      "round 275\n",
      "time to device 0.012734 sec\n",
      "time forward 2.992204 sec\n",
      "loss time 0.000760 sec\n",
      "backward time 0.006953 sec\n",
      "optimizer time 0.017089 sec\n",
      "training time in round 275 cost 0.3689079284667969 sec\n",
      "loss 2.346055, train acc 0.096864\n",
      "round 276\n",
      "time to device 0.005980 sec\n",
      "time forward 2.999756 sec\n",
      "loss time 0.000801 sec\n",
      "backward time 0.007162 sec\n",
      "optimizer time 0.017907 sec\n",
      "training time in round 276 cost 0.4023549556732178 sec\n",
      "loss 2.345900, train acc 0.096881\n",
      "round 277\n",
      "time to device 0.008952 sec\n",
      "time forward 3.012206 sec\n",
      "loss time 0.001086 sec\n",
      "backward time 0.025616 sec\n",
      "optimizer time 0.018233 sec\n",
      "training time in round 277 cost 0.4187967777252197 sec\n",
      "loss 2.345741, train acc 0.096897\n",
      "round 278\n",
      "time to device 0.006891 sec\n",
      "time forward 3.024787 sec\n",
      "loss time 0.001579 sec\n",
      "backward time 0.011158 sec\n",
      "optimizer time 0.028940 sec\n",
      "training time in round 278 cost 0.4821178913116455 sec\n",
      "loss 2.345646, train acc 0.096830\n",
      "round 279\n",
      "time to device 0.004859 sec\n",
      "time forward 3.033345 sec\n",
      "loss time 0.000502 sec\n",
      "backward time 0.004684 sec\n",
      "optimizer time 0.014738 sec\n",
      "training time in round 279 cost 0.4589269161224365 sec\n",
      "loss 2.345494, train acc 0.096708\n",
      "round 280\n",
      "time to device 0.007808 sec\n",
      "time forward 3.040220 sec\n",
      "loss time 0.000949 sec\n",
      "backward time 0.009534 sec\n",
      "optimizer time 0.014093 sec\n",
      "training time in round 280 cost 0.37891507148742676 sec\n",
      "loss 2.345344, train acc 0.096780\n",
      "round 281\n",
      "time to device 0.006440 sec\n",
      "time forward 3.054000 sec\n",
      "loss time 0.001333 sec\n",
      "backward time 0.007962 sec\n",
      "optimizer time 0.014465 sec\n",
      "training time in round 281 cost 0.39367222785949707 sec\n",
      "loss 2.345193, train acc 0.096770\n",
      "round 282\n",
      "time to device 0.009404 sec\n",
      "time forward 3.067305 sec\n",
      "loss time 0.001632 sec\n",
      "backward time 0.008925 sec\n",
      "optimizer time 0.017536 sec\n",
      "training time in round 282 cost 0.40840888023376465 sec\n",
      "loss 2.345040, train acc 0.096869\n",
      "round 283\n",
      "time to device 0.008226 sec\n",
      "time forward 3.073895 sec\n",
      "loss time 0.000774 sec\n",
      "backward time 0.006899 sec\n",
      "optimizer time 0.017300 sec\n",
      "training time in round 283 cost 0.38584327697753906 sec\n",
      "loss 2.344907, train acc 0.096721\n",
      "round 284\n",
      "time to device 0.007792 sec\n",
      "time forward 3.082109 sec\n",
      "loss time 0.000766 sec\n",
      "backward time 0.006521 sec\n",
      "optimizer time 0.016503 sec\n",
      "training time in round 284 cost 0.3710939884185791 sec\n",
      "loss 2.344799, train acc 0.096546\n",
      "round 285\n",
      "time to device 0.006981 sec\n",
      "time forward 3.089756 sec\n",
      "loss time 0.000647 sec\n",
      "backward time 0.007730 sec\n",
      "optimizer time 0.016155 sec\n",
      "training time in round 285 cost 0.3750002384185791 sec\n",
      "loss 2.344777, train acc 0.096400\n",
      "round 286\n",
      "time to device 0.008836 sec\n",
      "time forward 3.097257 sec\n",
      "loss time 0.000677 sec\n",
      "backward time 0.010391 sec\n",
      "optimizer time 0.019120 sec\n",
      "training time in round 286 cost 0.4064943790435791 sec\n",
      "loss 2.344620, train acc 0.096418\n",
      "round 287\n",
      "time to device 0.007477 sec\n",
      "time forward 3.107540 sec\n",
      "loss time 0.001089 sec\n",
      "backward time 0.008884 sec\n",
      "optimizer time 0.020676 sec\n",
      "training time in round 287 cost 0.4160451889038086 sec\n",
      "loss 2.344524, train acc 0.096598\n",
      "round 288\n",
      "time to device 0.006596 sec\n",
      "time forward 3.119475 sec\n",
      "loss time 0.001046 sec\n",
      "backward time 0.012250 sec\n",
      "optimizer time 0.026754 sec\n",
      "training time in round 288 cost 0.409404993057251 sec\n",
      "loss 2.344367, train acc 0.096588\n",
      "round 289\n",
      "time to device 0.007305 sec\n",
      "time forward 3.127631 sec\n",
      "loss time 0.000802 sec\n",
      "backward time 0.009061 sec\n",
      "optimizer time 0.016587 sec\n",
      "training time in round 289 cost 0.37355804443359375 sec\n",
      "loss 2.344215, train acc 0.096633\n",
      "round 290\n",
      "time to device 0.008422 sec\n",
      "time forward 3.138913 sec\n",
      "loss time 0.001435 sec\n",
      "backward time 0.013497 sec\n",
      "optimizer time 0.027379 sec\n",
      "training time in round 290 cost 0.3959946632385254 sec\n",
      "loss 2.344911, train acc 0.096569\n",
      "round 291\n",
      "time to device 0.006744 sec\n",
      "time forward 3.147081 sec\n",
      "loss time 0.000893 sec\n",
      "backward time 0.007103 sec\n",
      "optimizer time 0.017082 sec\n",
      "training time in round 291 cost 0.37405991554260254 sec\n",
      "loss 2.344762, train acc 0.096586\n",
      "round 292\n",
      "time to device 0.006932 sec\n",
      "time forward 3.158748 sec\n",
      "loss time 0.001077 sec\n",
      "backward time 0.011550 sec\n",
      "optimizer time 0.026134 sec\n",
      "training time in round 292 cost 0.43433499336242676 sec\n",
      "loss 2.344625, train acc 0.096630\n",
      "round 293\n",
      "time to device 0.007556 sec\n",
      "time forward 3.170551 sec\n",
      "loss time 0.001237 sec\n",
      "backward time 0.008931 sec\n",
      "optimizer time 0.018535 sec\n",
      "training time in round 293 cost 0.39494991302490234 sec\n",
      "loss 2.344489, train acc 0.096540\n",
      "round 294\n",
      "time to device 0.007182 sec\n",
      "time forward 3.181978 sec\n",
      "loss time 0.001234 sec\n",
      "backward time 0.006439 sec\n",
      "optimizer time 0.012091 sec\n",
      "training time in round 294 cost 0.39061403274536133 sec\n",
      "loss 2.344347, train acc 0.096557\n",
      "round 295\n",
      "time to device 0.008863 sec\n",
      "time forward 3.190076 sec\n",
      "loss time 0.000843 sec\n",
      "backward time 0.007723 sec\n",
      "optimizer time 0.019965 sec\n",
      "training time in round 295 cost 0.38001108169555664 sec\n",
      "loss 2.344202, train acc 0.096601\n",
      "round 296\n",
      "time to device 0.007080 sec\n",
      "time forward 3.203161 sec\n",
      "loss time 0.001225 sec\n",
      "backward time 0.011696 sec\n",
      "optimizer time 0.026061 sec\n",
      "training time in round 296 cost 0.4310488700866699 sec\n",
      "loss 2.344051, train acc 0.096644\n",
      "round 297\n",
      "time to device 0.006154 sec\n",
      "time forward 3.215558 sec\n",
      "loss time 0.001087 sec\n",
      "backward time 0.011012 sec\n",
      "optimizer time 0.023650 sec\n",
      "training time in round 297 cost 0.4640073776245117 sec\n",
      "loss 2.343909, train acc 0.096608\n",
      "round 298\n",
      "time to device 0.006223 sec\n",
      "time forward 3.229111 sec\n",
      "loss time 0.001393 sec\n",
      "backward time 0.013585 sec\n",
      "optimizer time 0.017733 sec\n",
      "training time in round 298 cost 0.4237949848175049 sec\n",
      "loss 2.343781, train acc 0.096494\n",
      "round 299\n",
      "time to device 0.006341 sec\n",
      "time forward 3.240184 sec\n",
      "loss time 0.001622 sec\n",
      "backward time 0.011189 sec\n",
      "optimizer time 0.034196 sec\n",
      "training time in round 299 cost 0.4202711582183838 sec\n",
      "loss 2.343650, train acc 0.096458\n",
      "round 300\n",
      "time to device 0.006862 sec\n",
      "time forward 3.248382 sec\n",
      "loss time 0.000521 sec\n",
      "backward time 0.004153 sec\n",
      "optimizer time 0.012738 sec\n",
      "training time in round 300 cost 0.39621996879577637 sec\n",
      "loss 2.343518, train acc 0.096527\n",
      "round 301\n",
      "time to device 0.009957 sec\n",
      "time forward 3.259368 sec\n",
      "loss time 0.001946 sec\n",
      "backward time 0.010711 sec\n",
      "optimizer time 0.024623 sec\n",
      "training time in round 301 cost 0.39316606521606445 sec\n",
      "loss 2.343398, train acc 0.096415\n",
      "round 302\n",
      "time to device 0.006125 sec\n",
      "time forward 3.267032 sec\n",
      "loss time 0.000556 sec\n",
      "backward time 0.004774 sec\n",
      "optimizer time 0.015655 sec\n",
      "training time in round 302 cost 0.3963651657104492 sec\n",
      "loss 2.343281, train acc 0.096303\n",
      "round 303\n",
      "time to device 0.007478 sec\n",
      "time forward 3.280064 sec\n",
      "loss time 0.001819 sec\n",
      "backward time 0.012158 sec\n",
      "optimizer time 0.025015 sec\n",
      "training time in round 303 cost 0.4095132350921631 sec\n",
      "loss 2.343156, train acc 0.096320\n",
      "round 304\n",
      "time to device 0.007038 sec\n",
      "time forward 3.290746 sec\n",
      "loss time 0.001032 sec\n",
      "backward time 0.012105 sec\n",
      "optimizer time 0.025122 sec\n",
      "training time in round 304 cost 0.39045190811157227 sec\n",
      "loss 2.343021, train acc 0.096286\n",
      "round 305\n",
      "time to device 0.011053 sec\n",
      "time forward 3.302061 sec\n",
      "loss time 0.001321 sec\n",
      "backward time 0.011896 sec\n",
      "optimizer time 0.023031 sec\n",
      "training time in round 305 cost 0.41520166397094727 sec\n",
      "loss 2.342890, train acc 0.096354\n",
      "round 306\n",
      "time to device 0.008605 sec\n",
      "time forward 3.314157 sec\n",
      "loss time 0.000952 sec\n",
      "backward time 0.021406 sec\n",
      "optimizer time 0.013515 sec\n",
      "training time in round 306 cost 0.4118788242340088 sec\n",
      "loss 2.342751, train acc 0.096422\n",
      "round 307\n",
      "time to device 0.006387 sec\n",
      "time forward 3.326279 sec\n",
      "loss time 0.001050 sec\n",
      "backward time 0.010228 sec\n",
      "optimizer time 0.019565 sec\n",
      "training time in round 307 cost 0.4995269775390625 sec\n",
      "loss 2.342641, train acc 0.096413\n",
      "round 308\n",
      "time to device 0.006840 sec\n",
      "time forward 3.340494 sec\n",
      "loss time 0.002067 sec\n",
      "backward time 0.015318 sec\n",
      "optimizer time 0.019327 sec\n",
      "training time in round 308 cost 0.416104793548584 sec\n",
      "loss 2.342800, train acc 0.096556\n",
      "round 309\n",
      "time to device 0.006800 sec\n",
      "time forward 3.352553 sec\n",
      "loss time 0.001011 sec\n",
      "backward time 0.016069 sec\n",
      "optimizer time 0.018749 sec\n",
      "training time in round 309 cost 0.4310340881347656 sec\n",
      "loss 2.342667, train acc 0.096522\n",
      "round 310\n",
      "time to device 0.037871 sec\n",
      "time forward 3.372259 sec\n",
      "loss time 0.000467 sec\n",
      "backward time 0.003778 sec\n",
      "optimizer time 0.014027 sec\n",
      "training time in round 310 cost 0.45348191261291504 sec\n",
      "loss 2.342544, train acc 0.096564\n",
      "round 311\n",
      "time to device 0.007477 sec\n",
      "time forward 3.384854 sec\n",
      "loss time 0.001454 sec\n",
      "backward time 0.018541 sec\n",
      "optimizer time 0.015596 sec\n",
      "training time in round 311 cost 0.43582892417907715 sec\n",
      "loss 2.342736, train acc 0.096655\n",
      "round 312\n",
      "time to device 0.006604 sec\n",
      "time forward 3.393842 sec\n",
      "loss time 0.001014 sec\n",
      "backward time 0.006261 sec\n",
      "optimizer time 0.018727 sec\n",
      "training time in round 312 cost 0.37995314598083496 sec\n",
      "loss 2.342613, train acc 0.096645\n",
      "round 313\n",
      "time to device 0.007836 sec\n",
      "time forward 3.408403 sec\n",
      "loss time 0.001035 sec\n",
      "backward time 0.015184 sec\n",
      "optimizer time 0.030380 sec\n",
      "training time in round 313 cost 0.41991591453552246 sec\n",
      "loss 2.342477, train acc 0.096711\n",
      "round 314\n",
      "time to device 0.008207 sec\n",
      "time forward 3.420449 sec\n",
      "loss time 0.001399 sec\n",
      "backward time 0.018563 sec\n",
      "optimizer time 0.023499 sec\n",
      "training time in round 314 cost 0.4423339366912842 sec\n",
      "loss 2.342406, train acc 0.096776\n",
      "round 315\n",
      "time to device 0.006203 sec\n",
      "time forward 3.431833 sec\n",
      "loss time 0.001152 sec\n",
      "backward time 0.011351 sec\n",
      "optimizer time 0.022296 sec\n",
      "training time in round 315 cost 0.4332430362701416 sec\n",
      "loss 2.342553, train acc 0.096791\n",
      "round 316\n",
      "time to device 0.030047 sec\n",
      "time forward 3.441452 sec\n",
      "loss time 0.001536 sec\n",
      "backward time 0.011116 sec\n",
      "optimizer time 0.023441 sec\n",
      "training time in round 316 cost 0.49449706077575684 sec\n",
      "loss 2.342443, train acc 0.096806\n",
      "round 317\n",
      "time to device 0.008299 sec\n",
      "time forward 3.450969 sec\n",
      "loss time 0.000945 sec\n",
      "backward time 0.009820 sec\n",
      "optimizer time 0.021643 sec\n",
      "training time in round 317 cost 0.41001296043395996 sec\n",
      "loss 2.342379, train acc 0.096723\n",
      "round 318\n",
      "time to device 0.007353 sec\n",
      "time forward 3.465657 sec\n",
      "loss time 0.001104 sec\n",
      "backward time 0.014206 sec\n",
      "optimizer time 0.024595 sec\n",
      "training time in round 318 cost 0.4877638816833496 sec\n",
      "loss 2.342355, train acc 0.096909\n",
      "round 319\n",
      "time to device 0.007142 sec\n",
      "time forward 3.474097 sec\n",
      "loss time 0.000844 sec\n",
      "backward time 0.007031 sec\n",
      "optimizer time 0.017731 sec\n",
      "training time in round 319 cost 0.44759392738342285 sec\n",
      "loss 2.342177, train acc 0.097095\n",
      "round 320\n",
      "time to device 0.007038 sec\n",
      "time forward 3.485421 sec\n",
      "loss time 0.001476 sec\n",
      "backward time 0.010559 sec\n",
      "optimizer time 0.031501 sec\n",
      "training time in round 320 cost 0.40079426765441895 sec\n",
      "loss 2.342069, train acc 0.096987\n",
      "round 321\n",
      "time to device 0.006466 sec\n",
      "time forward 3.496961 sec\n",
      "loss time 0.001214 sec\n",
      "backward time 0.013592 sec\n",
      "optimizer time 0.028262 sec\n",
      "training time in round 321 cost 0.3995239734649658 sec\n",
      "loss 2.341929, train acc 0.097268\n",
      "round 322\n",
      "time to device 0.008676 sec\n",
      "time forward 3.504678 sec\n",
      "loss time 0.000679 sec\n",
      "backward time 0.006405 sec\n",
      "optimizer time 0.017095 sec\n",
      "training time in round 322 cost 0.36841678619384766 sec\n",
      "loss 2.341811, train acc 0.097209\n",
      "round 323\n",
      "time to device 0.010609 sec\n",
      "time forward 3.511065 sec\n",
      "loss time 0.000677 sec\n",
      "backward time 0.006388 sec\n",
      "optimizer time 0.015928 sec\n",
      "training time in round 323 cost 0.37639808654785156 sec\n",
      "loss 2.342001, train acc 0.097198\n",
      "round 324\n",
      "time to device 0.007960 sec\n",
      "time forward 3.523527 sec\n",
      "loss time 0.001877 sec\n",
      "backward time 0.009696 sec\n",
      "optimizer time 0.046963 sec\n",
      "training time in round 324 cost 0.4215972423553467 sec\n",
      "loss 2.342318, train acc 0.097139\n",
      "round 325\n",
      "time to device 0.007226 sec\n",
      "time forward 3.532021 sec\n",
      "loss time 0.000968 sec\n",
      "backward time 0.006742 sec\n",
      "optimizer time 0.016662 sec\n",
      "training time in round 325 cost 0.37743067741394043 sec\n",
      "loss 2.342703, train acc 0.097081\n",
      "round 326\n",
      "time to device 0.008289 sec\n",
      "time forward 3.544055 sec\n",
      "loss time 0.000955 sec\n",
      "backward time 0.010451 sec\n",
      "optimizer time 0.016015 sec\n",
      "training time in round 326 cost 0.38947272300720215 sec\n",
      "loss 2.342579, train acc 0.097071\n",
      "round 327\n",
      "time to device 0.007475 sec\n",
      "time forward 3.552326 sec\n",
      "loss time 0.000967 sec\n",
      "backward time 0.009055 sec\n",
      "optimizer time 0.013646 sec\n",
      "training time in round 327 cost 0.39560389518737793 sec\n",
      "loss 2.342457, train acc 0.097037\n",
      "round 328\n",
      "time to device 0.005946 sec\n",
      "time forward 3.563582 sec\n",
      "loss time 0.000896 sec\n",
      "backward time 0.010471 sec\n",
      "optimizer time 0.017976 sec\n",
      "training time in round 328 cost 0.42519211769104004 sec\n",
      "loss 2.342350, train acc 0.096979\n",
      "round 329\n",
      "time to device 0.003719 sec\n",
      "time forward 3.575570 sec\n",
      "loss time 0.001182 sec\n",
      "backward time 0.011687 sec\n",
      "optimizer time 0.016254 sec\n",
      "training time in round 329 cost 0.43219470977783203 sec\n",
      "loss 2.342242, train acc 0.096875\n",
      "round 330\n",
      "time to device 0.006830 sec\n",
      "time forward 3.582774 sec\n",
      "loss time 0.001387 sec\n",
      "backward time 0.005270 sec\n",
      "optimizer time 0.014712 sec\n",
      "training time in round 330 cost 0.4351232051849365 sec\n",
      "loss 2.342171, train acc 0.096960\n",
      "round 331\n",
      "time to device 0.007161 sec\n",
      "time forward 3.590744 sec\n",
      "loss time 0.000798 sec\n",
      "backward time 0.006662 sec\n",
      "optimizer time 0.018008 sec\n",
      "training time in round 331 cost 0.36839795112609863 sec\n",
      "loss 2.342061, train acc 0.096762\n",
      "round 332\n",
      "time to device 0.007803 sec\n",
      "time forward 3.598082 sec\n",
      "loss time 0.000678 sec\n",
      "backward time 0.008275 sec\n",
      "optimizer time 0.015155 sec\n",
      "training time in round 332 cost 0.36536312103271484 sec\n",
      "loss 2.342133, train acc 0.096823\n",
      "round 333\n",
      "time to device 0.007120 sec\n",
      "time forward 3.606754 sec\n",
      "loss time 0.000781 sec\n",
      "backward time 0.006570 sec\n",
      "optimizer time 0.018497 sec\n",
      "training time in round 333 cost 0.3859529495239258 sec\n",
      "loss 2.342093, train acc 0.096814\n",
      "round 334\n",
      "time to device 0.007775 sec\n",
      "time forward 3.619903 sec\n",
      "loss time 0.001273 sec\n",
      "backward time 0.020479 sec\n",
      "optimizer time 0.019623 sec\n",
      "training time in round 334 cost 0.41433191299438477 sec\n",
      "loss 2.341946, train acc 0.096875\n",
      "round 335\n",
      "time to device 0.011534 sec\n",
      "time forward 3.628545 sec\n",
      "loss time 0.000794 sec\n",
      "backward time 0.007022 sec\n",
      "optimizer time 0.017443 sec\n",
      "training time in round 335 cost 0.36828112602233887 sec\n",
      "loss 2.341878, train acc 0.096959\n",
      "round 336\n",
      "time to device 0.005114 sec\n",
      "time forward 3.636366 sec\n",
      "loss time 0.001291 sec\n",
      "backward time 0.009898 sec\n",
      "optimizer time 0.019769 sec\n",
      "training time in round 336 cost 0.371488094329834 sec\n",
      "loss 2.341779, train acc 0.096810\n",
      "round 337\n",
      "time to device 0.007011 sec\n",
      "time forward 3.647128 sec\n",
      "loss time 0.001196 sec\n",
      "backward time 0.009688 sec\n",
      "optimizer time 0.021251 sec\n",
      "training time in round 337 cost 0.3747220039367676 sec\n",
      "loss 2.341672, train acc 0.096870\n",
      "round 338\n",
      "time to device 0.007485 sec\n",
      "time forward 3.660961 sec\n",
      "loss time 0.001115 sec\n",
      "backward time 0.008674 sec\n",
      "optimizer time 0.021414 sec\n",
      "training time in round 338 cost 0.37996697425842285 sec\n",
      "loss 2.341861, train acc 0.096953\n",
      "round 339\n",
      "time to device 0.008632 sec\n",
      "time forward 3.666304 sec\n",
      "loss time 0.000431 sec\n",
      "backward time 0.003911 sec\n",
      "optimizer time 0.011626 sec\n",
      "training time in round 339 cost 0.3432309627532959 sec\n",
      "loss 2.341761, train acc 0.096944\n",
      "round 340\n",
      "time to device 0.006979 sec\n",
      "time forward 3.676740 sec\n",
      "loss time 0.001195 sec\n",
      "backward time 0.008758 sec\n",
      "optimizer time 0.020582 sec\n",
      "training time in round 340 cost 0.3691749572753906 sec\n",
      "loss 2.341695, train acc 0.096866\n",
      "round 341\n",
      "time to device 0.006864 sec\n",
      "time forward 3.685230 sec\n",
      "loss time 0.000722 sec\n",
      "backward time 0.008244 sec\n",
      "optimizer time 0.020015 sec\n",
      "training time in round 341 cost 0.3716542720794678 sec\n",
      "loss 2.341640, train acc 0.096834\n",
      "round 342\n",
      "time to device 0.007451 sec\n",
      "time forward 3.691270 sec\n",
      "loss time 0.000658 sec\n",
      "backward time 0.006927 sec\n",
      "optimizer time 0.017468 sec\n",
      "training time in round 342 cost 0.41080808639526367 sec\n",
      "loss 2.341522, train acc 0.096870\n",
      "round 343\n",
      "time to device 0.006869 sec\n",
      "time forward 3.701586 sec\n",
      "loss time 0.001171 sec\n",
      "backward time 0.009263 sec\n",
      "optimizer time 0.021062 sec\n",
      "training time in round 343 cost 0.3970339298248291 sec\n",
      "loss 2.341407, train acc 0.096952\n",
      "round 344\n",
      "time to device 0.006862 sec\n",
      "time forward 3.707205 sec\n",
      "loss time 0.000648 sec\n",
      "backward time 0.005652 sec\n",
      "optimizer time 0.015546 sec\n",
      "training time in round 344 cost 0.362346887588501 sec\n",
      "loss 2.341287, train acc 0.097034\n",
      "round 345\n",
      "time to device 0.006363 sec\n",
      "time forward 3.719050 sec\n",
      "loss time 0.001074 sec\n",
      "backward time 0.008434 sec\n",
      "optimizer time 0.020254 sec\n",
      "training time in round 345 cost 0.36940598487854004 sec\n",
      "loss 2.341175, train acc 0.097069\n",
      "round 346\n",
      "time to device 0.007152 sec\n",
      "time forward 3.728431 sec\n",
      "loss time 0.001223 sec\n",
      "backward time 0.008566 sec\n",
      "optimizer time 0.020174 sec\n",
      "training time in round 346 cost 0.38226938247680664 sec\n",
      "loss 2.341074, train acc 0.097082\n",
      "round 347\n",
      "time to device 0.006512 sec\n",
      "time forward 3.735080 sec\n",
      "loss time 0.000533 sec\n",
      "backward time 0.004664 sec\n",
      "optimizer time 0.013466 sec\n",
      "training time in round 347 cost 0.34262967109680176 sec\n",
      "loss 2.340969, train acc 0.097095\n",
      "round 348\n",
      "time to device 0.006220 sec\n",
      "time forward 3.743487 sec\n",
      "loss time 0.000890 sec\n",
      "backward time 0.008519 sec\n",
      "optimizer time 0.020131 sec\n",
      "training time in round 348 cost 0.38242316246032715 sec\n",
      "loss 2.340870, train acc 0.097130\n",
      "round 349\n",
      "time to device 0.006815 sec\n",
      "time forward 3.755365 sec\n",
      "loss time 0.000863 sec\n",
      "backward time 0.008260 sec\n",
      "optimizer time 0.020595 sec\n",
      "training time in round 349 cost 0.3703749179840088 sec\n",
      "loss 2.340791, train acc 0.097098\n",
      "round 350\n",
      "time to device 0.007035 sec\n",
      "time forward 3.764669 sec\n",
      "loss time 0.000866 sec\n",
      "backward time 0.008288 sec\n",
      "optimizer time 0.019409 sec\n",
      "training time in round 350 cost 0.3604469299316406 sec\n",
      "loss 2.341065, train acc 0.097178\n",
      "round 351\n",
      "time to device 0.007465 sec\n",
      "time forward 3.771332 sec\n",
      "loss time 0.000626 sec\n",
      "backward time 0.006199 sec\n",
      "optimizer time 0.017122 sec\n",
      "training time in round 351 cost 0.3447549343109131 sec\n",
      "loss 2.340976, train acc 0.097124\n",
      "round 352\n",
      "time to device 0.006746 sec\n",
      "time forward 3.781240 sec\n",
      "loss time 0.001098 sec\n",
      "backward time 0.008375 sec\n",
      "optimizer time 0.020398 sec\n",
      "training time in round 352 cost 0.36892223358154297 sec\n",
      "loss 2.340870, train acc 0.097070\n",
      "round 353\n",
      "time to device 0.006959 sec\n",
      "time forward 3.787783 sec\n",
      "loss time 0.000644 sec\n",
      "backward time 0.005498 sec\n",
      "optimizer time 0.015195 sec\n",
      "training time in round 353 cost 0.34470081329345703 sec\n",
      "loss 2.340770, train acc 0.096972\n",
      "round 354\n",
      "time to device 0.006937 sec\n",
      "time forward 3.798099 sec\n",
      "loss time 0.001158 sec\n",
      "backward time 0.008887 sec\n",
      "optimizer time 0.020858 sec\n",
      "training time in round 354 cost 0.36728978157043457 sec\n",
      "loss 2.340667, train acc 0.097007\n",
      "round 355\n",
      "time to device 0.006457 sec\n",
      "time forward 3.806191 sec\n",
      "loss time 0.001301 sec\n",
      "backward time 0.008551 sec\n",
      "optimizer time 0.020392 sec\n",
      "training time in round 355 cost 0.36643099784851074 sec\n",
      "loss 2.340561, train acc 0.096932\n",
      "round 356\n",
      "time to device 0.005966 sec\n",
      "time forward 3.815784 sec\n",
      "loss time 0.001120 sec\n",
      "backward time 0.008937 sec\n",
      "optimizer time 0.020432 sec\n",
      "training time in round 356 cost 0.36548304557800293 sec\n",
      "loss 2.340458, train acc 0.096967\n",
      "round 357\n",
      "time to device 0.006656 sec\n",
      "time forward 3.825481 sec\n",
      "loss time 0.001098 sec\n",
      "backward time 0.008601 sec\n",
      "optimizer time 0.020069 sec\n",
      "training time in round 357 cost 0.3633890151977539 sec\n",
      "loss 2.340352, train acc 0.097067\n",
      "round 358\n",
      "time to device 0.008063 sec\n",
      "time forward 3.834914 sec\n",
      "loss time 0.000505 sec\n",
      "backward time 0.004303 sec\n",
      "optimizer time 0.017262 sec\n",
      "training time in round 358 cost 0.38121509552001953 sec\n",
      "loss 2.340252, train acc 0.097080\n",
      "round 359\n",
      "time to device 0.006231 sec\n",
      "time forward 3.844634 sec\n",
      "loss time 0.001114 sec\n",
      "backward time 0.008607 sec\n",
      "optimizer time 0.020428 sec\n",
      "training time in round 359 cost 0.36487507820129395 sec\n",
      "loss 2.340147, train acc 0.097201\n",
      "round 360\n",
      "time to device 0.006981 sec\n",
      "time forward 3.851129 sec\n",
      "loss time 0.000641 sec\n",
      "backward time 0.005909 sec\n",
      "optimizer time 0.015223 sec\n",
      "training time in round 360 cost 0.3444521427154541 sec\n",
      "loss 2.340049, train acc 0.097191\n",
      "round 361\n",
      "time to device 0.005965 sec\n",
      "time forward 3.860985 sec\n",
      "loss time 0.001124 sec\n",
      "backward time 0.004533 sec\n",
      "optimizer time 0.018182 sec\n",
      "training time in round 361 cost 0.36150074005126953 sec\n",
      "loss 2.339935, train acc 0.097289\n",
      "round 362\n",
      "time to device 0.006578 sec\n",
      "time forward 3.868140 sec\n",
      "loss time 0.000639 sec\n",
      "backward time 0.006123 sec\n",
      "optimizer time 0.016321 sec\n",
      "training time in round 362 cost 0.34949707984924316 sec\n",
      "loss 2.339829, train acc 0.097409\n",
      "round 363\n",
      "time to device 0.007124 sec\n",
      "time forward 3.878090 sec\n",
      "loss time 0.001236 sec\n",
      "backward time 0.009067 sec\n",
      "optimizer time 0.020501 sec\n",
      "training time in round 363 cost 0.36934518814086914 sec\n",
      "loss 2.339721, train acc 0.097442\n",
      "round 364\n",
      "time to device 0.003089 sec\n",
      "time forward 3.887196 sec\n",
      "loss time 0.001081 sec\n",
      "backward time 0.008501 sec\n",
      "optimizer time 0.020096 sec\n",
      "training time in round 364 cost 0.37209200859069824 sec\n",
      "loss 2.339623, train acc 0.097410\n",
      "round 365\n",
      "time to device 0.004356 sec\n",
      "time forward 3.897417 sec\n",
      "loss time 0.001219 sec\n",
      "backward time 0.009484 sec\n",
      "optimizer time 0.021090 sec\n",
      "training time in round 365 cost 0.3654348850250244 sec\n",
      "loss 2.339517, train acc 0.097400\n",
      "round 366\n",
      "time to device 0.003665 sec\n",
      "time forward 3.903862 sec\n",
      "loss time 0.000494 sec\n",
      "backward time 0.004578 sec\n",
      "optimizer time 0.012692 sec\n",
      "training time in round 366 cost 0.34477734565734863 sec\n",
      "loss 2.339436, train acc 0.097262\n",
      "round 367\n",
      "time to device 0.003637 sec\n",
      "time forward 3.913072 sec\n",
      "loss time 0.001177 sec\n",
      "backward time 0.009122 sec\n",
      "optimizer time 0.020898 sec\n",
      "training time in round 367 cost 0.37678003311157227 sec\n",
      "loss 2.339312, train acc 0.097295\n",
      "round 368\n",
      "time to device 0.003165 sec\n",
      "time forward 3.924379 sec\n",
      "loss time 0.001311 sec\n",
      "backward time 0.009543 sec\n",
      "optimizer time 0.020691 sec\n",
      "training time in round 368 cost 0.37236785888671875 sec\n",
      "loss 2.339234, train acc 0.097159\n",
      "round 369\n",
      "time to device 0.003814 sec\n",
      "time forward 3.930952 sec\n",
      "loss time 0.000661 sec\n",
      "backward time 0.005932 sec\n",
      "optimizer time 0.015576 sec\n",
      "training time in round 369 cost 0.34476399421691895 sec\n",
      "loss 2.339167, train acc 0.097107\n",
      "round 370\n",
      "time to device 0.003291 sec\n",
      "time forward 3.940939 sec\n",
      "loss time 0.001272 sec\n",
      "backward time 0.010493 sec\n",
      "optimizer time 0.020955 sec\n",
      "training time in round 370 cost 0.3683300018310547 sec\n",
      "loss 2.339074, train acc 0.097077\n",
      "round 371\n",
      "time to device 0.003474 sec\n",
      "time forward 3.947211 sec\n",
      "loss time 0.000643 sec\n",
      "backward time 0.005946 sec\n",
      "optimizer time 0.016127 sec\n",
      "training time in round 371 cost 0.34339189529418945 sec\n",
      "loss 2.338972, train acc 0.096963\n",
      "round 372\n",
      "time to device 0.003122 sec\n",
      "time forward 3.956182 sec\n",
      "loss time 0.001069 sec\n",
      "backward time 0.012929 sec\n",
      "optimizer time 0.019235 sec\n",
      "training time in round 372 cost 0.3586459159851074 sec\n",
      "loss 2.338874, train acc 0.096955\n",
      "round 373\n",
      "time to device 0.003792 sec\n",
      "time forward 3.966959 sec\n",
      "loss time 0.001409 sec\n",
      "backward time 0.008599 sec\n",
      "optimizer time 0.020225 sec\n",
      "training time in round 373 cost 0.37041211128234863 sec\n",
      "loss 2.338780, train acc 0.096883\n",
      "round 374\n",
      "time to device 0.003651 sec\n",
      "time forward 3.977549 sec\n",
      "loss time 0.001129 sec\n",
      "backward time 0.008692 sec\n",
      "optimizer time 0.019918 sec\n",
      "training time in round 374 cost 0.3786013126373291 sec\n",
      "loss 2.338670, train acc 0.096979\n",
      "round 375\n",
      "time to device 0.004038 sec\n",
      "time forward 3.987367 sec\n",
      "loss time 0.000866 sec\n",
      "backward time 0.008091 sec\n",
      "optimizer time 0.019206 sec\n",
      "training time in round 375 cost 0.36331605911254883 sec\n",
      "loss 2.338571, train acc 0.096908\n",
      "round 376\n",
      "time to device 0.003459 sec\n",
      "time forward 3.998646 sec\n",
      "loss time 0.001055 sec\n",
      "backward time 0.008836 sec\n",
      "optimizer time 0.020426 sec\n",
      "training time in round 376 cost 0.3728938102722168 sec\n",
      "loss 2.338481, train acc 0.096921\n",
      "round 377\n",
      "time to device 0.003400 sec\n",
      "time forward 4.009107 sec\n",
      "loss time 0.001182 sec\n",
      "backward time 0.008904 sec\n",
      "optimizer time 0.020131 sec\n",
      "training time in round 377 cost 0.3732430934906006 sec\n",
      "loss 2.338387, train acc 0.096871\n",
      "round 378\n",
      "time to device 0.003338 sec\n",
      "time forward 4.015988 sec\n",
      "loss time 0.000638 sec\n",
      "backward time 0.005974 sec\n",
      "optimizer time 0.015879 sec\n",
      "training time in round 378 cost 0.3474400043487549 sec\n",
      "loss 2.338454, train acc 0.096966\n",
      "round 379\n",
      "time to device 0.004970 sec\n",
      "time forward 4.027107 sec\n",
      "loss time 0.001125 sec\n",
      "backward time 0.008693 sec\n",
      "optimizer time 0.020004 sec\n",
      "training time in round 379 cost 0.37247300148010254 sec\n",
      "loss 2.338372, train acc 0.097060\n",
      "round 380\n",
      "time to device 0.003551 sec\n",
      "time forward 4.034089 sec\n",
      "loss time 0.000714 sec\n",
      "backward time 0.006041 sec\n",
      "optimizer time 0.016479 sec\n",
      "training time in round 380 cost 0.3486361503601074 sec\n",
      "loss 2.338272, train acc 0.097010\n",
      "round 381\n",
      "time to device 0.003200 sec\n",
      "time forward 4.045018 sec\n",
      "loss time 0.001125 sec\n",
      "backward time 0.008741 sec\n",
      "optimizer time 0.020201 sec\n",
      "training time in round 381 cost 0.37084484100341797 sec\n",
      "loss 2.338173, train acc 0.097125\n",
      "round 382\n",
      "time to device 0.003520 sec\n",
      "time forward 4.056254 sec\n",
      "loss time 0.001315 sec\n",
      "backward time 0.009732 sec\n",
      "optimizer time 0.020544 sec\n",
      "training time in round 382 cost 0.37338709831237793 sec\n",
      "loss 2.338076, train acc 0.097116\n",
      "round 383\n",
      "time to device 0.004000 sec\n",
      "time forward 4.066687 sec\n",
      "loss time 0.001186 sec\n",
      "backward time 0.009715 sec\n",
      "optimizer time 0.020471 sec\n",
      "training time in round 383 cost 0.36947011947631836 sec\n",
      "loss 2.337941, train acc 0.097127\n",
      "round 384\n",
      "time to device 0.004412 sec\n",
      "time forward 4.078073 sec\n",
      "loss time 0.001250 sec\n",
      "backward time 0.008798 sec\n",
      "optimizer time 0.020296 sec\n",
      "training time in round 384 cost 0.3769550323486328 sec\n",
      "loss 2.338194, train acc 0.097179\n",
      "round 385\n",
      "time to device 0.002345 sec\n",
      "time forward 4.086120 sec\n",
      "loss time 0.000731 sec\n",
      "backward time 0.020684 sec\n",
      "optimizer time 0.016627 sec\n",
      "training time in round 385 cost 0.40265774726867676 sec\n",
      "loss 2.338165, train acc 0.097251\n",
      "round 386\n",
      "time to device 0.007301 sec\n",
      "time forward 4.102545 sec\n",
      "loss time 0.001528 sec\n",
      "backward time 0.010802 sec\n",
      "optimizer time 0.034278 sec\n",
      "training time in round 386 cost 0.5421769618988037 sec\n",
      "loss 2.338081, train acc 0.097222\n",
      "round 387\n",
      "time to device 0.008729 sec\n",
      "time forward 4.112463 sec\n",
      "loss time 0.001059 sec\n",
      "backward time 0.006331 sec\n",
      "optimizer time 0.016753 sec\n",
      "training time in round 387 cost 0.44249606132507324 sec\n",
      "loss 2.337988, train acc 0.097092\n",
      "round 388\n",
      "time to device 0.006220 sec\n",
      "time forward 4.125477 sec\n",
      "loss time 0.001218 sec\n",
      "backward time 0.013586 sec\n",
      "optimizer time 0.026799 sec\n",
      "training time in round 388 cost 0.4220740795135498 sec\n",
      "loss 2.337903, train acc 0.097044\n",
      "round 389\n",
      "time to device 0.009310 sec\n",
      "time forward 4.134735 sec\n",
      "loss time 0.000418 sec\n",
      "backward time 0.004990 sec\n",
      "optimizer time 0.015094 sec\n",
      "training time in round 389 cost 0.38821887969970703 sec\n",
      "loss 2.337926, train acc 0.097035\n",
      "round 390\n",
      "time to device 0.007525 sec\n",
      "time forward 4.145742 sec\n",
      "loss time 0.001022 sec\n",
      "backward time 0.011487 sec\n",
      "optimizer time 0.020459 sec\n",
      "training time in round 390 cost 0.40842199325561523 sec\n",
      "loss 2.337834, train acc 0.097007\n",
      "round 391\n",
      "time to device 0.007534 sec\n",
      "time forward 4.157743 sec\n",
      "loss time 0.000906 sec\n",
      "backward time 0.011140 sec\n",
      "optimizer time 0.022978 sec\n",
      "training time in round 391 cost 0.4598820209503174 sec\n",
      "loss 2.337746, train acc 0.096919\n",
      "round 392\n",
      "time to device 0.007788 sec\n",
      "time forward 4.170816 sec\n",
      "loss time 0.001200 sec\n",
      "backward time 0.012016 sec\n",
      "optimizer time 0.026003 sec\n",
      "training time in round 392 cost 0.4480879306793213 sec\n",
      "loss 2.337676, train acc 0.096811\n",
      "round 393\n",
      "time to device 0.007021 sec\n",
      "time forward 4.180725 sec\n",
      "loss time 0.001108 sec\n",
      "backward time 0.011564 sec\n",
      "optimizer time 0.025579 sec\n",
      "training time in round 393 cost 0.424375057220459 sec\n",
      "loss 2.337588, train acc 0.096804\n",
      "round 394\n",
      "time to device 0.006685 sec\n",
      "time forward 4.193833 sec\n",
      "loss time 0.000900 sec\n",
      "backward time 0.007636 sec\n",
      "optimizer time 0.017543 sec\n",
      "training time in round 394 cost 0.38988208770751953 sec\n",
      "loss 2.337537, train acc 0.096796\n",
      "round 395\n",
      "time to device 0.006978 sec\n",
      "time forward 4.204658 sec\n",
      "loss time 0.001013 sec\n",
      "backward time 0.011757 sec\n",
      "optimizer time 0.026143 sec\n",
      "training time in round 395 cost 0.39278316497802734 sec\n",
      "loss 2.337442, train acc 0.096828\n",
      "round 396\n",
      "time to device 0.006890 sec\n",
      "time forward 4.215650 sec\n",
      "loss time 0.001513 sec\n",
      "backward time 0.011426 sec\n",
      "optimizer time 0.023739 sec\n",
      "training time in round 396 cost 0.4042799472808838 sec\n",
      "loss 2.337387, train acc 0.096800\n",
      "round 397\n",
      "time to device 0.006257 sec\n",
      "time forward 4.230043 sec\n",
      "loss time 0.002417 sec\n",
      "backward time 0.013333 sec\n",
      "optimizer time 0.024224 sec\n",
      "training time in round 397 cost 0.40696215629577637 sec\n",
      "loss 2.337319, train acc 0.096891\n",
      "round 398\n",
      "time to device 0.007269 sec\n",
      "time forward 4.240368 sec\n",
      "loss time 0.001353 sec\n",
      "backward time 0.011732 sec\n",
      "optimizer time 0.024521 sec\n",
      "training time in round 398 cost 0.4266650676727295 sec\n",
      "loss 2.337439, train acc 0.096883\n",
      "round 399\n",
      "time to device 0.006737 sec\n",
      "time forward 4.251589 sec\n",
      "loss time 0.001259 sec\n",
      "backward time 0.014440 sec\n",
      "optimizer time 0.041180 sec\n",
      "training time in round 399 cost 0.4234499931335449 sec\n",
      "loss 2.337363, train acc 0.096875\n",
      "round 400\n",
      "time to device 0.006807 sec\n",
      "time forward 4.262494 sec\n",
      "loss time 0.001240 sec\n",
      "backward time 0.010527 sec\n",
      "optimizer time 0.032057 sec\n",
      "training time in round 400 cost 0.4322080612182617 sec\n",
      "loss 2.337271, train acc 0.096867\n",
      "round 401\n",
      "time to device 0.009000 sec\n",
      "time forward 4.278105 sec\n",
      "loss time 0.001130 sec\n",
      "backward time 0.013863 sec\n",
      "optimizer time 0.033961 sec\n",
      "training time in round 401 cost 0.42657017707824707 sec\n",
      "loss 2.337157, train acc 0.096918\n",
      "round 402\n",
      "time to device 0.008072 sec\n",
      "time forward 4.286873 sec\n",
      "loss time 0.000802 sec\n",
      "backward time 0.007387 sec\n",
      "optimizer time 0.017197 sec\n",
      "training time in round 402 cost 0.3735239505767822 sec\n",
      "loss 2.337076, train acc 0.096813\n",
      "round 403\n",
      "time to device 0.006971 sec\n",
      "time forward 4.298592 sec\n",
      "loss time 0.001146 sec\n",
      "backward time 0.014559 sec\n",
      "optimizer time 0.024453 sec\n",
      "training time in round 403 cost 0.43533802032470703 sec\n",
      "loss 2.337062, train acc 0.096709\n",
      "round 404\n",
      "time to device 0.007904 sec\n",
      "time forward 4.306340 sec\n",
      "loss time 0.000454 sec\n",
      "backward time 0.004065 sec\n",
      "optimizer time 0.013692 sec\n",
      "training time in round 404 cost 0.38254618644714355 sec\n",
      "loss 2.337197, train acc 0.096721\n",
      "round 405\n",
      "time to device 0.007393 sec\n",
      "time forward 4.319906 sec\n",
      "loss time 0.001263 sec\n",
      "backward time 0.017561 sec\n",
      "optimizer time 0.015530 sec\n",
      "training time in round 405 cost 0.40534114837646484 sec\n",
      "loss 2.337303, train acc 0.096733\n",
      "round 406\n",
      "time to device 0.006725 sec\n",
      "time forward 4.333155 sec\n",
      "loss time 0.001023 sec\n",
      "backward time 0.012348 sec\n",
      "optimizer time 0.036455 sec\n",
      "training time in round 406 cost 0.46337389945983887 sec\n",
      "loss 2.337219, train acc 0.096648\n",
      "round 407\n",
      "time to device 0.007455 sec\n",
      "time forward 4.346422 sec\n",
      "loss time 0.001838 sec\n",
      "backward time 0.014150 sec\n",
      "optimizer time 0.018004 sec\n",
      "training time in round 407 cost 0.4319479465484619 sec\n",
      "loss 2.337156, train acc 0.096680\n",
      "round 408\n",
      "time to device 0.012440 sec\n",
      "time forward 4.363046 sec\n",
      "loss time 0.002579 sec\n",
      "backward time 0.012905 sec\n",
      "optimizer time 0.027932 sec\n",
      "training time in round 408 cost 0.4312608242034912 sec\n",
      "loss 2.337132, train acc 0.096577\n",
      "round 409\n",
      "time to device 0.007238 sec\n",
      "time forward 4.369224 sec\n",
      "loss time 0.000667 sec\n",
      "backward time 0.006178 sec\n",
      "optimizer time 0.016599 sec\n",
      "training time in round 409 cost 0.36899590492248535 sec\n",
      "loss 2.337049, train acc 0.096627\n",
      "round 410\n",
      "time to device 0.007316 sec\n",
      "time forward 4.379126 sec\n",
      "loss time 0.001198 sec\n",
      "backward time 0.010566 sec\n",
      "optimizer time 0.017962 sec\n",
      "training time in round 410 cost 0.3987603187561035 sec\n",
      "loss 2.336946, train acc 0.096734\n",
      "round 411\n",
      "time to device 0.007253 sec\n",
      "time forward 4.387342 sec\n",
      "loss time 0.000745 sec\n",
      "backward time 0.006701 sec\n",
      "optimizer time 0.017438 sec\n",
      "training time in round 411 cost 0.36924099922180176 sec\n",
      "loss 2.336858, train acc 0.096727\n",
      "round 412\n",
      "time to device 0.014680 sec\n",
      "time forward 4.414310 sec\n",
      "loss time 0.003434 sec\n",
      "backward time 0.018934 sec\n",
      "optimizer time 0.060467 sec\n",
      "training time in round 412 cost 0.5826919078826904 sec\n",
      "loss 2.336832, train acc 0.096625\n",
      "round 413\n",
      "time to device 0.007310 sec\n",
      "time forward 4.431978 sec\n",
      "loss time 0.001298 sec\n",
      "backward time 0.018181 sec\n",
      "optimizer time 0.020785 sec\n",
      "training time in round 413 cost 0.6131689548492432 sec\n",
      "loss 2.336740, train acc 0.096713\n",
      "round 414\n",
      "time to device 0.013497 sec\n",
      "time forward 4.447276 sec\n",
      "loss time 0.001293 sec\n",
      "backward time 0.010859 sec\n",
      "optimizer time 0.031305 sec\n",
      "training time in round 414 cost 0.5323851108551025 sec\n",
      "loss 2.336666, train acc 0.096649\n",
      "round 415\n",
      "time to device 0.007376 sec\n",
      "time forward 4.458608 sec\n",
      "loss time 0.001929 sec\n",
      "backward time 0.014056 sec\n",
      "optimizer time 0.024194 sec\n",
      "training time in round 415 cost 0.41829800605773926 sec\n",
      "loss 2.337019, train acc 0.096605\n",
      "round 416\n",
      "time to device 0.006595 sec\n",
      "time forward 4.471258 sec\n",
      "loss time 0.000912 sec\n",
      "backward time 0.015379 sec\n",
      "optimizer time 0.015563 sec\n",
      "training time in round 416 cost 0.40584301948547363 sec\n",
      "loss 2.337556, train acc 0.096710\n",
      "round 417\n",
      "time to device 0.009941 sec\n",
      "time forward 4.477155 sec\n",
      "loss time 0.000417 sec\n",
      "backward time 0.004012 sec\n",
      "optimizer time 0.017392 sec\n",
      "training time in round 417 cost 0.3957970142364502 sec\n",
      "loss 2.337856, train acc 0.096684\n",
      "round 418\n",
      "time to device 0.008628 sec\n",
      "time forward 4.489712 sec\n",
      "loss time 0.001030 sec\n",
      "backward time 0.014651 sec\n",
      "optimizer time 0.017182 sec\n",
      "training time in round 418 cost 0.4161982536315918 sec\n",
      "loss 2.337774, train acc 0.096715\n",
      "round 419\n",
      "time to device 0.007215 sec\n",
      "time forward 4.500479 sec\n",
      "loss time 0.000984 sec\n",
      "backward time 0.013062 sec\n",
      "optimizer time 0.020625 sec\n",
      "training time in round 419 cost 0.4364469051361084 sec\n",
      "loss 2.337860, train acc 0.096782\n",
      "round 420\n",
      "time to device 0.006651 sec\n",
      "time forward 4.512744 sec\n",
      "loss time 0.001552 sec\n",
      "backward time 0.011228 sec\n",
      "optimizer time 0.024773 sec\n",
      "training time in round 420 cost 0.41614723205566406 sec\n",
      "loss 2.337784, train acc 0.096738\n",
      "round 421\n",
      "time to device 0.006930 sec\n",
      "time forward 4.527872 sec\n",
      "loss time 0.001191 sec\n",
      "backward time 0.012512 sec\n",
      "optimizer time 0.021255 sec\n",
      "training time in round 421 cost 0.40840983390808105 sec\n",
      "loss 2.337728, train acc 0.096712\n",
      "round 422\n",
      "time to device 0.007682 sec\n",
      "time forward 4.538520 sec\n",
      "loss time 0.001049 sec\n",
      "backward time 0.011015 sec\n",
      "optimizer time 0.021611 sec\n",
      "training time in round 422 cost 0.3857567310333252 sec\n",
      "loss 2.337640, train acc 0.096724\n",
      "round 423\n",
      "time to device 0.008218 sec\n",
      "time forward 4.549002 sec\n",
      "loss time 0.001223 sec\n",
      "backward time 0.011163 sec\n",
      "optimizer time 0.022600 sec\n",
      "training time in round 423 cost 0.3871428966522217 sec\n",
      "loss 2.337547, train acc 0.096827\n",
      "round 424\n",
      "time to device 0.007967 sec\n",
      "time forward 4.562245 sec\n",
      "loss time 0.001478 sec\n",
      "backward time 0.014155 sec\n",
      "optimizer time 0.018968 sec\n",
      "training time in round 424 cost 0.4380009174346924 sec\n",
      "loss 2.337739, train acc 0.096838\n",
      "round 425\n",
      "time to device 0.007334 sec\n",
      "time forward 4.575882 sec\n",
      "loss time 0.001033 sec\n",
      "backward time 0.011119 sec\n",
      "optimizer time 0.021713 sec\n",
      "training time in round 425 cost 0.4013099670410156 sec\n",
      "loss 2.337648, train acc 0.096904\n",
      "round 426\n",
      "time to device 0.007814 sec\n",
      "time forward 4.585866 sec\n",
      "loss time 0.001106 sec\n",
      "backward time 0.010921 sec\n",
      "optimizer time 0.021348 sec\n",
      "training time in round 426 cost 0.38748598098754883 sec\n",
      "loss 2.337575, train acc 0.096915\n",
      "round 427\n",
      "time to device 0.008309 sec\n",
      "time forward 4.596865 sec\n",
      "loss time 0.001099 sec\n",
      "backward time 0.010836 sec\n",
      "optimizer time 0.018431 sec\n",
      "training time in round 427 cost 0.38683271408081055 sec\n",
      "loss 2.337504, train acc 0.096981\n",
      "round 428\n",
      "time to device 0.007164 sec\n",
      "time forward 4.607763 sec\n",
      "loss time 0.000967 sec\n",
      "backward time 0.009998 sec\n",
      "optimizer time 0.024985 sec\n",
      "training time in round 428 cost 0.4008510112762451 sec\n",
      "loss 2.337430, train acc 0.097046\n",
      "round 429\n",
      "time to device 0.004266 sec\n",
      "time forward 4.617996 sec\n",
      "loss time 0.001671 sec\n",
      "backward time 0.010636 sec\n",
      "optimizer time 0.023276 sec\n",
      "training time in round 429 cost 0.3930530548095703 sec\n",
      "loss 2.337351, train acc 0.097002\n",
      "round 430\n",
      "time to device 0.004035 sec\n",
      "time forward 4.631917 sec\n",
      "loss time 0.001092 sec\n",
      "backward time 0.012213 sec\n",
      "optimizer time 0.026290 sec\n",
      "training time in round 430 cost 0.4080538749694824 sec\n",
      "loss 2.337253, train acc 0.097230\n",
      "round 431\n",
      "time to device 0.004632 sec\n",
      "time forward 4.640049 sec\n",
      "loss time 0.000793 sec\n",
      "backward time 0.006047 sec\n",
      "optimizer time 0.017727 sec\n",
      "training time in round 431 cost 0.36983275413513184 sec\n",
      "loss 2.337180, train acc 0.097222\n",
      "round 432\n",
      "time to device 0.003519 sec\n",
      "time forward 4.651751 sec\n",
      "loss time 0.001053 sec\n",
      "backward time 0.012617 sec\n",
      "optimizer time 0.024259 sec\n",
      "training time in round 432 cost 0.38916897773742676 sec\n",
      "loss 2.337099, train acc 0.097286\n",
      "round 433\n",
      "time to device 0.003743 sec\n",
      "time forward 4.659428 sec\n",
      "loss time 0.000438 sec\n",
      "backward time 0.004505 sec\n",
      "optimizer time 0.011894 sec\n",
      "training time in round 433 cost 0.36018919944763184 sec\n",
      "loss 2.337026, train acc 0.097332\n",
      "round 434\n",
      "time to device 0.006109 sec\n",
      "time forward 4.671286 sec\n",
      "loss time 0.001448 sec\n",
      "backward time 0.012684 sec\n",
      "optimizer time 0.029853 sec\n",
      "training time in round 434 cost 0.4046022891998291 sec\n",
      "loss 2.336949, train acc 0.097342\n",
      "round 435\n",
      "time to device 0.007599 sec\n",
      "time forward 4.682000 sec\n",
      "loss time 0.001025 sec\n",
      "backward time 0.017598 sec\n",
      "optimizer time 0.026640 sec\n",
      "training time in round 435 cost 0.4083418846130371 sec\n",
      "loss 2.336954, train acc 0.097423\n",
      "round 436\n",
      "time to device 0.006985 sec\n",
      "time forward 4.694102 sec\n",
      "loss time 0.001451 sec\n",
      "backward time 0.017026 sec\n",
      "optimizer time 0.020771 sec\n",
      "training time in round 436 cost 0.4165489673614502 sec\n",
      "loss 2.336869, train acc 0.097486\n",
      "round 437\n",
      "time to device 0.008565 sec\n",
      "time forward 4.702460 sec\n",
      "loss time 0.001082 sec\n",
      "backward time 0.009416 sec\n",
      "optimizer time 0.018743 sec\n",
      "training time in round 437 cost 0.40137696266174316 sec\n",
      "loss 2.337078, train acc 0.097478\n",
      "round 438\n",
      "time to device 0.007007 sec\n",
      "time forward 4.714298 sec\n",
      "loss time 0.001303 sec\n",
      "backward time 0.018906 sec\n",
      "optimizer time 0.024133 sec\n",
      "training time in round 438 cost 0.3991091251373291 sec\n",
      "loss 2.336998, train acc 0.097452\n",
      "round 439\n",
      "time to device 0.008259 sec\n",
      "time forward 4.722718 sec\n",
      "loss time 0.000897 sec\n",
      "backward time 0.008472 sec\n",
      "optimizer time 0.018962 sec\n",
      "training time in round 439 cost 0.38909411430358887 sec\n",
      "loss 2.336912, train acc 0.097550\n",
      "round 440\n",
      "time to device 0.006703 sec\n",
      "time forward 4.732822 sec\n",
      "loss time 0.000741 sec\n",
      "backward time 0.007159 sec\n",
      "optimizer time 0.016932 sec\n",
      "training time in round 440 cost 0.37086009979248047 sec\n",
      "loss 2.336848, train acc 0.097506\n",
      "round 441\n",
      "time to device 0.006650 sec\n",
      "time forward 4.741129 sec\n",
      "loss time 0.000891 sec\n",
      "backward time 0.008423 sec\n",
      "optimizer time 0.018735 sec\n",
      "training time in round 441 cost 0.40137600898742676 sec\n",
      "loss 2.336830, train acc 0.097533\n",
      "round 442\n",
      "time to device 0.007423 sec\n",
      "time forward 4.752978 sec\n",
      "loss time 0.001125 sec\n",
      "backward time 0.011358 sec\n",
      "optimizer time 0.030334 sec\n",
      "training time in round 442 cost 0.39585399627685547 sec\n",
      "loss 2.336758, train acc 0.097577\n",
      "round 443\n",
      "time to device 0.006642 sec\n",
      "time forward 4.765213 sec\n",
      "loss time 0.001527 sec\n",
      "backward time 0.012074 sec\n",
      "optimizer time 0.029018 sec\n",
      "training time in round 443 cost 0.4077122211456299 sec\n",
      "loss 2.336685, train acc 0.097586\n",
      "round 444\n",
      "time to device 0.006703 sec\n",
      "time forward 4.778211 sec\n",
      "loss time 0.000966 sec\n",
      "backward time 0.010138 sec\n",
      "optimizer time 0.026702 sec\n",
      "training time in round 444 cost 0.393582820892334 sec\n",
      "loss 2.336614, train acc 0.097612\n",
      "round 445\n",
      "time to device 0.006711 sec\n",
      "time forward 4.793599 sec\n",
      "loss time 0.001150 sec\n",
      "backward time 0.012338 sec\n",
      "optimizer time 0.029432 sec\n",
      "training time in round 445 cost 0.4090878963470459 sec\n",
      "loss 2.336534, train acc 0.097604\n",
      "round 446\n",
      "time to device 0.006967 sec\n",
      "time forward 4.801449 sec\n",
      "loss time 0.000630 sec\n",
      "backward time 0.006283 sec\n",
      "optimizer time 0.014901 sec\n",
      "training time in round 446 cost 0.3621640205383301 sec\n",
      "loss 2.336486, train acc 0.097578\n",
      "round 447\n",
      "time to device 0.008353 sec\n",
      "time forward 4.811366 sec\n",
      "loss time 0.001411 sec\n",
      "backward time 0.012453 sec\n",
      "optimizer time 0.027509 sec\n",
      "training time in round 447 cost 0.4019479751586914 sec\n",
      "loss 2.336479, train acc 0.097517\n",
      "round 448\n",
      "time to device 0.007827 sec\n",
      "time forward 4.819138 sec\n",
      "loss time 0.000784 sec\n",
      "backward time 0.006695 sec\n",
      "optimizer time 0.017197 sec\n",
      "training time in round 448 cost 0.36512303352355957 sec\n",
      "loss 2.336406, train acc 0.097561\n",
      "round 449\n",
      "time to device 0.008879 sec\n",
      "time forward 4.830992 sec\n",
      "loss time 0.000911 sec\n",
      "backward time 0.007415 sec\n",
      "optimizer time 0.017758 sec\n",
      "training time in round 449 cost 0.38161587715148926 sec\n",
      "loss 2.336320, train acc 0.097656\n",
      "round 450\n",
      "time to device 0.007022 sec\n",
      "time forward 4.842221 sec\n",
      "loss time 0.001150 sec\n",
      "backward time 0.013923 sec\n",
      "optimizer time 0.023442 sec\n",
      "training time in round 450 cost 0.38787007331848145 sec\n",
      "loss 2.336329, train acc 0.097613\n",
      "round 451\n",
      "time to device 0.006354 sec\n",
      "time forward 4.850612 sec\n",
      "loss time 0.000885 sec\n",
      "backward time 0.006514 sec\n",
      "optimizer time 0.016046 sec\n",
      "training time in round 451 cost 0.36345386505126953 sec\n",
      "loss 2.336260, train acc 0.097570\n",
      "round 452\n",
      "time to device 0.007182 sec\n",
      "time forward 4.861715 sec\n",
      "loss time 0.001142 sec\n",
      "backward time 0.011407 sec\n",
      "optimizer time 0.025789 sec\n",
      "training time in round 452 cost 0.3977668285369873 sec\n",
      "loss 2.336180, train acc 0.097630\n",
      "round 453\n",
      "time to device 0.003118 sec\n",
      "time forward 4.868695 sec\n",
      "loss time 0.000540 sec\n",
      "backward time 0.004264 sec\n",
      "optimizer time 0.013399 sec\n",
      "training time in round 453 cost 0.35882091522216797 sec\n",
      "loss 2.336263, train acc 0.097673\n",
      "round 454\n",
      "time to device 0.003876 sec\n",
      "time forward 4.880610 sec\n",
      "loss time 0.001285 sec\n",
      "backward time 0.014099 sec\n",
      "optimizer time 0.025941 sec\n",
      "training time in round 454 cost 0.38883471488952637 sec\n",
      "loss 2.336194, train acc 0.097648\n",
      "round 455\n",
      "time to device 0.003493 sec\n",
      "time forward 4.888113 sec\n",
      "loss time 0.000721 sec\n",
      "backward time 0.006505 sec\n",
      "optimizer time 0.016192 sec\n",
      "training time in round 455 cost 0.35952210426330566 sec\n",
      "loss 2.336114, train acc 0.097725\n",
      "round 456\n",
      "time to device 0.003477 sec\n",
      "time forward 4.899884 sec\n",
      "loss time 0.001093 sec\n",
      "backward time 0.012087 sec\n",
      "optimizer time 0.043717 sec\n",
      "training time in round 456 cost 0.4521219730377197 sec\n",
      "loss 2.336042, train acc 0.097699\n",
      "round 457\n",
      "time to device 0.006660 sec\n",
      "time forward 4.910517 sec\n",
      "loss time 0.001421 sec\n",
      "backward time 0.012548 sec\n",
      "optimizer time 0.023536 sec\n",
      "training time in round 457 cost 0.40697193145751953 sec\n",
      "loss 2.335969, train acc 0.097724\n",
      "round 458\n",
      "time to device 0.007157 sec\n",
      "time forward 4.922538 sec\n",
      "loss time 0.001214 sec\n",
      "backward time 0.013398 sec\n",
      "optimizer time 0.026800 sec\n",
      "training time in round 458 cost 0.42392611503601074 sec\n",
      "loss 2.335889, train acc 0.097835\n",
      "round 459\n",
      "time to device 0.006496 sec\n",
      "time forward 4.930075 sec\n",
      "loss time 0.000717 sec\n",
      "backward time 0.006098 sec\n",
      "optimizer time 0.016973 sec\n",
      "training time in round 459 cost 0.36522912979125977 sec\n",
      "loss 2.335815, train acc 0.097843\n",
      "round 460\n",
      "time to device 0.008109 sec\n",
      "time forward 4.946576 sec\n",
      "loss time 0.001035 sec\n",
      "backward time 0.013401 sec\n",
      "optimizer time 0.026054 sec\n",
      "training time in round 460 cost 0.41472506523132324 sec\n",
      "loss 2.335740, train acc 0.097919\n",
      "round 461\n",
      "time to device 0.006525 sec\n",
      "time forward 4.959512 sec\n",
      "loss time 0.001459 sec\n",
      "backward time 0.016581 sec\n",
      "optimizer time 0.026002 sec\n",
      "training time in round 461 cost 0.40027379989624023 sec\n",
      "loss 2.335660, train acc 0.097961\n",
      "round 462\n",
      "time to device 0.007195 sec\n",
      "time forward 4.966951 sec\n",
      "loss time 0.000733 sec\n",
      "backward time 0.006982 sec\n",
      "optimizer time 0.016963 sec\n",
      "training time in round 462 cost 0.36186909675598145 sec\n",
      "loss 2.335595, train acc 0.097935\n",
      "round 463\n",
      "time to device 0.007132 sec\n",
      "time forward 4.977903 sec\n",
      "loss time 0.000551 sec\n",
      "backward time 0.005230 sec\n",
      "optimizer time 0.016426 sec\n",
      "training time in round 463 cost 0.3764491081237793 sec\n",
      "loss 2.335521, train acc 0.098044\n",
      "round 464\n",
      "time to device 0.006496 sec\n",
      "time forward 4.990626 sec\n",
      "loss time 0.001683 sec\n",
      "backward time 0.012122 sec\n",
      "optimizer time 0.027980 sec\n",
      "training time in round 464 cost 0.3944251537322998 sec\n",
      "loss 2.335454, train acc 0.098068\n",
      "round 465\n",
      "time to device 0.003807 sec\n",
      "time forward 5.003034 sec\n",
      "loss time 0.001484 sec\n",
      "backward time 0.010970 sec\n",
      "optimizer time 0.028781 sec\n",
      "training time in round 465 cost 0.3904099464416504 sec\n",
      "loss 2.335397, train acc 0.098008\n",
      "round 466\n",
      "time to device 0.003720 sec\n",
      "time forward 5.016178 sec\n",
      "loss time 0.001199 sec\n",
      "backward time 0.010104 sec\n",
      "optimizer time 0.026202 sec\n",
      "training time in round 466 cost 0.385634183883667 sec\n",
      "loss 2.338730, train acc 0.097966\n",
      "round 467\n",
      "time to device 0.003966 sec\n",
      "time forward 5.029965 sec\n",
      "loss time 0.000981 sec\n",
      "backward time 0.010508 sec\n",
      "optimizer time 0.027108 sec\n",
      "training time in round 467 cost 0.39026689529418945 sec\n",
      "loss 2.338659, train acc 0.097923\n",
      "round 468\n",
      "time to device 0.003118 sec\n",
      "time forward 5.044804 sec\n",
      "loss time 0.001108 sec\n",
      "backward time 0.009925 sec\n",
      "optimizer time 0.013810 sec\n",
      "training time in round 468 cost 0.32236313819885254 sec\n",
      "loss 2.338599, train acc 0.097950\n",
      "test acc is 0.100000\n",
      "epoch 4, time 2203.266477 sec\n",
      "epoch 6\n",
      "round 0\n",
      "time to device 0.043792 sec\n",
      "time forward 0.015942 sec\n",
      "loss time 0.000899 sec\n",
      "backward time 0.010275 sec\n",
      "optimizer time 0.058154 sec\n",
      "training time in round 0 cost 0.5774679183959961 sec\n",
      "loss 2.303093, train acc 0.093750\n",
      "round 1\n",
      "time to device 0.003824 sec\n",
      "time forward 0.026880 sec\n",
      "loss time 0.001544 sec\n",
      "backward time 0.015503 sec\n",
      "optimizer time 0.021373 sec\n",
      "training time in round 1 cost 0.44062113761901855 sec\n",
      "loss 2.334788, train acc 0.101562\n",
      "round 2\n",
      "time to device 0.005806 sec\n",
      "time forward 0.038553 sec\n",
      "loss time 0.001056 sec\n",
      "backward time 0.018359 sec\n",
      "optimizer time 0.019906 sec\n",
      "training time in round 2 cost 0.4464137554168701 sec\n",
      "loss 2.325235, train acc 0.088542\n",
      "round 3\n",
      "time to device 0.007943 sec\n",
      "time forward 0.050093 sec\n",
      "loss time 0.001055 sec\n",
      "backward time 0.011165 sec\n",
      "optimizer time 0.028833 sec\n",
      "training time in round 3 cost 0.4236459732055664 sec\n",
      "loss 2.320849, train acc 0.078125\n",
      "round 4\n",
      "time to device 0.007318 sec\n",
      "time forward 0.064677 sec\n",
      "loss time 0.001060 sec\n",
      "backward time 0.011217 sec\n",
      "optimizer time 0.028952 sec\n",
      "training time in round 4 cost 0.40788698196411133 sec\n",
      "loss 2.317344, train acc 0.076563\n",
      "round 5\n",
      "time to device 0.006469 sec\n",
      "time forward 0.081458 sec\n",
      "loss time 0.001130 sec\n",
      "backward time 0.014535 sec\n",
      "optimizer time 0.023722 sec\n",
      "training time in round 5 cost 0.4143831729888916 sec\n",
      "loss 2.314416, train acc 0.078125\n",
      "round 6\n",
      "time to device 0.007227 sec\n",
      "time forward 0.094342 sec\n",
      "loss time 0.001933 sec\n",
      "backward time 0.013924 sec\n",
      "optimizer time 0.016790 sec\n",
      "training time in round 6 cost 0.38698697090148926 sec\n",
      "loss 2.312396, train acc 0.079241\n",
      "round 7\n",
      "time to device 0.010308 sec\n",
      "time forward 0.109359 sec\n",
      "loss time 0.001052 sec\n",
      "backward time 0.011662 sec\n",
      "optimizer time 0.028986 sec\n",
      "training time in round 7 cost 0.4212038516998291 sec\n",
      "loss 2.311067, train acc 0.087891\n",
      "round 8\n",
      "time to device 0.006832 sec\n",
      "time forward 0.123882 sec\n",
      "loss time 0.001402 sec\n",
      "backward time 0.011753 sec\n",
      "optimizer time 0.010694 sec\n",
      "training time in round 8 cost 0.399198055267334 sec\n",
      "loss 2.311527, train acc 0.091146\n",
      "round 9\n",
      "time to device 0.006707 sec\n",
      "time forward 0.131568 sec\n",
      "loss time 0.000946 sec\n",
      "backward time 0.008660 sec\n",
      "optimizer time 0.019718 sec\n",
      "training time in round 9 cost 0.4346139430999756 sec\n",
      "loss 2.310346, train acc 0.095312\n",
      "round 10\n",
      "time to device 0.007881 sec\n",
      "time forward 0.151018 sec\n",
      "loss time 0.001125 sec\n",
      "backward time 0.012230 sec\n",
      "optimizer time 0.021886 sec\n",
      "training time in round 10 cost 0.4010181427001953 sec\n",
      "loss 2.309309, train acc 0.098722\n",
      "round 11\n",
      "time to device 0.008897 sec\n",
      "time forward 0.163738 sec\n",
      "loss time 0.001935 sec\n",
      "backward time 0.019367 sec\n",
      "optimizer time 0.023905 sec\n",
      "training time in round 11 cost 0.4117140769958496 sec\n",
      "loss 2.308817, train acc 0.098307\n",
      "round 12\n",
      "time to device 0.006503 sec\n",
      "time forward 0.175605 sec\n",
      "loss time 0.006275 sec\n",
      "backward time 0.010408 sec\n",
      "optimizer time 0.025365 sec\n",
      "training time in round 12 cost 0.4035928249359131 sec\n",
      "loss 2.308506, train acc 0.097957\n",
      "round 13\n",
      "time to device 0.006066 sec\n",
      "time forward 0.182744 sec\n",
      "loss time 0.000743 sec\n",
      "backward time 0.007063 sec\n",
      "optimizer time 0.017516 sec\n",
      "training time in round 13 cost 0.3933219909667969 sec\n",
      "loss 2.308277, train acc 0.098214\n",
      "round 14\n",
      "time to device 0.008505 sec\n",
      "time forward 0.196241 sec\n",
      "loss time 0.001789 sec\n",
      "backward time 0.014914 sec\n",
      "optimizer time 0.031599 sec\n",
      "training time in round 14 cost 0.4109840393066406 sec\n",
      "loss 2.307947, train acc 0.095833\n",
      "round 15\n",
      "time to device 0.006972 sec\n",
      "time forward 0.210680 sec\n",
      "loss time 0.002270 sec\n",
      "backward time 0.015816 sec\n",
      "optimizer time 0.027095 sec\n",
      "training time in round 15 cost 0.40857434272766113 sec\n",
      "loss 2.307673, train acc 0.099121\n",
      "round 16\n",
      "time to device 0.008674 sec\n",
      "time forward 0.222413 sec\n",
      "loss time 0.001692 sec\n",
      "backward time 0.011913 sec\n",
      "optimizer time 0.029977 sec\n",
      "training time in round 16 cost 0.39808201789855957 sec\n",
      "loss 2.309692, train acc 0.100643\n",
      "round 17\n",
      "time to device 0.006295 sec\n",
      "time forward 0.229302 sec\n",
      "loss time 0.000395 sec\n",
      "backward time 0.005083 sec\n",
      "optimizer time 0.011734 sec\n",
      "training time in round 17 cost 0.39168810844421387 sec\n",
      "loss 2.310894, train acc 0.099392\n",
      "round 18\n",
      "time to device 0.007865 sec\n",
      "time forward 0.241111 sec\n",
      "loss time 0.001602 sec\n",
      "backward time 0.012185 sec\n",
      "optimizer time 0.025706 sec\n",
      "training time in round 18 cost 0.40845704078674316 sec\n",
      "loss 2.311544, train acc 0.100329\n",
      "round 19\n",
      "time to device 0.006412 sec\n",
      "time forward 0.248786 sec\n",
      "loss time 0.000775 sec\n",
      "backward time 0.006790 sec\n",
      "optimizer time 0.016847 sec\n",
      "training time in round 19 cost 0.35898399353027344 sec\n",
      "loss 2.311097, train acc 0.100391\n",
      "round 20\n",
      "time to device 0.008754 sec\n",
      "time forward 0.263420 sec\n",
      "loss time 0.001940 sec\n",
      "backward time 0.013944 sec\n",
      "optimizer time 0.027941 sec\n",
      "training time in round 20 cost 0.4066731929779053 sec\n",
      "loss 2.310729, train acc 0.100446\n",
      "round 21\n",
      "time to device 0.007867 sec\n",
      "time forward 0.276174 sec\n",
      "loss time 0.001568 sec\n",
      "backward time 0.013588 sec\n",
      "optimizer time 0.025475 sec\n",
      "training time in round 21 cost 0.44866108894348145 sec\n",
      "loss 2.310433, train acc 0.100497\n",
      "round 22\n",
      "time to device 0.006987 sec\n",
      "time forward 0.287947 sec\n",
      "loss time 0.001335 sec\n",
      "backward time 0.013377 sec\n",
      "optimizer time 0.027673 sec\n",
      "training time in round 22 cost 0.3910071849822998 sec\n",
      "loss 2.310177, train acc 0.097147\n",
      "round 23\n",
      "time to device 0.008455 sec\n",
      "time forward 0.295458 sec\n",
      "loss time 0.000726 sec\n",
      "backward time 0.006734 sec\n",
      "optimizer time 0.016703 sec\n",
      "training time in round 23 cost 0.3613471984863281 sec\n",
      "loss 2.311000, train acc 0.096029\n",
      "round 24\n",
      "time to device 0.005442 sec\n",
      "time forward 0.309693 sec\n",
      "loss time 0.001206 sec\n",
      "backward time 0.011613 sec\n",
      "optimizer time 0.026157 sec\n",
      "training time in round 24 cost 0.3991737365722656 sec\n",
      "loss 2.310691, train acc 0.096250\n",
      "round 25\n",
      "time to device 0.006610 sec\n",
      "time forward 0.322917 sec\n",
      "loss time 0.001671 sec\n",
      "backward time 0.014180 sec\n",
      "optimizer time 0.027821 sec\n",
      "training time in round 25 cost 0.4064939022064209 sec\n",
      "loss 2.310316, train acc 0.097957\n",
      "round 26\n",
      "time to device 0.007275 sec\n",
      "time forward 0.336309 sec\n",
      "loss time 0.001431 sec\n",
      "backward time 0.014789 sec\n",
      "optimizer time 0.027819 sec\n",
      "training time in round 26 cost 0.4039957523345947 sec\n",
      "loss 2.310141, train acc 0.097512\n",
      "round 27\n",
      "time to device 0.007210 sec\n",
      "time forward 0.342685 sec\n",
      "loss time 0.000426 sec\n",
      "backward time 0.004146 sec\n",
      "optimizer time 0.013415 sec\n",
      "training time in round 27 cost 0.34868407249450684 sec\n",
      "loss 2.310031, train acc 0.098214\n",
      "round 28\n",
      "time to device 0.009201 sec\n",
      "time forward 0.354212 sec\n",
      "loss time 0.001226 sec\n",
      "backward time 0.013890 sec\n",
      "optimizer time 0.024704 sec\n",
      "training time in round 28 cost 0.4075760841369629 sec\n",
      "loss 2.310138, train acc 0.097522\n",
      "round 29\n",
      "time to device 0.009177 sec\n",
      "time forward 0.365520 sec\n",
      "loss time 0.000974 sec\n",
      "backward time 0.009993 sec\n",
      "optimizer time 0.026387 sec\n",
      "training time in round 29 cost 0.38065409660339355 sec\n",
      "loss 2.311014, train acc 0.097917\n",
      "round 30\n",
      "time to device 0.006828 sec\n",
      "time forward 0.379266 sec\n",
      "loss time 0.001211 sec\n",
      "backward time 0.016160 sec\n",
      "optimizer time 0.043787 sec\n",
      "training time in round 30 cost 0.4147019386291504 sec\n",
      "loss 2.310663, train acc 0.098286\n",
      "round 31\n",
      "time to device 0.008832 sec\n",
      "time forward 0.386935 sec\n",
      "loss time 0.000792 sec\n",
      "backward time 0.007525 sec\n",
      "optimizer time 0.018487 sec\n",
      "training time in round 31 cost 0.3639233112335205 sec\n",
      "loss 2.310493, train acc 0.099609\n",
      "round 32\n",
      "time to device 0.007353 sec\n",
      "time forward 0.402597 sec\n",
      "loss time 0.001862 sec\n",
      "backward time 0.017331 sec\n",
      "optimizer time 0.022909 sec\n",
      "training time in round 32 cost 0.4234309196472168 sec\n",
      "loss 2.310237, train acc 0.099195\n",
      "round 33\n",
      "time to device 0.006379 sec\n",
      "time forward 0.416232 sec\n",
      "loss time 0.001004 sec\n",
      "backward time 0.010537 sec\n",
      "optimizer time 0.033681 sec\n",
      "training time in round 33 cost 0.39608216285705566 sec\n",
      "loss 2.310594, train acc 0.099954\n",
      "round 34\n",
      "time to device 0.007970 sec\n",
      "time forward 0.429620 sec\n",
      "loss time 0.001290 sec\n",
      "backward time 0.011462 sec\n",
      "optimizer time 0.027900 sec\n",
      "training time in round 34 cost 0.41855502128601074 sec\n",
      "loss 2.310306, train acc 0.099554\n",
      "round 35\n",
      "time to device 0.007268 sec\n",
      "time forward 0.442861 sec\n",
      "loss time 0.006303 sec\n",
      "backward time 0.018096 sec\n",
      "optimizer time 0.026658 sec\n",
      "training time in round 35 cost 0.41353392601013184 sec\n",
      "loss 2.310165, train acc 0.098307\n",
      "round 36\n",
      "time to device 0.008017 sec\n",
      "time forward 0.454505 sec\n",
      "loss time 0.000713 sec\n",
      "backward time 0.007136 sec\n",
      "optimizer time 0.017446 sec\n",
      "training time in round 36 cost 0.37195491790771484 sec\n",
      "loss 2.313400, train acc 0.098818\n",
      "round 37\n",
      "time to device 0.009571 sec\n",
      "time forward 0.460973 sec\n",
      "loss time 0.000565 sec\n",
      "backward time 0.005127 sec\n",
      "optimizer time 0.013704 sec\n",
      "training time in round 37 cost 0.3631911277770996 sec\n",
      "loss 2.313465, train acc 0.099095\n",
      "round 38\n",
      "time to device 0.009734 sec\n",
      "time forward 0.468452 sec\n",
      "loss time 0.000724 sec\n",
      "backward time 0.006550 sec\n",
      "optimizer time 0.016444 sec\n",
      "training time in round 38 cost 0.3578927516937256 sec\n",
      "loss 2.313206, train acc 0.099359\n",
      "round 39\n",
      "time to device 0.007135 sec\n",
      "time forward 0.478191 sec\n",
      "loss time 0.000997 sec\n",
      "backward time 0.010546 sec\n",
      "optimizer time 0.021108 sec\n",
      "training time in round 39 cost 0.39824771881103516 sec\n",
      "loss 2.312918, train acc 0.099023\n",
      "round 40\n",
      "time to device 0.006327 sec\n",
      "time forward 0.491340 sec\n",
      "loss time 0.000956 sec\n",
      "backward time 0.011760 sec\n",
      "optimizer time 0.021635 sec\n",
      "training time in round 40 cost 0.40255212783813477 sec\n",
      "loss 2.312691, train acc 0.098514\n",
      "round 41\n",
      "time to device 0.006418 sec\n",
      "time forward 0.505657 sec\n",
      "loss time 0.001360 sec\n",
      "backward time 0.011845 sec\n",
      "optimizer time 0.030063 sec\n",
      "training time in round 41 cost 0.4939570426940918 sec\n",
      "loss 2.312371, train acc 0.098958\n",
      "round 42\n",
      "time to device 0.007179 sec\n",
      "time forward 0.515409 sec\n",
      "loss time 0.001824 sec\n",
      "backward time 0.011126 sec\n",
      "optimizer time 0.029929 sec\n",
      "training time in round 42 cost 0.5036768913269043 sec\n",
      "loss 2.312129, train acc 0.098656\n",
      "round 43\n",
      "time to device 0.007091 sec\n",
      "time forward 0.532625 sec\n",
      "loss time 0.001022 sec\n",
      "backward time 0.011537 sec\n",
      "optimizer time 0.029976 sec\n",
      "training time in round 43 cost 0.42828965187072754 sec\n",
      "loss 2.311911, train acc 0.098722\n",
      "round 44\n",
      "time to device 0.007605 sec\n",
      "time forward 0.548674 sec\n",
      "loss time 0.001653 sec\n",
      "backward time 0.013156 sec\n",
      "optimizer time 0.021031 sec\n",
      "training time in round 44 cost 0.4170548915863037 sec\n",
      "loss 2.311325, train acc 0.098958\n",
      "round 45\n",
      "time to device 0.007085 sec\n",
      "time forward 0.565370 sec\n",
      "loss time 0.000956 sec\n",
      "backward time 0.007259 sec\n",
      "optimizer time 0.018432 sec\n",
      "training time in round 45 cost 0.41144776344299316 sec\n",
      "loss 2.312167, train acc 0.099694\n",
      "round 46\n",
      "time to device 0.007058 sec\n",
      "time forward 0.573010 sec\n",
      "loss time 0.000588 sec\n",
      "backward time 0.005922 sec\n",
      "optimizer time 0.018923 sec\n",
      "training time in round 46 cost 0.3841431140899658 sec\n",
      "loss 2.312518, train acc 0.099568\n",
      "round 47\n",
      "time to device 0.006666 sec\n",
      "time forward 0.587134 sec\n",
      "loss time 0.001217 sec\n",
      "backward time 0.016024 sec\n",
      "optimizer time 0.031319 sec\n",
      "training time in round 47 cost 0.42266392707824707 sec\n",
      "loss 2.312462, train acc 0.099772\n",
      "round 48\n",
      "time to device 0.010166 sec\n",
      "time forward 0.606146 sec\n",
      "loss time 0.001503 sec\n",
      "backward time 0.013104 sec\n",
      "optimizer time 0.015695 sec\n",
      "training time in round 48 cost 0.42136216163635254 sec\n",
      "loss 2.312268, train acc 0.099968\n",
      "round 49\n",
      "time to device 0.005848 sec\n",
      "time forward 0.620425 sec\n",
      "loss time 0.002547 sec\n",
      "backward time 0.018510 sec\n",
      "optimizer time 0.026001 sec\n",
      "training time in round 49 cost 0.5316059589385986 sec\n",
      "loss 2.313907, train acc 0.100469\n",
      "round 50\n",
      "time to device 0.006774 sec\n",
      "time forward 0.631934 sec\n",
      "loss time 0.001314 sec\n",
      "backward time 0.008404 sec\n",
      "optimizer time 0.018759 sec\n",
      "training time in round 50 cost 0.4454078674316406 sec\n",
      "loss 2.313580, train acc 0.100184\n",
      "round 51\n",
      "time to device 0.008204 sec\n",
      "time forward 0.639083 sec\n",
      "loss time 0.000458 sec\n",
      "backward time 0.004885 sec\n",
      "optimizer time 0.017619 sec\n",
      "training time in round 51 cost 0.40576982498168945 sec\n",
      "loss 2.313691, train acc 0.100661\n",
      "round 52\n",
      "time to device 0.007552 sec\n",
      "time forward 0.646762 sec\n",
      "loss time 0.000775 sec\n",
      "backward time 0.006681 sec\n",
      "optimizer time 0.017850 sec\n",
      "training time in round 52 cost 0.38545894622802734 sec\n",
      "loss 2.313574, train acc 0.099794\n",
      "round 53\n",
      "time to device 0.008118 sec\n",
      "time forward 0.656705 sec\n",
      "loss time 0.001202 sec\n",
      "backward time 0.014904 sec\n",
      "optimizer time 0.020727 sec\n",
      "training time in round 53 cost 0.41066789627075195 sec\n",
      "loss 2.313372, train acc 0.099537\n",
      "round 54\n",
      "time to device 0.007524 sec\n",
      "time forward 0.670772 sec\n",
      "loss time 0.001400 sec\n",
      "backward time 0.020584 sec\n",
      "optimizer time 0.015789 sec\n",
      "training time in round 54 cost 0.48468613624572754 sec\n",
      "loss 2.313137, train acc 0.100142\n",
      "round 55\n",
      "time to device 0.011000 sec\n",
      "time forward 0.683976 sec\n",
      "loss time 0.001459 sec\n",
      "backward time 0.010988 sec\n",
      "optimizer time 0.027028 sec\n",
      "training time in round 55 cost 0.4621262550354004 sec\n",
      "loss 2.314943, train acc 0.100028\n",
      "round 56\n",
      "time to device 0.008174 sec\n",
      "time forward 0.696786 sec\n",
      "loss time 0.001951 sec\n",
      "backward time 0.013669 sec\n",
      "optimizer time 0.026288 sec\n",
      "training time in round 56 cost 0.41108202934265137 sec\n",
      "loss 2.314705, train acc 0.100192\n",
      "round 57\n",
      "time to device 0.009632 sec\n",
      "time forward 0.714351 sec\n",
      "loss time 0.001201 sec\n",
      "backward time 0.013364 sec\n",
      "optimizer time 0.027776 sec\n",
      "training time in round 57 cost 0.410430908203125 sec\n",
      "loss 2.314581, train acc 0.099946\n",
      "round 58\n",
      "time to device 0.009890 sec\n",
      "time forward 0.726252 sec\n",
      "loss time 0.001018 sec\n",
      "backward time 0.013278 sec\n",
      "optimizer time 0.021910 sec\n",
      "training time in round 58 cost 0.3912632465362549 sec\n",
      "loss 2.314404, train acc 0.100371\n",
      "round 59\n",
      "time to device 0.010289 sec\n",
      "time forward 0.743166 sec\n",
      "loss time 0.002209 sec\n",
      "backward time 0.015259 sec\n",
      "optimizer time 0.025882 sec\n",
      "training time in round 59 cost 0.4092531204223633 sec\n",
      "loss 2.314120, train acc 0.100781\n",
      "round 60\n",
      "time to device 0.006489 sec\n",
      "time forward 0.756903 sec\n",
      "loss time 0.001568 sec\n",
      "backward time 0.016053 sec\n",
      "optimizer time 0.023214 sec\n",
      "training time in round 60 cost 0.3936758041381836 sec\n",
      "loss 2.313889, train acc 0.100410\n",
      "round 61\n",
      "time to device 0.010146 sec\n",
      "time forward 0.771139 sec\n",
      "loss time 0.001600 sec\n",
      "backward time 0.012920 sec\n",
      "optimizer time 0.023651 sec\n",
      "training time in round 61 cost 0.39995908737182617 sec\n",
      "loss 2.313795, train acc 0.100176\n",
      "round 62\n",
      "time to device 0.006769 sec\n",
      "time forward 0.779607 sec\n",
      "loss time 0.000771 sec\n",
      "backward time 0.006564 sec\n",
      "optimizer time 0.016673 sec\n",
      "training time in round 62 cost 0.38532519340515137 sec\n",
      "loss 2.313598, train acc 0.100818\n",
      "round 63\n",
      "time to device 0.006922 sec\n",
      "time forward 0.791703 sec\n",
      "loss time 0.001760 sec\n",
      "backward time 0.015835 sec\n",
      "optimizer time 0.020515 sec\n",
      "training time in round 63 cost 0.4107050895690918 sec\n",
      "loss 2.313415, train acc 0.101196\n",
      "round 64\n",
      "time to device 0.006852 sec\n",
      "time forward 0.824760 sec\n",
      "loss time 0.001654 sec\n",
      "backward time 0.016262 sec\n",
      "optimizer time 0.020330 sec\n",
      "training time in round 64 cost 0.4825129508972168 sec\n",
      "loss 2.313255, train acc 0.101322\n",
      "round 65\n",
      "time to device 0.006922 sec\n",
      "time forward 0.838165 sec\n",
      "loss time 0.000937 sec\n",
      "backward time 0.015016 sec\n",
      "optimizer time 0.022277 sec\n",
      "training time in round 65 cost 0.47754693031311035 sec\n",
      "loss 2.313026, train acc 0.101681\n",
      "round 66\n",
      "time to device 0.007674 sec\n",
      "time forward 0.852007 sec\n",
      "loss time 0.001038 sec\n",
      "backward time 0.010701 sec\n",
      "optimizer time 0.022323 sec\n",
      "training time in round 66 cost 0.45180511474609375 sec\n",
      "loss 2.313632, train acc 0.101329\n",
      "round 67\n",
      "time to device 0.009502 sec\n",
      "time forward 0.863552 sec\n",
      "loss time 0.001490 sec\n",
      "backward time 0.019921 sec\n",
      "optimizer time 0.024255 sec\n",
      "training time in round 67 cost 0.40592288970947266 sec\n",
      "loss 2.313671, train acc 0.101333\n",
      "round 68\n",
      "time to device 0.007418 sec\n",
      "time forward 0.870800 sec\n",
      "loss time 0.000454 sec\n",
      "backward time 0.005759 sec\n",
      "optimizer time 0.013047 sec\n",
      "training time in round 68 cost 0.3755300045013428 sec\n",
      "loss 2.313567, train acc 0.100996\n",
      "round 69\n",
      "time to device 0.006533 sec\n",
      "time forward 0.884238 sec\n",
      "loss time 0.001547 sec\n",
      "backward time 0.014565 sec\n",
      "optimizer time 0.025197 sec\n",
      "training time in round 69 cost 0.41362929344177246 sec\n",
      "loss 2.313489, train acc 0.100670\n",
      "round 70\n",
      "time to device 0.010441 sec\n",
      "time forward 0.895137 sec\n",
      "loss time 0.001295 sec\n",
      "backward time 0.013752 sec\n",
      "optimizer time 0.020138 sec\n",
      "training time in round 70 cost 0.4201798439025879 sec\n",
      "loss 2.313403, train acc 0.100792\n",
      "round 71\n",
      "time to device 0.006795 sec\n",
      "time forward 0.907316 sec\n",
      "loss time 0.001174 sec\n",
      "backward time 0.013168 sec\n",
      "optimizer time 0.030982 sec\n",
      "training time in round 71 cost 0.41356897354125977 sec\n",
      "loss 2.313321, train acc 0.100477\n",
      "round 72\n",
      "time to device 0.007878 sec\n",
      "time forward 0.918495 sec\n",
      "loss time 0.001329 sec\n",
      "backward time 0.010939 sec\n",
      "optimizer time 0.013047 sec\n",
      "training time in round 72 cost 0.3774912357330322 sec\n",
      "loss 2.316672, train acc 0.100492\n",
      "round 73\n",
      "time to device 0.008507 sec\n",
      "time forward 0.935101 sec\n",
      "loss time 0.001178 sec\n",
      "backward time 0.012598 sec\n",
      "optimizer time 0.027486 sec\n",
      "training time in round 73 cost 0.41437506675720215 sec\n",
      "loss 2.316513, train acc 0.100507\n",
      "round 74\n",
      "time to device 0.010975 sec\n",
      "time forward 0.945927 sec\n",
      "loss time 0.001175 sec\n",
      "backward time 0.011657 sec\n",
      "optimizer time 0.018037 sec\n",
      "training time in round 74 cost 0.41463494300842285 sec\n",
      "loss 2.316368, train acc 0.100208\n",
      "round 75\n",
      "time to device 0.007498 sec\n",
      "time forward 0.956482 sec\n",
      "loss time 0.001028 sec\n",
      "backward time 0.011277 sec\n",
      "optimizer time 0.029383 sec\n",
      "training time in round 75 cost 0.4025280475616455 sec\n",
      "loss 2.316202, train acc 0.100123\n",
      "round 76\n",
      "time to device 0.007676 sec\n",
      "time forward 0.968920 sec\n",
      "loss time 0.001412 sec\n",
      "backward time 0.015010 sec\n",
      "optimizer time 0.027005 sec\n",
      "training time in round 76 cost 0.4062361717224121 sec\n",
      "loss 2.316172, train acc 0.100142\n",
      "round 77\n",
      "time to device 0.007591 sec\n",
      "time forward 0.975401 sec\n",
      "loss time 0.000485 sec\n",
      "backward time 0.004135 sec\n",
      "optimizer time 0.015052 sec\n",
      "training time in round 77 cost 0.39377522468566895 sec\n",
      "loss 2.315998, train acc 0.099860\n",
      "round 78\n",
      "time to device 0.008533 sec\n",
      "time forward 0.989492 sec\n",
      "loss time 0.001243 sec\n",
      "backward time 0.011610 sec\n",
      "optimizer time 0.022650 sec\n",
      "training time in round 78 cost 0.4022641181945801 sec\n",
      "loss 2.315872, train acc 0.099881\n",
      "round 79\n",
      "time to device 0.006645 sec\n",
      "time forward 1.001333 sec\n",
      "loss time 0.001603 sec\n",
      "backward time 0.023240 sec\n",
      "optimizer time 0.019462 sec\n",
      "training time in round 79 cost 0.41036105155944824 sec\n",
      "loss 2.315719, train acc 0.099707\n",
      "round 80\n",
      "time to device 0.006394 sec\n",
      "time forward 1.013245 sec\n",
      "loss time 0.001135 sec\n",
      "backward time 0.020284 sec\n",
      "optimizer time 0.015601 sec\n",
      "training time in round 80 cost 0.39507007598876953 sec\n",
      "loss 2.315568, train acc 0.099826\n",
      "round 81\n",
      "time to device 0.006760 sec\n",
      "time forward 1.025559 sec\n",
      "loss time 0.001233 sec\n",
      "backward time 0.014354 sec\n",
      "optimizer time 0.019896 sec\n",
      "training time in round 81 cost 0.4529261589050293 sec\n",
      "loss 2.315565, train acc 0.099371\n",
      "round 82\n",
      "time to device 0.007956 sec\n",
      "time forward 1.038957 sec\n",
      "loss time 0.000981 sec\n",
      "backward time 0.010678 sec\n",
      "optimizer time 0.025321 sec\n",
      "training time in round 82 cost 0.41071081161499023 sec\n",
      "loss 2.315210, train acc 0.099021\n",
      "round 83\n",
      "time to device 0.007666 sec\n",
      "time forward 1.055470 sec\n",
      "loss time 0.001439 sec\n",
      "backward time 0.040690 sec\n",
      "optimizer time 0.050737 sec\n",
      "training time in round 83 cost 0.4911327362060547 sec\n",
      "loss 2.315066, train acc 0.098865\n",
      "round 84\n",
      "time to device 0.007102 sec\n",
      "time forward 1.073786 sec\n",
      "loss time 0.000704 sec\n",
      "backward time 0.010783 sec\n",
      "optimizer time 0.028831 sec\n",
      "training time in round 84 cost 0.5200419425964355 sec\n",
      "loss 2.314825, train acc 0.099449\n",
      "round 85\n",
      "time to device 0.010386 sec\n",
      "time forward 1.093439 sec\n",
      "loss time 0.001230 sec\n",
      "backward time 0.055583 sec\n",
      "optimizer time 0.077251 sec\n",
      "training time in round 85 cost 0.7309689521789551 sec\n",
      "loss 2.314689, train acc 0.099019\n",
      "round 86\n",
      "time to device 0.005051 sec\n",
      "time forward 1.104465 sec\n",
      "loss time 0.000472 sec\n",
      "backward time 0.004515 sec\n",
      "optimizer time 0.016237 sec\n",
      "training time in round 86 cost 0.45667028427124023 sec\n",
      "loss 2.314585, train acc 0.099228\n",
      "round 87\n",
      "time to device 0.006844 sec\n",
      "time forward 1.115252 sec\n",
      "loss time 0.000472 sec\n",
      "backward time 0.004409 sec\n",
      "optimizer time 0.016189 sec\n",
      "training time in round 87 cost 0.4079911708831787 sec\n",
      "loss 2.314636, train acc 0.098366\n",
      "round 88\n",
      "time to device 0.005175 sec\n",
      "time forward 1.121988 sec\n",
      "loss time 0.000515 sec\n",
      "backward time 0.004700 sec\n",
      "optimizer time 0.013448 sec\n",
      "training time in round 88 cost 0.3632819652557373 sec\n",
      "loss 2.314546, train acc 0.098315\n",
      "round 89\n",
      "time to device 0.006700 sec\n",
      "time forward 1.127584 sec\n",
      "loss time 0.000578 sec\n",
      "backward time 0.005308 sec\n",
      "optimizer time 0.014610 sec\n",
      "training time in round 89 cost 0.3848280906677246 sec\n",
      "loss 2.314759, train acc 0.098264\n",
      "round 90\n",
      "time to device 0.007265 sec\n",
      "time forward 1.137061 sec\n",
      "loss time 0.000450 sec\n",
      "backward time 0.004307 sec\n",
      "optimizer time 0.013959 sec\n",
      "training time in round 90 cost 0.3679208755493164 sec\n",
      "loss 2.314639, train acc 0.098043\n",
      "round 91\n",
      "time to device 0.006812 sec\n",
      "time forward 1.254641 sec\n",
      "loss time 0.000776 sec\n",
      "backward time 0.007943 sec\n",
      "optimizer time 0.048800 sec\n",
      "training time in round 91 cost 0.7675211429595947 sec\n",
      "loss 2.314470, train acc 0.098166\n",
      "round 92\n",
      "time to device 0.006774 sec\n",
      "time forward 1.275776 sec\n",
      "loss time 0.001948 sec\n",
      "backward time 0.012651 sec\n",
      "optimizer time 0.025227 sec\n",
      "training time in round 92 cost 0.5025148391723633 sec\n",
      "loss 2.314353, train acc 0.098622\n",
      "round 93\n",
      "time to device 0.007823 sec\n",
      "time forward 1.286659 sec\n",
      "loss time 0.003997 sec\n",
      "backward time 0.025274 sec\n",
      "optimizer time 0.023108 sec\n",
      "training time in round 93 cost 0.4685487747192383 sec\n",
      "loss 2.314811, train acc 0.098487\n",
      "round 94\n",
      "time to device 0.094428 sec\n",
      "time forward 1.296296 sec\n",
      "loss time 0.000982 sec\n",
      "backward time 0.008409 sec\n",
      "optimizer time 0.080862 sec\n",
      "training time in round 94 cost 0.6988987922668457 sec\n",
      "loss 2.314884, train acc 0.098684\n",
      "round 95\n",
      "time to device 0.004571 sec\n",
      "time forward 1.302256 sec\n",
      "loss time 0.000429 sec\n",
      "backward time 0.003982 sec\n",
      "optimizer time 0.020698 sec\n",
      "training time in round 95 cost 0.38568592071533203 sec\n",
      "loss 2.314852, train acc 0.098877\n",
      "round 96\n",
      "time to device 0.006208 sec\n",
      "time forward 1.307355 sec\n",
      "loss time 0.000490 sec\n",
      "backward time 0.004391 sec\n",
      "optimizer time 0.016360 sec\n",
      "training time in round 96 cost 0.37519001960754395 sec\n",
      "loss 2.314739, train acc 0.098744\n",
      "round 97\n",
      "time to device 0.007633 sec\n",
      "time forward 1.387863 sec\n",
      "loss time 0.001527 sec\n",
      "backward time 0.013927 sec\n",
      "optimizer time 0.019180 sec\n",
      "training time in round 97 cost 0.7282760143280029 sec\n",
      "loss 2.314636, train acc 0.098294\n",
      "round 98\n",
      "time to device 0.010141 sec\n",
      "time forward 1.405930 sec\n",
      "loss time 0.001464 sec\n",
      "backward time 0.012317 sec\n",
      "optimizer time 0.040411 sec\n",
      "training time in round 98 cost 0.5596308708190918 sec\n",
      "loss 2.315091, train acc 0.098722\n",
      "round 99\n",
      "time to device 0.006693 sec\n",
      "time forward 1.417929 sec\n",
      "loss time 0.002309 sec\n",
      "backward time 0.021163 sec\n",
      "optimizer time 0.024136 sec\n",
      "training time in round 99 cost 0.42394495010375977 sec\n",
      "loss 2.315141, train acc 0.098828\n",
      "round 100\n",
      "time to device 0.006445 sec\n",
      "time forward 1.433926 sec\n",
      "loss time 0.001404 sec\n",
      "backward time 0.014412 sec\n",
      "optimizer time 0.022769 sec\n",
      "training time in round 100 cost 0.40839099884033203 sec\n",
      "loss 2.315038, train acc 0.099010\n",
      "round 101\n",
      "time to device 0.009286 sec\n",
      "time forward 1.440517 sec\n",
      "loss time 0.000653 sec\n",
      "backward time 0.005912 sec\n",
      "optimizer time 0.015693 sec\n",
      "training time in round 101 cost 0.36184215545654297 sec\n",
      "loss 2.315728, train acc 0.099035\n",
      "round 102\n",
      "time to device 0.007826 sec\n",
      "time forward 1.454704 sec\n",
      "loss time 0.001475 sec\n",
      "backward time 0.016568 sec\n",
      "optimizer time 0.026084 sec\n",
      "training time in round 102 cost 0.41452789306640625 sec\n",
      "loss 2.317792, train acc 0.099135\n",
      "round 103\n",
      "time to device 0.007429 sec\n",
      "time forward 1.461056 sec\n",
      "loss time 0.000613 sec\n",
      "backward time 0.005656 sec\n",
      "optimizer time 0.015376 sec\n",
      "training time in round 103 cost 0.39803194999694824 sec\n",
      "loss 2.319043, train acc 0.099384\n",
      "round 104\n",
      "time to device 0.008469 sec\n",
      "time forward 1.472449 sec\n",
      "loss time 0.001548 sec\n",
      "backward time 0.011982 sec\n",
      "optimizer time 0.026385 sec\n",
      "training time in round 104 cost 0.45009708404541016 sec\n",
      "loss 2.319302, train acc 0.099405\n",
      "round 105\n",
      "time to device 0.011424 sec\n",
      "time forward 1.484777 sec\n",
      "loss time 0.002264 sec\n",
      "backward time 0.018984 sec\n",
      "optimizer time 0.032428 sec\n",
      "training time in round 105 cost 0.4347419738769531 sec\n",
      "loss 2.319145, train acc 0.099425\n",
      "round 106\n",
      "time to device 0.008540 sec\n",
      "time forward 1.495646 sec\n",
      "loss time 0.000941 sec\n",
      "backward time 0.008344 sec\n",
      "optimizer time 0.016745 sec\n",
      "training time in round 106 cost 0.37185096740722656 sec\n",
      "loss 2.320685, train acc 0.099445\n",
      "round 107\n",
      "time to device 0.008504 sec\n",
      "time forward 1.511873 sec\n",
      "loss time 0.001600 sec\n",
      "backward time 0.018612 sec\n",
      "optimizer time 0.064174 sec\n",
      "training time in round 107 cost 0.49109506607055664 sec\n",
      "loss 2.320440, train acc 0.099392\n",
      "round 108\n",
      "time to device 0.006652 sec\n",
      "time forward 1.519700 sec\n",
      "loss time 0.000614 sec\n",
      "backward time 0.006075 sec\n",
      "optimizer time 0.016201 sec\n",
      "training time in round 108 cost 0.38030195236206055 sec\n",
      "loss 2.320864, train acc 0.099341\n",
      "round 109\n",
      "time to device 0.007380 sec\n",
      "time forward 1.530950 sec\n",
      "loss time 0.001038 sec\n",
      "backward time 0.010207 sec\n",
      "optimizer time 0.028585 sec\n",
      "training time in round 109 cost 0.4146449565887451 sec\n",
      "loss 2.321242, train acc 0.099716\n",
      "round 110\n",
      "time to device 0.007166 sec\n",
      "time forward 1.542677 sec\n",
      "loss time 0.001087 sec\n",
      "backward time 0.011800 sec\n",
      "optimizer time 0.020520 sec\n",
      "training time in round 110 cost 0.41748690605163574 sec\n",
      "loss 2.321140, train acc 0.099521\n",
      "round 111\n",
      "time to device 0.007327 sec\n",
      "time forward 1.552835 sec\n",
      "loss time 0.001237 sec\n",
      "backward time 0.013626 sec\n",
      "optimizer time 0.023654 sec\n",
      "training time in round 111 cost 0.4072849750518799 sec\n",
      "loss 2.320992, train acc 0.099400\n",
      "round 112\n",
      "time to device 0.007861 sec\n",
      "time forward 1.569441 sec\n",
      "loss time 0.001382 sec\n",
      "backward time 0.014236 sec\n",
      "optimizer time 0.022352 sec\n",
      "training time in round 112 cost 0.41762304306030273 sec\n",
      "loss 2.320838, train acc 0.099627\n",
      "round 113\n",
      "time to device 0.007337 sec\n",
      "time forward 1.580491 sec\n",
      "loss time 0.001356 sec\n",
      "backward time 0.013010 sec\n",
      "optimizer time 0.026106 sec\n",
      "training time in round 113 cost 0.413715124130249 sec\n",
      "loss 2.320697, train acc 0.099781\n",
      "round 114\n",
      "time to device 0.008657 sec\n",
      "time forward 1.594389 sec\n",
      "loss time 0.002273 sec\n",
      "backward time 0.020459 sec\n",
      "optimizer time 0.022767 sec\n",
      "training time in round 114 cost 0.41416001319885254 sec\n",
      "loss 2.320515, train acc 0.100272\n",
      "round 115\n",
      "time to device 0.007297 sec\n",
      "time forward 1.603386 sec\n",
      "loss time 0.001440 sec\n",
      "backward time 0.009609 sec\n",
      "optimizer time 0.019689 sec\n",
      "training time in round 115 cost 0.3905360698699951 sec\n",
      "loss 2.320342, train acc 0.100485\n",
      "round 116\n",
      "time to device 0.006490 sec\n",
      "time forward 1.616877 sec\n",
      "loss time 0.001494 sec\n",
      "backward time 0.013696 sec\n",
      "optimizer time 0.024101 sec\n",
      "training time in round 116 cost 0.4487729072570801 sec\n",
      "loss 2.320188, train acc 0.100561\n",
      "round 117\n",
      "time to device 0.007609 sec\n",
      "time forward 1.623250 sec\n",
      "loss time 0.000667 sec\n",
      "backward time 0.005912 sec\n",
      "optimizer time 0.016178 sec\n",
      "training time in round 117 cost 0.3717000484466553 sec\n",
      "loss 2.320051, train acc 0.100305\n",
      "round 118\n",
      "time to device 0.006194 sec\n",
      "time forward 1.637697 sec\n",
      "loss time 0.001289 sec\n",
      "backward time 0.014803 sec\n",
      "optimizer time 0.028419 sec\n",
      "training time in round 118 cost 0.41765594482421875 sec\n",
      "loss 2.319895, train acc 0.100184\n",
      "round 119\n",
      "time to device 0.007050 sec\n",
      "time forward 1.648881 sec\n",
      "loss time 0.001496 sec\n",
      "backward time 0.010695 sec\n",
      "optimizer time 0.012298 sec\n",
      "training time in round 119 cost 0.39663195610046387 sec\n",
      "loss 2.319743, train acc 0.100521\n",
      "round 120\n",
      "time to device 0.009728 sec\n",
      "time forward 1.659213 sec\n",
      "loss time 0.002120 sec\n",
      "backward time 0.016822 sec\n",
      "optimizer time 0.023777 sec\n",
      "training time in round 120 cost 0.4225170612335205 sec\n",
      "loss 2.319620, train acc 0.100465\n",
      "round 121\n",
      "time to device 0.012249 sec\n",
      "time forward 1.669257 sec\n",
      "loss time 0.000553 sec\n",
      "backward time 0.005366 sec\n",
      "optimizer time 0.014097 sec\n",
      "training time in round 121 cost 0.3721621036529541 sec\n",
      "loss 2.319502, train acc 0.100154\n",
      "round 122\n",
      "time to device 0.007881 sec\n",
      "time forward 1.684922 sec\n",
      "loss time 0.001455 sec\n",
      "backward time 0.015247 sec\n",
      "optimizer time 0.023479 sec\n",
      "training time in round 122 cost 0.4122130870819092 sec\n",
      "loss 2.319268, train acc 0.100483\n",
      "round 123\n",
      "time to device 0.008914 sec\n",
      "time forward 1.695756 sec\n",
      "loss time 0.001316 sec\n",
      "backward time 0.012927 sec\n",
      "optimizer time 0.015266 sec\n",
      "training time in round 123 cost 0.38687777519226074 sec\n",
      "loss 2.319155, train acc 0.100365\n",
      "round 124\n",
      "time to device 0.006484 sec\n",
      "time forward 1.703304 sec\n",
      "loss time 0.000732 sec\n",
      "backward time 0.006516 sec\n",
      "optimizer time 0.016219 sec\n",
      "training time in round 124 cost 0.35778212547302246 sec\n",
      "loss 2.319035, train acc 0.100312\n",
      "round 125\n",
      "time to device 0.003067 sec\n",
      "time forward 1.720975 sec\n",
      "loss time 0.001944 sec\n",
      "backward time 0.014512 sec\n",
      "optimizer time 0.024778 sec\n",
      "training time in round 125 cost 0.41054272651672363 sec\n",
      "loss 2.318920, train acc 0.099826\n",
      "round 126\n",
      "time to device 0.003752 sec\n",
      "time forward 1.727746 sec\n",
      "loss time 0.000343 sec\n",
      "backward time 0.004394 sec\n",
      "optimizer time 0.013176 sec\n",
      "training time in round 126 cost 0.3590729236602783 sec\n",
      "loss 2.319444, train acc 0.099902\n",
      "round 127\n",
      "time to device 0.004678 sec\n",
      "time forward 1.745476 sec\n",
      "loss time 0.001700 sec\n",
      "backward time 0.013439 sec\n",
      "optimizer time 0.021818 sec\n",
      "training time in round 127 cost 0.4515550136566162 sec\n",
      "loss 2.319437, train acc 0.099854\n",
      "round 128\n",
      "time to device 0.003656 sec\n",
      "time forward 1.758669 sec\n",
      "loss time 0.001498 sec\n",
      "backward time 0.015556 sec\n",
      "optimizer time 0.025848 sec\n",
      "training time in round 128 cost 0.39606690406799316 sec\n",
      "loss 2.319652, train acc 0.099746\n",
      "round 129\n",
      "time to device 0.004670 sec\n",
      "time forward 1.771323 sec\n",
      "loss time 0.001032 sec\n",
      "backward time 0.019222 sec\n",
      "optimizer time 0.016311 sec\n",
      "training time in round 129 cost 0.40482592582702637 sec\n",
      "loss 2.320868, train acc 0.099700\n",
      "round 130\n",
      "time to device 0.004731 sec\n",
      "time forward 1.783215 sec\n",
      "loss time 0.000973 sec\n",
      "backward time 0.009310 sec\n",
      "optimizer time 0.026327 sec\n",
      "training time in round 130 cost 0.4249131679534912 sec\n",
      "loss 2.320814, train acc 0.099416\n",
      "round 131\n",
      "time to device 0.006490 sec\n",
      "time forward 1.797443 sec\n",
      "loss time 0.001198 sec\n",
      "backward time 0.011764 sec\n",
      "optimizer time 0.031996 sec\n",
      "training time in round 131 cost 0.4117429256439209 sec\n",
      "loss 2.320733, train acc 0.099609\n",
      "round 132\n",
      "time to device 0.007005 sec\n",
      "time forward 1.808522 sec\n",
      "loss time 0.001013 sec\n",
      "backward time 0.010895 sec\n",
      "optimizer time 0.023347 sec\n",
      "training time in round 132 cost 0.39372706413269043 sec\n",
      "loss 2.321434, train acc 0.099330\n",
      "round 133\n",
      "time to device 0.008381 sec\n",
      "time forward 1.817698 sec\n",
      "loss time 0.000650 sec\n",
      "backward time 0.006429 sec\n",
      "optimizer time 0.016132 sec\n",
      "training time in round 133 cost 0.36905598640441895 sec\n",
      "loss 2.321308, train acc 0.099172\n",
      "round 134\n",
      "time to device 0.007360 sec\n",
      "time forward 1.829472 sec\n",
      "loss time 0.001180 sec\n",
      "backward time 0.013387 sec\n",
      "optimizer time 0.024143 sec\n",
      "training time in round 134 cost 0.39804577827453613 sec\n",
      "loss 2.321255, train acc 0.099248\n",
      "round 135\n",
      "time to device 0.005351 sec\n",
      "time forward 1.837988 sec\n",
      "loss time 0.000545 sec\n",
      "backward time 0.004821 sec\n",
      "optimizer time 0.014923 sec\n",
      "training time in round 135 cost 0.35960984230041504 sec\n",
      "loss 2.321091, train acc 0.099552\n",
      "round 136\n",
      "time to device 0.003938 sec\n",
      "time forward 1.849171 sec\n",
      "loss time 0.001109 sec\n",
      "backward time 0.012378 sec\n",
      "optimizer time 0.026704 sec\n",
      "training time in round 136 cost 0.43139195442199707 sec\n",
      "loss 2.320976, train acc 0.099281\n",
      "round 137\n",
      "time to device 0.006329 sec\n",
      "time forward 1.860813 sec\n",
      "loss time 0.001057 sec\n",
      "backward time 0.010447 sec\n",
      "optimizer time 0.021222 sec\n",
      "training time in round 137 cost 0.3999507427215576 sec\n",
      "loss 2.324692, train acc 0.099468\n",
      "round 138\n",
      "time to device 0.006802 sec\n",
      "time forward 1.873834 sec\n",
      "loss time 0.000990 sec\n",
      "backward time 0.017992 sec\n",
      "optimizer time 0.016409 sec\n",
      "training time in round 138 cost 0.4037292003631592 sec\n",
      "loss 2.324517, train acc 0.099314\n",
      "round 139\n",
      "time to device 0.006205 sec\n",
      "time forward 1.881890 sec\n",
      "loss time 0.000802 sec\n",
      "backward time 0.006724 sec\n",
      "optimizer time 0.016357 sec\n",
      "training time in round 139 cost 0.38093090057373047 sec\n",
      "loss 2.324328, train acc 0.099051\n",
      "round 140\n",
      "time to device 0.007160 sec\n",
      "time forward 1.894816 sec\n",
      "loss time 0.001076 sec\n",
      "backward time 0.022573 sec\n",
      "optimizer time 0.017970 sec\n",
      "training time in round 140 cost 0.40930891036987305 sec\n",
      "loss 2.324356, train acc 0.099457\n",
      "round 141\n",
      "time to device 0.006853 sec\n",
      "time forward 1.906392 sec\n",
      "loss time 0.001080 sec\n",
      "backward time 0.013238 sec\n",
      "optimizer time 0.020167 sec\n",
      "training time in round 141 cost 0.4071033000946045 sec\n",
      "loss 2.324375, train acc 0.099527\n",
      "round 142\n",
      "time to device 0.006703 sec\n",
      "time forward 1.915749 sec\n",
      "loss time 0.001251 sec\n",
      "backward time 0.005641 sec\n",
      "optimizer time 0.017521 sec\n",
      "training time in round 142 cost 0.3798961639404297 sec\n",
      "loss 2.324207, train acc 0.099432\n",
      "round 143\n",
      "time to device 0.019084 sec\n",
      "time forward 1.931994 sec\n",
      "loss time 0.000701 sec\n",
      "backward time 0.005551 sec\n",
      "optimizer time 0.017490 sec\n",
      "training time in round 143 cost 0.5289418697357178 sec\n",
      "loss 2.324012, train acc 0.099555\n",
      "round 144\n",
      "time to device 0.005369 sec\n",
      "time forward 1.938958 sec\n",
      "loss time 0.000852 sec\n",
      "backward time 0.007696 sec\n",
      "optimizer time 0.029821 sec\n",
      "training time in round 144 cost 0.41460680961608887 sec\n",
      "loss 2.324070, train acc 0.099623\n",
      "round 145\n",
      "time to device 0.006455 sec\n",
      "time forward 1.949503 sec\n",
      "loss time 0.000520 sec\n",
      "backward time 0.004853 sec\n",
      "optimizer time 0.016147 sec\n",
      "training time in round 145 cost 0.3647899627685547 sec\n",
      "loss 2.325154, train acc 0.099690\n",
      "round 146\n",
      "time to device 0.007113 sec\n",
      "time forward 1.955469 sec\n",
      "loss time 0.000560 sec\n",
      "backward time 0.004267 sec\n",
      "optimizer time 0.012660 sec\n",
      "training time in round 146 cost 0.36234068870544434 sec\n",
      "loss 2.324964, train acc 0.099649\n",
      "round 147\n",
      "time to device 0.006822 sec\n",
      "time forward 1.962158 sec\n",
      "loss time 0.000437 sec\n",
      "backward time 0.003822 sec\n",
      "optimizer time 0.013125 sec\n",
      "training time in round 147 cost 0.3678150177001953 sec\n",
      "loss 2.324847, train acc 0.099609\n",
      "round 148\n",
      "time to device 0.008397 sec\n",
      "time forward 1.969440 sec\n",
      "loss time 0.000800 sec\n",
      "backward time 0.006428 sec\n",
      "optimizer time 0.018218 sec\n",
      "training time in round 148 cost 0.38573694229125977 sec\n",
      "loss 2.324663, train acc 0.099622\n",
      "round 149\n",
      "time to device 0.005805 sec\n",
      "time forward 1.978013 sec\n",
      "loss time 0.000407 sec\n",
      "backward time 0.003984 sec\n",
      "optimizer time 0.014656 sec\n",
      "training time in round 149 cost 0.3748810291290283 sec\n",
      "loss 2.324789, train acc 0.099792\n",
      "round 150\n",
      "time to device 0.006995 sec\n",
      "time forward 1.989438 sec\n",
      "loss time 0.001096 sec\n",
      "backward time 0.008899 sec\n",
      "optimizer time 0.021581 sec\n",
      "training time in round 150 cost 0.39136672019958496 sec\n",
      "loss 2.324767, train acc 0.099803\n",
      "round 151\n",
      "time to device 0.006036 sec\n",
      "time forward 1.995182 sec\n",
      "loss time 0.000632 sec\n",
      "backward time 0.005996 sec\n",
      "optimizer time 0.015963 sec\n",
      "training time in round 151 cost 0.3515501022338867 sec\n",
      "loss 2.325035, train acc 0.099661\n",
      "round 152\n",
      "time to device 0.017977 sec\n",
      "time forward 2.010131 sec\n",
      "loss time 0.002001 sec\n",
      "backward time 0.016483 sec\n",
      "optimizer time 0.100372 sec\n",
      "training time in round 152 cost 0.5053417682647705 sec\n",
      "loss 2.324897, train acc 0.099826\n",
      "round 153\n",
      "time to device 0.006791 sec\n",
      "time forward 2.019905 sec\n",
      "loss time 0.000988 sec\n",
      "backward time 0.013422 sec\n",
      "optimizer time 0.017488 sec\n",
      "training time in round 153 cost 0.39892101287841797 sec\n",
      "loss 2.325285, train acc 0.099635\n",
      "round 154\n",
      "time to device 0.007620 sec\n",
      "time forward 2.026214 sec\n",
      "loss time 0.000662 sec\n",
      "backward time 0.006122 sec\n",
      "optimizer time 0.016159 sec\n",
      "training time in round 154 cost 0.37798213958740234 sec\n",
      "loss 2.325527, train acc 0.099647\n",
      "round 155\n",
      "time to device 0.007139 sec\n",
      "time forward 2.039033 sec\n",
      "loss time 0.002000 sec\n",
      "backward time 0.015964 sec\n",
      "optimizer time 0.025127 sec\n",
      "training time in round 155 cost 0.4148721694946289 sec\n",
      "loss 2.325356, train acc 0.099509\n",
      "round 156\n",
      "time to device 0.007451 sec\n",
      "time forward 2.051075 sec\n",
      "loss time 0.001565 sec\n",
      "backward time 0.013043 sec\n",
      "optimizer time 0.023366 sec\n",
      "training time in round 156 cost 0.41823840141296387 sec\n",
      "loss 2.325213, train acc 0.099721\n",
      "round 157\n",
      "time to device 0.007678 sec\n",
      "time forward 2.063110 sec\n",
      "loss time 0.001400 sec\n",
      "backward time 0.015427 sec\n",
      "optimizer time 0.025163 sec\n",
      "training time in round 157 cost 0.4163651466369629 sec\n",
      "loss 2.325098, train acc 0.099733\n",
      "round 158\n",
      "time to device 0.008244 sec\n",
      "time forward 2.074839 sec\n",
      "loss time 0.001102 sec\n",
      "backward time 0.013961 sec\n",
      "optimizer time 0.025497 sec\n",
      "training time in round 158 cost 0.4086768627166748 sec\n",
      "loss 2.324999, train acc 0.099646\n",
      "round 159\n",
      "time to device 0.011097 sec\n",
      "time forward 2.083905 sec\n",
      "loss time 0.000352 sec\n",
      "backward time 0.004850 sec\n",
      "optimizer time 0.011897 sec\n",
      "training time in round 159 cost 0.4455699920654297 sec\n",
      "loss 2.324841, train acc 0.099463\n",
      "round 160\n",
      "time to device 0.005252 sec\n",
      "time forward 2.090272 sec\n",
      "loss time 0.000475 sec\n",
      "backward time 0.007418 sec\n",
      "optimizer time 0.015075 sec\n",
      "training time in round 160 cost 0.41869497299194336 sec\n",
      "loss 2.324702, train acc 0.099573\n",
      "round 161\n",
      "time to device 0.009587 sec\n",
      "time forward 2.115487 sec\n",
      "loss time 0.001129 sec\n",
      "backward time 0.019246 sec\n",
      "optimizer time 0.068553 sec\n",
      "training time in round 161 cost 0.8071532249450684 sec\n",
      "loss 2.325888, train acc 0.099730\n",
      "round 162\n",
      "time to device 0.023503 sec\n",
      "time forward 2.125719 sec\n",
      "loss time 0.000498 sec\n",
      "backward time 0.004413 sec\n",
      "optimizer time 0.014834 sec\n",
      "training time in round 162 cost 0.5281281471252441 sec\n",
      "loss 2.325738, train acc 0.099981\n",
      "round 163\n",
      "time to device 0.008164 sec\n",
      "time forward 2.131481 sec\n",
      "loss time 0.000523 sec\n",
      "backward time 0.004778 sec\n",
      "optimizer time 0.017311 sec\n",
      "training time in round 163 cost 0.37735486030578613 sec\n",
      "loss 2.325591, train acc 0.099705\n",
      "round 164\n",
      "time to device 0.006272 sec\n",
      "time forward 2.137320 sec\n",
      "loss time 0.000465 sec\n",
      "backward time 0.005664 sec\n",
      "optimizer time 0.017290 sec\n",
      "training time in round 164 cost 0.3685109615325928 sec\n",
      "loss 2.325433, train acc 0.099858\n",
      "round 165\n",
      "time to device 0.008061 sec\n",
      "time forward 2.146255 sec\n",
      "loss time 0.000627 sec\n",
      "backward time 0.005230 sec\n",
      "optimizer time 0.014437 sec\n",
      "training time in round 165 cost 0.38582706451416016 sec\n",
      "loss 2.325409, train acc 0.099774\n",
      "round 166\n",
      "time to device 0.005737 sec\n",
      "time forward 2.154539 sec\n",
      "loss time 0.000415 sec\n",
      "backward time 0.004935 sec\n",
      "optimizer time 0.014719 sec\n",
      "training time in round 166 cost 0.3811330795288086 sec\n",
      "loss 2.325270, train acc 0.099785\n",
      "round 167\n",
      "time to device 0.004765 sec\n",
      "time forward 2.159508 sec\n",
      "loss time 0.000456 sec\n",
      "backward time 0.005205 sec\n",
      "optimizer time 0.013442 sec\n",
      "training time in round 167 cost 0.3453221321105957 sec\n",
      "loss 2.325305, train acc 0.100121\n",
      "round 168\n",
      "time to device 0.006241 sec\n",
      "time forward 2.164005 sec\n",
      "loss time 0.000431 sec\n",
      "backward time 0.003658 sec\n",
      "optimizer time 0.011002 sec\n",
      "training time in round 168 cost 0.3351621627807617 sec\n",
      "loss 2.325409, train acc 0.099898\n",
      "round 169\n",
      "time to device 0.004834 sec\n",
      "time forward 2.169975 sec\n",
      "loss time 0.000628 sec\n",
      "backward time 0.005982 sec\n",
      "optimizer time 0.016652 sec\n",
      "training time in round 169 cost 0.3733229637145996 sec\n",
      "loss 2.325301, train acc 0.099678\n",
      "round 170\n",
      "time to device 0.004692 sec\n",
      "time forward 2.175796 sec\n",
      "loss time 0.000859 sec\n",
      "backward time 0.007545 sec\n",
      "optimizer time 0.020929 sec\n",
      "training time in round 170 cost 0.3735983371734619 sec\n",
      "loss 2.325211, train acc 0.099552\n",
      "round 171\n",
      "time to device 0.007634 sec\n",
      "time forward 2.182410 sec\n",
      "loss time 0.000493 sec\n",
      "backward time 0.004090 sec\n",
      "optimizer time 0.014991 sec\n",
      "training time in round 171 cost 0.3799448013305664 sec\n",
      "loss 2.325093, train acc 0.099655\n",
      "round 172\n",
      "time to device 0.006076 sec\n",
      "time forward 2.188096 sec\n",
      "loss time 0.000432 sec\n",
      "backward time 0.003992 sec\n",
      "optimizer time 0.012751 sec\n",
      "training time in round 172 cost 0.3718698024749756 sec\n",
      "loss 2.325381, train acc 0.099711\n",
      "round 173\n",
      "time to device 0.006157 sec\n",
      "time forward 2.194015 sec\n",
      "loss time 0.000784 sec\n",
      "backward time 0.004669 sec\n",
      "optimizer time 0.018559 sec\n",
      "training time in round 173 cost 0.40367698669433594 sec\n",
      "loss 2.325228, train acc 0.099677\n",
      "round 174\n",
      "time to device 0.005990 sec\n",
      "time forward 2.201004 sec\n",
      "loss time 0.000444 sec\n",
      "backward time 0.004015 sec\n",
      "optimizer time 0.017182 sec\n",
      "training time in round 174 cost 0.40453600883483887 sec\n",
      "loss 2.325121, train acc 0.099375\n",
      "round 175\n",
      "time to device 0.005307 sec\n",
      "time forward 2.214031 sec\n",
      "loss time 0.000483 sec\n",
      "backward time 0.005914 sec\n",
      "optimizer time 0.015599 sec\n",
      "training time in round 175 cost 0.43265581130981445 sec\n",
      "loss 2.325026, train acc 0.099165\n",
      "round 176\n",
      "time to device 0.007661 sec\n",
      "time forward 2.221313 sec\n",
      "loss time 0.000642 sec\n",
      "backward time 0.005743 sec\n",
      "optimizer time 0.018596 sec\n",
      "training time in round 176 cost 0.3782639503479004 sec\n",
      "loss 2.324945, train acc 0.099356\n",
      "round 177\n",
      "time to device 0.007570 sec\n",
      "time forward 2.227316 sec\n",
      "loss time 0.000543 sec\n",
      "backward time 0.004449 sec\n",
      "optimizer time 0.013416 sec\n",
      "training time in round 177 cost 0.371675968170166 sec\n",
      "loss 2.324847, train acc 0.099192\n",
      "round 178\n",
      "time to device 0.006816 sec\n",
      "time forward 2.235411 sec\n",
      "loss time 0.001092 sec\n",
      "backward time 0.008512 sec\n",
      "optimizer time 0.020978 sec\n",
      "training time in round 178 cost 0.3984830379486084 sec\n",
      "loss 2.325323, train acc 0.099031\n",
      "round 179\n",
      "time to device 0.006001 sec\n",
      "time forward 2.242221 sec\n",
      "loss time 0.000406 sec\n",
      "backward time 0.004054 sec\n",
      "optimizer time 0.013462 sec\n",
      "training time in round 179 cost 0.36824607849121094 sec\n",
      "loss 2.325151, train acc 0.099219\n",
      "round 180\n",
      "time to device 0.006780 sec\n",
      "time forward 2.251227 sec\n",
      "loss time 0.001124 sec\n",
      "backward time 0.009843 sec\n",
      "optimizer time 0.021844 sec\n",
      "training time in round 180 cost 0.37545180320739746 sec\n",
      "loss 2.327383, train acc 0.099361\n",
      "round 181\n",
      "time to device 0.006884 sec\n",
      "time forward 2.261521 sec\n",
      "loss time 0.001102 sec\n",
      "backward time 0.008495 sec\n",
      "optimizer time 0.021256 sec\n",
      "training time in round 181 cost 0.3832368850708008 sec\n",
      "loss 2.327648, train acc 0.099159\n",
      "round 182\n",
      "time to device 0.005483 sec\n",
      "time forward 2.267816 sec\n",
      "loss time 0.000736 sec\n",
      "backward time 0.006218 sec\n",
      "optimizer time 0.015943 sec\n",
      "training time in round 182 cost 0.36659717559814453 sec\n",
      "loss 2.327534, train acc 0.099129\n",
      "round 183\n",
      "time to device 0.005918 sec\n",
      "time forward 2.273032 sec\n",
      "loss time 0.000527 sec\n",
      "backward time 0.004309 sec\n",
      "optimizer time 0.014762 sec\n",
      "training time in round 183 cost 0.34239792823791504 sec\n",
      "loss 2.330782, train acc 0.099270\n",
      "round 184\n",
      "time to device 0.006934 sec\n",
      "time forward 2.280953 sec\n",
      "loss time 0.000911 sec\n",
      "backward time 0.013897 sec\n",
      "optimizer time 0.025166 sec\n",
      "training time in round 184 cost 0.38846707344055176 sec\n",
      "loss 2.330617, train acc 0.099155\n",
      "round 185\n",
      "time to device 0.007204 sec\n",
      "time forward 2.291585 sec\n",
      "loss time 0.000923 sec\n",
      "backward time 0.008286 sec\n",
      "optimizer time 0.020667 sec\n",
      "training time in round 185 cost 0.37424302101135254 sec\n",
      "loss 2.330466, train acc 0.099126\n",
      "round 186\n",
      "time to device 0.005601 sec\n",
      "time forward 2.296857 sec\n",
      "loss time 0.000475 sec\n",
      "backward time 0.004449 sec\n",
      "optimizer time 0.015272 sec\n",
      "training time in round 186 cost 0.34424495697021484 sec\n",
      "loss 2.330323, train acc 0.099181\n",
      "round 187\n",
      "time to device 0.007165 sec\n",
      "time forward 2.312199 sec\n",
      "loss time 0.000960 sec\n",
      "backward time 0.011254 sec\n",
      "optimizer time 0.018009 sec\n",
      "training time in round 187 cost 0.6358981132507324 sec\n",
      "loss 2.330121, train acc 0.099152\n",
      "round 188\n",
      "time to device 0.006930 sec\n",
      "time forward 2.329453 sec\n",
      "loss time 0.001376 sec\n",
      "backward time 0.012032 sec\n",
      "optimizer time 0.020827 sec\n",
      "training time in round 188 cost 0.5152909755706787 sec\n",
      "loss 2.330068, train acc 0.099041\n",
      "round 189\n",
      "time to device 0.008383 sec\n",
      "time forward 2.345013 sec\n",
      "loss time 0.001720 sec\n",
      "backward time 0.017487 sec\n",
      "optimizer time 0.023344 sec\n",
      "training time in round 189 cost 0.4166371822357178 sec\n",
      "loss 2.329860, train acc 0.099178\n",
      "round 190\n",
      "time to device 0.008135 sec\n",
      "time forward 2.357663 sec\n",
      "loss time 0.001459 sec\n",
      "backward time 0.013287 sec\n",
      "optimizer time 0.021825 sec\n",
      "training time in round 190 cost 0.41009998321533203 sec\n",
      "loss 2.329725, train acc 0.099231\n",
      "round 191\n",
      "time to device 0.016827 sec\n",
      "time forward 2.372375 sec\n",
      "loss time 0.001428 sec\n",
      "backward time 0.015594 sec\n",
      "optimizer time 0.023618 sec\n",
      "training time in round 191 cost 0.4369852542877197 sec\n",
      "loss 2.329790, train acc 0.099162\n",
      "round 192\n",
      "time to device 0.007813 sec\n",
      "time forward 2.385831 sec\n",
      "loss time 0.001145 sec\n",
      "backward time 0.014058 sec\n",
      "optimizer time 0.025650 sec\n",
      "training time in round 192 cost 0.3984079360961914 sec\n",
      "loss 2.329640, train acc 0.099134\n",
      "round 193\n",
      "time to device 0.008196 sec\n",
      "time forward 2.398800 sec\n",
      "loss time 0.001179 sec\n",
      "backward time 0.011958 sec\n",
      "optimizer time 0.023558 sec\n",
      "training time in round 193 cost 0.4034543037414551 sec\n",
      "loss 2.329486, train acc 0.099307\n",
      "round 194\n",
      "time to device 0.009153 sec\n",
      "time forward 2.413452 sec\n",
      "loss time 0.001381 sec\n",
      "backward time 0.015354 sec\n",
      "optimizer time 0.025621 sec\n",
      "training time in round 194 cost 0.4079139232635498 sec\n",
      "loss 2.329342, train acc 0.099159\n",
      "round 195\n",
      "time to device 0.006628 sec\n",
      "time forward 2.428081 sec\n",
      "loss time 0.001853 sec\n",
      "backward time 0.011312 sec\n",
      "optimizer time 0.022941 sec\n",
      "training time in round 195 cost 0.3993687629699707 sec\n",
      "loss 2.329220, train acc 0.098932\n",
      "round 196\n",
      "time to device 0.008871 sec\n",
      "time forward 2.441753 sec\n",
      "loss time 0.001630 sec\n",
      "backward time 0.019960 sec\n",
      "optimizer time 0.024971 sec\n",
      "training time in round 196 cost 0.44262099266052246 sec\n",
      "loss 2.329121, train acc 0.098826\n",
      "round 197\n",
      "time to device 0.007725 sec\n",
      "time forward 2.451421 sec\n",
      "loss time 0.001401 sec\n",
      "backward time 0.011292 sec\n",
      "optimizer time 0.019386 sec\n",
      "training time in round 197 cost 0.46860694885253906 sec\n",
      "loss 2.328959, train acc 0.098919\n",
      "round 198\n",
      "time to device 0.006733 sec\n",
      "time forward 2.463569 sec\n",
      "loss time 0.001656 sec\n",
      "backward time 0.014373 sec\n",
      "optimizer time 0.024420 sec\n",
      "training time in round 198 cost 0.4061739444732666 sec\n",
      "loss 2.328875, train acc 0.098657\n",
      "round 199\n",
      "time to device 0.007324 sec\n",
      "time forward 2.475188 sec\n",
      "loss time 0.002510 sec\n",
      "backward time 0.024003 sec\n",
      "optimizer time 0.022960 sec\n",
      "training time in round 199 cost 0.40172910690307617 sec\n",
      "loss 2.328751, train acc 0.098594\n",
      "round 200\n",
      "time to device 0.006604 sec\n",
      "time forward 2.489959 sec\n",
      "loss time 0.001361 sec\n",
      "backward time 0.010224 sec\n",
      "optimizer time 0.022217 sec\n",
      "training time in round 200 cost 0.4106638431549072 sec\n",
      "loss 2.328607, train acc 0.098492\n",
      "round 201\n",
      "time to device 0.009374 sec\n",
      "time forward 2.503240 sec\n",
      "loss time 0.001268 sec\n",
      "backward time 0.017311 sec\n",
      "optimizer time 0.025533 sec\n",
      "training time in round 201 cost 0.4440150260925293 sec\n",
      "loss 2.328595, train acc 0.098507\n",
      "round 202\n",
      "time to device 0.009110 sec\n",
      "time forward 2.516655 sec\n",
      "loss time 0.001155 sec\n",
      "backward time 0.013255 sec\n",
      "optimizer time 0.024199 sec\n",
      "training time in round 202 cost 0.4022679328918457 sec\n",
      "loss 2.328470, train acc 0.098676\n",
      "round 203\n",
      "time to device 0.008405 sec\n",
      "time forward 2.535148 sec\n",
      "loss time 0.001503 sec\n",
      "backward time 0.010727 sec\n",
      "optimizer time 0.029967 sec\n",
      "training time in round 203 cost 0.41706228256225586 sec\n",
      "loss 2.328334, train acc 0.098729\n",
      "round 204\n",
      "time to device 0.007786 sec\n",
      "time forward 2.550772 sec\n",
      "loss time 0.001157 sec\n",
      "backward time 0.019798 sec\n",
      "optimizer time 0.023991 sec\n",
      "training time in round 204 cost 0.41230273246765137 sec\n",
      "loss 2.328258, train acc 0.098780\n",
      "round 205\n",
      "time to device 0.007420 sec\n",
      "time forward 2.563349 sec\n",
      "loss time 0.001088 sec\n",
      "backward time 0.009779 sec\n",
      "optimizer time 0.028901 sec\n",
      "training time in round 205 cost 0.3967452049255371 sec\n",
      "loss 2.328356, train acc 0.098718\n",
      "round 206\n",
      "time to device 0.006870 sec\n",
      "time forward 2.581176 sec\n",
      "loss time 0.001215 sec\n",
      "backward time 0.011335 sec\n",
      "optimizer time 0.028519 sec\n",
      "training time in round 206 cost 0.4205300807952881 sec\n",
      "loss 2.328241, train acc 0.098732\n",
      "round 207\n",
      "time to device 0.007721 sec\n",
      "time forward 2.592880 sec\n",
      "loss time 0.002200 sec\n",
      "backward time 0.014628 sec\n",
      "optimizer time 0.023865 sec\n",
      "training time in round 207 cost 0.39159727096557617 sec\n",
      "loss 2.328142, train acc 0.098745\n",
      "round 208\n",
      "time to device 0.007272 sec\n",
      "time forward 2.603418 sec\n",
      "loss time 0.001677 sec\n",
      "backward time 0.013696 sec\n",
      "optimizer time 0.021577 sec\n",
      "training time in round 208 cost 0.38740992546081543 sec\n",
      "loss 2.328027, train acc 0.098535\n",
      "round 209\n",
      "time to device 0.008930 sec\n",
      "time forward 2.611435 sec\n",
      "loss time 0.000572 sec\n",
      "backward time 0.004532 sec\n",
      "optimizer time 0.012962 sec\n",
      "training time in round 209 cost 0.38103485107421875 sec\n",
      "loss 2.327966, train acc 0.098549\n",
      "round 210\n",
      "time to device 0.007489 sec\n",
      "time forward 2.624613 sec\n",
      "loss time 0.001029 sec\n",
      "backward time 0.012519 sec\n",
      "optimizer time 0.027635 sec\n",
      "training time in round 210 cost 0.4070720672607422 sec\n",
      "loss 2.327853, train acc 0.098674\n",
      "round 211\n",
      "time to device 0.004021 sec\n",
      "time forward 2.635527 sec\n",
      "loss time 0.001300 sec\n",
      "backward time 0.012028 sec\n",
      "optimizer time 0.026656 sec\n",
      "training time in round 211 cost 0.39011311531066895 sec\n",
      "loss 2.327727, train acc 0.098614\n",
      "round 212\n",
      "time to device 0.003874 sec\n",
      "time forward 2.647785 sec\n",
      "loss time 0.001440 sec\n",
      "backward time 0.014391 sec\n",
      "optimizer time 0.024269 sec\n",
      "training time in round 212 cost 0.3896620273590088 sec\n",
      "loss 2.327615, train acc 0.098665\n",
      "round 213\n",
      "time to device 0.003634 sec\n",
      "time forward 2.659497 sec\n",
      "loss time 0.001425 sec\n",
      "backward time 0.010716 sec\n",
      "optimizer time 0.027937 sec\n",
      "training time in round 213 cost 0.40314769744873047 sec\n",
      "loss 2.327657, train acc 0.098569\n",
      "round 214\n",
      "time to device 0.003406 sec\n",
      "time forward 2.672611 sec\n",
      "loss time 0.001438 sec\n",
      "backward time 0.013606 sec\n",
      "optimizer time 0.013750 sec\n",
      "training time in round 214 cost 0.39145398139953613 sec\n",
      "loss 2.327540, train acc 0.098619\n",
      "round 215\n",
      "time to device 0.003474 sec\n",
      "time forward 2.684561 sec\n",
      "loss time 0.002057 sec\n",
      "backward time 0.010942 sec\n",
      "optimizer time 0.028882 sec\n",
      "training time in round 215 cost 0.4024620056152344 sec\n",
      "loss 2.327429, train acc 0.098597\n",
      "round 216\n",
      "time to device 0.002468 sec\n",
      "time forward 2.696217 sec\n",
      "loss time 0.002024 sec\n",
      "backward time 0.019056 sec\n",
      "optimizer time 0.039732 sec\n",
      "training time in round 216 cost 0.41247081756591797 sec\n",
      "loss 2.327304, train acc 0.098682\n",
      "round 217\n",
      "time to device 0.003718 sec\n",
      "time forward 2.709481 sec\n",
      "loss time 0.001279 sec\n",
      "backward time 0.014177 sec\n",
      "optimizer time 0.023043 sec\n",
      "training time in round 217 cost 0.39481019973754883 sec\n",
      "loss 2.327196, train acc 0.098552\n",
      "round 218\n",
      "time to device 0.004057 sec\n",
      "time forward 2.721566 sec\n",
      "loss time 0.001550 sec\n",
      "backward time 0.013951 sec\n",
      "optimizer time 0.029205 sec\n",
      "training time in round 218 cost 0.43545079231262207 sec\n",
      "loss 2.327092, train acc 0.098566\n",
      "round 219\n",
      "time to device 0.006515 sec\n",
      "time forward 2.734888 sec\n",
      "loss time 0.000972 sec\n",
      "backward time 0.013565 sec\n",
      "optimizer time 0.022339 sec\n",
      "training time in round 219 cost 0.420896053314209 sec\n",
      "loss 2.326995, train acc 0.098580\n",
      "round 220\n",
      "time to device 0.007032 sec\n",
      "time forward 2.746538 sec\n",
      "loss time 0.001082 sec\n",
      "backward time 0.013732 sec\n",
      "optimizer time 0.028717 sec\n",
      "training time in round 220 cost 0.3955252170562744 sec\n",
      "loss 2.326895, train acc 0.098593\n",
      "round 221\n",
      "time to device 0.007421 sec\n",
      "time forward 2.757194 sec\n",
      "loss time 0.001408 sec\n",
      "backward time 0.010650 sec\n",
      "optimizer time 0.032579 sec\n",
      "training time in round 221 cost 0.39965295791625977 sec\n",
      "loss 2.326763, train acc 0.098677\n",
      "round 222\n",
      "time to device 0.008157 sec\n",
      "time forward 2.771090 sec\n",
      "loss time 0.001040 sec\n",
      "backward time 0.011664 sec\n",
      "optimizer time 0.025883 sec\n",
      "training time in round 222 cost 0.4010009765625 sec\n",
      "loss 2.326668, train acc 0.098620\n",
      "round 223\n",
      "time to device 0.016772 sec\n",
      "time forward 2.782745 sec\n",
      "loss time 0.001135 sec\n",
      "backward time 0.014488 sec\n",
      "optimizer time 0.022485 sec\n",
      "training time in round 223 cost 0.4073941707611084 sec\n",
      "loss 2.326568, train acc 0.098668\n",
      "round 224\n",
      "time to device 0.007153 sec\n",
      "time forward 2.795102 sec\n",
      "loss time 0.001055 sec\n",
      "backward time 0.012099 sec\n",
      "optimizer time 0.029361 sec\n",
      "training time in round 224 cost 0.3964552879333496 sec\n",
      "loss 2.326469, train acc 0.098576\n",
      "round 225\n",
      "time to device 0.007518 sec\n",
      "time forward 2.807930 sec\n",
      "loss time 0.001632 sec\n",
      "backward time 0.014902 sec\n",
      "optimizer time 0.027791 sec\n",
      "training time in round 225 cost 0.40955114364624023 sec\n",
      "loss 2.326375, train acc 0.098486\n",
      "round 226\n",
      "time to device 0.008298 sec\n",
      "time forward 2.814191 sec\n",
      "loss time 0.000442 sec\n",
      "backward time 0.004061 sec\n",
      "optimizer time 0.011650 sec\n",
      "training time in round 226 cost 0.3703761100769043 sec\n",
      "loss 2.326399, train acc 0.098706\n",
      "round 227\n",
      "time to device 0.007610 sec\n",
      "time forward 2.825799 sec\n",
      "loss time 0.001463 sec\n",
      "backward time 0.011921 sec\n",
      "optimizer time 0.030261 sec\n",
      "training time in round 227 cost 0.42969393730163574 sec\n",
      "loss 2.326310, train acc 0.098753\n",
      "round 228\n",
      "time to device 0.009277 sec\n",
      "time forward 2.843426 sec\n",
      "loss time 0.001505 sec\n",
      "backward time 0.011957 sec\n",
      "optimizer time 0.023022 sec\n",
      "training time in round 228 cost 0.4262120723724365 sec\n",
      "loss 2.326205, train acc 0.098799\n",
      "round 229\n",
      "time to device 0.006806 sec\n",
      "time forward 2.855327 sec\n",
      "loss time 0.001540 sec\n",
      "backward time 0.011534 sec\n",
      "optimizer time 0.020007 sec\n",
      "training time in round 229 cost 0.4258129596710205 sec\n",
      "loss 2.326180, train acc 0.098947\n",
      "round 230\n",
      "time to device 0.007100 sec\n",
      "time forward 2.868515 sec\n",
      "loss time 0.001767 sec\n",
      "backward time 0.012076 sec\n",
      "optimizer time 0.021711 sec\n",
      "training time in round 230 cost 0.41547322273254395 sec\n",
      "loss 2.326166, train acc 0.098992\n",
      "round 231\n",
      "time to device 0.006897 sec\n",
      "time forward 2.881768 sec\n",
      "loss time 0.001474 sec\n",
      "backward time 0.015079 sec\n",
      "optimizer time 0.022237 sec\n",
      "training time in round 231 cost 0.4098210334777832 sec\n",
      "loss 2.326115, train acc 0.098970\n",
      "round 232\n",
      "time to device 0.007787 sec\n",
      "time forward 2.896769 sec\n",
      "loss time 0.001098 sec\n",
      "backward time 0.012783 sec\n",
      "optimizer time 0.027160 sec\n",
      "training time in round 232 cost 0.41747307777404785 sec\n",
      "loss 2.326052, train acc 0.098914\n",
      "round 233\n",
      "time to device 0.007105 sec\n",
      "time forward 2.910190 sec\n",
      "loss time 0.001279 sec\n",
      "backward time 0.015151 sec\n",
      "optimizer time 0.027699 sec\n",
      "training time in round 233 cost 0.4068310260772705 sec\n",
      "loss 2.325971, train acc 0.098691\n",
      "round 234\n",
      "time to device 0.006816 sec\n",
      "time forward 2.916927 sec\n",
      "loss time 0.000596 sec\n",
      "backward time 0.005450 sec\n",
      "optimizer time 0.014025 sec\n",
      "training time in round 234 cost 0.3853189945220947 sec\n",
      "loss 2.325865, train acc 0.098703\n",
      "round 235\n",
      "time to device 0.007075 sec\n",
      "time forward 2.928776 sec\n",
      "loss time 0.002027 sec\n",
      "backward time 0.011824 sec\n",
      "optimizer time 0.023542 sec\n",
      "training time in round 235 cost 0.40828990936279297 sec\n",
      "loss 2.325763, train acc 0.098815\n",
      "round 236\n",
      "time to device 0.006602 sec\n",
      "time forward 2.946843 sec\n",
      "loss time 0.001067 sec\n",
      "backward time 0.014308 sec\n",
      "optimizer time 0.018010 sec\n",
      "training time in round 236 cost 0.41881299018859863 sec\n",
      "loss 2.325681, train acc 0.098728\n",
      "round 237\n",
      "time to device 0.007215 sec\n",
      "time forward 2.962061 sec\n",
      "loss time 0.001269 sec\n",
      "backward time 0.012298 sec\n",
      "optimizer time 0.014168 sec\n",
      "training time in round 237 cost 0.40610504150390625 sec\n",
      "loss 2.325584, train acc 0.098871\n",
      "round 238\n",
      "time to device 0.007882 sec\n",
      "time forward 2.974273 sec\n",
      "loss time 0.001361 sec\n",
      "backward time 0.016810 sec\n",
      "optimizer time 0.025246 sec\n",
      "training time in round 238 cost 0.39763689041137695 sec\n",
      "loss 2.325490, train acc 0.098719\n",
      "round 239\n",
      "time to device 0.006938 sec\n",
      "time forward 2.987893 sec\n",
      "loss time 0.001121 sec\n",
      "backward time 0.015285 sec\n",
      "optimizer time 0.024039 sec\n",
      "training time in round 239 cost 0.4003407955169678 sec\n",
      "loss 2.325396, train acc 0.098730\n",
      "round 240\n",
      "time to device 0.003299 sec\n",
      "time forward 3.000161 sec\n",
      "loss time 0.001475 sec\n",
      "backward time 0.013839 sec\n",
      "optimizer time 0.029743 sec\n",
      "training time in round 240 cost 0.3993229866027832 sec\n",
      "loss 2.325305, train acc 0.098613\n",
      "round 241\n",
      "time to device 0.003184 sec\n",
      "time forward 3.017022 sec\n",
      "loss time 0.001005 sec\n",
      "backward time 0.013395 sec\n",
      "optimizer time 0.025057 sec\n",
      "training time in round 241 cost 0.4127769470214844 sec\n",
      "loss 2.325220, train acc 0.098463\n",
      "round 242\n",
      "time to device 0.003854 sec\n",
      "time forward 3.035559 sec\n",
      "loss time 0.001149 sec\n",
      "backward time 0.015074 sec\n",
      "optimizer time 0.032101 sec\n",
      "training time in round 242 cost 0.4249420166015625 sec\n",
      "loss 2.325139, train acc 0.098605\n",
      "round 243\n",
      "time to device 0.003668 sec\n",
      "time forward 3.047958 sec\n",
      "loss time 0.001570 sec\n",
      "backward time 0.013513 sec\n",
      "optimizer time 0.024656 sec\n",
      "training time in round 243 cost 0.3916049003601074 sec\n",
      "loss 2.325039, train acc 0.098521\n",
      "round 244\n",
      "time to device 0.004040 sec\n",
      "time forward 3.060574 sec\n",
      "loss time 0.001516 sec\n",
      "backward time 0.017213 sec\n",
      "optimizer time 0.027896 sec\n",
      "training time in round 244 cost 0.3969709873199463 sec\n",
      "loss 2.324961, train acc 0.098565\n",
      "round 245\n",
      "time to device 0.003373 sec\n",
      "time forward 3.072917 sec\n",
      "loss time 0.004971 sec\n",
      "backward time 0.020876 sec\n",
      "optimizer time 0.016333 sec\n",
      "training time in round 245 cost 0.4187922477722168 sec\n",
      "loss 2.324880, train acc 0.098418\n",
      "round 246\n",
      "time to device 0.004806 sec\n",
      "time forward 3.086488 sec\n",
      "loss time 0.001874 sec\n",
      "backward time 0.016103 sec\n",
      "optimizer time 0.029542 sec\n",
      "training time in round 246 cost 0.4505579471588135 sec\n",
      "loss 2.324904, train acc 0.098463\n",
      "round 247\n",
      "time to device 0.003470 sec\n",
      "time forward 3.099082 sec\n",
      "loss time 0.001078 sec\n",
      "backward time 0.021861 sec\n",
      "optimizer time 0.025634 sec\n",
      "training time in round 247 cost 0.4040048122406006 sec\n",
      "loss 2.324819, train acc 0.098444\n",
      "round 248\n",
      "time to device 0.003723 sec\n",
      "time forward 3.112715 sec\n",
      "loss time 0.001203 sec\n",
      "backward time 0.022607 sec\n",
      "optimizer time 0.026725 sec\n",
      "training time in round 248 cost 0.4278428554534912 sec\n",
      "loss 2.324737, train acc 0.098425\n",
      "round 249\n",
      "time to device 0.008075 sec\n",
      "time forward 3.126956 sec\n",
      "loss time 0.001008 sec\n",
      "backward time 0.011043 sec\n",
      "optimizer time 0.023857 sec\n",
      "training time in round 249 cost 0.42916083335876465 sec\n",
      "loss 2.324690, train acc 0.098437\n",
      "round 250\n",
      "time to device 0.003705 sec\n",
      "time forward 3.142587 sec\n",
      "loss time 0.001088 sec\n",
      "backward time 0.014969 sec\n",
      "optimizer time 0.034771 sec\n",
      "training time in round 250 cost 0.42902588844299316 sec\n",
      "loss 2.324624, train acc 0.098388\n",
      "round 251\n",
      "time to device 0.005489 sec\n",
      "time forward 3.158050 sec\n",
      "loss time 0.001359 sec\n",
      "backward time 0.015011 sec\n",
      "optimizer time 0.028260 sec\n",
      "training time in round 251 cost 0.418895959854126 sec\n",
      "loss 2.324522, train acc 0.098493\n",
      "round 252\n",
      "time to device 0.015031 sec\n",
      "time forward 3.169430 sec\n",
      "loss time 0.003043 sec\n",
      "backward time 0.012344 sec\n",
      "optimizer time 0.028169 sec\n",
      "training time in round 252 cost 0.4151759147644043 sec\n",
      "loss 2.324446, train acc 0.098413\n",
      "round 253\n",
      "time to device 0.007210 sec\n",
      "time forward 3.184758 sec\n",
      "loss time 0.001581 sec\n",
      "backward time 0.014969 sec\n",
      "optimizer time 0.027162 sec\n",
      "training time in round 253 cost 0.4246370792388916 sec\n",
      "loss 2.324355, train acc 0.098271\n",
      "round 254\n",
      "time to device 0.007329 sec\n",
      "time forward 3.199154 sec\n",
      "loss time 0.001773 sec\n",
      "backward time 0.013434 sec\n",
      "optimizer time 0.031404 sec\n",
      "training time in round 254 cost 0.4800570011138916 sec\n",
      "loss 2.324279, train acc 0.098346\n",
      "round 255\n",
      "time to device 0.006444 sec\n",
      "time forward 3.207025 sec\n",
      "loss time 0.000507 sec\n",
      "backward time 0.004268 sec\n",
      "optimizer time 0.012995 sec\n",
      "training time in round 255 cost 0.3995399475097656 sec\n",
      "loss 2.324213, train acc 0.098328\n",
      "round 256\n",
      "time to device 0.006830 sec\n",
      "time forward 3.221635 sec\n",
      "loss time 0.001224 sec\n",
      "backward time 0.012547 sec\n",
      "optimizer time 0.024447 sec\n",
      "training time in round 256 cost 0.41718506813049316 sec\n",
      "loss 2.324140, train acc 0.098249\n",
      "round 257\n",
      "time to device 0.006909 sec\n",
      "time forward 3.235969 sec\n",
      "loss time 0.002082 sec\n",
      "backward time 0.014857 sec\n",
      "optimizer time 0.023491 sec\n",
      "training time in round 257 cost 0.4330179691314697 sec\n",
      "loss 2.324077, train acc 0.098292\n",
      "round 258\n",
      "time to device 0.013461 sec\n",
      "time forward 3.247273 sec\n",
      "loss time 0.000633 sec\n",
      "backward time 0.008230 sec\n",
      "optimizer time 0.020820 sec\n",
      "training time in round 258 cost 0.3996100425720215 sec\n",
      "loss 2.323984, train acc 0.098214\n",
      "round 259\n",
      "time to device 0.025186 sec\n",
      "time forward 3.261890 sec\n",
      "loss time 0.000446 sec\n",
      "backward time 0.004170 sec\n",
      "optimizer time 0.012696 sec\n",
      "training time in round 259 cost 0.4874298572540283 sec\n",
      "loss 2.323887, train acc 0.098197\n",
      "round 260\n",
      "time to device 0.007153 sec\n",
      "time forward 3.272267 sec\n",
      "loss time 0.001061 sec\n",
      "backward time 0.008526 sec\n",
      "optimizer time 0.023868 sec\n",
      "training time in round 260 cost 0.42244887351989746 sec\n",
      "loss 2.323788, train acc 0.098210\n",
      "round 261\n",
      "time to device 0.006136 sec\n",
      "time forward 3.280184 sec\n",
      "loss time 0.000862 sec\n",
      "backward time 0.008686 sec\n",
      "optimizer time 0.021771 sec\n",
      "training time in round 261 cost 0.3851940631866455 sec\n",
      "loss 2.323704, train acc 0.098133\n",
      "round 262\n",
      "time to device 0.007565 sec\n",
      "time forward 3.286638 sec\n",
      "loss time 0.000805 sec\n",
      "backward time 0.006232 sec\n",
      "optimizer time 0.016566 sec\n",
      "training time in round 262 cost 0.36904335021972656 sec\n",
      "loss 2.323635, train acc 0.098176\n",
      "round 263\n",
      "time to device 0.007625 sec\n",
      "time forward 3.293721 sec\n",
      "loss time 0.000677 sec\n",
      "backward time 0.005809 sec\n",
      "optimizer time 0.019857 sec\n",
      "training time in round 263 cost 0.3741312026977539 sec\n",
      "loss 2.323645, train acc 0.098189\n",
      "round 264\n",
      "time to device 0.006093 sec\n",
      "time forward 3.299041 sec\n",
      "loss time 0.000574 sec\n",
      "backward time 0.005323 sec\n",
      "optimizer time 0.015532 sec\n",
      "training time in round 264 cost 0.3655691146850586 sec\n",
      "loss 2.323557, train acc 0.098320\n",
      "round 265\n",
      "time to device 0.006735 sec\n",
      "time forward 3.305788 sec\n",
      "loss time 0.000839 sec\n",
      "backward time 0.007415 sec\n",
      "optimizer time 0.017000 sec\n",
      "training time in round 265 cost 0.3664729595184326 sec\n",
      "loss 2.323628, train acc 0.098273\n",
      "round 266\n",
      "time to device 0.008159 sec\n",
      "time forward 3.311739 sec\n",
      "loss time 0.000699 sec\n",
      "backward time 0.006536 sec\n",
      "optimizer time 0.015568 sec\n",
      "training time in round 266 cost 0.39235472679138184 sec\n",
      "loss 2.323523, train acc 0.098315\n",
      "round 267\n",
      "time to device 0.007198 sec\n",
      "time forward 3.319087 sec\n",
      "loss time 0.000714 sec\n",
      "backward time 0.006360 sec\n",
      "optimizer time 0.016930 sec\n",
      "training time in round 267 cost 0.38468503952026367 sec\n",
      "loss 2.323932, train acc 0.098356\n",
      "round 268\n",
      "time to device 0.006597 sec\n",
      "time forward 3.326781 sec\n",
      "loss time 0.000472 sec\n",
      "backward time 0.005422 sec\n",
      "optimizer time 0.017382 sec\n",
      "training time in round 268 cost 0.38636302947998047 sec\n",
      "loss 2.323871, train acc 0.098339\n",
      "round 269\n",
      "time to device 0.005572 sec\n",
      "time forward 3.335098 sec\n",
      "loss time 0.000393 sec\n",
      "backward time 0.004854 sec\n",
      "optimizer time 0.015209 sec\n",
      "training time in round 269 cost 0.448422908782959 sec\n",
      "loss 2.323801, train acc 0.098235\n",
      "round 270\n",
      "time to device 0.006065 sec\n",
      "time forward 3.340583 sec\n",
      "loss time 0.000455 sec\n",
      "backward time 0.003717 sec\n",
      "optimizer time 0.012350 sec\n",
      "training time in round 270 cost 0.38337182998657227 sec\n",
      "loss 2.323737, train acc 0.098161\n",
      "round 271\n",
      "time to device 0.007625 sec\n",
      "time forward 3.349926 sec\n",
      "loss time 0.000707 sec\n",
      "backward time 0.005292 sec\n",
      "optimizer time 0.016690 sec\n",
      "training time in round 271 cost 0.3806459903717041 sec\n",
      "loss 2.323668, train acc 0.098030\n",
      "round 272\n",
      "time to device 0.006345 sec\n",
      "time forward 3.364517 sec\n",
      "loss time 0.000583 sec\n",
      "backward time 0.006985 sec\n",
      "optimizer time 0.017179 sec\n",
      "training time in round 272 cost 0.45568299293518066 sec\n",
      "loss 2.323568, train acc 0.098186\n",
      "round 273\n",
      "time to device 0.015626 sec\n",
      "time forward 3.377561 sec\n",
      "loss time 0.000815 sec\n",
      "backward time 0.006245 sec\n",
      "optimizer time 0.020369 sec\n",
      "training time in round 273 cost 0.45034098625183105 sec\n",
      "loss 2.323487, train acc 0.098198\n",
      "round 274\n",
      "time to device 0.077130 sec\n",
      "time forward 3.406783 sec\n",
      "loss time 0.001879 sec\n",
      "backward time 0.009735 sec\n",
      "optimizer time 0.050993 sec\n",
      "training time in round 274 cost 0.6280498504638672 sec\n",
      "loss 2.323403, train acc 0.098153\n",
      "round 275\n",
      "time to device 0.008675 sec\n",
      "time forward 3.422800 sec\n",
      "loss time 0.001937 sec\n",
      "backward time 0.013894 sec\n",
      "optimizer time 0.023759 sec\n",
      "training time in round 275 cost 0.542762041091919 sec\n",
      "loss 2.323312, train acc 0.098081\n",
      "round 276\n",
      "time to device 0.008712 sec\n",
      "time forward 3.433907 sec\n",
      "loss time 0.001060 sec\n",
      "backward time 0.011303 sec\n",
      "optimizer time 0.022292 sec\n",
      "training time in round 276 cost 0.4487471580505371 sec\n",
      "loss 2.323244, train acc 0.097981\n",
      "round 277\n",
      "time to device 0.006829 sec\n",
      "time forward 3.444340 sec\n",
      "loss time 0.001515 sec\n",
      "backward time 0.010407 sec\n",
      "optimizer time 0.028631 sec\n",
      "training time in round 277 cost 0.414874792098999 sec\n",
      "loss 2.323164, train acc 0.097965\n",
      "round 278\n",
      "time to device 0.008325 sec\n",
      "time forward 3.456824 sec\n",
      "loss time 0.001198 sec\n",
      "backward time 0.009865 sec\n",
      "optimizer time 0.027155 sec\n",
      "training time in round 278 cost 0.4452018737792969 sec\n",
      "loss 2.323081, train acc 0.098062\n",
      "round 279\n",
      "time to device 0.011898 sec\n",
      "time forward 3.471958 sec\n",
      "loss time 0.001288 sec\n",
      "backward time 0.015751 sec\n",
      "optimizer time 0.014572 sec\n",
      "training time in round 279 cost 0.4190826416015625 sec\n",
      "loss 2.322990, train acc 0.098131\n",
      "round 280\n",
      "time to device 0.006622 sec\n",
      "time forward 3.487366 sec\n",
      "loss time 0.001744 sec\n",
      "backward time 0.014607 sec\n",
      "optimizer time 0.030309 sec\n",
      "training time in round 280 cost 0.42065906524658203 sec\n",
      "loss 2.322895, train acc 0.098226\n",
      "round 281\n",
      "time to device 0.007331 sec\n",
      "time forward 3.498415 sec\n",
      "loss time 0.000518 sec\n",
      "backward time 0.005777 sec\n",
      "optimizer time 0.016090 sec\n",
      "training time in round 281 cost 0.3784010410308838 sec\n",
      "loss 2.322805, train acc 0.098266\n",
      "round 282\n",
      "time to device 0.007894 sec\n",
      "time forward 3.510701 sec\n",
      "loss time 0.001539 sec\n",
      "backward time 0.020814 sec\n",
      "optimizer time 0.024519 sec\n",
      "training time in round 282 cost 0.4074060916900635 sec\n",
      "loss 2.322759, train acc 0.098222\n",
      "round 283\n",
      "time to device 0.007138 sec\n",
      "time forward 3.525494 sec\n",
      "loss time 0.001093 sec\n",
      "backward time 0.012214 sec\n",
      "optimizer time 0.018704 sec\n",
      "training time in round 283 cost 0.4826350212097168 sec\n",
      "loss 2.323039, train acc 0.098151\n",
      "round 284\n",
      "time to device 0.007429 sec\n",
      "time forward 3.533014 sec\n",
      "loss time 0.000634 sec\n",
      "backward time 0.005592 sec\n",
      "optimizer time 0.014719 sec\n",
      "training time in round 284 cost 0.3719899654388428 sec\n",
      "loss 2.322964, train acc 0.098136\n",
      "round 285\n",
      "time to device 0.007568 sec\n",
      "time forward 3.546379 sec\n",
      "loss time 0.001281 sec\n",
      "backward time 0.017595 sec\n",
      "optimizer time 0.025688 sec\n",
      "training time in round 285 cost 0.4896719455718994 sec\n",
      "loss 2.322918, train acc 0.098093\n",
      "round 286\n",
      "time to device 0.006828 sec\n",
      "time forward 3.561339 sec\n",
      "loss time 0.001467 sec\n",
      "backward time 0.012198 sec\n",
      "optimizer time 0.033681 sec\n",
      "training time in round 286 cost 0.4947381019592285 sec\n",
      "loss 2.322844, train acc 0.098105\n",
      "round 287\n",
      "time to device 0.008760 sec\n",
      "time forward 3.571339 sec\n",
      "loss time 0.000473 sec\n",
      "backward time 0.006176 sec\n",
      "optimizer time 0.017589 sec\n",
      "training time in round 287 cost 0.46604180335998535 sec\n",
      "loss 2.322786, train acc 0.097928\n",
      "round 288\n",
      "time to device 0.007531 sec\n",
      "time forward 3.579641 sec\n",
      "loss time 0.001288 sec\n",
      "backward time 0.010861 sec\n",
      "optimizer time 0.071745 sec\n",
      "training time in round 288 cost 0.5423910617828369 sec\n",
      "loss 2.323401, train acc 0.097967\n",
      "round 289\n",
      "time to device 0.006830 sec\n",
      "time forward 3.588636 sec\n",
      "loss time 0.000448 sec\n",
      "backward time 0.003871 sec\n",
      "optimizer time 0.043681 sec\n",
      "training time in round 289 cost 0.4147469997406006 sec\n",
      "loss 2.323354, train acc 0.097926\n",
      "round 290\n",
      "time to device 0.008214 sec\n",
      "time forward 3.596753 sec\n",
      "loss time 0.000457 sec\n",
      "backward time 0.004408 sec\n",
      "optimizer time 0.013059 sec\n",
      "training time in round 290 cost 0.3705179691314697 sec\n",
      "loss 2.323282, train acc 0.098046\n",
      "round 291\n",
      "time to device 0.005295 sec\n",
      "time forward 3.606208 sec\n",
      "loss time 0.000633 sec\n",
      "backward time 0.006351 sec\n",
      "optimizer time 0.019734 sec\n",
      "training time in round 291 cost 0.41791272163391113 sec\n",
      "loss 2.323174, train acc 0.098004\n",
      "round 292\n",
      "time to device 0.005626 sec\n",
      "time forward 3.613613 sec\n",
      "loss time 0.000797 sec\n",
      "backward time 0.006415 sec\n",
      "optimizer time 0.018075 sec\n",
      "training time in round 292 cost 0.42119789123535156 sec\n",
      "loss 2.323152, train acc 0.097910\n",
      "round 293\n",
      "time to device 0.007682 sec\n",
      "time forward 3.625973 sec\n",
      "loss time 0.000948 sec\n",
      "backward time 0.008501 sec\n",
      "optimizer time 0.019587 sec\n",
      "training time in round 293 cost 0.37984585762023926 sec\n",
      "loss 2.323070, train acc 0.098055\n",
      "round 294\n",
      "time to device 0.005152 sec\n",
      "time forward 3.637094 sec\n",
      "loss time 0.001079 sec\n",
      "backward time 0.009283 sec\n",
      "optimizer time 0.015803 sec\n",
      "training time in round 294 cost 0.4433319568634033 sec\n",
      "loss 2.323004, train acc 0.098014\n",
      "round 295\n",
      "time to device 0.005284 sec\n",
      "time forward 3.644377 sec\n",
      "loss time 0.000599 sec\n",
      "backward time 0.004201 sec\n",
      "optimizer time 0.014383 sec\n",
      "training time in round 295 cost 0.43918681144714355 sec\n",
      "loss 2.322901, train acc 0.097999\n",
      "round 296\n",
      "time to device 0.006102 sec\n",
      "time forward 3.649250 sec\n",
      "loss time 0.000452 sec\n",
      "backward time 0.004211 sec\n",
      "optimizer time 0.012254 sec\n",
      "training time in round 296 cost 0.3740968704223633 sec\n",
      "loss 2.322951, train acc 0.097959\n",
      "round 297\n",
      "time to device 0.006994 sec\n",
      "time forward 3.655183 sec\n",
      "loss time 0.000479 sec\n",
      "backward time 0.004248 sec\n",
      "optimizer time 0.016303 sec\n",
      "training time in round 297 cost 0.37892699241638184 sec\n",
      "loss 2.322956, train acc 0.097945\n",
      "round 298\n",
      "time to device 0.007771 sec\n",
      "time forward 3.665031 sec\n",
      "loss time 0.000423 sec\n",
      "backward time 0.004067 sec\n",
      "optimizer time 0.012247 sec\n",
      "training time in round 298 cost 0.405850887298584 sec\n",
      "loss 2.322903, train acc 0.097878\n",
      "round 299\n",
      "time to device 0.006013 sec\n",
      "time forward 3.670952 sec\n",
      "loss time 0.000429 sec\n",
      "backward time 0.003831 sec\n",
      "optimizer time 0.013254 sec\n",
      "training time in round 299 cost 0.38094592094421387 sec\n",
      "loss 2.322868, train acc 0.098021\n",
      "round 300\n",
      "time to device 0.006660 sec\n",
      "time forward 3.683574 sec\n",
      "loss time 0.000386 sec\n",
      "backward time 0.003820 sec\n",
      "optimizer time 0.013269 sec\n",
      "training time in round 300 cost 0.392345666885376 sec\n",
      "loss 2.323632, train acc 0.097903\n",
      "round 301\n",
      "time to device 0.004897 sec\n",
      "time forward 3.690454 sec\n",
      "loss time 0.000480 sec\n",
      "backward time 0.003763 sec\n",
      "optimizer time 0.014990 sec\n",
      "training time in round 301 cost 0.3653910160064697 sec\n",
      "loss 2.323556, train acc 0.097811\n",
      "round 302\n",
      "time to device 0.006196 sec\n",
      "time forward 3.701863 sec\n",
      "loss time 0.001338 sec\n",
      "backward time 0.005726 sec\n",
      "optimizer time 0.017926 sec\n",
      "training time in round 302 cost 0.40195202827453613 sec\n",
      "loss 2.323500, train acc 0.097669\n",
      "round 303\n",
      "time to device 0.019854 sec\n",
      "time forward 3.712927 sec\n",
      "loss time 0.000925 sec\n",
      "backward time 0.008812 sec\n",
      "optimizer time 0.024376 sec\n",
      "training time in round 303 cost 0.41452622413635254 sec\n",
      "loss 2.323759, train acc 0.097682\n",
      "round 304\n",
      "time to device 0.007025 sec\n",
      "time forward 3.720087 sec\n",
      "loss time 0.000465 sec\n",
      "backward time 0.004161 sec\n",
      "optimizer time 0.014383 sec\n",
      "training time in round 304 cost 0.37996602058410645 sec\n",
      "loss 2.323805, train acc 0.097669\n",
      "round 305\n",
      "time to device 0.005581 sec\n",
      "time forward 3.730503 sec\n",
      "loss time 0.000429 sec\n",
      "backward time 0.003861 sec\n",
      "optimizer time 0.012811 sec\n",
      "training time in round 305 cost 0.3654637336730957 sec\n",
      "loss 2.323739, train acc 0.097631\n",
      "round 306\n",
      "time to device 0.006401 sec\n",
      "time forward 3.737846 sec\n",
      "loss time 0.000492 sec\n",
      "backward time 0.004114 sec\n",
      "optimizer time 0.013972 sec\n",
      "training time in round 306 cost 0.38289785385131836 sec\n",
      "loss 2.323672, train acc 0.097516\n",
      "round 307\n",
      "time to device 0.006699 sec\n",
      "time forward 3.748331 sec\n",
      "loss time 0.000603 sec\n",
      "backward time 0.004975 sec\n",
      "optimizer time 0.013951 sec\n",
      "training time in round 307 cost 0.3849761486053467 sec\n",
      "loss 2.323590, train acc 0.097529\n",
      "round 308\n",
      "time to device 0.006020 sec\n",
      "time forward 3.764480 sec\n",
      "loss time 0.001211 sec\n",
      "backward time 0.010500 sec\n",
      "optimizer time 0.020953 sec\n",
      "training time in round 308 cost 0.38258790969848633 sec\n",
      "loss 2.323519, train acc 0.097542\n",
      "round 309\n",
      "time to device 0.006161 sec\n",
      "time forward 3.773661 sec\n",
      "loss time 0.000384 sec\n",
      "backward time 0.003326 sec\n",
      "optimizer time 0.010432 sec\n",
      "training time in round 309 cost 0.35772109031677246 sec\n",
      "loss 2.323461, train acc 0.097530\n",
      "round 310\n",
      "time to device 0.006805 sec\n",
      "time forward 3.782732 sec\n",
      "loss time 0.000438 sec\n",
      "backward time 0.003897 sec\n",
      "optimizer time 0.018392 sec\n",
      "training time in round 310 cost 0.44113612174987793 sec\n",
      "loss 2.323406, train acc 0.097543\n",
      "round 311\n",
      "time to device 0.004616 sec\n",
      "time forward 3.791750 sec\n",
      "loss time 0.000389 sec\n",
      "backward time 0.003736 sec\n",
      "optimizer time 0.014254 sec\n",
      "training time in round 311 cost 0.3851449489593506 sec\n",
      "loss 2.323351, train acc 0.097506\n",
      "round 312\n",
      "time to device 0.006322 sec\n",
      "time forward 3.801644 sec\n",
      "loss time 0.000439 sec\n",
      "backward time 0.004155 sec\n",
      "optimizer time 0.014222 sec\n",
      "training time in round 312 cost 0.38872504234313965 sec\n",
      "loss 2.323299, train acc 0.097469\n",
      "round 313\n",
      "time to device 0.007981 sec\n",
      "time forward 3.813096 sec\n",
      "loss time 0.000669 sec\n",
      "backward time 0.006787 sec\n",
      "optimizer time 0.020541 sec\n",
      "training time in round 313 cost 0.38657593727111816 sec\n",
      "loss 2.323278, train acc 0.097507\n",
      "round 314\n",
      "time to device 0.007124 sec\n",
      "time forward 3.818633 sec\n",
      "loss time 0.000537 sec\n",
      "backward time 0.004656 sec\n",
      "optimizer time 0.014381 sec\n",
      "training time in round 314 cost 0.33980274200439453 sec\n",
      "loss 2.323213, train acc 0.097619\n",
      "round 315\n",
      "time to device 0.006081 sec\n",
      "time forward 3.839236 sec\n",
      "loss time 0.000714 sec\n",
      "backward time 0.007573 sec\n",
      "optimizer time 0.020468 sec\n",
      "training time in round 315 cost 0.6583390235900879 sec\n",
      "loss 2.323151, train acc 0.097607\n",
      "round 316\n",
      "time to device 0.009260 sec\n",
      "time forward 3.851920 sec\n",
      "loss time 0.000656 sec\n",
      "backward time 0.005026 sec\n",
      "optimizer time 0.017700 sec\n",
      "training time in round 316 cost 0.5165281295776367 sec\n",
      "loss 2.323091, train acc 0.097545\n",
      "round 317\n",
      "time to device 0.009870 sec\n",
      "time forward 3.863381 sec\n",
      "loss time 0.001134 sec\n",
      "backward time 0.008983 sec\n",
      "optimizer time 0.021236 sec\n",
      "training time in round 317 cost 0.3998548984527588 sec\n",
      "loss 2.323020, train acc 0.097484\n",
      "round 318\n",
      "time to device 0.006859 sec\n",
      "time forward 3.877788 sec\n",
      "loss time 0.003346 sec\n",
      "backward time 0.014664 sec\n",
      "optimizer time 0.031705 sec\n",
      "training time in round 318 cost 0.425980806350708 sec\n",
      "loss 2.322948, train acc 0.097522\n",
      "round 319\n",
      "time to device 0.006790 sec\n",
      "time forward 3.892471 sec\n",
      "loss time 0.001518 sec\n",
      "backward time 0.013399 sec\n",
      "optimizer time 0.022859 sec\n",
      "training time in round 319 cost 0.4064059257507324 sec\n",
      "loss 2.322884, train acc 0.097559\n",
      "round 320\n",
      "time to device 0.010662 sec\n",
      "time forward 3.904761 sec\n",
      "loss time 0.002506 sec\n",
      "backward time 0.020383 sec\n",
      "optimizer time 0.023099 sec\n",
      "training time in round 320 cost 0.4027419090270996 sec\n",
      "loss 2.322869, train acc 0.097717\n",
      "round 321\n",
      "time to device 0.009257 sec\n",
      "time forward 3.917615 sec\n",
      "loss time 0.001835 sec\n",
      "backward time 0.013447 sec\n",
      "optimizer time 0.023647 sec\n",
      "training time in round 321 cost 0.39550113677978516 sec\n",
      "loss 2.322823, train acc 0.097753\n",
      "round 322\n",
      "time to device 0.008330 sec\n",
      "time forward 3.929830 sec\n",
      "loss time 0.001507 sec\n",
      "backward time 0.016003 sec\n",
      "optimizer time 0.026114 sec\n",
      "training time in round 322 cost 0.4477832317352295 sec\n",
      "loss 2.322766, train acc 0.097717\n",
      "round 323\n",
      "time to device 0.006825 sec\n",
      "time forward 3.935911 sec\n",
      "loss time 0.000664 sec\n",
      "backward time 0.006387 sec\n",
      "optimizer time 0.018137 sec\n",
      "training time in round 323 cost 0.38930702209472656 sec\n",
      "loss 2.322726, train acc 0.097560\n",
      "round 324\n",
      "time to device 0.007874 sec\n",
      "time forward 3.954197 sec\n",
      "loss time 0.001435 sec\n",
      "backward time 0.014119 sec\n",
      "optimizer time 0.018902 sec\n",
      "training time in round 324 cost 0.42858386039733887 sec\n",
      "loss 2.322685, train acc 0.097524\n",
      "round 325\n",
      "time to device 0.007166 sec\n",
      "time forward 3.972510 sec\n",
      "loss time 0.001123 sec\n",
      "backward time 0.012050 sec\n",
      "optimizer time 0.020933 sec\n",
      "training time in round 325 cost 0.4180002212524414 sec\n",
      "loss 2.322610, train acc 0.097608\n",
      "round 326\n",
      "time to device 0.007124 sec\n",
      "time forward 3.988911 sec\n",
      "loss time 0.001039 sec\n",
      "backward time 0.013590 sec\n",
      "optimizer time 0.025043 sec\n",
      "training time in round 326 cost 0.4097111225128174 sec\n",
      "loss 2.322550, train acc 0.097597\n",
      "round 327\n",
      "time to device 0.007100 sec\n",
      "time forward 4.000741 sec\n",
      "loss time 0.000888 sec\n",
      "backward time 0.016156 sec\n",
      "optimizer time 0.017269 sec\n",
      "training time in round 327 cost 0.39283108711242676 sec\n",
      "loss 2.322484, train acc 0.097585\n",
      "round 328\n",
      "time to device 0.009770 sec\n",
      "time forward 4.011906 sec\n",
      "loss time 0.001827 sec\n",
      "backward time 0.015120 sec\n",
      "optimizer time 0.019576 sec\n",
      "training time in round 328 cost 0.4074208736419678 sec\n",
      "loss 2.322414, train acc 0.097597\n",
      "round 329\n",
      "time to device 0.007507 sec\n",
      "time forward 4.022854 sec\n",
      "loss time 0.001130 sec\n",
      "backward time 0.014431 sec\n",
      "optimizer time 0.031650 sec\n",
      "training time in round 329 cost 0.43256187438964844 sec\n",
      "loss 2.322344, train acc 0.097609\n",
      "round 330\n",
      "time to device 0.006448 sec\n",
      "time forward 4.036890 sec\n",
      "loss time 0.001518 sec\n",
      "backward time 0.017491 sec\n",
      "optimizer time 0.018454 sec\n",
      "training time in round 330 cost 0.410830020904541 sec\n",
      "loss 2.322284, train acc 0.097550\n",
      "round 331\n",
      "time to device 0.006216 sec\n",
      "time forward 4.048716 sec\n",
      "loss time 0.001025 sec\n",
      "backward time 0.012411 sec\n",
      "optimizer time 0.019564 sec\n",
      "training time in round 331 cost 0.4087510108947754 sec\n",
      "loss 2.322226, train acc 0.097562\n",
      "round 332\n",
      "time to device 0.006425 sec\n",
      "time forward 4.060810 sec\n",
      "loss time 0.001172 sec\n",
      "backward time 0.016929 sec\n",
      "optimizer time 0.022033 sec\n",
      "training time in round 332 cost 0.39363932609558105 sec\n",
      "loss 2.322178, train acc 0.097598\n",
      "round 333\n",
      "time to device 0.007087 sec\n",
      "time forward 4.072778 sec\n",
      "loss time 0.001412 sec\n",
      "backward time 0.011154 sec\n",
      "optimizer time 0.016197 sec\n",
      "training time in round 333 cost 0.3970191478729248 sec\n",
      "loss 2.322116, train acc 0.097656\n",
      "round 334\n",
      "time to device 0.008118 sec\n",
      "time forward 4.087095 sec\n",
      "loss time 0.000599 sec\n",
      "backward time 0.011699 sec\n",
      "optimizer time 0.012605 sec\n",
      "training time in round 334 cost 0.40191006660461426 sec\n",
      "loss 2.322060, train acc 0.097551\n",
      "round 335\n",
      "time to device 0.006846 sec\n",
      "time forward 4.097128 sec\n",
      "loss time 0.000592 sec\n",
      "backward time 0.006141 sec\n",
      "optimizer time 0.016478 sec\n",
      "training time in round 335 cost 0.3972597122192383 sec\n",
      "loss 2.321985, train acc 0.097680\n",
      "round 336\n",
      "time to device 0.007979 sec\n",
      "time forward 4.108814 sec\n",
      "loss time 0.001136 sec\n",
      "backward time 0.025431 sec\n",
      "optimizer time 0.011881 sec\n",
      "training time in round 336 cost 0.39408397674560547 sec\n",
      "loss 2.321934, train acc 0.097784\n",
      "round 337\n",
      "time to device 0.007421 sec\n",
      "time forward 4.119647 sec\n",
      "loss time 0.001785 sec\n",
      "backward time 0.013369 sec\n",
      "optimizer time 0.017711 sec\n",
      "training time in round 337 cost 0.4139268398284912 sec\n",
      "loss 2.321891, train acc 0.097795\n",
      "round 338\n",
      "time to device 0.006181 sec\n",
      "time forward 4.131942 sec\n",
      "loss time 0.000960 sec\n",
      "backward time 0.013294 sec\n",
      "optimizer time 0.021578 sec\n",
      "training time in round 338 cost 0.40167927742004395 sec\n",
      "loss 2.321830, train acc 0.097783\n",
      "round 339\n",
      "time to device 0.008609 sec\n",
      "time forward 4.140591 sec\n",
      "loss time 0.000642 sec\n",
      "backward time 0.005620 sec\n",
      "optimizer time 0.015662 sec\n",
      "training time in round 339 cost 0.3508110046386719 sec\n",
      "loss 2.321784, train acc 0.097748\n",
      "round 340\n",
      "time to device 0.009648 sec\n",
      "time forward 4.151734 sec\n",
      "loss time 0.001118 sec\n",
      "backward time 0.012441 sec\n",
      "optimizer time 0.016281 sec\n",
      "training time in round 340 cost 0.3923637866973877 sec\n",
      "loss 2.321729, train acc 0.097714\n",
      "round 341\n",
      "time to device 0.010826 sec\n",
      "time forward 4.163893 sec\n",
      "loss time 0.001036 sec\n",
      "backward time 0.009199 sec\n",
      "optimizer time 0.020850 sec\n",
      "training time in round 341 cost 0.39143967628479004 sec\n",
      "loss 2.321677, train acc 0.097725\n",
      "round 342\n",
      "time to device 0.008166 sec\n",
      "time forward 4.177589 sec\n",
      "loss time 0.001122 sec\n",
      "backward time 0.012646 sec\n",
      "optimizer time 0.025528 sec\n",
      "training time in round 342 cost 0.39972519874572754 sec\n",
      "loss 2.321616, train acc 0.097782\n",
      "round 343\n",
      "time to device 0.010672 sec\n",
      "time forward 4.193007 sec\n",
      "loss time 0.001183 sec\n",
      "backward time 0.011302 sec\n",
      "optimizer time 0.023061 sec\n",
      "training time in round 343 cost 0.45575690269470215 sec\n",
      "loss 2.321565, train acc 0.097770\n",
      "round 344\n",
      "time to device 0.007378 sec\n",
      "time forward 4.205833 sec\n",
      "loss time 0.003492 sec\n",
      "backward time 0.011029 sec\n",
      "optimizer time 0.023983 sec\n",
      "training time in round 344 cost 0.394197940826416 sec\n",
      "loss 2.321531, train acc 0.097871\n",
      "round 345\n",
      "time to device 0.007072 sec\n",
      "time forward 4.222732 sec\n",
      "loss time 0.001366 sec\n",
      "backward time 0.019780 sec\n",
      "optimizer time 0.024102 sec\n",
      "training time in round 345 cost 0.41930699348449707 sec\n",
      "loss 2.321490, train acc 0.097882\n",
      "round 346\n",
      "time to device 0.012886 sec\n",
      "time forward 4.235881 sec\n",
      "loss time 0.001544 sec\n",
      "backward time 0.010812 sec\n",
      "optimizer time 0.026282 sec\n",
      "training time in round 346 cost 0.3989429473876953 sec\n",
      "loss 2.321442, train acc 0.097848\n",
      "round 347\n",
      "time to device 0.007114 sec\n",
      "time forward 4.249178 sec\n",
      "loss time 0.001606 sec\n",
      "backward time 0.012521 sec\n",
      "optimizer time 0.022539 sec\n",
      "training time in round 347 cost 0.40038514137268066 sec\n",
      "loss 2.321392, train acc 0.097948\n",
      "round 348\n",
      "time to device 0.006997 sec\n",
      "time forward 4.262781 sec\n",
      "loss time 0.001663 sec\n",
      "backward time 0.013498 sec\n",
      "optimizer time 0.023811 sec\n",
      "training time in round 348 cost 0.4005148410797119 sec\n",
      "loss 2.321331, train acc 0.097981\n",
      "round 349\n",
      "time to device 0.008110 sec\n",
      "time forward 4.277091 sec\n",
      "loss time 0.001578 sec\n",
      "backward time 0.014112 sec\n",
      "optimizer time 0.021473 sec\n",
      "training time in round 349 cost 0.3968660831451416 sec\n",
      "loss 2.321275, train acc 0.098058\n",
      "round 350\n",
      "time to device 0.008843 sec\n",
      "time forward 4.291352 sec\n",
      "loss time 0.001043 sec\n",
      "backward time 0.012512 sec\n",
      "optimizer time 0.022691 sec\n",
      "training time in round 350 cost 0.39760684967041016 sec\n",
      "loss 2.321235, train acc 0.098179\n",
      "round 351\n",
      "time to device 0.003627 sec\n",
      "time forward 4.300662 sec\n",
      "loss time 0.000897 sec\n",
      "backward time 0.007078 sec\n",
      "optimizer time 0.018153 sec\n",
      "training time in round 351 cost 0.40581178665161133 sec\n",
      "loss 2.321195, train acc 0.098233\n",
      "round 352\n",
      "time to device 0.009024 sec\n",
      "time forward 4.315194 sec\n",
      "loss time 0.001287 sec\n",
      "backward time 0.010769 sec\n",
      "optimizer time 0.021756 sec\n",
      "training time in round 352 cost 0.40352392196655273 sec\n",
      "loss 2.321137, train acc 0.098243\n",
      "round 353\n",
      "time to device 0.009901 sec\n",
      "time forward 4.329589 sec\n",
      "loss time 0.001695 sec\n",
      "backward time 0.020756 sec\n",
      "optimizer time 0.027497 sec\n",
      "training time in round 353 cost 0.4112849235534668 sec\n",
      "loss 2.321095, train acc 0.098186\n",
      "round 354\n",
      "time to device 0.006434 sec\n",
      "time forward 4.343734 sec\n",
      "loss time 0.001482 sec\n",
      "backward time 0.015345 sec\n",
      "optimizer time 0.022587 sec\n",
      "training time in round 354 cost 0.4422729015350342 sec\n",
      "loss 2.321037, train acc 0.098239\n",
      "round 355\n",
      "time to device 0.009256 sec\n",
      "time forward 4.361306 sec\n",
      "loss time 0.001214 sec\n",
      "backward time 0.017294 sec\n",
      "optimizer time 0.026964 sec\n",
      "training time in round 355 cost 0.4084129333496094 sec\n",
      "loss 2.320984, train acc 0.098315\n",
      "round 356\n",
      "time to device 0.008570 sec\n",
      "time forward 4.373637 sec\n",
      "loss time 0.000546 sec\n",
      "backward time 0.004468 sec\n",
      "optimizer time 0.011962 sec\n",
      "training time in round 356 cost 0.40840911865234375 sec\n",
      "loss 2.320945, train acc 0.098236\n",
      "round 357\n",
      "time to device 0.006675 sec\n",
      "time forward 4.387488 sec\n",
      "loss time 0.004592 sec\n",
      "backward time 0.015664 sec\n",
      "optimizer time 0.024400 sec\n",
      "training time in round 357 cost 0.40292906761169434 sec\n",
      "loss 2.320901, train acc 0.098202\n",
      "round 358\n",
      "time to device 0.007598 sec\n",
      "time forward 4.401251 sec\n",
      "loss time 0.001533 sec\n",
      "backward time 0.013857 sec\n",
      "optimizer time 0.022136 sec\n",
      "training time in round 358 cost 0.4060029983520508 sec\n",
      "loss 2.320871, train acc 0.098081\n",
      "round 359\n",
      "time to device 0.005351 sec\n",
      "time forward 4.417203 sec\n",
      "loss time 0.001159 sec\n",
      "backward time 0.014562 sec\n",
      "optimizer time 0.020422 sec\n",
      "training time in round 359 cost 0.4553639888763428 sec\n",
      "loss 2.320817, train acc 0.098069\n",
      "round 360\n",
      "time to device 0.006478 sec\n",
      "time forward 4.426931 sec\n",
      "loss time 0.001475 sec\n",
      "backward time 0.028627 sec\n",
      "optimizer time 0.016702 sec\n",
      "training time in round 360 cost 0.41731786727905273 sec\n",
      "loss 2.320874, train acc 0.098078\n",
      "round 361\n",
      "time to device 0.007210 sec\n",
      "time forward 4.438061 sec\n",
      "loss time 0.000976 sec\n",
      "backward time 0.009181 sec\n",
      "optimizer time 0.024953 sec\n",
      "training time in round 361 cost 0.41223788261413574 sec\n",
      "loss 2.320834, train acc 0.098002\n",
      "round 362\n",
      "time to device 0.007735 sec\n",
      "time forward 4.453959 sec\n",
      "loss time 0.001296 sec\n",
      "backward time 0.015935 sec\n",
      "optimizer time 0.022090 sec\n",
      "training time in round 362 cost 0.4169948101043701 sec\n",
      "loss 2.320788, train acc 0.098033\n",
      "round 363\n",
      "time to device 0.008104 sec\n",
      "time forward 4.466158 sec\n",
      "loss time 0.000962 sec\n",
      "backward time 0.011256 sec\n",
      "optimizer time 0.020786 sec\n",
      "training time in round 363 cost 0.401486873626709 sec\n",
      "loss 2.320736, train acc 0.098000\n",
      "round 364\n",
      "time to device 0.006618 sec\n",
      "time forward 4.478382 sec\n",
      "loss time 0.001210 sec\n",
      "backward time 0.012043 sec\n",
      "optimizer time 0.025123 sec\n",
      "training time in round 364 cost 0.3915860652923584 sec\n",
      "loss 2.320695, train acc 0.098074\n",
      "round 365\n",
      "time to device 0.010105 sec\n",
      "time forward 4.489180 sec\n",
      "loss time 0.001294 sec\n",
      "backward time 0.015302 sec\n",
      "optimizer time 0.026772 sec\n",
      "training time in round 365 cost 0.3961930274963379 sec\n",
      "loss 2.320659, train acc 0.098062\n",
      "round 366\n",
      "time to device 0.008080 sec\n",
      "time forward 4.500927 sec\n",
      "loss time 0.001134 sec\n",
      "backward time 0.011543 sec\n",
      "optimizer time 0.015508 sec\n",
      "training time in round 366 cost 0.38502979278564453 sec\n",
      "loss 2.320607, train acc 0.098029\n",
      "round 367\n",
      "time to device 0.006763 sec\n",
      "time forward 4.512209 sec\n",
      "loss time 0.001872 sec\n",
      "backward time 0.014536 sec\n",
      "optimizer time 0.023982 sec\n",
      "training time in round 367 cost 0.3984959125518799 sec\n",
      "loss 2.320581, train acc 0.097996\n",
      "round 368\n",
      "time to device 0.003758 sec\n",
      "time forward 4.520346 sec\n",
      "loss time 0.000479 sec\n",
      "backward time 0.004187 sec\n",
      "optimizer time 0.014811 sec\n",
      "training time in round 368 cost 0.37052321434020996 sec\n",
      "loss 2.320548, train acc 0.098006\n",
      "round 369\n",
      "time to device 0.003455 sec\n",
      "time forward 4.533364 sec\n",
      "loss time 0.001094 sec\n",
      "backward time 0.011733 sec\n",
      "optimizer time 0.025479 sec\n",
      "training time in round 369 cost 0.43626904487609863 sec\n",
      "loss 2.320503, train acc 0.098142\n",
      "round 370\n",
      "time to device 0.007311 sec\n",
      "time forward 4.545588 sec\n",
      "loss time 0.001531 sec\n",
      "backward time 0.018855 sec\n",
      "optimizer time 0.023873 sec\n",
      "training time in round 370 cost 0.3984510898590088 sec\n",
      "loss 2.320457, train acc 0.098130\n",
      "round 371\n",
      "time to device 0.007191 sec\n",
      "time forward 4.557294 sec\n",
      "loss time 0.001404 sec\n",
      "backward time 0.013304 sec\n",
      "optimizer time 0.023631 sec\n",
      "training time in round 371 cost 0.4074740409851074 sec\n",
      "loss 2.320413, train acc 0.098202\n",
      "round 372\n",
      "time to device 0.007286 sec\n",
      "time forward 4.568742 sec\n",
      "loss time 0.001191 sec\n",
      "backward time 0.017727 sec\n",
      "optimizer time 0.025546 sec\n",
      "training time in round 372 cost 0.4029989242553711 sec\n",
      "loss 2.320368, train acc 0.098190\n",
      "round 373\n",
      "time to device 0.008248 sec\n",
      "time forward 4.582509 sec\n",
      "loss time 0.001945 sec\n",
      "backward time 0.020457 sec\n",
      "optimizer time 0.027228 sec\n",
      "training time in round 373 cost 0.42749691009521484 sec\n",
      "loss 2.320319, train acc 0.098158\n",
      "round 374\n",
      "time to device 0.008607 sec\n",
      "time forward 4.596183 sec\n",
      "loss time 0.001119 sec\n",
      "backward time 0.006303 sec\n",
      "optimizer time 0.018993 sec\n",
      "training time in round 374 cost 0.4241499900817871 sec\n",
      "loss 2.320272, train acc 0.098312\n",
      "round 375\n",
      "time to device 0.009511 sec\n",
      "time forward 4.609718 sec\n",
      "loss time 0.001142 sec\n",
      "backward time 0.017533 sec\n",
      "optimizer time 0.025405 sec\n",
      "training time in round 375 cost 0.419658899307251 sec\n",
      "loss 2.320346, train acc 0.098238\n",
      "round 376\n",
      "time to device 0.008232 sec\n",
      "time forward 4.623145 sec\n",
      "loss time 0.001661 sec\n",
      "backward time 0.019820 sec\n",
      "optimizer time 0.023854 sec\n",
      "training time in round 376 cost 0.42146825790405273 sec\n",
      "loss 2.320304, train acc 0.098309\n",
      "round 377\n",
      "time to device 0.009519 sec\n",
      "time forward 4.634474 sec\n",
      "loss time 0.000945 sec\n",
      "backward time 0.016774 sec\n",
      "optimizer time 0.023475 sec\n",
      "training time in round 377 cost 0.4029839038848877 sec\n",
      "loss 2.320280, train acc 0.098380\n",
      "round 378\n",
      "time to device 0.006986 sec\n",
      "time forward 4.646580 sec\n",
      "loss time 0.001214 sec\n",
      "backward time 0.011581 sec\n",
      "optimizer time 0.026565 sec\n",
      "training time in round 378 cost 0.4582397937774658 sec\n",
      "loss 2.320244, train acc 0.098306\n",
      "round 379\n",
      "time to device 0.006625 sec\n",
      "time forward 4.659202 sec\n",
      "loss time 0.001192 sec\n",
      "backward time 0.018050 sec\n",
      "optimizer time 0.030591 sec\n",
      "training time in round 379 cost 0.41179800033569336 sec\n",
      "loss 2.320203, train acc 0.098273\n",
      "round 380\n",
      "time to device 0.010030 sec\n",
      "time forward 4.674787 sec\n",
      "loss time 0.004579 sec\n",
      "backward time 0.012927 sec\n",
      "optimizer time 0.021783 sec\n",
      "training time in round 380 cost 0.4103727340698242 sec\n",
      "loss 2.320163, train acc 0.098261\n",
      "round 381\n",
      "time to device 0.009823 sec\n",
      "time forward 4.687093 sec\n",
      "loss time 0.001132 sec\n",
      "backward time 0.011619 sec\n",
      "optimizer time 0.028505 sec\n",
      "training time in round 381 cost 0.4145059585571289 sec\n",
      "loss 2.320152, train acc 0.098290\n",
      "round 382\n",
      "time to device 0.007628 sec\n",
      "time forward 4.701378 sec\n",
      "loss time 0.001045 sec\n",
      "backward time 0.014367 sec\n",
      "optimizer time 0.024258 sec\n",
      "training time in round 382 cost 0.40458130836486816 sec\n",
      "loss 2.320097, train acc 0.098503\n",
      "round 383\n",
      "time to device 0.006511 sec\n",
      "time forward 4.712490 sec\n",
      "loss time 0.001838 sec\n",
      "backward time 0.014073 sec\n",
      "optimizer time 0.028968 sec\n",
      "training time in round 383 cost 0.4030609130859375 sec\n",
      "loss 2.320049, train acc 0.098653\n",
      "round 384\n",
      "time to device 0.006801 sec\n",
      "time forward 4.728658 sec\n",
      "loss time 0.001188 sec\n",
      "backward time 0.010941 sec\n",
      "optimizer time 0.030673 sec\n",
      "training time in round 384 cost 0.44905781745910645 sec\n",
      "loss 2.319991, train acc 0.098803\n",
      "round 385\n",
      "time to device 0.006380 sec\n",
      "time forward 4.743753 sec\n",
      "loss time 0.001380 sec\n",
      "backward time 0.015603 sec\n",
      "optimizer time 0.016979 sec\n",
      "training time in round 385 cost 0.4217052459716797 sec\n",
      "loss 2.319952, train acc 0.098729\n",
      "round 386\n",
      "time to device 0.006042 sec\n",
      "time forward 4.755694 sec\n",
      "loss time 0.001784 sec\n",
      "backward time 0.017220 sec\n",
      "optimizer time 0.023100 sec\n",
      "training time in round 386 cost 0.3950080871582031 sec\n",
      "loss 2.319917, train acc 0.098716\n",
      "round 387\n",
      "time to device 0.008616 sec\n",
      "time forward 4.767809 sec\n",
      "loss time 0.001485 sec\n",
      "backward time 0.011071 sec\n",
      "optimizer time 0.013991 sec\n",
      "training time in round 387 cost 0.3860819339752197 sec\n",
      "loss 2.319881, train acc 0.098663\n",
      "round 388\n",
      "time to device 0.022309 sec\n",
      "time forward 4.780281 sec\n",
      "loss time 0.002402 sec\n",
      "backward time 0.025580 sec\n",
      "optimizer time 0.020057 sec\n",
      "training time in round 388 cost 0.4406242370605469 sec\n",
      "loss 2.319840, train acc 0.098590\n",
      "round 389\n",
      "time to device 0.007208 sec\n",
      "time forward 4.794569 sec\n",
      "loss time 0.001076 sec\n",
      "backward time 0.013663 sec\n",
      "optimizer time 0.019179 sec\n",
      "training time in round 389 cost 0.41052699089050293 sec\n",
      "loss 2.319787, train acc 0.098778\n",
      "round 390\n",
      "time to device 0.006267 sec\n",
      "time forward 4.810414 sec\n",
      "loss time 0.000916 sec\n",
      "backward time 0.009811 sec\n",
      "optimizer time 0.020472 sec\n",
      "training time in round 390 cost 0.4033830165863037 sec\n",
      "loss 2.319749, train acc 0.098765\n",
      "round 391\n",
      "time to device 0.007303 sec\n",
      "time forward 4.820101 sec\n",
      "loss time 0.001053 sec\n",
      "backward time 0.009557 sec\n",
      "optimizer time 0.018874 sec\n",
      "training time in round 391 cost 0.40857982635498047 sec\n",
      "loss 2.319711, train acc 0.098732\n",
      "round 392\n",
      "time to device 0.008804 sec\n",
      "time forward 4.833772 sec\n",
      "loss time 0.001436 sec\n",
      "backward time 0.010934 sec\n",
      "optimizer time 0.044048 sec\n",
      "training time in round 392 cost 0.4274868965148926 sec\n",
      "loss 2.319663, train acc 0.098740\n",
      "round 393\n",
      "time to device 0.006919 sec\n",
      "time forward 4.845254 sec\n",
      "loss time 0.001714 sec\n",
      "backward time 0.012905 sec\n",
      "optimizer time 0.022352 sec\n",
      "training time in round 393 cost 0.41300392150878906 sec\n",
      "loss 2.319627, train acc 0.098707\n",
      "round 394\n",
      "time to device 0.007334 sec\n",
      "time forward 4.858613 sec\n",
      "loss time 0.001271 sec\n",
      "backward time 0.012103 sec\n",
      "optimizer time 0.020691 sec\n",
      "training time in round 394 cost 0.4063889980316162 sec\n",
      "loss 2.319580, train acc 0.098714\n",
      "round 395\n",
      "time to device 0.007209 sec\n",
      "time forward 4.874030 sec\n",
      "loss time 0.001062 sec\n",
      "backward time 0.013795 sec\n",
      "optimizer time 0.016426 sec\n",
      "training time in round 395 cost 0.4498879909515381 sec\n",
      "loss 2.319542, train acc 0.098702\n",
      "round 396\n",
      "time to device 0.011993 sec\n",
      "time forward 4.888409 sec\n",
      "loss time 0.001551 sec\n",
      "backward time 0.012428 sec\n",
      "optimizer time 0.021314 sec\n",
      "training time in round 396 cost 0.4159109592437744 sec\n",
      "loss 2.319488, train acc 0.098768\n",
      "round 397\n",
      "time to device 0.006872 sec\n",
      "time forward 4.901308 sec\n",
      "loss time 0.001062 sec\n",
      "backward time 0.012370 sec\n",
      "optimizer time 0.024015 sec\n",
      "training time in round 397 cost 0.4165229797363281 sec\n",
      "loss 2.319449, train acc 0.098736\n",
      "round 398\n",
      "time to device 0.008964 sec\n",
      "time forward 4.917212 sec\n",
      "loss time 0.001258 sec\n",
      "backward time 0.013198 sec\n",
      "optimizer time 0.021130 sec\n",
      "training time in round 398 cost 0.4204120635986328 sec\n",
      "loss 2.319409, train acc 0.098704\n",
      "round 399\n",
      "time to device 0.008666 sec\n",
      "time forward 4.930904 sec\n",
      "loss time 0.001391 sec\n",
      "backward time 0.011107 sec\n",
      "optimizer time 0.021236 sec\n",
      "training time in round 399 cost 0.3997020721435547 sec\n",
      "loss 2.319378, train acc 0.098652\n",
      "round 400\n",
      "time to device 0.008782 sec\n",
      "time forward 4.941835 sec\n",
      "loss time 0.001300 sec\n",
      "backward time 0.013864 sec\n",
      "optimizer time 0.017444 sec\n",
      "training time in round 400 cost 0.39459800720214844 sec\n",
      "loss 2.319348, train acc 0.098718\n",
      "round 401\n",
      "time to device 0.007359 sec\n",
      "time forward 4.954117 sec\n",
      "loss time 0.001253 sec\n",
      "backward time 0.014412 sec\n",
      "optimizer time 0.025408 sec\n",
      "training time in round 401 cost 0.39461708068847656 sec\n",
      "loss 2.319306, train acc 0.098822\n",
      "round 402\n",
      "time to device 0.009663 sec\n",
      "time forward 4.966355 sec\n",
      "loss time 0.001408 sec\n",
      "backward time 0.014013 sec\n",
      "optimizer time 0.023248 sec\n",
      "training time in round 402 cost 0.39077210426330566 sec\n",
      "loss 2.319438, train acc 0.098907\n",
      "round 403\n",
      "time to device 0.007154 sec\n",
      "time forward 4.979283 sec\n",
      "loss time 0.001366 sec\n",
      "backward time 0.011670 sec\n",
      "optimizer time 0.021629 sec\n",
      "training time in round 403 cost 0.4023408889770508 sec\n",
      "loss 2.319394, train acc 0.098991\n",
      "round 404\n",
      "time to device 0.004198 sec\n",
      "time forward 4.990670 sec\n",
      "loss time 0.001358 sec\n",
      "backward time 0.011084 sec\n",
      "optimizer time 0.024782 sec\n",
      "training time in round 404 cost 0.38663792610168457 sec\n",
      "loss 2.319356, train acc 0.099016\n",
      "round 405\n",
      "time to device 0.004188 sec\n",
      "time forward 5.003040 sec\n",
      "loss time 0.001521 sec\n",
      "backward time 0.011631 sec\n",
      "optimizer time 0.028481 sec\n",
      "training time in round 405 cost 0.41740989685058594 sec\n",
      "loss 2.319323, train acc 0.098926\n",
      "round 406\n",
      "time to device 0.002434 sec\n",
      "time forward 5.017688 sec\n",
      "loss time 0.002250 sec\n",
      "backward time 0.015537 sec\n",
      "optimizer time 0.023238 sec\n",
      "training time in round 406 cost 0.42333102226257324 sec\n",
      "loss 2.319283, train acc 0.098952\n",
      "round 407\n",
      "time to device 0.008018 sec\n",
      "time forward 5.034654 sec\n",
      "loss time 0.001147 sec\n",
      "backward time 0.013084 sec\n",
      "optimizer time 0.023478 sec\n",
      "training time in round 407 cost 0.418942928314209 sec\n",
      "loss 2.319237, train acc 0.098977\n",
      "round 408\n",
      "time to device 0.009288 sec\n",
      "time forward 5.046684 sec\n",
      "loss time 0.000941 sec\n",
      "backward time 0.015722 sec\n",
      "optimizer time 0.019546 sec\n",
      "training time in round 408 cost 0.38837289810180664 sec\n",
      "loss 2.319170, train acc 0.099137\n",
      "round 409\n",
      "time to device 0.009190 sec\n",
      "time forward 5.062394 sec\n",
      "loss time 0.001240 sec\n",
      "backward time 0.011500 sec\n",
      "optimizer time 0.021419 sec\n",
      "training time in round 409 cost 0.404583215713501 sec\n",
      "loss 2.319161, train acc 0.099104\n",
      "round 410\n",
      "time to device 0.010442 sec\n",
      "time forward 5.068807 sec\n",
      "loss time 0.000521 sec\n",
      "backward time 0.004616 sec\n",
      "optimizer time 0.012854 sec\n",
      "training time in round 410 cost 0.36246585845947266 sec\n",
      "loss 2.319114, train acc 0.099205\n",
      "round 411\n",
      "time to device 0.006571 sec\n",
      "time forward 5.080234 sec\n",
      "loss time 0.001714 sec\n",
      "backward time 0.016264 sec\n",
      "optimizer time 0.021338 sec\n",
      "training time in round 411 cost 0.4430382251739502 sec\n",
      "loss 2.319071, train acc 0.099230\n",
      "round 412\n",
      "time to device 0.007238 sec\n",
      "time forward 5.094183 sec\n",
      "loss time 0.001136 sec\n",
      "backward time 0.013726 sec\n",
      "optimizer time 0.022302 sec\n",
      "training time in round 412 cost 0.42630887031555176 sec\n",
      "loss 2.319031, train acc 0.099255\n",
      "round 413\n",
      "time to device 0.009031 sec\n",
      "time forward 5.106268 sec\n",
      "loss time 0.001454 sec\n",
      "backward time 0.023821 sec\n",
      "optimizer time 0.023416 sec\n",
      "training time in round 413 cost 0.4040069580078125 sec\n",
      "loss 2.319001, train acc 0.099223\n",
      "round 414\n",
      "time to device 0.007985 sec\n",
      "time forward 5.114457 sec\n",
      "loss time 0.000981 sec\n",
      "backward time 0.010460 sec\n",
      "optimizer time 0.012259 sec\n",
      "training time in round 414 cost 0.3764808177947998 sec\n",
      "loss 2.318956, train acc 0.099209\n",
      "round 415\n",
      "time to device 0.013127 sec\n",
      "time forward 5.127311 sec\n",
      "loss time 0.001278 sec\n",
      "backward time 0.012799 sec\n",
      "optimizer time 0.020287 sec\n",
      "training time in round 415 cost 0.4400959014892578 sec\n",
      "loss 2.318909, train acc 0.099309\n",
      "round 416\n",
      "time to device 0.006596 sec\n",
      "time forward 5.143199 sec\n",
      "loss time 0.001762 sec\n",
      "backward time 0.011968 sec\n",
      "optimizer time 0.020747 sec\n",
      "training time in round 416 cost 0.4190049171447754 sec\n",
      "loss 2.318881, train acc 0.099183\n",
      "round 417\n",
      "time to device 0.008149 sec\n",
      "time forward 5.154464 sec\n",
      "loss time 0.001043 sec\n",
      "backward time 0.013222 sec\n",
      "optimizer time 0.026011 sec\n",
      "training time in round 417 cost 0.4131190776824951 sec\n",
      "loss 2.318847, train acc 0.099151\n",
      "round 418\n",
      "time to device 0.009465 sec\n",
      "time forward 5.167572 sec\n",
      "loss time 0.001178 sec\n",
      "backward time 0.020551 sec\n",
      "optimizer time 0.021691 sec\n",
      "training time in round 418 cost 0.4029057025909424 sec\n",
      "loss 2.318821, train acc 0.099139\n",
      "round 419\n",
      "time to device 0.008490 sec\n",
      "time forward 5.179817 sec\n",
      "loss time 0.000926 sec\n",
      "backward time 0.013456 sec\n",
      "optimizer time 0.019592 sec\n",
      "training time in round 419 cost 0.4452400207519531 sec\n",
      "loss 2.318775, train acc 0.099144\n",
      "round 420\n",
      "time to device 0.007281 sec\n",
      "time forward 5.191751 sec\n",
      "loss time 0.001091 sec\n",
      "backward time 0.014556 sec\n",
      "optimizer time 0.015404 sec\n",
      "training time in round 420 cost 0.39203906059265137 sec\n",
      "loss 2.318740, train acc 0.099206\n",
      "round 421\n",
      "time to device 0.007133 sec\n",
      "time forward 5.200489 sec\n",
      "loss time 0.000597 sec\n",
      "backward time 0.005541 sec\n",
      "optimizer time 0.028978 sec\n",
      "training time in round 421 cost 0.407149076461792 sec\n",
      "loss 2.318709, train acc 0.099193\n",
      "round 422\n",
      "time to device 0.010290 sec\n",
      "time forward 5.214886 sec\n",
      "loss time 0.001646 sec\n",
      "backward time 0.017297 sec\n",
      "optimizer time 0.026580 sec\n",
      "training time in round 422 cost 0.4358479976654053 sec\n",
      "loss 2.318667, train acc 0.099346\n",
      "round 423\n",
      "time to device 0.009821 sec\n",
      "time forward 5.231591 sec\n",
      "loss time 0.001191 sec\n",
      "backward time 0.015424 sec\n",
      "optimizer time 0.018323 sec\n",
      "training time in round 423 cost 0.4882378578186035 sec\n",
      "loss 2.318638, train acc 0.099333\n",
      "round 424\n",
      "time to device 0.006934 sec\n",
      "time forward 5.248629 sec\n",
      "loss time 0.001327 sec\n",
      "backward time 0.010463 sec\n",
      "optimizer time 0.034033 sec\n",
      "training time in round 424 cost 0.421097993850708 sec\n",
      "loss 2.318610, train acc 0.099265\n",
      "round 425\n",
      "time to device 0.008711 sec\n",
      "time forward 5.262408 sec\n",
      "loss time 0.000941 sec\n",
      "backward time 0.021570 sec\n",
      "optimizer time 0.032710 sec\n",
      "training time in round 425 cost 0.4334371089935303 sec\n",
      "loss 2.318571, train acc 0.099233\n",
      "round 426\n",
      "time to device 0.007734 sec\n",
      "time forward 5.275650 sec\n",
      "loss time 0.001122 sec\n",
      "backward time 0.011985 sec\n",
      "optimizer time 0.019136 sec\n",
      "training time in round 426 cost 0.4259757995605469 sec\n",
      "loss 2.318542, train acc 0.099166\n",
      "round 427\n",
      "time to device 0.006846 sec\n",
      "time forward 5.291763 sec\n",
      "loss time 0.001118 sec\n",
      "backward time 0.013927 sec\n",
      "optimizer time 0.023990 sec\n",
      "training time in round 427 cost 0.433729887008667 sec\n",
      "loss 2.318512, train acc 0.099153\n",
      "round 428\n",
      "time to device 0.008313 sec\n",
      "time forward 5.305226 sec\n",
      "loss time 0.001528 sec\n",
      "backward time 0.016203 sec\n",
      "optimizer time 0.025137 sec\n",
      "training time in round 428 cost 0.43584609031677246 sec\n",
      "loss 2.318475, train acc 0.099195\n",
      "round 429\n",
      "time to device 0.007167 sec\n",
      "time forward 5.319132 sec\n",
      "loss time 0.001362 sec\n",
      "backward time 0.011197 sec\n",
      "optimizer time 0.018778 sec\n",
      "training time in round 429 cost 0.4319438934326172 sec\n",
      "loss 2.318488, train acc 0.099255\n",
      "round 430\n",
      "time to device 0.007559 sec\n",
      "time forward 5.329344 sec\n",
      "loss time 0.001235 sec\n",
      "backward time 0.007204 sec\n",
      "optimizer time 0.015946 sec\n",
      "training time in round 430 cost 0.42024970054626465 sec\n",
      "loss 2.318461, train acc 0.099134\n",
      "round 431\n",
      "time to device 0.007515 sec\n",
      "time forward 5.346860 sec\n",
      "loss time 0.000952 sec\n",
      "backward time 0.011256 sec\n",
      "optimizer time 0.018494 sec\n",
      "training time in round 431 cost 0.40621495246887207 sec\n",
      "loss 2.318429, train acc 0.099067\n",
      "round 432\n",
      "time to device 0.007165 sec\n",
      "time forward 5.353412 sec\n",
      "loss time 0.000401 sec\n",
      "backward time 0.005774 sec\n",
      "optimizer time 0.012022 sec\n",
      "training time in round 432 cost 0.3738739490509033 sec\n",
      "loss 2.318397, train acc 0.098982\n",
      "round 433\n",
      "time to device 0.006805 sec\n",
      "time forward 5.360235 sec\n",
      "loss time 0.000444 sec\n",
      "backward time 0.004059 sec\n",
      "optimizer time 0.013575 sec\n",
      "training time in round 433 cost 0.418621301651001 sec\n",
      "loss 2.318379, train acc 0.099132\n",
      "round 434\n",
      "time to device 0.007095 sec\n",
      "time forward 5.379619 sec\n",
      "loss time 0.001648 sec\n",
      "backward time 0.015392 sec\n",
      "optimizer time 0.015345 sec\n",
      "training time in round 434 cost 0.4281327724456787 sec\n",
      "loss 2.318346, train acc 0.099120\n",
      "round 435\n",
      "time to device 0.010402 sec\n",
      "time forward 5.396547 sec\n",
      "loss time 0.001028 sec\n",
      "backward time 0.012504 sec\n",
      "optimizer time 0.020740 sec\n",
      "training time in round 435 cost 0.4221210479736328 sec\n",
      "loss 2.318307, train acc 0.099108\n",
      "round 436\n",
      "time to device 0.008779 sec\n",
      "time forward 5.406766 sec\n",
      "loss time 0.002054 sec\n",
      "backward time 0.013454 sec\n",
      "optimizer time 0.027689 sec\n",
      "training time in round 436 cost 0.4073469638824463 sec\n",
      "loss 2.318278, train acc 0.099149\n",
      "round 437\n",
      "time to device 0.006091 sec\n",
      "time forward 5.417554 sec\n",
      "loss time 0.002483 sec\n",
      "backward time 0.009330 sec\n",
      "optimizer time 0.019116 sec\n",
      "training time in round 437 cost 0.37209081649780273 sec\n",
      "loss 2.318244, train acc 0.099012\n",
      "round 438\n",
      "time to device 0.008124 sec\n",
      "time forward 5.423712 sec\n",
      "loss time 0.000558 sec\n",
      "backward time 0.004716 sec\n",
      "optimizer time 0.016489 sec\n",
      "training time in round 438 cost 0.37212204933166504 sec\n",
      "loss 2.318197, train acc 0.099089\n",
      "round 439\n",
      "time to device 0.007461 sec\n",
      "time forward 5.436794 sec\n",
      "loss time 0.001069 sec\n",
      "backward time 0.015701 sec\n",
      "optimizer time 0.018031 sec\n",
      "training time in round 439 cost 0.41150832176208496 sec\n",
      "loss 2.318167, train acc 0.098988\n",
      "round 440\n",
      "time to device 0.006869 sec\n",
      "time forward 5.451159 sec\n",
      "loss time 0.001394 sec\n",
      "backward time 0.009490 sec\n",
      "optimizer time 0.022416 sec\n",
      "training time in round 440 cost 0.4139411449432373 sec\n",
      "loss 2.318120, train acc 0.099029\n",
      "round 441\n",
      "time to device 0.006985 sec\n",
      "time forward 5.466808 sec\n",
      "loss time 0.001563 sec\n",
      "backward time 0.016133 sec\n",
      "optimizer time 0.025991 sec\n",
      "training time in round 441 cost 0.46088075637817383 sec\n",
      "loss 2.318090, train acc 0.098947\n",
      "round 442\n",
      "time to device 0.007229 sec\n",
      "time forward 5.478873 sec\n",
      "loss time 0.001096 sec\n",
      "backward time 0.015321 sec\n",
      "optimizer time 0.024097 sec\n",
      "training time in round 442 cost 0.3946547508239746 sec\n",
      "loss 2.318051, train acc 0.098988\n",
      "round 443\n",
      "time to device 0.005929 sec\n",
      "time forward 5.491904 sec\n",
      "loss time 0.002219 sec\n",
      "backward time 0.016584 sec\n",
      "optimizer time 0.025344 sec\n",
      "training time in round 443 cost 0.41968512535095215 sec\n",
      "loss 2.317984, train acc 0.098976\n",
      "round 444\n",
      "time to device 0.006963 sec\n",
      "time forward 5.504854 sec\n",
      "loss time 0.001437 sec\n",
      "backward time 0.016122 sec\n",
      "optimizer time 0.023957 sec\n",
      "training time in round 444 cost 0.40045595169067383 sec\n",
      "loss 2.317947, train acc 0.098964\n",
      "round 445\n",
      "time to device 0.008406 sec\n",
      "time forward 5.518574 sec\n",
      "loss time 0.001490 sec\n",
      "backward time 0.013151 sec\n",
      "optimizer time 0.023794 sec\n",
      "training time in round 445 cost 0.4075746536254883 sec\n",
      "loss 2.317912, train acc 0.098970\n",
      "round 446\n",
      "time to device 0.006802 sec\n",
      "time forward 5.532787 sec\n",
      "loss time 0.001389 sec\n",
      "backward time 0.014424 sec\n",
      "optimizer time 0.021848 sec\n",
      "training time in round 446 cost 0.4379079341888428 sec\n",
      "loss 2.317882, train acc 0.098993\n",
      "round 447\n",
      "time to device 0.008625 sec\n",
      "time forward 5.549823 sec\n",
      "loss time 0.001102 sec\n",
      "backward time 0.017205 sec\n",
      "optimizer time 0.017892 sec\n",
      "training time in round 447 cost 0.46302008628845215 sec\n",
      "loss 2.317845, train acc 0.099208\n",
      "round 448\n",
      "time to device 0.008272 sec\n",
      "time forward 5.574125 sec\n",
      "loss time 0.002457 sec\n",
      "backward time 0.005482 sec\n",
      "optimizer time 0.015040 sec\n",
      "training time in round 448 cost 0.4673447608947754 sec\n",
      "loss 2.317815, train acc 0.099179\n",
      "round 449\n",
      "time to device 0.026134 sec\n",
      "time forward 5.587924 sec\n",
      "loss time 0.001756 sec\n",
      "backward time 0.014051 sec\n",
      "optimizer time 0.027225 sec\n",
      "training time in round 449 cost 0.43367791175842285 sec\n",
      "loss 2.317770, train acc 0.099132\n",
      "round 450\n",
      "time to device 0.007091 sec\n",
      "time forward 5.600459 sec\n",
      "loss time 0.001464 sec\n",
      "backward time 0.013150 sec\n",
      "optimizer time 0.048526 sec\n",
      "training time in round 450 cost 0.45419812202453613 sec\n",
      "loss 2.317735, train acc 0.099137\n",
      "round 451\n",
      "time to device 0.008388 sec\n",
      "time forward 5.613058 sec\n",
      "loss time 0.001693 sec\n",
      "backward time 0.017481 sec\n",
      "optimizer time 0.026619 sec\n",
      "training time in round 451 cost 0.44664788246154785 sec\n",
      "loss 2.317707, train acc 0.099177\n",
      "round 452\n",
      "time to device 0.009790 sec\n",
      "time forward 5.627122 sec\n",
      "loss time 0.001415 sec\n",
      "backward time 0.015502 sec\n",
      "optimizer time 0.024304 sec\n",
      "training time in round 452 cost 0.43331408500671387 sec\n",
      "loss 2.317678, train acc 0.099114\n",
      "round 453\n",
      "time to device 0.007590 sec\n",
      "time forward 5.637291 sec\n",
      "loss time 0.001857 sec\n",
      "backward time 0.010466 sec\n",
      "optimizer time 0.019624 sec\n",
      "training time in round 453 cost 0.38612794876098633 sec\n",
      "loss 2.317755, train acc 0.098998\n",
      "round 454\n",
      "time to device 0.008721 sec\n",
      "time forward 5.649332 sec\n",
      "loss time 0.001755 sec\n",
      "backward time 0.012287 sec\n",
      "optimizer time 0.022192 sec\n",
      "training time in round 454 cost 0.4112069606781006 sec\n",
      "loss 2.317722, train acc 0.098970\n",
      "round 455\n",
      "time to device 0.011271 sec\n",
      "time forward 5.659320 sec\n",
      "loss time 0.001311 sec\n",
      "backward time 0.015854 sec\n",
      "optimizer time 0.021473 sec\n",
      "training time in round 455 cost 0.39046216011047363 sec\n",
      "loss 2.317686, train acc 0.099044\n",
      "round 456\n",
      "time to device 0.014222 sec\n",
      "time forward 5.670932 sec\n",
      "loss time 0.001900 sec\n",
      "backward time 0.014649 sec\n",
      "optimizer time 0.027806 sec\n",
      "training time in round 456 cost 0.4143197536468506 sec\n",
      "loss 2.317661, train acc 0.099067\n",
      "round 457\n",
      "time to device 0.008676 sec\n",
      "time forward 5.682462 sec\n",
      "loss time 0.001548 sec\n",
      "backward time 0.014129 sec\n",
      "optimizer time 0.020362 sec\n",
      "training time in round 457 cost 0.43374013900756836 sec\n",
      "loss 2.317627, train acc 0.099089\n",
      "round 458\n",
      "time to device 0.007638 sec\n",
      "time forward 5.694668 sec\n",
      "loss time 0.001404 sec\n",
      "backward time 0.020149 sec\n",
      "optimizer time 0.053149 sec\n",
      "training time in round 458 cost 0.4532160758972168 sec\n",
      "loss 2.317577, train acc 0.099129\n",
      "round 459\n",
      "time to device 0.008886 sec\n",
      "time forward 5.706744 sec\n",
      "loss time 0.002217 sec\n",
      "backward time 0.012931 sec\n",
      "optimizer time 0.030545 sec\n",
      "training time in round 459 cost 0.403961181640625 sec\n",
      "loss 2.317549, train acc 0.099151\n",
      "round 460\n",
      "time to device 0.008784 sec\n",
      "time forward 5.721574 sec\n",
      "loss time 0.001993 sec\n",
      "backward time 0.015108 sec\n",
      "optimizer time 0.025747 sec\n",
      "training time in round 460 cost 0.4353499412536621 sec\n",
      "loss 2.317514, train acc 0.099122\n",
      "round 461\n",
      "time to device 0.010725 sec\n",
      "time forward 5.736611 sec\n",
      "loss time 0.001987 sec\n",
      "backward time 0.016506 sec\n",
      "optimizer time 0.027296 sec\n",
      "training time in round 461 cost 0.41974711418151855 sec\n",
      "loss 2.317490, train acc 0.099094\n",
      "round 462\n",
      "time to device 0.006421 sec\n",
      "time forward 5.750951 sec\n",
      "loss time 0.001438 sec\n",
      "backward time 0.017355 sec\n",
      "optimizer time 0.025056 sec\n",
      "training time in round 462 cost 0.4146449565887451 sec\n",
      "loss 2.317447, train acc 0.099116\n",
      "round 463\n",
      "time to device 0.007688 sec\n",
      "time forward 5.763562 sec\n",
      "loss time 0.001390 sec\n",
      "backward time 0.011569 sec\n",
      "optimizer time 0.018485 sec\n",
      "training time in round 463 cost 0.41535305976867676 sec\n",
      "loss 2.317421, train acc 0.099138\n",
      "round 464\n",
      "time to device 0.008145 sec\n",
      "time forward 5.777404 sec\n",
      "loss time 0.001469 sec\n",
      "backward time 0.012907 sec\n",
      "optimizer time 0.022758 sec\n",
      "training time in round 464 cost 0.40506625175476074 sec\n",
      "loss 2.317394, train acc 0.099177\n",
      "round 465\n",
      "time to device 0.005487 sec\n",
      "time forward 5.791065 sec\n",
      "loss time 0.001933 sec\n",
      "backward time 0.013975 sec\n",
      "optimizer time 0.023584 sec\n",
      "training time in round 465 cost 0.39785003662109375 sec\n",
      "loss 2.317361, train acc 0.099098\n",
      "round 466\n",
      "time to device 0.003285 sec\n",
      "time forward 5.806225 sec\n",
      "loss time 0.001381 sec\n",
      "backward time 0.016583 sec\n",
      "optimizer time 0.024086 sec\n",
      "training time in round 466 cost 0.40212106704711914 sec\n",
      "loss 2.317393, train acc 0.099053\n",
      "round 467\n",
      "time to device 0.004947 sec\n",
      "time forward 5.819906 sec\n",
      "loss time 0.001061 sec\n",
      "backward time 0.012001 sec\n",
      "optimizer time 0.025537 sec\n",
      "training time in round 467 cost 0.3947031497955322 sec\n",
      "loss 2.317362, train acc 0.099058\n",
      "round 468\n",
      "time to device 0.003032 sec\n",
      "time forward 5.843626 sec\n",
      "loss time 0.001977 sec\n",
      "backward time 0.015786 sec\n",
      "optimizer time 0.018349 sec\n",
      "training time in round 468 cost 0.3583223819732666 sec\n",
      "loss 2.317358, train acc 0.099017\n",
      "test acc is 0.100000\n",
      "epoch 5, time 2649.743540 sec\n",
      "epoch 7\n",
      "round 0\n",
      "time to device 0.046368 sec\n",
      "time forward 0.025654 sec\n",
      "loss time 0.001048 sec\n",
      "backward time 0.009852 sec\n",
      "optimizer time 0.060670 sec\n",
      "training time in round 0 cost 0.8731508255004883 sec\n",
      "loss 2.308173, train acc 0.109375\n",
      "round 1\n",
      "time to device 0.014273 sec\n",
      "time forward 0.041504 sec\n",
      "loss time 0.001229 sec\n",
      "backward time 0.013227 sec\n",
      "optimizer time 0.026929 sec\n",
      "training time in round 1 cost 0.46384596824645996 sec\n",
      "loss 2.306193, train acc 0.093750\n",
      "round 2\n",
      "time to device 0.009825 sec\n",
      "time forward 0.054621 sec\n",
      "loss time 0.001115 sec\n",
      "backward time 0.009535 sec\n",
      "optimizer time 0.021089 sec\n",
      "training time in round 2 cost 0.4083549976348877 sec\n",
      "loss 2.307131, train acc 0.088542\n",
      "round 3\n",
      "time to device 0.006997 sec\n",
      "time forward 0.068598 sec\n",
      "loss time 0.001359 sec\n",
      "backward time 0.011271 sec\n",
      "optimizer time 0.021081 sec\n",
      "training time in round 3 cost 0.4048619270324707 sec\n",
      "loss 2.306555, train acc 0.076172\n",
      "round 4\n",
      "time to device 0.007540 sec\n",
      "time forward 0.081359 sec\n",
      "loss time 0.002045 sec\n",
      "backward time 0.013720 sec\n",
      "optimizer time 0.021056 sec\n",
      "training time in round 4 cost 0.4003031253814697 sec\n",
      "loss 2.306575, train acc 0.076563\n",
      "round 5\n",
      "time to device 0.007220 sec\n",
      "time forward 0.094418 sec\n",
      "loss time 0.001294 sec\n",
      "backward time 0.015024 sec\n",
      "optimizer time 0.024529 sec\n",
      "training time in round 5 cost 0.4080488681793213 sec\n",
      "loss 2.305287, train acc 0.091146\n",
      "round 6\n",
      "time to device 0.011768 sec\n",
      "time forward 0.109153 sec\n",
      "loss time 0.001569 sec\n",
      "backward time 0.011800 sec\n",
      "optimizer time 0.020878 sec\n",
      "training time in round 6 cost 0.43251895904541016 sec\n",
      "loss 2.305177, train acc 0.089286\n",
      "round 7\n",
      "time to device 0.010667 sec\n",
      "time forward 0.126729 sec\n",
      "loss time 0.001403 sec\n",
      "backward time 0.013673 sec\n",
      "optimizer time 0.021293 sec\n",
      "training time in round 7 cost 0.47449707984924316 sec\n",
      "loss 2.304818, train acc 0.094727\n",
      "round 8\n",
      "time to device 0.006730 sec\n",
      "time forward 0.143141 sec\n",
      "loss time 0.001295 sec\n",
      "backward time 0.012570 sec\n",
      "optimizer time 0.022103 sec\n",
      "training time in round 8 cost 0.4084169864654541 sec\n",
      "loss 2.304987, train acc 0.092882\n",
      "round 9\n",
      "time to device 0.008231 sec\n",
      "time forward 0.157636 sec\n",
      "loss time 0.003266 sec\n",
      "backward time 0.013247 sec\n",
      "optimizer time 0.022692 sec\n",
      "training time in round 9 cost 0.4057881832122803 sec\n",
      "loss 2.305015, train acc 0.092969\n",
      "round 10\n",
      "time to device 0.008497 sec\n",
      "time forward 0.163768 sec\n",
      "loss time 0.000358 sec\n",
      "backward time 0.003366 sec\n",
      "optimizer time 0.012770 sec\n",
      "training time in round 10 cost 0.3504190444946289 sec\n",
      "loss 2.304887, train acc 0.092330\n",
      "round 11\n",
      "time to device 0.011302 sec\n",
      "time forward 0.174915 sec\n",
      "loss time 0.001202 sec\n",
      "backward time 0.010758 sec\n",
      "optimizer time 0.021867 sec\n",
      "training time in round 11 cost 0.38428497314453125 sec\n",
      "loss 2.304650, train acc 0.090495\n",
      "round 12\n",
      "time to device 0.014420 sec\n",
      "time forward 0.188248 sec\n",
      "loss time 0.001324 sec\n",
      "backward time 0.013438 sec\n",
      "optimizer time 0.023434 sec\n",
      "training time in round 12 cost 0.4169349670410156 sec\n",
      "loss 2.304567, train acc 0.093149\n",
      "round 13\n",
      "time to device 0.007737 sec\n",
      "time forward 0.206272 sec\n",
      "loss time 0.001146 sec\n",
      "backward time 0.010707 sec\n",
      "optimizer time 0.026063 sec\n",
      "training time in round 13 cost 0.4063730239868164 sec\n",
      "loss 2.304562, train acc 0.090960\n",
      "round 14\n",
      "time to device 0.009208 sec\n",
      "time forward 0.218988 sec\n",
      "loss time 0.001521 sec\n",
      "backward time 0.013799 sec\n",
      "optimizer time 0.022101 sec\n",
      "training time in round 14 cost 0.40184688568115234 sec\n",
      "loss 2.304256, train acc 0.093229\n",
      "round 15\n",
      "time to device 0.009957 sec\n",
      "time forward 0.232838 sec\n",
      "loss time 0.001087 sec\n",
      "backward time 0.017869 sec\n",
      "optimizer time 0.022167 sec\n",
      "training time in round 15 cost 0.42171406745910645 sec\n",
      "loss 2.303931, train acc 0.097168\n",
      "round 16\n",
      "time to device 0.010263 sec\n",
      "time forward 0.247254 sec\n",
      "loss time 0.001880 sec\n",
      "backward time 0.020621 sec\n",
      "optimizer time 0.025045 sec\n",
      "training time in round 16 cost 0.4108400344848633 sec\n",
      "loss 2.303808, train acc 0.096967\n",
      "round 17\n",
      "time to device 0.006219 sec\n",
      "time forward 0.268921 sec\n",
      "loss time 0.001175 sec\n",
      "backward time 0.011285 sec\n",
      "optimizer time 0.020867 sec\n",
      "training time in round 17 cost 0.4331200122833252 sec\n",
      "loss 2.303815, train acc 0.095920\n",
      "round 18\n",
      "time to device 0.008021 sec\n",
      "time forward 0.283185 sec\n",
      "loss time 0.002053 sec\n",
      "backward time 0.014380 sec\n",
      "optimizer time 0.023402 sec\n",
      "training time in round 18 cost 0.4099459648132324 sec\n",
      "loss 2.303719, train acc 0.097039\n",
      "round 19\n",
      "time to device 0.003974 sec\n",
      "time forward 0.301876 sec\n",
      "loss time 0.001247 sec\n",
      "backward time 0.012343 sec\n",
      "optimizer time 0.021516 sec\n",
      "training time in round 19 cost 0.41770291328430176 sec\n",
      "loss 2.303606, train acc 0.099609\n",
      "round 20\n",
      "time to device 0.004477 sec\n",
      "time forward 0.308915 sec\n",
      "loss time 0.000648 sec\n",
      "backward time 0.005818 sec\n",
      "optimizer time 0.014944 sec\n",
      "training time in round 20 cost 0.3600320816040039 sec\n",
      "loss 2.303792, train acc 0.098958\n",
      "round 21\n",
      "time to device 0.004376 sec\n",
      "time forward 0.316757 sec\n",
      "loss time 0.000390 sec\n",
      "backward time 0.005422 sec\n",
      "optimizer time 0.014521 sec\n",
      "training time in round 21 cost 0.381350040435791 sec\n",
      "loss 2.303930, train acc 0.098722\n",
      "round 22\n",
      "time to device 0.003779 sec\n",
      "time forward 0.333236 sec\n",
      "loss time 0.001943 sec\n",
      "backward time 0.017476 sec\n",
      "optimizer time 0.026305 sec\n",
      "training time in round 22 cost 0.4449920654296875 sec\n",
      "loss 2.303979, train acc 0.098166\n",
      "round 23\n",
      "time to device 0.008001 sec\n",
      "time forward 0.343662 sec\n",
      "loss time 0.001210 sec\n",
      "backward time 0.011471 sec\n",
      "optimizer time 0.026307 sec\n",
      "training time in round 23 cost 0.38656091690063477 sec\n",
      "loss 2.303954, train acc 0.098633\n",
      "round 24\n",
      "time to device 0.006744 sec\n",
      "time forward 0.350083 sec\n",
      "loss time 0.000758 sec\n",
      "backward time 0.007147 sec\n",
      "optimizer time 0.018612 sec\n",
      "training time in round 24 cost 0.4127480983734131 sec\n",
      "loss 2.303972, train acc 0.099062\n",
      "round 25\n",
      "time to device 0.008771 sec\n",
      "time forward 0.363596 sec\n",
      "loss time 0.000987 sec\n",
      "backward time 0.013577 sec\n",
      "optimizer time 0.026550 sec\n",
      "training time in round 25 cost 0.4195089340209961 sec\n",
      "loss 2.304030, train acc 0.099459\n",
      "round 26\n",
      "time to device 0.007230 sec\n",
      "time forward 0.376735 sec\n",
      "loss time 0.001024 sec\n",
      "backward time 0.010014 sec\n",
      "optimizer time 0.028399 sec\n",
      "training time in round 26 cost 0.4133009910583496 sec\n",
      "loss 2.303888, train acc 0.099248\n",
      "round 27\n",
      "time to device 0.010043 sec\n",
      "time forward 0.392485 sec\n",
      "loss time 0.001679 sec\n",
      "backward time 0.018310 sec\n",
      "optimizer time 0.024991 sec\n",
      "training time in round 27 cost 0.4267549514770508 sec\n",
      "loss 2.303913, train acc 0.098772\n",
      "round 28\n",
      "time to device 0.010181 sec\n",
      "time forward 0.407307 sec\n",
      "loss time 0.002264 sec\n",
      "backward time 0.008569 sec\n",
      "optimizer time 0.031581 sec\n",
      "training time in round 28 cost 0.5398850440979004 sec\n",
      "loss 2.304027, train acc 0.097252\n",
      "round 29\n",
      "time to device 0.006700 sec\n",
      "time forward 0.422035 sec\n",
      "loss time 0.001007 sec\n",
      "backward time 0.015258 sec\n",
      "optimizer time 0.025346 sec\n",
      "training time in round 29 cost 0.45809507369995117 sec\n",
      "loss 2.303868, train acc 0.098437\n",
      "round 30\n",
      "time to device 0.010149 sec\n",
      "time forward 0.436866 sec\n",
      "loss time 0.001454 sec\n",
      "backward time 0.014174 sec\n",
      "optimizer time 0.024125 sec\n",
      "training time in round 30 cost 0.4569680690765381 sec\n",
      "loss 2.303800, train acc 0.097530\n",
      "round 31\n",
      "time to device 0.010031 sec\n",
      "time forward 0.451224 sec\n",
      "loss time 0.001519 sec\n",
      "backward time 0.016217 sec\n",
      "optimizer time 0.024407 sec\n",
      "training time in round 31 cost 0.4109220504760742 sec\n",
      "loss 2.303717, train acc 0.097412\n",
      "round 32\n",
      "time to device 0.007560 sec\n",
      "time forward 0.461210 sec\n",
      "loss time 0.001197 sec\n",
      "backward time 0.010746 sec\n",
      "optimizer time 0.022738 sec\n",
      "training time in round 32 cost 0.3736090660095215 sec\n",
      "loss 2.303507, train acc 0.098248\n",
      "round 33\n",
      "time to device 0.006882 sec\n",
      "time forward 0.474346 sec\n",
      "loss time 0.001386 sec\n",
      "backward time 0.015316 sec\n",
      "optimizer time 0.024519 sec\n",
      "training time in round 33 cost 0.40549612045288086 sec\n",
      "loss 2.303447, train acc 0.098346\n",
      "round 34\n",
      "time to device 0.008843 sec\n",
      "time forward 0.484236 sec\n",
      "loss time 0.000580 sec\n",
      "backward time 0.005654 sec\n",
      "optimizer time 0.014695 sec\n",
      "training time in round 34 cost 0.4184432029724121 sec\n",
      "loss 2.303444, train acc 0.097098\n",
      "round 35\n",
      "time to device 0.007297 sec\n",
      "time forward 0.494976 sec\n",
      "loss time 0.002385 sec\n",
      "backward time 0.015468 sec\n",
      "optimizer time 0.021439 sec\n",
      "training time in round 35 cost 0.39791321754455566 sec\n",
      "loss 2.303380, train acc 0.097873\n",
      "round 36\n",
      "time to device 0.011621 sec\n",
      "time forward 0.506063 sec\n",
      "loss time 0.000590 sec\n",
      "backward time 0.012337 sec\n",
      "optimizer time 0.025455 sec\n",
      "training time in round 36 cost 0.4057450294494629 sec\n",
      "loss 2.303422, train acc 0.097973\n",
      "round 37\n",
      "time to device 0.007382 sec\n",
      "time forward 0.520615 sec\n",
      "loss time 0.001310 sec\n",
      "backward time 0.011592 sec\n",
      "optimizer time 0.031510 sec\n",
      "training time in round 37 cost 0.4947807788848877 sec\n",
      "loss 2.303322, train acc 0.096628\n",
      "round 38\n",
      "time to device 0.007128 sec\n",
      "time forward 0.534105 sec\n",
      "loss time 0.001276 sec\n",
      "backward time 0.011000 sec\n",
      "optimizer time 0.023687 sec\n",
      "training time in round 38 cost 0.4080338478088379 sec\n",
      "loss 2.303230, train acc 0.097356\n",
      "round 39\n",
      "time to device 0.009844 sec\n",
      "time forward 0.551664 sec\n",
      "loss time 0.002058 sec\n",
      "backward time 0.014786 sec\n",
      "optimizer time 0.023838 sec\n",
      "training time in round 39 cost 0.44135594367980957 sec\n",
      "loss 2.303333, train acc 0.097656\n",
      "round 40\n",
      "time to device 0.008590 sec\n",
      "time forward 0.565198 sec\n",
      "loss time 0.002238 sec\n",
      "backward time 0.019623 sec\n",
      "optimizer time 0.025647 sec\n",
      "training time in round 40 cost 0.4147970676422119 sec\n",
      "loss 2.303313, train acc 0.098323\n",
      "round 41\n",
      "time to device 0.009705 sec\n",
      "time forward 0.578013 sec\n",
      "loss time 0.001169 sec\n",
      "backward time 0.018696 sec\n",
      "optimizer time 0.025090 sec\n",
      "training time in round 41 cost 0.41602492332458496 sec\n",
      "loss 2.303228, train acc 0.099516\n",
      "round 42\n",
      "time to device 0.008095 sec\n",
      "time forward 0.590515 sec\n",
      "loss time 0.001878 sec\n",
      "backward time 0.012862 sec\n",
      "optimizer time 0.025020 sec\n",
      "training time in round 42 cost 0.3999788761138916 sec\n",
      "loss 2.303231, train acc 0.099746\n",
      "round 43\n",
      "time to device 0.009426 sec\n",
      "time forward 0.608734 sec\n",
      "loss time 0.001133 sec\n",
      "backward time 0.012261 sec\n",
      "optimizer time 0.011191 sec\n",
      "training time in round 43 cost 0.39360904693603516 sec\n",
      "loss 2.303201, train acc 0.099609\n",
      "round 44\n",
      "time to device 0.008865 sec\n",
      "time forward 0.615406 sec\n",
      "loss time 0.000516 sec\n",
      "backward time 0.004556 sec\n",
      "optimizer time 0.013451 sec\n",
      "training time in round 44 cost 0.3573589324951172 sec\n",
      "loss 2.303350, train acc 0.098611\n",
      "round 45\n",
      "time to device 0.009216 sec\n",
      "time forward 0.629946 sec\n",
      "loss time 0.002515 sec\n",
      "backward time 0.022864 sec\n",
      "optimizer time 0.023428 sec\n",
      "training time in round 45 cost 0.42792725563049316 sec\n",
      "loss 2.303272, train acc 0.098505\n",
      "round 46\n",
      "time to device 0.010130 sec\n",
      "time forward 0.643992 sec\n",
      "loss time 0.001023 sec\n",
      "backward time 0.012678 sec\n",
      "optimizer time 0.024447 sec\n",
      "training time in round 46 cost 0.40717196464538574 sec\n",
      "loss 2.303317, train acc 0.098570\n",
      "round 47\n",
      "time to device 0.007139 sec\n",
      "time forward 0.657850 sec\n",
      "loss time 0.001555 sec\n",
      "backward time 0.017047 sec\n",
      "optimizer time 0.025960 sec\n",
      "training time in round 47 cost 0.4047577381134033 sec\n",
      "loss 2.303275, train acc 0.098796\n",
      "round 48\n",
      "time to device 0.006699 sec\n",
      "time forward 0.672716 sec\n",
      "loss time 0.001838 sec\n",
      "backward time 0.017256 sec\n",
      "optimizer time 0.024331 sec\n",
      "training time in round 48 cost 0.4069700241088867 sec\n",
      "loss 2.303243, train acc 0.098852\n",
      "round 49\n",
      "time to device 0.008582 sec\n",
      "time forward 0.684400 sec\n",
      "loss time 0.001401 sec\n",
      "backward time 0.013024 sec\n",
      "optimizer time 0.025608 sec\n",
      "training time in round 49 cost 0.3941488265991211 sec\n",
      "loss 2.303296, train acc 0.098125\n",
      "round 50\n",
      "time to device 0.007240 sec\n",
      "time forward 0.699056 sec\n",
      "loss time 0.001364 sec\n",
      "backward time 0.012527 sec\n",
      "optimizer time 0.021992 sec\n",
      "training time in round 50 cost 0.3992331027984619 sec\n",
      "loss 2.303349, train acc 0.098192\n",
      "round 51\n",
      "time to device 0.005905 sec\n",
      "time forward 0.711732 sec\n",
      "loss time 0.001140 sec\n",
      "backward time 0.016186 sec\n",
      "optimizer time 0.019900 sec\n",
      "training time in round 51 cost 0.3941917419433594 sec\n",
      "loss 2.303804, train acc 0.097806\n",
      "round 52\n",
      "time to device 0.004667 sec\n",
      "time forward 0.724899 sec\n",
      "loss time 0.001810 sec\n",
      "backward time 0.023756 sec\n",
      "optimizer time 0.020597 sec\n",
      "training time in round 52 cost 0.4014420509338379 sec\n",
      "loss 2.303812, train acc 0.097435\n",
      "round 53\n",
      "time to device 0.008298 sec\n",
      "time forward 0.739705 sec\n",
      "loss time 0.001936 sec\n",
      "backward time 0.012699 sec\n",
      "optimizer time 0.022385 sec\n",
      "training time in round 53 cost 0.4041321277618408 sec\n",
      "loss 2.303843, train acc 0.096933\n",
      "round 54\n",
      "time to device 0.004443 sec\n",
      "time forward 0.752805 sec\n",
      "loss time 0.001839 sec\n",
      "backward time 0.009889 sec\n",
      "optimizer time 0.027413 sec\n",
      "training time in round 54 cost 0.41512084007263184 sec\n",
      "loss 2.303811, train acc 0.096591\n",
      "round 55\n",
      "time to device 0.004663 sec\n",
      "time forward 0.760951 sec\n",
      "loss time 0.000566 sec\n",
      "backward time 0.005051 sec\n",
      "optimizer time 0.013626 sec\n",
      "training time in round 55 cost 0.3550100326538086 sec\n",
      "loss 2.303870, train acc 0.096680\n",
      "round 56\n",
      "time to device 0.004265 sec\n",
      "time forward 0.772195 sec\n",
      "loss time 0.001529 sec\n",
      "backward time 0.012566 sec\n",
      "optimizer time 0.026534 sec\n",
      "training time in round 56 cost 0.41112804412841797 sec\n",
      "loss 2.303781, train acc 0.096902\n",
      "round 57\n",
      "time to device 0.005355 sec\n",
      "time forward 0.785326 sec\n",
      "loss time 0.002259 sec\n",
      "backward time 0.012776 sec\n",
      "optimizer time 0.026162 sec\n",
      "training time in round 57 cost 0.4052920341491699 sec\n",
      "loss 2.303744, train acc 0.096848\n",
      "round 58\n",
      "time to device 0.005523 sec\n",
      "time forward 0.798631 sec\n",
      "loss time 0.001252 sec\n",
      "backward time 0.018473 sec\n",
      "optimizer time 0.022308 sec\n",
      "training time in round 58 cost 0.431901216506958 sec\n",
      "loss 2.303820, train acc 0.095869\n",
      "round 59\n",
      "time to device 0.004490 sec\n",
      "time forward 0.812453 sec\n",
      "loss time 0.001282 sec\n",
      "backward time 0.012143 sec\n",
      "optimizer time 0.023388 sec\n",
      "training time in round 59 cost 0.4446721076965332 sec\n",
      "loss 2.303829, train acc 0.096484\n",
      "round 60\n",
      "time to device 0.007487 sec\n",
      "time forward 0.824753 sec\n",
      "loss time 0.001430 sec\n",
      "backward time 0.014448 sec\n",
      "optimizer time 0.019074 sec\n",
      "training time in round 60 cost 0.3869283199310303 sec\n",
      "loss 2.303839, train acc 0.096055\n",
      "round 61\n",
      "time to device 0.005521 sec\n",
      "time forward 0.838760 sec\n",
      "loss time 0.001454 sec\n",
      "backward time 0.011586 sec\n",
      "optimizer time 0.021727 sec\n",
      "training time in round 61 cost 0.4052920341491699 sec\n",
      "loss 2.303816, train acc 0.095514\n",
      "round 62\n",
      "time to device 0.003605 sec\n",
      "time forward 0.846893 sec\n",
      "loss time 0.000534 sec\n",
      "backward time 0.007022 sec\n",
      "optimizer time 0.036240 sec\n",
      "training time in round 62 cost 0.4455742835998535 sec\n",
      "loss 2.303824, train acc 0.095610\n",
      "round 63\n",
      "time to device 0.008618 sec\n",
      "time forward 0.866968 sec\n",
      "loss time 0.002000 sec\n",
      "backward time 0.016953 sec\n",
      "optimizer time 0.026484 sec\n",
      "training time in round 63 cost 0.42387819290161133 sec\n",
      "loss 2.303828, train acc 0.095947\n",
      "round 64\n",
      "time to device 0.007297 sec\n",
      "time forward 0.880396 sec\n",
      "loss time 0.000971 sec\n",
      "backward time 0.011773 sec\n",
      "optimizer time 0.031590 sec\n",
      "training time in round 64 cost 0.4393422603607178 sec\n",
      "loss 2.303831, train acc 0.095673\n",
      "round 65\n",
      "time to device 0.007048 sec\n",
      "time forward 0.891789 sec\n",
      "loss time 0.001542 sec\n",
      "backward time 0.010626 sec\n",
      "optimizer time 0.034685 sec\n",
      "training time in round 65 cost 0.4012439250946045 sec\n",
      "loss 2.303813, train acc 0.095881\n",
      "round 66\n",
      "time to device 0.007477 sec\n",
      "time forward 0.904122 sec\n",
      "loss time 0.001541 sec\n",
      "backward time 0.016761 sec\n",
      "optimizer time 0.025937 sec\n",
      "training time in round 66 cost 0.42778801918029785 sec\n",
      "loss 2.303774, train acc 0.095732\n",
      "round 67\n",
      "time to device 0.005732 sec\n",
      "time forward 0.913637 sec\n",
      "loss time 0.000750 sec\n",
      "backward time 0.006622 sec\n",
      "optimizer time 0.019918 sec\n",
      "training time in round 67 cost 0.36562490463256836 sec\n",
      "loss 2.303787, train acc 0.096163\n",
      "round 68\n",
      "time to device 0.007228 sec\n",
      "time forward 0.927105 sec\n",
      "loss time 0.000603 sec\n",
      "backward time 0.010197 sec\n",
      "optimizer time 0.022429 sec\n",
      "training time in round 68 cost 0.3978402614593506 sec\n",
      "loss 2.303724, train acc 0.096128\n",
      "round 69\n",
      "time to device 0.008879 sec\n",
      "time forward 0.939954 sec\n",
      "loss time 0.000974 sec\n",
      "backward time 0.014199 sec\n",
      "optimizer time 0.030108 sec\n",
      "training time in round 69 cost 0.4165651798248291 sec\n",
      "loss 2.303708, train acc 0.095759\n",
      "round 70\n",
      "time to device 0.009099 sec\n",
      "time forward 0.952659 sec\n",
      "loss time 0.001655 sec\n",
      "backward time 0.015487 sec\n",
      "optimizer time 0.017082 sec\n",
      "training time in round 70 cost 0.4486048221588135 sec\n",
      "loss 2.303718, train acc 0.095841\n",
      "round 71\n",
      "time to device 0.008101 sec\n",
      "time forward 0.968028 sec\n",
      "loss time 0.001250 sec\n",
      "backward time 0.010376 sec\n",
      "optimizer time 0.014621 sec\n",
      "training time in round 71 cost 0.44188404083251953 sec\n",
      "loss 2.303706, train acc 0.096354\n",
      "round 72\n",
      "time to device 0.006915 sec\n",
      "time forward 0.980852 sec\n",
      "loss time 0.001982 sec\n",
      "backward time 0.014510 sec\n",
      "optimizer time 0.020369 sec\n",
      "training time in round 72 cost 0.43228697776794434 sec\n",
      "loss 2.303711, train acc 0.096211\n",
      "round 73\n",
      "time to device 0.009288 sec\n",
      "time forward 0.992275 sec\n",
      "loss time 0.001446 sec\n",
      "backward time 0.014649 sec\n",
      "optimizer time 0.023115 sec\n",
      "training time in round 73 cost 0.4213120937347412 sec\n",
      "loss 2.303721, train acc 0.095967\n",
      "round 74\n",
      "time to device 0.007319 sec\n",
      "time forward 1.010829 sec\n",
      "loss time 0.002428 sec\n",
      "backward time 0.052925 sec\n",
      "optimizer time 0.032077 sec\n",
      "training time in round 74 cost 0.5302262306213379 sec\n",
      "loss 2.303664, train acc 0.095729\n",
      "round 75\n",
      "time to device 0.006234 sec\n",
      "time forward 1.018484 sec\n",
      "loss time 0.000548 sec\n",
      "backward time 0.005408 sec\n",
      "optimizer time 0.016157 sec\n",
      "training time in round 75 cost 0.45431089401245117 sec\n",
      "loss 2.303674, train acc 0.095600\n",
      "round 76\n",
      "time to device 0.006927 sec\n",
      "time forward 1.032241 sec\n",
      "loss time 0.001758 sec\n",
      "backward time 0.012942 sec\n",
      "optimizer time 0.041073 sec\n",
      "training time in round 76 cost 0.5430920124053955 sec\n",
      "loss 2.303719, train acc 0.095069\n",
      "round 77\n",
      "time to device 0.007783 sec\n",
      "time forward 1.046816 sec\n",
      "loss time 0.001182 sec\n",
      "backward time 0.028320 sec\n",
      "optimizer time 0.030050 sec\n",
      "training time in round 77 cost 0.6236979961395264 sec\n",
      "loss 2.303693, train acc 0.095252\n",
      "round 78\n",
      "time to device 0.008942 sec\n",
      "time forward 1.062786 sec\n",
      "loss time 0.001761 sec\n",
      "backward time 0.019506 sec\n",
      "optimizer time 0.024432 sec\n",
      "training time in round 78 cost 0.5056121349334717 sec\n",
      "loss 2.303680, train acc 0.095629\n",
      "round 79\n",
      "time to device 0.016398 sec\n",
      "time forward 1.073632 sec\n",
      "loss time 0.000494 sec\n",
      "backward time 0.004276 sec\n",
      "optimizer time 0.015904 sec\n",
      "training time in round 79 cost 0.4215400218963623 sec\n",
      "loss 2.303845, train acc 0.096094\n",
      "round 80\n",
      "time to device 0.007581 sec\n",
      "time forward 1.083819 sec\n",
      "loss time 0.000877 sec\n",
      "backward time 0.007095 sec\n",
      "optimizer time 0.025505 sec\n",
      "training time in round 80 cost 0.37613606452941895 sec\n",
      "loss 2.303808, train acc 0.096161\n",
      "round 81\n",
      "time to device 0.008787 sec\n",
      "time forward 1.090485 sec\n",
      "loss time 0.000769 sec\n",
      "backward time 0.007046 sec\n",
      "optimizer time 0.018490 sec\n",
      "training time in round 81 cost 0.37990474700927734 sec\n",
      "loss 2.303806, train acc 0.095846\n",
      "round 82\n",
      "time to device 0.007347 sec\n",
      "time forward 1.097502 sec\n",
      "loss time 0.001014 sec\n",
      "backward time 0.008405 sec\n",
      "optimizer time 0.020216 sec\n",
      "training time in round 82 cost 0.37783312797546387 sec\n",
      "loss 2.303828, train acc 0.095350\n",
      "round 83\n",
      "time to device 0.008577 sec\n",
      "time forward 1.110821 sec\n",
      "loss time 0.000934 sec\n",
      "backward time 0.008219 sec\n",
      "optimizer time 0.020338 sec\n",
      "training time in round 83 cost 0.3866899013519287 sec\n",
      "loss 2.303854, train acc 0.095331\n",
      "round 84\n",
      "time to device 0.006953 sec\n",
      "time forward 1.123363 sec\n",
      "loss time 0.001317 sec\n",
      "backward time 0.009933 sec\n",
      "optimizer time 0.021586 sec\n",
      "training time in round 84 cost 0.3786048889160156 sec\n",
      "loss 2.303852, train acc 0.095404\n",
      "round 85\n",
      "time to device 0.006808 sec\n",
      "time forward 1.132762 sec\n",
      "loss time 0.000928 sec\n",
      "backward time 0.007417 sec\n",
      "optimizer time 0.021718 sec\n",
      "training time in round 85 cost 0.37366795539855957 sec\n",
      "loss 2.303828, train acc 0.095294\n",
      "round 86\n",
      "time to device 0.007075 sec\n",
      "time forward 1.143334 sec\n",
      "loss time 0.001101 sec\n",
      "backward time 0.008542 sec\n",
      "optimizer time 0.020737 sec\n",
      "training time in round 86 cost 0.378558874130249 sec\n",
      "loss 2.303798, train acc 0.095277\n",
      "round 87\n",
      "time to device 0.007115 sec\n",
      "time forward 1.151148 sec\n",
      "loss time 0.000631 sec\n",
      "backward time 0.007200 sec\n",
      "optimizer time 0.018361 sec\n",
      "training time in round 87 cost 0.3785102367401123 sec\n",
      "loss 2.303770, train acc 0.095348\n",
      "round 88\n",
      "time to device 0.005690 sec\n",
      "time forward 1.160838 sec\n",
      "loss time 0.000866 sec\n",
      "backward time 0.008148 sec\n",
      "optimizer time 0.019602 sec\n",
      "training time in round 88 cost 0.37206602096557617 sec\n",
      "loss 2.303783, train acc 0.095242\n",
      "round 89\n",
      "time to device 0.006421 sec\n",
      "time forward 1.171027 sec\n",
      "loss time 0.001129 sec\n",
      "backward time 0.009187 sec\n",
      "optimizer time 0.020353 sec\n",
      "training time in round 89 cost 0.38591909408569336 sec\n",
      "loss 2.303796, train acc 0.095399\n",
      "round 90\n",
      "time to device 0.006117 sec\n",
      "time forward 1.180884 sec\n",
      "loss time 0.001118 sec\n",
      "backward time 0.015654 sec\n",
      "optimizer time 0.019930 sec\n",
      "training time in round 90 cost 0.3788580894470215 sec\n",
      "loss 2.303816, train acc 0.095209\n",
      "round 91\n",
      "time to device 0.003287 sec\n",
      "time forward 1.190586 sec\n",
      "loss time 0.001125 sec\n",
      "backward time 0.008081 sec\n",
      "optimizer time 0.019855 sec\n",
      "training time in round 91 cost 0.3674910068511963 sec\n",
      "loss 2.303775, train acc 0.095363\n",
      "round 92\n",
      "time to device 0.003460 sec\n",
      "time forward 1.199959 sec\n",
      "loss time 0.000724 sec\n",
      "backward time 0.006919 sec\n",
      "optimizer time 0.022310 sec\n",
      "training time in round 92 cost 0.3854689598083496 sec\n",
      "loss 2.303781, train acc 0.095262\n",
      "round 93\n",
      "time to device 0.003988 sec\n",
      "time forward 1.209521 sec\n",
      "loss time 0.000899 sec\n",
      "backward time 0.008114 sec\n",
      "optimizer time 0.019899 sec\n",
      "training time in round 93 cost 0.3645181655883789 sec\n",
      "loss 2.303762, train acc 0.095163\n",
      "round 94\n",
      "time to device 0.007130 sec\n",
      "time forward 1.217832 sec\n",
      "loss time 0.000718 sec\n",
      "backward time 0.008309 sec\n",
      "optimizer time 0.020171 sec\n",
      "training time in round 94 cost 0.3683662414550781 sec\n",
      "loss 2.303768, train acc 0.094901\n",
      "round 95\n",
      "time to device 0.006121 sec\n",
      "time forward 1.228835 sec\n",
      "loss time 0.000941 sec\n",
      "backward time 0.008232 sec\n",
      "optimizer time 0.019558 sec\n",
      "training time in round 95 cost 0.36605072021484375 sec\n",
      "loss 2.303761, train acc 0.094971\n",
      "round 96\n",
      "time to device 0.002967 sec\n",
      "time forward 1.234346 sec\n",
      "loss time 0.000738 sec\n",
      "backward time 0.006070 sec\n",
      "optimizer time 0.016199 sec\n",
      "training time in round 96 cost 0.3457200527191162 sec\n",
      "loss 2.303708, train acc 0.095119\n",
      "round 97\n",
      "time to device 0.006987 sec\n",
      "time forward 1.245505 sec\n",
      "loss time 0.000691 sec\n",
      "backward time 0.006719 sec\n",
      "optimizer time 0.020215 sec\n",
      "training time in round 97 cost 0.3970010280609131 sec\n",
      "loss 2.303685, train acc 0.095185\n",
      "round 98\n",
      "time to device 0.006804 sec\n",
      "time forward 1.254322 sec\n",
      "loss time 0.000886 sec\n",
      "backward time 0.007616 sec\n",
      "optimizer time 0.019269 sec\n",
      "training time in round 98 cost 0.35969996452331543 sec\n",
      "loss 2.303666, train acc 0.095328\n",
      "round 99\n",
      "time to device 0.007825 sec\n",
      "time forward 1.262227 sec\n",
      "loss time 0.001009 sec\n",
      "backward time 0.008335 sec\n",
      "optimizer time 0.019682 sec\n",
      "training time in round 99 cost 0.3779280185699463 sec\n",
      "loss 2.303695, train acc 0.095234\n",
      "round 100\n",
      "time to device 0.007452 sec\n",
      "time forward 1.271322 sec\n",
      "loss time 0.000881 sec\n",
      "backward time 0.008296 sec\n",
      "optimizer time 0.019267 sec\n",
      "training time in round 100 cost 0.36165285110473633 sec\n",
      "loss 2.303681, train acc 0.094910\n",
      "round 101\n",
      "time to device 0.008001 sec\n",
      "time forward 1.283600 sec\n",
      "loss time 0.000909 sec\n",
      "backward time 0.007454 sec\n",
      "optimizer time 0.018508 sec\n",
      "training time in round 101 cost 0.38724398612976074 sec\n",
      "loss 2.303674, train acc 0.094746\n",
      "round 102\n",
      "time to device 0.006829 sec\n",
      "time forward 1.293154 sec\n",
      "loss time 0.001317 sec\n",
      "backward time 0.008548 sec\n",
      "optimizer time 0.020668 sec\n",
      "training time in round 102 cost 0.3686411380767822 sec\n",
      "loss 2.303690, train acc 0.094888\n",
      "round 103\n",
      "time to device 0.006878 sec\n",
      "time forward 1.302350 sec\n",
      "loss time 0.000874 sec\n",
      "backward time 0.007937 sec\n",
      "optimizer time 0.018530 sec\n",
      "training time in round 103 cost 0.3610529899597168 sec\n",
      "loss 2.303743, train acc 0.095102\n",
      "round 104\n",
      "time to device 0.008963 sec\n",
      "time forward 1.311982 sec\n",
      "loss time 0.001056 sec\n",
      "backward time 0.008393 sec\n",
      "optimizer time 0.019745 sec\n",
      "training time in round 104 cost 0.37305593490600586 sec\n",
      "loss 2.303731, train acc 0.095238\n",
      "round 105\n",
      "time to device 0.007278 sec\n",
      "time forward 1.320069 sec\n",
      "loss time 0.000877 sec\n",
      "backward time 0.008286 sec\n",
      "optimizer time 0.020506 sec\n",
      "training time in round 105 cost 0.3644568920135498 sec\n",
      "loss 2.303722, train acc 0.095371\n",
      "round 106\n",
      "time to device 0.007189 sec\n",
      "time forward 1.330845 sec\n",
      "loss time 0.000858 sec\n",
      "backward time 0.008299 sec\n",
      "optimizer time 0.019272 sec\n",
      "training time in round 106 cost 0.3761179447174072 sec\n",
      "loss 2.303714, train acc 0.095575\n",
      "round 107\n",
      "time to device 0.007176 sec\n",
      "time forward 1.339832 sec\n",
      "loss time 0.001104 sec\n",
      "backward time 0.014764 sec\n",
      "optimizer time 0.019752 sec\n",
      "training time in round 107 cost 0.37569212913513184 sec\n",
      "loss 2.303736, train acc 0.095558\n",
      "round 108\n",
      "time to device 0.006838 sec\n",
      "time forward 1.349114 sec\n",
      "loss time 0.001075 sec\n",
      "backward time 0.008920 sec\n",
      "optimizer time 0.020309 sec\n",
      "training time in round 108 cost 0.3748130798339844 sec\n",
      "loss 2.303704, train acc 0.095900\n",
      "round 109\n",
      "time to device 0.006279 sec\n",
      "time forward 1.359110 sec\n",
      "loss time 0.000952 sec\n",
      "backward time 0.008086 sec\n",
      "optimizer time 0.019925 sec\n",
      "training time in round 109 cost 0.36467719078063965 sec\n",
      "loss 2.303705, train acc 0.096094\n",
      "round 110\n",
      "time to device 0.004167 sec\n",
      "time forward 1.363060 sec\n",
      "loss time 0.000434 sec\n",
      "backward time 0.003805 sec\n",
      "optimizer time 0.011260 sec\n",
      "training time in round 110 cost 0.32834291458129883 sec\n",
      "loss 2.303689, train acc 0.096143\n",
      "round 111\n",
      "time to device 0.022016 sec\n",
      "time forward 1.377059 sec\n",
      "loss time 0.004294 sec\n",
      "backward time 0.013621 sec\n",
      "optimizer time 0.070410 sec\n",
      "training time in round 111 cost 0.5327270030975342 sec\n",
      "loss 2.303668, train acc 0.096331\n",
      "round 112\n",
      "time to device 0.007579 sec\n",
      "time forward 1.390963 sec\n",
      "loss time 0.002606 sec\n",
      "backward time 0.017772 sec\n",
      "optimizer time 0.026352 sec\n",
      "training time in round 112 cost 0.42810893058776855 sec\n",
      "loss 2.303671, train acc 0.096377\n",
      "round 113\n",
      "time to device 0.012141 sec\n",
      "time forward 1.403119 sec\n",
      "loss time 0.001457 sec\n",
      "backward time 0.012867 sec\n",
      "optimizer time 0.020633 sec\n",
      "training time in round 113 cost 0.4089088439941406 sec\n",
      "loss 2.303682, train acc 0.096354\n",
      "round 114\n",
      "time to device 0.007233 sec\n",
      "time forward 1.415514 sec\n",
      "loss time 0.002015 sec\n",
      "backward time 0.015975 sec\n",
      "optimizer time 0.027922 sec\n",
      "training time in round 114 cost 0.42028212547302246 sec\n",
      "loss 2.303709, train acc 0.095992\n",
      "round 115\n",
      "time to device 0.008178 sec\n",
      "time forward 1.429105 sec\n",
      "loss time 0.001224 sec\n",
      "backward time 0.022986 sec\n",
      "optimizer time 0.021672 sec\n",
      "training time in round 115 cost 0.4098548889160156 sec\n",
      "loss 2.303743, train acc 0.095568\n",
      "round 116\n",
      "time to device 0.008204 sec\n",
      "time forward 1.442251 sec\n",
      "loss time 0.001489 sec\n",
      "backward time 0.011190 sec\n",
      "optimizer time 0.024664 sec\n",
      "training time in round 116 cost 0.4239819049835205 sec\n",
      "loss 2.303749, train acc 0.095753\n",
      "round 117\n",
      "time to device 0.007311 sec\n",
      "time forward 1.456684 sec\n",
      "loss time 0.001584 sec\n",
      "backward time 0.012095 sec\n",
      "optimizer time 0.023156 sec\n",
      "training time in round 117 cost 0.4004499912261963 sec\n",
      "loss 2.303742, train acc 0.095869\n",
      "round 118\n",
      "time to device 0.009285 sec\n",
      "time forward 1.469347 sec\n",
      "loss time 0.001456 sec\n",
      "backward time 0.012190 sec\n",
      "optimizer time 0.022751 sec\n",
      "training time in round 118 cost 0.39575910568237305 sec\n",
      "loss 2.303757, train acc 0.095720\n",
      "round 119\n",
      "time to device 0.009678 sec\n",
      "time forward 1.480679 sec\n",
      "loss time 0.001322 sec\n",
      "backward time 0.011585 sec\n",
      "optimizer time 0.021807 sec\n",
      "training time in round 119 cost 0.3908882141113281 sec\n",
      "loss 2.303769, train acc 0.095378\n",
      "round 120\n",
      "time to device 0.007691 sec\n",
      "time forward 1.496224 sec\n",
      "loss time 0.002357 sec\n",
      "backward time 0.016652 sec\n",
      "optimizer time 0.024744 sec\n",
      "training time in round 120 cost 0.45663905143737793 sec\n",
      "loss 2.303764, train acc 0.095235\n",
      "round 121\n",
      "time to device 0.010852 sec\n",
      "time forward 1.509377 sec\n",
      "loss time 0.001602 sec\n",
      "backward time 0.013628 sec\n",
      "optimizer time 0.023540 sec\n",
      "training time in round 121 cost 0.42397093772888184 sec\n",
      "loss 2.303828, train acc 0.094903\n",
      "round 122\n",
      "time to device 0.008216 sec\n",
      "time forward 1.528181 sec\n",
      "loss time 0.002594 sec\n",
      "backward time 0.013453 sec\n",
      "optimizer time 0.027426 sec\n",
      "training time in round 122 cost 0.42270994186401367 sec\n",
      "loss 2.303749, train acc 0.094766\n",
      "round 123\n",
      "time to device 0.008501 sec\n",
      "time forward 1.545533 sec\n",
      "loss time 0.001428 sec\n",
      "backward time 0.013062 sec\n",
      "optimizer time 0.021379 sec\n",
      "training time in round 123 cost 0.41175317764282227 sec\n",
      "loss 2.303743, train acc 0.095136\n",
      "round 124\n",
      "time to device 0.009676 sec\n",
      "time forward 1.561841 sec\n",
      "loss time 0.001601 sec\n",
      "backward time 0.018834 sec\n",
      "optimizer time 0.022260 sec\n",
      "training time in round 124 cost 0.42946815490722656 sec\n",
      "loss 2.304026, train acc 0.095312\n",
      "round 125\n",
      "time to device 0.005462 sec\n",
      "time forward 1.575704 sec\n",
      "loss time 0.001438 sec\n",
      "backward time 0.013513 sec\n",
      "optimizer time 0.028403 sec\n",
      "training time in round 125 cost 0.41458797454833984 sec\n",
      "loss 2.304020, train acc 0.095300\n",
      "round 126\n",
      "time to device 0.007264 sec\n",
      "time forward 1.588664 sec\n",
      "loss time 0.002680 sec\n",
      "backward time 0.021868 sec\n",
      "optimizer time 0.020815 sec\n",
      "training time in round 126 cost 0.4132671356201172 sec\n",
      "loss 2.304017, train acc 0.095042\n",
      "round 127\n",
      "time to device 0.007650 sec\n",
      "time forward 1.603434 sec\n",
      "loss time 0.001431 sec\n",
      "backward time 0.013997 sec\n",
      "optimizer time 0.023593 sec\n",
      "training time in round 127 cost 0.41789793968200684 sec\n",
      "loss 2.304012, train acc 0.095093\n",
      "round 128\n",
      "time to device 0.004375 sec\n",
      "time forward 1.620738 sec\n",
      "loss time 0.002233 sec\n",
      "backward time 0.018417 sec\n",
      "optimizer time 0.022418 sec\n",
      "training time in round 128 cost 0.4186978340148926 sec\n",
      "loss 2.303993, train acc 0.095325\n",
      "round 129\n",
      "time to device 0.003285 sec\n",
      "time forward 1.634645 sec\n",
      "loss time 0.002090 sec\n",
      "backward time 0.015585 sec\n",
      "optimizer time 0.023725 sec\n",
      "training time in round 129 cost 0.39943909645080566 sec\n",
      "loss 2.303975, train acc 0.095793\n",
      "round 130\n",
      "time to device 0.005713 sec\n",
      "time forward 1.650348 sec\n",
      "loss time 0.001023 sec\n",
      "backward time 0.010490 sec\n",
      "optimizer time 0.023543 sec\n",
      "training time in round 130 cost 0.39433789253234863 sec\n",
      "loss 2.303966, train acc 0.095897\n",
      "round 131\n",
      "time to device 0.003327 sec\n",
      "time forward 1.657917 sec\n",
      "loss time 0.000552 sec\n",
      "backward time 0.005114 sec\n",
      "optimizer time 0.013620 sec\n",
      "training time in round 131 cost 0.35298824310302734 sec\n",
      "loss 2.303962, train acc 0.095999\n",
      "round 132\n",
      "time to device 0.004475 sec\n",
      "time forward 1.670109 sec\n",
      "loss time 0.001451 sec\n",
      "backward time 0.018161 sec\n",
      "optimizer time 0.021239 sec\n",
      "training time in round 132 cost 0.41078805923461914 sec\n",
      "loss 2.303976, train acc 0.095923\n",
      "round 133\n",
      "time to device 0.003580 sec\n",
      "time forward 1.691992 sec\n",
      "loss time 0.001225 sec\n",
      "backward time 0.011893 sec\n",
      "optimizer time 0.022035 sec\n",
      "training time in round 133 cost 0.4812760353088379 sec\n",
      "loss 2.303958, train acc 0.095849\n",
      "round 134\n",
      "time to device 0.008822 sec\n",
      "time forward 1.706950 sec\n",
      "loss time 0.001457 sec\n",
      "backward time 0.014133 sec\n",
      "optimizer time 0.025991 sec\n",
      "training time in round 134 cost 0.4073910713195801 sec\n",
      "loss 2.303965, train acc 0.096181\n",
      "round 135\n",
      "time to device 0.006455 sec\n",
      "time forward 1.722664 sec\n",
      "loss time 0.001780 sec\n",
      "backward time 0.015526 sec\n",
      "optimizer time 0.026353 sec\n",
      "training time in round 135 cost 0.40563201904296875 sec\n",
      "loss 2.304016, train acc 0.096163\n",
      "round 136\n",
      "time to device 0.009383 sec\n",
      "time forward 1.738484 sec\n",
      "loss time 0.001412 sec\n",
      "backward time 0.013410 sec\n",
      "optimizer time 0.025138 sec\n",
      "training time in round 136 cost 0.4131298065185547 sec\n",
      "loss 2.304020, train acc 0.095746\n",
      "round 137\n",
      "time to device 0.003192 sec\n",
      "time forward 1.751328 sec\n",
      "loss time 0.001682 sec\n",
      "backward time 0.014153 sec\n",
      "optimizer time 0.023018 sec\n",
      "training time in round 137 cost 0.3879890441894531 sec\n",
      "loss 2.304013, train acc 0.095731\n",
      "round 138\n",
      "time to device 0.002647 sec\n",
      "time forward 1.768789 sec\n",
      "loss time 0.001306 sec\n",
      "backward time 0.015664 sec\n",
      "optimizer time 0.026973 sec\n",
      "training time in round 138 cost 0.474135160446167 sec\n",
      "loss 2.304005, train acc 0.095942\n",
      "round 139\n",
      "time to device 0.009846 sec\n",
      "time forward 1.780978 sec\n",
      "loss time 0.002502 sec\n",
      "backward time 0.014981 sec\n",
      "optimizer time 0.025662 sec\n",
      "training time in round 139 cost 0.39577198028564453 sec\n",
      "loss 2.304028, train acc 0.095815\n",
      "round 140\n",
      "time to device 0.007491 sec\n",
      "time forward 1.793969 sec\n",
      "loss time 0.001252 sec\n",
      "backward time 0.010903 sec\n",
      "optimizer time 0.022926 sec\n",
      "training time in round 140 cost 0.3957328796386719 sec\n",
      "loss 2.304005, train acc 0.095966\n",
      "round 141\n",
      "time to device 0.010625 sec\n",
      "time forward 1.809173 sec\n",
      "loss time 0.001418 sec\n",
      "backward time 0.020328 sec\n",
      "optimizer time 0.017719 sec\n",
      "training time in round 141 cost 0.4301021099090576 sec\n",
      "loss 2.303987, train acc 0.096171\n",
      "round 142\n",
      "time to device 0.004924 sec\n",
      "time forward 1.826622 sec\n",
      "loss time 0.001126 sec\n",
      "backward time 0.015507 sec\n",
      "optimizer time 0.022789 sec\n",
      "training time in round 142 cost 0.40480518341064453 sec\n",
      "loss 2.303975, train acc 0.096154\n",
      "round 143\n",
      "time to device 0.004400 sec\n",
      "time forward 1.841128 sec\n",
      "loss time 0.001400 sec\n",
      "backward time 0.013497 sec\n",
      "optimizer time 0.011459 sec\n",
      "training time in round 143 cost 0.41296911239624023 sec\n",
      "loss 2.303951, train acc 0.096354\n",
      "round 144\n",
      "time to device 0.006246 sec\n",
      "time forward 1.857017 sec\n",
      "loss time 0.001812 sec\n",
      "backward time 0.013876 sec\n",
      "optimizer time 0.024643 sec\n",
      "training time in round 144 cost 0.4341452121734619 sec\n",
      "loss 2.303943, train acc 0.096067\n",
      "round 145\n",
      "time to device 0.008895 sec\n",
      "time forward 1.873080 sec\n",
      "loss time 0.001619 sec\n",
      "backward time 0.012296 sec\n",
      "optimizer time 0.026772 sec\n",
      "training time in round 145 cost 0.42709803581237793 sec\n",
      "loss 2.304259, train acc 0.096372\n",
      "round 146\n",
      "time to device 0.006736 sec\n",
      "time forward 1.888626 sec\n",
      "loss time 0.001589 sec\n",
      "backward time 0.016982 sec\n",
      "optimizer time 0.021807 sec\n",
      "training time in round 146 cost 0.40631103515625 sec\n",
      "loss 2.304247, train acc 0.096460\n",
      "round 147\n",
      "time to device 0.009988 sec\n",
      "time forward 1.904179 sec\n",
      "loss time 0.001330 sec\n",
      "backward time 0.013165 sec\n",
      "optimizer time 0.021926 sec\n",
      "training time in round 147 cost 0.41552019119262695 sec\n",
      "loss 2.304227, train acc 0.096337\n",
      "round 148\n",
      "time to device 0.006957 sec\n",
      "time forward 1.916154 sec\n",
      "loss time 0.001509 sec\n",
      "backward time 0.011049 sec\n",
      "optimizer time 0.026772 sec\n",
      "training time in round 148 cost 0.3896510601043701 sec\n",
      "loss 2.304244, train acc 0.096109\n",
      "round 149\n",
      "time to device 0.008532 sec\n",
      "time forward 1.925917 sec\n",
      "loss time 0.001787 sec\n",
      "backward time 0.014667 sec\n",
      "optimizer time 0.022399 sec\n",
      "training time in round 149 cost 0.3852980136871338 sec\n",
      "loss 2.304265, train acc 0.096198\n",
      "round 150\n",
      "time to device 0.006324 sec\n",
      "time forward 1.941434 sec\n",
      "loss time 0.001953 sec\n",
      "backward time 0.014387 sec\n",
      "optimizer time 0.032979 sec\n",
      "training time in round 150 cost 0.4568359851837158 sec\n",
      "loss 2.304259, train acc 0.096285\n",
      "round 151\n",
      "time to device 0.007798 sec\n",
      "time forward 1.956484 sec\n",
      "loss time 0.001433 sec\n",
      "backward time 0.014117 sec\n",
      "optimizer time 0.024113 sec\n",
      "training time in round 151 cost 0.3969850540161133 sec\n",
      "loss 2.304263, train acc 0.096114\n",
      "round 152\n",
      "time to device 0.008158 sec\n",
      "time forward 1.963387 sec\n",
      "loss time 0.000638 sec\n",
      "backward time 0.005707 sec\n",
      "optimizer time 0.014623 sec\n",
      "training time in round 152 cost 0.35581398010253906 sec\n",
      "loss 2.304300, train acc 0.096048\n",
      "round 153\n",
      "time to device 0.003812 sec\n",
      "time forward 1.978252 sec\n",
      "loss time 0.001387 sec\n",
      "backward time 0.012298 sec\n",
      "optimizer time 0.022877 sec\n",
      "training time in round 153 cost 0.39222121238708496 sec\n",
      "loss 2.304292, train acc 0.095881\n",
      "round 154\n",
      "time to device 0.006550 sec\n",
      "time forward 1.992450 sec\n",
      "loss time 0.002170 sec\n",
      "backward time 0.014618 sec\n",
      "optimizer time 0.032577 sec\n",
      "training time in round 154 cost 0.4067702293395996 sec\n",
      "loss 2.304331, train acc 0.095514\n",
      "round 155\n",
      "time to device 0.006962 sec\n",
      "time forward 2.007271 sec\n",
      "loss time 0.001894 sec\n",
      "backward time 0.010694 sec\n",
      "optimizer time 0.023968 sec\n",
      "training time in round 155 cost 0.40622997283935547 sec\n",
      "loss 2.304354, train acc 0.095603\n",
      "round 156\n",
      "time to device 0.005482 sec\n",
      "time forward 2.012953 sec\n",
      "loss time 0.000510 sec\n",
      "backward time 0.004384 sec\n",
      "optimizer time 0.012866 sec\n",
      "training time in round 156 cost 0.4236259460449219 sec\n",
      "loss 2.304336, train acc 0.095591\n",
      "round 157\n",
      "time to device 0.008428 sec\n",
      "time forward 2.017677 sec\n",
      "loss time 0.000531 sec\n",
      "backward time 0.004010 sec\n",
      "optimizer time 0.013807 sec\n",
      "training time in round 157 cost 0.3820798397064209 sec\n",
      "loss 2.304320, train acc 0.095728\n",
      "round 158\n",
      "time to device 0.006073 sec\n",
      "time forward 2.023798 sec\n",
      "loss time 0.000588 sec\n",
      "backward time 0.003880 sec\n",
      "optimizer time 0.016353 sec\n",
      "training time in round 158 cost 0.4108700752258301 sec\n",
      "loss 2.304312, train acc 0.095765\n",
      "round 159\n",
      "time to device 0.008349 sec\n",
      "time forward 2.039813 sec\n",
      "loss time 0.001147 sec\n",
      "backward time 0.009457 sec\n",
      "optimizer time 0.021062 sec\n",
      "training time in round 159 cost 0.4148268699645996 sec\n",
      "loss 2.304286, train acc 0.095850\n",
      "round 160\n",
      "time to device 0.012864 sec\n",
      "time forward 2.052524 sec\n",
      "loss time 0.001095 sec\n",
      "backward time 0.008550 sec\n",
      "optimizer time 0.021920 sec\n",
      "training time in round 160 cost 0.39532923698425293 sec\n",
      "loss 2.304282, train acc 0.096031\n",
      "round 161\n",
      "time to device 0.010186 sec\n",
      "time forward 2.068408 sec\n",
      "loss time 0.001762 sec\n",
      "backward time 0.017772 sec\n",
      "optimizer time 0.022759 sec\n",
      "training time in round 161 cost 0.4147148132324219 sec\n",
      "loss 2.304424, train acc 0.096161\n",
      "round 162\n",
      "time to device 0.007312 sec\n",
      "time forward 2.084870 sec\n",
      "loss time 0.001006 sec\n",
      "backward time 0.015058 sec\n",
      "optimizer time 0.025693 sec\n",
      "training time in round 162 cost 0.4165928363800049 sec\n",
      "loss 2.304417, train acc 0.096146\n",
      "round 163\n",
      "time to device 0.008081 sec\n",
      "time forward 2.099218 sec\n",
      "loss time 0.001123 sec\n",
      "backward time 0.014236 sec\n",
      "optimizer time 0.024238 sec\n",
      "training time in round 163 cost 0.4282219409942627 sec\n",
      "loss 2.304389, train acc 0.096179\n",
      "round 164\n",
      "time to device 0.008869 sec\n",
      "time forward 2.114050 sec\n",
      "loss time 0.001971 sec\n",
      "backward time 0.015838 sec\n",
      "optimizer time 0.022321 sec\n",
      "training time in round 164 cost 0.40925073623657227 sec\n",
      "loss 2.304372, train acc 0.096449\n",
      "round 165\n",
      "time to device 0.008424 sec\n",
      "time forward 2.128300 sec\n",
      "loss time 0.001433 sec\n",
      "backward time 0.013696 sec\n",
      "optimizer time 0.021850 sec\n",
      "training time in round 165 cost 0.40337610244750977 sec\n",
      "loss 2.304368, train acc 0.096386\n",
      "round 166\n",
      "time to device 0.005100 sec\n",
      "time forward 2.142817 sec\n",
      "loss time 0.001496 sec\n",
      "backward time 0.016897 sec\n",
      "optimizer time 0.023896 sec\n",
      "training time in round 166 cost 0.40274596214294434 sec\n",
      "loss 2.304373, train acc 0.096276\n",
      "round 167\n",
      "time to device 0.003422 sec\n",
      "time forward 2.149521 sec\n",
      "loss time 0.000506 sec\n",
      "backward time 0.004616 sec\n",
      "optimizer time 0.012721 sec\n",
      "training time in round 167 cost 0.35785794258117676 sec\n",
      "loss 2.304368, train acc 0.096261\n",
      "round 168\n",
      "time to device 0.003863 sec\n",
      "time forward 2.161149 sec\n",
      "loss time 0.001182 sec\n",
      "backward time 0.011398 sec\n",
      "optimizer time 0.024226 sec\n",
      "training time in round 168 cost 0.3881351947784424 sec\n",
      "loss 2.304356, train acc 0.096339\n",
      "round 169\n",
      "time to device 0.005340 sec\n",
      "time forward 2.173085 sec\n",
      "loss time 0.001059 sec\n",
      "backward time 0.008445 sec\n",
      "optimizer time 0.019767 sec\n",
      "training time in round 169 cost 0.39030027389526367 sec\n",
      "loss 2.304336, train acc 0.096140\n",
      "round 170\n",
      "time to device 0.004366 sec\n",
      "time forward 2.188088 sec\n",
      "loss time 0.001509 sec\n",
      "backward time 0.009376 sec\n",
      "optimizer time 0.029871 sec\n",
      "training time in round 170 cost 0.41279006004333496 sec\n",
      "loss 2.304322, train acc 0.096126\n",
      "round 171\n",
      "time to device 0.003535 sec\n",
      "time forward 2.202568 sec\n",
      "loss time 0.001577 sec\n",
      "backward time 0.017799 sec\n",
      "optimizer time 0.028032 sec\n",
      "training time in round 171 cost 0.44425296783447266 sec\n",
      "loss 2.304292, train acc 0.096248\n",
      "round 172\n",
      "time to device 0.005624 sec\n",
      "time forward 2.215498 sec\n",
      "loss time 0.001491 sec\n",
      "backward time 0.013088 sec\n",
      "optimizer time 0.024781 sec\n",
      "training time in round 172 cost 0.4093489646911621 sec\n",
      "loss 2.304294, train acc 0.096279\n",
      "round 173\n",
      "time to device 0.004115 sec\n",
      "time forward 2.233748 sec\n",
      "loss time 0.001157 sec\n",
      "backward time 0.017504 sec\n",
      "optimizer time 0.022670 sec\n",
      "training time in round 173 cost 0.41274118423461914 sec\n",
      "loss 2.304280, train acc 0.096130\n",
      "round 174\n",
      "time to device 0.007409 sec\n",
      "time forward 2.250192 sec\n",
      "loss time 0.002093 sec\n",
      "backward time 0.014141 sec\n",
      "optimizer time 0.025740 sec\n",
      "training time in round 174 cost 0.4246511459350586 sec\n",
      "loss 2.304255, train acc 0.096429\n",
      "round 175\n",
      "time to device 0.004013 sec\n",
      "time forward 2.264642 sec\n",
      "loss time 0.001207 sec\n",
      "backward time 0.011709 sec\n",
      "optimizer time 0.021675 sec\n",
      "training time in round 175 cost 0.3925187587738037 sec\n",
      "loss 2.304257, train acc 0.096413\n",
      "round 176\n",
      "time to device 0.003547 sec\n",
      "time forward 2.275190 sec\n",
      "loss time 0.000379 sec\n",
      "backward time 0.005179 sec\n",
      "optimizer time 0.014037 sec\n",
      "training time in round 176 cost 0.4299015998840332 sec\n",
      "loss 2.304238, train acc 0.096487\n",
      "round 177\n",
      "time to device 0.010885 sec\n",
      "time forward 2.294758 sec\n",
      "loss time 0.001880 sec\n",
      "backward time 0.014393 sec\n",
      "optimizer time 0.024172 sec\n",
      "training time in round 177 cost 0.4646620750427246 sec\n",
      "loss 2.304246, train acc 0.096515\n",
      "round 178\n",
      "time to device 0.008813 sec\n",
      "time forward 2.307677 sec\n",
      "loss time 0.002005 sec\n",
      "backward time 0.012772 sec\n",
      "optimizer time 0.025841 sec\n",
      "training time in round 178 cost 0.40515708923339844 sec\n",
      "loss 2.304224, train acc 0.096412\n",
      "round 179\n",
      "time to device 0.006730 sec\n",
      "time forward 2.323322 sec\n",
      "loss time 0.001633 sec\n",
      "backward time 0.014037 sec\n",
      "optimizer time 0.026345 sec\n",
      "training time in round 179 cost 0.48728489875793457 sec\n",
      "loss 2.304236, train acc 0.096441\n",
      "round 180\n",
      "time to device 0.008701 sec\n",
      "time forward 2.347352 sec\n",
      "loss time 0.001476 sec\n",
      "backward time 0.014307 sec\n",
      "optimizer time 0.022745 sec\n",
      "training time in round 180 cost 0.44152402877807617 sec\n",
      "loss 2.304216, train acc 0.096340\n",
      "round 181\n",
      "time to device 0.008693 sec\n",
      "time forward 2.360531 sec\n",
      "loss time 0.001656 sec\n",
      "backward time 0.015728 sec\n",
      "optimizer time 0.024096 sec\n",
      "training time in round 181 cost 0.4171769618988037 sec\n",
      "loss 2.304740, train acc 0.096368\n",
      "round 182\n",
      "time to device 0.007542 sec\n",
      "time forward 2.377527 sec\n",
      "loss time 0.001313 sec\n",
      "backward time 0.011607 sec\n",
      "optimizer time 0.020667 sec\n",
      "training time in round 182 cost 0.40509581565856934 sec\n",
      "loss 2.304712, train acc 0.096269\n",
      "round 183\n",
      "time to device 0.012429 sec\n",
      "time forward 2.389407 sec\n",
      "loss time 0.001246 sec\n",
      "backward time 0.012254 sec\n",
      "optimizer time 0.027684 sec\n",
      "training time in round 183 cost 0.3941020965576172 sec\n",
      "loss 2.304702, train acc 0.096382\n",
      "round 184\n",
      "time to device 0.009520 sec\n",
      "time forward 2.403841 sec\n",
      "loss time 0.001576 sec\n",
      "backward time 0.014707 sec\n",
      "optimizer time 0.025726 sec\n",
      "training time in round 184 cost 0.40502071380615234 sec\n",
      "loss 2.304718, train acc 0.096242\n",
      "round 185\n",
      "time to device 0.009722 sec\n",
      "time forward 2.416476 sec\n",
      "loss time 0.001627 sec\n",
      "backward time 0.010828 sec\n",
      "optimizer time 0.025544 sec\n",
      "training time in round 185 cost 0.3908209800720215 sec\n",
      "loss 2.304668, train acc 0.096396\n",
      "round 186\n",
      "time to device 0.007229 sec\n",
      "time forward 2.428799 sec\n",
      "loss time 0.001764 sec\n",
      "backward time 0.013600 sec\n",
      "optimizer time 0.022667 sec\n",
      "training time in round 186 cost 0.38905787467956543 sec\n",
      "loss 2.305178, train acc 0.096298\n",
      "round 187\n",
      "time to device 0.007367 sec\n",
      "time forward 2.442823 sec\n",
      "loss time 0.002002 sec\n",
      "backward time 0.013249 sec\n",
      "optimizer time 0.026369 sec\n",
      "training time in round 187 cost 0.40586185455322266 sec\n",
      "loss 2.305165, train acc 0.096368\n",
      "round 188\n",
      "time to device 0.005132 sec\n",
      "time forward 2.454039 sec\n",
      "loss time 0.001794 sec\n",
      "backward time 0.013689 sec\n",
      "optimizer time 0.025027 sec\n",
      "training time in round 188 cost 0.3894360065460205 sec\n",
      "loss 2.305165, train acc 0.096437\n",
      "round 189\n",
      "time to device 0.004715 sec\n",
      "time forward 2.459236 sec\n",
      "loss time 0.000517 sec\n",
      "backward time 0.004855 sec\n",
      "optimizer time 0.013176 sec\n",
      "training time in round 189 cost 0.3396182060241699 sec\n",
      "loss 2.305154, train acc 0.096299\n",
      "round 190\n",
      "time to device 0.004447 sec\n",
      "time forward 2.468620 sec\n",
      "loss time 0.000763 sec\n",
      "backward time 0.006398 sec\n",
      "optimizer time 0.016279 sec\n",
      "training time in round 190 cost 0.40433382987976074 sec\n",
      "loss 2.305138, train acc 0.096286\n",
      "round 191\n",
      "time to device 0.011846 sec\n",
      "time forward 2.483676 sec\n",
      "loss time 0.001496 sec\n",
      "backward time 0.012915 sec\n",
      "optimizer time 0.022344 sec\n",
      "training time in round 191 cost 0.40460705757141113 sec\n",
      "loss 2.305118, train acc 0.096395\n",
      "round 192\n",
      "time to device 0.009185 sec\n",
      "time forward 2.496720 sec\n",
      "loss time 0.003742 sec\n",
      "backward time 0.017003 sec\n",
      "optimizer time 0.024080 sec\n",
      "training time in round 192 cost 0.4175591468811035 sec\n",
      "loss 2.305213, train acc 0.096260\n",
      "round 193\n",
      "time to device 0.010253 sec\n",
      "time forward 2.509624 sec\n",
      "loss time 0.001695 sec\n",
      "backward time 0.013123 sec\n",
      "optimizer time 0.026952 sec\n",
      "training time in round 193 cost 0.40755701065063477 sec\n",
      "loss 2.305190, train acc 0.096609\n",
      "round 194\n",
      "time to device 0.007306 sec\n",
      "time forward 2.524030 sec\n",
      "loss time 0.002033 sec\n",
      "backward time 0.017717 sec\n",
      "optimizer time 0.029040 sec\n",
      "training time in round 194 cost 0.4134249687194824 sec\n",
      "loss 2.305164, train acc 0.096875\n",
      "round 195\n",
      "time to device 0.007484 sec\n",
      "time forward 2.540570 sec\n",
      "loss time 0.001244 sec\n",
      "backward time 0.014104 sec\n",
      "optimizer time 0.022676 sec\n",
      "training time in round 195 cost 0.4053840637207031 sec\n",
      "loss 2.305159, train acc 0.096739\n",
      "round 196\n",
      "time to device 0.004396 sec\n",
      "time forward 2.552119 sec\n",
      "loss time 0.001136 sec\n",
      "backward time 0.008856 sec\n",
      "optimizer time 0.020590 sec\n",
      "training time in round 196 cost 0.3673868179321289 sec\n",
      "loss 2.305134, train acc 0.096843\n",
      "round 197\n",
      "time to device 0.009072 sec\n",
      "time forward 2.566626 sec\n",
      "loss time 0.001696 sec\n",
      "backward time 0.011415 sec\n",
      "optimizer time 0.021905 sec\n",
      "training time in round 197 cost 0.39550113677978516 sec\n",
      "loss 2.305118, train acc 0.096828\n",
      "round 198\n",
      "time to device 0.009888 sec\n",
      "time forward 2.581048 sec\n",
      "loss time 0.002492 sec\n",
      "backward time 0.017544 sec\n",
      "optimizer time 0.024485 sec\n",
      "training time in round 198 cost 0.43271899223327637 sec\n",
      "loss 2.305220, train acc 0.096616\n",
      "round 199\n",
      "time to device 0.006424 sec\n",
      "time forward 2.592652 sec\n",
      "loss time 0.001348 sec\n",
      "backward time 0.011824 sec\n",
      "optimizer time 0.025437 sec\n",
      "training time in round 199 cost 0.40590810775756836 sec\n",
      "loss 2.305297, train acc 0.096602\n",
      "round 200\n",
      "time to device 0.010972 sec\n",
      "time forward 2.600625 sec\n",
      "loss time 0.000518 sec\n",
      "backward time 0.004688 sec\n",
      "optimizer time 0.013432 sec\n",
      "training time in round 200 cost 0.3903799057006836 sec\n",
      "loss 2.305279, train acc 0.096743\n",
      "round 201\n",
      "time to device 0.009343 sec\n",
      "time forward 2.614431 sec\n",
      "loss time 0.001060 sec\n",
      "backward time 0.010726 sec\n",
      "optimizer time 0.022246 sec\n",
      "training time in round 201 cost 0.43370890617370605 sec\n",
      "loss 2.305299, train acc 0.096651\n",
      "round 202\n",
      "time to device 0.009958 sec\n",
      "time forward 2.631582 sec\n",
      "loss time 0.001511 sec\n",
      "backward time 0.012176 sec\n",
      "optimizer time 0.025795 sec\n",
      "training time in round 202 cost 0.44942688941955566 sec\n",
      "loss 2.305307, train acc 0.096752\n",
      "round 203\n",
      "time to device 0.007094 sec\n",
      "time forward 2.643986 sec\n",
      "loss time 0.001943 sec\n",
      "backward time 0.012455 sec\n",
      "optimizer time 0.021061 sec\n",
      "training time in round 203 cost 0.3929429054260254 sec\n",
      "loss 2.305282, train acc 0.096775\n",
      "round 204\n",
      "time to device 0.009411 sec\n",
      "time forward 2.650439 sec\n",
      "loss time 0.000434 sec\n",
      "backward time 0.004021 sec\n",
      "optimizer time 0.011385 sec\n",
      "training time in round 204 cost 0.3639862537384033 sec\n",
      "loss 2.305245, train acc 0.096951\n",
      "round 205\n",
      "time to device 0.010101 sec\n",
      "time forward 2.664560 sec\n",
      "loss time 0.002257 sec\n",
      "backward time 0.011856 sec\n",
      "optimizer time 0.022814 sec\n",
      "training time in round 205 cost 0.3987247943878174 sec\n",
      "loss 2.305221, train acc 0.096936\n",
      "round 206\n",
      "time to device 0.009575 sec\n",
      "time forward 2.679592 sec\n",
      "loss time 0.001099 sec\n",
      "backward time 0.012011 sec\n",
      "optimizer time 0.021583 sec\n",
      "training time in round 206 cost 0.4040060043334961 sec\n",
      "loss 2.305253, train acc 0.097071\n",
      "round 207\n",
      "time to device 0.009382 sec\n",
      "time forward 2.694992 sec\n",
      "loss time 0.001362 sec\n",
      "backward time 0.013959 sec\n",
      "optimizer time 0.027130 sec\n",
      "training time in round 207 cost 0.4298429489135742 sec\n",
      "loss 2.305500, train acc 0.097130\n",
      "round 208\n",
      "time to device 0.012419 sec\n",
      "time forward 2.709454 sec\n",
      "loss time 0.001751 sec\n",
      "backward time 0.011850 sec\n",
      "optimizer time 0.026631 sec\n",
      "training time in round 208 cost 0.40818095207214355 sec\n",
      "loss 2.305486, train acc 0.097002\n",
      "round 209\n",
      "time to device 0.009360 sec\n",
      "time forward 2.724027 sec\n",
      "loss time 0.001904 sec\n",
      "backward time 0.011972 sec\n",
      "optimizer time 0.023547 sec\n",
      "training time in round 209 cost 0.4019331932067871 sec\n",
      "loss 2.305420, train acc 0.097321\n",
      "round 210\n",
      "time to device 0.003656 sec\n",
      "time forward 2.738579 sec\n",
      "loss time 0.000471 sec\n",
      "backward time 0.003597 sec\n",
      "optimizer time 0.009988 sec\n",
      "training time in round 210 cost 0.36847996711730957 sec\n",
      "loss 2.305400, train acc 0.097379\n",
      "round 211\n",
      "time to device 0.003682 sec\n",
      "time forward 2.751721 sec\n",
      "loss time 0.001251 sec\n",
      "backward time 0.012321 sec\n",
      "optimizer time 0.027684 sec\n",
      "training time in round 211 cost 0.3993690013885498 sec\n",
      "loss 2.305395, train acc 0.097325\n",
      "round 212\n",
      "time to device 0.004574 sec\n",
      "time forward 2.765854 sec\n",
      "loss time 0.001752 sec\n",
      "backward time 0.012637 sec\n",
      "optimizer time 0.024762 sec\n",
      "training time in round 212 cost 0.4031040668487549 sec\n",
      "loss 2.305385, train acc 0.097381\n",
      "round 213\n",
      "time to device 0.004130 sec\n",
      "time forward 2.780199 sec\n",
      "loss time 0.001399 sec\n",
      "backward time 0.015192 sec\n",
      "optimizer time 0.023950 sec\n",
      "training time in round 213 cost 0.40344882011413574 sec\n",
      "loss 2.305356, train acc 0.097401\n",
      "round 214\n",
      "time to device 0.004107 sec\n",
      "time forward 2.787679 sec\n",
      "loss time 0.000633 sec\n",
      "backward time 0.005471 sec\n",
      "optimizer time 0.014091 sec\n",
      "training time in round 214 cost 0.3588371276855469 sec\n",
      "loss 2.305321, train acc 0.097529\n",
      "round 215\n",
      "time to device 0.003866 sec\n",
      "time forward 2.804423 sec\n",
      "loss time 0.001293 sec\n",
      "backward time 0.015594 sec\n",
      "optimizer time 0.025396 sec\n",
      "training time in round 215 cost 0.4058339595794678 sec\n",
      "loss 2.305336, train acc 0.097439\n",
      "round 216\n",
      "time to device 0.004584 sec\n",
      "time forward 2.820596 sec\n",
      "loss time 0.001431 sec\n",
      "backward time 0.012636 sec\n",
      "optimizer time 0.026841 sec\n",
      "training time in round 216 cost 0.4046049118041992 sec\n",
      "loss 2.305327, train acc 0.097422\n",
      "round 217\n",
      "time to device 0.003460 sec\n",
      "time forward 2.834169 sec\n",
      "loss time 0.001883 sec\n",
      "backward time 0.014498 sec\n",
      "optimizer time 0.022260 sec\n",
      "training time in round 217 cost 0.39565396308898926 sec\n",
      "loss 2.305282, train acc 0.097692\n",
      "round 218\n",
      "time to device 0.005050 sec\n",
      "time forward 2.847098 sec\n",
      "loss time 0.002227 sec\n",
      "backward time 0.011898 sec\n",
      "optimizer time 0.020320 sec\n",
      "training time in round 218 cost 0.38503313064575195 sec\n",
      "loss 2.305253, train acc 0.097852\n",
      "round 219\n",
      "time to device 0.003892 sec\n",
      "time forward 2.863722 sec\n",
      "loss time 0.001456 sec\n",
      "backward time 0.012991 sec\n",
      "optimizer time 0.022029 sec\n",
      "training time in round 219 cost 0.39649486541748047 sec\n",
      "loss 2.305223, train acc 0.098047\n",
      "round 220\n",
      "time to device 0.004592 sec\n",
      "time forward 2.877667 sec\n",
      "loss time 0.001357 sec\n",
      "backward time 0.013284 sec\n",
      "optimizer time 0.023316 sec\n",
      "training time in round 220 cost 0.39393091201782227 sec\n",
      "loss 2.305244, train acc 0.097992\n",
      "round 221\n",
      "time to device 0.004303 sec\n",
      "time forward 2.891026 sec\n",
      "loss time 0.001486 sec\n",
      "backward time 0.013621 sec\n",
      "optimizer time 0.021587 sec\n",
      "training time in round 221 cost 0.3935551643371582 sec\n",
      "loss 2.305261, train acc 0.097973\n",
      "round 222\n",
      "time to device 0.004371 sec\n",
      "time forward 2.904621 sec\n",
      "loss time 0.002244 sec\n",
      "backward time 0.013245 sec\n",
      "optimizer time 0.023860 sec\n",
      "training time in round 222 cost 0.39507508277893066 sec\n",
      "loss 2.305278, train acc 0.097919\n",
      "round 223\n",
      "time to device 0.003118 sec\n",
      "time forward 2.918738 sec\n",
      "loss time 0.001658 sec\n",
      "backward time 0.013697 sec\n",
      "optimizer time 0.027343 sec\n",
      "training time in round 223 cost 0.39868998527526855 sec\n",
      "loss 2.305345, train acc 0.097970\n",
      "round 224\n",
      "time to device 0.004584 sec\n",
      "time forward 2.932975 sec\n",
      "loss time 0.001427 sec\n",
      "backward time 0.014297 sec\n",
      "optimizer time 0.023829 sec\n",
      "training time in round 224 cost 0.3999898433685303 sec\n",
      "loss 2.305349, train acc 0.097882\n",
      "round 225\n",
      "time to device 0.003662 sec\n",
      "time forward 2.947246 sec\n",
      "loss time 0.002948 sec\n",
      "backward time 0.013652 sec\n",
      "optimizer time 0.024447 sec\n",
      "training time in round 225 cost 0.3977241516113281 sec\n",
      "loss 2.305366, train acc 0.097829\n",
      "round 226\n",
      "time to device 0.004006 sec\n",
      "time forward 2.959811 sec\n",
      "loss time 0.001431 sec\n",
      "backward time 0.017150 sec\n",
      "optimizer time 0.022519 sec\n",
      "training time in round 226 cost 0.392413854598999 sec\n",
      "loss 2.305366, train acc 0.097742\n",
      "round 227\n",
      "time to device 0.004189 sec\n",
      "time forward 2.974029 sec\n",
      "loss time 0.001486 sec\n",
      "backward time 0.015306 sec\n",
      "optimizer time 0.024659 sec\n",
      "training time in round 227 cost 0.39447712898254395 sec\n",
      "loss 2.305378, train acc 0.097691\n",
      "round 228\n",
      "time to device 0.004593 sec\n",
      "time forward 2.993125 sec\n",
      "loss time 0.001460 sec\n",
      "backward time 0.012377 sec\n",
      "optimizer time 0.024461 sec\n",
      "training time in round 228 cost 0.4082522392272949 sec\n",
      "loss 2.305410, train acc 0.097434\n",
      "round 229\n",
      "time to device 0.003666 sec\n",
      "time forward 3.007497 sec\n",
      "loss time 0.001708 sec\n",
      "backward time 0.012653 sec\n",
      "optimizer time 0.023428 sec\n",
      "training time in round 229 cost 0.39621710777282715 sec\n",
      "loss 2.305400, train acc 0.097554\n",
      "round 230\n",
      "time to device 0.003359 sec\n",
      "time forward 3.014506 sec\n",
      "loss time 0.000633 sec\n",
      "backward time 0.005737 sec\n",
      "optimizer time 0.015411 sec\n",
      "training time in round 230 cost 0.3618738651275635 sec\n",
      "loss 2.305378, train acc 0.097707\n",
      "round 231\n",
      "time to device 0.004307 sec\n",
      "time forward 3.033203 sec\n",
      "loss time 0.001676 sec\n",
      "backward time 0.014188 sec\n",
      "optimizer time 0.023067 sec\n",
      "training time in round 231 cost 0.39565491676330566 sec\n",
      "loss 2.305379, train acc 0.097656\n",
      "round 232\n",
      "time to device 0.004029 sec\n",
      "time forward 3.047980 sec\n",
      "loss time 0.001094 sec\n",
      "backward time 0.015765 sec\n",
      "optimizer time 0.024636 sec\n",
      "training time in round 232 cost 0.4029409885406494 sec\n",
      "loss 2.305377, train acc 0.097606\n",
      "round 233\n",
      "time to device 0.003914 sec\n",
      "time forward 3.062313 sec\n",
      "loss time 0.001363 sec\n",
      "backward time 0.014338 sec\n",
      "optimizer time 0.022009 sec\n",
      "training time in round 233 cost 0.39115214347839355 sec\n",
      "loss 2.305375, train acc 0.097656\n",
      "round 234\n",
      "time to device 0.004650 sec\n",
      "time forward 3.073642 sec\n",
      "loss time 0.002174 sec\n",
      "backward time 0.013601 sec\n",
      "optimizer time 0.021700 sec\n",
      "training time in round 234 cost 0.3849599361419678 sec\n",
      "loss 2.305368, train acc 0.097606\n",
      "round 235\n",
      "time to device 0.006514 sec\n",
      "time forward 3.080720 sec\n",
      "loss time 0.000547 sec\n",
      "backward time 0.004674 sec\n",
      "optimizer time 0.013098 sec\n",
      "training time in round 235 cost 0.35285496711730957 sec\n",
      "loss 2.305349, train acc 0.097756\n",
      "round 236\n",
      "time to device 0.004306 sec\n",
      "time forward 3.095005 sec\n",
      "loss time 0.001530 sec\n",
      "backward time 0.012602 sec\n",
      "optimizer time 0.022070 sec\n",
      "training time in round 236 cost 0.3950817584991455 sec\n",
      "loss 2.305339, train acc 0.097903\n",
      "round 237\n",
      "time to device 0.005171 sec\n",
      "time forward 3.110349 sec\n",
      "loss time 0.001607 sec\n",
      "backward time 0.016649 sec\n",
      "optimizer time 0.024413 sec\n",
      "training time in round 237 cost 0.4082670211791992 sec\n",
      "loss 2.305326, train acc 0.097985\n",
      "round 238\n",
      "time to device 0.003485 sec\n",
      "time forward 3.125016 sec\n",
      "loss time 0.001339 sec\n",
      "backward time 0.014213 sec\n",
      "optimizer time 0.022810 sec\n",
      "training time in round 238 cost 0.40996289253234863 sec\n",
      "loss 2.305326, train acc 0.097901\n",
      "round 239\n",
      "time to device 0.003900 sec\n",
      "time forward 3.140164 sec\n",
      "loss time 0.001125 sec\n",
      "backward time 0.012229 sec\n",
      "optimizer time 0.038052 sec\n",
      "training time in round 239 cost 0.420604944229126 sec\n",
      "loss 2.305309, train acc 0.098014\n",
      "round 240\n",
      "time to device 0.004818 sec\n",
      "time forward 3.157394 sec\n",
      "loss time 0.001008 sec\n",
      "backward time 0.016830 sec\n",
      "optimizer time 0.022279 sec\n",
      "training time in round 240 cost 0.41347503662109375 sec\n",
      "loss 2.305288, train acc 0.098094\n",
      "round 241\n",
      "time to device 0.004755 sec\n",
      "time forward 3.173951 sec\n",
      "loss time 0.001537 sec\n",
      "backward time 0.012702 sec\n",
      "optimizer time 0.022184 sec\n",
      "training time in round 241 cost 0.4112050533294678 sec\n",
      "loss 2.305288, train acc 0.098108\n",
      "round 242\n",
      "time to device 0.003777 sec\n",
      "time forward 3.187372 sec\n",
      "loss time 0.001973 sec\n",
      "backward time 0.015664 sec\n",
      "optimizer time 0.023853 sec\n",
      "training time in round 242 cost 0.3928999900817871 sec\n",
      "loss 2.305272, train acc 0.098122\n",
      "round 243\n",
      "time to device 0.003988 sec\n",
      "time forward 3.202730 sec\n",
      "loss time 0.001584 sec\n",
      "backward time 0.012138 sec\n",
      "optimizer time 0.023482 sec\n",
      "training time in round 243 cost 0.39896106719970703 sec\n",
      "loss 2.305229, train acc 0.098233\n",
      "round 244\n",
      "time to device 0.003675 sec\n",
      "time forward 3.216454 sec\n",
      "loss time 0.001719 sec\n",
      "backward time 0.014317 sec\n",
      "optimizer time 0.014137 sec\n",
      "training time in round 244 cost 0.38936924934387207 sec\n",
      "loss 2.305216, train acc 0.098119\n",
      "round 245\n",
      "time to device 0.008636 sec\n",
      "time forward 3.228047 sec\n",
      "loss time 0.000668 sec\n",
      "backward time 0.008602 sec\n",
      "optimizer time 0.020632 sec\n",
      "training time in round 245 cost 0.4499781131744385 sec\n",
      "loss 2.305221, train acc 0.098069\n",
      "round 246\n",
      "time to device 0.008372 sec\n",
      "time forward 3.238127 sec\n",
      "loss time 0.000747 sec\n",
      "backward time 0.006957 sec\n",
      "optimizer time 0.016809 sec\n",
      "training time in round 246 cost 0.40601682662963867 sec\n",
      "loss 2.305204, train acc 0.098336\n",
      "round 247\n",
      "time to device 0.008757 sec\n",
      "time forward 3.250891 sec\n",
      "loss time 0.001401 sec\n",
      "backward time 0.021392 sec\n",
      "optimizer time 0.023700 sec\n",
      "training time in round 247 cost 0.4131283760070801 sec\n",
      "loss 2.305195, train acc 0.098286\n",
      "round 248\n",
      "time to device 0.008163 sec\n",
      "time forward 3.266057 sec\n",
      "loss time 0.001838 sec\n",
      "backward time 0.015667 sec\n",
      "optimizer time 0.026010 sec\n",
      "training time in round 248 cost 0.4719827175140381 sec\n",
      "loss 2.305179, train acc 0.098299\n",
      "round 249\n",
      "time to device 0.008254 sec\n",
      "time forward 3.281837 sec\n",
      "loss time 0.002046 sec\n",
      "backward time 0.011083 sec\n",
      "optimizer time 0.022382 sec\n",
      "training time in round 249 cost 0.39928603172302246 sec\n",
      "loss 2.305149, train acc 0.098344\n",
      "round 250\n",
      "time to device 0.008614 sec\n",
      "time forward 3.292209 sec\n",
      "loss time 0.001631 sec\n",
      "backward time 0.012632 sec\n",
      "optimizer time 0.021471 sec\n",
      "training time in round 250 cost 0.3761579990386963 sec\n",
      "loss 2.305149, train acc 0.098232\n",
      "round 251\n",
      "time to device 0.008239 sec\n",
      "time forward 3.304806 sec\n",
      "loss time 0.001073 sec\n",
      "backward time 0.020649 sec\n",
      "optimizer time 0.022043 sec\n",
      "training time in round 251 cost 0.4016730785369873 sec\n",
      "loss 2.305173, train acc 0.098245\n",
      "round 252\n",
      "time to device 0.008584 sec\n",
      "time forward 3.317300 sec\n",
      "loss time 0.002282 sec\n",
      "backward time 0.015812 sec\n",
      "optimizer time 0.023616 sec\n",
      "training time in round 252 cost 0.3966078758239746 sec\n",
      "loss 2.305173, train acc 0.098135\n",
      "round 253\n",
      "time to device 0.006770 sec\n",
      "time forward 3.331535 sec\n",
      "loss time 0.002230 sec\n",
      "backward time 0.012302 sec\n",
      "optimizer time 0.023522 sec\n",
      "training time in round 253 cost 0.4143826961517334 sec\n",
      "loss 2.305188, train acc 0.098056\n",
      "round 254\n",
      "time to device 0.007158 sec\n",
      "time forward 3.346588 sec\n",
      "loss time 0.001403 sec\n",
      "backward time 0.013972 sec\n",
      "optimizer time 0.024022 sec\n",
      "training time in round 254 cost 0.40729212760925293 sec\n",
      "loss 2.305145, train acc 0.098223\n",
      "round 255\n",
      "time to device 0.011089 sec\n",
      "time forward 3.361148 sec\n",
      "loss time 0.001428 sec\n",
      "backward time 0.012718 sec\n",
      "optimizer time 0.021660 sec\n",
      "training time in round 255 cost 0.4134089946746826 sec\n",
      "loss 2.307438, train acc 0.098206\n",
      "round 256\n",
      "time to device 0.007141 sec\n",
      "time forward 3.377016 sec\n",
      "loss time 0.001497 sec\n",
      "backward time 0.012625 sec\n",
      "optimizer time 0.022485 sec\n",
      "training time in round 256 cost 0.41011905670166016 sec\n",
      "loss 2.307410, train acc 0.098158\n",
      "round 257\n",
      "time to device 0.003780 sec\n",
      "time forward 3.393070 sec\n",
      "loss time 0.001282 sec\n",
      "backward time 0.012416 sec\n",
      "optimizer time 0.024338 sec\n",
      "training time in round 257 cost 0.40126681327819824 sec\n",
      "loss 2.307464, train acc 0.098110\n",
      "round 258\n",
      "time to device 0.003370 sec\n",
      "time forward 3.413651 sec\n",
      "loss time 0.001225 sec\n",
      "backward time 0.013974 sec\n",
      "optimizer time 0.023251 sec\n",
      "training time in round 258 cost 0.42482686042785645 sec\n",
      "loss 2.307465, train acc 0.098033\n",
      "round 259\n",
      "time to device 0.004027 sec\n",
      "time forward 3.428527 sec\n",
      "loss time 0.001822 sec\n",
      "backward time 0.012593 sec\n",
      "optimizer time 0.023268 sec\n",
      "training time in round 259 cost 0.41077709197998047 sec\n",
      "loss 2.307445, train acc 0.098077\n",
      "round 260\n",
      "time to device 0.004516 sec\n",
      "time forward 3.443209 sec\n",
      "loss time 0.001862 sec\n",
      "backward time 0.011254 sec\n",
      "optimizer time 0.021925 sec\n",
      "training time in round 260 cost 0.3940291404724121 sec\n",
      "loss 2.307435, train acc 0.098060\n",
      "round 261\n",
      "time to device 0.003722 sec\n",
      "time forward 3.457140 sec\n",
      "loss time 0.001333 sec\n",
      "backward time 0.014278 sec\n",
      "optimizer time 0.012222 sec\n",
      "training time in round 261 cost 0.3833651542663574 sec\n",
      "loss 2.307422, train acc 0.098193\n",
      "round 262\n",
      "time to device 0.003748 sec\n",
      "time forward 3.472171 sec\n",
      "loss time 0.001406 sec\n",
      "backward time 0.012850 sec\n",
      "optimizer time 0.023613 sec\n",
      "training time in round 262 cost 0.4020111560821533 sec\n",
      "loss 2.307380, train acc 0.098176\n",
      "round 263\n",
      "time to device 0.004381 sec\n",
      "time forward 3.488580 sec\n",
      "loss time 0.001615 sec\n",
      "backward time 0.012736 sec\n",
      "optimizer time 0.022545 sec\n",
      "training time in round 263 cost 0.40860915184020996 sec\n",
      "loss 2.307367, train acc 0.098278\n",
      "round 264\n",
      "time to device 0.004562 sec\n",
      "time forward 3.503690 sec\n",
      "loss time 0.003691 sec\n",
      "backward time 0.015215 sec\n",
      "optimizer time 0.027595 sec\n",
      "training time in round 264 cost 0.4100508689880371 sec\n",
      "loss 2.307381, train acc 0.098261\n",
      "round 265\n",
      "time to device 0.003452 sec\n",
      "time forward 3.517245 sec\n",
      "loss time 0.001917 sec\n",
      "backward time 0.012062 sec\n",
      "optimizer time 0.024002 sec\n",
      "training time in round 265 cost 0.39264917373657227 sec\n",
      "loss 2.307371, train acc 0.098302\n",
      "round 266\n",
      "time to device 0.004383 sec\n",
      "time forward 3.530765 sec\n",
      "loss time 0.001615 sec\n",
      "backward time 0.015728 sec\n",
      "optimizer time 0.025613 sec\n",
      "training time in round 266 cost 0.401702880859375 sec\n",
      "loss 2.307407, train acc 0.098373\n",
      "round 267\n",
      "time to device 0.004427 sec\n",
      "time forward 3.546082 sec\n",
      "loss time 0.001333 sec\n",
      "backward time 0.014279 sec\n",
      "optimizer time 0.027268 sec\n",
      "training time in round 267 cost 0.4032609462738037 sec\n",
      "loss 2.307375, train acc 0.098618\n",
      "round 268\n",
      "time to device 0.004566 sec\n",
      "time forward 3.553508 sec\n",
      "loss time 0.000610 sec\n",
      "backward time 0.006465 sec\n",
      "optimizer time 0.014864 sec\n",
      "training time in round 268 cost 0.35329103469848633 sec\n",
      "loss 2.307357, train acc 0.098600\n",
      "round 269\n",
      "time to device 0.004404 sec\n",
      "time forward 3.571111 sec\n",
      "loss time 0.001444 sec\n",
      "backward time 0.012851 sec\n",
      "optimizer time 0.023687 sec\n",
      "training time in round 269 cost 0.47203493118286133 sec\n",
      "loss 2.307297, train acc 0.098756\n",
      "round 270\n",
      "time to device 0.010154 sec\n",
      "time forward 3.582808 sec\n",
      "loss time 0.001381 sec\n",
      "backward time 0.015601 sec\n",
      "optimizer time 0.026351 sec\n",
      "training time in round 270 cost 0.3989119529724121 sec\n",
      "loss 2.307284, train acc 0.098737\n",
      "round 271\n",
      "time to device 0.011151 sec\n",
      "time forward 3.595422 sec\n",
      "loss time 0.001325 sec\n",
      "backward time 0.009898 sec\n",
      "optimizer time 0.022446 sec\n",
      "training time in round 271 cost 0.39659976959228516 sec\n",
      "loss 2.307262, train acc 0.098863\n",
      "round 272\n",
      "time to device 0.012824 sec\n",
      "time forward 3.607936 sec\n",
      "loss time 0.001754 sec\n",
      "backward time 0.013377 sec\n",
      "optimizer time 0.022451 sec\n",
      "training time in round 272 cost 0.40010499954223633 sec\n",
      "loss 2.307242, train acc 0.099016\n",
      "round 273\n",
      "time to device 0.008442 sec\n",
      "time forward 3.621325 sec\n",
      "loss time 0.001349 sec\n",
      "backward time 0.015101 sec\n",
      "optimizer time 0.021626 sec\n",
      "training time in round 273 cost 0.40128302574157715 sec\n",
      "loss 2.307214, train acc 0.099139\n",
      "round 274\n",
      "time to device 0.008691 sec\n",
      "time forward 3.634978 sec\n",
      "loss time 0.001831 sec\n",
      "backward time 0.016969 sec\n",
      "optimizer time 0.026591 sec\n",
      "training time in round 274 cost 0.4026062488555908 sec\n",
      "loss 2.307206, train acc 0.099205\n",
      "round 275\n",
      "time to device 0.006721 sec\n",
      "time forward 3.652467 sec\n",
      "loss time 0.001007 sec\n",
      "backward time 0.015297 sec\n",
      "optimizer time 0.019823 sec\n",
      "training time in round 275 cost 0.39737701416015625 sec\n",
      "loss 2.307186, train acc 0.099072\n",
      "round 276\n",
      "time to device 0.008465 sec\n",
      "time forward 3.668703 sec\n",
      "loss time 0.001466 sec\n",
      "backward time 0.012391 sec\n",
      "optimizer time 0.021965 sec\n",
      "training time in round 276 cost 0.41628432273864746 sec\n",
      "loss 2.307187, train acc 0.099109\n",
      "round 277\n",
      "time to device 0.007843 sec\n",
      "time forward 3.683260 sec\n",
      "loss time 0.001923 sec\n",
      "backward time 0.010843 sec\n",
      "optimizer time 0.022597 sec\n",
      "training time in round 277 cost 0.40079212188720703 sec\n",
      "loss 2.307177, train acc 0.099230\n",
      "round 278\n",
      "time to device 0.003695 sec\n",
      "time forward 3.696745 sec\n",
      "loss time 0.001404 sec\n",
      "backward time 0.012711 sec\n",
      "optimizer time 0.010786 sec\n",
      "training time in round 278 cost 0.3946261405944824 sec\n",
      "loss 2.307166, train acc 0.099238\n",
      "round 279\n",
      "time to device 0.005026 sec\n",
      "time forward 3.704334 sec\n",
      "loss time 0.000646 sec\n",
      "backward time 0.005701 sec\n",
      "optimizer time 0.015070 sec\n",
      "training time in round 279 cost 0.3672358989715576 sec\n",
      "loss 2.307164, train acc 0.099191\n",
      "round 280\n",
      "time to device 0.005487 sec\n",
      "time forward 3.721385 sec\n",
      "loss time 0.001201 sec\n",
      "backward time 0.013914 sec\n",
      "optimizer time 0.024861 sec\n",
      "training time in round 280 cost 0.4161109924316406 sec\n",
      "loss 2.307160, train acc 0.099310\n",
      "round 281\n",
      "time to device 0.004963 sec\n",
      "time forward 3.738358 sec\n",
      "loss time 0.001769 sec\n",
      "backward time 0.013348 sec\n",
      "optimizer time 0.023654 sec\n",
      "training time in round 281 cost 0.4145820140838623 sec\n",
      "loss 2.307160, train acc 0.099152\n",
      "round 282\n",
      "time to device 0.004948 sec\n",
      "time forward 3.753195 sec\n",
      "loss time 0.001913 sec\n",
      "backward time 0.014030 sec\n",
      "optimizer time 0.025038 sec\n",
      "training time in round 282 cost 0.41611576080322266 sec\n",
      "loss 2.307142, train acc 0.099216\n",
      "round 283\n",
      "time to device 0.005521 sec\n",
      "time forward 3.758518 sec\n",
      "loss time 0.000731 sec\n",
      "backward time 0.006589 sec\n",
      "optimizer time 0.016143 sec\n",
      "training time in round 283 cost 0.3453819751739502 sec\n",
      "loss 2.307143, train acc 0.099389\n",
      "round 284\n",
      "time to device 0.002870 sec\n",
      "time forward 3.774531 sec\n",
      "loss time 0.002319 sec\n",
      "backward time 0.013101 sec\n",
      "optimizer time 0.025922 sec\n",
      "training time in round 284 cost 0.4181990623474121 sec\n",
      "loss 2.307134, train acc 0.099370\n",
      "round 285\n",
      "time to device 0.004162 sec\n",
      "time forward 3.789175 sec\n",
      "loss time 0.001529 sec\n",
      "backward time 0.015110 sec\n",
      "optimizer time 0.024896 sec\n",
      "training time in round 285 cost 0.41027188301086426 sec\n",
      "loss 2.307121, train acc 0.099432\n",
      "round 286\n",
      "time to device 0.006343 sec\n",
      "time forward 3.803938 sec\n",
      "loss time 0.001514 sec\n",
      "backward time 0.016831 sec\n",
      "optimizer time 0.020524 sec\n",
      "training time in round 286 cost 0.4091331958770752 sec\n",
      "loss 2.307104, train acc 0.099466\n",
      "round 287\n",
      "time to device 0.006387 sec\n",
      "time forward 3.818501 sec\n",
      "loss time 0.001424 sec\n",
      "backward time 0.012831 sec\n",
      "optimizer time 0.023386 sec\n",
      "training time in round 287 cost 0.4034256935119629 sec\n",
      "loss 2.307047, train acc 0.099447\n",
      "round 288\n",
      "time to device 0.004431 sec\n",
      "time forward 3.834732 sec\n",
      "loss time 0.001451 sec\n",
      "backward time 0.013388 sec\n",
      "optimizer time 0.023534 sec\n",
      "training time in round 288 cost 0.4052116870880127 sec\n",
      "loss 2.307061, train acc 0.099427\n",
      "round 289\n",
      "time to device 0.004525 sec\n",
      "time forward 3.848518 sec\n",
      "loss time 0.002400 sec\n",
      "backward time 0.022975 sec\n",
      "optimizer time 0.026241 sec\n",
      "training time in round 289 cost 0.4193441867828369 sec\n",
      "loss 2.307059, train acc 0.099353\n",
      "round 290\n",
      "time to device 0.004218 sec\n",
      "time forward 3.865608 sec\n",
      "loss time 0.001246 sec\n",
      "backward time 0.014617 sec\n",
      "optimizer time 0.022675 sec\n",
      "training time in round 290 cost 0.40947794914245605 sec\n",
      "loss 2.307035, train acc 0.099415\n",
      "round 291\n",
      "time to device 0.003759 sec\n",
      "time forward 3.878639 sec\n",
      "loss time 0.001824 sec\n",
      "backward time 0.016194 sec\n",
      "optimizer time 0.025372 sec\n",
      "training time in round 291 cost 0.42069196701049805 sec\n",
      "loss 2.307052, train acc 0.099235\n",
      "round 292\n",
      "time to device 0.004233 sec\n",
      "time forward 3.893476 sec\n",
      "loss time 0.001538 sec\n",
      "backward time 0.012741 sec\n",
      "optimizer time 0.022624 sec\n",
      "training time in round 292 cost 0.3876979351043701 sec\n",
      "loss 2.307172, train acc 0.099216\n",
      "round 293\n",
      "time to device 0.005859 sec\n",
      "time forward 3.909024 sec\n",
      "loss time 0.002394 sec\n",
      "backward time 0.019511 sec\n",
      "optimizer time 0.018962 sec\n",
      "training time in round 293 cost 0.41007208824157715 sec\n",
      "loss 2.307152, train acc 0.099144\n",
      "round 294\n",
      "time to device 0.007948 sec\n",
      "time forward 3.921976 sec\n",
      "loss time 0.001357 sec\n",
      "backward time 0.013276 sec\n",
      "optimizer time 0.024101 sec\n",
      "training time in round 294 cost 0.3961181640625 sec\n",
      "loss 2.307150, train acc 0.099073\n",
      "round 295\n",
      "time to device 0.005483 sec\n",
      "time forward 3.936038 sec\n",
      "loss time 0.001364 sec\n",
      "backward time 0.010900 sec\n",
      "optimizer time 0.023333 sec\n",
      "training time in round 295 cost 0.409106969833374 sec\n",
      "loss 2.307143, train acc 0.099082\n",
      "round 296\n",
      "time to device 0.009095 sec\n",
      "time forward 3.949200 sec\n",
      "loss time 0.001427 sec\n",
      "backward time 0.012910 sec\n",
      "optimizer time 0.026829 sec\n",
      "training time in round 296 cost 0.40095090866088867 sec\n",
      "loss 2.307129, train acc 0.099037\n",
      "round 297\n",
      "time to device 0.006552 sec\n",
      "time forward 3.963287 sec\n",
      "loss time 0.001964 sec\n",
      "backward time 0.013053 sec\n",
      "optimizer time 0.022812 sec\n",
      "training time in round 297 cost 0.4073460102081299 sec\n",
      "loss 2.307219, train acc 0.099072\n",
      "round 298\n",
      "time to device 0.004571 sec\n",
      "time forward 3.979223 sec\n",
      "loss time 0.001292 sec\n",
      "backward time 0.012644 sec\n",
      "optimizer time 0.025194 sec\n",
      "training time in round 298 cost 0.4027070999145508 sec\n",
      "loss 2.307196, train acc 0.099159\n",
      "round 299\n",
      "time to device 0.006422 sec\n",
      "time forward 3.986494 sec\n",
      "loss time 0.000585 sec\n",
      "backward time 0.005051 sec\n",
      "optimizer time 0.014267 sec\n",
      "training time in round 299 cost 0.35956788063049316 sec\n",
      "loss 2.307176, train acc 0.099245\n",
      "round 300\n",
      "time to device 0.004951 sec\n",
      "time forward 4.000818 sec\n",
      "loss time 0.001252 sec\n",
      "backward time 0.010754 sec\n",
      "optimizer time 0.021329 sec\n",
      "training time in round 300 cost 0.4003469944000244 sec\n",
      "loss 2.307137, train acc 0.099227\n",
      "round 301\n",
      "time to device 0.005550 sec\n",
      "time forward 4.014311 sec\n",
      "loss time 0.001764 sec\n",
      "backward time 0.013593 sec\n",
      "optimizer time 0.023107 sec\n",
      "training time in round 301 cost 0.4137110710144043 sec\n",
      "loss 2.307140, train acc 0.099183\n",
      "round 302\n",
      "time to device 0.004702 sec\n",
      "time forward 4.030501 sec\n",
      "loss time 0.001418 sec\n",
      "backward time 0.018306 sec\n",
      "optimizer time 0.022491 sec\n",
      "training time in round 302 cost 0.4127078056335449 sec\n",
      "loss 2.307120, train acc 0.099190\n",
      "round 303\n",
      "time to device 0.005486 sec\n",
      "time forward 4.046310 sec\n",
      "loss time 0.001579 sec\n",
      "backward time 0.013082 sec\n",
      "optimizer time 0.024608 sec\n",
      "training time in round 303 cost 0.4065248966217041 sec\n",
      "loss 2.307103, train acc 0.099198\n",
      "round 304\n",
      "time to device 0.004486 sec\n",
      "time forward 4.060466 sec\n",
      "loss time 0.001550 sec\n",
      "backward time 0.011215 sec\n",
      "optimizer time 0.023973 sec\n",
      "training time in round 304 cost 0.3969390392303467 sec\n",
      "loss 2.307087, train acc 0.099001\n",
      "round 305\n",
      "time to device 0.003326 sec\n",
      "time forward 4.077141 sec\n",
      "loss time 0.001642 sec\n",
      "backward time 0.011991 sec\n",
      "optimizer time 0.021220 sec\n",
      "training time in round 305 cost 0.4089090824127197 sec\n",
      "loss 2.307068, train acc 0.099086\n",
      "round 306\n",
      "time to device 0.003787 sec\n",
      "time forward 4.091387 sec\n",
      "loss time 0.002024 sec\n",
      "backward time 0.013515 sec\n",
      "optimizer time 0.022010 sec\n",
      "training time in round 306 cost 0.4035327434539795 sec\n",
      "loss 2.307052, train acc 0.099018\n",
      "round 307\n",
      "time to device 0.010698 sec\n",
      "time forward 4.107564 sec\n",
      "loss time 0.001970 sec\n",
      "backward time 0.016035 sec\n",
      "optimizer time 0.022408 sec\n",
      "training time in round 307 cost 0.4191009998321533 sec\n",
      "loss 2.307038, train acc 0.099051\n",
      "round 308\n",
      "time to device 0.004261 sec\n",
      "time forward 4.123502 sec\n",
      "loss time 0.001607 sec\n",
      "backward time 0.013514 sec\n",
      "optimizer time 0.022075 sec\n",
      "training time in round 308 cost 0.40763020515441895 sec\n",
      "loss 2.307134, train acc 0.099236\n",
      "round 309\n",
      "time to device 0.006773 sec\n",
      "time forward 4.138525 sec\n",
      "loss time 0.002367 sec\n",
      "backward time 0.013945 sec\n",
      "optimizer time 0.024083 sec\n",
      "training time in round 309 cost 0.4154937267303467 sec\n",
      "loss 2.307125, train acc 0.099244\n",
      "round 310\n",
      "time to device 0.008913 sec\n",
      "time forward 4.146151 sec\n",
      "loss time 0.000881 sec\n",
      "backward time 0.007657 sec\n",
      "optimizer time 0.018203 sec\n",
      "training time in round 310 cost 0.3972349166870117 sec\n",
      "loss 2.307118, train acc 0.099176\n",
      "round 311\n",
      "time to device 0.004307 sec\n",
      "time forward 4.160015 sec\n",
      "loss time 0.001463 sec\n",
      "backward time 0.012869 sec\n",
      "optimizer time 0.023216 sec\n",
      "training time in round 311 cost 0.39687228202819824 sec\n",
      "loss 2.307103, train acc 0.099234\n",
      "round 312\n",
      "time to device 0.007861 sec\n",
      "time forward 4.173914 sec\n",
      "loss time 0.002684 sec\n",
      "backward time 0.013550 sec\n",
      "optimizer time 0.026018 sec\n",
      "training time in round 312 cost 0.40688586235046387 sec\n",
      "loss 2.307085, train acc 0.099166\n",
      "round 313\n",
      "time to device 0.009177 sec\n",
      "time forward 4.187596 sec\n",
      "loss time 0.002100 sec\n",
      "backward time 0.012415 sec\n",
      "optimizer time 0.027284 sec\n",
      "training time in round 313 cost 0.40345191955566406 sec\n",
      "loss 2.307106, train acc 0.099149\n",
      "round 314\n",
      "time to device 0.009603 sec\n",
      "time forward 4.201665 sec\n",
      "loss time 0.000992 sec\n",
      "backward time 0.010130 sec\n",
      "optimizer time 0.023454 sec\n",
      "training time in round 314 cost 0.408581018447876 sec\n",
      "loss 2.307107, train acc 0.099157\n",
      "round 315\n",
      "time to device 0.008989 sec\n",
      "time forward 4.219230 sec\n",
      "loss time 0.002109 sec\n",
      "backward time 0.014112 sec\n",
      "optimizer time 0.024071 sec\n",
      "training time in round 315 cost 0.4210469722747803 sec\n",
      "loss 2.307164, train acc 0.098991\n",
      "round 316\n",
      "time to device 0.008815 sec\n",
      "time forward 4.232172 sec\n",
      "loss time 0.001521 sec\n",
      "backward time 0.012768 sec\n",
      "optimizer time 0.022051 sec\n",
      "training time in round 316 cost 0.39451003074645996 sec\n",
      "loss 2.307163, train acc 0.098999\n",
      "round 317\n",
      "time to device 0.008236 sec\n",
      "time forward 4.247202 sec\n",
      "loss time 0.001582 sec\n",
      "backward time 0.015482 sec\n",
      "optimizer time 0.029664 sec\n",
      "training time in round 317 cost 0.4072749614715576 sec\n",
      "loss 2.307143, train acc 0.098934\n",
      "round 318\n",
      "time to device 0.009344 sec\n",
      "time forward 4.261673 sec\n",
      "loss time 0.006647 sec\n",
      "backward time 0.013601 sec\n",
      "optimizer time 0.023909 sec\n",
      "training time in round 318 cost 0.41062188148498535 sec\n",
      "loss 2.307137, train acc 0.098795\n",
      "round 319\n",
      "time to device 0.009733 sec\n",
      "time forward 4.275258 sec\n",
      "loss time 0.001038 sec\n",
      "backward time 0.011163 sec\n",
      "optimizer time 0.020347 sec\n",
      "training time in round 319 cost 0.4016439914703369 sec\n",
      "loss 2.307130, train acc 0.098853\n",
      "round 320\n",
      "time to device 0.012232 sec\n",
      "time forward 4.291901 sec\n",
      "loss time 0.001771 sec\n",
      "backward time 0.011732 sec\n",
      "optimizer time 0.023703 sec\n",
      "training time in round 320 cost 0.41259312629699707 sec\n",
      "loss 2.307117, train acc 0.098983\n",
      "round 321\n",
      "time to device 0.007384 sec\n",
      "time forward 4.300177 sec\n",
      "loss time 0.000603 sec\n",
      "backward time 0.009984 sec\n",
      "optimizer time 0.014572 sec\n",
      "training time in round 321 cost 0.3620009422302246 sec\n",
      "loss 2.307091, train acc 0.099063\n",
      "round 322\n",
      "time to device 0.008734 sec\n",
      "time forward 4.315678 sec\n",
      "loss time 0.001436 sec\n",
      "backward time 0.014010 sec\n",
      "optimizer time 0.024697 sec\n",
      "training time in round 322 cost 0.41939711570739746 sec\n",
      "loss 2.307089, train acc 0.099023\n",
      "round 323\n",
      "time to device 0.009180 sec\n",
      "time forward 4.330573 sec\n",
      "loss time 0.001371 sec\n",
      "backward time 0.013919 sec\n",
      "optimizer time 0.021720 sec\n",
      "training time in round 323 cost 0.39627981185913086 sec\n",
      "loss 2.307093, train acc 0.098838\n",
      "round 324\n",
      "time to device 0.006030 sec\n",
      "time forward 4.344193 sec\n",
      "loss time 0.001530 sec\n",
      "backward time 0.013066 sec\n",
      "optimizer time 0.021746 sec\n",
      "training time in round 324 cost 0.3935060501098633 sec\n",
      "loss 2.307082, train acc 0.098726\n",
      "round 325\n",
      "time to device 0.003881 sec\n",
      "time forward 4.358091 sec\n",
      "loss time 0.001660 sec\n",
      "backward time 0.011246 sec\n",
      "optimizer time 0.021609 sec\n",
      "training time in round 325 cost 0.40831899642944336 sec\n",
      "loss 2.307075, train acc 0.098783\n",
      "round 326\n",
      "time to device 0.003245 sec\n",
      "time forward 4.365127 sec\n",
      "loss time 0.000566 sec\n",
      "backward time 0.005254 sec\n",
      "optimizer time 0.014190 sec\n",
      "training time in round 326 cost 0.3498978614807129 sec\n",
      "loss 2.307061, train acc 0.098839\n",
      "round 327\n",
      "time to device 0.003187 sec\n",
      "time forward 4.379925 sec\n",
      "loss time 0.001612 sec\n",
      "backward time 0.015663 sec\n",
      "optimizer time 0.024936 sec\n",
      "training time in round 327 cost 0.39930200576782227 sec\n",
      "loss 2.307048, train acc 0.098776\n",
      "round 328\n",
      "time to device 0.004633 sec\n",
      "time forward 4.395713 sec\n",
      "loss time 0.002020 sec\n",
      "backward time 0.013363 sec\n",
      "optimizer time 0.023819 sec\n",
      "training time in round 328 cost 0.4076259136199951 sec\n",
      "loss 2.307044, train acc 0.098808\n",
      "round 329\n",
      "time to device 0.004050 sec\n",
      "time forward 4.409412 sec\n",
      "loss time 0.001927 sec\n",
      "backward time 0.015927 sec\n",
      "optimizer time 0.024362 sec\n",
      "training time in round 329 cost 0.40261316299438477 sec\n",
      "loss 2.307044, train acc 0.098698\n",
      "round 330\n",
      "time to device 0.003519 sec\n",
      "time forward 4.421668 sec\n",
      "loss time 0.001662 sec\n",
      "backward time 0.011999 sec\n",
      "optimizer time 0.023844 sec\n",
      "training time in round 330 cost 0.3915228843688965 sec\n",
      "loss 2.307026, train acc 0.098683\n",
      "round 331\n",
      "time to device 0.004383 sec\n",
      "time forward 4.437289 sec\n",
      "loss time 0.001552 sec\n",
      "backward time 0.015037 sec\n",
      "optimizer time 0.022139 sec\n",
      "training time in round 331 cost 0.3999459743499756 sec\n",
      "loss 2.307036, train acc 0.098645\n",
      "round 332\n",
      "time to device 0.006322 sec\n",
      "time forward 4.444144 sec\n",
      "loss time 0.000626 sec\n",
      "backward time 0.005730 sec\n",
      "optimizer time 0.015216 sec\n",
      "training time in round 332 cost 0.3630659580230713 sec\n",
      "loss 2.307023, train acc 0.098653\n",
      "round 333\n",
      "time to device 0.004131 sec\n",
      "time forward 4.457185 sec\n",
      "loss time 0.001604 sec\n",
      "backward time 0.013528 sec\n",
      "optimizer time 0.024358 sec\n",
      "training time in round 333 cost 0.4000530242919922 sec\n",
      "loss 2.307008, train acc 0.098779\n",
      "round 334\n",
      "time to device 0.004365 sec\n",
      "time forward 4.471149 sec\n",
      "loss time 0.001747 sec\n",
      "backward time 0.013216 sec\n",
      "optimizer time 0.024514 sec\n",
      "training time in round 334 cost 0.40160512924194336 sec\n",
      "loss 2.306991, train acc 0.098717\n",
      "round 335\n",
      "time to device 0.003445 sec\n",
      "time forward 4.485833 sec\n",
      "loss time 0.001910 sec\n",
      "backward time 0.013083 sec\n",
      "optimizer time 0.023695 sec\n",
      "training time in round 335 cost 0.40106916427612305 sec\n",
      "loss 2.306980, train acc 0.098726\n",
      "round 336\n",
      "time to device 0.002770 sec\n",
      "time forward 4.496800 sec\n",
      "loss time 0.000934 sec\n",
      "backward time 0.007605 sec\n",
      "optimizer time 0.017504 sec\n",
      "training time in round 336 cost 0.35644102096557617 sec\n",
      "loss 2.306967, train acc 0.098781\n",
      "round 337\n",
      "time to device 0.004896 sec\n",
      "time forward 4.504195 sec\n",
      "loss time 0.000640 sec\n",
      "backward time 0.006013 sec\n",
      "optimizer time 0.015778 sec\n",
      "training time in round 337 cost 0.3952507972717285 sec\n",
      "loss 2.306959, train acc 0.098766\n",
      "round 338\n",
      "time to device 0.009260 sec\n",
      "time forward 4.520134 sec\n",
      "loss time 0.001641 sec\n",
      "backward time 0.015083 sec\n",
      "optimizer time 0.025598 sec\n",
      "training time in round 338 cost 0.40960097312927246 sec\n",
      "loss 2.306953, train acc 0.098728\n",
      "round 339\n",
      "time to device 0.008526 sec\n",
      "time forward 4.532923 sec\n",
      "loss time 0.001311 sec\n",
      "backward time 0.010425 sec\n",
      "optimizer time 0.021336 sec\n",
      "training time in round 339 cost 0.39124393463134766 sec\n",
      "loss 2.306947, train acc 0.098690\n",
      "round 340\n",
      "time to device 0.009599 sec\n",
      "time forward 4.547858 sec\n",
      "loss time 0.001973 sec\n",
      "backward time 0.012067 sec\n",
      "optimizer time 0.022154 sec\n",
      "training time in round 340 cost 0.4113316535949707 sec\n",
      "loss 2.306919, train acc 0.098699\n",
      "round 341\n",
      "time to device 0.008968 sec\n",
      "time forward 4.563946 sec\n",
      "loss time 0.001405 sec\n",
      "backward time 0.012267 sec\n",
      "optimizer time 0.022115 sec\n",
      "training time in round 341 cost 0.404224157333374 sec\n",
      "loss 2.306905, train acc 0.098776\n",
      "round 342\n",
      "time to device 0.004267 sec\n",
      "time forward 4.577790 sec\n",
      "loss time 0.003639 sec\n",
      "backward time 0.012444 sec\n",
      "optimizer time 0.023189 sec\n",
      "training time in round 342 cost 0.39768505096435547 sec\n",
      "loss 2.306898, train acc 0.098784\n",
      "round 343\n",
      "time to device 0.004658 sec\n",
      "time forward 4.589714 sec\n",
      "loss time 0.002356 sec\n",
      "backward time 0.012174 sec\n",
      "optimizer time 0.027568 sec\n",
      "training time in round 343 cost 0.3886260986328125 sec\n",
      "loss 2.306884, train acc 0.098701\n",
      "round 344\n",
      "time to device 0.003910 sec\n",
      "time forward 4.596728 sec\n",
      "loss time 0.000644 sec\n",
      "backward time 0.005477 sec\n",
      "optimizer time 0.014435 sec\n",
      "training time in round 344 cost 0.34943294525146484 sec\n",
      "loss 2.306871, train acc 0.098687\n",
      "round 345\n",
      "time to device 0.004459 sec\n",
      "time forward 4.611532 sec\n",
      "loss time 0.001787 sec\n",
      "backward time 0.012975 sec\n",
      "optimizer time 0.024520 sec\n",
      "training time in round 345 cost 0.3918938636779785 sec\n",
      "loss 2.306855, train acc 0.098605\n",
      "round 346\n",
      "time to device 0.003207 sec\n",
      "time forward 4.624313 sec\n",
      "loss time 0.001337 sec\n",
      "backward time 0.011515 sec\n",
      "optimizer time 0.010696 sec\n",
      "training time in round 346 cost 0.37595486640930176 sec\n",
      "loss 2.306852, train acc 0.098591\n",
      "round 347\n",
      "time to device 0.004295 sec\n",
      "time forward 4.639093 sec\n",
      "loss time 0.001059 sec\n",
      "backward time 0.010517 sec\n",
      "optimizer time 0.022748 sec\n",
      "training time in round 347 cost 0.415820837020874 sec\n",
      "loss 2.306849, train acc 0.098554\n",
      "round 348\n",
      "time to device 0.004127 sec\n",
      "time forward 4.654977 sec\n",
      "loss time 0.001579 sec\n",
      "backward time 0.012729 sec\n",
      "optimizer time 0.026294 sec\n",
      "training time in round 348 cost 0.45274806022644043 sec\n",
      "loss 2.306845, train acc 0.098563\n",
      "round 349\n",
      "time to device 0.004654 sec\n",
      "time forward 4.670578 sec\n",
      "loss time 0.001565 sec\n",
      "backward time 0.016424 sec\n",
      "optimizer time 0.020828 sec\n",
      "training time in round 349 cost 0.4156200885772705 sec\n",
      "loss 2.306823, train acc 0.098571\n",
      "round 350\n",
      "time to device 0.005619 sec\n",
      "time forward 4.683834 sec\n",
      "loss time 0.002570 sec\n",
      "backward time 0.014811 sec\n",
      "optimizer time 0.023519 sec\n",
      "training time in round 350 cost 0.41180896759033203 sec\n",
      "loss 2.306807, train acc 0.098624\n",
      "round 351\n",
      "time to device 0.003603 sec\n",
      "time forward 4.700630 sec\n",
      "loss time 0.001996 sec\n",
      "backward time 0.012817 sec\n",
      "optimizer time 0.021735 sec\n",
      "training time in round 351 cost 0.40010809898376465 sec\n",
      "loss 2.306821, train acc 0.098611\n",
      "round 352\n",
      "time to device 0.004524 sec\n",
      "time forward 4.715104 sec\n",
      "loss time 0.001390 sec\n",
      "backward time 0.012795 sec\n",
      "optimizer time 0.021823 sec\n",
      "training time in round 352 cost 0.4107630252838135 sec\n",
      "loss 2.306807, train acc 0.098619\n",
      "round 353\n",
      "time to device 0.007284 sec\n",
      "time forward 4.731894 sec\n",
      "loss time 0.001427 sec\n",
      "backward time 0.016796 sec\n",
      "optimizer time 0.025204 sec\n",
      "training time in round 353 cost 0.4149138927459717 sec\n",
      "loss 2.306805, train acc 0.098605\n",
      "round 354\n",
      "time to device 0.008657 sec\n",
      "time forward 4.749041 sec\n",
      "loss time 0.001883 sec\n",
      "backward time 0.014314 sec\n",
      "optimizer time 0.015675 sec\n",
      "training time in round 354 cost 0.41713500022888184 sec\n",
      "loss 2.306791, train acc 0.098636\n",
      "round 355\n",
      "time to device 0.009776 sec\n",
      "time forward 4.764011 sec\n",
      "loss time 0.001249 sec\n",
      "backward time 0.015027 sec\n",
      "optimizer time 0.021854 sec\n",
      "training time in round 355 cost 0.3998539447784424 sec\n",
      "loss 2.306806, train acc 0.098534\n",
      "round 356\n",
      "time to device 0.004225 sec\n",
      "time forward 4.773752 sec\n",
      "loss time 0.000651 sec\n",
      "backward time 0.006021 sec\n",
      "optimizer time 0.015004 sec\n",
      "training time in round 356 cost 0.38190674781799316 sec\n",
      "loss 2.306785, train acc 0.098499\n",
      "round 357\n",
      "time to device 0.003751 sec\n",
      "time forward 4.787426 sec\n",
      "loss time 0.002028 sec\n",
      "backward time 0.015969 sec\n",
      "optimizer time 0.026418 sec\n",
      "training time in round 357 cost 0.4198949337005615 sec\n",
      "loss 2.306971, train acc 0.098507\n",
      "round 358\n",
      "time to device 0.005312 sec\n",
      "time forward 4.802162 sec\n",
      "loss time 0.002233 sec\n",
      "backward time 0.015432 sec\n",
      "optimizer time 0.024490 sec\n",
      "training time in round 358 cost 0.41089391708374023 sec\n",
      "loss 2.306953, train acc 0.098538\n",
      "round 359\n",
      "time to device 0.003504 sec\n",
      "time forward 4.820699 sec\n",
      "loss time 0.004698 sec\n",
      "backward time 0.012375 sec\n",
      "optimizer time 0.021712 sec\n",
      "training time in round 359 cost 0.4180569648742676 sec\n",
      "loss 2.306937, train acc 0.098633\n",
      "round 360\n",
      "time to device 0.004690 sec\n",
      "time forward 4.834330 sec\n",
      "loss time 0.001445 sec\n",
      "backward time 0.013657 sec\n",
      "optimizer time 0.023089 sec\n",
      "training time in round 360 cost 0.41123414039611816 sec\n",
      "loss 2.306937, train acc 0.098554\n",
      "round 361\n",
      "time to device 0.005951 sec\n",
      "time forward 4.851199 sec\n",
      "loss time 0.001600 sec\n",
      "backward time 0.012723 sec\n",
      "optimizer time 0.022239 sec\n",
      "training time in round 361 cost 0.40793490409851074 sec\n",
      "loss 2.306907, train acc 0.098735\n",
      "round 362\n",
      "time to device 0.004953 sec\n",
      "time forward 4.867144 sec\n",
      "loss time 0.002040 sec\n",
      "backward time 0.010818 sec\n",
      "optimizer time 0.023782 sec\n",
      "training time in round 362 cost 0.39461278915405273 sec\n",
      "loss 2.306899, train acc 0.098808\n",
      "round 363\n",
      "time to device 0.004803 sec\n",
      "time forward 4.882557 sec\n",
      "loss time 0.001556 sec\n",
      "backward time 0.013336 sec\n",
      "optimizer time 0.023040 sec\n",
      "training time in round 363 cost 0.3954129219055176 sec\n",
      "loss 2.306898, train acc 0.098751\n",
      "round 364\n",
      "time to device 0.004278 sec\n",
      "time forward 4.922876 sec\n",
      "loss time 0.000500 sec\n",
      "backward time 0.004144 sec\n",
      "optimizer time 0.014416 sec\n",
      "training time in round 364 cost 0.41135573387145996 sec\n",
      "loss 2.306916, train acc 0.098801\n",
      "round 365\n",
      "time to device 0.005018 sec\n",
      "time forward 4.940115 sec\n",
      "loss time 0.001713 sec\n",
      "backward time 0.017889 sec\n",
      "optimizer time 0.022262 sec\n",
      "training time in round 365 cost 0.4086930751800537 sec\n",
      "loss 2.306968, train acc 0.098894\n",
      "round 366\n",
      "time to device 0.004406 sec\n",
      "time forward 4.954533 sec\n",
      "loss time 0.001934 sec\n",
      "backward time 0.016830 sec\n",
      "optimizer time 0.025276 sec\n",
      "training time in round 366 cost 0.4096341133117676 sec\n",
      "loss 2.306963, train acc 0.098816\n",
      "round 367\n",
      "time to device 0.004864 sec\n",
      "time forward 4.970520 sec\n",
      "loss time 0.001150 sec\n",
      "backward time 0.015578 sec\n",
      "optimizer time 0.028395 sec\n",
      "training time in round 367 cost 0.4154980182647705 sec\n",
      "loss 2.306982, train acc 0.098781\n",
      "round 368\n",
      "time to device 0.004104 sec\n",
      "time forward 4.985278 sec\n",
      "loss time 0.001745 sec\n",
      "backward time 0.011212 sec\n",
      "optimizer time 0.020764 sec\n",
      "training time in round 368 cost 0.4021618366241455 sec\n",
      "loss 2.306976, train acc 0.098789\n",
      "round 369\n",
      "time to device 0.003602 sec\n",
      "time forward 4.998528 sec\n",
      "loss time 0.001911 sec\n",
      "backward time 0.019305 sec\n",
      "optimizer time 0.023313 sec\n",
      "training time in round 369 cost 0.40578293800354004 sec\n",
      "loss 2.307002, train acc 0.098712\n",
      "round 370\n",
      "time to device 0.004898 sec\n",
      "time forward 5.011409 sec\n",
      "loss time 0.002509 sec\n",
      "backward time 0.017477 sec\n",
      "optimizer time 0.022492 sec\n",
      "training time in round 370 cost 0.42989373207092285 sec\n",
      "loss 2.306993, train acc 0.098699\n",
      "round 371\n",
      "time to device 0.004889 sec\n",
      "time forward 5.025414 sec\n",
      "loss time 0.001560 sec\n",
      "backward time 0.013878 sec\n",
      "optimizer time 0.022738 sec\n",
      "training time in round 371 cost 0.3938100337982178 sec\n",
      "loss 2.306983, train acc 0.098622\n",
      "round 372\n",
      "time to device 0.007479 sec\n",
      "time forward 5.045825 sec\n",
      "loss time 0.001497 sec\n",
      "backward time 0.012827 sec\n",
      "optimizer time 0.022310 sec\n",
      "training time in round 372 cost 0.4250640869140625 sec\n",
      "loss 2.306979, train acc 0.098672\n",
      "round 373\n",
      "time to device 0.011372 sec\n",
      "time forward 5.053230 sec\n",
      "loss time 0.000691 sec\n",
      "backward time 0.005157 sec\n",
      "optimizer time 0.014208 sec\n",
      "training time in round 373 cost 0.36138010025024414 sec\n",
      "loss 2.306967, train acc 0.098701\n",
      "round 374\n",
      "time to device 0.007972 sec\n",
      "time forward 5.067214 sec\n",
      "loss time 0.001527 sec\n",
      "backward time 0.014284 sec\n",
      "optimizer time 0.021977 sec\n",
      "training time in round 374 cost 0.397233247756958 sec\n",
      "loss 2.306963, train acc 0.098583\n",
      "round 375\n",
      "time to device 0.009480 sec\n",
      "time forward 5.081114 sec\n",
      "loss time 0.001225 sec\n",
      "backward time 0.014435 sec\n",
      "optimizer time 0.024083 sec\n",
      "training time in round 375 cost 0.4056358337402344 sec\n",
      "loss 2.306950, train acc 0.098591\n",
      "round 376\n",
      "time to device 0.011645 sec\n",
      "time forward 5.096855 sec\n",
      "loss time 0.003090 sec\n",
      "backward time 0.015003 sec\n",
      "optimizer time 0.026298 sec\n",
      "training time in round 376 cost 0.4209470748901367 sec\n",
      "loss 2.306945, train acc 0.098558\n",
      "round 377\n",
      "time to device 0.008233 sec\n",
      "time forward 5.111610 sec\n",
      "loss time 0.001228 sec\n",
      "backward time 0.012424 sec\n",
      "optimizer time 0.021890 sec\n",
      "training time in round 377 cost 0.39787983894348145 sec\n",
      "loss 2.306925, train acc 0.098607\n",
      "round 378\n",
      "time to device 0.003801 sec\n",
      "time forward 5.126101 sec\n",
      "loss time 0.001979 sec\n",
      "backward time 0.018185 sec\n",
      "optimizer time 0.025672 sec\n",
      "training time in round 378 cost 0.40653419494628906 sec\n",
      "loss 2.306920, train acc 0.098532\n",
      "round 379\n",
      "time to device 0.004565 sec\n",
      "time forward 5.142868 sec\n",
      "loss time 0.001461 sec\n",
      "backward time 0.012070 sec\n",
      "optimizer time 0.024135 sec\n",
      "training time in round 379 cost 0.3950669765472412 sec\n",
      "loss 2.306904, train acc 0.098581\n",
      "round 380\n",
      "time to device 0.002923 sec\n",
      "time forward 5.156563 sec\n",
      "loss time 0.002052 sec\n",
      "backward time 0.011863 sec\n",
      "optimizer time 0.022863 sec\n",
      "training time in round 380 cost 0.4015800952911377 sec\n",
      "loss 2.306899, train acc 0.098589\n",
      "round 381\n",
      "time to device 0.004210 sec\n",
      "time forward 5.169235 sec\n",
      "loss time 0.001719 sec\n",
      "backward time 0.013430 sec\n",
      "optimizer time 0.020234 sec\n",
      "training time in round 381 cost 0.39075589179992676 sec\n",
      "loss 2.306888, train acc 0.098638\n",
      "round 382\n",
      "time to device 0.006131 sec\n",
      "time forward 5.182799 sec\n",
      "loss time 0.001626 sec\n",
      "backward time 0.014449 sec\n",
      "optimizer time 0.023394 sec\n",
      "training time in round 382 cost 0.3993349075317383 sec\n",
      "loss 2.306876, train acc 0.098625\n",
      "round 383\n",
      "time to device 0.003474 sec\n",
      "time forward 5.196583 sec\n",
      "loss time 0.001119 sec\n",
      "backward time 0.010185 sec\n",
      "optimizer time 0.011669 sec\n",
      "training time in round 383 cost 0.3789341449737549 sec\n",
      "loss 2.307008, train acc 0.098694\n",
      "round 384\n",
      "time to device 0.005788 sec\n",
      "time forward 5.209857 sec\n",
      "loss time 0.001872 sec\n",
      "backward time 0.015890 sec\n",
      "optimizer time 0.023240 sec\n",
      "training time in round 384 cost 0.4068148136138916 sec\n",
      "loss 2.307010, train acc 0.098681\n",
      "round 385\n",
      "time to device 0.004329 sec\n",
      "time forward 5.221608 sec\n",
      "loss time 0.001631 sec\n",
      "backward time 0.014608 sec\n",
      "optimizer time 0.022401 sec\n",
      "training time in round 385 cost 0.39337897300720215 sec\n",
      "loss 2.306986, train acc 0.098810\n",
      "round 386\n",
      "time to device 0.003866 sec\n",
      "time forward 5.240425 sec\n",
      "loss time 0.001579 sec\n",
      "backward time 0.013214 sec\n",
      "optimizer time 0.023930 sec\n",
      "training time in round 386 cost 0.4109508991241455 sec\n",
      "loss 2.306973, train acc 0.098777\n",
      "round 387\n",
      "time to device 0.003357 sec\n",
      "time forward 5.255475 sec\n",
      "loss time 0.001362 sec\n",
      "backward time 0.011550 sec\n",
      "optimizer time 0.021676 sec\n",
      "training time in round 387 cost 0.4526369571685791 sec\n",
      "loss 2.306964, train acc 0.098804\n",
      "round 388\n",
      "time to device 0.004524 sec\n",
      "time forward 5.268640 sec\n",
      "loss time 0.001650 sec\n",
      "backward time 0.014861 sec\n",
      "optimizer time 0.028110 sec\n",
      "training time in round 388 cost 0.4006619453430176 sec\n",
      "loss 2.306956, train acc 0.098791\n",
      "round 389\n",
      "time to device 0.010563 sec\n",
      "time forward 5.283034 sec\n",
      "loss time 0.002324 sec\n",
      "backward time 0.015013 sec\n",
      "optimizer time 0.022992 sec\n",
      "training time in round 389 cost 0.4034860134124756 sec\n",
      "loss 2.306943, train acc 0.098838\n",
      "round 390\n",
      "time to device 0.009936 sec\n",
      "time forward 5.294173 sec\n",
      "loss time 0.001972 sec\n",
      "backward time 0.015408 sec\n",
      "optimizer time 0.025088 sec\n",
      "training time in round 390 cost 0.41260313987731934 sec\n",
      "loss 2.306936, train acc 0.098785\n",
      "round 391\n",
      "time to device 0.008357 sec\n",
      "time forward 5.307880 sec\n",
      "loss time 0.001522 sec\n",
      "backward time 0.014218 sec\n",
      "optimizer time 0.025166 sec\n",
      "training time in round 391 cost 0.403684139251709 sec\n",
      "loss 2.306935, train acc 0.098673\n",
      "round 392\n",
      "time to device 0.010326 sec\n",
      "time forward 5.321940 sec\n",
      "loss time 0.001801 sec\n",
      "backward time 0.015673 sec\n",
      "optimizer time 0.027028 sec\n",
      "training time in round 392 cost 0.42181921005249023 sec\n",
      "loss 2.306914, train acc 0.098760\n",
      "round 393\n",
      "time to device 0.009174 sec\n",
      "time forward 5.336575 sec\n",
      "loss time 0.001641 sec\n",
      "backward time 0.011746 sec\n",
      "optimizer time 0.023684 sec\n",
      "training time in round 393 cost 0.4072089195251465 sec\n",
      "loss 2.306915, train acc 0.098707\n",
      "round 394\n",
      "time to device 0.008357 sec\n",
      "time forward 5.352107 sec\n",
      "loss time 0.001673 sec\n",
      "backward time 0.015745 sec\n",
      "optimizer time 0.024305 sec\n",
      "training time in round 394 cost 0.4074680805206299 sec\n",
      "loss 2.306898, train acc 0.098774\n",
      "round 395\n",
      "time to device 0.009021 sec\n",
      "time forward 5.367314 sec\n",
      "loss time 0.001734 sec\n",
      "backward time 0.020115 sec\n",
      "optimizer time 0.020606 sec\n",
      "training time in round 395 cost 0.42798423767089844 sec\n",
      "loss 2.306881, train acc 0.098820\n",
      "round 396\n",
      "time to device 0.007970 sec\n",
      "time forward 5.382377 sec\n",
      "loss time 0.001588 sec\n",
      "backward time 0.014335 sec\n",
      "optimizer time 0.022830 sec\n",
      "training time in round 396 cost 0.42920899391174316 sec\n",
      "loss 2.306874, train acc 0.098847\n",
      "round 397\n",
      "time to device 0.008743 sec\n",
      "time forward 5.397713 sec\n",
      "loss time 0.001467 sec\n",
      "backward time 0.013708 sec\n",
      "optimizer time 0.023687 sec\n",
      "training time in round 397 cost 0.40285181999206543 sec\n",
      "loss 2.306868, train acc 0.098736\n",
      "round 398\n",
      "time to device 0.005285 sec\n",
      "time forward 5.417059 sec\n",
      "loss time 0.001565 sec\n",
      "backward time 0.016341 sec\n",
      "optimizer time 0.022969 sec\n",
      "training time in round 398 cost 0.4156491756439209 sec\n",
      "loss 2.306839, train acc 0.098665\n",
      "round 399\n",
      "time to device 0.003692 sec\n",
      "time forward 5.431052 sec\n",
      "loss time 0.001926 sec\n",
      "backward time 0.014332 sec\n",
      "optimizer time 0.022116 sec\n",
      "training time in round 399 cost 0.3988020420074463 sec\n",
      "loss 2.306821, train acc 0.098672\n",
      "round 400\n",
      "time to device 0.003357 sec\n",
      "time forward 5.445985 sec\n",
      "loss time 0.001812 sec\n",
      "backward time 0.014116 sec\n",
      "optimizer time 0.024374 sec\n",
      "training time in round 400 cost 0.4017219543457031 sec\n",
      "loss 2.306811, train acc 0.098640\n",
      "round 401\n",
      "time to device 0.005810 sec\n",
      "time forward 5.459805 sec\n",
      "loss time 0.001344 sec\n",
      "backward time 0.012622 sec\n",
      "optimizer time 0.021890 sec\n",
      "training time in round 401 cost 0.3956129550933838 sec\n",
      "loss 2.306803, train acc 0.098589\n",
      "round 402\n",
      "time to device 0.004262 sec\n",
      "time forward 5.472441 sec\n",
      "loss time 0.001537 sec\n",
      "backward time 0.014063 sec\n",
      "optimizer time 0.024483 sec\n",
      "training time in round 402 cost 0.39619874954223633 sec\n",
      "loss 2.306801, train acc 0.098538\n",
      "round 403\n",
      "time to device 0.003744 sec\n",
      "time forward 5.485655 sec\n",
      "loss time 0.002180 sec\n",
      "backward time 0.014084 sec\n",
      "optimizer time 0.027925 sec\n",
      "training time in round 403 cost 0.4041872024536133 sec\n",
      "loss 2.306791, train acc 0.098526\n",
      "round 404\n",
      "time to device 0.002808 sec\n",
      "time forward 5.500096 sec\n",
      "loss time 0.001364 sec\n",
      "backward time 0.014332 sec\n",
      "optimizer time 0.024032 sec\n",
      "training time in round 404 cost 0.399212121963501 sec\n",
      "loss 2.306777, train acc 0.098515\n",
      "round 405\n",
      "time to device 0.006978 sec\n",
      "time forward 5.513934 sec\n",
      "loss time 0.001378 sec\n",
      "backward time 0.011513 sec\n",
      "optimizer time 0.026722 sec\n",
      "training time in round 405 cost 0.406296968460083 sec\n",
      "loss 2.306813, train acc 0.098580\n",
      "round 406\n",
      "time to device 0.003739 sec\n",
      "time forward 5.530266 sec\n",
      "loss time 0.001429 sec\n",
      "backward time 0.017311 sec\n",
      "optimizer time 0.025477 sec\n",
      "training time in round 406 cost 0.421130895614624 sec\n",
      "loss 2.306810, train acc 0.098587\n",
      "round 407\n",
      "time to device 0.004650 sec\n",
      "time forward 5.544582 sec\n",
      "loss time 0.001637 sec\n",
      "backward time 0.013088 sec\n",
      "optimizer time 0.023946 sec\n",
      "training time in round 407 cost 0.39858508110046387 sec\n",
      "loss 2.306795, train acc 0.098575\n",
      "round 408\n",
      "time to device 0.003815 sec\n",
      "time forward 5.559289 sec\n",
      "loss time 0.001588 sec\n",
      "backward time 0.012355 sec\n",
      "optimizer time 0.024560 sec\n",
      "training time in round 408 cost 0.4053518772125244 sec\n",
      "loss 2.306785, train acc 0.098544\n",
      "round 409\n",
      "time to device 0.004788 sec\n",
      "time forward 5.572223 sec\n",
      "loss time 0.003022 sec\n",
      "backward time 0.011917 sec\n",
      "optimizer time 0.024282 sec\n",
      "training time in round 409 cost 0.3996872901916504 sec\n",
      "loss 2.306792, train acc 0.098533\n",
      "round 410\n",
      "time to device 0.004901 sec\n",
      "time forward 5.588089 sec\n",
      "loss time 0.003726 sec\n",
      "backward time 0.018884 sec\n",
      "optimizer time 0.021376 sec\n",
      "training time in round 410 cost 0.41050076484680176 sec\n",
      "loss 2.306783, train acc 0.098464\n",
      "round 411\n",
      "time to device 0.003887 sec\n",
      "time forward 5.602409 sec\n",
      "loss time 0.002454 sec\n",
      "backward time 0.009415 sec\n",
      "optimizer time 0.020426 sec\n",
      "training time in round 411 cost 0.3941068649291992 sec\n",
      "loss 2.306839, train acc 0.098415\n",
      "round 412\n",
      "time to device 0.004330 sec\n",
      "time forward 5.617632 sec\n",
      "loss time 0.001891 sec\n",
      "backward time 0.012995 sec\n",
      "optimizer time 0.022564 sec\n",
      "training time in round 412 cost 0.40224194526672363 sec\n",
      "loss 2.306841, train acc 0.098422\n",
      "round 413\n",
      "time to device 0.003688 sec\n",
      "time forward 5.629497 sec\n",
      "loss time 0.001663 sec\n",
      "backward time 0.015704 sec\n",
      "optimizer time 0.014862 sec\n",
      "training time in round 413 cost 0.377453088760376 sec\n",
      "loss 2.306821, train acc 0.098430\n",
      "round 414\n",
      "time to device 0.003730 sec\n",
      "time forward 5.645154 sec\n",
      "loss time 0.001901 sec\n",
      "backward time 0.012064 sec\n",
      "optimizer time 0.025306 sec\n",
      "training time in round 414 cost 0.40422725677490234 sec\n",
      "loss 2.306802, train acc 0.098532\n",
      "round 415\n",
      "time to device 0.003705 sec\n",
      "time forward 5.652261 sec\n",
      "loss time 0.000534 sec\n",
      "backward time 0.004543 sec\n",
      "optimizer time 0.016530 sec\n",
      "training time in round 415 cost 0.4024698734283447 sec\n",
      "loss 2.306793, train acc 0.098520\n",
      "round 416\n",
      "time to device 0.003555 sec\n",
      "time forward 5.669370 sec\n",
      "loss time 0.003311 sec\n",
      "backward time 0.023566 sec\n",
      "optimizer time 0.021627 sec\n",
      "training time in round 416 cost 0.42320799827575684 sec\n",
      "loss 2.306796, train acc 0.098546\n",
      "round 417\n",
      "time to device 0.004460 sec\n",
      "time forward 5.682241 sec\n",
      "loss time 0.003443 sec\n",
      "backward time 0.010839 sec\n",
      "optimizer time 0.021854 sec\n",
      "training time in round 417 cost 0.4039921760559082 sec\n",
      "loss 2.306804, train acc 0.098460\n",
      "round 418\n",
      "time to device 0.003744 sec\n",
      "time forward 5.694534 sec\n",
      "loss time 0.001115 sec\n",
      "backward time 0.013557 sec\n",
      "optimizer time 0.024047 sec\n",
      "training time in round 418 cost 0.3901481628417969 sec\n",
      "loss 2.306813, train acc 0.098337\n",
      "round 419\n",
      "time to device 0.003232 sec\n",
      "time forward 5.709428 sec\n",
      "loss time 0.004682 sec\n",
      "backward time 0.011915 sec\n",
      "optimizer time 0.021037 sec\n",
      "training time in round 419 cost 0.3998987674713135 sec\n",
      "loss 2.306818, train acc 0.098326\n",
      "round 420\n",
      "time to device 0.004213 sec\n",
      "time forward 5.721889 sec\n",
      "loss time 0.001967 sec\n",
      "backward time 0.014969 sec\n",
      "optimizer time 0.026687 sec\n",
      "training time in round 420 cost 0.40045905113220215 sec\n",
      "loss 2.306813, train acc 0.098241\n",
      "round 421\n",
      "time to device 0.003236 sec\n",
      "time forward 5.734298 sec\n",
      "loss time 0.001272 sec\n",
      "backward time 0.010941 sec\n",
      "optimizer time 0.021808 sec\n",
      "training time in round 421 cost 0.39034199714660645 sec\n",
      "loss 2.306860, train acc 0.098286\n",
      "round 422\n",
      "time to device 0.010449 sec\n",
      "time forward 5.751023 sec\n",
      "loss time 0.001983 sec\n",
      "backward time 0.022926 sec\n",
      "optimizer time 0.023085 sec\n",
      "training time in round 422 cost 0.4192240238189697 sec\n",
      "loss 2.306846, train acc 0.098330\n",
      "round 423\n",
      "time to device 0.005614 sec\n",
      "time forward 5.764837 sec\n",
      "loss time 0.001605 sec\n",
      "backward time 0.012715 sec\n",
      "optimizer time 0.022410 sec\n",
      "training time in round 423 cost 0.41089701652526855 sec\n",
      "loss 2.306888, train acc 0.098227\n",
      "round 424\n",
      "time to device 0.004039 sec\n",
      "time forward 5.781494 sec\n",
      "loss time 0.001858 sec\n",
      "backward time 0.011847 sec\n",
      "optimizer time 0.027237 sec\n",
      "training time in round 424 cost 0.41680264472961426 sec\n",
      "loss 2.306879, train acc 0.098180\n",
      "round 425\n",
      "time to device 0.003604 sec\n",
      "time forward 5.794132 sec\n",
      "loss time 0.002124 sec\n",
      "backward time 0.020963 sec\n",
      "optimizer time 0.023402 sec\n",
      "training time in round 425 cost 0.4051351547241211 sec\n",
      "loss 2.306873, train acc 0.098151\n",
      "round 426\n",
      "time to device 0.003369 sec\n",
      "time forward 5.803488 sec\n",
      "loss time 0.000523 sec\n",
      "backward time 0.004540 sec\n",
      "optimizer time 0.013204 sec\n",
      "training time in round 426 cost 0.3567178249359131 sec\n",
      "loss 2.306874, train acc 0.098086\n",
      "round 427\n",
      "time to device 0.005013 sec\n",
      "time forward 5.816431 sec\n",
      "loss time 0.001901 sec\n",
      "backward time 0.015639 sec\n",
      "optimizer time 0.022214 sec\n",
      "training time in round 427 cost 0.3981740474700928 sec\n",
      "loss 2.306864, train acc 0.098094\n",
      "round 428\n",
      "time to device 0.003579 sec\n",
      "time forward 5.834110 sec\n",
      "loss time 0.001263 sec\n",
      "backward time 0.012096 sec\n",
      "optimizer time 0.024696 sec\n",
      "training time in round 428 cost 0.4139430522918701 sec\n",
      "loss 2.306855, train acc 0.098157\n",
      "round 429\n",
      "time to device 0.004343 sec\n",
      "time forward 5.851894 sec\n",
      "loss time 0.001511 sec\n",
      "backward time 0.014935 sec\n",
      "optimizer time 0.023561 sec\n",
      "training time in round 429 cost 0.455000638961792 sec\n",
      "loss 2.306833, train acc 0.098365\n",
      "round 430\n",
      "time to device 0.007812 sec\n",
      "time forward 5.867837 sec\n",
      "loss time 0.001568 sec\n",
      "backward time 0.012048 sec\n",
      "optimizer time 0.023163 sec\n",
      "training time in round 430 cost 0.4029092788696289 sec\n",
      "loss 2.306819, train acc 0.098463\n",
      "round 431\n",
      "time to device 0.008213 sec\n",
      "time forward 5.885297 sec\n",
      "loss time 0.002325 sec\n",
      "backward time 0.011972 sec\n",
      "optimizer time 0.024269 sec\n",
      "training time in round 431 cost 0.41074109077453613 sec\n",
      "loss 2.306815, train acc 0.098416\n",
      "round 432\n",
      "time to device 0.007950 sec\n",
      "time forward 5.892398 sec\n",
      "loss time 0.000577 sec\n",
      "backward time 0.005296 sec\n",
      "optimizer time 0.015059 sec\n",
      "training time in round 432 cost 0.3611183166503906 sec\n",
      "loss 2.306826, train acc 0.098369\n",
      "round 433\n",
      "time to device 0.007146 sec\n",
      "time forward 5.908410 sec\n",
      "loss time 0.001977 sec\n",
      "backward time 0.014082 sec\n",
      "optimizer time 0.022972 sec\n",
      "training time in round 433 cost 0.4257190227508545 sec\n",
      "loss 2.306817, train acc 0.098394\n",
      "round 434\n",
      "time to device 0.009744 sec\n",
      "time forward 5.923315 sec\n",
      "loss time 0.001990 sec\n",
      "backward time 0.013894 sec\n",
      "optimizer time 0.022211 sec\n",
      "training time in round 434 cost 0.4050590991973877 sec\n",
      "loss 2.306805, train acc 0.098437\n",
      "round 435\n",
      "time to device 0.008365 sec\n",
      "time forward 5.937241 sec\n",
      "loss time 0.003370 sec\n",
      "backward time 0.011451 sec\n",
      "optimizer time 0.021354 sec\n",
      "training time in round 435 cost 0.4039168357849121 sec\n",
      "loss 2.306803, train acc 0.098373\n",
      "round 436\n",
      "time to device 0.007985 sec\n",
      "time forward 5.950697 sec\n",
      "loss time 0.001579 sec\n",
      "backward time 0.012495 sec\n",
      "optimizer time 0.023477 sec\n",
      "training time in round 436 cost 0.41854310035705566 sec\n",
      "loss 2.306798, train acc 0.098291\n",
      "round 437\n",
      "time to device 0.010976 sec\n",
      "time forward 5.964918 sec\n",
      "loss time 0.003281 sec\n",
      "backward time 0.020573 sec\n",
      "optimizer time 0.022943 sec\n",
      "training time in round 437 cost 0.4079861640930176 sec\n",
      "loss 2.306785, train acc 0.098352\n",
      "round 438\n",
      "time to device 0.010548 sec\n",
      "time forward 5.981872 sec\n",
      "loss time 0.001949 sec\n",
      "backward time 0.014917 sec\n",
      "optimizer time 0.023998 sec\n",
      "training time in round 438 cost 0.4095339775085449 sec\n",
      "loss 2.306775, train acc 0.098377\n",
      "round 439\n",
      "time to device 0.006631 sec\n",
      "time forward 5.992802 sec\n",
      "loss time 0.001370 sec\n",
      "backward time 0.011718 sec\n",
      "optimizer time 0.016428 sec\n",
      "training time in round 439 cost 0.3752329349517822 sec\n",
      "loss 2.306773, train acc 0.098366\n",
      "round 440\n",
      "time to device 0.007186 sec\n",
      "time forward 6.005975 sec\n",
      "loss time 0.001938 sec\n",
      "backward time 0.015542 sec\n",
      "optimizer time 0.025030 sec\n",
      "training time in round 440 cost 0.40688014030456543 sec\n",
      "loss 2.306765, train acc 0.098303\n",
      "round 441\n",
      "time to device 0.007797 sec\n",
      "time forward 6.020410 sec\n",
      "loss time 0.002027 sec\n",
      "backward time 0.013855 sec\n",
      "optimizer time 0.022776 sec\n",
      "training time in round 441 cost 0.39795899391174316 sec\n",
      "loss 2.306792, train acc 0.098328\n",
      "round 442\n",
      "time to device 0.006418 sec\n",
      "time forward 6.039495 sec\n",
      "loss time 0.001484 sec\n",
      "backward time 0.013744 sec\n",
      "optimizer time 0.022028 sec\n",
      "training time in round 442 cost 0.4177131652832031 sec\n",
      "loss 2.306786, train acc 0.098335\n",
      "round 443\n",
      "time to device 0.008840 sec\n",
      "time forward 6.052375 sec\n",
      "loss time 0.001586 sec\n",
      "backward time 0.012590 sec\n",
      "optimizer time 0.022884 sec\n",
      "training time in round 443 cost 0.3983159065246582 sec\n",
      "loss 2.306776, train acc 0.098413\n",
      "round 444\n",
      "time to device 0.003518 sec\n",
      "time forward 6.067762 sec\n",
      "loss time 0.001091 sec\n",
      "backward time 0.013847 sec\n",
      "optimizer time 0.024196 sec\n",
      "training time in round 444 cost 0.4000210762023926 sec\n",
      "loss 2.306768, train acc 0.098385\n",
      "round 445\n",
      "time to device 0.004038 sec\n",
      "time forward 6.081105 sec\n",
      "loss time 0.001780 sec\n",
      "backward time 0.012385 sec\n",
      "optimizer time 0.022542 sec\n",
      "training time in round 445 cost 0.39042091369628906 sec\n",
      "loss 2.306813, train acc 0.098409\n",
      "round 446\n",
      "time to device 0.003860 sec\n",
      "time forward 6.088349 sec\n",
      "loss time 0.000576 sec\n",
      "backward time 0.005135 sec\n",
      "optimizer time 0.013733 sec\n",
      "training time in round 446 cost 0.3588080406188965 sec\n",
      "loss 2.306829, train acc 0.098329\n",
      "round 447\n",
      "time to device 0.003353 sec\n",
      "time forward 6.101066 sec\n",
      "loss time 0.001945 sec\n",
      "backward time 0.020540 sec\n",
      "optimizer time 0.013936 sec\n",
      "training time in round 447 cost 0.39588308334350586 sec\n",
      "loss 2.306826, train acc 0.098284\n",
      "round 448\n",
      "time to device 0.003617 sec\n",
      "time forward 6.116488 sec\n",
      "loss time 0.001311 sec\n",
      "backward time 0.010935 sec\n",
      "optimizer time 0.010290 sec\n",
      "training time in round 448 cost 0.3823881149291992 sec\n",
      "loss 2.306939, train acc 0.098257\n",
      "round 449\n",
      "time to device 0.003075 sec\n",
      "time forward 6.131305 sec\n",
      "loss time 0.001467 sec\n",
      "backward time 0.012991 sec\n",
      "optimizer time 0.022342 sec\n",
      "training time in round 449 cost 0.3959999084472656 sec\n",
      "loss 2.306924, train acc 0.098281\n",
      "round 450\n",
      "time to device 0.003794 sec\n",
      "time forward 6.144469 sec\n",
      "loss time 0.001345 sec\n",
      "backward time 0.011473 sec\n",
      "optimizer time 0.020748 sec\n",
      "training time in round 450 cost 0.3932051658630371 sec\n",
      "loss 2.306919, train acc 0.098237\n",
      "round 451\n",
      "time to device 0.003616 sec\n",
      "time forward 6.159917 sec\n",
      "loss time 0.001051 sec\n",
      "backward time 0.013861 sec\n",
      "optimizer time 0.025606 sec\n",
      "training time in round 451 cost 0.40305399894714355 sec\n",
      "loss 2.306908, train acc 0.098313\n",
      "round 452\n",
      "time to device 0.003168 sec\n",
      "time forward 6.174752 sec\n",
      "loss time 0.001149 sec\n",
      "backward time 0.011025 sec\n",
      "optimizer time 0.021690 sec\n",
      "training time in round 452 cost 0.3953592777252197 sec\n",
      "loss 2.306894, train acc 0.098286\n",
      "round 453\n",
      "time to device 0.003541 sec\n",
      "time forward 6.188263 sec\n",
      "loss time 0.001425 sec\n",
      "backward time 0.012949 sec\n",
      "optimizer time 0.023567 sec\n",
      "training time in round 453 cost 0.3963918685913086 sec\n",
      "loss 2.307043, train acc 0.098327\n",
      "round 454\n",
      "time to device 0.004791 sec\n",
      "time forward 6.202083 sec\n",
      "loss time 0.001575 sec\n",
      "backward time 0.013592 sec\n",
      "optimizer time 0.021754 sec\n",
      "training time in round 454 cost 0.3997530937194824 sec\n",
      "loss 2.310092, train acc 0.098283\n",
      "round 455\n",
      "time to device 0.003359 sec\n",
      "time forward 6.214537 sec\n",
      "loss time 0.001268 sec\n",
      "backward time 0.014423 sec\n",
      "optimizer time 0.013759 sec\n",
      "training time in round 455 cost 0.3808619976043701 sec\n",
      "loss 2.310155, train acc 0.098187\n",
      "round 456\n",
      "time to device 0.005177 sec\n",
      "time forward 6.233426 sec\n",
      "loss time 0.001996 sec\n",
      "backward time 0.012497 sec\n",
      "optimizer time 0.022060 sec\n",
      "training time in round 456 cost 0.42191386222839355 sec\n",
      "loss 2.310296, train acc 0.098178\n",
      "round 457\n",
      "time to device 0.006683 sec\n",
      "time forward 6.247997 sec\n",
      "loss time 0.001529 sec\n",
      "backward time 0.014163 sec\n",
      "optimizer time 0.022721 sec\n",
      "training time in round 457 cost 0.4528999328613281 sec\n",
      "loss 2.310642, train acc 0.098083\n",
      "round 458\n",
      "time to device 0.010711 sec\n",
      "time forward 6.262179 sec\n",
      "loss time 0.001778 sec\n",
      "backward time 0.016805 sec\n",
      "optimizer time 0.021248 sec\n",
      "training time in round 458 cost 0.40230798721313477 sec\n",
      "loss 2.310678, train acc 0.098141\n",
      "round 459\n",
      "time to device 0.006690 sec\n",
      "time forward 6.276490 sec\n",
      "loss time 0.001542 sec\n",
      "backward time 0.012792 sec\n",
      "optimizer time 0.022181 sec\n",
      "training time in round 459 cost 0.39485907554626465 sec\n",
      "loss 2.310860, train acc 0.098132\n",
      "round 460\n",
      "time to device 0.005644 sec\n",
      "time forward 6.293247 sec\n",
      "loss time 0.002388 sec\n",
      "backward time 0.012023 sec\n",
      "optimizer time 0.024599 sec\n",
      "training time in round 460 cost 0.42760705947875977 sec\n",
      "loss 2.310902, train acc 0.098088\n",
      "round 461\n",
      "time to device 0.003773 sec\n",
      "time forward 6.312228 sec\n",
      "loss time 0.001518 sec\n",
      "backward time 0.015055 sec\n",
      "optimizer time 0.025684 sec\n",
      "training time in round 461 cost 0.4267730712890625 sec\n",
      "loss 2.310947, train acc 0.097994\n",
      "round 462\n",
      "time to device 0.004405 sec\n",
      "time forward 6.329120 sec\n",
      "loss time 0.001588 sec\n",
      "backward time 0.014904 sec\n",
      "optimizer time 0.024776 sec\n",
      "training time in round 462 cost 0.41083407402038574 sec\n",
      "loss 2.311139, train acc 0.098053\n",
      "round 463\n",
      "time to device 0.003405 sec\n",
      "time forward 6.346608 sec\n",
      "loss time 0.001152 sec\n",
      "backward time 0.010171 sec\n",
      "optimizer time 0.019884 sec\n",
      "training time in round 463 cost 0.40566015243530273 sec\n",
      "loss 2.311121, train acc 0.097993\n",
      "round 464\n",
      "time to device 0.004360 sec\n",
      "time forward 6.364240 sec\n",
      "loss time 0.001481 sec\n",
      "backward time 0.012507 sec\n",
      "optimizer time 0.023305 sec\n",
      "training time in round 464 cost 0.4211890697479248 sec\n",
      "loss 2.311461, train acc 0.097984\n",
      "round 465\n",
      "time to device 0.003950 sec\n",
      "time forward 6.373919 sec\n",
      "loss time 0.000760 sec\n",
      "backward time 0.006940 sec\n",
      "optimizer time 0.016356 sec\n",
      "training time in round 465 cost 0.3775486946105957 sec\n",
      "loss 2.311892, train acc 0.098042\n",
      "round 466\n",
      "time to device 0.005084 sec\n",
      "time forward 6.389259 sec\n",
      "loss time 0.002016 sec\n",
      "backward time 0.017953 sec\n",
      "optimizer time 0.024946 sec\n",
      "training time in round 466 cost 0.41599106788635254 sec\n",
      "loss 2.311870, train acc 0.098033\n",
      "round 467\n",
      "time to device 0.003380 sec\n",
      "time forward 6.404446 sec\n",
      "loss time 0.001190 sec\n",
      "backward time 0.014071 sec\n",
      "optimizer time 0.021490 sec\n",
      "training time in round 467 cost 0.40821099281311035 sec\n",
      "loss 2.312150, train acc 0.098024\n",
      "round 468\n",
      "time to device 0.004354 sec\n",
      "time forward 6.426834 sec\n",
      "loss time 0.002903 sec\n",
      "backward time 0.016078 sec\n",
      "optimizer time 0.018976 sec\n",
      "training time in round 468 cost 0.37417078018188477 sec\n",
      "loss 2.312136, train acc 0.098050\n",
      "test acc is 0.100000\n",
      "epoch 6, time 3084.977520 sec\n",
      "epoch 8\n",
      "round 0\n",
      "time to device 0.041750 sec\n",
      "time forward 0.013894 sec\n",
      "loss time 0.002298 sec\n",
      "backward time 0.017667 sec\n",
      "optimizer time 0.056557 sec\n",
      "training time in round 0 cost 0.5442779064178467 sec\n",
      "loss 2.320306, train acc 0.093750\n",
      "round 1\n",
      "time to device 0.006232 sec\n",
      "time forward 0.032089 sec\n",
      "loss time 0.001612 sec\n",
      "backward time 0.014581 sec\n",
      "optimizer time 0.024174 sec\n",
      "training time in round 1 cost 0.47352075576782227 sec\n",
      "loss 2.319648, train acc 0.101562\n",
      "round 2\n",
      "time to device 0.011487 sec\n",
      "time forward 0.047187 sec\n",
      "loss time 0.001982 sec\n",
      "backward time 0.014747 sec\n",
      "optimizer time 0.026115 sec\n",
      "training time in round 2 cost 0.41304802894592285 sec\n",
      "loss 2.312949, train acc 0.088542\n",
      "round 3\n",
      "time to device 0.008529 sec\n",
      "time forward 0.059994 sec\n",
      "loss time 0.002438 sec\n",
      "backward time 0.015134 sec\n",
      "optimizer time 0.024761 sec\n",
      "training time in round 3 cost 0.39733195304870605 sec\n",
      "loss 2.305941, train acc 0.093750\n",
      "round 4\n",
      "time to device 0.009632 sec\n",
      "time forward 0.075715 sec\n",
      "loss time 0.001438 sec\n",
      "backward time 0.013247 sec\n",
      "optimizer time 0.022978 sec\n",
      "training time in round 4 cost 0.40064382553100586 sec\n",
      "loss 2.298943, train acc 0.101562\n",
      "round 5\n",
      "time to device 0.008567 sec\n",
      "time forward 0.088101 sec\n",
      "loss time 0.001285 sec\n",
      "backward time 0.011762 sec\n",
      "optimizer time 0.023043 sec\n",
      "training time in round 5 cost 0.39327120780944824 sec\n",
      "loss 2.330740, train acc 0.093750\n",
      "round 6\n",
      "time to device 0.009575 sec\n",
      "time forward 0.101668 sec\n",
      "loss time 0.001898 sec\n",
      "backward time 0.017198 sec\n",
      "optimizer time 0.028071 sec\n",
      "training time in round 6 cost 0.4158170223236084 sec\n",
      "loss 2.340873, train acc 0.094866\n",
      "round 7\n",
      "time to device 0.008798 sec\n",
      "time forward 0.113797 sec\n",
      "loss time 0.002092 sec\n",
      "backward time 0.025739 sec\n",
      "optimizer time 0.021743 sec\n",
      "training time in round 7 cost 0.40868496894836426 sec\n",
      "loss 2.335437, train acc 0.092773\n",
      "round 8\n",
      "time to device 0.010567 sec\n",
      "time forward 0.126481 sec\n",
      "loss time 0.001846 sec\n",
      "backward time 0.011640 sec\n",
      "optimizer time 0.021583 sec\n",
      "training time in round 8 cost 0.42154693603515625 sec\n",
      "loss 2.331604, train acc 0.095486\n",
      "round 9\n",
      "time to device 0.009114 sec\n",
      "time forward 0.140496 sec\n",
      "loss time 0.001364 sec\n",
      "backward time 0.011116 sec\n",
      "optimizer time 0.021778 sec\n",
      "training time in round 9 cost 0.39854884147644043 sec\n",
      "loss 2.328882, train acc 0.091406\n",
      "round 10\n",
      "time to device 0.008902 sec\n",
      "time forward 0.154544 sec\n",
      "loss time 0.002356 sec\n",
      "backward time 0.011718 sec\n",
      "optimizer time 0.024884 sec\n",
      "training time in round 10 cost 0.4012112617492676 sec\n",
      "loss 2.326820, train acc 0.093040\n",
      "round 11\n",
      "time to device 0.006386 sec\n",
      "time forward 0.168481 sec\n",
      "loss time 0.002020 sec\n",
      "backward time 0.013945 sec\n",
      "optimizer time 0.024047 sec\n",
      "training time in round 11 cost 0.40221309661865234 sec\n",
      "loss 2.337194, train acc 0.095052\n",
      "round 12\n",
      "time to device 0.003688 sec\n",
      "time forward 0.182547 sec\n",
      "loss time 0.001628 sec\n",
      "backward time 0.012182 sec\n",
      "optimizer time 0.022047 sec\n",
      "training time in round 12 cost 0.38936591148376465 sec\n",
      "loss 2.334524, train acc 0.094952\n",
      "round 13\n",
      "time to device 0.006186 sec\n",
      "time forward 0.197158 sec\n",
      "loss time 0.001598 sec\n",
      "backward time 0.011894 sec\n",
      "optimizer time 0.021961 sec\n",
      "training time in round 13 cost 0.40100789070129395 sec\n",
      "loss 2.332117, train acc 0.098214\n",
      "round 14\n",
      "time to device 0.003697 sec\n",
      "time forward 0.210152 sec\n",
      "loss time 0.002213 sec\n",
      "backward time 0.013389 sec\n",
      "optimizer time 0.022042 sec\n",
      "training time in round 14 cost 0.40631866455078125 sec\n",
      "loss 2.330217, train acc 0.099479\n",
      "round 15\n",
      "time to device 0.005197 sec\n",
      "time forward 0.222617 sec\n",
      "loss time 0.001371 sec\n",
      "backward time 0.013927 sec\n",
      "optimizer time 0.032828 sec\n",
      "training time in round 15 cost 0.4465930461883545 sec\n",
      "loss 2.328850, train acc 0.097168\n",
      "round 16\n",
      "time to device 0.009340 sec\n",
      "time forward 0.239454 sec\n",
      "loss time 0.002345 sec\n",
      "backward time 0.010333 sec\n",
      "optimizer time 0.022030 sec\n",
      "training time in round 16 cost 0.4083690643310547 sec\n",
      "loss 2.327318, train acc 0.094669\n",
      "round 17\n",
      "time to device 0.010145 sec\n",
      "time forward 0.257648 sec\n",
      "loss time 0.003259 sec\n",
      "backward time 0.012756 sec\n",
      "optimizer time 0.023243 sec\n",
      "training time in round 17 cost 0.41283392906188965 sec\n",
      "loss 2.325833, train acc 0.095920\n",
      "round 18\n",
      "time to device 0.009047 sec\n",
      "time forward 0.264486 sec\n",
      "loss time 0.000468 sec\n",
      "backward time 0.004248 sec\n",
      "optimizer time 0.012889 sec\n",
      "training time in round 18 cost 0.3669250011444092 sec\n",
      "loss 2.324443, train acc 0.096217\n",
      "round 19\n",
      "time to device 0.010376 sec\n",
      "time forward 0.276774 sec\n",
      "loss time 0.001355 sec\n",
      "backward time 0.017337 sec\n",
      "optimizer time 0.016519 sec\n",
      "training time in round 19 cost 0.4087333679199219 sec\n",
      "loss 2.323297, train acc 0.096484\n",
      "round 20\n",
      "time to device 0.009587 sec\n",
      "time forward 0.292155 sec\n",
      "loss time 0.001275 sec\n",
      "backward time 0.013162 sec\n",
      "optimizer time 0.022156 sec\n",
      "training time in round 20 cost 0.4186570644378662 sec\n",
      "loss 2.322273, train acc 0.097842\n",
      "round 21\n",
      "time to device 0.009127 sec\n",
      "time forward 0.304934 sec\n",
      "loss time 0.002406 sec\n",
      "backward time 0.011884 sec\n",
      "optimizer time 0.023266 sec\n",
      "training time in round 21 cost 0.4085700511932373 sec\n",
      "loss 2.321887, train acc 0.095170\n",
      "round 22\n",
      "time to device 0.009745 sec\n",
      "time forward 0.318122 sec\n",
      "loss time 0.001178 sec\n",
      "backward time 0.010205 sec\n",
      "optimizer time 0.021170 sec\n",
      "training time in round 22 cost 0.41591405868530273 sec\n",
      "loss 2.329416, train acc 0.096807\n",
      "round 23\n",
      "time to device 0.011879 sec\n",
      "time forward 0.325744 sec\n",
      "loss time 0.000735 sec\n",
      "backward time 0.005235 sec\n",
      "optimizer time 0.014556 sec\n",
      "training time in round 23 cost 0.3783841133117676 sec\n",
      "loss 2.328373, train acc 0.095052\n",
      "round 24\n",
      "time to device 0.007439 sec\n",
      "time forward 0.337814 sec\n",
      "loss time 0.002102 sec\n",
      "backward time 0.012797 sec\n",
      "optimizer time 0.024953 sec\n",
      "training time in round 24 cost 0.41154909133911133 sec\n",
      "loss 2.329697, train acc 0.093438\n",
      "round 25\n",
      "time to device 0.012110 sec\n",
      "time forward 0.350046 sec\n",
      "loss time 0.001281 sec\n",
      "backward time 0.011780 sec\n",
      "optimizer time 0.022512 sec\n",
      "training time in round 25 cost 0.40586304664611816 sec\n",
      "loss 2.328786, train acc 0.092548\n",
      "round 26\n",
      "time to device 0.009993 sec\n",
      "time forward 0.367712 sec\n",
      "loss time 0.001462 sec\n",
      "backward time 0.012126 sec\n",
      "optimizer time 0.025540 sec\n",
      "training time in round 26 cost 0.41524600982666016 sec\n",
      "loss 2.335058, train acc 0.090567\n",
      "round 27\n",
      "time to device 0.003360 sec\n",
      "time forward 0.384672 sec\n",
      "loss time 0.001829 sec\n",
      "backward time 0.014912 sec\n",
      "optimizer time 0.014615 sec\n",
      "training time in round 27 cost 0.408951997756958 sec\n",
      "loss 2.335194, train acc 0.091797\n",
      "round 28\n",
      "time to device 0.004264 sec\n",
      "time forward 0.391672 sec\n",
      "loss time 0.000507 sec\n",
      "backward time 0.004649 sec\n",
      "optimizer time 0.012924 sec\n",
      "training time in round 28 cost 0.35425281524658203 sec\n",
      "loss 2.339010, train acc 0.091864\n",
      "round 29\n",
      "time to device 0.004080 sec\n",
      "time forward 0.404713 sec\n",
      "loss time 0.001471 sec\n",
      "backward time 0.017298 sec\n",
      "optimizer time 0.025360 sec\n",
      "training time in round 29 cost 0.4021139144897461 sec\n",
      "loss 2.337715, train acc 0.091927\n",
      "round 30\n",
      "time to device 0.003473 sec\n",
      "time forward 0.419481 sec\n",
      "loss time 0.001250 sec\n",
      "backward time 0.011068 sec\n",
      "optimizer time 0.021218 sec\n",
      "training time in round 30 cost 0.39446592330932617 sec\n",
      "loss 2.337238, train acc 0.092490\n",
      "round 31\n",
      "time to device 0.003887 sec\n",
      "time forward 0.432663 sec\n",
      "loss time 0.001488 sec\n",
      "backward time 0.013574 sec\n",
      "optimizer time 0.024459 sec\n",
      "training time in round 31 cost 0.396090030670166 sec\n",
      "loss 2.336150, train acc 0.093994\n",
      "round 32\n",
      "time to device 0.004416 sec\n",
      "time forward 0.446082 sec\n",
      "loss time 0.003243 sec\n",
      "backward time 0.013349 sec\n",
      "optimizer time 0.025326 sec\n",
      "training time in round 32 cost 0.40811705589294434 sec\n",
      "loss 2.336191, train acc 0.094934\n",
      "round 33\n",
      "time to device 0.003584 sec\n",
      "time forward 0.459356 sec\n",
      "loss time 0.002296 sec\n",
      "backward time 0.010352 sec\n",
      "optimizer time 0.020245 sec\n",
      "training time in round 33 cost 0.395261287689209 sec\n",
      "loss 2.336506, train acc 0.094439\n",
      "round 34\n",
      "time to device 0.003389 sec\n",
      "time forward 0.474340 sec\n",
      "loss time 0.001500 sec\n",
      "backward time 0.013665 sec\n",
      "optimizer time 0.021692 sec\n",
      "training time in round 34 cost 0.3980369567871094 sec\n",
      "loss 2.338391, train acc 0.095089\n",
      "round 35\n",
      "time to device 0.003665 sec\n",
      "time forward 0.489359 sec\n",
      "loss time 0.002503 sec\n",
      "backward time 0.012549 sec\n",
      "optimizer time 0.022270 sec\n",
      "training time in round 35 cost 0.40032386779785156 sec\n",
      "loss 2.337576, train acc 0.095052\n",
      "round 36\n",
      "time to device 0.003638 sec\n",
      "time forward 0.503003 sec\n",
      "loss time 0.002425 sec\n",
      "backward time 0.012916 sec\n",
      "optimizer time 0.025261 sec\n",
      "training time in round 36 cost 0.40869808197021484 sec\n",
      "loss 2.340942, train acc 0.094806\n",
      "round 37\n",
      "time to device 0.003619 sec\n",
      "time forward 0.520191 sec\n",
      "loss time 0.002029 sec\n",
      "backward time 0.016950 sec\n",
      "optimizer time 0.027646 sec\n",
      "training time in round 37 cost 0.41471385955810547 sec\n",
      "loss 2.339996, train acc 0.093956\n",
      "round 38\n",
      "time to device 0.004390 sec\n",
      "time forward 0.535128 sec\n",
      "loss time 0.001605 sec\n",
      "backward time 0.021314 sec\n",
      "optimizer time 0.026896 sec\n",
      "training time in round 38 cost 0.4112699031829834 sec\n",
      "loss 2.339079, train acc 0.094151\n",
      "round 39\n",
      "time to device 0.004396 sec\n",
      "time forward 0.551466 sec\n",
      "loss time 0.002550 sec\n",
      "backward time 0.014578 sec\n",
      "optimizer time 0.023232 sec\n",
      "training time in round 39 cost 0.40969419479370117 sec\n",
      "loss 2.338261, train acc 0.093945\n",
      "round 40\n",
      "time to device 0.003776 sec\n",
      "time forward 0.565459 sec\n",
      "loss time 0.001767 sec\n",
      "backward time 0.013379 sec\n",
      "optimizer time 0.022184 sec\n",
      "training time in round 40 cost 0.4047977924346924 sec\n",
      "loss 2.337613, train acc 0.092988\n",
      "round 41\n",
      "time to device 0.004479 sec\n",
      "time forward 0.582847 sec\n",
      "loss time 0.001632 sec\n",
      "backward time 0.014176 sec\n",
      "optimizer time 0.023205 sec\n",
      "training time in round 41 cost 0.4125368595123291 sec\n",
      "loss 2.336958, train acc 0.094680\n",
      "round 42\n",
      "time to device 0.004175 sec\n",
      "time forward 0.598420 sec\n",
      "loss time 0.001686 sec\n",
      "backward time 0.015571 sec\n",
      "optimizer time 0.023710 sec\n",
      "training time in round 42 cost 0.4076051712036133 sec\n",
      "loss 2.339148, train acc 0.094477\n",
      "round 43\n",
      "time to device 0.005277 sec\n",
      "time forward 0.612401 sec\n",
      "loss time 0.001395 sec\n",
      "backward time 0.012652 sec\n",
      "optimizer time 0.023162 sec\n",
      "training time in round 43 cost 0.3993110656738281 sec\n",
      "loss 2.338260, train acc 0.094638\n",
      "round 44\n",
      "time to device 0.009979 sec\n",
      "time forward 0.621188 sec\n",
      "loss time 0.000667 sec\n",
      "backward time 0.005350 sec\n",
      "optimizer time 0.015470 sec\n",
      "training time in round 44 cost 0.36489105224609375 sec\n",
      "loss 2.337340, train acc 0.094965\n",
      "round 45\n",
      "time to device 0.002694 sec\n",
      "time forward 0.635585 sec\n",
      "loss time 0.001324 sec\n",
      "backward time 0.016494 sec\n",
      "optimizer time 0.022863 sec\n",
      "training time in round 45 cost 0.40132808685302734 sec\n",
      "loss 2.343698, train acc 0.095279\n",
      "round 46\n",
      "time to device 0.008887 sec\n",
      "time forward 0.645746 sec\n",
      "loss time 0.000886 sec\n",
      "backward time 0.011707 sec\n",
      "optimizer time 0.022391 sec\n",
      "training time in round 46 cost 0.4549276828765869 sec\n",
      "loss 2.342903, train acc 0.095080\n",
      "round 47\n",
      "time to device 0.009288 sec\n",
      "time forward 0.659470 sec\n",
      "loss time 0.001125 sec\n",
      "backward time 0.016625 sec\n",
      "optimizer time 0.027214 sec\n",
      "training time in round 47 cost 0.420928955078125 sec\n",
      "loss 2.342090, train acc 0.095052\n",
      "round 48\n",
      "time to device 0.005846 sec\n",
      "time forward 0.668365 sec\n",
      "loss time 0.001327 sec\n",
      "backward time 0.009700 sec\n",
      "optimizer time 0.023005 sec\n",
      "training time in round 48 cost 0.40571117401123047 sec\n",
      "loss 2.341265, train acc 0.095344\n",
      "round 49\n",
      "time to device 0.007071 sec\n",
      "time forward 0.676139 sec\n",
      "loss time 0.000406 sec\n",
      "backward time 0.005188 sec\n",
      "optimizer time 0.010922 sec\n",
      "training time in round 49 cost 0.36196208000183105 sec\n",
      "loss 2.340484, train acc 0.095937\n",
      "round 50\n",
      "time to device 0.010372 sec\n",
      "time forward 0.708459 sec\n",
      "loss time 0.001767 sec\n",
      "backward time 0.018239 sec\n",
      "optimizer time 0.023613 sec\n",
      "training time in round 50 cost 0.6145331859588623 sec\n",
      "loss 2.339793, train acc 0.095588\n",
      "round 51\n",
      "time to device 0.004871 sec\n",
      "time forward 0.723899 sec\n",
      "loss time 0.001297 sec\n",
      "backward time 0.012352 sec\n",
      "optimizer time 0.024148 sec\n",
      "training time in round 51 cost 0.4584178924560547 sec\n",
      "loss 2.339213, train acc 0.095403\n",
      "round 52\n",
      "time to device 0.007986 sec\n",
      "time forward 0.742255 sec\n",
      "loss time 0.001141 sec\n",
      "backward time 0.013391 sec\n",
      "optimizer time 0.027970 sec\n",
      "training time in round 52 cost 0.43099308013916016 sec\n",
      "loss 2.338505, train acc 0.095371\n",
      "round 53\n",
      "time to device 0.007641 sec\n",
      "time forward 0.757398 sec\n",
      "loss time 0.001253 sec\n",
      "backward time 0.011838 sec\n",
      "optimizer time 0.023742 sec\n",
      "training time in round 53 cost 0.40872788429260254 sec\n",
      "loss 2.337815, train acc 0.095486\n",
      "round 54\n",
      "time to device 0.007731 sec\n",
      "time forward 0.764282 sec\n",
      "loss time 0.000489 sec\n",
      "backward time 0.004282 sec\n",
      "optimizer time 0.014299 sec\n",
      "training time in round 54 cost 0.38203907012939453 sec\n",
      "loss 2.337144, train acc 0.096023\n",
      "round 55\n",
      "time to device 0.007118 sec\n",
      "time forward 0.776375 sec\n",
      "loss time 0.001748 sec\n",
      "backward time 0.013969 sec\n",
      "optimizer time 0.024721 sec\n",
      "training time in round 55 cost 0.42333507537841797 sec\n",
      "loss 2.336457, train acc 0.095843\n",
      "round 56\n",
      "time to device 0.005197 sec\n",
      "time forward 0.791039 sec\n",
      "loss time 0.001161 sec\n",
      "backward time 0.011662 sec\n",
      "optimizer time 0.025234 sec\n",
      "training time in round 56 cost 0.4052870273590088 sec\n",
      "loss 2.335898, train acc 0.095943\n",
      "round 57\n",
      "time to device 0.011652 sec\n",
      "time forward 0.802169 sec\n",
      "loss time 0.001750 sec\n",
      "backward time 0.016469 sec\n",
      "optimizer time 0.022908 sec\n",
      "training time in round 57 cost 0.40115928649902344 sec\n",
      "loss 2.335371, train acc 0.095770\n",
      "round 58\n",
      "time to device 0.006874 sec\n",
      "time forward 0.816679 sec\n",
      "loss time 0.001165 sec\n",
      "backward time 0.013409 sec\n",
      "optimizer time 0.035308 sec\n",
      "training time in round 58 cost 0.41111087799072266 sec\n",
      "loss 2.334835, train acc 0.096266\n",
      "round 59\n",
      "time to device 0.007060 sec\n",
      "time forward 0.833380 sec\n",
      "loss time 0.002166 sec\n",
      "backward time 0.012264 sec\n",
      "optimizer time 0.022430 sec\n",
      "training time in round 59 cost 0.4325597286224365 sec\n",
      "loss 2.334570, train acc 0.096354\n",
      "round 60\n",
      "time to device 0.009252 sec\n",
      "time forward 0.843112 sec\n",
      "loss time 0.001090 sec\n",
      "backward time 0.011831 sec\n",
      "optimizer time 0.017514 sec\n",
      "training time in round 60 cost 0.40271806716918945 sec\n",
      "loss 2.334063, train acc 0.096952\n",
      "round 61\n",
      "time to device 0.006857 sec\n",
      "time forward 0.861584 sec\n",
      "loss time 0.001029 sec\n",
      "backward time 0.017270 sec\n",
      "optimizer time 0.027915 sec\n",
      "training time in round 61 cost 0.43406081199645996 sec\n",
      "loss 2.333566, train acc 0.097152\n",
      "round 62\n",
      "time to device 0.008832 sec\n",
      "time forward 0.876476 sec\n",
      "loss time 0.001186 sec\n",
      "backward time 0.007851 sec\n",
      "optimizer time 0.018701 sec\n",
      "training time in round 62 cost 0.43519020080566406 sec\n",
      "loss 2.333070, train acc 0.097222\n",
      "round 63\n",
      "time to device 0.011872 sec\n",
      "time forward 0.891051 sec\n",
      "loss time 0.001257 sec\n",
      "backward time 0.014753 sec\n",
      "optimizer time 0.030644 sec\n",
      "training time in round 63 cost 0.4859273433685303 sec\n",
      "loss 2.332599, train acc 0.097046\n",
      "round 64\n",
      "time to device 0.006740 sec\n",
      "time forward 0.906941 sec\n",
      "loss time 0.002895 sec\n",
      "backward time 0.024520 sec\n",
      "optimizer time 0.017086 sec\n",
      "training time in round 64 cost 0.41313910484313965 sec\n",
      "loss 2.332596, train acc 0.097716\n",
      "round 65\n",
      "time to device 0.009055 sec\n",
      "time forward 0.918555 sec\n",
      "loss time 0.001047 sec\n",
      "backward time 0.014057 sec\n",
      "optimizer time 0.025744 sec\n",
      "training time in round 65 cost 0.39618396759033203 sec\n",
      "loss 2.333242, train acc 0.097775\n",
      "round 66\n",
      "time to device 0.008707 sec\n",
      "time forward 0.932240 sec\n",
      "loss time 0.001086 sec\n",
      "backward time 0.009651 sec\n",
      "optimizer time 0.020635 sec\n",
      "training time in round 66 cost 0.42661190032958984 sec\n",
      "loss 2.333181, train acc 0.097015\n",
      "round 67\n",
      "time to device 0.008421 sec\n",
      "time forward 0.950777 sec\n",
      "loss time 0.001759 sec\n",
      "backward time 0.012691 sec\n",
      "optimizer time 0.022646 sec\n",
      "training time in round 67 cost 0.4087851047515869 sec\n",
      "loss 2.332753, train acc 0.096622\n",
      "round 68\n",
      "time to device 0.007049 sec\n",
      "time forward 0.963578 sec\n",
      "loss time 0.001336 sec\n",
      "backward time 0.012554 sec\n",
      "optimizer time 0.028230 sec\n",
      "training time in round 68 cost 0.4112260341644287 sec\n",
      "loss 2.332486, train acc 0.096467\n",
      "round 69\n",
      "time to device 0.005500 sec\n",
      "time forward 0.972642 sec\n",
      "loss time 0.001214 sec\n",
      "backward time 0.011283 sec\n",
      "optimizer time 0.021112 sec\n",
      "training time in round 69 cost 0.3853299617767334 sec\n",
      "loss 2.332073, train acc 0.096763\n",
      "round 70\n",
      "time to device 0.008354 sec\n",
      "time forward 0.983029 sec\n",
      "loss time 0.001156 sec\n",
      "backward time 0.014740 sec\n",
      "optimizer time 0.026348 sec\n",
      "training time in round 70 cost 0.47606778144836426 sec\n",
      "loss 2.331562, train acc 0.095841\n",
      "round 71\n",
      "time to device 0.008332 sec\n",
      "time forward 0.990631 sec\n",
      "loss time 0.000583 sec\n",
      "backward time 0.004947 sec\n",
      "optimizer time 0.013836 sec\n",
      "training time in round 71 cost 0.5319609642028809 sec\n",
      "loss 2.331182, train acc 0.096029\n",
      "round 72\n",
      "time to device 0.005447 sec\n",
      "time forward 0.997233 sec\n",
      "loss time 0.000430 sec\n",
      "backward time 0.003799 sec\n",
      "optimizer time 0.011588 sec\n",
      "training time in round 72 cost 0.4385099411010742 sec\n",
      "loss 2.330764, train acc 0.096640\n",
      "round 73\n",
      "time to device 0.007440 sec\n",
      "time forward 1.008193 sec\n",
      "loss time 0.000898 sec\n",
      "backward time 0.008017 sec\n",
      "optimizer time 0.020394 sec\n",
      "training time in round 73 cost 0.36846303939819336 sec\n",
      "loss 2.330421, train acc 0.095756\n",
      "round 74\n",
      "time to device 0.005113 sec\n",
      "time forward 1.014947 sec\n",
      "loss time 0.000585 sec\n",
      "backward time 0.004798 sec\n",
      "optimizer time 0.022933 sec\n",
      "training time in round 74 cost 0.37507104873657227 sec\n",
      "loss 2.331780, train acc 0.095729\n",
      "round 75\n",
      "time to device 0.019798 sec\n",
      "time forward 1.021590 sec\n",
      "loss time 0.000729 sec\n",
      "backward time 0.006470 sec\n",
      "optimizer time 0.017404 sec\n",
      "training time in round 75 cost 0.369096040725708 sec\n",
      "loss 2.331383, train acc 0.095498\n",
      "round 76\n",
      "time to device 0.005116 sec\n",
      "time forward 1.031115 sec\n",
      "loss time 0.000446 sec\n",
      "backward time 0.003994 sec\n",
      "optimizer time 0.012374 sec\n",
      "training time in round 76 cost 0.3697779178619385 sec\n",
      "loss 2.330988, train acc 0.095475\n",
      "round 77\n",
      "time to device 0.005812 sec\n",
      "time forward 1.041046 sec\n",
      "loss time 0.000755 sec\n",
      "backward time 0.007181 sec\n",
      "optimizer time 0.019660 sec\n",
      "training time in round 77 cost 0.3713071346282959 sec\n",
      "loss 2.330642, train acc 0.095853\n",
      "round 78\n",
      "time to device 0.007080 sec\n",
      "time forward 1.053032 sec\n",
      "loss time 0.001106 sec\n",
      "backward time 0.010282 sec\n",
      "optimizer time 0.018747 sec\n",
      "training time in round 78 cost 0.3738281726837158 sec\n",
      "loss 2.330840, train acc 0.095827\n",
      "round 79\n",
      "time to device 0.005670 sec\n",
      "time forward 1.059681 sec\n",
      "loss time 0.000847 sec\n",
      "backward time 0.007671 sec\n",
      "optimizer time 0.018672 sec\n",
      "training time in round 79 cost 0.3487851619720459 sec\n",
      "loss 2.330403, train acc 0.095996\n",
      "round 80\n",
      "time to device 0.006749 sec\n",
      "time forward 1.071049 sec\n",
      "loss time 0.000484 sec\n",
      "backward time 0.004223 sec\n",
      "optimizer time 0.018651 sec\n",
      "training time in round 80 cost 0.4002809524536133 sec\n",
      "loss 2.330079, train acc 0.095872\n",
      "round 81\n",
      "time to device 0.008469 sec\n",
      "time forward 1.078422 sec\n",
      "loss time 0.000879 sec\n",
      "backward time 0.008224 sec\n",
      "optimizer time 0.019672 sec\n",
      "training time in round 81 cost 0.3755970001220703 sec\n",
      "loss 2.329696, train acc 0.096704\n",
      "round 82\n",
      "time to device 0.005690 sec\n",
      "time forward 1.087932 sec\n",
      "loss time 0.000711 sec\n",
      "backward time 0.006865 sec\n",
      "optimizer time 0.018686 sec\n",
      "training time in round 82 cost 0.3598330020904541 sec\n",
      "loss 2.329721, train acc 0.096950\n",
      "round 83\n",
      "time to device 0.007977 sec\n",
      "time forward 1.098844 sec\n",
      "loss time 0.002070 sec\n",
      "backward time 0.014160 sec\n",
      "optimizer time 0.017758 sec\n",
      "training time in round 83 cost 0.4093787670135498 sec\n",
      "loss 2.329505, train acc 0.096540\n",
      "round 84\n",
      "time to device 0.007675 sec\n",
      "time forward 1.112241 sec\n",
      "loss time 0.002264 sec\n",
      "backward time 0.027837 sec\n",
      "optimizer time 0.024031 sec\n",
      "training time in round 84 cost 0.48257899284362793 sec\n",
      "loss 2.329189, train acc 0.096691\n",
      "round 85\n",
      "time to device 0.006799 sec\n",
      "time forward 1.125261 sec\n",
      "loss time 0.001484 sec\n",
      "backward time 0.026897 sec\n",
      "optimizer time 0.023741 sec\n",
      "training time in round 85 cost 0.45406603813171387 sec\n",
      "loss 2.328854, train acc 0.096930\n",
      "round 86\n",
      "time to device 0.009709 sec\n",
      "time forward 1.138057 sec\n",
      "loss time 0.001016 sec\n",
      "backward time 0.009725 sec\n",
      "optimizer time 0.050908 sec\n",
      "training time in round 86 cost 0.4345560073852539 sec\n",
      "loss 2.328574, train acc 0.096803\n",
      "round 87\n",
      "time to device 0.009074 sec\n",
      "time forward 1.147863 sec\n",
      "loss time 0.001075 sec\n",
      "backward time 0.010255 sec\n",
      "optimizer time 0.030917 sec\n",
      "training time in round 87 cost 0.4079279899597168 sec\n",
      "loss 2.328243, train acc 0.097212\n",
      "round 88\n",
      "time to device 0.022559 sec\n",
      "time forward 1.160220 sec\n",
      "loss time 0.001122 sec\n",
      "backward time 0.010701 sec\n",
      "optimizer time 0.036071 sec\n",
      "training time in round 88 cost 0.4517860412597656 sec\n",
      "loss 2.327950, train acc 0.097173\n",
      "round 89\n",
      "time to device 0.027324 sec\n",
      "time forward 1.173656 sec\n",
      "loss time 0.001390 sec\n",
      "backward time 0.012335 sec\n",
      "optimizer time 0.025801 sec\n",
      "training time in round 89 cost 0.434751033782959 sec\n",
      "loss 2.327605, train acc 0.097656\n",
      "round 90\n",
      "time to device 0.008059 sec\n",
      "time forward 1.186778 sec\n",
      "loss time 0.001727 sec\n",
      "backward time 0.011543 sec\n",
      "optimizer time 0.033592 sec\n",
      "training time in round 90 cost 0.44089412689208984 sec\n",
      "loss 2.327357, train acc 0.097785\n",
      "round 91\n",
      "time to device 0.006567 sec\n",
      "time forward 1.199145 sec\n",
      "loss time 0.001572 sec\n",
      "backward time 0.011269 sec\n",
      "optimizer time 0.023010 sec\n",
      "training time in round 91 cost 0.40185070037841797 sec\n",
      "loss 2.327112, train acc 0.098166\n",
      "round 92\n",
      "time to device 0.006584 sec\n",
      "time forward 1.209202 sec\n",
      "loss time 0.000904 sec\n",
      "backward time 0.008106 sec\n",
      "optimizer time 0.020471 sec\n",
      "training time in round 92 cost 0.36653804779052734 sec\n",
      "loss 2.326875, train acc 0.098202\n",
      "round 93\n",
      "time to device 0.008177 sec\n",
      "time forward 1.216830 sec\n",
      "loss time 0.002424 sec\n",
      "backward time 0.004081 sec\n",
      "optimizer time 0.010571 sec\n",
      "training time in round 93 cost 0.35275888442993164 sec\n",
      "loss 2.326636, train acc 0.098155\n",
      "round 94\n",
      "time to device 0.006458 sec\n",
      "time forward 1.222092 sec\n",
      "loss time 0.000463 sec\n",
      "backward time 0.005700 sec\n",
      "optimizer time 0.011896 sec\n",
      "training time in round 94 cost 0.35356903076171875 sec\n",
      "loss 2.326463, train acc 0.097780\n",
      "round 95\n",
      "time to device 0.007056 sec\n",
      "time forward 1.230937 sec\n",
      "loss time 0.000892 sec\n",
      "backward time 0.008132 sec\n",
      "optimizer time 0.018877 sec\n",
      "training time in round 95 cost 0.40174198150634766 sec\n",
      "loss 2.326423, train acc 0.097738\n",
      "round 96\n",
      "time to device 0.008667 sec\n",
      "time forward 1.244765 sec\n",
      "loss time 0.002029 sec\n",
      "backward time 0.020354 sec\n",
      "optimizer time 0.024383 sec\n",
      "training time in round 96 cost 0.41008806228637695 sec\n",
      "loss 2.326187, train acc 0.097938\n",
      "round 97\n",
      "time to device 0.008584 sec\n",
      "time forward 1.258686 sec\n",
      "loss time 0.001980 sec\n",
      "backward time 0.014209 sec\n",
      "optimizer time 0.025136 sec\n",
      "training time in round 97 cost 0.41118407249450684 sec\n",
      "loss 2.325926, train acc 0.098055\n",
      "round 98\n",
      "time to device 0.008748 sec\n",
      "time forward 1.274333 sec\n",
      "loss time 0.001522 sec\n",
      "backward time 0.015494 sec\n",
      "optimizer time 0.023515 sec\n",
      "training time in round 98 cost 0.40327978134155273 sec\n",
      "loss 2.325613, train acc 0.098327\n",
      "round 99\n",
      "time to device 0.008458 sec\n",
      "time forward 1.284242 sec\n",
      "loss time 0.000585 sec\n",
      "backward time 0.005322 sec\n",
      "optimizer time 0.014463 sec\n",
      "training time in round 99 cost 0.3877577781677246 sec\n",
      "loss 2.325375, train acc 0.098672\n",
      "round 100\n",
      "time to device 0.006966 sec\n",
      "time forward 1.297638 sec\n",
      "loss time 0.001758 sec\n",
      "backward time 0.014376 sec\n",
      "optimizer time 0.035080 sec\n",
      "training time in round 100 cost 0.4055640697479248 sec\n",
      "loss 2.325184, train acc 0.098468\n",
      "round 101\n",
      "time to device 0.007969 sec\n",
      "time forward 1.311750 sec\n",
      "loss time 0.002062 sec\n",
      "backward time 0.013498 sec\n",
      "optimizer time 0.024189 sec\n",
      "training time in round 101 cost 0.40024900436401367 sec\n",
      "loss 2.324991, train acc 0.098269\n",
      "round 102\n",
      "time to device 0.007859 sec\n",
      "time forward 1.324702 sec\n",
      "loss time 0.001810 sec\n",
      "backward time 0.011844 sec\n",
      "optimizer time 0.025842 sec\n",
      "training time in round 102 cost 0.3934769630432129 sec\n",
      "loss 2.324791, train acc 0.098529\n",
      "round 103\n",
      "time to device 0.006293 sec\n",
      "time forward 1.344794 sec\n",
      "loss time 0.001854 sec\n",
      "backward time 0.013251 sec\n",
      "optimizer time 0.020278 sec\n",
      "training time in round 103 cost 0.4092731475830078 sec\n",
      "loss 2.324642, train acc 0.098708\n",
      "round 104\n",
      "time to device 0.007676 sec\n",
      "time forward 1.356384 sec\n",
      "loss time 0.001749 sec\n",
      "backward time 0.011439 sec\n",
      "optimizer time 0.029502 sec\n",
      "training time in round 104 cost 0.3926999568939209 sec\n",
      "loss 2.324423, train acc 0.098958\n",
      "round 105\n",
      "time to device 0.007826 sec\n",
      "time forward 1.369238 sec\n",
      "loss time 0.001348 sec\n",
      "backward time 0.016754 sec\n",
      "optimizer time 0.027957 sec\n",
      "training time in round 105 cost 0.4072098731994629 sec\n",
      "loss 2.324180, train acc 0.099278\n",
      "round 106\n",
      "time to device 0.004095 sec\n",
      "time forward 1.378830 sec\n",
      "loss time 0.001082 sec\n",
      "backward time 0.010742 sec\n",
      "optimizer time 0.021635 sec\n",
      "training time in round 106 cost 0.4020400047302246 sec\n",
      "loss 2.323957, train acc 0.099518\n",
      "round 107\n",
      "time to device 0.007195 sec\n",
      "time forward 1.390013 sec\n",
      "loss time 0.001511 sec\n",
      "backward time 0.012856 sec\n",
      "optimizer time 0.027033 sec\n",
      "training time in round 107 cost 0.41370701789855957 sec\n",
      "loss 2.323745, train acc 0.099609\n",
      "round 108\n",
      "time to device 0.010337 sec\n",
      "time forward 1.409655 sec\n",
      "loss time 0.000559 sec\n",
      "backward time 0.007857 sec\n",
      "optimizer time 0.023409 sec\n",
      "training time in round 108 cost 0.40697503089904785 sec\n",
      "loss 2.323592, train acc 0.099412\n",
      "round 109\n",
      "time to device 0.006945 sec\n",
      "time forward 1.422250 sec\n",
      "loss time 0.001654 sec\n",
      "backward time 0.012395 sec\n",
      "optimizer time 0.025049 sec\n",
      "training time in round 109 cost 0.41768908500671387 sec\n",
      "loss 2.323475, train acc 0.099361\n",
      "round 110\n",
      "time to device 0.007180 sec\n",
      "time forward 1.435957 sec\n",
      "loss time 0.001047 sec\n",
      "backward time 0.017831 sec\n",
      "optimizer time 0.024772 sec\n",
      "training time in round 110 cost 0.4035298824310303 sec\n",
      "loss 2.323298, train acc 0.099451\n",
      "round 111\n",
      "time to device 0.007612 sec\n",
      "time forward 1.450287 sec\n",
      "loss time 0.002024 sec\n",
      "backward time 0.012988 sec\n",
      "optimizer time 0.024884 sec\n",
      "training time in round 111 cost 0.41820502281188965 sec\n",
      "loss 2.323153, train acc 0.099609\n",
      "round 112\n",
      "time to device 0.006581 sec\n",
      "time forward 1.463546 sec\n",
      "loss time 0.001988 sec\n",
      "backward time 0.015223 sec\n",
      "optimizer time 0.026775 sec\n",
      "training time in round 112 cost 0.45287132263183594 sec\n",
      "loss 2.322997, train acc 0.099558\n",
      "round 113\n",
      "time to device 0.006828 sec\n",
      "time forward 1.477382 sec\n",
      "loss time 0.001700 sec\n",
      "backward time 0.019992 sec\n",
      "optimizer time 0.023843 sec\n",
      "training time in round 113 cost 0.4026458263397217 sec\n",
      "loss 2.322893, train acc 0.099027\n",
      "round 114\n",
      "time to device 0.008280 sec\n",
      "time forward 1.491485 sec\n",
      "loss time 0.002213 sec\n",
      "backward time 0.017013 sec\n",
      "optimizer time 0.027157 sec\n",
      "training time in round 114 cost 0.41130590438842773 sec\n",
      "loss 2.322693, train acc 0.099321\n",
      "round 115\n",
      "time to device 0.007232 sec\n",
      "time forward 1.504865 sec\n",
      "loss time 0.002310 sec\n",
      "backward time 0.022084 sec\n",
      "optimizer time 0.020450 sec\n",
      "training time in round 115 cost 0.4032256603240967 sec\n",
      "loss 2.322524, train acc 0.099273\n",
      "round 116\n",
      "time to device 0.008058 sec\n",
      "time forward 1.512702 sec\n",
      "loss time 0.000518 sec\n",
      "backward time 0.004635 sec\n",
      "optimizer time 0.012624 sec\n",
      "training time in round 116 cost 0.3678860664367676 sec\n",
      "loss 2.322356, train acc 0.099493\n",
      "round 117\n",
      "time to device 0.008239 sec\n",
      "time forward 1.526400 sec\n",
      "loss time 0.002033 sec\n",
      "backward time 0.014926 sec\n",
      "optimizer time 0.026478 sec\n",
      "training time in round 117 cost 0.41906094551086426 sec\n",
      "loss 2.322177, train acc 0.099576\n",
      "round 118\n",
      "time to device 0.007279 sec\n",
      "time forward 1.536049 sec\n",
      "loss time 0.000656 sec\n",
      "backward time 0.010835 sec\n",
      "optimizer time 0.016074 sec\n",
      "training time in round 118 cost 0.3835592269897461 sec\n",
      "loss 2.322008, train acc 0.099593\n",
      "round 119\n",
      "time to device 0.009565 sec\n",
      "time forward 1.555656 sec\n",
      "loss time 0.002445 sec\n",
      "backward time 0.007728 sec\n",
      "optimizer time 0.024243 sec\n",
      "training time in round 119 cost 0.45911097526550293 sec\n",
      "loss 2.321789, train acc 0.099805\n",
      "round 120\n",
      "time to device 0.010444 sec\n",
      "time forward 1.569674 sec\n",
      "loss time 0.001273 sec\n",
      "backward time 0.015240 sec\n",
      "optimizer time 0.028692 sec\n",
      "training time in round 120 cost 0.4360501766204834 sec\n",
      "loss 2.321562, train acc 0.099755\n",
      "round 121\n",
      "time to device 0.007678 sec\n",
      "time forward 1.583991 sec\n",
      "loss time 0.002441 sec\n",
      "backward time 0.012481 sec\n",
      "optimizer time 0.021887 sec\n",
      "training time in round 121 cost 0.42014217376708984 sec\n",
      "loss 2.321414, train acc 0.099769\n",
      "round 122\n",
      "time to device 0.007683 sec\n",
      "time forward 1.595292 sec\n",
      "loss time 0.003026 sec\n",
      "backward time 0.018611 sec\n",
      "optimizer time 0.025848 sec\n",
      "training time in round 122 cost 0.42005395889282227 sec\n",
      "loss 2.321122, train acc 0.100229\n",
      "round 123\n",
      "time to device 0.006729 sec\n",
      "time forward 1.609424 sec\n",
      "loss time 0.002291 sec\n",
      "backward time 0.013078 sec\n",
      "optimizer time 0.020102 sec\n",
      "training time in round 123 cost 0.41974520683288574 sec\n",
      "loss 2.320855, train acc 0.100428\n",
      "round 124\n",
      "time to device 0.008362 sec\n",
      "time forward 1.623883 sec\n",
      "loss time 0.001719 sec\n",
      "backward time 0.013243 sec\n",
      "optimizer time 0.023387 sec\n",
      "training time in round 124 cost 0.471362829208374 sec\n",
      "loss 2.320741, train acc 0.100062\n",
      "round 125\n",
      "time to device 0.007880 sec\n",
      "time forward 1.635811 sec\n",
      "loss time 0.004041 sec\n",
      "backward time 0.014056 sec\n",
      "optimizer time 0.030366 sec\n",
      "training time in round 125 cost 0.40178799629211426 sec\n",
      "loss 2.320575, train acc 0.100260\n",
      "round 126\n",
      "time to device 0.006303 sec\n",
      "time forward 1.647893 sec\n",
      "loss time 0.001495 sec\n",
      "backward time 0.015269 sec\n",
      "optimizer time 0.024901 sec\n",
      "training time in round 126 cost 0.39734911918640137 sec\n",
      "loss 2.320399, train acc 0.100701\n",
      "round 127\n",
      "time to device 0.008584 sec\n",
      "time forward 1.660988 sec\n",
      "loss time 0.001598 sec\n",
      "backward time 0.012526 sec\n",
      "optimizer time 0.028173 sec\n",
      "training time in round 127 cost 0.4042990207672119 sec\n",
      "loss 2.320398, train acc 0.100525\n",
      "round 128\n",
      "time to device 0.007359 sec\n",
      "time forward 1.678261 sec\n",
      "loss time 0.001603 sec\n",
      "backward time 0.017784 sec\n",
      "optimizer time 0.025739 sec\n",
      "training time in round 128 cost 0.4234650135040283 sec\n",
      "loss 2.320268, train acc 0.100412\n",
      "round 129\n",
      "time to device 0.007061 sec\n",
      "time forward 1.690558 sec\n",
      "loss time 0.000964 sec\n",
      "backward time 0.011532 sec\n",
      "optimizer time 0.026427 sec\n",
      "training time in round 129 cost 0.3853881359100342 sec\n",
      "loss 2.320146, train acc 0.100300\n",
      "round 130\n",
      "time to device 0.010110 sec\n",
      "time forward 1.701497 sec\n",
      "loss time 0.001211 sec\n",
      "backward time 0.015523 sec\n",
      "optimizer time 0.027266 sec\n",
      "training time in round 130 cost 0.38941407203674316 sec\n",
      "loss 2.319996, train acc 0.100489\n",
      "round 131\n",
      "time to device 0.006696 sec\n",
      "time forward 1.715779 sec\n",
      "loss time 0.002064 sec\n",
      "backward time 0.015338 sec\n",
      "optimizer time 0.025376 sec\n",
      "training time in round 131 cost 0.4041719436645508 sec\n",
      "loss 2.319877, train acc 0.100497\n",
      "round 132\n",
      "time to device 0.003364 sec\n",
      "time forward 1.728647 sec\n",
      "loss time 0.001507 sec\n",
      "backward time 0.012394 sec\n",
      "optimizer time 0.022814 sec\n",
      "training time in round 132 cost 0.3878798484802246 sec\n",
      "loss 2.319762, train acc 0.100388\n",
      "round 133\n",
      "time to device 0.002543 sec\n",
      "time forward 1.744110 sec\n",
      "loss time 0.001198 sec\n",
      "backward time 0.015139 sec\n",
      "optimizer time 0.023799 sec\n",
      "training time in round 133 cost 0.4047410488128662 sec\n",
      "loss 2.319763, train acc 0.099872\n",
      "round 134\n",
      "time to device 0.006246 sec\n",
      "time forward 1.758475 sec\n",
      "loss time 0.001336 sec\n",
      "backward time 0.012652 sec\n",
      "optimizer time 0.028493 sec\n",
      "training time in round 134 cost 0.41144585609436035 sec\n",
      "loss 2.319661, train acc 0.099769\n",
      "round 135\n",
      "time to device 0.012469 sec\n",
      "time forward 1.767964 sec\n",
      "loss time 0.000438 sec\n",
      "backward time 0.003819 sec\n",
      "optimizer time 0.014947 sec\n",
      "training time in round 135 cost 0.5215158462524414 sec\n",
      "loss 2.319531, train acc 0.099782\n",
      "round 136\n",
      "time to device 0.004746 sec\n",
      "time forward 1.775707 sec\n",
      "loss time 0.000974 sec\n",
      "backward time 0.006263 sec\n",
      "optimizer time 0.019590 sec\n",
      "training time in round 136 cost 0.410524845123291 sec\n",
      "loss 2.319425, train acc 0.099624\n",
      "round 137\n",
      "time to device 0.008709 sec\n",
      "time forward 1.780294 sec\n",
      "loss time 0.000544 sec\n",
      "backward time 0.005889 sec\n",
      "optimizer time 0.017145 sec\n",
      "training time in round 137 cost 0.3447422981262207 sec\n",
      "loss 2.320896, train acc 0.099808\n",
      "round 138\n",
      "time to device 0.006936 sec\n",
      "time forward 1.799129 sec\n",
      "loss time 0.000898 sec\n",
      "backward time 0.022373 sec\n",
      "optimizer time 0.045490 sec\n",
      "training time in round 138 cost 0.6471281051635742 sec\n",
      "loss 2.320753, train acc 0.099820\n",
      "round 139\n",
      "time to device 0.006770 sec\n",
      "time forward 1.806453 sec\n",
      "loss time 0.000543 sec\n",
      "backward time 0.003909 sec\n",
      "optimizer time 0.018193 sec\n",
      "training time in round 139 cost 0.43798398971557617 sec\n",
      "loss 2.320527, train acc 0.099721\n",
      "round 140\n",
      "time to device 0.008290 sec\n",
      "time forward 1.811571 sec\n",
      "loss time 0.000655 sec\n",
      "backward time 0.005329 sec\n",
      "optimizer time 0.015570 sec\n",
      "training time in round 140 cost 0.3531360626220703 sec\n",
      "loss 2.321008, train acc 0.099568\n",
      "round 141\n",
      "time to device 0.006989 sec\n",
      "time forward 1.816886 sec\n",
      "loss time 0.000510 sec\n",
      "backward time 0.005036 sec\n",
      "optimizer time 0.014980 sec\n",
      "training time in round 141 cost 0.35719919204711914 sec\n",
      "loss 2.320815, train acc 0.099802\n",
      "round 142\n",
      "time to device 0.006404 sec\n",
      "time forward 1.826760 sec\n",
      "loss time 0.000635 sec\n",
      "backward time 0.006096 sec\n",
      "optimizer time 0.018416 sec\n",
      "training time in round 142 cost 0.35775113105773926 sec\n",
      "loss 2.320733, train acc 0.099650\n",
      "round 143\n",
      "time to device 0.008601 sec\n",
      "time forward 1.833134 sec\n",
      "loss time 0.000875 sec\n",
      "backward time 0.008109 sec\n",
      "optimizer time 0.019231 sec\n",
      "training time in round 143 cost 0.3676490783691406 sec\n",
      "loss 2.320611, train acc 0.099772\n",
      "round 144\n",
      "time to device 0.006901 sec\n",
      "time forward 1.840665 sec\n",
      "loss time 0.000934 sec\n",
      "backward time 0.008201 sec\n",
      "optimizer time 0.019415 sec\n",
      "training time in round 144 cost 0.3710598945617676 sec\n",
      "loss 2.320533, train acc 0.099569\n",
      "round 145\n",
      "time to device 0.007142 sec\n",
      "time forward 1.851485 sec\n",
      "loss time 0.000858 sec\n",
      "backward time 0.008519 sec\n",
      "optimizer time 0.020024 sec\n",
      "training time in round 145 cost 0.38648104667663574 sec\n",
      "loss 2.320417, train acc 0.099476\n",
      "round 146\n",
      "time to device 0.006567 sec\n",
      "time forward 1.859770 sec\n",
      "loss time 0.000869 sec\n",
      "backward time 0.008220 sec\n",
      "optimizer time 0.019648 sec\n",
      "training time in round 146 cost 0.37706613540649414 sec\n",
      "loss 2.320302, train acc 0.099809\n",
      "round 147\n",
      "time to device 0.006651 sec\n",
      "time forward 1.869025 sec\n",
      "loss time 0.000850 sec\n",
      "backward time 0.008062 sec\n",
      "optimizer time 0.019449 sec\n",
      "training time in round 147 cost 0.38222432136535645 sec\n",
      "loss 2.320177, train acc 0.099926\n",
      "round 148\n",
      "time to device 0.007150 sec\n",
      "time forward 1.880380 sec\n",
      "loss time 0.001254 sec\n",
      "backward time 0.008413 sec\n",
      "optimizer time 0.020835 sec\n",
      "training time in round 148 cost 0.3759469985961914 sec\n",
      "loss 2.320071, train acc 0.099937\n",
      "round 149\n",
      "time to device 0.006840 sec\n",
      "time forward 1.888482 sec\n",
      "loss time 0.001170 sec\n",
      "backward time 0.008009 sec\n",
      "optimizer time 0.021377 sec\n",
      "training time in round 149 cost 0.3679342269897461 sec\n",
      "loss 2.319977, train acc 0.100000\n",
      "round 150\n",
      "time to device 0.007568 sec\n",
      "time forward 1.899623 sec\n",
      "loss time 0.000543 sec\n",
      "backward time 0.005508 sec\n",
      "optimizer time 0.013642 sec\n",
      "training time in round 150 cost 0.35861992835998535 sec\n",
      "loss 2.319868, train acc 0.099959\n",
      "round 151\n",
      "time to device 0.006025 sec\n",
      "time forward 1.904758 sec\n",
      "loss time 0.000653 sec\n",
      "backward time 0.006050 sec\n",
      "optimizer time 0.016021 sec\n",
      "training time in round 151 cost 0.34979820251464844 sec\n",
      "loss 2.319752, train acc 0.099764\n",
      "round 152\n",
      "time to device 0.005576 sec\n",
      "time forward 1.909575 sec\n",
      "loss time 0.000456 sec\n",
      "backward time 0.024297 sec\n",
      "optimizer time 0.018308 sec\n",
      "training time in round 152 cost 0.3704228401184082 sec\n",
      "loss 2.319647, train acc 0.099980\n",
      "round 153\n",
      "time to device 0.005308 sec\n",
      "time forward 1.915915 sec\n",
      "loss time 0.000443 sec\n",
      "backward time 0.004240 sec\n",
      "optimizer time 0.016355 sec\n",
      "training time in round 153 cost 0.38837695121765137 sec\n",
      "loss 2.319564, train acc 0.099888\n",
      "round 154\n",
      "time to device 0.006656 sec\n",
      "time forward 1.925192 sec\n",
      "loss time 0.001105 sec\n",
      "backward time 0.009810 sec\n",
      "optimizer time 0.019328 sec\n",
      "training time in round 154 cost 0.36401891708374023 sec\n",
      "loss 2.319402, train acc 0.100050\n",
      "round 155\n",
      "time to device 0.006760 sec\n",
      "time forward 1.934999 sec\n",
      "loss time 0.001073 sec\n",
      "backward time 0.008209 sec\n",
      "optimizer time 0.019746 sec\n",
      "training time in round 155 cost 0.36332201957702637 sec\n",
      "loss 2.319316, train acc 0.099810\n",
      "round 156\n",
      "time to device 0.006969 sec\n",
      "time forward 1.944689 sec\n",
      "loss time 0.000859 sec\n",
      "backward time 0.011903 sec\n",
      "optimizer time 0.019094 sec\n",
      "training time in round 156 cost 0.3882458209991455 sec\n",
      "loss 2.319205, train acc 0.099871\n",
      "round 157\n",
      "time to device 0.006696 sec\n",
      "time forward 1.951414 sec\n",
      "loss time 0.000621 sec\n",
      "backward time 0.005672 sec\n",
      "optimizer time 0.015169 sec\n",
      "training time in round 157 cost 0.3803598880767822 sec\n",
      "loss 2.319154, train acc 0.099733\n",
      "round 158\n",
      "time to device 0.007140 sec\n",
      "time forward 1.959461 sec\n",
      "loss time 0.001032 sec\n",
      "backward time 0.008289 sec\n",
      "optimizer time 0.020131 sec\n",
      "training time in round 158 cost 0.42168498039245605 sec\n",
      "loss 2.319625, train acc 0.099695\n",
      "round 159\n",
      "time to device 0.006722 sec\n",
      "time forward 1.967777 sec\n",
      "loss time 0.001065 sec\n",
      "backward time 0.008349 sec\n",
      "optimizer time 0.020152 sec\n",
      "training time in round 159 cost 0.3578639030456543 sec\n",
      "loss 2.319519, train acc 0.099658\n",
      "round 160\n",
      "time to device 0.006475 sec\n",
      "time forward 1.973399 sec\n",
      "loss time 0.000628 sec\n",
      "backward time 0.003546 sec\n",
      "optimizer time 0.015140 sec\n",
      "training time in round 160 cost 0.33760499954223633 sec\n",
      "loss 2.319386, train acc 0.100010\n",
      "round 161\n",
      "time to device 0.016573 sec\n",
      "time forward 1.983549 sec\n",
      "loss time 0.000648 sec\n",
      "backward time 0.003985 sec\n",
      "optimizer time 0.015164 sec\n",
      "training time in round 161 cost 0.38486480712890625 sec\n",
      "loss 2.319279, train acc 0.100164\n",
      "round 162\n",
      "time to device 0.005293 sec\n",
      "time forward 1.992747 sec\n",
      "loss time 0.000439 sec\n",
      "backward time 0.003843 sec\n",
      "optimizer time 0.012091 sec\n",
      "training time in round 162 cost 0.37531185150146484 sec\n",
      "loss 2.319213, train acc 0.100125\n",
      "round 163\n",
      "time to device 0.006826 sec\n",
      "time forward 2.000993 sec\n",
      "loss time 0.000822 sec\n",
      "backward time 0.007159 sec\n",
      "optimizer time 0.020369 sec\n",
      "training time in round 163 cost 0.3872261047363281 sec\n",
      "loss 2.319133, train acc 0.099943\n",
      "round 164\n",
      "time to device 0.009368 sec\n",
      "time forward 2.021384 sec\n",
      "loss time 0.002064 sec\n",
      "backward time 0.014306 sec\n",
      "optimizer time 0.026636 sec\n",
      "training time in round 164 cost 0.42068004608154297 sec\n",
      "loss 2.319054, train acc 0.099811\n",
      "round 165\n",
      "time to device 0.008201 sec\n",
      "time forward 2.035733 sec\n",
      "loss time 0.001602 sec\n",
      "backward time 0.012530 sec\n",
      "optimizer time 0.025171 sec\n",
      "training time in round 165 cost 0.4167821407318115 sec\n",
      "loss 2.318959, train acc 0.099586\n",
      "round 166\n",
      "time to device 0.011609 sec\n",
      "time forward 2.048190 sec\n",
      "loss time 0.001382 sec\n",
      "backward time 0.019178 sec\n",
      "optimizer time 0.022396 sec\n",
      "training time in round 166 cost 0.39920878410339355 sec\n",
      "loss 2.318854, train acc 0.099457\n",
      "round 167\n",
      "time to device 0.011773 sec\n",
      "time forward 2.063005 sec\n",
      "loss time 0.001629 sec\n",
      "backward time 0.013982 sec\n",
      "optimizer time 0.024148 sec\n",
      "training time in round 167 cost 0.41066694259643555 sec\n",
      "loss 2.318755, train acc 0.099377\n",
      "round 168\n",
      "time to device 0.009368 sec\n",
      "time forward 2.069653 sec\n",
      "loss time 0.000574 sec\n",
      "backward time 0.005015 sec\n",
      "optimizer time 0.013458 sec\n",
      "training time in round 168 cost 0.37619614601135254 sec\n",
      "loss 2.318679, train acc 0.099112\n",
      "round 169\n",
      "time to device 0.010488 sec\n",
      "time forward 2.083025 sec\n",
      "loss time 0.002100 sec\n",
      "backward time 0.014112 sec\n",
      "optimizer time 0.027592 sec\n",
      "training time in round 169 cost 0.41485071182250977 sec\n",
      "loss 2.318579, train acc 0.099449\n",
      "round 170\n",
      "time to device 0.007293 sec\n",
      "time forward 2.095889 sec\n",
      "loss time 0.001799 sec\n",
      "backward time 0.011679 sec\n",
      "optimizer time 0.023253 sec\n",
      "training time in round 170 cost 0.3914649486541748 sec\n",
      "loss 2.318486, train acc 0.099461\n",
      "round 171\n",
      "time to device 0.009857 sec\n",
      "time forward 2.100866 sec\n",
      "loss time 0.000446 sec\n",
      "backward time 0.005120 sec\n",
      "optimizer time 0.011949 sec\n",
      "training time in round 171 cost 0.3408231735229492 sec\n",
      "loss 2.318390, train acc 0.099337\n",
      "round 172\n",
      "time to device 0.008856 sec\n",
      "time forward 2.114082 sec\n",
      "loss time 0.002066 sec\n",
      "backward time 0.011778 sec\n",
      "optimizer time 0.028329 sec\n",
      "training time in round 172 cost 0.39897966384887695 sec\n",
      "loss 2.318327, train acc 0.099350\n",
      "round 173\n",
      "time to device 0.008578 sec\n",
      "time forward 2.128015 sec\n",
      "loss time 0.001585 sec\n",
      "backward time 0.018900 sec\n",
      "optimizer time 0.023858 sec\n",
      "training time in round 173 cost 0.4323239326477051 sec\n",
      "loss 2.318232, train acc 0.099318\n",
      "round 174\n",
      "time to device 0.004568 sec\n",
      "time forward 2.141069 sec\n",
      "loss time 0.001975 sec\n",
      "backward time 0.012000 sec\n",
      "optimizer time 0.023664 sec\n",
      "training time in round 174 cost 0.3988339900970459 sec\n",
      "loss 2.318166, train acc 0.099554\n",
      "round 175\n",
      "time to device 0.003663 sec\n",
      "time forward 2.156003 sec\n",
      "loss time 0.002039 sec\n",
      "backward time 0.015071 sec\n",
      "optimizer time 0.025282 sec\n",
      "training time in round 175 cost 0.4134981632232666 sec\n",
      "loss 2.318065, train acc 0.099654\n",
      "round 176\n",
      "time to device 0.003857 sec\n",
      "time forward 2.168334 sec\n",
      "loss time 0.001880 sec\n",
      "backward time 0.015506 sec\n",
      "optimizer time 0.027539 sec\n",
      "training time in round 176 cost 0.39841413497924805 sec\n",
      "loss 2.317986, train acc 0.099444\n",
      "round 177\n",
      "time to device 0.004335 sec\n",
      "time forward 2.181882 sec\n",
      "loss time 0.001939 sec\n",
      "backward time 0.017784 sec\n",
      "optimizer time 0.022300 sec\n",
      "training time in round 177 cost 0.4083521366119385 sec\n",
      "loss 2.317914, train acc 0.099192\n",
      "round 178\n",
      "time to device 0.003399 sec\n",
      "time forward 2.195902 sec\n",
      "loss time 0.001201 sec\n",
      "backward time 0.015833 sec\n",
      "optimizer time 0.029009 sec\n",
      "training time in round 178 cost 0.4185450077056885 sec\n",
      "loss 2.317852, train acc 0.099118\n",
      "round 179\n",
      "time to device 0.004111 sec\n",
      "time forward 2.209625 sec\n",
      "loss time 0.001542 sec\n",
      "backward time 0.012069 sec\n",
      "optimizer time 0.022781 sec\n",
      "training time in round 179 cost 0.4000999927520752 sec\n",
      "loss 2.317775, train acc 0.099045\n",
      "round 180\n",
      "time to device 0.004058 sec\n",
      "time forward 2.224447 sec\n",
      "loss time 0.001906 sec\n",
      "backward time 0.016152 sec\n",
      "optimizer time 0.024029 sec\n",
      "training time in round 180 cost 0.41302990913391113 sec\n",
      "loss 2.317701, train acc 0.099189\n",
      "round 181\n",
      "time to device 0.004351 sec\n",
      "time forward 2.238488 sec\n",
      "loss time 0.001876 sec\n",
      "backward time 0.025964 sec\n",
      "optimizer time 0.034816 sec\n",
      "training time in round 181 cost 0.44727396965026855 sec\n",
      "loss 2.317621, train acc 0.099116\n",
      "round 182\n",
      "time to device 0.010074 sec\n",
      "time forward 2.252688 sec\n",
      "loss time 0.001400 sec\n",
      "backward time 0.012974 sec\n",
      "optimizer time 0.026420 sec\n",
      "training time in round 182 cost 0.39702725410461426 sec\n",
      "loss 2.318116, train acc 0.099001\n",
      "round 183\n",
      "time to device 0.008639 sec\n",
      "time forward 2.265954 sec\n",
      "loss time 0.001870 sec\n",
      "backward time 0.013117 sec\n",
      "optimizer time 0.024045 sec\n",
      "training time in round 183 cost 0.40078067779541016 sec\n",
      "loss 2.318030, train acc 0.099015\n",
      "round 184\n",
      "time to device 0.007224 sec\n",
      "time forward 2.278374 sec\n",
      "loss time 0.001488 sec\n",
      "backward time 0.012103 sec\n",
      "optimizer time 0.024367 sec\n",
      "training time in round 184 cost 0.39917588233947754 sec\n",
      "loss 2.317957, train acc 0.098944\n",
      "round 185\n",
      "time to device 0.007988 sec\n",
      "time forward 2.291753 sec\n",
      "loss time 0.001317 sec\n",
      "backward time 0.016240 sec\n",
      "optimizer time 0.026807 sec\n",
      "training time in round 185 cost 0.4027419090270996 sec\n",
      "loss 2.317879, train acc 0.098916\n",
      "round 186\n",
      "time to device 0.009227 sec\n",
      "time forward 2.305687 sec\n",
      "loss time 0.001516 sec\n",
      "backward time 0.012826 sec\n",
      "optimizer time 0.023664 sec\n",
      "training time in round 186 cost 0.39968204498291016 sec\n",
      "loss 2.317798, train acc 0.099265\n",
      "round 187\n",
      "time to device 0.009314 sec\n",
      "time forward 2.320747 sec\n",
      "loss time 0.001273 sec\n",
      "backward time 0.015016 sec\n",
      "optimizer time 0.026311 sec\n",
      "training time in round 187 cost 0.40607166290283203 sec\n",
      "loss 2.317704, train acc 0.099318\n",
      "round 188\n",
      "time to device 0.008348 sec\n",
      "time forward 2.327897 sec\n",
      "loss time 0.000630 sec\n",
      "backward time 0.005598 sec\n",
      "optimizer time 0.015254 sec\n",
      "training time in round 188 cost 0.35808730125427246 sec\n",
      "loss 2.317645, train acc 0.099165\n",
      "round 189\n",
      "time to device 0.008005 sec\n",
      "time forward 2.342183 sec\n",
      "loss time 0.001461 sec\n",
      "backward time 0.013929 sec\n",
      "optimizer time 0.023511 sec\n",
      "training time in round 189 cost 0.399029016494751 sec\n",
      "loss 2.317555, train acc 0.099219\n",
      "round 190\n",
      "time to device 0.009178 sec\n",
      "time forward 2.355850 sec\n",
      "loss time 0.001219 sec\n",
      "backward time 0.013314 sec\n",
      "optimizer time 0.025384 sec\n",
      "training time in round 190 cost 0.40569591522216797 sec\n",
      "loss 2.317478, train acc 0.099272\n",
      "round 191\n",
      "time to device 0.010553 sec\n",
      "time forward 2.371101 sec\n",
      "loss time 0.001987 sec\n",
      "backward time 0.012952 sec\n",
      "optimizer time 0.024506 sec\n",
      "training time in round 191 cost 0.4087212085723877 sec\n",
      "loss 2.317395, train acc 0.099447\n",
      "round 192\n",
      "time to device 0.009945 sec\n",
      "time forward 2.385523 sec\n",
      "loss time 0.001840 sec\n",
      "backward time 0.014067 sec\n",
      "optimizer time 0.024944 sec\n",
      "training time in round 192 cost 0.40663814544677734 sec\n",
      "loss 2.317564, train acc 0.099619\n",
      "round 193\n",
      "time to device 0.003907 sec\n",
      "time forward 2.400075 sec\n",
      "loss time 0.001798 sec\n",
      "backward time 0.016932 sec\n",
      "optimizer time 0.025580 sec\n",
      "training time in round 193 cost 0.4023449420928955 sec\n",
      "loss 2.317480, train acc 0.099630\n",
      "round 194\n",
      "time to device 0.004067 sec\n",
      "time forward 2.413153 sec\n",
      "loss time 0.001769 sec\n",
      "backward time 0.015988 sec\n",
      "optimizer time 0.017215 sec\n",
      "training time in round 194 cost 0.38875913619995117 sec\n",
      "loss 2.317386, train acc 0.099760\n",
      "round 195\n",
      "time to device 0.005693 sec\n",
      "time forward 2.427374 sec\n",
      "loss time 0.002103 sec\n",
      "backward time 0.015089 sec\n",
      "optimizer time 0.025707 sec\n",
      "training time in round 195 cost 0.3948800563812256 sec\n",
      "loss 2.317335, train acc 0.099450\n",
      "round 196\n",
      "time to device 0.005447 sec\n",
      "time forward 2.438554 sec\n",
      "loss time 0.001596 sec\n",
      "backward time 0.013871 sec\n",
      "optimizer time 0.022533 sec\n",
      "training time in round 196 cost 0.37813496589660645 sec\n",
      "loss 2.317259, train acc 0.099421\n",
      "round 197\n",
      "time to device 0.003620 sec\n",
      "time forward 2.453294 sec\n",
      "loss time 0.001006 sec\n",
      "backward time 0.011811 sec\n",
      "optimizer time 0.023777 sec\n",
      "training time in round 197 cost 0.39012598991394043 sec\n",
      "loss 2.317178, train acc 0.099353\n",
      "round 198\n",
      "time to device 0.003289 sec\n",
      "time forward 2.467238 sec\n",
      "loss time 0.001506 sec\n",
      "backward time 0.011909 sec\n",
      "optimizer time 0.024131 sec\n",
      "training time in round 198 cost 0.39231014251708984 sec\n",
      "loss 2.317098, train acc 0.099325\n",
      "round 199\n",
      "time to device 0.004062 sec\n",
      "time forward 2.480558 sec\n",
      "loss time 0.001039 sec\n",
      "backward time 0.013629 sec\n",
      "optimizer time 0.028310 sec\n",
      "training time in round 199 cost 0.39340996742248535 sec\n",
      "loss 2.317043, train acc 0.099297\n",
      "round 200\n",
      "time to device 0.004048 sec\n",
      "time forward 2.496431 sec\n",
      "loss time 0.001453 sec\n",
      "backward time 0.020761 sec\n",
      "optimizer time 0.020966 sec\n",
      "training time in round 200 cost 0.4042317867279053 sec\n",
      "loss 2.316985, train acc 0.099114\n",
      "round 201\n",
      "time to device 0.003895 sec\n",
      "time forward 2.504059 sec\n",
      "loss time 0.000567 sec\n",
      "backward time 0.005203 sec\n",
      "optimizer time 0.014336 sec\n",
      "training time in round 201 cost 0.35444116592407227 sec\n",
      "loss 2.316909, train acc 0.099087\n",
      "round 202\n",
      "time to device 0.003936 sec\n",
      "time forward 2.518455 sec\n",
      "loss time 0.002033 sec\n",
      "backward time 0.015068 sec\n",
      "optimizer time 0.023825 sec\n",
      "training time in round 202 cost 0.414046049118042 sec\n",
      "loss 2.316826, train acc 0.099176\n",
      "round 203\n",
      "time to device 0.007726 sec\n",
      "time forward 2.532706 sec\n",
      "loss time 0.001808 sec\n",
      "backward time 0.013501 sec\n",
      "optimizer time 0.025956 sec\n",
      "training time in round 203 cost 0.4116997718811035 sec\n",
      "loss 2.316756, train acc 0.099188\n",
      "round 204\n",
      "time to device 0.004194 sec\n",
      "time forward 2.545357 sec\n",
      "loss time 0.001952 sec\n",
      "backward time 0.016987 sec\n",
      "optimizer time 0.027168 sec\n",
      "training time in round 204 cost 0.4080231189727783 sec\n",
      "loss 2.316681, train acc 0.099200\n",
      "round 205\n",
      "time to device 0.004515 sec\n",
      "time forward 2.559136 sec\n",
      "loss time 0.001446 sec\n",
      "backward time 0.012737 sec\n",
      "optimizer time 0.022535 sec\n",
      "training time in round 205 cost 0.3991539478302002 sec\n",
      "loss 2.316617, train acc 0.099439\n",
      "round 206\n",
      "time to device 0.004729 sec\n",
      "time forward 2.572937 sec\n",
      "loss time 0.001276 sec\n",
      "backward time 0.010303 sec\n",
      "optimizer time 0.024360 sec\n",
      "training time in round 206 cost 0.39702320098876953 sec\n",
      "loss 2.316591, train acc 0.099185\n",
      "round 207\n",
      "time to device 0.004291 sec\n",
      "time forward 2.587492 sec\n",
      "loss time 0.001826 sec\n",
      "backward time 0.014633 sec\n",
      "optimizer time 0.024592 sec\n",
      "training time in round 207 cost 0.40532708168029785 sec\n",
      "loss 2.316870, train acc 0.099159\n",
      "round 208\n",
      "time to device 0.004492 sec\n",
      "time forward 2.600971 sec\n",
      "loss time 0.001114 sec\n",
      "backward time 0.012481 sec\n",
      "optimizer time 0.023599 sec\n",
      "training time in round 208 cost 0.39575719833374023 sec\n",
      "loss 2.316855, train acc 0.099282\n",
      "round 209\n",
      "time to device 0.004639 sec\n",
      "time forward 2.614973 sec\n",
      "loss time 0.001449 sec\n",
      "backward time 0.014124 sec\n",
      "optimizer time 0.025995 sec\n",
      "training time in round 209 cost 0.405864953994751 sec\n",
      "loss 2.316794, train acc 0.099182\n",
      "round 210\n",
      "time to device 0.003870 sec\n",
      "time forward 2.628838 sec\n",
      "loss time 0.002016 sec\n",
      "backward time 0.012655 sec\n",
      "optimizer time 0.022477 sec\n",
      "training time in round 210 cost 0.39504194259643555 sec\n",
      "loss 2.316819, train acc 0.099230\n",
      "round 211\n",
      "time to device 0.005129 sec\n",
      "time forward 2.642821 sec\n",
      "loss time 0.001872 sec\n",
      "backward time 0.013407 sec\n",
      "optimizer time 0.024920 sec\n",
      "training time in round 211 cost 0.40283799171447754 sec\n",
      "loss 2.316752, train acc 0.099167\n",
      "round 212\n",
      "time to device 0.005486 sec\n",
      "time forward 2.656057 sec\n",
      "loss time 0.001558 sec\n",
      "backward time 0.015300 sec\n",
      "optimizer time 0.023261 sec\n",
      "training time in round 212 cost 0.4007740020751953 sec\n",
      "loss 2.317137, train acc 0.099215\n",
      "round 213\n",
      "time to device 0.005513 sec\n",
      "time forward 2.668295 sec\n",
      "loss time 0.001574 sec\n",
      "backward time 0.017269 sec\n",
      "optimizer time 0.025382 sec\n",
      "training time in round 213 cost 0.40368008613586426 sec\n",
      "loss 2.317042, train acc 0.099299\n",
      "round 214\n",
      "time to device 0.003987 sec\n",
      "time forward 2.681996 sec\n",
      "loss time 0.001494 sec\n",
      "backward time 0.016608 sec\n",
      "optimizer time 0.025690 sec\n",
      "training time in round 214 cost 0.4081590175628662 sec\n",
      "loss 2.316969, train acc 0.099201\n",
      "round 215\n",
      "time to device 0.004072 sec\n",
      "time forward 2.688874 sec\n",
      "loss time 0.000550 sec\n",
      "backward time 0.005169 sec\n",
      "optimizer time 0.014196 sec\n",
      "training time in round 215 cost 0.3592369556427002 sec\n",
      "loss 2.316923, train acc 0.099175\n",
      "round 216\n",
      "time to device 0.004039 sec\n",
      "time forward 2.702773 sec\n",
      "loss time 0.001250 sec\n",
      "backward time 0.022809 sec\n",
      "optimizer time 0.015408 sec\n",
      "training time in round 216 cost 0.42849278450012207 sec\n",
      "loss 2.316860, train acc 0.099078\n",
      "round 217\n",
      "time to device 0.002372 sec\n",
      "time forward 2.714979 sec\n",
      "loss time 0.000985 sec\n",
      "backward time 0.016139 sec\n",
      "optimizer time 0.016936 sec\n",
      "training time in round 217 cost 0.460299015045166 sec\n",
      "loss 2.316795, train acc 0.099018\n",
      "round 218\n",
      "time to device 0.008753 sec\n",
      "time forward 2.731412 sec\n",
      "loss time 0.002262 sec\n",
      "backward time 0.012007 sec\n",
      "optimizer time 0.024662 sec\n",
      "training time in round 218 cost 0.5190310478210449 sec\n",
      "loss 2.316705, train acc 0.099315\n",
      "round 219\n",
      "time to device 0.009695 sec\n",
      "time forward 2.745881 sec\n",
      "loss time 0.001827 sec\n",
      "backward time 0.014618 sec\n",
      "optimizer time 0.025754 sec\n",
      "training time in round 219 cost 0.40046000480651855 sec\n",
      "loss 2.316631, train acc 0.099325\n",
      "round 220\n",
      "time to device 0.007947 sec\n",
      "time forward 2.751930 sec\n",
      "loss time 0.000432 sec\n",
      "backward time 0.003930 sec\n",
      "optimizer time 0.011657 sec\n",
      "training time in round 220 cost 0.3559889793395996 sec\n",
      "loss 2.316585, train acc 0.099194\n",
      "round 221\n",
      "time to device 0.010126 sec\n",
      "time forward 2.763795 sec\n",
      "loss time 0.002499 sec\n",
      "backward time 0.019068 sec\n",
      "optimizer time 0.011141 sec\n",
      "training time in round 221 cost 0.40851616859436035 sec\n",
      "loss 2.316674, train acc 0.098994\n",
      "round 222\n",
      "time to device 0.007299 sec\n",
      "time forward 2.791334 sec\n",
      "loss time 0.001619 sec\n",
      "backward time 0.013317 sec\n",
      "optimizer time 0.026905 sec\n",
      "training time in round 222 cost 0.47594594955444336 sec\n",
      "loss 2.316604, train acc 0.099110\n",
      "round 223\n",
      "time to device 0.008897 sec\n",
      "time forward 2.805458 sec\n",
      "loss time 0.001507 sec\n",
      "backward time 0.015639 sec\n",
      "optimizer time 0.023882 sec\n",
      "training time in round 223 cost 0.4145359992980957 sec\n",
      "loss 2.316519, train acc 0.099330\n",
      "round 224\n",
      "time to device 0.009445 sec\n",
      "time forward 2.818271 sec\n",
      "loss time 0.001454 sec\n",
      "backward time 0.013608 sec\n",
      "optimizer time 0.022419 sec\n",
      "training time in round 224 cost 0.40784406661987305 sec\n",
      "loss 2.316448, train acc 0.099201\n",
      "round 225\n",
      "time to device 0.008187 sec\n",
      "time forward 2.824005 sec\n",
      "loss time 0.000563 sec\n",
      "backward time 0.005155 sec\n",
      "optimizer time 0.016265 sec\n",
      "training time in round 225 cost 0.3631711006164551 sec\n",
      "loss 2.316370, train acc 0.099246\n",
      "round 226\n",
      "time to device 0.008860 sec\n",
      "time forward 2.839428 sec\n",
      "loss time 0.001430 sec\n",
      "backward time 0.012748 sec\n",
      "optimizer time 0.026186 sec\n",
      "training time in round 226 cost 0.4165170192718506 sec\n",
      "loss 2.316317, train acc 0.099085\n",
      "round 227\n",
      "time to device 0.007408 sec\n",
      "time forward 2.853168 sec\n",
      "loss time 0.001539 sec\n",
      "backward time 0.013468 sec\n",
      "optimizer time 0.024176 sec\n",
      "training time in round 227 cost 0.4107639789581299 sec\n",
      "loss 2.316552, train acc 0.099061\n",
      "round 228\n",
      "time to device 0.008899 sec\n",
      "time forward 2.870546 sec\n",
      "loss time 0.001115 sec\n",
      "backward time 0.009960 sec\n",
      "optimizer time 0.019050 sec\n",
      "training time in round 228 cost 0.4303319454193115 sec\n",
      "loss 2.316497, train acc 0.099072\n",
      "round 229\n",
      "time to device 0.008610 sec\n",
      "time forward 2.885541 sec\n",
      "loss time 0.001914 sec\n",
      "backward time 0.013374 sec\n",
      "optimizer time 0.025555 sec\n",
      "training time in round 229 cost 0.40290045738220215 sec\n",
      "loss 2.316440, train acc 0.099083\n",
      "round 230\n",
      "time to device 0.007067 sec\n",
      "time forward 2.892871 sec\n",
      "loss time 0.000547 sec\n",
      "backward time 0.005283 sec\n",
      "optimizer time 0.014598 sec\n",
      "training time in round 230 cost 0.35292792320251465 sec\n",
      "loss 2.316391, train acc 0.099094\n",
      "round 231\n",
      "time to device 0.006253 sec\n",
      "time forward 2.902716 sec\n",
      "loss time 0.001090 sec\n",
      "backward time 0.012827 sec\n",
      "optimizer time 0.028804 sec\n",
      "training time in round 231 cost 0.3995659351348877 sec\n",
      "loss 2.316333, train acc 0.099138\n",
      "round 232\n",
      "time to device 0.007501 sec\n",
      "time forward 2.911032 sec\n",
      "loss time 0.000516 sec\n",
      "backward time 0.006875 sec\n",
      "optimizer time 0.028957 sec\n",
      "training time in round 232 cost 0.38910794258117676 sec\n",
      "loss 2.316286, train acc 0.099048\n",
      "round 233\n",
      "time to device 0.007635 sec\n",
      "time forward 2.926701 sec\n",
      "loss time 0.002071 sec\n",
      "backward time 0.014952 sec\n",
      "optimizer time 0.025813 sec\n",
      "training time in round 233 cost 0.43158578872680664 sec\n",
      "loss 2.316242, train acc 0.098992\n",
      "round 234\n",
      "time to device 0.008207 sec\n",
      "time forward 2.940121 sec\n",
      "loss time 0.001880 sec\n",
      "backward time 0.016874 sec\n",
      "optimizer time 0.025135 sec\n",
      "training time in round 234 cost 0.4014017581939697 sec\n",
      "loss 2.316203, train acc 0.098870\n",
      "round 235\n",
      "time to device 0.011096 sec\n",
      "time forward 2.946551 sec\n",
      "loss time 0.000559 sec\n",
      "backward time 0.005158 sec\n",
      "optimizer time 0.013886 sec\n",
      "training time in round 235 cost 0.35480594635009766 sec\n",
      "loss 2.316469, train acc 0.099014\n",
      "round 236\n",
      "time to device 0.008598 sec\n",
      "time forward 2.959013 sec\n",
      "loss time 0.001303 sec\n",
      "backward time 0.012013 sec\n",
      "optimizer time 0.021308 sec\n",
      "training time in round 236 cost 0.4014008045196533 sec\n",
      "loss 2.316431, train acc 0.098859\n",
      "round 237\n",
      "time to device 0.009911 sec\n",
      "time forward 2.970085 sec\n",
      "loss time 0.001249 sec\n",
      "backward time 0.013499 sec\n",
      "optimizer time 0.026419 sec\n",
      "training time in round 237 cost 0.39892125129699707 sec\n",
      "loss 2.316404, train acc 0.098641\n",
      "round 238\n",
      "time to device 0.009295 sec\n",
      "time forward 2.982908 sec\n",
      "loss time 0.001443 sec\n",
      "backward time 0.017654 sec\n",
      "optimizer time 0.021805 sec\n",
      "training time in round 238 cost 0.3971719741821289 sec\n",
      "loss 2.316347, train acc 0.098588\n",
      "round 239\n",
      "time to device 0.004988 sec\n",
      "time forward 2.998519 sec\n",
      "loss time 0.002045 sec\n",
      "backward time 0.014172 sec\n",
      "optimizer time 0.026842 sec\n",
      "training time in round 239 cost 0.4148290157318115 sec\n",
      "loss 2.316306, train acc 0.098405\n",
      "round 240\n",
      "time to device 0.004717 sec\n",
      "time forward 3.011432 sec\n",
      "loss time 0.002172 sec\n",
      "backward time 0.012459 sec\n",
      "optimizer time 0.025263 sec\n",
      "training time in round 240 cost 0.39125609397888184 sec\n",
      "loss 2.316755, train acc 0.098288\n",
      "round 241\n",
      "time to device 0.004019 sec\n",
      "time forward 3.023364 sec\n",
      "loss time 0.001068 sec\n",
      "backward time 0.010808 sec\n",
      "optimizer time 0.021353 sec\n",
      "training time in round 241 cost 0.41086792945861816 sec\n",
      "loss 2.316752, train acc 0.098334\n",
      "round 242\n",
      "time to device 0.006125 sec\n",
      "time forward 3.037556 sec\n",
      "loss time 0.000911 sec\n",
      "backward time 0.011635 sec\n",
      "optimizer time 0.018376 sec\n",
      "training time in round 242 cost 0.3843247890472412 sec\n",
      "loss 2.316708, train acc 0.098090\n",
      "round 243\n",
      "time to device 0.005642 sec\n",
      "time forward 3.051327 sec\n",
      "loss time 0.001071 sec\n",
      "backward time 0.024120 sec\n",
      "optimizer time 0.012347 sec\n",
      "training time in round 243 cost 0.3873772621154785 sec\n",
      "loss 2.316638, train acc 0.098072\n",
      "round 244\n",
      "time to device 0.006046 sec\n",
      "time forward 3.060820 sec\n",
      "loss time 0.000984 sec\n",
      "backward time 0.016311 sec\n",
      "optimizer time 0.016033 sec\n",
      "training time in round 244 cost 0.3768157958984375 sec\n",
      "loss 2.316575, train acc 0.097991\n",
      "round 245\n",
      "time to device 0.006407 sec\n",
      "time forward 3.070940 sec\n",
      "loss time 0.001103 sec\n",
      "backward time 0.010335 sec\n",
      "optimizer time 0.018727 sec\n",
      "training time in round 245 cost 0.37841081619262695 sec\n",
      "loss 2.316529, train acc 0.098037\n",
      "round 246\n",
      "time to device 0.006541 sec\n",
      "time forward 3.076236 sec\n",
      "loss time 0.000413 sec\n",
      "backward time 0.003440 sec\n",
      "optimizer time 0.010753 sec\n",
      "training time in round 246 cost 0.34960174560546875 sec\n",
      "loss 2.316618, train acc 0.098083\n",
      "round 247\n",
      "time to device 0.005675 sec\n",
      "time forward 3.087466 sec\n",
      "loss time 0.001074 sec\n",
      "backward time 0.011522 sec\n",
      "optimizer time 0.012560 sec\n",
      "training time in round 247 cost 0.3707859516143799 sec\n",
      "loss 2.316550, train acc 0.098097\n",
      "round 248\n",
      "time to device 0.005728 sec\n",
      "time forward 3.105064 sec\n",
      "loss time 0.001167 sec\n",
      "backward time 0.012574 sec\n",
      "optimizer time 0.016359 sec\n",
      "training time in round 248 cost 0.4024162292480469 sec\n",
      "loss 2.316503, train acc 0.097797\n",
      "round 249\n",
      "time to device 0.005995 sec\n",
      "time forward 3.115121 sec\n",
      "loss time 0.001371 sec\n",
      "backward time 0.014651 sec\n",
      "optimizer time 0.015207 sec\n",
      "training time in round 249 cost 0.36971187591552734 sec\n",
      "loss 2.316495, train acc 0.097844\n",
      "round 250\n",
      "time to device 0.006854 sec\n",
      "time forward 3.124742 sec\n",
      "loss time 0.000926 sec\n",
      "backward time 0.010824 sec\n",
      "optimizer time 0.020111 sec\n",
      "training time in round 250 cost 0.3669929504394531 sec\n",
      "loss 2.316434, train acc 0.097859\n",
      "round 251\n",
      "time to device 0.006450 sec\n",
      "time forward 3.135163 sec\n",
      "loss time 0.001299 sec\n",
      "backward time 0.010678 sec\n",
      "optimizer time 0.024111 sec\n",
      "training time in round 251 cost 0.40274691581726074 sec\n",
      "loss 2.316388, train acc 0.097780\n",
      "round 252\n",
      "time to device 0.006645 sec\n",
      "time forward 3.145412 sec\n",
      "loss time 0.000944 sec\n",
      "backward time 0.023727 sec\n",
      "optimizer time 0.013210 sec\n",
      "training time in round 252 cost 0.38371896743774414 sec\n",
      "loss 2.316345, train acc 0.097733\n",
      "round 253\n",
      "time to device 0.006297 sec\n",
      "time forward 3.166381 sec\n",
      "loss time 0.001219 sec\n",
      "backward time 0.013777 sec\n",
      "optimizer time 0.015687 sec\n",
      "training time in round 253 cost 0.3907649517059326 sec\n",
      "loss 2.316296, train acc 0.097595\n",
      "round 254\n",
      "time to device 0.006139 sec\n",
      "time forward 3.177391 sec\n",
      "loss time 0.000940 sec\n",
      "backward time 0.010875 sec\n",
      "optimizer time 0.014780 sec\n",
      "training time in round 254 cost 0.3776237964630127 sec\n",
      "loss 2.316263, train acc 0.097488\n",
      "round 255\n",
      "time to device 0.010510 sec\n",
      "time forward 3.187645 sec\n",
      "loss time 0.000968 sec\n",
      "backward time 0.014416 sec\n",
      "optimizer time 0.014915 sec\n",
      "training time in round 255 cost 0.38775014877319336 sec\n",
      "loss 2.316219, train acc 0.097473\n",
      "round 256\n",
      "time to device 0.006495 sec\n",
      "time forward 3.198512 sec\n",
      "loss time 0.000967 sec\n",
      "backward time 0.010541 sec\n",
      "optimizer time 0.018221 sec\n",
      "training time in round 256 cost 0.3928518295288086 sec\n",
      "loss 2.316180, train acc 0.097489\n",
      "round 257\n",
      "time to device 0.006131 sec\n",
      "time forward 3.208792 sec\n",
      "loss time 0.001093 sec\n",
      "backward time 0.012721 sec\n",
      "optimizer time 0.018071 sec\n",
      "training time in round 257 cost 0.37737107276916504 sec\n",
      "loss 2.316158, train acc 0.097353\n",
      "round 258\n",
      "time to device 0.007787 sec\n",
      "time forward 3.223364 sec\n",
      "loss time 0.001878 sec\n",
      "backward time 0.012861 sec\n",
      "optimizer time 0.012983 sec\n",
      "training time in round 258 cost 0.3922858238220215 sec\n",
      "loss 2.316130, train acc 0.097279\n",
      "round 259\n",
      "time to device 0.006942 sec\n",
      "time forward 3.233788 sec\n",
      "loss time 0.001721 sec\n",
      "backward time 0.014157 sec\n",
      "optimizer time 0.018378 sec\n",
      "training time in round 259 cost 0.3786921501159668 sec\n",
      "loss 2.316079, train acc 0.097296\n",
      "round 260\n",
      "time to device 0.009293 sec\n",
      "time forward 3.245843 sec\n",
      "loss time 0.001623 sec\n",
      "backward time 0.013825 sec\n",
      "optimizer time 0.024602 sec\n",
      "training time in round 260 cost 0.3832259178161621 sec\n",
      "loss 2.316034, train acc 0.097192\n",
      "round 261\n",
      "time to device 0.009044 sec\n",
      "time forward 3.262287 sec\n",
      "loss time 0.001876 sec\n",
      "backward time 0.013137 sec\n",
      "optimizer time 0.023974 sec\n",
      "training time in round 261 cost 0.4105520248413086 sec\n",
      "loss 2.316030, train acc 0.097179\n",
      "round 262\n",
      "time to device 0.006575 sec\n",
      "time forward 3.274222 sec\n",
      "loss time 0.001692 sec\n",
      "backward time 0.012432 sec\n",
      "optimizer time 0.014652 sec\n",
      "training time in round 262 cost 0.3892378807067871 sec\n",
      "loss 2.315976, train acc 0.097107\n",
      "round 263\n",
      "time to device 0.009162 sec\n",
      "time forward 3.284948 sec\n",
      "loss time 0.001131 sec\n",
      "backward time 0.009798 sec\n",
      "optimizer time 0.029214 sec\n",
      "training time in round 263 cost 0.38423895835876465 sec\n",
      "loss 2.315924, train acc 0.097183\n",
      "round 264\n",
      "time to device 0.010092 sec\n",
      "time forward 3.299093 sec\n",
      "loss time 0.001171 sec\n",
      "backward time 0.015851 sec\n",
      "optimizer time 0.025176 sec\n",
      "training time in round 264 cost 0.4207608699798584 sec\n",
      "loss 2.315878, train acc 0.097081\n",
      "round 265\n",
      "time to device 0.007032 sec\n",
      "time forward 3.306484 sec\n",
      "loss time 0.000563 sec\n",
      "backward time 0.005211 sec\n",
      "optimizer time 0.014170 sec\n",
      "training time in round 265 cost 0.3611452579498291 sec\n",
      "loss 2.315839, train acc 0.097039\n",
      "round 266\n",
      "time to device 0.008832 sec\n",
      "time forward 3.320602 sec\n",
      "loss time 0.001574 sec\n",
      "backward time 0.012477 sec\n",
      "optimizer time 0.023466 sec\n",
      "training time in round 266 cost 0.3928258419036865 sec\n",
      "loss 2.315783, train acc 0.097056\n",
      "round 267\n",
      "time to device 0.003719 sec\n",
      "time forward 3.333591 sec\n",
      "loss time 0.002178 sec\n",
      "backward time 0.014050 sec\n",
      "optimizer time 0.023725 sec\n",
      "training time in round 267 cost 0.38878488540649414 sec\n",
      "loss 2.315744, train acc 0.096869\n",
      "round 268\n",
      "time to device 0.004397 sec\n",
      "time forward 3.343282 sec\n",
      "loss time 0.000587 sec\n",
      "backward time 0.008418 sec\n",
      "optimizer time 0.030685 sec\n",
      "training time in round 268 cost 0.3885200023651123 sec\n",
      "loss 2.315706, train acc 0.096799\n",
      "round 269\n",
      "time to device 0.005317 sec\n",
      "time forward 3.356866 sec\n",
      "loss time 0.001903 sec\n",
      "backward time 0.016938 sec\n",
      "optimizer time 0.025756 sec\n",
      "training time in round 269 cost 0.43710803985595703 sec\n",
      "loss 2.315835, train acc 0.096644\n",
      "round 270\n",
      "time to device 0.004186 sec\n",
      "time forward 3.370707 sec\n",
      "loss time 0.001524 sec\n",
      "backward time 0.016641 sec\n",
      "optimizer time 0.026349 sec\n",
      "training time in round 270 cost 0.45392298698425293 sec\n",
      "loss 2.315796, train acc 0.096604\n",
      "round 271\n",
      "time to device 0.007834 sec\n",
      "time forward 3.383886 sec\n",
      "loss time 0.001304 sec\n",
      "backward time 0.010698 sec\n",
      "optimizer time 0.021653 sec\n",
      "training time in round 271 cost 0.38345861434936523 sec\n",
      "loss 2.315742, train acc 0.096708\n",
      "round 272\n",
      "time to device 0.007368 sec\n",
      "time forward 3.398737 sec\n",
      "loss time 0.002076 sec\n",
      "backward time 0.015264 sec\n",
      "optimizer time 0.026578 sec\n",
      "training time in round 272 cost 0.4006621837615967 sec\n",
      "loss 2.316574, train acc 0.096841\n",
      "round 273\n",
      "time to device 0.009387 sec\n",
      "time forward 3.410111 sec\n",
      "loss time 0.001306 sec\n",
      "backward time 0.013916 sec\n",
      "optimizer time 0.026634 sec\n",
      "training time in round 273 cost 0.4039607048034668 sec\n",
      "loss 2.316535, train acc 0.096801\n",
      "round 274\n",
      "time to device 0.007794 sec\n",
      "time forward 3.422858 sec\n",
      "loss time 0.001426 sec\n",
      "backward time 0.012087 sec\n",
      "optimizer time 0.024411 sec\n",
      "training time in round 274 cost 0.3881220817565918 sec\n",
      "loss 2.316479, train acc 0.096875\n",
      "round 275\n",
      "time to device 0.007773 sec\n",
      "time forward 3.435951 sec\n",
      "loss time 0.001154 sec\n",
      "backward time 0.015285 sec\n",
      "optimizer time 0.023700 sec\n",
      "training time in round 275 cost 0.39542388916015625 sec\n",
      "loss 2.316472, train acc 0.097034\n",
      "round 276\n",
      "time to device 0.011103 sec\n",
      "time forward 3.448414 sec\n",
      "loss time 0.002026 sec\n",
      "backward time 0.013629 sec\n",
      "optimizer time 0.023772 sec\n",
      "training time in round 276 cost 0.39066624641418457 sec\n",
      "loss 2.316495, train acc 0.097050\n",
      "round 277\n",
      "time to device 0.007117 sec\n",
      "time forward 3.460426 sec\n",
      "loss time 0.000964 sec\n",
      "backward time 0.009641 sec\n",
      "optimizer time 0.021733 sec\n",
      "training time in round 277 cost 0.39060115814208984 sec\n",
      "loss 2.316456, train acc 0.096897\n",
      "round 278\n",
      "time to device 0.008429 sec\n",
      "time forward 3.473734 sec\n",
      "loss time 0.001877 sec\n",
      "backward time 0.015907 sec\n",
      "optimizer time 0.025161 sec\n",
      "training time in round 278 cost 0.39488673210144043 sec\n",
      "loss 2.316400, train acc 0.096802\n",
      "round 279\n",
      "time to device 0.007497 sec\n",
      "time forward 3.486179 sec\n",
      "loss time 0.001912 sec\n",
      "backward time 0.013603 sec\n",
      "optimizer time 0.024865 sec\n",
      "training time in round 279 cost 0.4254271984100342 sec\n",
      "loss 2.316353, train acc 0.096680\n",
      "round 280\n",
      "time to device 0.004219 sec\n",
      "time forward 3.498772 sec\n",
      "loss time 0.001515 sec\n",
      "backward time 0.015933 sec\n",
      "optimizer time 0.026563 sec\n",
      "training time in round 280 cost 0.38776087760925293 sec\n",
      "loss 2.316308, train acc 0.096641\n",
      "round 281\n",
      "time to device 0.010398 sec\n",
      "time forward 3.512783 sec\n",
      "loss time 0.001946 sec\n",
      "backward time 0.016732 sec\n",
      "optimizer time 0.027050 sec\n",
      "training time in round 281 cost 0.4103817939758301 sec\n",
      "loss 2.316266, train acc 0.096520\n",
      "round 282\n",
      "time to device 0.006338 sec\n",
      "time forward 3.525700 sec\n",
      "loss time 0.001190 sec\n",
      "backward time 0.013686 sec\n",
      "optimizer time 0.027562 sec\n",
      "training time in round 282 cost 0.39370274543762207 sec\n",
      "loss 2.316469, train acc 0.096538\n",
      "round 283\n",
      "time to device 0.007965 sec\n",
      "time forward 3.536525 sec\n",
      "loss time 0.001409 sec\n",
      "backward time 0.011894 sec\n",
      "optimizer time 0.022089 sec\n",
      "training time in round 283 cost 0.3971409797668457 sec\n",
      "loss 2.319408, train acc 0.096556\n",
      "round 284\n",
      "time to device 0.006811 sec\n",
      "time forward 3.549653 sec\n",
      "loss time 0.001735 sec\n",
      "backward time 0.012114 sec\n",
      "optimizer time 0.027468 sec\n",
      "training time in round 284 cost 0.39111781120300293 sec\n",
      "loss 2.319360, train acc 0.096409\n",
      "round 285\n",
      "time to device 0.009631 sec\n",
      "time forward 3.567943 sec\n",
      "loss time 0.001660 sec\n",
      "backward time 0.013051 sec\n",
      "optimizer time 0.022851 sec\n",
      "training time in round 285 cost 0.4076700210571289 sec\n",
      "loss 2.319302, train acc 0.096400\n",
      "round 286\n",
      "time to device 0.003184 sec\n",
      "time forward 3.575101 sec\n",
      "loss time 0.000550 sec\n",
      "backward time 0.005134 sec\n",
      "optimizer time 0.014800 sec\n",
      "training time in round 286 cost 0.3424718379974365 sec\n",
      "loss 2.320115, train acc 0.096527\n",
      "round 287\n",
      "time to device 0.007487 sec\n",
      "time forward 3.588716 sec\n",
      "loss time 0.001598 sec\n",
      "backward time 0.017484 sec\n",
      "optimizer time 0.023668 sec\n",
      "training time in round 287 cost 0.39818406105041504 sec\n",
      "loss 2.320068, train acc 0.096544\n",
      "round 288\n",
      "time to device 0.010370 sec\n",
      "time forward 3.600889 sec\n",
      "loss time 0.002008 sec\n",
      "backward time 0.016348 sec\n",
      "optimizer time 0.027259 sec\n",
      "training time in round 288 cost 0.39840102195739746 sec\n",
      "loss 2.320007, train acc 0.096453\n",
      "round 289\n",
      "time to device 0.005318 sec\n",
      "time forward 3.612922 sec\n",
      "loss time 0.001845 sec\n",
      "backward time 0.015915 sec\n",
      "optimizer time 0.026568 sec\n",
      "training time in round 289 cost 0.38663673400878906 sec\n",
      "loss 2.319952, train acc 0.096444\n",
      "round 290\n",
      "time to device 0.007208 sec\n",
      "time forward 3.626000 sec\n",
      "loss time 0.001898 sec\n",
      "backward time 0.012832 sec\n",
      "optimizer time 0.022522 sec\n",
      "training time in round 290 cost 0.39046692848205566 sec\n",
      "loss 2.319911, train acc 0.096220\n",
      "round 291\n",
      "time to device 0.003734 sec\n",
      "time forward 3.634197 sec\n",
      "loss time 0.000552 sec\n",
      "backward time 0.005174 sec\n",
      "optimizer time 0.013976 sec\n",
      "training time in round 291 cost 0.3561410903930664 sec\n",
      "loss 2.319861, train acc 0.096211\n",
      "round 292\n",
      "time to device 0.004413 sec\n",
      "time forward 3.647666 sec\n",
      "loss time 0.001443 sec\n",
      "backward time 0.010891 sec\n",
      "optimizer time 0.024517 sec\n",
      "training time in round 292 cost 0.3862760066986084 sec\n",
      "loss 2.319803, train acc 0.096256\n",
      "round 293\n",
      "time to device 0.004252 sec\n",
      "time forward 3.660658 sec\n",
      "loss time 0.001705 sec\n",
      "backward time 0.011794 sec\n",
      "optimizer time 0.024453 sec\n",
      "training time in round 293 cost 0.38470888137817383 sec\n",
      "loss 2.319748, train acc 0.096195\n",
      "round 294\n",
      "time to device 0.003834 sec\n",
      "time forward 3.673402 sec\n",
      "loss time 0.001926 sec\n",
      "backward time 0.012137 sec\n",
      "optimizer time 0.026942 sec\n",
      "training time in round 294 cost 0.3888101577758789 sec\n",
      "loss 2.319686, train acc 0.096292\n",
      "round 295\n",
      "time to device 0.003743 sec\n",
      "time forward 3.686448 sec\n",
      "loss time 0.001901 sec\n",
      "backward time 0.013099 sec\n",
      "optimizer time 0.024498 sec\n",
      "training time in round 295 cost 0.3885338306427002 sec\n",
      "loss 2.319626, train acc 0.096310\n",
      "round 296\n",
      "time to device 0.004628 sec\n",
      "time forward 3.694040 sec\n",
      "loss time 0.000575 sec\n",
      "backward time 0.005039 sec\n",
      "optimizer time 0.013763 sec\n",
      "training time in round 296 cost 0.351088285446167 sec\n",
      "loss 2.319573, train acc 0.096196\n",
      "round 297\n",
      "time to device 0.003347 sec\n",
      "time forward 3.709180 sec\n",
      "loss time 0.001382 sec\n",
      "backward time 0.012290 sec\n",
      "optimizer time 0.023872 sec\n",
      "training time in round 297 cost 0.39127182960510254 sec\n",
      "loss 2.319516, train acc 0.096188\n",
      "round 298\n",
      "time to device 0.003589 sec\n",
      "time forward 3.722551 sec\n",
      "loss time 0.001408 sec\n",
      "backward time 0.012826 sec\n",
      "optimizer time 0.012869 sec\n",
      "training time in round 298 cost 0.37859511375427246 sec\n",
      "loss 2.319464, train acc 0.096206\n",
      "round 299\n",
      "time to device 0.003288 sec\n",
      "time forward 3.735301 sec\n",
      "loss time 0.001574 sec\n",
      "backward time 0.016842 sec\n",
      "optimizer time 0.026492 sec\n",
      "training time in round 299 cost 0.3969688415527344 sec\n",
      "loss 2.319416, train acc 0.096120\n",
      "round 300\n",
      "time to device 0.004234 sec\n",
      "time forward 3.748877 sec\n",
      "loss time 0.001747 sec\n",
      "backward time 0.014463 sec\n",
      "optimizer time 0.021030 sec\n",
      "training time in round 300 cost 0.38962697982788086 sec\n",
      "loss 2.319357, train acc 0.096112\n",
      "round 301\n",
      "time to device 0.004201 sec\n",
      "time forward 3.755967 sec\n",
      "loss time 0.000512 sec\n",
      "backward time 0.005241 sec\n",
      "optimizer time 0.012581 sec\n",
      "training time in round 301 cost 0.33924198150634766 sec\n",
      "loss 2.319315, train acc 0.095975\n",
      "round 302\n",
      "time to device 0.003665 sec\n",
      "time forward 3.770146 sec\n",
      "loss time 0.002205 sec\n",
      "backward time 0.013204 sec\n",
      "optimizer time 0.025964 sec\n",
      "training time in round 302 cost 0.3913149833679199 sec\n",
      "loss 2.319259, train acc 0.096148\n",
      "round 303\n",
      "time to device 0.003607 sec\n",
      "time forward 3.784003 sec\n",
      "loss time 0.001586 sec\n",
      "backward time 0.017421 sec\n",
      "optimizer time 0.028081 sec\n",
      "training time in round 303 cost 0.39980483055114746 sec\n",
      "loss 2.319200, train acc 0.096089\n",
      "round 304\n",
      "time to device 0.003149 sec\n",
      "time forward 3.797267 sec\n",
      "loss time 0.001148 sec\n",
      "backward time 0.012287 sec\n",
      "optimizer time 0.024011 sec\n",
      "training time in round 304 cost 0.3865318298339844 sec\n",
      "loss 2.319142, train acc 0.096132\n",
      "round 305\n",
      "time to device 0.005046 sec\n",
      "time forward 3.811348 sec\n",
      "loss time 0.001338 sec\n",
      "backward time 0.013903 sec\n",
      "optimizer time 0.027350 sec\n",
      "training time in round 305 cost 0.3952150344848633 sec\n",
      "loss 2.319092, train acc 0.096099\n",
      "round 306\n",
      "time to device 0.003941 sec\n",
      "time forward 3.818604 sec\n",
      "loss time 0.000548 sec\n",
      "backward time 0.005565 sec\n",
      "optimizer time 0.014824 sec\n",
      "training time in round 306 cost 0.3567471504211426 sec\n",
      "loss 2.319039, train acc 0.096117\n",
      "round 307\n",
      "time to device 0.004106 sec\n",
      "time forward 3.831440 sec\n",
      "loss time 0.001894 sec\n",
      "backward time 0.010565 sec\n",
      "optimizer time 0.024132 sec\n",
      "training time in round 307 cost 0.38500404357910156 sec\n",
      "loss 2.319088, train acc 0.096337\n",
      "round 308\n",
      "time to device 0.004563 sec\n",
      "time forward 3.850537 sec\n",
      "loss time 0.001548 sec\n",
      "backward time 0.016902 sec\n",
      "optimizer time 0.024541 sec\n",
      "training time in round 308 cost 0.4347829818725586 sec\n",
      "loss 2.319035, train acc 0.096379\n",
      "round 309\n",
      "time to device 0.009016 sec\n",
      "time forward 3.863810 sec\n",
      "loss time 0.001192 sec\n",
      "backward time 0.012312 sec\n",
      "optimizer time 0.024632 sec\n",
      "training time in round 309 cost 0.40667295455932617 sec\n",
      "loss 2.318987, train acc 0.096371\n",
      "round 310\n",
      "time to device 0.004028 sec\n",
      "time forward 3.877979 sec\n",
      "loss time 0.001574 sec\n",
      "backward time 0.011283 sec\n",
      "optimizer time 0.022717 sec\n",
      "training time in round 310 cost 0.39408206939697266 sec\n",
      "loss 2.318959, train acc 0.096438\n",
      "round 311\n",
      "time to device 0.003707 sec\n",
      "time forward 3.890959 sec\n",
      "loss time 0.001522 sec\n",
      "backward time 0.011386 sec\n",
      "optimizer time 0.023279 sec\n",
      "training time in round 311 cost 0.38399195671081543 sec\n",
      "loss 2.318897, train acc 0.096379\n",
      "round 312\n",
      "time to device 0.004139 sec\n",
      "time forward 3.904015 sec\n",
      "loss time 0.001166 sec\n",
      "backward time 0.011371 sec\n",
      "optimizer time 0.028068 sec\n",
      "training time in round 312 cost 0.3879427909851074 sec\n",
      "loss 2.318851, train acc 0.096246\n",
      "round 313\n",
      "time to device 0.004381 sec\n",
      "time forward 3.918425 sec\n",
      "loss time 0.002402 sec\n",
      "backward time 0.016395 sec\n",
      "optimizer time 0.022669 sec\n",
      "training time in round 313 cost 0.3944568634033203 sec\n",
      "loss 2.318807, train acc 0.096188\n",
      "round 314\n",
      "time to device 0.003590 sec\n",
      "time forward 3.930372 sec\n",
      "loss time 0.001879 sec\n",
      "backward time 0.014363 sec\n",
      "optimizer time 0.027682 sec\n",
      "training time in round 314 cost 0.38739871978759766 sec\n",
      "loss 2.318767, train acc 0.096156\n",
      "round 315\n",
      "time to device 0.004770 sec\n",
      "time forward 3.942171 sec\n",
      "loss time 0.001860 sec\n",
      "backward time 0.014195 sec\n",
      "optimizer time 0.027061 sec\n",
      "training time in round 315 cost 0.3870382308959961 sec\n",
      "loss 2.318726, train acc 0.096123\n",
      "round 316\n",
      "time to device 0.003816 sec\n",
      "time forward 3.955692 sec\n",
      "loss time 0.001892 sec\n",
      "backward time 0.015789 sec\n",
      "optimizer time 0.024974 sec\n",
      "training time in round 316 cost 0.39174604415893555 sec\n",
      "loss 2.318680, train acc 0.096042\n",
      "round 317\n",
      "time to device 0.004340 sec\n",
      "time forward 3.969035 sec\n",
      "loss time 0.002010 sec\n",
      "backward time 0.016304 sec\n",
      "optimizer time 0.025787 sec\n",
      "training time in round 317 cost 0.39432191848754883 sec\n",
      "loss 2.318631, train acc 0.095986\n",
      "round 318\n",
      "time to device 0.003664 sec\n",
      "time forward 3.983536 sec\n",
      "loss time 0.001548 sec\n",
      "backward time 0.010688 sec\n",
      "optimizer time 0.021431 sec\n",
      "training time in round 318 cost 0.3846242427825928 sec\n",
      "loss 2.318576, train acc 0.096052\n",
      "round 319\n",
      "time to device 0.005778 sec\n",
      "time forward 3.997545 sec\n",
      "loss time 0.001962 sec\n",
      "backward time 0.013078 sec\n",
      "optimizer time 0.023518 sec\n",
      "training time in round 319 cost 0.3922879695892334 sec\n",
      "loss 2.318521, train acc 0.096143\n",
      "round 320\n",
      "time to device 0.004077 sec\n",
      "time forward 4.008818 sec\n",
      "loss time 0.001281 sec\n",
      "backward time 0.013433 sec\n",
      "optimizer time 0.026494 sec\n",
      "training time in round 320 cost 0.3796679973602295 sec\n",
      "loss 2.318466, train acc 0.096111\n",
      "round 321\n",
      "time to device 0.004245 sec\n",
      "time forward 4.024463 sec\n",
      "loss time 0.001324 sec\n",
      "backward time 0.015314 sec\n",
      "optimizer time 0.025797 sec\n",
      "training time in round 321 cost 0.3971121311187744 sec\n",
      "loss 2.318415, train acc 0.096201\n",
      "round 322\n",
      "time to device 0.003981 sec\n",
      "time forward 4.034409 sec\n",
      "loss time 0.000570 sec\n",
      "backward time 0.005301 sec\n",
      "optimizer time 0.014130 sec\n",
      "training time in round 322 cost 0.36368274688720703 sec\n",
      "loss 2.318371, train acc 0.096217\n",
      "round 323\n",
      "time to device 0.004817 sec\n",
      "time forward 4.047440 sec\n",
      "loss time 0.001907 sec\n",
      "backward time 0.013463 sec\n",
      "optimizer time 0.025163 sec\n",
      "training time in round 323 cost 0.38819289207458496 sec\n",
      "loss 2.318316, train acc 0.096234\n",
      "round 324\n",
      "time to device 0.004534 sec\n",
      "time forward 4.059617 sec\n",
      "loss time 0.001901 sec\n",
      "backward time 0.013503 sec\n",
      "optimizer time 0.023780 sec\n",
      "training time in round 324 cost 0.383939266204834 sec\n",
      "loss 2.318277, train acc 0.096274\n",
      "round 325\n",
      "time to device 0.003909 sec\n",
      "time forward 4.073842 sec\n",
      "loss time 0.001949 sec\n",
      "backward time 0.013826 sec\n",
      "optimizer time 0.026637 sec\n",
      "training time in round 325 cost 0.396359920501709 sec\n",
      "loss 2.318186, train acc 0.096314\n",
      "round 326\n",
      "time to device 0.003518 sec\n",
      "time forward 4.086776 sec\n",
      "loss time 0.001439 sec\n",
      "backward time 0.010985 sec\n",
      "optimizer time 0.022636 sec\n",
      "training time in round 326 cost 0.38492703437805176 sec\n",
      "loss 2.318121, train acc 0.096330\n",
      "round 327\n",
      "time to device 0.003449 sec\n",
      "time forward 4.098020 sec\n",
      "loss time 0.001309 sec\n",
      "backward time 0.012496 sec\n",
      "optimizer time 0.028757 sec\n",
      "training time in round 327 cost 0.3925330638885498 sec\n",
      "loss 2.318062, train acc 0.096370\n",
      "round 328\n",
      "time to device 0.003812 sec\n",
      "time forward 4.110470 sec\n",
      "loss time 0.001176 sec\n",
      "backward time 0.011121 sec\n",
      "optimizer time 0.027679 sec\n",
      "training time in round 328 cost 0.3888559341430664 sec\n",
      "loss 2.318011, train acc 0.096338\n",
      "round 329\n",
      "time to device 0.003969 sec\n",
      "time forward 4.125278 sec\n",
      "loss time 0.001900 sec\n",
      "backward time 0.013121 sec\n",
      "optimizer time 0.023949 sec\n",
      "training time in round 329 cost 0.4002659320831299 sec\n",
      "loss 2.317964, train acc 0.096354\n",
      "round 330\n",
      "time to device 0.005155 sec\n",
      "time forward 4.137505 sec\n",
      "loss time 0.001552 sec\n",
      "backward time 0.015690 sec\n",
      "optimizer time 0.026220 sec\n",
      "training time in round 330 cost 0.3873920440673828 sec\n",
      "loss 2.317904, train acc 0.096488\n",
      "round 331\n",
      "time to device 0.003904 sec\n",
      "time forward 4.151164 sec\n",
      "loss time 0.001332 sec\n",
      "backward time 0.012449 sec\n",
      "optimizer time 0.012031 sec\n",
      "training time in round 331 cost 0.3858628273010254 sec\n",
      "loss 2.317855, train acc 0.096621\n",
      "round 332\n",
      "time to device 0.003688 sec\n",
      "time forward 4.165902 sec\n",
      "loss time 0.001488 sec\n",
      "backward time 0.014268 sec\n",
      "optimizer time 0.026797 sec\n",
      "training time in round 332 cost 0.4293961524963379 sec\n",
      "loss 2.317802, train acc 0.096612\n",
      "round 333\n",
      "time to device 0.010439 sec\n",
      "time forward 4.181762 sec\n",
      "loss time 0.001619 sec\n",
      "backward time 0.013217 sec\n",
      "optimizer time 0.024661 sec\n",
      "training time in round 333 cost 0.4128878116607666 sec\n",
      "loss 2.317894, train acc 0.096627\n",
      "round 334\n",
      "time to device 0.007378 sec\n",
      "time forward 4.195340 sec\n",
      "loss time 0.001906 sec\n",
      "backward time 0.014378 sec\n",
      "optimizer time 0.030495 sec\n",
      "training time in round 334 cost 0.40259480476379395 sec\n",
      "loss 2.317904, train acc 0.096688\n",
      "round 335\n",
      "time to device 0.009259 sec\n",
      "time forward 4.207214 sec\n",
      "loss time 0.001514 sec\n",
      "backward time 0.012669 sec\n",
      "optimizer time 0.026386 sec\n",
      "training time in round 335 cost 0.39051389694213867 sec\n",
      "loss 2.318115, train acc 0.096703\n",
      "round 336\n",
      "time to device 0.007162 sec\n",
      "time forward 4.221695 sec\n",
      "loss time 0.001492 sec\n",
      "backward time 0.012416 sec\n",
      "optimizer time 0.024437 sec\n",
      "training time in round 336 cost 0.39353108406066895 sec\n",
      "loss 2.318101, train acc 0.096764\n",
      "round 337\n",
      "time to device 0.008682 sec\n",
      "time forward 4.232114 sec\n",
      "loss time 0.001099 sec\n",
      "backward time 0.009316 sec\n",
      "optimizer time 0.019935 sec\n",
      "training time in round 337 cost 0.36968493461608887 sec\n",
      "loss 2.318059, train acc 0.096662\n",
      "round 338\n",
      "time to device 0.008233 sec\n",
      "time forward 4.245100 sec\n",
      "loss time 0.001195 sec\n",
      "backward time 0.012020 sec\n",
      "optimizer time 0.024141 sec\n",
      "training time in round 338 cost 0.38670802116394043 sec\n",
      "loss 2.318154, train acc 0.096723\n",
      "round 339\n",
      "time to device 0.008751 sec\n",
      "time forward 4.257880 sec\n",
      "loss time 0.001506 sec\n",
      "backward time 0.013312 sec\n",
      "optimizer time 0.023480 sec\n",
      "training time in round 339 cost 0.40616393089294434 sec\n",
      "loss 2.318093, train acc 0.096852\n",
      "round 340\n",
      "time to device 0.009297 sec\n",
      "time forward 4.270758 sec\n",
      "loss time 0.001093 sec\n",
      "backward time 0.011582 sec\n",
      "optimizer time 0.028798 sec\n",
      "training time in round 340 cost 0.39183473587036133 sec\n",
      "loss 2.318067, train acc 0.096912\n",
      "round 341\n",
      "time to device 0.009162 sec\n",
      "time forward 4.284968 sec\n",
      "loss time 0.001674 sec\n",
      "backward time 0.019646 sec\n",
      "optimizer time 0.021357 sec\n",
      "training time in round 341 cost 0.4027268886566162 sec\n",
      "loss 2.318050, train acc 0.096857\n",
      "round 342\n",
      "time to device 0.007522 sec\n",
      "time forward 4.298814 sec\n",
      "loss time 0.001526 sec\n",
      "backward time 0.012125 sec\n",
      "optimizer time 0.023839 sec\n",
      "training time in round 342 cost 0.39046216011047363 sec\n",
      "loss 2.318003, train acc 0.096939\n",
      "round 343\n",
      "time to device 0.006377 sec\n",
      "time forward 4.311730 sec\n",
      "loss time 0.001608 sec\n",
      "backward time 0.013871 sec\n",
      "optimizer time 0.023854 sec\n",
      "training time in round 343 cost 0.40448999404907227 sec\n",
      "loss 2.317971, train acc 0.096861\n",
      "round 344\n",
      "time to device 0.013074 sec\n",
      "time forward 4.326975 sec\n",
      "loss time 0.001133 sec\n",
      "backward time 0.012296 sec\n",
      "optimizer time 0.027457 sec\n",
      "training time in round 344 cost 0.40814208984375 sec\n",
      "loss 2.317925, train acc 0.096943\n",
      "round 345\n",
      "time to device 0.004534 sec\n",
      "time forward 4.338945 sec\n",
      "loss time 0.001862 sec\n",
      "backward time 0.013064 sec\n",
      "optimizer time 0.026567 sec\n",
      "training time in round 345 cost 0.392697811126709 sec\n",
      "loss 2.317906, train acc 0.096821\n",
      "round 346\n",
      "time to device 0.004826 sec\n",
      "time forward 4.351346 sec\n",
      "loss time 0.001843 sec\n",
      "backward time 0.013671 sec\n",
      "optimizer time 0.024793 sec\n",
      "training time in round 346 cost 0.3885321617126465 sec\n",
      "loss 2.317854, train acc 0.096902\n",
      "round 347\n",
      "time to device 0.003933 sec\n",
      "time forward 4.363451 sec\n",
      "loss time 0.001906 sec\n",
      "backward time 0.013208 sec\n",
      "optimizer time 0.025330 sec\n",
      "training time in round 347 cost 0.3913130760192871 sec\n",
      "loss 2.317825, train acc 0.096803\n",
      "round 348\n",
      "time to device 0.004342 sec\n",
      "time forward 4.376093 sec\n",
      "loss time 0.001263 sec\n",
      "backward time 0.014903 sec\n",
      "optimizer time 0.025258 sec\n",
      "training time in round 348 cost 0.40033912658691406 sec\n",
      "loss 2.317914, train acc 0.096817\n",
      "round 349\n",
      "time to device 0.003895 sec\n",
      "time forward 4.390098 sec\n",
      "loss time 0.001911 sec\n",
      "backward time 0.013970 sec\n",
      "optimizer time 0.024639 sec\n",
      "training time in round 349 cost 0.3987739086151123 sec\n",
      "loss 2.317855, train acc 0.096897\n",
      "round 350\n",
      "time to device 0.003423 sec\n",
      "time forward 4.403532 sec\n",
      "loss time 0.001726 sec\n",
      "backward time 0.011927 sec\n",
      "optimizer time 0.023569 sec\n",
      "training time in round 350 cost 0.3990781307220459 sec\n",
      "loss 2.317810, train acc 0.097000\n",
      "round 351\n",
      "time to device 0.004005 sec\n",
      "time forward 4.417378 sec\n",
      "loss time 0.001321 sec\n",
      "backward time 0.014728 sec\n",
      "optimizer time 0.026186 sec\n",
      "training time in round 351 cost 0.3990659713745117 sec\n",
      "loss 2.317773, train acc 0.096990\n",
      "round 352\n",
      "time to device 0.003863 sec\n",
      "time forward 4.430974 sec\n",
      "loss time 0.001483 sec\n",
      "backward time 0.012868 sec\n",
      "optimizer time 0.023584 sec\n",
      "training time in round 352 cost 0.3947591781616211 sec\n",
      "loss 2.317730, train acc 0.097092\n",
      "round 353\n",
      "time to device 0.004109 sec\n",
      "time forward 4.443029 sec\n",
      "loss time 0.001532 sec\n",
      "backward time 0.014136 sec\n",
      "optimizer time 0.027185 sec\n",
      "training time in round 353 cost 0.39293909072875977 sec\n",
      "loss 2.317750, train acc 0.097060\n",
      "round 354\n",
      "time to device 0.004536 sec\n",
      "time forward 4.455621 sec\n",
      "loss time 0.001486 sec\n",
      "backward time 0.012686 sec\n",
      "optimizer time 0.023637 sec\n",
      "training time in round 354 cost 0.39629316329956055 sec\n",
      "loss 2.317698, train acc 0.097117\n",
      "round 355\n",
      "time to device 0.003959 sec\n",
      "time forward 4.469655 sec\n",
      "loss time 0.001798 sec\n",
      "backward time 0.013391 sec\n",
      "optimizer time 0.024632 sec\n",
      "training time in round 355 cost 0.3972163200378418 sec\n",
      "loss 2.317642, train acc 0.097152\n",
      "round 356\n",
      "time to device 0.003782 sec\n",
      "time forward 4.483951 sec\n",
      "loss time 0.001926 sec\n",
      "backward time 0.014340 sec\n",
      "optimizer time 0.026935 sec\n",
      "training time in round 356 cost 0.408527135848999 sec\n",
      "loss 2.317589, train acc 0.097142\n",
      "round 357\n",
      "time to device 0.004350 sec\n",
      "time forward 4.498623 sec\n",
      "loss time 0.002461 sec\n",
      "backward time 0.010657 sec\n",
      "optimizer time 0.022885 sec\n",
      "training time in round 357 cost 0.4018850326538086 sec\n",
      "loss 2.317562, train acc 0.097023\n",
      "round 358\n",
      "time to device 0.003603 sec\n",
      "time forward 4.512602 sec\n",
      "loss time 0.001363 sec\n",
      "backward time 0.012590 sec\n",
      "optimizer time 0.024118 sec\n",
      "training time in round 358 cost 0.3995800018310547 sec\n",
      "loss 2.317525, train acc 0.097058\n",
      "round 359\n",
      "time to device 0.004342 sec\n",
      "time forward 4.525714 sec\n",
      "loss time 0.001301 sec\n",
      "backward time 0.012612 sec\n",
      "optimizer time 0.026771 sec\n",
      "training time in round 359 cost 0.3937821388244629 sec\n",
      "loss 2.317510, train acc 0.097070\n",
      "round 360\n",
      "time to device 0.003961 sec\n",
      "time forward 4.539541 sec\n",
      "loss time 0.001454 sec\n",
      "backward time 0.012544 sec\n",
      "optimizer time 0.018390 sec\n",
      "training time in round 360 cost 0.40941596031188965 sec\n",
      "loss 2.317460, train acc 0.097126\n",
      "round 361\n",
      "time to device 0.004274 sec\n",
      "time forward 4.554460 sec\n",
      "loss time 0.001166 sec\n",
      "backward time 0.011705 sec\n",
      "optimizer time 0.025068 sec\n",
      "training time in round 361 cost 0.4695010185241699 sec\n",
      "loss 2.317432, train acc 0.097074\n",
      "round 362\n",
      "time to device 0.007473 sec\n",
      "time forward 4.567318 sec\n",
      "loss time 0.000869 sec\n",
      "backward time 0.007487 sec\n",
      "optimizer time 0.019065 sec\n",
      "training time in round 362 cost 0.3787851333618164 sec\n",
      "loss 2.317379, train acc 0.097107\n",
      "round 363\n",
      "time to device 0.006978 sec\n",
      "time forward 4.580285 sec\n",
      "loss time 0.001534 sec\n",
      "backward time 0.019256 sec\n",
      "optimizer time 0.021586 sec\n",
      "training time in round 363 cost 0.3898649215698242 sec\n",
      "loss 2.317362, train acc 0.096969\n",
      "round 364\n",
      "time to device 0.009661 sec\n",
      "time forward 4.586931 sec\n",
      "loss time 0.000647 sec\n",
      "backward time 0.005883 sec\n",
      "optimizer time 0.014949 sec\n",
      "training time in round 364 cost 0.3716890811920166 sec\n",
      "loss 2.317327, train acc 0.096939\n",
      "round 365\n",
      "time to device 0.009501 sec\n",
      "time forward 4.599978 sec\n",
      "loss time 0.001210 sec\n",
      "backward time 0.012442 sec\n",
      "optimizer time 0.015034 sec\n",
      "training time in round 365 cost 0.3781309127807617 sec\n",
      "loss 2.317256, train acc 0.096973\n",
      "round 366\n",
      "time to device 0.010470 sec\n",
      "time forward 4.614643 sec\n",
      "loss time 0.001509 sec\n",
      "backward time 0.013439 sec\n",
      "optimizer time 0.023587 sec\n",
      "training time in round 366 cost 0.4002039432525635 sec\n",
      "loss 2.317221, train acc 0.096858\n",
      "round 367\n",
      "time to device 0.005681 sec\n",
      "time forward 4.624132 sec\n",
      "loss time 0.001240 sec\n",
      "backward time 0.013546 sec\n",
      "optimizer time 0.024367 sec\n",
      "training time in round 367 cost 0.3750598430633545 sec\n",
      "loss 2.317184, train acc 0.096850\n",
      "round 368\n",
      "time to device 0.009785 sec\n",
      "time forward 4.636845 sec\n",
      "loss time 0.001473 sec\n",
      "backward time 0.013968 sec\n",
      "optimizer time 0.027536 sec\n",
      "training time in round 368 cost 0.4126288890838623 sec\n",
      "loss 2.317155, train acc 0.096778\n",
      "round 369\n",
      "time to device 0.005626 sec\n",
      "time forward 4.645213 sec\n",
      "loss time 0.001127 sec\n",
      "backward time 0.008297 sec\n",
      "optimizer time 0.020019 sec\n",
      "training time in round 369 cost 0.38140416145324707 sec\n",
      "loss 2.317123, train acc 0.096727\n",
      "round 370\n",
      "time to device 0.006616 sec\n",
      "time forward 4.660364 sec\n",
      "loss time 0.001467 sec\n",
      "backward time 0.017137 sec\n",
      "optimizer time 0.021955 sec\n",
      "training time in round 370 cost 0.40331006050109863 sec\n",
      "loss 2.317093, train acc 0.096740\n",
      "round 371\n",
      "time to device 0.004338 sec\n",
      "time forward 4.673113 sec\n",
      "loss time 0.001600 sec\n",
      "backward time 0.013367 sec\n",
      "optimizer time 0.023572 sec\n",
      "training time in round 371 cost 0.3986787796020508 sec\n",
      "loss 2.317054, train acc 0.096774\n",
      "round 372\n",
      "time to device 0.003400 sec\n",
      "time forward 4.679435 sec\n",
      "loss time 0.001103 sec\n",
      "backward time 0.008267 sec\n",
      "optimizer time 0.018411 sec\n",
      "training time in round 372 cost 0.33916401863098145 sec\n",
      "loss 2.317024, train acc 0.096829\n",
      "round 373\n",
      "time to device 0.004247 sec\n",
      "time forward 4.693523 sec\n",
      "loss time 0.001945 sec\n",
      "backward time 0.014117 sec\n",
      "optimizer time 0.025546 sec\n",
      "training time in round 373 cost 0.39256882667541504 sec\n",
      "loss 2.316994, train acc 0.096904\n",
      "round 374\n",
      "time to device 0.003468 sec\n",
      "time forward 4.706679 sec\n",
      "loss time 0.001890 sec\n",
      "backward time 0.014650 sec\n",
      "optimizer time 0.026202 sec\n",
      "training time in round 374 cost 0.38700294494628906 sec\n",
      "loss 2.316947, train acc 0.096958\n",
      "round 375\n",
      "time to device 0.005835 sec\n",
      "time forward 4.719195 sec\n",
      "loss time 0.001946 sec\n",
      "backward time 0.013074 sec\n",
      "optimizer time 0.024452 sec\n",
      "training time in round 375 cost 0.3901667594909668 sec\n",
      "loss 2.316914, train acc 0.096950\n",
      "round 376\n",
      "time to device 0.003555 sec\n",
      "time forward 4.731079 sec\n",
      "loss time 0.001771 sec\n",
      "backward time 0.014171 sec\n",
      "optimizer time 0.024344 sec\n",
      "training time in round 376 cost 0.38456296920776367 sec\n",
      "loss 2.316896, train acc 0.097003\n",
      "round 377\n",
      "time to device 0.004042 sec\n",
      "time forward 4.746750 sec\n",
      "loss time 0.001456 sec\n",
      "backward time 0.014987 sec\n",
      "optimizer time 0.024138 sec\n",
      "training time in round 377 cost 0.4028031826019287 sec\n",
      "loss 2.316864, train acc 0.096974\n",
      "round 378\n",
      "time to device 0.004965 sec\n",
      "time forward 4.759067 sec\n",
      "loss time 0.001400 sec\n",
      "backward time 0.013163 sec\n",
      "optimizer time 0.026200 sec\n",
      "training time in round 378 cost 0.4030301570892334 sec\n",
      "loss 2.316841, train acc 0.096904\n",
      "round 379\n",
      "time to device 0.003486 sec\n",
      "time forward 4.773971 sec\n",
      "loss time 0.001279 sec\n",
      "backward time 0.016317 sec\n",
      "optimizer time 0.023424 sec\n",
      "training time in round 379 cost 0.38863515853881836 sec\n",
      "loss 2.316802, train acc 0.096957\n",
      "round 380\n",
      "time to device 0.003569 sec\n",
      "time forward 4.789912 sec\n",
      "loss time 0.002597 sec\n",
      "backward time 0.012406 sec\n",
      "optimizer time 0.027948 sec\n",
      "training time in round 380 cost 0.4016268253326416 sec\n",
      "loss 2.316761, train acc 0.096990\n",
      "round 381\n",
      "time to device 0.004769 sec\n",
      "time forward 4.802705 sec\n",
      "loss time 0.001656 sec\n",
      "backward time 0.011596 sec\n",
      "optimizer time 0.023884 sec\n",
      "training time in round 381 cost 0.4025099277496338 sec\n",
      "loss 2.316727, train acc 0.096940\n",
      "round 382\n",
      "time to device 0.003575 sec\n",
      "time forward 4.817680 sec\n",
      "loss time 0.001527 sec\n",
      "backward time 0.012694 sec\n",
      "optimizer time 0.023863 sec\n",
      "training time in round 382 cost 0.38937902450561523 sec\n",
      "loss 2.316692, train acc 0.096891\n",
      "round 383\n",
      "time to device 0.003614 sec\n",
      "time forward 4.833191 sec\n",
      "loss time 0.001274 sec\n",
      "backward time 0.014147 sec\n",
      "optimizer time 0.024821 sec\n",
      "training time in round 383 cost 0.39376401901245117 sec\n",
      "loss 2.316654, train acc 0.096924\n",
      "round 384\n",
      "time to device 0.003114 sec\n",
      "time forward 4.845925 sec\n",
      "loss time 0.001905 sec\n",
      "backward time 0.012755 sec\n",
      "optimizer time 0.023035 sec\n",
      "training time in round 384 cost 0.3971400260925293 sec\n",
      "loss 2.316622, train acc 0.096895\n",
      "round 385\n",
      "time to device 0.003570 sec\n",
      "time forward 4.859611 sec\n",
      "loss time 0.001168 sec\n",
      "backward time 0.012192 sec\n",
      "optimizer time 0.023757 sec\n",
      "training time in round 385 cost 0.39156413078308105 sec\n",
      "loss 2.316578, train acc 0.096948\n",
      "round 386\n",
      "time to device 0.004222 sec\n",
      "time forward 4.873087 sec\n",
      "loss time 0.001754 sec\n",
      "backward time 0.013366 sec\n",
      "optimizer time 0.025381 sec\n",
      "training time in round 386 cost 0.39331698417663574 sec\n",
      "loss 2.316538, train acc 0.097061\n",
      "round 387\n",
      "time to device 0.006665 sec\n",
      "time forward 4.886359 sec\n",
      "loss time 0.001607 sec\n",
      "backward time 0.012528 sec\n",
      "optimizer time 0.024296 sec\n",
      "training time in round 387 cost 0.3923530578613281 sec\n",
      "loss 2.316496, train acc 0.097032\n",
      "round 388\n",
      "time to device 0.004236 sec\n",
      "time forward 4.902351 sec\n",
      "loss time 0.001354 sec\n",
      "backward time 0.012308 sec\n",
      "optimizer time 0.021968 sec\n",
      "training time in round 388 cost 0.39681220054626465 sec\n",
      "loss 2.316468, train acc 0.097024\n",
      "round 389\n",
      "time to device 0.005203 sec\n",
      "time forward 4.909010 sec\n",
      "loss time 0.000655 sec\n",
      "backward time 0.006228 sec\n",
      "optimizer time 0.015876 sec\n",
      "training time in round 389 cost 0.37285828590393066 sec\n",
      "loss 2.316433, train acc 0.097075\n",
      "round 390\n",
      "time to device 0.006897 sec\n",
      "time forward 4.922836 sec\n",
      "loss time 0.001527 sec\n",
      "backward time 0.018816 sec\n",
      "optimizer time 0.024380 sec\n",
      "training time in round 390 cost 0.39914584159851074 sec\n",
      "loss 2.316393, train acc 0.097127\n",
      "round 391\n",
      "time to device 0.009186 sec\n",
      "time forward 4.935771 sec\n",
      "loss time 0.001971 sec\n",
      "backward time 0.015149 sec\n",
      "optimizer time 0.026883 sec\n",
      "training time in round 391 cost 0.4088461399078369 sec\n",
      "loss 2.316357, train acc 0.097078\n",
      "round 392\n",
      "time to device 0.007048 sec\n",
      "time forward 4.950071 sec\n",
      "loss time 0.001620 sec\n",
      "backward time 0.014335 sec\n",
      "optimizer time 0.025036 sec\n",
      "training time in round 392 cost 0.39776611328125 sec\n",
      "loss 2.316325, train acc 0.097070\n",
      "round 393\n",
      "time to device 0.003364 sec\n",
      "time forward 4.963423 sec\n",
      "loss time 0.001902 sec\n",
      "backward time 0.012688 sec\n",
      "optimizer time 0.023469 sec\n",
      "training time in round 393 cost 0.39516520500183105 sec\n",
      "loss 2.316601, train acc 0.097061\n",
      "round 394\n",
      "time to device 0.004584 sec\n",
      "time forward 4.979254 sec\n",
      "loss time 0.001448 sec\n",
      "backward time 0.015172 sec\n",
      "optimizer time 0.025454 sec\n",
      "training time in round 394 cost 0.39798903465270996 sec\n",
      "loss 2.316560, train acc 0.097152\n",
      "round 395\n",
      "time to device 0.003824 sec\n",
      "time forward 4.993586 sec\n",
      "loss time 0.001542 sec\n",
      "backward time 0.009306 sec\n",
      "optimizer time 0.020773 sec\n",
      "training time in round 395 cost 0.41739988327026367 sec\n",
      "loss 2.316526, train acc 0.097084\n",
      "round 396\n",
      "time to device 0.005100 sec\n",
      "time forward 5.008218 sec\n",
      "loss time 0.002244 sec\n",
      "backward time 0.013054 sec\n",
      "optimizer time 0.024726 sec\n",
      "training time in round 396 cost 0.3946077823638916 sec\n",
      "loss 2.316497, train acc 0.097056\n",
      "round 397\n",
      "time to device 0.003431 sec\n",
      "time forward 5.022127 sec\n",
      "loss time 0.001244 sec\n",
      "backward time 0.013362 sec\n",
      "optimizer time 0.026097 sec\n",
      "training time in round 397 cost 0.3939199447631836 sec\n",
      "loss 2.316462, train acc 0.097067\n",
      "round 398\n",
      "time to device 0.004160 sec\n",
      "time forward 5.034513 sec\n",
      "loss time 0.001973 sec\n",
      "backward time 0.012984 sec\n",
      "optimizer time 0.023059 sec\n",
      "training time in round 398 cost 0.40398693084716797 sec\n",
      "loss 2.316429, train acc 0.097079\n",
      "round 399\n",
      "time to device 0.005041 sec\n",
      "time forward 5.051160 sec\n",
      "loss time 0.001734 sec\n",
      "backward time 0.013957 sec\n",
      "optimizer time 0.013856 sec\n",
      "training time in round 399 cost 0.4052469730377197 sec\n",
      "loss 2.316392, train acc 0.097109\n",
      "round 400\n",
      "time to device 0.003416 sec\n",
      "time forward 5.064516 sec\n",
      "loss time 0.001201 sec\n",
      "backward time 0.015822 sec\n",
      "optimizer time 0.024932 sec\n",
      "training time in round 400 cost 0.40552210807800293 sec\n",
      "loss 2.316355, train acc 0.097062\n",
      "round 401\n",
      "time to device 0.004201 sec\n",
      "time forward 5.080640 sec\n",
      "loss time 0.001681 sec\n",
      "backward time 0.015869 sec\n",
      "optimizer time 0.014784 sec\n",
      "training time in round 401 cost 0.4013819694519043 sec\n",
      "loss 2.316334, train acc 0.096937\n",
      "round 402\n",
      "time to device 0.003704 sec\n",
      "time forward 5.094254 sec\n",
      "loss time 0.001986 sec\n",
      "backward time 0.010145 sec\n",
      "optimizer time 0.026281 sec\n",
      "training time in round 402 cost 0.39180707931518555 sec\n",
      "loss 2.316305, train acc 0.096929\n",
      "round 403\n",
      "time to device 0.003358 sec\n",
      "time forward 5.106219 sec\n",
      "loss time 0.001813 sec\n",
      "backward time 0.013648 sec\n",
      "optimizer time 0.024414 sec\n",
      "training time in round 403 cost 0.38059306144714355 sec\n",
      "loss 2.316279, train acc 0.096941\n",
      "round 404\n",
      "time to device 0.004250 sec\n",
      "time forward 5.119460 sec\n",
      "loss time 0.002008 sec\n",
      "backward time 0.014399 sec\n",
      "optimizer time 0.025101 sec\n",
      "training time in round 404 cost 0.3892529010772705 sec\n",
      "loss 2.316250, train acc 0.096933\n",
      "round 405\n",
      "time to device 0.004547 sec\n",
      "time forward 5.132190 sec\n",
      "loss time 0.001404 sec\n",
      "backward time 0.013630 sec\n",
      "optimizer time 0.025169 sec\n",
      "training time in round 405 cost 0.3889768123626709 sec\n",
      "loss 2.316218, train acc 0.097002\n",
      "round 406\n",
      "time to device 0.004169 sec\n",
      "time forward 5.139776 sec\n",
      "loss time 0.000562 sec\n",
      "backward time 0.005036 sec\n",
      "optimizer time 0.012918 sec\n",
      "training time in round 406 cost 0.3487980365753174 sec\n",
      "loss 2.316196, train acc 0.096917\n",
      "round 407\n",
      "time to device 0.003000 sec\n",
      "time forward 5.152871 sec\n",
      "loss time 0.002216 sec\n",
      "backward time 0.013698 sec\n",
      "optimizer time 0.025392 sec\n",
      "training time in round 407 cost 0.38891077041625977 sec\n",
      "loss 2.316189, train acc 0.096948\n",
      "round 408\n",
      "time to device 0.003026 sec\n",
      "time forward 5.167659 sec\n",
      "loss time 0.001504 sec\n",
      "backward time 0.012726 sec\n",
      "optimizer time 0.023816 sec\n",
      "training time in round 408 cost 0.3928050994873047 sec\n",
      "loss 2.316158, train acc 0.096902\n",
      "round 409\n",
      "time to device 0.006553 sec\n",
      "time forward 5.180155 sec\n",
      "loss time 0.001495 sec\n",
      "backward time 0.012157 sec\n",
      "optimizer time 0.027863 sec\n",
      "training time in round 409 cost 0.3901021480560303 sec\n",
      "loss 2.316119, train acc 0.096951\n",
      "round 410\n",
      "time to device 0.004295 sec\n",
      "time forward 5.192773 sec\n",
      "loss time 0.001886 sec\n",
      "backward time 0.013975 sec\n",
      "optimizer time 0.025886 sec\n",
      "training time in round 410 cost 0.38942813873291016 sec\n",
      "loss 2.316082, train acc 0.097000\n",
      "round 411\n",
      "time to device 0.004263 sec\n",
      "time forward 5.205953 sec\n",
      "loss time 0.001777 sec\n",
      "backward time 0.011714 sec\n",
      "optimizer time 0.025129 sec\n",
      "training time in round 411 cost 0.3873269557952881 sec\n",
      "loss 2.316056, train acc 0.096955\n",
      "round 412\n",
      "time to device 0.004609 sec\n",
      "time forward 5.218583 sec\n",
      "loss time 0.001785 sec\n",
      "backward time 0.013205 sec\n",
      "optimizer time 0.025109 sec\n",
      "training time in round 412 cost 0.38666796684265137 sec\n",
      "loss 2.316019, train acc 0.097041\n",
      "round 413\n",
      "time to device 0.004531 sec\n",
      "time forward 5.232244 sec\n",
      "loss time 0.003664 sec\n",
      "backward time 0.012068 sec\n",
      "optimizer time 0.026564 sec\n",
      "training time in round 413 cost 0.3967921733856201 sec\n",
      "loss 2.315984, train acc 0.097090\n",
      "round 414\n",
      "time to device 0.003142 sec\n",
      "time forward 5.245185 sec\n",
      "loss time 0.001450 sec\n",
      "backward time 0.013790 sec\n",
      "optimizer time 0.025581 sec\n",
      "training time in round 414 cost 0.38753366470336914 sec\n",
      "loss 2.315908, train acc 0.097101\n",
      "round 415\n",
      "time to device 0.003490 sec\n",
      "time forward 5.258549 sec\n",
      "loss time 0.001965 sec\n",
      "backward time 0.015264 sec\n",
      "optimizer time 0.025522 sec\n",
      "training time in round 415 cost 0.391251802444458 sec\n",
      "loss 2.315874, train acc 0.097130\n",
      "round 416\n",
      "time to device 0.003475 sec\n",
      "time forward 5.273358 sec\n",
      "loss time 0.002064 sec\n",
      "backward time 0.013650 sec\n",
      "optimizer time 0.024186 sec\n",
      "training time in round 416 cost 0.3979358673095703 sec\n",
      "loss 2.315849, train acc 0.097122\n",
      "round 417\n",
      "time to device 0.004100 sec\n",
      "time forward 5.286305 sec\n",
      "loss time 0.001826 sec\n",
      "backward time 0.013481 sec\n",
      "optimizer time 0.024471 sec\n",
      "training time in round 417 cost 0.3894822597503662 sec\n",
      "loss 2.315823, train acc 0.097189\n",
      "round 418\n",
      "time to device 0.004872 sec\n",
      "time forward 5.299378 sec\n",
      "loss time 0.002009 sec\n",
      "backward time 0.011679 sec\n",
      "optimizer time 0.025536 sec\n",
      "training time in round 418 cost 0.38845205307006836 sec\n",
      "loss 2.315906, train acc 0.097106\n",
      "round 419\n",
      "time to device 0.003857 sec\n",
      "time forward 5.311952 sec\n",
      "loss time 0.002046 sec\n",
      "backward time 0.015607 sec\n",
      "optimizer time 0.026550 sec\n",
      "training time in round 419 cost 0.3887019157409668 sec\n",
      "loss 2.315870, train acc 0.097135\n",
      "round 420\n",
      "time to device 0.004326 sec\n",
      "time forward 5.325775 sec\n",
      "loss time 0.001677 sec\n",
      "backward time 0.012016 sec\n",
      "optimizer time 0.026719 sec\n",
      "training time in round 420 cost 0.3930690288543701 sec\n",
      "loss 2.316041, train acc 0.097202\n",
      "round 421\n",
      "time to device 0.003572 sec\n",
      "time forward 5.341496 sec\n",
      "loss time 0.001491 sec\n",
      "backward time 0.011657 sec\n",
      "optimizer time 0.022447 sec\n",
      "training time in round 421 cost 0.3906068801879883 sec\n",
      "loss 2.315999, train acc 0.097212\n",
      "round 422\n",
      "time to device 0.003380 sec\n",
      "time forward 5.348685 sec\n",
      "loss time 0.000641 sec\n",
      "backward time 0.005303 sec\n",
      "optimizer time 0.014133 sec\n",
      "training time in round 422 cost 0.3518400192260742 sec\n",
      "loss 2.315974, train acc 0.097130\n",
      "round 423\n",
      "time to device 0.002936 sec\n",
      "time forward 5.362296 sec\n",
      "loss time 0.001251 sec\n",
      "backward time 0.012368 sec\n",
      "optimizer time 0.025706 sec\n",
      "training time in round 423 cost 0.3892989158630371 sec\n",
      "loss 2.315944, train acc 0.097103\n",
      "round 424\n",
      "time to device 0.003964 sec\n",
      "time forward 5.374461 sec\n",
      "loss time 0.001902 sec\n",
      "backward time 0.009812 sec\n",
      "optimizer time 0.026410 sec\n",
      "training time in round 424 cost 0.382432222366333 sec\n",
      "loss 2.315925, train acc 0.096985\n",
      "round 425\n",
      "time to device 0.005695 sec\n",
      "time forward 5.387016 sec\n",
      "loss time 0.001134 sec\n",
      "backward time 0.012140 sec\n",
      "optimizer time 0.026461 sec\n",
      "training time in round 425 cost 0.389376163482666 sec\n",
      "loss 2.315874, train acc 0.097033\n",
      "round 426\n",
      "time to device 0.004605 sec\n",
      "time forward 5.403143 sec\n",
      "loss time 0.001344 sec\n",
      "backward time 0.014076 sec\n",
      "optimizer time 0.022071 sec\n",
      "training time in round 426 cost 0.4026002883911133 sec\n",
      "loss 2.315847, train acc 0.097007\n",
      "round 427\n",
      "time to device 0.003591 sec\n",
      "time forward 5.417794 sec\n",
      "loss time 0.001291 sec\n",
      "backward time 0.013172 sec\n",
      "optimizer time 0.025310 sec\n",
      "training time in round 427 cost 0.392780065536499 sec\n",
      "loss 2.315831, train acc 0.096999\n",
      "round 428\n",
      "time to device 0.003720 sec\n",
      "time forward 5.433094 sec\n",
      "loss time 0.002018 sec\n",
      "backward time 0.013876 sec\n",
      "optimizer time 0.024312 sec\n",
      "training time in round 428 cost 0.39623093605041504 sec\n",
      "loss 2.315804, train acc 0.097046\n",
      "round 429\n",
      "time to device 0.004394 sec\n",
      "time forward 5.446264 sec\n",
      "loss time 0.001213 sec\n",
      "backward time 0.011241 sec\n",
      "optimizer time 0.023817 sec\n",
      "training time in round 429 cost 0.3882262706756592 sec\n",
      "loss 2.315777, train acc 0.097166\n",
      "round 430\n",
      "time to device 0.004410 sec\n",
      "time forward 5.459297 sec\n",
      "loss time 0.001465 sec\n",
      "backward time 0.015212 sec\n",
      "optimizer time 0.024807 sec\n",
      "training time in round 430 cost 0.40114498138427734 sec\n",
      "loss 2.315741, train acc 0.097285\n",
      "round 431\n",
      "time to device 0.002768 sec\n",
      "time forward 5.473161 sec\n",
      "loss time 0.001584 sec\n",
      "backward time 0.011619 sec\n",
      "optimizer time 0.023499 sec\n",
      "training time in round 431 cost 0.42603111267089844 sec\n",
      "loss 2.316357, train acc 0.097295\n",
      "round 432\n",
      "time to device 0.003574 sec\n",
      "time forward 5.486466 sec\n",
      "loss time 0.001762 sec\n",
      "backward time 0.015374 sec\n",
      "optimizer time 0.027623 sec\n",
      "training time in round 432 cost 0.39181995391845703 sec\n",
      "loss 2.316326, train acc 0.097250\n",
      "round 433\n",
      "time to device 0.009538 sec\n",
      "time forward 5.493092 sec\n",
      "loss time 0.000591 sec\n",
      "backward time 0.005106 sec\n",
      "optimizer time 0.014205 sec\n",
      "training time in round 433 cost 0.35455799102783203 sec\n",
      "loss 2.316308, train acc 0.097260\n",
      "round 434\n",
      "time to device 0.007833 sec\n",
      "time forward 5.507568 sec\n",
      "loss time 0.001364 sec\n",
      "backward time 0.017163 sec\n",
      "optimizer time 0.010607 sec\n",
      "training time in round 434 cost 0.38618016242980957 sec\n",
      "loss 2.316289, train acc 0.097360\n",
      "round 435\n",
      "time to device 0.008495 sec\n",
      "time forward 5.521680 sec\n",
      "loss time 0.001404 sec\n",
      "backward time 0.012602 sec\n",
      "optimizer time 0.024304 sec\n",
      "training time in round 435 cost 0.40757203102111816 sec\n",
      "loss 2.316255, train acc 0.097370\n",
      "round 436\n",
      "time to device 0.009227 sec\n",
      "time forward 5.534382 sec\n",
      "loss time 0.001614 sec\n",
      "backward time 0.012325 sec\n",
      "optimizer time 0.022737 sec\n",
      "training time in round 436 cost 0.39563894271850586 sec\n",
      "loss 2.316229, train acc 0.097343\n",
      "round 437\n",
      "time to device 0.006951 sec\n",
      "time forward 5.548519 sec\n",
      "loss time 0.001700 sec\n",
      "backward time 0.015481 sec\n",
      "optimizer time 0.024370 sec\n",
      "training time in round 437 cost 0.39850616455078125 sec\n",
      "loss 2.316503, train acc 0.097282\n",
      "round 438\n",
      "time to device 0.006661 sec\n",
      "time forward 5.559143 sec\n",
      "loss time 0.001930 sec\n",
      "backward time 0.011245 sec\n",
      "optimizer time 0.028374 sec\n",
      "training time in round 438 cost 0.3797628879547119 sec\n",
      "loss 2.316469, train acc 0.097327\n",
      "round 439\n",
      "time to device 0.002975 sec\n",
      "time forward 5.573242 sec\n",
      "loss time 0.001983 sec\n",
      "backward time 0.011934 sec\n",
      "optimizer time 0.025079 sec\n",
      "training time in round 439 cost 0.3906700611114502 sec\n",
      "loss 2.316443, train acc 0.097301\n",
      "round 440\n",
      "time to device 0.003548 sec\n",
      "time forward 5.585713 sec\n",
      "loss time 0.001829 sec\n",
      "backward time 0.014986 sec\n",
      "optimizer time 0.026595 sec\n",
      "training time in round 440 cost 0.39051318168640137 sec\n",
      "loss 2.316413, train acc 0.097311\n",
      "round 441\n",
      "time to device 0.004408 sec\n",
      "time forward 5.599010 sec\n",
      "loss time 0.001920 sec\n",
      "backward time 0.015592 sec\n",
      "optimizer time 0.025766 sec\n",
      "training time in round 441 cost 0.386044979095459 sec\n",
      "loss 2.316387, train acc 0.097356\n",
      "round 442\n",
      "time to device 0.003869 sec\n",
      "time forward 5.612673 sec\n",
      "loss time 0.005120 sec\n",
      "backward time 0.011914 sec\n",
      "optimizer time 0.022682 sec\n",
      "training time in round 442 cost 0.3926510810852051 sec\n",
      "loss 2.316357, train acc 0.097436\n",
      "round 443\n",
      "time to device 0.002963 sec\n",
      "time forward 5.624589 sec\n",
      "loss time 0.001935 sec\n",
      "backward time 0.015416 sec\n",
      "optimizer time 0.027087 sec\n",
      "training time in round 443 cost 0.3859248161315918 sec\n",
      "loss 2.316328, train acc 0.097428\n",
      "round 444\n",
      "time to device 0.004139 sec\n",
      "time forward 5.631978 sec\n",
      "loss time 0.000611 sec\n",
      "backward time 0.005488 sec\n",
      "optimizer time 0.014443 sec\n",
      "training time in round 444 cost 0.3518970012664795 sec\n",
      "loss 2.316363, train acc 0.097384\n",
      "round 445\n",
      "time to device 0.005918 sec\n",
      "time forward 5.646194 sec\n",
      "loss time 0.001860 sec\n",
      "backward time 0.013516 sec\n",
      "optimizer time 0.025527 sec\n",
      "training time in round 445 cost 0.3933088779449463 sec\n",
      "loss 2.316349, train acc 0.097323\n",
      "round 446\n",
      "time to device 0.003152 sec\n",
      "time forward 5.658823 sec\n",
      "loss time 0.001166 sec\n",
      "backward time 0.011334 sec\n",
      "optimizer time 0.025918 sec\n",
      "training time in round 446 cost 0.38294386863708496 sec\n",
      "loss 2.316638, train acc 0.097368\n",
      "round 447\n",
      "time to device 0.004640 sec\n",
      "time forward 5.672204 sec\n",
      "loss time 0.001952 sec\n",
      "backward time 0.014103 sec\n",
      "optimizer time 0.025771 sec\n",
      "training time in round 447 cost 0.39228010177612305 sec\n",
      "loss 2.316723, train acc 0.097395\n",
      "round 448\n",
      "time to device 0.006029 sec\n",
      "time forward 5.686104 sec\n",
      "loss time 0.001598 sec\n",
      "backward time 0.013189 sec\n",
      "optimizer time 0.023831 sec\n",
      "training time in round 448 cost 0.39290499687194824 sec\n",
      "loss 2.316775, train acc 0.097334\n",
      "round 449\n",
      "time to device 0.003967 sec\n",
      "time forward 5.699588 sec\n",
      "loss time 0.000902 sec\n",
      "backward time 0.012550 sec\n",
      "optimizer time 0.022233 sec\n",
      "training time in round 449 cost 0.3848841190338135 sec\n",
      "loss 2.316764, train acc 0.097344\n",
      "round 450\n",
      "time to device 0.003345 sec\n",
      "time forward 5.712204 sec\n",
      "loss time 0.001965 sec\n",
      "backward time 0.014696 sec\n",
      "optimizer time 0.026902 sec\n",
      "training time in round 450 cost 0.38634324073791504 sec\n",
      "loss 2.316731, train acc 0.097405\n",
      "round 451\n",
      "time to device 0.004173 sec\n",
      "time forward 5.725462 sec\n",
      "loss time 0.001884 sec\n",
      "backward time 0.014039 sec\n",
      "optimizer time 0.025414 sec\n",
      "training time in round 451 cost 0.39038896560668945 sec\n",
      "loss 2.317191, train acc 0.097345\n",
      "round 452\n",
      "time to device 0.003155 sec\n",
      "time forward 5.739757 sec\n",
      "loss time 0.001572 sec\n",
      "backward time 0.012388 sec\n",
      "optimizer time 0.023677 sec\n",
      "training time in round 452 cost 0.39516186714172363 sec\n",
      "loss 2.317158, train acc 0.097354\n",
      "round 453\n",
      "time to device 0.003491 sec\n",
      "time forward 5.753214 sec\n",
      "loss time 0.001179 sec\n",
      "backward time 0.010663 sec\n",
      "optimizer time 0.026472 sec\n",
      "training time in round 453 cost 0.3857390880584717 sec\n",
      "loss 2.317128, train acc 0.097278\n",
      "round 454\n",
      "time to device 0.003323 sec\n",
      "time forward 5.767561 sec\n",
      "loss time 0.002025 sec\n",
      "backward time 0.014083 sec\n",
      "optimizer time 0.025530 sec\n",
      "training time in round 454 cost 0.39667582511901855 sec\n",
      "loss 2.317090, train acc 0.097424\n",
      "round 455\n",
      "time to device 0.003872 sec\n",
      "time forward 5.780530 sec\n",
      "loss time 0.001863 sec\n",
      "backward time 0.013401 sec\n",
      "optimizer time 0.027281 sec\n",
      "training time in round 455 cost 0.3946952819824219 sec\n",
      "loss 2.317073, train acc 0.097382\n",
      "round 456\n",
      "time to device 0.006516 sec\n",
      "time forward 5.791643 sec\n",
      "loss time 0.001387 sec\n",
      "backward time 0.016410 sec\n",
      "optimizer time 0.026799 sec\n",
      "training time in round 456 cost 0.38556909561157227 sec\n",
      "loss 2.317113, train acc 0.097357\n",
      "round 457\n",
      "time to device 0.003627 sec\n",
      "time forward 5.803882 sec\n",
      "loss time 0.001824 sec\n",
      "backward time 0.016141 sec\n",
      "optimizer time 0.016687 sec\n",
      "training time in round 457 cost 0.3898036479949951 sec\n",
      "loss 2.317082, train acc 0.097400\n",
      "round 458\n",
      "time to device 0.004255 sec\n",
      "time forward 5.817017 sec\n",
      "loss time 0.001253 sec\n",
      "backward time 0.018993 sec\n",
      "optimizer time 0.022399 sec\n",
      "training time in round 458 cost 0.41204404830932617 sec\n",
      "loss 2.317063, train acc 0.097324\n",
      "round 459\n",
      "time to device 0.004277 sec\n",
      "time forward 5.832252 sec\n",
      "loss time 0.001549 sec\n",
      "backward time 0.012059 sec\n",
      "optimizer time 0.023305 sec\n",
      "training time in round 459 cost 0.4096181392669678 sec\n",
      "loss 2.317001, train acc 0.097385\n",
      "round 460\n",
      "time to device 0.004537 sec\n",
      "time forward 5.846753 sec\n",
      "loss time 0.001576 sec\n",
      "backward time 0.012699 sec\n",
      "optimizer time 0.023573 sec\n",
      "training time in round 460 cost 0.3928260803222656 sec\n",
      "loss 2.316972, train acc 0.097394\n",
      "round 461\n",
      "time to device 0.003780 sec\n",
      "time forward 5.856160 sec\n",
      "loss time 0.000857 sec\n",
      "backward time 0.006980 sec\n",
      "optimizer time 0.017041 sec\n",
      "training time in round 461 cost 0.3497657775878906 sec\n",
      "loss 2.316930, train acc 0.097453\n",
      "round 462\n",
      "time to device 0.004962 sec\n",
      "time forward 5.869984 sec\n",
      "loss time 0.001444 sec\n",
      "backward time 0.012051 sec\n",
      "optimizer time 0.023435 sec\n",
      "training time in round 462 cost 0.3858449459075928 sec\n",
      "loss 2.316911, train acc 0.097412\n",
      "round 463\n",
      "time to device 0.003442 sec\n",
      "time forward 5.884077 sec\n",
      "loss time 0.001381 sec\n",
      "backward time 0.012039 sec\n",
      "optimizer time 0.022011 sec\n",
      "training time in round 463 cost 0.3826732635498047 sec\n",
      "loss 2.316991, train acc 0.097454\n",
      "round 464\n",
      "time to device 0.002606 sec\n",
      "time forward 5.891617 sec\n",
      "loss time 0.000646 sec\n",
      "backward time 0.007107 sec\n",
      "optimizer time 0.018060 sec\n",
      "training time in round 464 cost 0.3429839611053467 sec\n",
      "loss 2.316984, train acc 0.097480\n",
      "round 465\n",
      "time to device 0.004421 sec\n",
      "time forward 5.907890 sec\n",
      "loss time 0.001158 sec\n",
      "backward time 0.015199 sec\n",
      "optimizer time 0.025380 sec\n",
      "training time in round 465 cost 0.39994025230407715 sec\n",
      "loss 2.317275, train acc 0.097422\n",
      "round 466\n",
      "time to device 0.003502 sec\n",
      "time forward 5.923504 sec\n",
      "loss time 0.001459 sec\n",
      "backward time 0.011822 sec\n",
      "optimizer time 0.023096 sec\n",
      "training time in round 466 cost 0.3933279514312744 sec\n",
      "loss 2.317252, train acc 0.097447\n",
      "round 467\n",
      "time to device 0.003716 sec\n",
      "time forward 5.940140 sec\n",
      "loss time 0.001573 sec\n",
      "backward time 0.012102 sec\n",
      "optimizer time 0.024181 sec\n",
      "training time in round 467 cost 0.3921787738800049 sec\n",
      "loss 2.317222, train acc 0.097339\n",
      "round 468\n",
      "time to device 0.002797 sec\n",
      "time forward 5.960199 sec\n",
      "loss time 0.002658 sec\n",
      "backward time 0.017224 sec\n",
      "optimizer time 0.020423 sec\n",
      "training time in round 468 cost 0.3390798568725586 sec\n",
      "loss 2.317401, train acc 0.097283\n",
      "test acc is 0.100000\n",
      "epoch 7, time 3515.815309 sec\n",
      "epoch 9\n",
      "round 0\n",
      "time to device 0.058640 sec\n",
      "time forward 0.013162 sec\n",
      "loss time 0.004208 sec\n",
      "backward time 0.018600 sec\n",
      "optimizer time 0.024123 sec\n",
      "training time in round 0 cost 0.532351016998291 sec\n",
      "loss 2.302138, train acc 0.085938\n",
      "round 1\n",
      "time to device 0.004748 sec\n",
      "time forward 0.026168 sec\n",
      "loss time 0.001225 sec\n",
      "backward time 0.015234 sec\n",
      "optimizer time 0.026778 sec\n",
      "training time in round 1 cost 0.42626404762268066 sec\n",
      "loss 2.301081, train acc 0.078125\n",
      "round 2\n",
      "time to device 0.007721 sec\n",
      "time forward 0.044925 sec\n",
      "loss time 0.001719 sec\n",
      "backward time 0.012188 sec\n",
      "optimizer time 0.022891 sec\n",
      "training time in round 2 cost 0.4060549736022949 sec\n",
      "loss 2.302370, train acc 0.083333\n",
      "round 3\n",
      "time to device 0.008626 sec\n",
      "time forward 0.055965 sec\n",
      "loss time 0.001414 sec\n",
      "backward time 0.012832 sec\n",
      "optimizer time 0.024166 sec\n",
      "training time in round 3 cost 0.39964914321899414 sec\n",
      "loss 2.301054, train acc 0.089844\n",
      "round 4\n",
      "time to device 0.007578 sec\n",
      "time forward 0.069516 sec\n",
      "loss time 0.001982 sec\n",
      "backward time 0.017125 sec\n",
      "optimizer time 0.025450 sec\n",
      "training time in round 4 cost 0.40405774116516113 sec\n",
      "loss 2.300366, train acc 0.089063\n",
      "round 5\n",
      "time to device 0.008541 sec\n",
      "time forward 0.080387 sec\n",
      "loss time 0.000509 sec\n",
      "backward time 0.006706 sec\n",
      "optimizer time 0.019428 sec\n",
      "training time in round 5 cost 0.3988208770751953 sec\n",
      "loss 2.314078, train acc 0.080729\n",
      "round 6\n",
      "time to device 0.009319 sec\n",
      "time forward 0.092534 sec\n",
      "loss time 0.001959 sec\n",
      "backward time 0.027448 sec\n",
      "optimizer time 0.023444 sec\n",
      "training time in round 6 cost 0.4242990016937256 sec\n",
      "loss 2.315079, train acc 0.082589\n",
      "round 7\n",
      "time to device 0.006780 sec\n",
      "time forward 0.099278 sec\n",
      "loss time 0.000643 sec\n",
      "backward time 0.005839 sec\n",
      "optimizer time 0.015020 sec\n",
      "training time in round 7 cost 0.3668839931488037 sec\n",
      "loss 2.312890, train acc 0.084961\n",
      "round 8\n",
      "time to device 0.008766 sec\n",
      "time forward 0.113182 sec\n",
      "loss time 0.001398 sec\n",
      "backward time 0.012171 sec\n",
      "optimizer time 0.024079 sec\n",
      "training time in round 8 cost 0.4126288890838623 sec\n",
      "loss 2.311858, train acc 0.083333\n",
      "round 9\n",
      "time to device 0.008306 sec\n",
      "time forward 0.128932 sec\n",
      "loss time 0.001897 sec\n",
      "backward time 0.014716 sec\n",
      "optimizer time 0.025907 sec\n",
      "training time in round 9 cost 0.4476768970489502 sec\n",
      "loss 2.311624, train acc 0.087500\n",
      "round 10\n",
      "time to device 0.006657 sec\n",
      "time forward 0.143757 sec\n",
      "loss time 0.001430 sec\n",
      "backward time 0.013199 sec\n",
      "optimizer time 0.021734 sec\n",
      "training time in round 10 cost 0.39986205101013184 sec\n",
      "loss 2.309551, train acc 0.091619\n",
      "round 11\n",
      "time to device 0.003736 sec\n",
      "time forward 0.158277 sec\n",
      "loss time 0.001511 sec\n",
      "backward time 0.016046 sec\n",
      "optimizer time 0.026747 sec\n",
      "training time in round 11 cost 0.41963696479797363 sec\n",
      "loss 2.308682, train acc 0.095052\n",
      "round 12\n",
      "time to device 0.004492 sec\n",
      "time forward 0.170601 sec\n",
      "loss time 0.001363 sec\n",
      "backward time 0.012185 sec\n",
      "optimizer time 0.024631 sec\n",
      "training time in round 12 cost 0.39932918548583984 sec\n",
      "loss 2.308098, train acc 0.096755\n",
      "round 13\n",
      "time to device 0.004089 sec\n",
      "time forward 0.183236 sec\n",
      "loss time 0.001327 sec\n",
      "backward time 0.011259 sec\n",
      "optimizer time 0.025243 sec\n",
      "training time in round 13 cost 0.3833048343658447 sec\n",
      "loss 2.333030, train acc 0.098214\n",
      "round 14\n",
      "time to device 0.009692 sec\n",
      "time forward 0.195935 sec\n",
      "loss time 0.001445 sec\n",
      "backward time 0.018091 sec\n",
      "optimizer time 0.023447 sec\n",
      "training time in round 14 cost 0.3969237804412842 sec\n",
      "loss 2.331261, train acc 0.096875\n",
      "round 15\n",
      "time to device 0.009269 sec\n",
      "time forward 0.208433 sec\n",
      "loss time 0.001850 sec\n",
      "backward time 0.014104 sec\n",
      "optimizer time 0.014527 sec\n",
      "training time in round 15 cost 0.38318419456481934 sec\n",
      "loss 2.330285, train acc 0.097656\n",
      "round 16\n",
      "time to device 0.009229 sec\n",
      "time forward 0.220475 sec\n",
      "loss time 0.001061 sec\n",
      "backward time 0.009580 sec\n",
      "optimizer time 0.021791 sec\n",
      "training time in round 16 cost 0.4079101085662842 sec\n",
      "loss 2.328534, train acc 0.098346\n",
      "round 17\n",
      "time to device 0.006990 sec\n",
      "time forward 0.234848 sec\n",
      "loss time 0.002118 sec\n",
      "backward time 0.010167 sec\n",
      "optimizer time 0.020020 sec\n",
      "training time in round 17 cost 0.39927077293395996 sec\n",
      "loss 2.336372, train acc 0.096354\n",
      "round 18\n",
      "time to device 0.011469 sec\n",
      "time forward 0.248539 sec\n",
      "loss time 0.001675 sec\n",
      "backward time 0.016206 sec\n",
      "optimizer time 0.026610 sec\n",
      "training time in round 18 cost 0.40979719161987305 sec\n",
      "loss 2.334674, train acc 0.095395\n",
      "round 19\n",
      "time to device 0.008861 sec\n",
      "time forward 0.263174 sec\n",
      "loss time 0.001525 sec\n",
      "backward time 0.013143 sec\n",
      "optimizer time 0.024287 sec\n",
      "training time in round 19 cost 0.39948201179504395 sec\n",
      "loss 2.333042, train acc 0.096484\n",
      "round 20\n",
      "time to device 0.010512 sec\n",
      "time forward 0.276362 sec\n",
      "loss time 0.001944 sec\n",
      "backward time 0.015247 sec\n",
      "optimizer time 0.022720 sec\n",
      "training time in round 20 cost 0.39202189445495605 sec\n",
      "loss 2.331328, train acc 0.096354\n",
      "round 21\n",
      "time to device 0.008453 sec\n",
      "time forward 0.293365 sec\n",
      "loss time 0.001680 sec\n",
      "backward time 0.011366 sec\n",
      "optimizer time 0.023317 sec\n",
      "training time in round 21 cost 0.40549302101135254 sec\n",
      "loss 2.329961, train acc 0.094460\n",
      "round 22\n",
      "time to device 0.006621 sec\n",
      "time forward 0.306390 sec\n",
      "loss time 0.001434 sec\n",
      "backward time 0.015450 sec\n",
      "optimizer time 0.022477 sec\n",
      "training time in round 22 cost 0.39156413078308105 sec\n",
      "loss 2.328831, train acc 0.095109\n",
      "round 23\n",
      "time to device 0.009509 sec\n",
      "time forward 0.321429 sec\n",
      "loss time 0.002015 sec\n",
      "backward time 0.015084 sec\n",
      "optimizer time 0.023738 sec\n",
      "training time in round 23 cost 0.403698205947876 sec\n",
      "loss 2.329932, train acc 0.095703\n",
      "round 24\n",
      "time to device 0.007553 sec\n",
      "time forward 0.337294 sec\n",
      "loss time 0.002384 sec\n",
      "backward time 0.016759 sec\n",
      "optimizer time 0.026058 sec\n",
      "training time in round 24 cost 0.4483010768890381 sec\n",
      "loss 2.328780, train acc 0.094375\n",
      "round 25\n",
      "time to device 0.008030 sec\n",
      "time forward 0.354539 sec\n",
      "loss time 0.001241 sec\n",
      "backward time 0.012330 sec\n",
      "optimizer time 0.027980 sec\n",
      "training time in round 25 cost 0.4132270812988281 sec\n",
      "loss 2.328015, train acc 0.094351\n",
      "round 26\n",
      "time to device 0.009373 sec\n",
      "time forward 0.367534 sec\n",
      "loss time 0.001468 sec\n",
      "backward time 0.013344 sec\n",
      "optimizer time 0.025006 sec\n",
      "training time in round 26 cost 0.41092801094055176 sec\n",
      "loss 2.326840, train acc 0.094329\n",
      "round 27\n",
      "time to device 0.004636 sec\n",
      "time forward 0.378377 sec\n",
      "loss time 0.002040 sec\n",
      "backward time 0.013354 sec\n",
      "optimizer time 0.025484 sec\n",
      "training time in round 27 cost 0.39220499992370605 sec\n",
      "loss 2.325805, train acc 0.095424\n",
      "round 28\n",
      "time to device 0.008027 sec\n",
      "time forward 0.391065 sec\n",
      "loss time 0.001492 sec\n",
      "backward time 0.014578 sec\n",
      "optimizer time 0.025682 sec\n",
      "training time in round 28 cost 0.41362690925598145 sec\n",
      "loss 2.324996, train acc 0.095905\n",
      "round 29\n",
      "time to device 0.008648 sec\n",
      "time forward 0.401623 sec\n",
      "loss time 0.001727 sec\n",
      "backward time 0.012733 sec\n",
      "optimizer time 0.027127 sec\n",
      "training time in round 29 cost 0.3864278793334961 sec\n",
      "loss 2.324301, train acc 0.097917\n",
      "round 30\n",
      "time to device 0.009230 sec\n",
      "time forward 0.415663 sec\n",
      "loss time 0.001764 sec\n",
      "backward time 0.014111 sec\n",
      "optimizer time 0.025707 sec\n",
      "training time in round 30 cost 0.40459513664245605 sec\n",
      "loss 2.323627, train acc 0.098034\n",
      "round 31\n",
      "time to device 0.009186 sec\n",
      "time forward 0.427986 sec\n",
      "loss time 0.001561 sec\n",
      "backward time 0.011677 sec\n",
      "optimizer time 0.021670 sec\n",
      "training time in round 31 cost 0.40146684646606445 sec\n",
      "loss 2.322831, train acc 0.099121\n",
      "round 32\n",
      "time to device 0.006888 sec\n",
      "time forward 0.441143 sec\n",
      "loss time 0.001479 sec\n",
      "backward time 0.020796 sec\n",
      "optimizer time 0.022890 sec\n",
      "training time in round 32 cost 0.40262603759765625 sec\n",
      "loss 2.322293, train acc 0.099432\n",
      "round 33\n",
      "time to device 0.003388 sec\n",
      "time forward 0.453625 sec\n",
      "loss time 0.001645 sec\n",
      "backward time 0.011741 sec\n",
      "optimizer time 0.026196 sec\n",
      "training time in round 33 cost 0.40125226974487305 sec\n",
      "loss 2.321718, train acc 0.098805\n",
      "round 34\n",
      "time to device 0.003951 sec\n",
      "time forward 0.461020 sec\n",
      "loss time 0.000632 sec\n",
      "backward time 0.005555 sec\n",
      "optimizer time 0.014775 sec\n",
      "training time in round 34 cost 0.34721899032592773 sec\n",
      "loss 2.321355, train acc 0.097768\n",
      "round 35\n",
      "time to device 0.004340 sec\n",
      "time forward 0.475028 sec\n",
      "loss time 0.001514 sec\n",
      "backward time 0.016140 sec\n",
      "optimizer time 0.023686 sec\n",
      "training time in round 35 cost 0.39048290252685547 sec\n",
      "loss 2.321570, train acc 0.096788\n",
      "round 36\n",
      "time to device 0.002903 sec\n",
      "time forward 0.489704 sec\n",
      "loss time 0.001703 sec\n",
      "backward time 0.012907 sec\n",
      "optimizer time 0.021994 sec\n",
      "training time in round 36 cost 0.39553403854370117 sec\n",
      "loss 2.320957, train acc 0.096073\n",
      "round 37\n",
      "time to device 0.003497 sec\n",
      "time forward 0.503556 sec\n",
      "loss time 0.001901 sec\n",
      "backward time 0.014073 sec\n",
      "optimizer time 0.025996 sec\n",
      "training time in round 37 cost 0.4006168842315674 sec\n",
      "loss 2.320294, train acc 0.096628\n",
      "round 38\n",
      "time to device 0.004130 sec\n",
      "time forward 0.515940 sec\n",
      "loss time 0.001931 sec\n",
      "backward time 0.013628 sec\n",
      "optimizer time 0.017861 sec\n",
      "training time in round 38 cost 0.44663214683532715 sec\n",
      "loss 2.319888, train acc 0.096955\n",
      "round 39\n",
      "time to device 0.004365 sec\n",
      "time forward 0.529780 sec\n",
      "loss time 0.001882 sec\n",
      "backward time 0.014676 sec\n",
      "optimizer time 0.029911 sec\n",
      "training time in round 39 cost 0.4051027297973633 sec\n",
      "loss 2.319257, train acc 0.096094\n",
      "round 40\n",
      "time to device 0.007759 sec\n",
      "time forward 0.542394 sec\n",
      "loss time 0.001651 sec\n",
      "backward time 0.018543 sec\n",
      "optimizer time 0.023953 sec\n",
      "training time in round 40 cost 0.41190004348754883 sec\n",
      "loss 2.318822, train acc 0.096608\n",
      "round 41\n",
      "time to device 0.008598 sec\n",
      "time forward 0.549285 sec\n",
      "loss time 0.000544 sec\n",
      "backward time 0.005137 sec\n",
      "optimizer time 0.014027 sec\n",
      "training time in round 41 cost 0.3447999954223633 sec\n",
      "loss 2.318490, train acc 0.097470\n",
      "round 42\n",
      "time to device 0.007769 sec\n",
      "time forward 0.563062 sec\n",
      "loss time 0.001987 sec\n",
      "backward time 0.015859 sec\n",
      "optimizer time 0.024686 sec\n",
      "training time in round 42 cost 0.4200730323791504 sec\n",
      "loss 2.318188, train acc 0.096657\n",
      "round 43\n",
      "time to device 0.007507 sec\n",
      "time forward 0.576886 sec\n",
      "loss time 0.001976 sec\n",
      "backward time 0.014012 sec\n",
      "optimizer time 0.025107 sec\n",
      "training time in round 43 cost 0.39881110191345215 sec\n",
      "loss 2.317698, train acc 0.097834\n",
      "round 44\n",
      "time to device 0.010099 sec\n",
      "time forward 0.589709 sec\n",
      "loss time 0.002011 sec\n",
      "backward time 0.014486 sec\n",
      "optimizer time 0.024821 sec\n",
      "training time in round 44 cost 0.39382100105285645 sec\n",
      "loss 2.317583, train acc 0.097743\n",
      "round 45\n",
      "time to device 0.008586 sec\n",
      "time forward 0.603267 sec\n",
      "loss time 0.001949 sec\n",
      "backward time 0.015394 sec\n",
      "optimizer time 0.029101 sec\n",
      "training time in round 45 cost 0.42648792266845703 sec\n",
      "loss 2.317152, train acc 0.098336\n",
      "round 46\n",
      "time to device 0.008291 sec\n",
      "time forward 0.618175 sec\n",
      "loss time 0.001060 sec\n",
      "backward time 0.009515 sec\n",
      "optimizer time 0.027232 sec\n",
      "training time in round 46 cost 0.41295909881591797 sec\n",
      "loss 2.317175, train acc 0.098903\n",
      "round 47\n",
      "time to device 0.003905 sec\n",
      "time forward 0.624510 sec\n",
      "loss time 0.000359 sec\n",
      "backward time 0.003227 sec\n",
      "optimizer time 0.009888 sec\n",
      "training time in round 47 cost 0.34481000900268555 sec\n",
      "loss 2.319396, train acc 0.098958\n",
      "round 48\n",
      "time to device 0.003485 sec\n",
      "time forward 0.638755 sec\n",
      "loss time 0.001513 sec\n",
      "backward time 0.013800 sec\n",
      "optimizer time 0.026841 sec\n",
      "training time in round 48 cost 0.39510297775268555 sec\n",
      "loss 2.319008, train acc 0.098693\n",
      "round 49\n",
      "time to device 0.003583 sec\n",
      "time forward 0.649114 sec\n",
      "loss time 0.001593 sec\n",
      "backward time 0.013180 sec\n",
      "optimizer time 0.017570 sec\n",
      "training time in round 49 cost 0.3672647476196289 sec\n",
      "loss 2.319403, train acc 0.098437\n",
      "round 50\n",
      "time to device 0.003177 sec\n",
      "time forward 0.659674 sec\n",
      "loss time 0.001228 sec\n",
      "backward time 0.010515 sec\n",
      "optimizer time 0.021342 sec\n",
      "training time in round 50 cost 0.37268900871276855 sec\n",
      "loss 2.318936, train acc 0.100031\n",
      "round 51\n",
      "time to device 0.003636 sec\n",
      "time forward 0.673776 sec\n",
      "loss time 0.001227 sec\n",
      "backward time 0.011015 sec\n",
      "optimizer time 0.021894 sec\n",
      "training time in round 51 cost 0.39209914207458496 sec\n",
      "loss 2.318377, train acc 0.100210\n",
      "round 52\n",
      "time to device 0.006157 sec\n",
      "time forward 0.686829 sec\n",
      "loss time 0.001272 sec\n",
      "backward time 0.011393 sec\n",
      "optimizer time 0.025763 sec\n",
      "training time in round 52 cost 0.395251989364624 sec\n",
      "loss 2.318090, train acc 0.099941\n",
      "round 53\n",
      "time to device 0.009178 sec\n",
      "time forward 0.703494 sec\n",
      "loss time 0.001781 sec\n",
      "backward time 0.016252 sec\n",
      "optimizer time 0.026440 sec\n",
      "training time in round 53 cost 0.41164517402648926 sec\n",
      "loss 2.317812, train acc 0.099392\n",
      "round 54\n",
      "time to device 0.006481 sec\n",
      "time forward 0.717449 sec\n",
      "loss time 0.001449 sec\n",
      "backward time 0.011487 sec\n",
      "optimizer time 0.022519 sec\n",
      "training time in round 54 cost 0.3891897201538086 sec\n",
      "loss 2.317578, train acc 0.099148\n",
      "round 55\n",
      "time to device 0.003648 sec\n",
      "time forward 0.729475 sec\n",
      "loss time 0.001273 sec\n",
      "backward time 0.013261 sec\n",
      "optimizer time 0.025902 sec\n",
      "training time in round 55 cost 0.37979698181152344 sec\n",
      "loss 2.317416, train acc 0.098493\n",
      "round 56\n",
      "time to device 0.006248 sec\n",
      "time forward 0.741591 sec\n",
      "loss time 0.001143 sec\n",
      "backward time 0.015630 sec\n",
      "optimizer time 0.028226 sec\n",
      "training time in round 56 cost 0.3904688358306885 sec\n",
      "loss 2.317242, train acc 0.097999\n",
      "round 57\n",
      "time to device 0.005374 sec\n",
      "time forward 0.754673 sec\n",
      "loss time 0.001429 sec\n",
      "backward time 0.012115 sec\n",
      "optimizer time 0.025795 sec\n",
      "training time in round 57 cost 0.38495802879333496 sec\n",
      "loss 2.321479, train acc 0.097252\n",
      "round 58\n",
      "time to device 0.004339 sec\n",
      "time forward 0.761446 sec\n",
      "loss time 0.000509 sec\n",
      "backward time 0.004653 sec\n",
      "optimizer time 0.013162 sec\n",
      "training time in round 58 cost 0.34706807136535645 sec\n",
      "loss 2.321160, train acc 0.097458\n",
      "round 59\n",
      "time to device 0.003587 sec\n",
      "time forward 0.774794 sec\n",
      "loss time 0.002118 sec\n",
      "backward time 0.015444 sec\n",
      "optimizer time 0.025193 sec\n",
      "training time in round 59 cost 0.38933563232421875 sec\n",
      "loss 2.320732, train acc 0.098177\n",
      "round 60\n",
      "time to device 0.003773 sec\n",
      "time forward 0.790163 sec\n",
      "loss time 0.002035 sec\n",
      "backward time 0.014252 sec\n",
      "optimizer time 0.023469 sec\n",
      "training time in round 60 cost 0.39246606826782227 sec\n",
      "loss 2.321235, train acc 0.097720\n",
      "round 61\n",
      "time to device 0.003460 sec\n",
      "time forward 0.802948 sec\n",
      "loss time 0.000987 sec\n",
      "backward time 0.010754 sec\n",
      "optimizer time 0.026410 sec\n",
      "training time in round 61 cost 0.3882718086242676 sec\n",
      "loss 2.320951, train acc 0.097782\n",
      "round 62\n",
      "time to device 0.004241 sec\n",
      "time forward 0.816505 sec\n",
      "loss time 0.001046 sec\n",
      "backward time 0.010859 sec\n",
      "optimizer time 0.026898 sec\n",
      "training time in round 62 cost 0.39009690284729004 sec\n",
      "loss 2.320777, train acc 0.097842\n",
      "round 63\n",
      "time to device 0.003330 sec\n",
      "time forward 0.827798 sec\n",
      "loss time 0.001756 sec\n",
      "backward time 0.015689 sec\n",
      "optimizer time 0.026892 sec\n",
      "training time in round 63 cost 0.38753509521484375 sec\n",
      "loss 2.320404, train acc 0.097534\n",
      "round 64\n",
      "time to device 0.003627 sec\n",
      "time forward 0.840937 sec\n",
      "loss time 0.001287 sec\n",
      "backward time 0.014180 sec\n",
      "optimizer time 0.025253 sec\n",
      "training time in round 64 cost 0.39466309547424316 sec\n",
      "loss 2.323936, train acc 0.098678\n",
      "round 65\n",
      "time to device 0.003665 sec\n",
      "time forward 0.855029 sec\n",
      "loss time 0.001178 sec\n",
      "backward time 0.011543 sec\n",
      "optimizer time 0.021267 sec\n",
      "training time in round 65 cost 0.41408395767211914 sec\n",
      "loss 2.323521, train acc 0.098603\n",
      "round 66\n",
      "time to device 0.003833 sec\n",
      "time forward 0.868610 sec\n",
      "loss time 0.001280 sec\n",
      "backward time 0.014446 sec\n",
      "optimizer time 0.027673 sec\n",
      "training time in round 66 cost 0.3975710868835449 sec\n",
      "loss 2.323239, train acc 0.098414\n",
      "round 67\n",
      "time to device 0.005937 sec\n",
      "time forward 0.881883 sec\n",
      "loss time 0.001938 sec\n",
      "backward time 0.013078 sec\n",
      "optimizer time 0.025470 sec\n",
      "training time in round 67 cost 0.3903076648712158 sec\n",
      "loss 2.322847, train acc 0.098575\n",
      "round 68\n",
      "time to device 0.002752 sec\n",
      "time forward 0.896064 sec\n",
      "loss time 0.001413 sec\n",
      "backward time 0.017977 sec\n",
      "optimizer time 0.019734 sec\n",
      "training time in round 68 cost 0.39320993423461914 sec\n",
      "loss 2.322566, train acc 0.098392\n",
      "round 69\n",
      "time to device 0.003881 sec\n",
      "time forward 0.908484 sec\n",
      "loss time 0.001221 sec\n",
      "backward time 0.011136 sec\n",
      "optimizer time 0.027217 sec\n",
      "training time in round 69 cost 0.3861210346221924 sec\n",
      "loss 2.327122, train acc 0.098214\n",
      "round 70\n",
      "time to device 0.004375 sec\n",
      "time forward 0.922323 sec\n",
      "loss time 0.001999 sec\n",
      "backward time 0.012064 sec\n",
      "optimizer time 0.028335 sec\n",
      "training time in round 70 cost 0.40805721282958984 sec\n",
      "loss 2.326746, train acc 0.098151\n",
      "round 71\n",
      "time to device 0.004361 sec\n",
      "time forward 0.937273 sec\n",
      "loss time 0.001854 sec\n",
      "backward time 0.014898 sec\n",
      "optimizer time 0.022425 sec\n",
      "training time in round 71 cost 0.4012937545776367 sec\n",
      "loss 2.326163, train acc 0.099067\n",
      "round 72\n",
      "time to device 0.003907 sec\n",
      "time forward 0.950384 sec\n",
      "loss time 0.001093 sec\n",
      "backward time 0.014061 sec\n",
      "optimizer time 0.023498 sec\n",
      "training time in round 72 cost 0.396561861038208 sec\n",
      "loss 2.325962, train acc 0.099208\n",
      "round 73\n",
      "time to device 0.003881 sec\n",
      "time forward 0.964960 sec\n",
      "loss time 0.001598 sec\n",
      "backward time 0.013199 sec\n",
      "optimizer time 0.025579 sec\n",
      "training time in round 73 cost 0.40248918533325195 sec\n",
      "loss 2.325954, train acc 0.099029\n",
      "round 74\n",
      "time to device 0.003350 sec\n",
      "time forward 0.979046 sec\n",
      "loss time 0.002009 sec\n",
      "backward time 0.013978 sec\n",
      "optimizer time 0.024832 sec\n",
      "training time in round 74 cost 0.396557092666626 sec\n",
      "loss 2.325529, train acc 0.099896\n",
      "round 75\n",
      "time to device 0.004960 sec\n",
      "time forward 0.994173 sec\n",
      "loss time 0.001502 sec\n",
      "backward time 0.013536 sec\n",
      "optimizer time 0.024658 sec\n",
      "training time in round 75 cost 0.4041898250579834 sec\n",
      "loss 2.325234, train acc 0.100123\n",
      "round 76\n",
      "time to device 0.002911 sec\n",
      "time forward 1.007929 sec\n",
      "loss time 0.001896 sec\n",
      "backward time 0.012520 sec\n",
      "optimizer time 0.024681 sec\n",
      "training time in round 76 cost 0.3941779136657715 sec\n",
      "loss 2.325036, train acc 0.100041\n",
      "round 77\n",
      "time to device 0.003834 sec\n",
      "time forward 1.015021 sec\n",
      "loss time 0.000661 sec\n",
      "backward time 0.005912 sec\n",
      "optimizer time 0.014906 sec\n",
      "training time in round 77 cost 0.3600602149963379 sec\n",
      "loss 2.324827, train acc 0.099860\n",
      "round 78\n",
      "time to device 0.003440 sec\n",
      "time forward 1.028508 sec\n",
      "loss time 0.002082 sec\n",
      "backward time 0.013938 sec\n",
      "optimizer time 0.026276 sec\n",
      "training time in round 78 cost 0.39561915397644043 sec\n",
      "loss 2.324487, train acc 0.100178\n",
      "round 79\n",
      "time to device 0.004404 sec\n",
      "time forward 1.040276 sec\n",
      "loss time 0.001821 sec\n",
      "backward time 0.021770 sec\n",
      "optimizer time 0.024706 sec\n",
      "training time in round 79 cost 0.3987441062927246 sec\n",
      "loss 2.324229, train acc 0.100391\n",
      "round 80\n",
      "time to device 0.003097 sec\n",
      "time forward 1.052928 sec\n",
      "loss time 0.002112 sec\n",
      "backward time 0.015495 sec\n",
      "optimizer time 0.026848 sec\n",
      "training time in round 80 cost 0.40178680419921875 sec\n",
      "loss 2.323976, train acc 0.100694\n",
      "round 81\n",
      "time to device 0.003374 sec\n",
      "time forward 1.067425 sec\n",
      "loss time 0.001228 sec\n",
      "backward time 0.013283 sec\n",
      "optimizer time 0.025095 sec\n",
      "training time in round 81 cost 0.39663076400756836 sec\n",
      "loss 2.323764, train acc 0.100038\n",
      "round 82\n",
      "time to device 0.003798 sec\n",
      "time forward 1.074416 sec\n",
      "loss time 0.000552 sec\n",
      "backward time 0.005168 sec\n",
      "optimizer time 0.014171 sec\n",
      "training time in round 82 cost 0.34160304069519043 sec\n",
      "loss 2.323591, train acc 0.099586\n",
      "round 83\n",
      "time to device 0.002974 sec\n",
      "time forward 1.086056 sec\n",
      "loss time 0.001555 sec\n",
      "backward time 0.012585 sec\n",
      "optimizer time 0.025638 sec\n",
      "training time in round 83 cost 0.3818798065185547 sec\n",
      "loss 2.323376, train acc 0.099702\n",
      "round 84\n",
      "time to device 0.004143 sec\n",
      "time forward 1.098188 sec\n",
      "loss time 0.001906 sec\n",
      "backward time 0.012775 sec\n",
      "optimizer time 0.024938 sec\n",
      "training time in round 84 cost 0.3887758255004883 sec\n",
      "loss 2.323118, train acc 0.099449\n",
      "round 85\n",
      "time to device 0.004151 sec\n",
      "time forward 1.111806 sec\n",
      "loss time 0.002046 sec\n",
      "backward time 0.013696 sec\n",
      "optimizer time 0.025582 sec\n",
      "training time in round 85 cost 0.3903350830078125 sec\n",
      "loss 2.322990, train acc 0.099291\n",
      "round 86\n",
      "time to device 0.003657 sec\n",
      "time forward 1.124332 sec\n",
      "loss time 0.001138 sec\n",
      "backward time 0.013144 sec\n",
      "optimizer time 0.022141 sec\n",
      "training time in round 86 cost 0.3900868892669678 sec\n",
      "loss 2.322896, train acc 0.099138\n",
      "round 87\n",
      "time to device 0.004909 sec\n",
      "time forward 1.137789 sec\n",
      "loss time 0.001898 sec\n",
      "backward time 0.012944 sec\n",
      "optimizer time 0.025662 sec\n",
      "training time in round 87 cost 0.3972179889678955 sec\n",
      "loss 2.322658, train acc 0.099165\n",
      "round 88\n",
      "time to device 0.003409 sec\n",
      "time forward 1.151409 sec\n",
      "loss time 0.002160 sec\n",
      "backward time 0.013301 sec\n",
      "optimizer time 0.023575 sec\n",
      "training time in round 88 cost 0.3943300247192383 sec\n",
      "loss 2.322419, train acc 0.098929\n",
      "round 89\n",
      "time to device 0.005447 sec\n",
      "time forward 1.165818 sec\n",
      "loss time 0.001839 sec\n",
      "backward time 0.014980 sec\n",
      "optimizer time 0.024994 sec\n",
      "training time in round 89 cost 0.3973672389984131 sec\n",
      "loss 2.322241, train acc 0.099045\n",
      "round 90\n",
      "time to device 0.003705 sec\n",
      "time forward 1.177767 sec\n",
      "loss time 0.001980 sec\n",
      "backward time 0.014683 sec\n",
      "optimizer time 0.025993 sec\n",
      "training time in round 90 cost 0.38262391090393066 sec\n",
      "loss 2.322107, train acc 0.098901\n",
      "round 91\n",
      "time to device 0.004431 sec\n",
      "time forward 1.192091 sec\n",
      "loss time 0.001660 sec\n",
      "backward time 0.013279 sec\n",
      "optimizer time 0.023414 sec\n",
      "training time in round 91 cost 0.3938581943511963 sec\n",
      "loss 2.321877, train acc 0.099100\n",
      "round 92\n",
      "time to device 0.003496 sec\n",
      "time forward 1.204644 sec\n",
      "loss time 0.001535 sec\n",
      "backward time 0.011938 sec\n",
      "optimizer time 0.027203 sec\n",
      "training time in round 92 cost 0.3859851360321045 sec\n",
      "loss 2.321615, train acc 0.099882\n",
      "round 93\n",
      "time to device 0.004979 sec\n",
      "time forward 1.217619 sec\n",
      "loss time 0.001407 sec\n",
      "backward time 0.011161 sec\n",
      "optimizer time 0.022737 sec\n",
      "training time in round 93 cost 0.3786659240722656 sec\n",
      "loss 2.321394, train acc 0.100233\n",
      "round 94\n",
      "time to device 0.003523 sec\n",
      "time forward 1.225080 sec\n",
      "loss time 0.000654 sec\n",
      "backward time 0.005830 sec\n",
      "optimizer time 0.014656 sec\n",
      "training time in round 94 cost 0.3540050983428955 sec\n",
      "loss 2.330245, train acc 0.100329\n",
      "round 95\n",
      "time to device 0.003501 sec\n",
      "time forward 1.242655 sec\n",
      "loss time 0.001787 sec\n",
      "backward time 0.014253 sec\n",
      "optimizer time 0.026385 sec\n",
      "training time in round 95 cost 0.3986668586730957 sec\n",
      "loss 2.329976, train acc 0.100016\n",
      "round 96\n",
      "time to device 0.004544 sec\n",
      "time forward 1.258487 sec\n",
      "loss time 0.001603 sec\n",
      "backward time 0.019745 sec\n",
      "optimizer time 0.022144 sec\n",
      "training time in round 96 cost 0.4150700569152832 sec\n",
      "loss 2.329746, train acc 0.099630\n",
      "round 97\n",
      "time to device 0.003810 sec\n",
      "time forward 1.272017 sec\n",
      "loss time 0.001824 sec\n",
      "backward time 0.013910 sec\n",
      "optimizer time 0.025813 sec\n",
      "training time in round 97 cost 0.4072246551513672 sec\n",
      "loss 2.329450, train acc 0.100048\n",
      "round 98\n",
      "time to device 0.005755 sec\n",
      "time forward 1.284016 sec\n",
      "loss time 0.001912 sec\n",
      "backward time 0.015426 sec\n",
      "optimizer time 0.025041 sec\n",
      "training time in round 98 cost 0.3840970993041992 sec\n",
      "loss 2.329828, train acc 0.100300\n",
      "round 99\n",
      "time to device 0.003575 sec\n",
      "time forward 1.297589 sec\n",
      "loss time 0.001909 sec\n",
      "backward time 0.014706 sec\n",
      "optimizer time 0.025677 sec\n",
      "training time in round 99 cost 0.3951590061187744 sec\n",
      "loss 2.329557, train acc 0.100234\n",
      "round 100\n",
      "time to device 0.004578 sec\n",
      "time forward 1.310456 sec\n",
      "loss time 0.001838 sec\n",
      "backward time 0.011267 sec\n",
      "optimizer time 0.026886 sec\n",
      "training time in round 100 cost 0.38988780975341797 sec\n",
      "loss 2.329318, train acc 0.100170\n",
      "round 101\n",
      "time to device 0.004360 sec\n",
      "time forward 1.322579 sec\n",
      "loss time 0.001838 sec\n",
      "backward time 0.014664 sec\n",
      "optimizer time 0.027996 sec\n",
      "training time in round 101 cost 0.3912370204925537 sec\n",
      "loss 2.329059, train acc 0.100107\n",
      "round 102\n",
      "time to device 0.003650 sec\n",
      "time forward 1.335877 sec\n",
      "loss time 0.002023 sec\n",
      "backward time 0.013853 sec\n",
      "optimizer time 0.024888 sec\n",
      "training time in round 102 cost 0.38926005363464355 sec\n",
      "loss 2.328841, train acc 0.099818\n",
      "round 103\n",
      "time to device 0.003458 sec\n",
      "time forward 1.348432 sec\n",
      "loss time 0.001134 sec\n",
      "backward time 0.010289 sec\n",
      "optimizer time 0.024767 sec\n",
      "training time in round 103 cost 0.383652925491333 sec\n",
      "loss 2.328559, train acc 0.099835\n",
      "round 104\n",
      "time to device 0.004723 sec\n",
      "time forward 1.364133 sec\n",
      "loss time 0.002028 sec\n",
      "backward time 0.015579 sec\n",
      "optimizer time 0.025401 sec\n",
      "training time in round 104 cost 0.40308713912963867 sec\n",
      "loss 2.328350, train acc 0.099554\n",
      "round 105\n",
      "time to device 0.003585 sec\n",
      "time forward 1.378088 sec\n",
      "loss time 0.001610 sec\n",
      "backward time 0.013481 sec\n",
      "optimizer time 0.025785 sec\n",
      "training time in round 105 cost 0.39241600036621094 sec\n",
      "loss 2.328131, train acc 0.099573\n",
      "round 106\n",
      "time to device 0.004536 sec\n",
      "time forward 1.389492 sec\n",
      "loss time 0.001905 sec\n",
      "backward time 0.012731 sec\n",
      "optimizer time 0.025715 sec\n",
      "training time in round 106 cost 0.38744282722473145 sec\n",
      "loss 2.327900, train acc 0.099591\n",
      "round 107\n",
      "time to device 0.004701 sec\n",
      "time forward 1.403439 sec\n",
      "loss time 0.001891 sec\n",
      "backward time 0.015305 sec\n",
      "optimizer time 0.027799 sec\n",
      "training time in round 107 cost 0.402972936630249 sec\n",
      "loss 2.327685, train acc 0.099754\n",
      "round 108\n",
      "time to device 0.008814 sec\n",
      "time forward 1.409886 sec\n",
      "loss time 0.000570 sec\n",
      "backward time 0.005569 sec\n",
      "optimizer time 0.016963 sec\n",
      "training time in round 108 cost 0.350665807723999 sec\n",
      "loss 2.327424, train acc 0.099842\n",
      "round 109\n",
      "time to device 0.008023 sec\n",
      "time forward 1.421766 sec\n",
      "loss time 0.001822 sec\n",
      "backward time 0.014392 sec\n",
      "optimizer time 0.025958 sec\n",
      "training time in round 109 cost 0.39186882972717285 sec\n",
      "loss 2.327219, train acc 0.099929\n",
      "round 110\n",
      "time to device 0.010301 sec\n",
      "time forward 1.435710 sec\n",
      "loss time 0.002035 sec\n",
      "backward time 0.013625 sec\n",
      "optimizer time 0.024215 sec\n",
      "training time in round 110 cost 0.3982689380645752 sec\n",
      "loss 2.327000, train acc 0.100366\n",
      "round 111\n",
      "time to device 0.008868 sec\n",
      "time forward 1.450398 sec\n",
      "loss time 0.001483 sec\n",
      "backward time 0.014869 sec\n",
      "optimizer time 0.024453 sec\n",
      "training time in round 111 cost 0.4029579162597656 sec\n",
      "loss 2.326798, train acc 0.100446\n",
      "round 112\n",
      "time to device 0.012149 sec\n",
      "time forward 1.464753 sec\n",
      "loss time 0.001652 sec\n",
      "backward time 0.012582 sec\n",
      "optimizer time 0.025449 sec\n",
      "training time in round 112 cost 0.39784693717956543 sec\n",
      "loss 2.326543, train acc 0.100111\n",
      "round 113\n",
      "time to device 0.007273 sec\n",
      "time forward 1.479797 sec\n",
      "loss time 0.002028 sec\n",
      "backward time 0.016267 sec\n",
      "optimizer time 0.025713 sec\n",
      "training time in round 113 cost 0.40433621406555176 sec\n",
      "loss 2.326445, train acc 0.099986\n",
      "round 114\n",
      "time to device 0.009724 sec\n",
      "time forward 1.492636 sec\n",
      "loss time 0.001948 sec\n",
      "backward time 0.016764 sec\n",
      "optimizer time 0.026007 sec\n",
      "training time in round 114 cost 0.4027099609375 sec\n",
      "loss 2.326216, train acc 0.100272\n",
      "round 115\n",
      "time to device 0.007316 sec\n",
      "time forward 1.504184 sec\n",
      "loss time 0.001461 sec\n",
      "backward time 0.013302 sec\n",
      "optimizer time 0.029731 sec\n",
      "training time in round 115 cost 0.3922390937805176 sec\n",
      "loss 2.326021, train acc 0.100418\n",
      "round 116\n",
      "time to device 0.007141 sec\n",
      "time forward 1.519005 sec\n",
      "loss time 0.002057 sec\n",
      "backward time 0.015009 sec\n",
      "optimizer time 0.024800 sec\n",
      "training time in round 116 cost 0.40107083320617676 sec\n",
      "loss 2.325826, train acc 0.100294\n",
      "round 117\n",
      "time to device 0.010236 sec\n",
      "time forward 1.530032 sec\n",
      "loss time 0.000653 sec\n",
      "backward time 0.006649 sec\n",
      "optimizer time 0.015994 sec\n",
      "training time in round 117 cost 0.3704640865325928 sec\n",
      "loss 2.325672, train acc 0.100106\n",
      "round 118\n",
      "time to device 0.007683 sec\n",
      "time forward 1.542422 sec\n",
      "loss time 0.001303 sec\n",
      "backward time 0.012152 sec\n",
      "optimizer time 0.012531 sec\n",
      "training time in round 118 cost 0.37604188919067383 sec\n",
      "loss 2.325473, train acc 0.100381\n",
      "round 119\n",
      "time to device 0.007309 sec\n",
      "time forward 1.554666 sec\n",
      "loss time 0.001589 sec\n",
      "backward time 0.012242 sec\n",
      "optimizer time 0.026278 sec\n",
      "training time in round 119 cost 0.38991594314575195 sec\n",
      "loss 2.325270, train acc 0.100391\n",
      "round 120\n",
      "time to device 0.007919 sec\n",
      "time forward 1.568202 sec\n",
      "loss time 0.001947 sec\n",
      "backward time 0.014190 sec\n",
      "optimizer time 0.025792 sec\n",
      "training time in round 120 cost 0.39950990676879883 sec\n",
      "loss 2.325062, train acc 0.100529\n",
      "round 121\n",
      "time to device 0.009183 sec\n",
      "time forward 1.580714 sec\n",
      "loss time 0.001855 sec\n",
      "backward time 0.015375 sec\n",
      "optimizer time 0.025701 sec\n",
      "training time in round 121 cost 0.39257287979125977 sec\n",
      "loss 2.324872, train acc 0.100666\n",
      "round 122\n",
      "time to device 0.006863 sec\n",
      "time forward 1.594422 sec\n",
      "loss time 0.001161 sec\n",
      "backward time 0.013521 sec\n",
      "optimizer time 0.029609 sec\n",
      "training time in round 122 cost 0.4208869934082031 sec\n",
      "loss 2.324725, train acc 0.100737\n",
      "round 123\n",
      "time to device 0.008030 sec\n",
      "time forward 1.607944 sec\n",
      "loss time 0.001833 sec\n",
      "backward time 0.014020 sec\n",
      "optimizer time 0.025112 sec\n",
      "training time in round 123 cost 0.3915371894836426 sec\n",
      "loss 2.324514, train acc 0.101121\n",
      "round 124\n",
      "time to device 0.007250 sec\n",
      "time forward 1.621737 sec\n",
      "loss time 0.003625 sec\n",
      "backward time 0.008627 sec\n",
      "optimizer time 0.019146 sec\n",
      "training time in round 124 cost 0.3927650451660156 sec\n",
      "loss 2.324326, train acc 0.101125\n",
      "round 125\n",
      "time to device 0.008838 sec\n",
      "time forward 1.632596 sec\n",
      "loss time 0.001782 sec\n",
      "backward time 0.012678 sec\n",
      "optimizer time 0.028762 sec\n",
      "training time in round 125 cost 0.3941671848297119 sec\n",
      "loss 2.324156, train acc 0.101066\n",
      "round 126\n",
      "time to device 0.009020 sec\n",
      "time forward 1.645839 sec\n",
      "loss time 0.001599 sec\n",
      "backward time 0.014201 sec\n",
      "optimizer time 0.023277 sec\n",
      "training time in round 126 cost 0.39453887939453125 sec\n",
      "loss 2.323973, train acc 0.101193\n",
      "round 127\n",
      "time to device 0.008317 sec\n",
      "time forward 1.666121 sec\n",
      "loss time 0.001440 sec\n",
      "backward time 0.012956 sec\n",
      "optimizer time 0.027259 sec\n",
      "training time in round 127 cost 0.4159119129180908 sec\n",
      "loss 2.323822, train acc 0.101013\n",
      "round 128\n",
      "time to device 0.008106 sec\n",
      "time forward 1.680106 sec\n",
      "loss time 0.001285 sec\n",
      "backward time 0.012012 sec\n",
      "optimizer time 0.024584 sec\n",
      "training time in round 128 cost 0.39327406883239746 sec\n",
      "loss 2.323627, train acc 0.101502\n",
      "round 129\n",
      "time to device 0.005460 sec\n",
      "time forward 1.693053 sec\n",
      "loss time 0.001223 sec\n",
      "backward time 0.014658 sec\n",
      "optimizer time 0.025500 sec\n",
      "training time in round 129 cost 0.3926839828491211 sec\n",
      "loss 2.323498, train acc 0.101142\n",
      "round 130\n",
      "time to device 0.009846 sec\n",
      "time forward 1.705498 sec\n",
      "loss time 0.001971 sec\n",
      "backward time 0.012445 sec\n",
      "optimizer time 0.028378 sec\n",
      "training time in round 130 cost 0.3958289623260498 sec\n",
      "loss 2.323383, train acc 0.100906\n",
      "round 131\n",
      "time to device 0.004226 sec\n",
      "time forward 1.723275 sec\n",
      "loss time 0.002107 sec\n",
      "backward time 0.011548 sec\n",
      "optimizer time 0.023742 sec\n",
      "training time in round 131 cost 0.39229679107666016 sec\n",
      "loss 2.323231, train acc 0.100852\n",
      "round 132\n",
      "time to device 0.003555 sec\n",
      "time forward 1.738445 sec\n",
      "loss time 0.001437 sec\n",
      "backward time 0.011922 sec\n",
      "optimizer time 0.021891 sec\n",
      "training time in round 132 cost 0.39229893684387207 sec\n",
      "loss 2.323077, train acc 0.101034\n",
      "round 133\n",
      "time to device 0.004242 sec\n",
      "time forward 1.752422 sec\n",
      "loss time 0.001260 sec\n",
      "backward time 0.013441 sec\n",
      "optimizer time 0.027787 sec\n",
      "training time in round 133 cost 0.38742613792419434 sec\n",
      "loss 2.322906, train acc 0.101154\n",
      "round 134\n",
      "time to device 0.003419 sec\n",
      "time forward 1.765236 sec\n",
      "loss time 0.001257 sec\n",
      "backward time 0.012121 sec\n",
      "optimizer time 0.024169 sec\n",
      "training time in round 134 cost 0.387545108795166 sec\n",
      "loss 2.323550, train acc 0.101157\n",
      "round 135\n",
      "time to device 0.003699 sec\n",
      "time forward 1.779334 sec\n",
      "loss time 0.001886 sec\n",
      "backward time 0.014858 sec\n",
      "optimizer time 0.025725 sec\n",
      "training time in round 135 cost 0.39710402488708496 sec\n",
      "loss 2.323404, train acc 0.101045\n",
      "round 136\n",
      "time to device 0.003436 sec\n",
      "time forward 1.793131 sec\n",
      "loss time 0.001729 sec\n",
      "backward time 0.012931 sec\n",
      "optimizer time 0.024349 sec\n",
      "training time in round 136 cost 0.3881669044494629 sec\n",
      "loss 2.323319, train acc 0.100878\n",
      "round 137\n",
      "time to device 0.003262 sec\n",
      "time forward 1.805135 sec\n",
      "loss time 0.001940 sec\n",
      "backward time 0.016191 sec\n",
      "optimizer time 0.025770 sec\n",
      "training time in round 137 cost 0.3857440948486328 sec\n",
      "loss 2.323188, train acc 0.100940\n",
      "round 138\n",
      "time to device 0.003471 sec\n",
      "time forward 1.824677 sec\n",
      "loss time 0.001447 sec\n",
      "backward time 0.011077 sec\n",
      "optimizer time 0.023843 sec\n",
      "training time in round 138 cost 0.3931100368499756 sec\n",
      "loss 2.323072, train acc 0.100832\n",
      "round 139\n",
      "time to device 0.003947 sec\n",
      "time forward 1.839817 sec\n",
      "loss time 0.001935 sec\n",
      "backward time 0.019625 sec\n",
      "optimizer time 0.024657 sec\n",
      "training time in round 139 cost 0.40473294258117676 sec\n",
      "loss 2.322883, train acc 0.101283\n",
      "round 140\n",
      "time to device 0.003748 sec\n",
      "time forward 1.846911 sec\n",
      "loss time 0.000559 sec\n",
      "backward time 0.005150 sec\n",
      "optimizer time 0.013574 sec\n",
      "training time in round 140 cost 0.3571488857269287 sec\n",
      "loss 2.322765, train acc 0.101064\n",
      "round 141\n",
      "time to device 0.003353 sec\n",
      "time forward 1.860146 sec\n",
      "loss time 0.001916 sec\n",
      "backward time 0.015524 sec\n",
      "optimizer time 0.022859 sec\n",
      "training time in round 141 cost 0.3877542018890381 sec\n",
      "loss 2.322621, train acc 0.101067\n",
      "round 142\n",
      "time to device 0.003595 sec\n",
      "time forward 1.870610 sec\n",
      "loss time 0.001272 sec\n",
      "backward time 0.011640 sec\n",
      "optimizer time 0.026111 sec\n",
      "training time in round 142 cost 0.3818809986114502 sec\n",
      "loss 2.322497, train acc 0.101016\n",
      "round 143\n",
      "time to device 0.003968 sec\n",
      "time forward 1.884966 sec\n",
      "loss time 0.001897 sec\n",
      "backward time 0.018676 sec\n",
      "optimizer time 0.024703 sec\n",
      "training time in round 143 cost 0.3999338150024414 sec\n",
      "loss 2.322350, train acc 0.101183\n",
      "round 144\n",
      "time to device 0.004222 sec\n",
      "time forward 1.898668 sec\n",
      "loss time 0.001533 sec\n",
      "backward time 0.013582 sec\n",
      "optimizer time 0.028194 sec\n",
      "training time in round 144 cost 0.39649510383605957 sec\n",
      "loss 2.322237, train acc 0.101024\n",
      "round 145\n",
      "time to device 0.003636 sec\n",
      "time forward 1.910950 sec\n",
      "loss time 0.001118 sec\n",
      "backward time 0.012040 sec\n",
      "optimizer time 0.025974 sec\n",
      "training time in round 145 cost 0.38547205924987793 sec\n",
      "loss 2.322116, train acc 0.100813\n",
      "round 146\n",
      "time to device 0.003593 sec\n",
      "time forward 1.926054 sec\n",
      "loss time 0.001735 sec\n",
      "backward time 0.016283 sec\n",
      "optimizer time 0.024443 sec\n",
      "training time in round 146 cost 0.3957960605621338 sec\n",
      "loss 2.322034, train acc 0.100659\n",
      "round 147\n",
      "time to device 0.004219 sec\n",
      "time forward 1.939931 sec\n",
      "loss time 0.001835 sec\n",
      "backward time 0.013583 sec\n",
      "optimizer time 0.026379 sec\n",
      "training time in round 147 cost 0.39548492431640625 sec\n",
      "loss 2.321914, train acc 0.100560\n",
      "round 148\n",
      "time to device 0.003882 sec\n",
      "time forward 1.951252 sec\n",
      "loss time 0.000985 sec\n",
      "backward time 0.014805 sec\n",
      "optimizer time 0.028141 sec\n",
      "training time in round 148 cost 0.38349199295043945 sec\n",
      "loss 2.321779, train acc 0.100619\n",
      "round 149\n",
      "time to device 0.003806 sec\n",
      "time forward 1.958284 sec\n",
      "loss time 0.000508 sec\n",
      "backward time 0.004635 sec\n",
      "optimizer time 0.012859 sec\n",
      "training time in round 149 cost 0.3357877731323242 sec\n",
      "loss 2.321674, train acc 0.100260\n",
      "round 150\n",
      "time to device 0.003187 sec\n",
      "time forward 1.971548 sec\n",
      "loss time 0.001305 sec\n",
      "backward time 0.010273 sec\n",
      "optimizer time 0.021133 sec\n",
      "training time in round 150 cost 0.3825197219848633 sec\n",
      "loss 2.321571, train acc 0.100062\n",
      "round 151\n",
      "time to device 0.003615 sec\n",
      "time forward 1.986827 sec\n",
      "loss time 0.001862 sec\n",
      "backward time 0.016366 sec\n",
      "optimizer time 0.026146 sec\n",
      "training time in round 151 cost 0.4007139205932617 sec\n",
      "loss 2.321437, train acc 0.100432\n",
      "round 152\n",
      "time to device 0.004244 sec\n",
      "time forward 1.999344 sec\n",
      "loss time 0.001665 sec\n",
      "backward time 0.014413 sec\n",
      "optimizer time 0.015174 sec\n",
      "training time in round 152 cost 0.3779921531677246 sec\n",
      "loss 2.321299, train acc 0.100490\n",
      "round 153\n",
      "time to device 0.003133 sec\n",
      "time forward 2.013733 sec\n",
      "loss time 0.001834 sec\n",
      "backward time 0.014547 sec\n",
      "optimizer time 0.026933 sec\n",
      "training time in round 153 cost 0.39820289611816406 sec\n",
      "loss 2.321185, train acc 0.100548\n",
      "round 154\n",
      "time to device 0.004197 sec\n",
      "time forward 2.025323 sec\n",
      "loss time 0.001439 sec\n",
      "backward time 0.011775 sec\n",
      "optimizer time 0.012370 sec\n",
      "training time in round 154 cost 0.40868091583251953 sec\n",
      "loss 2.321754, train acc 0.100554\n",
      "round 155\n",
      "time to device 0.003450 sec\n",
      "time forward 2.035223 sec\n",
      "loss time 0.000575 sec\n",
      "backward time 0.005411 sec\n",
      "optimizer time 0.014524 sec\n",
      "training time in round 155 cost 0.35972023010253906 sec\n",
      "loss 2.321622, train acc 0.100511\n",
      "round 156\n",
      "time to device 0.004124 sec\n",
      "time forward 2.050535 sec\n",
      "loss time 0.001960 sec\n",
      "backward time 0.014926 sec\n",
      "optimizer time 0.021610 sec\n",
      "training time in round 156 cost 0.3903961181640625 sec\n",
      "loss 2.321524, train acc 0.100518\n",
      "round 157\n",
      "time to device 0.004018 sec\n",
      "time forward 2.063600 sec\n",
      "loss time 0.001690 sec\n",
      "backward time 0.012805 sec\n",
      "optimizer time 0.024046 sec\n",
      "training time in round 157 cost 0.38750576972961426 sec\n",
      "loss 2.321417, train acc 0.100475\n",
      "round 158\n",
      "time to device 0.004157 sec\n",
      "time forward 2.077125 sec\n",
      "loss time 0.001438 sec\n",
      "backward time 0.011733 sec\n",
      "optimizer time 0.021769 sec\n",
      "training time in round 158 cost 0.38253068923950195 sec\n",
      "loss 2.321262, train acc 0.101071\n",
      "round 159\n",
      "time to device 0.003530 sec\n",
      "time forward 2.090851 sec\n",
      "loss time 0.001711 sec\n",
      "backward time 0.010538 sec\n",
      "optimizer time 0.022451 sec\n",
      "training time in round 159 cost 0.38593101501464844 sec\n",
      "loss 2.321141, train acc 0.101172\n",
      "round 160\n",
      "time to device 0.004373 sec\n",
      "time forward 2.102772 sec\n",
      "loss time 0.001210 sec\n",
      "backward time 0.013153 sec\n",
      "optimizer time 0.025952 sec\n",
      "training time in round 160 cost 0.38069915771484375 sec\n",
      "loss 2.322006, train acc 0.101417\n",
      "round 161\n",
      "time to device 0.003404 sec\n",
      "time forward 2.117059 sec\n",
      "loss time 0.001951 sec\n",
      "backward time 0.016536 sec\n",
      "optimizer time 0.029063 sec\n",
      "training time in round 161 cost 0.3978400230407715 sec\n",
      "loss 2.321885, train acc 0.101418\n",
      "round 162\n",
      "time to device 0.004168 sec\n",
      "time forward 2.129787 sec\n",
      "loss time 0.001982 sec\n",
      "backward time 0.012496 sec\n",
      "optimizer time 0.026309 sec\n",
      "training time in round 162 cost 0.39104580879211426 sec\n",
      "loss 2.321783, train acc 0.101083\n",
      "round 163\n",
      "time to device 0.004517 sec\n",
      "time forward 2.142398 sec\n",
      "loss time 0.001891 sec\n",
      "backward time 0.014057 sec\n",
      "optimizer time 0.026303 sec\n",
      "training time in round 163 cost 0.3895139694213867 sec\n",
      "loss 2.321672, train acc 0.100991\n",
      "round 164\n",
      "time to device 0.006015 sec\n",
      "time forward 2.156073 sec\n",
      "loss time 0.001509 sec\n",
      "backward time 0.011599 sec\n",
      "optimizer time 0.021855 sec\n",
      "training time in round 164 cost 0.3856368064880371 sec\n",
      "loss 2.321589, train acc 0.100758\n",
      "round 165\n",
      "time to device 0.003438 sec\n",
      "time forward 2.169543 sec\n",
      "loss time 0.001588 sec\n",
      "backward time 0.011431 sec\n",
      "optimizer time 0.023375 sec\n",
      "training time in round 165 cost 0.390639066696167 sec\n",
      "loss 2.321488, train acc 0.100574\n",
      "round 166\n",
      "time to device 0.004201 sec\n",
      "time forward 2.183628 sec\n",
      "loss time 0.001997 sec\n",
      "backward time 0.015458 sec\n",
      "optimizer time 0.025434 sec\n",
      "training time in round 166 cost 0.40143513679504395 sec\n",
      "loss 2.321362, train acc 0.100487\n",
      "round 167\n",
      "time to device 0.003888 sec\n",
      "time forward 2.197146 sec\n",
      "loss time 0.001898 sec\n",
      "backward time 0.014521 sec\n",
      "optimizer time 0.023849 sec\n",
      "training time in round 167 cost 0.38940882682800293 sec\n",
      "loss 2.321289, train acc 0.100214\n",
      "round 168\n",
      "time to device 0.005471 sec\n",
      "time forward 2.209940 sec\n",
      "loss time 0.002014 sec\n",
      "backward time 0.015887 sec\n",
      "optimizer time 0.025849 sec\n",
      "training time in round 168 cost 0.44861412048339844 sec\n",
      "loss 2.321166, train acc 0.100268\n",
      "round 169\n",
      "time to device 0.004341 sec\n",
      "time forward 2.224070 sec\n",
      "loss time 0.001198 sec\n",
      "backward time 0.011768 sec\n",
      "optimizer time 0.022356 sec\n",
      "training time in round 169 cost 0.3855140209197998 sec\n",
      "loss 2.321089, train acc 0.100138\n",
      "round 170\n",
      "time to device 0.009746 sec\n",
      "time forward 2.237684 sec\n",
      "loss time 0.001599 sec\n",
      "backward time 0.011230 sec\n",
      "optimizer time 0.024920 sec\n",
      "training time in round 170 cost 0.3949089050292969 sec\n",
      "loss 2.320992, train acc 0.100238\n",
      "round 171\n",
      "time to device 0.008899 sec\n",
      "time forward 2.250701 sec\n",
      "loss time 0.001955 sec\n",
      "backward time 0.015093 sec\n",
      "optimizer time 0.026694 sec\n",
      "training time in round 171 cost 0.39887166023254395 sec\n",
      "loss 2.320882, train acc 0.100154\n",
      "round 172\n",
      "time to device 0.008607 sec\n",
      "time forward 2.262035 sec\n",
      "loss time 0.001153 sec\n",
      "backward time 0.014351 sec\n",
      "optimizer time 0.024976 sec\n",
      "training time in round 172 cost 0.386415958404541 sec\n",
      "loss 2.320764, train acc 0.100479\n",
      "round 173\n",
      "time to device 0.007851 sec\n",
      "time forward 2.274135 sec\n",
      "loss time 0.001767 sec\n",
      "backward time 0.015439 sec\n",
      "optimizer time 0.028586 sec\n",
      "training time in round 173 cost 0.3955569267272949 sec\n",
      "loss 2.320678, train acc 0.100395\n",
      "round 174\n",
      "time to device 0.009422 sec\n",
      "time forward 2.287031 sec\n",
      "loss time 0.001621 sec\n",
      "backward time 0.012953 sec\n",
      "optimizer time 0.025154 sec\n",
      "training time in round 174 cost 0.3938748836517334 sec\n",
      "loss 2.320562, train acc 0.100714\n",
      "round 175\n",
      "time to device 0.007073 sec\n",
      "time forward 2.301483 sec\n",
      "loss time 0.001516 sec\n",
      "backward time 0.012793 sec\n",
      "optimizer time 0.024223 sec\n",
      "training time in round 175 cost 0.3982110023498535 sec\n",
      "loss 2.320473, train acc 0.100675\n",
      "round 176\n",
      "time to device 0.007268 sec\n",
      "time forward 2.313356 sec\n",
      "loss time 0.001765 sec\n",
      "backward time 0.023395 sec\n",
      "optimizer time 0.021999 sec\n",
      "training time in round 176 cost 0.39380478858947754 sec\n",
      "loss 2.320578, train acc 0.100680\n",
      "round 177\n",
      "time to device 0.008377 sec\n",
      "time forward 2.327252 sec\n",
      "loss time 0.001367 sec\n",
      "backward time 0.012646 sec\n",
      "optimizer time 0.023751 sec\n",
      "training time in round 177 cost 0.389132022857666 sec\n",
      "loss 2.320484, train acc 0.100509\n",
      "round 178\n",
      "time to device 0.006615 sec\n",
      "time forward 2.341869 sec\n",
      "loss time 0.001134 sec\n",
      "backward time 0.019130 sec\n",
      "optimizer time 0.025105 sec\n",
      "training time in round 178 cost 0.4192037582397461 sec\n",
      "loss 2.320387, train acc 0.100384\n",
      "round 179\n",
      "time to device 0.009362 sec\n",
      "time forward 2.355370 sec\n",
      "loss time 0.001186 sec\n",
      "backward time 0.009304 sec\n",
      "optimizer time 0.026394 sec\n",
      "training time in round 179 cost 0.3970320224761963 sec\n",
      "loss 2.320292, train acc 0.100347\n",
      "round 180\n",
      "time to device 0.004198 sec\n",
      "time forward 2.369803 sec\n",
      "loss time 0.001817 sec\n",
      "backward time 0.015769 sec\n",
      "optimizer time 0.026417 sec\n",
      "training time in round 180 cost 0.40140795707702637 sec\n",
      "loss 2.320197, train acc 0.100311\n",
      "round 181\n",
      "time to device 0.006140 sec\n",
      "time forward 2.383924 sec\n",
      "loss time 0.002149 sec\n",
      "backward time 0.014275 sec\n",
      "optimizer time 0.022257 sec\n",
      "training time in round 181 cost 0.4056220054626465 sec\n",
      "loss 2.320107, train acc 0.100232\n",
      "round 182\n",
      "time to device 0.003567 sec\n",
      "time forward 2.391158 sec\n",
      "loss time 0.000582 sec\n",
      "backward time 0.005233 sec\n",
      "optimizer time 0.014061 sec\n",
      "training time in round 182 cost 0.35958385467529297 sec\n",
      "loss 2.320017, train acc 0.100324\n",
      "round 183\n",
      "time to device 0.003489 sec\n",
      "time forward 2.401429 sec\n",
      "loss time 0.003362 sec\n",
      "backward time 0.013067 sec\n",
      "optimizer time 0.026392 sec\n",
      "training time in round 183 cost 0.38007426261901855 sec\n",
      "loss 2.319913, train acc 0.100289\n",
      "round 184\n",
      "time to device 0.003729 sec\n",
      "time forward 2.411247 sec\n",
      "loss time 0.001074 sec\n",
      "backward time 0.010754 sec\n",
      "optimizer time 0.030652 sec\n",
      "training time in round 184 cost 0.3816556930541992 sec\n",
      "loss 2.319932, train acc 0.100591\n",
      "round 185\n",
      "time to device 0.003985 sec\n",
      "time forward 2.424843 sec\n",
      "loss time 0.002268 sec\n",
      "backward time 0.016899 sec\n",
      "optimizer time 0.024697 sec\n",
      "training time in round 185 cost 0.40552186965942383 sec\n",
      "loss 2.319840, train acc 0.100470\n",
      "round 186\n",
      "time to device 0.005647 sec\n",
      "time forward 2.437054 sec\n",
      "loss time 0.001426 sec\n",
      "backward time 0.012006 sec\n",
      "optimizer time 0.024566 sec\n",
      "training time in round 186 cost 0.388779878616333 sec\n",
      "loss 2.319741, train acc 0.100643\n",
      "round 187\n",
      "time to device 0.004477 sec\n",
      "time forward 2.449649 sec\n",
      "loss time 0.000408 sec\n",
      "backward time 0.003387 sec\n",
      "optimizer time 0.011045 sec\n",
      "training time in round 187 cost 0.37201976776123047 sec\n",
      "loss 2.319658, train acc 0.100565\n",
      "round 188\n",
      "time to device 0.006165 sec\n",
      "time forward 2.462991 sec\n",
      "loss time 0.001601 sec\n",
      "backward time 0.013030 sec\n",
      "optimizer time 0.025479 sec\n",
      "training time in round 188 cost 0.3896751403808594 sec\n",
      "loss 2.319568, train acc 0.100488\n",
      "round 189\n",
      "time to device 0.003648 sec\n",
      "time forward 2.476810 sec\n",
      "loss time 0.001560 sec\n",
      "backward time 0.013801 sec\n",
      "optimizer time 0.024533 sec\n",
      "training time in round 189 cost 0.38985300064086914 sec\n",
      "loss 2.319480, train acc 0.100452\n",
      "round 190\n",
      "time to device 0.004034 sec\n",
      "time forward 2.494496 sec\n",
      "loss time 0.001831 sec\n",
      "backward time 0.013304 sec\n",
      "optimizer time 0.025589 sec\n",
      "training time in round 190 cost 0.4129667282104492 sec\n",
      "loss 2.319386, train acc 0.100663\n",
      "round 191\n",
      "time to device 0.004443 sec\n",
      "time forward 2.506994 sec\n",
      "loss time 0.002080 sec\n",
      "backward time 0.012797 sec\n",
      "optimizer time 0.026660 sec\n",
      "training time in round 191 cost 0.38997387886047363 sec\n",
      "loss 2.319409, train acc 0.100627\n",
      "round 192\n",
      "time to device 0.003611 sec\n",
      "time forward 2.519893 sec\n",
      "loss time 0.002333 sec\n",
      "backward time 0.012903 sec\n",
      "optimizer time 0.027431 sec\n",
      "training time in round 192 cost 0.39121007919311523 sec\n",
      "loss 2.319314, train acc 0.100712\n",
      "round 193\n",
      "time to device 0.003504 sec\n",
      "time forward 2.532811 sec\n",
      "loss time 0.001492 sec\n",
      "backward time 0.011260 sec\n",
      "optimizer time 0.024536 sec\n",
      "training time in round 193 cost 0.3844170570373535 sec\n",
      "loss 2.319231, train acc 0.100556\n",
      "round 194\n",
      "time to device 0.004499 sec\n",
      "time forward 2.547592 sec\n",
      "loss time 0.001560 sec\n",
      "backward time 0.017201 sec\n",
      "optimizer time 0.022288 sec\n",
      "training time in round 194 cost 0.40096402168273926 sec\n",
      "loss 2.319418, train acc 0.100280\n",
      "round 195\n",
      "time to device 0.003863 sec\n",
      "time forward 2.562761 sec\n",
      "loss time 0.001120 sec\n",
      "backward time 0.013696 sec\n",
      "optimizer time 0.026232 sec\n",
      "training time in round 195 cost 0.44595813751220703 sec\n",
      "loss 2.319334, train acc 0.100327\n",
      "round 196\n",
      "time to device 0.009807 sec\n",
      "time forward 2.576012 sec\n",
      "loss time 0.002027 sec\n",
      "backward time 0.015750 sec\n",
      "optimizer time 0.025295 sec\n",
      "training time in round 196 cost 0.41643500328063965 sec\n",
      "loss 2.319228, train acc 0.100254\n",
      "round 197\n",
      "time to device 0.009717 sec\n",
      "time forward 2.588463 sec\n",
      "loss time 0.001894 sec\n",
      "backward time 0.014867 sec\n",
      "optimizer time 0.028142 sec\n",
      "training time in round 197 cost 0.416187047958374 sec\n",
      "loss 2.319141, train acc 0.100418\n",
      "round 198\n",
      "time to device 0.009474 sec\n",
      "time forward 2.600530 sec\n",
      "loss time 0.001784 sec\n",
      "backward time 0.014073 sec\n",
      "optimizer time 0.023869 sec\n",
      "training time in round 198 cost 0.40452098846435547 sec\n",
      "loss 2.319069, train acc 0.100306\n",
      "round 199\n",
      "time to device 0.006578 sec\n",
      "time forward 2.614477 sec\n",
      "loss time 0.001541 sec\n",
      "backward time 0.013917 sec\n",
      "optimizer time 0.024360 sec\n",
      "training time in round 199 cost 0.40963315963745117 sec\n",
      "loss 2.318979, train acc 0.100273\n",
      "round 200\n",
      "time to device 0.009421 sec\n",
      "time forward 2.627447 sec\n",
      "loss time 0.001853 sec\n",
      "backward time 0.016510 sec\n",
      "optimizer time 0.027236 sec\n",
      "training time in round 200 cost 0.4227118492126465 sec\n",
      "loss 2.318898, train acc 0.100202\n",
      "round 201\n",
      "time to device 0.007293 sec\n",
      "time forward 2.639795 sec\n",
      "loss time 0.001449 sec\n",
      "backward time 0.012328 sec\n",
      "optimizer time 0.021404 sec\n",
      "training time in round 201 cost 0.4008193016052246 sec\n",
      "loss 2.318813, train acc 0.100325\n",
      "round 202\n",
      "time to device 0.007993 sec\n",
      "time forward 2.652631 sec\n",
      "loss time 0.001495 sec\n",
      "backward time 0.014052 sec\n",
      "optimizer time 0.023762 sec\n",
      "training time in round 202 cost 0.3920929431915283 sec\n",
      "loss 2.318650, train acc 0.100485\n",
      "round 203\n",
      "time to device 0.009105 sec\n",
      "time forward 2.665261 sec\n",
      "loss time 0.001696 sec\n",
      "backward time 0.013613 sec\n",
      "optimizer time 0.025429 sec\n",
      "training time in round 203 cost 0.4169809818267822 sec\n",
      "loss 2.324385, train acc 0.100299\n",
      "round 204\n",
      "time to device 0.004059 sec\n",
      "time forward 2.677161 sec\n",
      "loss time 0.001975 sec\n",
      "backward time 0.011323 sec\n",
      "optimizer time 0.023940 sec\n",
      "training time in round 204 cost 0.3818511962890625 sec\n",
      "loss 2.324331, train acc 0.100229\n",
      "round 205\n",
      "time to device 0.005049 sec\n",
      "time forward 2.690512 sec\n",
      "loss time 0.001505 sec\n",
      "backward time 0.011100 sec\n",
      "optimizer time 0.021280 sec\n",
      "training time in round 205 cost 0.3840501308441162 sec\n",
      "loss 2.324227, train acc 0.100197\n",
      "round 206\n",
      "time to device 0.003862 sec\n",
      "time forward 2.697052 sec\n",
      "loss time 0.000562 sec\n",
      "backward time 0.005203 sec\n",
      "optimizer time 0.014064 sec\n",
      "training time in round 206 cost 0.34679698944091797 sec\n",
      "loss 2.324119, train acc 0.100091\n",
      "round 207\n",
      "time to device 0.004727 sec\n",
      "time forward 2.711722 sec\n",
      "loss time 0.001542 sec\n",
      "backward time 0.014111 sec\n",
      "optimizer time 0.023204 sec\n",
      "training time in round 207 cost 0.39571094512939453 sec\n",
      "loss 2.324021, train acc 0.100135\n",
      "round 208\n",
      "time to device 0.003685 sec\n",
      "time forward 2.725351 sec\n",
      "loss time 0.001568 sec\n",
      "backward time 0.016172 sec\n",
      "optimizer time 0.024099 sec\n",
      "training time in round 208 cost 0.39139676094055176 sec\n",
      "loss 2.323910, train acc 0.100105\n",
      "round 209\n",
      "time to device 0.003838 sec\n",
      "time forward 2.740319 sec\n",
      "loss time 0.001472 sec\n",
      "backward time 0.013228 sec\n",
      "optimizer time 0.023464 sec\n",
      "training time in round 209 cost 0.4039440155029297 sec\n",
      "loss 2.323791, train acc 0.100112\n",
      "round 210\n",
      "time to device 0.004265 sec\n",
      "time forward 2.755951 sec\n",
      "loss time 0.001321 sec\n",
      "backward time 0.015063 sec\n",
      "optimizer time 0.027115 sec\n",
      "training time in round 210 cost 0.4055819511413574 sec\n",
      "loss 2.323696, train acc 0.100156\n",
      "round 211\n",
      "time to device 0.004879 sec\n",
      "time forward 2.768573 sec\n",
      "loss time 0.001613 sec\n",
      "backward time 0.016186 sec\n",
      "optimizer time 0.024539 sec\n",
      "training time in round 211 cost 0.40759706497192383 sec\n",
      "loss 2.323584, train acc 0.100162\n",
      "round 212\n",
      "time to device 0.008851 sec\n",
      "time forward 2.780929 sec\n",
      "loss time 0.001363 sec\n",
      "backward time 0.014492 sec\n",
      "optimizer time 0.024506 sec\n",
      "training time in round 212 cost 0.38883423805236816 sec\n",
      "loss 2.323488, train acc 0.099949\n",
      "round 213\n",
      "time to device 0.005099 sec\n",
      "time forward 2.794404 sec\n",
      "loss time 0.001608 sec\n",
      "backward time 0.012986 sec\n",
      "optimizer time 0.024231 sec\n",
      "training time in round 213 cost 0.3924088478088379 sec\n",
      "loss 2.323377, train acc 0.099883\n",
      "round 214\n",
      "time to device 0.003783 sec\n",
      "time forward 2.808646 sec\n",
      "loss time 0.001978 sec\n",
      "backward time 0.015346 sec\n",
      "optimizer time 0.025724 sec\n",
      "training time in round 214 cost 0.3982229232788086 sec\n",
      "loss 2.323308, train acc 0.099927\n",
      "round 215\n",
      "time to device 0.003777 sec\n",
      "time forward 2.821807 sec\n",
      "loss time 0.001895 sec\n",
      "backward time 0.014238 sec\n",
      "optimizer time 0.026939 sec\n",
      "training time in round 215 cost 0.3918170928955078 sec\n",
      "loss 2.323226, train acc 0.099899\n",
      "round 216\n",
      "time to device 0.004527 sec\n",
      "time forward 2.834603 sec\n",
      "loss time 0.001568 sec\n",
      "backward time 0.010821 sec\n",
      "optimizer time 0.020422 sec\n",
      "training time in round 216 cost 0.3807680606842041 sec\n",
      "loss 2.323091, train acc 0.100086\n",
      "round 217\n",
      "time to device 0.003616 sec\n",
      "time forward 2.847540 sec\n",
      "loss time 0.001489 sec\n",
      "backward time 0.012998 sec\n",
      "optimizer time 0.021069 sec\n",
      "training time in round 217 cost 0.3849320411682129 sec\n",
      "loss 2.323123, train acc 0.099842\n",
      "round 218\n",
      "time to device 0.003246 sec\n",
      "time forward 2.860280 sec\n",
      "loss time 0.001277 sec\n",
      "backward time 0.012160 sec\n",
      "optimizer time 0.027823 sec\n",
      "training time in round 218 cost 0.39000701904296875 sec\n",
      "loss 2.323008, train acc 0.099886\n",
      "round 219\n",
      "time to device 0.003919 sec\n",
      "time forward 2.872530 sec\n",
      "loss time 0.001265 sec\n",
      "backward time 0.011432 sec\n",
      "optimizer time 0.025538 sec\n",
      "training time in round 219 cost 0.3820631504058838 sec\n",
      "loss 2.322929, train acc 0.099858\n",
      "round 220\n",
      "time to device 0.003935 sec\n",
      "time forward 2.879946 sec\n",
      "loss time 0.000578 sec\n",
      "backward time 0.004990 sec\n",
      "optimizer time 0.013358 sec\n",
      "training time in round 220 cost 0.348797082901001 sec\n",
      "loss 2.322852, train acc 0.099618\n",
      "round 221\n",
      "time to device 0.003191 sec\n",
      "time forward 2.893727 sec\n",
      "loss time 0.001699 sec\n",
      "backward time 0.013839 sec\n",
      "optimizer time 0.011420 sec\n",
      "training time in round 221 cost 0.38013195991516113 sec\n",
      "loss 2.322880, train acc 0.099627\n",
      "round 222\n",
      "time to device 0.004774 sec\n",
      "time forward 2.907363 sec\n",
      "loss time 0.001462 sec\n",
      "backward time 0.013490 sec\n",
      "optimizer time 0.024679 sec\n",
      "training time in round 222 cost 0.3903028964996338 sec\n",
      "loss 2.322778, train acc 0.099671\n",
      "round 223\n",
      "time to device 0.003949 sec\n",
      "time forward 2.921806 sec\n",
      "loss time 0.001450 sec\n",
      "backward time 0.016492 sec\n",
      "optimizer time 0.025149 sec\n",
      "training time in round 223 cost 0.4024930000305176 sec\n",
      "loss 2.322668, train acc 0.099714\n",
      "round 224\n",
      "time to device 0.004843 sec\n",
      "time forward 2.934096 sec\n",
      "loss time 0.001084 sec\n",
      "backward time 0.015137 sec\n",
      "optimizer time 0.028476 sec\n",
      "training time in round 224 cost 0.3888101577758789 sec\n",
      "loss 2.322587, train acc 0.099687\n",
      "round 225\n",
      "time to device 0.004074 sec\n",
      "time forward 2.953900 sec\n",
      "loss time 0.001923 sec\n",
      "backward time 0.015042 sec\n",
      "optimizer time 0.027917 sec\n",
      "training time in round 225 cost 0.4133889675140381 sec\n",
      "loss 2.322514, train acc 0.099523\n",
      "round 226\n",
      "time to device 0.003806 sec\n",
      "time forward 2.966428 sec\n",
      "loss time 0.001887 sec\n",
      "backward time 0.012771 sec\n",
      "optimizer time 0.026544 sec\n",
      "training time in round 226 cost 0.3883838653564453 sec\n",
      "loss 2.324078, train acc 0.099635\n",
      "round 227\n",
      "time to device 0.004685 sec\n",
      "time forward 2.978858 sec\n",
      "loss time 0.001441 sec\n",
      "backward time 0.013377 sec\n",
      "optimizer time 0.026940 sec\n",
      "training time in round 227 cost 0.3871469497680664 sec\n",
      "loss 2.323994, train acc 0.099541\n",
      "round 228\n",
      "time to device 0.003307 sec\n",
      "time forward 2.991526 sec\n",
      "loss time 0.001503 sec\n",
      "backward time 0.013810 sec\n",
      "optimizer time 0.023860 sec\n",
      "training time in round 228 cost 0.38578009605407715 sec\n",
      "loss 2.323890, train acc 0.099516\n",
      "round 229\n",
      "time to device 0.003190 sec\n",
      "time forward 3.006471 sec\n",
      "loss time 0.002051 sec\n",
      "backward time 0.013198 sec\n",
      "optimizer time 0.023085 sec\n",
      "training time in round 229 cost 0.39238500595092773 sec\n",
      "loss 2.323813, train acc 0.099524\n",
      "round 230\n",
      "time to device 0.004468 sec\n",
      "time forward 3.017900 sec\n",
      "loss time 0.001257 sec\n",
      "backward time 0.015174 sec\n",
      "optimizer time 0.025231 sec\n",
      "training time in round 230 cost 0.3862431049346924 sec\n",
      "loss 2.323720, train acc 0.099736\n",
      "round 231\n",
      "time to device 0.004325 sec\n",
      "time forward 3.031725 sec\n",
      "loss time 0.001498 sec\n",
      "backward time 0.014636 sec\n",
      "optimizer time 0.024353 sec\n",
      "training time in round 231 cost 0.3897721767425537 sec\n",
      "loss 2.323641, train acc 0.099643\n",
      "round 232\n",
      "time to device 0.003651 sec\n",
      "time forward 3.045626 sec\n",
      "loss time 0.001523 sec\n",
      "backward time 0.011497 sec\n",
      "optimizer time 0.023430 sec\n",
      "training time in round 232 cost 0.38739705085754395 sec\n",
      "loss 2.323533, train acc 0.099785\n",
      "round 233\n",
      "time to device 0.003923 sec\n",
      "time forward 3.057269 sec\n",
      "loss time 0.001076 sec\n",
      "backward time 0.011273 sec\n",
      "optimizer time 0.026960 sec\n",
      "training time in round 233 cost 0.37999391555786133 sec\n",
      "loss 2.323427, train acc 0.099760\n",
      "round 234\n",
      "time to device 0.003857 sec\n",
      "time forward 3.064853 sec\n",
      "loss time 0.000529 sec\n",
      "backward time 0.004527 sec\n",
      "optimizer time 0.012775 sec\n",
      "training time in round 234 cost 0.34715819358825684 sec\n",
      "loss 2.323355, train acc 0.099734\n",
      "round 235\n",
      "time to device 0.004003 sec\n",
      "time forward 3.078519 sec\n",
      "loss time 0.002331 sec\n",
      "backward time 0.015466 sec\n",
      "optimizer time 0.025073 sec\n",
      "training time in round 235 cost 0.39444684982299805 sec\n",
      "loss 2.323274, train acc 0.099808\n",
      "round 236\n",
      "time to device 0.003816 sec\n",
      "time forward 3.093297 sec\n",
      "loss time 0.001438 sec\n",
      "backward time 0.012093 sec\n",
      "optimizer time 0.023400 sec\n",
      "training time in round 236 cost 0.38606691360473633 sec\n",
      "loss 2.323175, train acc 0.099848\n",
      "round 237\n",
      "time to device 0.004103 sec\n",
      "time forward 3.105732 sec\n",
      "loss time 0.001869 sec\n",
      "backward time 0.014899 sec\n",
      "optimizer time 0.028023 sec\n",
      "training time in round 237 cost 0.388660192489624 sec\n",
      "loss 2.323099, train acc 0.099987\n",
      "round 238\n",
      "time to device 0.004426 sec\n",
      "time forward 3.118780 sec\n",
      "loss time 0.002017 sec\n",
      "backward time 0.012979 sec\n",
      "optimizer time 0.028046 sec\n",
      "training time in round 238 cost 0.3911619186401367 sec\n",
      "loss 2.323117, train acc 0.099928\n",
      "round 239\n",
      "time to device 0.003620 sec\n",
      "time forward 3.131631 sec\n",
      "loss time 0.001829 sec\n",
      "backward time 0.013646 sec\n",
      "optimizer time 0.026121 sec\n",
      "training time in round 239 cost 0.39045095443725586 sec\n",
      "loss 2.323032, train acc 0.099837\n",
      "round 240\n",
      "time to device 0.004343 sec\n",
      "time forward 3.145730 sec\n",
      "loss time 0.002072 sec\n",
      "backward time 0.012510 sec\n",
      "optimizer time 0.024992 sec\n",
      "training time in round 240 cost 0.39126110076904297 sec\n",
      "loss 2.322929, train acc 0.099780\n",
      "round 241\n",
      "time to device 0.003415 sec\n",
      "time forward 3.159077 sec\n",
      "loss time 0.001926 sec\n",
      "backward time 0.013027 sec\n",
      "optimizer time 0.024864 sec\n",
      "training time in round 241 cost 0.38904595375061035 sec\n",
      "loss 2.322908, train acc 0.099561\n",
      "round 242\n",
      "time to device 0.003705 sec\n",
      "time forward 3.172067 sec\n",
      "loss time 0.001447 sec\n",
      "backward time 0.011008 sec\n",
      "optimizer time 0.023439 sec\n",
      "training time in round 242 cost 0.38259315490722656 sec\n",
      "loss 2.322822, train acc 0.099537\n",
      "round 243\n",
      "time to device 0.005640 sec\n",
      "time forward 3.182522 sec\n",
      "loss time 0.001820 sec\n",
      "backward time 0.013004 sec\n",
      "optimizer time 0.023371 sec\n",
      "training time in round 243 cost 0.3778078556060791 sec\n",
      "loss 2.322759, train acc 0.099321\n",
      "round 244\n",
      "time to device 0.004258 sec\n",
      "time forward 3.195403 sec\n",
      "loss time 0.002029 sec\n",
      "backward time 0.013251 sec\n",
      "optimizer time 0.024456 sec\n",
      "training time in round 244 cost 0.3895750045776367 sec\n",
      "loss 2.322684, train acc 0.099171\n",
      "round 245\n",
      "time to device 0.004717 sec\n",
      "time forward 3.202444 sec\n",
      "loss time 0.000555 sec\n",
      "backward time 0.005131 sec\n",
      "optimizer time 0.013727 sec\n",
      "training time in round 245 cost 0.3591639995574951 sec\n",
      "loss 2.322628, train acc 0.099117\n",
      "round 246\n",
      "time to device 0.003676 sec\n",
      "time forward 3.214850 sec\n",
      "loss time 0.001462 sec\n",
      "backward time 0.014606 sec\n",
      "optimizer time 0.025648 sec\n",
      "training time in round 246 cost 0.38346123695373535 sec\n",
      "loss 2.322547, train acc 0.099001\n",
      "round 247\n",
      "time to device 0.003806 sec\n",
      "time forward 3.229203 sec\n",
      "loss time 0.001455 sec\n",
      "backward time 0.013024 sec\n",
      "optimizer time 0.023374 sec\n",
      "training time in round 247 cost 0.38655591011047363 sec\n",
      "loss 2.322473, train acc 0.098979\n",
      "round 248\n",
      "time to device 0.004474 sec\n",
      "time forward 3.241319 sec\n",
      "loss time 0.001045 sec\n",
      "backward time 0.012408 sec\n",
      "optimizer time 0.025995 sec\n",
      "training time in round 248 cost 0.3831040859222412 sec\n",
      "loss 2.322394, train acc 0.099084\n",
      "round 249\n",
      "time to device 0.004013 sec\n",
      "time forward 3.252915 sec\n",
      "loss time 0.001595 sec\n",
      "backward time 0.013427 sec\n",
      "optimizer time 0.025070 sec\n",
      "training time in round 249 cost 0.38570380210876465 sec\n",
      "loss 2.322332, train acc 0.098969\n",
      "round 250\n",
      "time to device 0.002878 sec\n",
      "time forward 3.264827 sec\n",
      "loss time 0.001149 sec\n",
      "backward time 0.009797 sec\n",
      "optimizer time 0.019762 sec\n",
      "training time in round 250 cost 0.3683161735534668 sec\n",
      "loss 2.322246, train acc 0.099010\n",
      "round 251\n",
      "time to device 0.003043 sec\n",
      "time forward 3.278590 sec\n",
      "loss time 0.001870 sec\n",
      "backward time 0.016604 sec\n",
      "optimizer time 0.023567 sec\n",
      "training time in round 251 cost 0.39315199851989746 sec\n",
      "loss 2.322186, train acc 0.098803\n",
      "round 252\n",
      "time to device 0.004374 sec\n",
      "time forward 3.292613 sec\n",
      "loss time 0.001346 sec\n",
      "backward time 0.011425 sec\n",
      "optimizer time 0.021428 sec\n",
      "training time in round 252 cost 0.3874349594116211 sec\n",
      "loss 2.322119, train acc 0.098783\n",
      "round 253\n",
      "time to device 0.010607 sec\n",
      "time forward 3.304200 sec\n",
      "loss time 0.001856 sec\n",
      "backward time 0.014445 sec\n",
      "optimizer time 0.026106 sec\n",
      "training time in round 253 cost 0.39003491401672363 sec\n",
      "loss 2.322053, train acc 0.098764\n",
      "round 254\n",
      "time to device 0.003566 sec\n",
      "time forward 3.317379 sec\n",
      "loss time 0.001967 sec\n",
      "backward time 0.014555 sec\n",
      "optimizer time 0.026124 sec\n",
      "training time in round 254 cost 0.3922891616821289 sec\n",
      "loss 2.321987, train acc 0.098683\n",
      "round 255\n",
      "time to device 0.004484 sec\n",
      "time forward 3.330901 sec\n",
      "loss time 0.001253 sec\n",
      "backward time 0.015600 sec\n",
      "optimizer time 0.025428 sec\n",
      "training time in round 255 cost 0.3971366882324219 sec\n",
      "loss 2.321912, train acc 0.098816\n",
      "round 256\n",
      "time to device 0.003650 sec\n",
      "time forward 3.346154 sec\n",
      "loss time 0.002071 sec\n",
      "backward time 0.010816 sec\n",
      "optimizer time 0.025547 sec\n",
      "training time in round 256 cost 0.4276161193847656 sec\n",
      "loss 2.321844, train acc 0.098796\n",
      "round 257\n",
      "time to device 0.004095 sec\n",
      "time forward 3.356629 sec\n",
      "loss time 0.000785 sec\n",
      "backward time 0.007067 sec\n",
      "optimizer time 0.013727 sec\n",
      "training time in round 257 cost 0.3672001361846924 sec\n",
      "loss 2.321775, train acc 0.098837\n",
      "round 258\n",
      "time to device 0.003914 sec\n",
      "time forward 3.364083 sec\n",
      "loss time 0.000576 sec\n",
      "backward time 0.005108 sec\n",
      "optimizer time 0.013569 sec\n",
      "training time in round 258 cost 0.35871386528015137 sec\n",
      "loss 2.321711, train acc 0.098757\n",
      "round 259\n",
      "time to device 0.004652 sec\n",
      "time forward 3.378368 sec\n",
      "loss time 0.002069 sec\n",
      "backward time 0.013190 sec\n",
      "optimizer time 0.025593 sec\n",
      "training time in round 259 cost 0.3974168300628662 sec\n",
      "loss 2.321642, train acc 0.098588\n",
      "round 260\n",
      "time to device 0.004602 sec\n",
      "time forward 3.391649 sec\n",
      "loss time 0.001937 sec\n",
      "backward time 0.013870 sec\n",
      "optimizer time 0.025026 sec\n",
      "training time in round 260 cost 0.3916637897491455 sec\n",
      "loss 2.321648, train acc 0.098509\n",
      "round 261\n",
      "time to device 0.003780 sec\n",
      "time forward 3.403121 sec\n",
      "loss time 0.001877 sec\n",
      "backward time 0.014541 sec\n",
      "optimizer time 0.024459 sec\n",
      "training time in round 261 cost 0.38317394256591797 sec\n",
      "loss 2.321577, train acc 0.098521\n",
      "round 262\n",
      "time to device 0.004031 sec\n",
      "time forward 3.413585 sec\n",
      "loss time 0.001551 sec\n",
      "backward time 0.012315 sec\n",
      "optimizer time 0.024437 sec\n",
      "training time in round 262 cost 0.373089075088501 sec\n",
      "loss 2.321512, train acc 0.098562\n",
      "round 263\n",
      "time to device 0.003965 sec\n",
      "time forward 3.426196 sec\n",
      "loss time 0.001763 sec\n",
      "backward time 0.015323 sec\n",
      "optimizer time 0.016880 sec\n",
      "training time in round 263 cost 0.41123366355895996 sec\n",
      "loss 2.321440, train acc 0.098662\n",
      "round 264\n",
      "time to device 0.004484 sec\n",
      "time forward 3.438173 sec\n",
      "loss time 0.001218 sec\n",
      "backward time 0.018163 sec\n",
      "optimizer time 0.023102 sec\n",
      "training time in round 264 cost 0.42197394371032715 sec\n",
      "loss 2.321385, train acc 0.098555\n",
      "round 265\n",
      "time to device 0.004808 sec\n",
      "time forward 3.445407 sec\n",
      "loss time 0.000556 sec\n",
      "backward time 0.005141 sec\n",
      "optimizer time 0.014384 sec\n",
      "training time in round 265 cost 0.35703206062316895 sec\n",
      "loss 2.321315, train acc 0.098684\n",
      "round 266\n",
      "time to device 0.004775 sec\n",
      "time forward 3.460380 sec\n",
      "loss time 0.001624 sec\n",
      "backward time 0.016302 sec\n",
      "optimizer time 0.020968 sec\n",
      "training time in round 266 cost 0.4195120334625244 sec\n",
      "loss 2.321243, train acc 0.098724\n",
      "round 267\n",
      "time to device 0.008297 sec\n",
      "time forward 3.473712 sec\n",
      "loss time 0.001842 sec\n",
      "backward time 0.011549 sec\n",
      "optimizer time 0.024557 sec\n",
      "training time in round 267 cost 0.4028770923614502 sec\n",
      "loss 2.321171, train acc 0.098822\n",
      "round 268\n",
      "time to device 0.006168 sec\n",
      "time forward 3.486986 sec\n",
      "loss time 0.001882 sec\n",
      "backward time 0.012886 sec\n",
      "optimizer time 0.023399 sec\n",
      "training time in round 268 cost 0.3916339874267578 sec\n",
      "loss 2.321106, train acc 0.098832\n",
      "round 269\n",
      "time to device 0.008511 sec\n",
      "time forward 3.501328 sec\n",
      "loss time 0.001382 sec\n",
      "backward time 0.016649 sec\n",
      "optimizer time 0.020692 sec\n",
      "training time in round 269 cost 0.3957250118255615 sec\n",
      "loss 2.321051, train acc 0.098640\n",
      "round 270\n",
      "time to device 0.008059 sec\n",
      "time forward 3.515321 sec\n",
      "loss time 0.001905 sec\n",
      "backward time 0.015432 sec\n",
      "optimizer time 0.026107 sec\n",
      "training time in round 270 cost 0.41475415229797363 sec\n",
      "loss 2.320987, train acc 0.098708\n",
      "round 271\n",
      "time to device 0.006911 sec\n",
      "time forward 3.528928 sec\n",
      "loss time 0.001441 sec\n",
      "backward time 0.012640 sec\n",
      "optimizer time 0.023395 sec\n",
      "training time in round 271 cost 0.39056992530822754 sec\n",
      "loss 2.323898, train acc 0.098719\n",
      "round 272\n",
      "time to device 0.002983 sec\n",
      "time forward 3.543588 sec\n",
      "loss time 0.001410 sec\n",
      "backward time 0.018031 sec\n",
      "optimizer time 0.022861 sec\n",
      "training time in round 272 cost 0.3955349922180176 sec\n",
      "loss 2.323855, train acc 0.098729\n",
      "round 273\n",
      "time to device 0.004336 sec\n",
      "time forward 3.556199 sec\n",
      "loss time 0.001868 sec\n",
      "backward time 0.017937 sec\n",
      "optimizer time 0.024183 sec\n",
      "training time in round 273 cost 0.40399599075317383 sec\n",
      "loss 2.323871, train acc 0.098654\n",
      "round 274\n",
      "time to device 0.004045 sec\n",
      "time forward 3.570677 sec\n",
      "loss time 0.002334 sec\n",
      "backward time 0.016104 sec\n",
      "optimizer time 0.024238 sec\n",
      "training time in round 274 cost 0.3990340232849121 sec\n",
      "loss 2.323795, train acc 0.098750\n",
      "round 275\n",
      "time to device 0.003503 sec\n",
      "time forward 3.584188 sec\n",
      "loss time 0.001100 sec\n",
      "backward time 0.010254 sec\n",
      "optimizer time 0.027396 sec\n",
      "training time in round 275 cost 0.386401891708374 sec\n",
      "loss 2.323703, train acc 0.098760\n",
      "round 276\n",
      "time to device 0.004113 sec\n",
      "time forward 3.599680 sec\n",
      "loss time 0.001456 sec\n",
      "backward time 0.015192 sec\n",
      "optimizer time 0.023959 sec\n",
      "training time in round 276 cost 0.39447689056396484 sec\n",
      "loss 2.323803, train acc 0.098742\n",
      "round 277\n",
      "time to device 0.003672 sec\n",
      "time forward 3.614870 sec\n",
      "loss time 0.001447 sec\n",
      "backward time 0.013607 sec\n",
      "optimizer time 0.024787 sec\n",
      "training time in round 277 cost 0.3971090316772461 sec\n",
      "loss 2.323929, train acc 0.098584\n",
      "round 278\n",
      "time to device 0.003672 sec\n",
      "time forward 3.626139 sec\n",
      "loss time 0.001203 sec\n",
      "backward time 0.013499 sec\n",
      "optimizer time 0.027142 sec\n",
      "training time in round 278 cost 0.3820359706878662 sec\n",
      "loss 2.323849, train acc 0.098566\n",
      "round 279\n",
      "time to device 0.004189 sec\n",
      "time forward 3.642613 sec\n",
      "loss time 0.001875 sec\n",
      "backward time 0.014850 sec\n",
      "optimizer time 0.025754 sec\n",
      "training time in round 279 cost 0.4125518798828125 sec\n",
      "loss 2.323775, train acc 0.098437\n",
      "round 280\n",
      "time to device 0.003714 sec\n",
      "time forward 3.657966 sec\n",
      "loss time 0.001363 sec\n",
      "backward time 0.011150 sec\n",
      "optimizer time 0.022510 sec\n",
      "training time in round 280 cost 0.39019203186035156 sec\n",
      "loss 2.323696, train acc 0.098476\n",
      "round 281\n",
      "time to device 0.004017 sec\n",
      "time forward 3.665625 sec\n",
      "loss time 0.000572 sec\n",
      "backward time 0.005058 sec\n",
      "optimizer time 0.013018 sec\n",
      "training time in round 281 cost 0.3395810127258301 sec\n",
      "loss 2.323616, train acc 0.098570\n",
      "round 282\n",
      "time to device 0.003154 sec\n",
      "time forward 3.681467 sec\n",
      "loss time 0.000886 sec\n",
      "backward time 0.011123 sec\n",
      "optimizer time 0.020543 sec\n",
      "training time in round 282 cost 0.38460469245910645 sec\n",
      "loss 2.323572, train acc 0.098609\n",
      "round 283\n",
      "time to device 0.003596 sec\n",
      "time forward 3.695328 sec\n",
      "loss time 0.001361 sec\n",
      "backward time 0.010777 sec\n",
      "optimizer time 0.021695 sec\n",
      "training time in round 283 cost 0.4206409454345703 sec\n",
      "loss 2.323493, train acc 0.098702\n",
      "round 284\n",
      "time to device 0.007352 sec\n",
      "time forward 3.713604 sec\n",
      "loss time 0.001549 sec\n",
      "backward time 0.012101 sec\n",
      "optimizer time 0.026203 sec\n",
      "training time in round 284 cost 0.41952013969421387 sec\n",
      "loss 2.323422, train acc 0.098712\n",
      "round 285\n",
      "time to device 0.009155 sec\n",
      "time forward 3.730331 sec\n",
      "loss time 0.001113 sec\n",
      "backward time 0.018788 sec\n",
      "optimizer time 0.024354 sec\n",
      "training time in round 285 cost 0.4295079708099365 sec\n",
      "loss 2.323357, train acc 0.098804\n",
      "round 286\n",
      "time to device 0.009187 sec\n",
      "time forward 3.743585 sec\n",
      "loss time 0.001439 sec\n",
      "backward time 0.015253 sec\n",
      "optimizer time 0.024835 sec\n",
      "training time in round 286 cost 0.39270710945129395 sec\n",
      "loss 2.323288, train acc 0.098759\n",
      "round 287\n",
      "time to device 0.006998 sec\n",
      "time forward 3.755893 sec\n",
      "loss time 0.001501 sec\n",
      "backward time 0.012055 sec\n",
      "optimizer time 0.023927 sec\n",
      "training time in round 287 cost 0.38762617111206055 sec\n",
      "loss 2.323226, train acc 0.098768\n",
      "round 288\n",
      "time to device 0.008579 sec\n",
      "time forward 3.768311 sec\n",
      "loss time 0.001175 sec\n",
      "backward time 0.014880 sec\n",
      "optimizer time 0.026210 sec\n",
      "training time in round 288 cost 0.3901510238647461 sec\n",
      "loss 2.323150, train acc 0.098778\n",
      "round 289\n",
      "time to device 0.008622 sec\n",
      "time forward 3.783774 sec\n",
      "loss time 0.001922 sec\n",
      "backward time 0.015414 sec\n",
      "optimizer time 0.027466 sec\n",
      "training time in round 289 cost 0.44764184951782227 sec\n",
      "loss 2.323081, train acc 0.098788\n",
      "round 290\n",
      "time to device 0.007412 sec\n",
      "time forward 3.795469 sec\n",
      "loss time 0.001510 sec\n",
      "backward time 0.013939 sec\n",
      "optimizer time 0.017328 sec\n",
      "training time in round 290 cost 0.41271018981933594 sec\n",
      "loss 2.323012, train acc 0.098797\n",
      "round 291\n",
      "time to device 0.008147 sec\n",
      "time forward 3.806307 sec\n",
      "loss time 0.005832 sec\n",
      "backward time 0.006719 sec\n",
      "optimizer time 0.017380 sec\n",
      "training time in round 291 cost 0.4088408946990967 sec\n",
      "loss 2.323166, train acc 0.098860\n",
      "round 292\n",
      "time to device 0.009151 sec\n",
      "time forward 3.820657 sec\n",
      "loss time 0.001712 sec\n",
      "backward time 0.016948 sec\n",
      "optimizer time 0.026005 sec\n",
      "training time in round 292 cost 0.42450404167175293 sec\n",
      "loss 2.323122, train acc 0.098763\n",
      "round 293\n",
      "time to device 0.008282 sec\n",
      "time forward 3.834878 sec\n",
      "loss time 0.002045 sec\n",
      "backward time 0.017197 sec\n",
      "optimizer time 0.022001 sec\n",
      "training time in round 293 cost 0.40814709663391113 sec\n",
      "loss 2.323049, train acc 0.098825\n",
      "round 294\n",
      "time to device 0.009405 sec\n",
      "time forward 3.848554 sec\n",
      "loss time 0.002029 sec\n",
      "backward time 0.014204 sec\n",
      "optimizer time 0.024719 sec\n",
      "training time in round 294 cost 0.40771007537841797 sec\n",
      "loss 2.322970, train acc 0.098835\n",
      "round 295\n",
      "time to device 0.009554 sec\n",
      "time forward 3.862463 sec\n",
      "loss time 0.002157 sec\n",
      "backward time 0.012186 sec\n",
      "optimizer time 0.023042 sec\n",
      "training time in round 295 cost 0.4165208339691162 sec\n",
      "loss 2.322914, train acc 0.098765\n",
      "round 296\n",
      "time to device 0.010232 sec\n",
      "time forward 3.876436 sec\n",
      "loss time 0.001573 sec\n",
      "backward time 0.007223 sec\n",
      "optimizer time 0.027060 sec\n",
      "training time in round 296 cost 0.4129180908203125 sec\n",
      "loss 2.322854, train acc 0.098722\n",
      "round 297\n",
      "time to device 0.009640 sec\n",
      "time forward 3.883152 sec\n",
      "loss time 0.000639 sec\n",
      "backward time 0.005770 sec\n",
      "optimizer time 0.015117 sec\n",
      "training time in round 297 cost 0.3629472255706787 sec\n",
      "loss 2.322778, train acc 0.098679\n",
      "round 298\n",
      "time to device 0.007912 sec\n",
      "time forward 3.899242 sec\n",
      "loss time 0.001903 sec\n",
      "backward time 0.014554 sec\n",
      "optimizer time 0.027703 sec\n",
      "training time in round 298 cost 0.43196702003479004 sec\n",
      "loss 2.322724, train acc 0.098662\n",
      "round 299\n",
      "time to device 0.008684 sec\n",
      "time forward 3.910426 sec\n",
      "loss time 0.001938 sec\n",
      "backward time 0.020164 sec\n",
      "optimizer time 0.021431 sec\n",
      "training time in round 299 cost 0.3949241638183594 sec\n",
      "loss 2.322669, train acc 0.098620\n",
      "round 300\n",
      "time to device 0.007195 sec\n",
      "time forward 3.924159 sec\n",
      "loss time 0.001178 sec\n",
      "backward time 0.011951 sec\n",
      "optimizer time 0.026978 sec\n",
      "training time in round 300 cost 0.42172813415527344 sec\n",
      "loss 2.322602, train acc 0.098707\n",
      "round 301\n",
      "time to device 0.010134 sec\n",
      "time forward 3.937293 sec\n",
      "loss time 0.001982 sec\n",
      "backward time 0.016237 sec\n",
      "optimizer time 0.025688 sec\n",
      "training time in round 301 cost 0.43323802947998047 sec\n",
      "loss 2.322543, train acc 0.098717\n",
      "round 302\n",
      "time to device 0.011502 sec\n",
      "time forward 3.951408 sec\n",
      "loss time 0.001996 sec\n",
      "backward time 0.022582 sec\n",
      "optimizer time 0.023393 sec\n",
      "training time in round 302 cost 0.41634321212768555 sec\n",
      "loss 2.322490, train acc 0.098675\n",
      "round 303\n",
      "time to device 0.010325 sec\n",
      "time forward 3.960273 sec\n",
      "loss time 0.001334 sec\n",
      "backward time 0.017680 sec\n",
      "optimizer time 0.024871 sec\n",
      "training time in round 303 cost 0.41162586212158203 sec\n",
      "loss 2.322424, train acc 0.098813\n",
      "round 304\n",
      "time to device 0.004325 sec\n",
      "time forward 3.974727 sec\n",
      "loss time 0.001667 sec\n",
      "backward time 0.014678 sec\n",
      "optimizer time 0.024216 sec\n",
      "training time in round 304 cost 0.4008603096008301 sec\n",
      "loss 2.323293, train acc 0.098719\n",
      "round 305\n",
      "time to device 0.003517 sec\n",
      "time forward 3.992119 sec\n",
      "loss time 0.001925 sec\n",
      "backward time 0.013181 sec\n",
      "optimizer time 0.023321 sec\n",
      "training time in round 305 cost 0.40815091133117676 sec\n",
      "loss 2.323233, train acc 0.098626\n",
      "round 306\n",
      "time to device 0.004609 sec\n",
      "time forward 4.007202 sec\n",
      "loss time 0.001491 sec\n",
      "backward time 0.012021 sec\n",
      "optimizer time 0.025096 sec\n",
      "training time in round 306 cost 0.39969515800476074 sec\n",
      "loss 2.323163, train acc 0.098636\n",
      "round 307\n",
      "time to device 0.004057 sec\n",
      "time forward 4.021836 sec\n",
      "loss time 0.001815 sec\n",
      "backward time 0.011433 sec\n",
      "optimizer time 0.028382 sec\n",
      "training time in round 307 cost 0.39965105056762695 sec\n",
      "loss 2.323186, train acc 0.098645\n",
      "round 308\n",
      "time to device 0.003187 sec\n",
      "time forward 4.036174 sec\n",
      "loss time 0.002007 sec\n",
      "backward time 0.011445 sec\n",
      "optimizer time 0.024686 sec\n",
      "training time in round 308 cost 0.39368510246276855 sec\n",
      "loss 2.323123, train acc 0.098630\n",
      "round 309\n",
      "time to device 0.003437 sec\n",
      "time forward 4.050634 sec\n",
      "loss time 0.001484 sec\n",
      "backward time 0.013497 sec\n",
      "optimizer time 0.026802 sec\n",
      "training time in round 309 cost 0.4021487236022949 sec\n",
      "loss 2.323063, train acc 0.098513\n",
      "round 310\n",
      "time to device 0.003696 sec\n",
      "time forward 4.066580 sec\n",
      "loss time 0.001633 sec\n",
      "backward time 0.016535 sec\n",
      "optimizer time 0.024442 sec\n",
      "training time in round 310 cost 0.4100029468536377 sec\n",
      "loss 2.322994, train acc 0.098548\n",
      "round 311\n",
      "time to device 0.004046 sec\n",
      "time forward 4.080923 sec\n",
      "loss time 0.001534 sec\n",
      "backward time 0.013558 sec\n",
      "optimizer time 0.024792 sec\n",
      "training time in round 311 cost 0.39540910720825195 sec\n",
      "loss 2.322933, train acc 0.098683\n",
      "round 312\n",
      "time to device 0.003509 sec\n",
      "time forward 4.094514 sec\n",
      "loss time 0.001944 sec\n",
      "backward time 0.015834 sec\n",
      "optimizer time 0.026957 sec\n",
      "training time in round 312 cost 0.4007449150085449 sec\n",
      "loss 2.322867, train acc 0.098642\n",
      "round 313\n",
      "time to device 0.004228 sec\n",
      "time forward 4.101357 sec\n",
      "loss time 0.000575 sec\n",
      "backward time 0.005164 sec\n",
      "optimizer time 0.013850 sec\n",
      "training time in round 313 cost 0.34767889976501465 sec\n",
      "loss 2.322772, train acc 0.098701\n",
      "round 314\n",
      "time to device 0.003151 sec\n",
      "time forward 4.114300 sec\n",
      "loss time 0.002052 sec\n",
      "backward time 0.014774 sec\n",
      "optimizer time 0.025516 sec\n",
      "training time in round 314 cost 0.3946249485015869 sec\n",
      "loss 2.322703, train acc 0.098810\n",
      "round 315\n",
      "time to device 0.004416 sec\n",
      "time forward 4.128780 sec\n",
      "loss time 0.002539 sec\n",
      "backward time 0.013500 sec\n",
      "optimizer time 0.026394 sec\n",
      "training time in round 315 cost 0.40072011947631836 sec\n",
      "loss 2.322636, train acc 0.098917\n",
      "round 316\n",
      "time to device 0.003825 sec\n",
      "time forward 4.141772 sec\n",
      "loss time 0.001525 sec\n",
      "backward time 0.013777 sec\n",
      "optimizer time 0.024648 sec\n",
      "training time in round 316 cost 0.3927040100097656 sec\n",
      "loss 2.322569, train acc 0.099024\n",
      "round 317\n",
      "time to device 0.003340 sec\n",
      "time forward 4.154542 sec\n",
      "loss time 0.001399 sec\n",
      "backward time 0.014055 sec\n",
      "optimizer time 0.025912 sec\n",
      "training time in round 317 cost 0.38927578926086426 sec\n",
      "loss 2.322509, train acc 0.099081\n",
      "round 318\n",
      "time to device 0.004796 sec\n",
      "time forward 4.169021 sec\n",
      "loss time 0.001849 sec\n",
      "backward time 0.013318 sec\n",
      "optimizer time 0.023869 sec\n",
      "training time in round 318 cost 0.3967471122741699 sec\n",
      "loss 2.322450, train acc 0.099064\n",
      "round 319\n",
      "time to device 0.005243 sec\n",
      "time forward 4.184194 sec\n",
      "loss time 0.001884 sec\n",
      "backward time 0.016152 sec\n",
      "optimizer time 0.035384 sec\n",
      "training time in round 319 cost 0.45279407501220703 sec\n",
      "loss 2.322396, train acc 0.098950\n",
      "round 320\n",
      "time to device 0.006617 sec\n",
      "time forward 4.208205 sec\n",
      "loss time 0.001866 sec\n",
      "backward time 0.017202 sec\n",
      "optimizer time 0.028738 sec\n",
      "training time in round 320 cost 0.42687392234802246 sec\n",
      "loss 2.322332, train acc 0.099031\n",
      "round 321\n",
      "time to device 0.004213 sec\n",
      "time forward 4.220805 sec\n",
      "loss time 0.001344 sec\n",
      "backward time 0.011827 sec\n",
      "optimizer time 0.023859 sec\n",
      "training time in round 321 cost 0.38394880294799805 sec\n",
      "loss 2.322275, train acc 0.098991\n",
      "round 322\n",
      "time to device 0.003175 sec\n",
      "time forward 4.236803 sec\n",
      "loss time 0.001911 sec\n",
      "backward time 0.014796 sec\n",
      "optimizer time 0.024787 sec\n",
      "training time in round 322 cost 0.4025561809539795 sec\n",
      "loss 2.322206, train acc 0.099047\n",
      "round 323\n",
      "time to device 0.004102 sec\n",
      "time forward 4.251689 sec\n",
      "loss time 0.001533 sec\n",
      "backward time 0.011801 sec\n",
      "optimizer time 0.024258 sec\n",
      "training time in round 323 cost 0.3915140628814697 sec\n",
      "loss 2.322151, train acc 0.098982\n",
      "round 324\n",
      "time to device 0.003997 sec\n",
      "time forward 4.265527 sec\n",
      "loss time 0.001717 sec\n",
      "backward time 0.014046 sec\n",
      "optimizer time 0.018635 sec\n",
      "training time in round 324 cost 0.3861730098724365 sec\n",
      "loss 2.322081, train acc 0.099111\n",
      "round 325\n",
      "time to device 0.004105 sec\n",
      "time forward 4.279644 sec\n",
      "loss time 0.001907 sec\n",
      "backward time 0.015981 sec\n",
      "optimizer time 0.028047 sec\n",
      "training time in round 325 cost 0.4014170169830322 sec\n",
      "loss 2.321953, train acc 0.099262\n",
      "round 326\n",
      "time to device 0.004202 sec\n",
      "time forward 4.295831 sec\n",
      "loss time 0.002102 sec\n",
      "backward time 0.011855 sec\n",
      "optimizer time 0.023909 sec\n",
      "training time in round 326 cost 0.4031181335449219 sec\n",
      "loss 2.321895, train acc 0.099245\n",
      "round 327\n",
      "time to device 0.003984 sec\n",
      "time forward 4.310454 sec\n",
      "loss time 0.001447 sec\n",
      "backward time 0.011573 sec\n",
      "optimizer time 0.022688 sec\n",
      "training time in round 327 cost 0.3909180164337158 sec\n",
      "loss 2.321839, train acc 0.099181\n",
      "round 328\n",
      "time to device 0.005121 sec\n",
      "time forward 4.332867 sec\n",
      "loss time 0.001397 sec\n",
      "backward time 0.011886 sec\n",
      "optimizer time 0.022601 sec\n",
      "training time in round 328 cost 0.4061617851257324 sec\n",
      "loss 2.321776, train acc 0.099259\n",
      "round 329\n",
      "time to device 0.003694 sec\n",
      "time forward 4.342414 sec\n",
      "loss time 0.000618 sec\n",
      "backward time 0.006412 sec\n",
      "optimizer time 0.014362 sec\n",
      "training time in round 329 cost 0.35225510597229004 sec\n",
      "loss 2.321705, train acc 0.099408\n",
      "round 330\n",
      "time to device 0.004390 sec\n",
      "time forward 4.351646 sec\n",
      "loss time 0.001182 sec\n",
      "backward time 0.009062 sec\n",
      "optimizer time 0.020133 sec\n",
      "training time in round 330 cost 0.38668179512023926 sec\n",
      "loss 2.321648, train acc 0.099462\n",
      "round 331\n",
      "time to device 0.007747 sec\n",
      "time forward 4.366485 sec\n",
      "loss time 0.001952 sec\n",
      "backward time 0.017803 sec\n",
      "optimizer time 0.021395 sec\n",
      "training time in round 331 cost 0.4061570167541504 sec\n",
      "loss 2.321600, train acc 0.099445\n",
      "round 332\n",
      "time to device 0.008306 sec\n",
      "time forward 4.379240 sec\n",
      "loss time 0.001231 sec\n",
      "backward time 0.016465 sec\n",
      "optimizer time 0.025904 sec\n",
      "training time in round 332 cost 0.41327881813049316 sec\n",
      "loss 2.321545, train acc 0.099404\n",
      "round 333\n",
      "time to device 0.008979 sec\n",
      "time forward 4.392592 sec\n",
      "loss time 0.001852 sec\n",
      "backward time 0.013732 sec\n",
      "optimizer time 0.023916 sec\n",
      "training time in round 333 cost 0.39648008346557617 sec\n",
      "loss 2.321491, train acc 0.099481\n",
      "round 334\n",
      "time to device 0.004255 sec\n",
      "time forward 4.406974 sec\n",
      "loss time 0.001534 sec\n",
      "backward time 0.013534 sec\n",
      "optimizer time 0.022162 sec\n",
      "training time in round 334 cost 0.411179780960083 sec\n",
      "loss 2.321443, train acc 0.099417\n",
      "round 335\n",
      "time to device 0.005242 sec\n",
      "time forward 4.421754 sec\n",
      "loss time 0.001883 sec\n",
      "backward time 0.016748 sec\n",
      "optimizer time 0.025871 sec\n",
      "training time in round 335 cost 0.4286980628967285 sec\n",
      "loss 2.321387, train acc 0.099470\n",
      "round 336\n",
      "time to device 0.008126 sec\n",
      "time forward 4.436461 sec\n",
      "loss time 0.001812 sec\n",
      "backward time 0.014738 sec\n",
      "optimizer time 0.023935 sec\n",
      "training time in round 336 cost 0.40466880798339844 sec\n",
      "loss 2.321338, train acc 0.099476\n",
      "round 337\n",
      "time to device 0.008142 sec\n",
      "time forward 4.451094 sec\n",
      "loss time 0.001847 sec\n",
      "backward time 0.013704 sec\n",
      "optimizer time 0.024688 sec\n",
      "training time in round 337 cost 0.4016299247741699 sec\n",
      "loss 2.321298, train acc 0.099413\n",
      "round 338\n",
      "time to device 0.007055 sec\n",
      "time forward 4.466226 sec\n",
      "loss time 0.001176 sec\n",
      "backward time 0.014349 sec\n",
      "optimizer time 0.025543 sec\n",
      "training time in round 338 cost 0.3957710266113281 sec\n",
      "loss 2.321226, train acc 0.099488\n",
      "round 339\n",
      "time to device 0.009455 sec\n",
      "time forward 4.481456 sec\n",
      "loss time 0.001662 sec\n",
      "backward time 0.019194 sec\n",
      "optimizer time 0.021632 sec\n",
      "training time in round 339 cost 0.40555310249328613 sec\n",
      "loss 2.321699, train acc 0.099632\n",
      "round 340\n",
      "time to device 0.009411 sec\n",
      "time forward 4.487703 sec\n",
      "loss time 0.000940 sec\n",
      "backward time 0.008212 sec\n",
      "optimizer time 0.018737 sec\n",
      "training time in round 340 cost 0.3447551727294922 sec\n",
      "loss 2.321640, train acc 0.099638\n",
      "round 341\n",
      "time to device 0.009925 sec\n",
      "time forward 4.501997 sec\n",
      "loss time 0.002801 sec\n",
      "backward time 0.013543 sec\n",
      "optimizer time 0.024166 sec\n",
      "training time in round 341 cost 0.42104125022888184 sec\n",
      "loss 2.321639, train acc 0.099666\n",
      "round 342\n",
      "time to device 0.007365 sec\n",
      "time forward 4.516143 sec\n",
      "loss time 0.001654 sec\n",
      "backward time 0.012504 sec\n",
      "optimizer time 0.024245 sec\n",
      "training time in round 342 cost 0.4024970531463623 sec\n",
      "loss 2.321585, train acc 0.099558\n",
      "round 343\n",
      "time to device 0.004226 sec\n",
      "time forward 4.530526 sec\n",
      "loss time 0.001662 sec\n",
      "backward time 0.012673 sec\n",
      "optimizer time 0.022560 sec\n",
      "training time in round 343 cost 0.3979198932647705 sec\n",
      "loss 2.321503, train acc 0.099587\n",
      "round 344\n",
      "time to device 0.004692 sec\n",
      "time forward 4.545142 sec\n",
      "loss time 0.001472 sec\n",
      "backward time 0.012352 sec\n",
      "optimizer time 0.022916 sec\n",
      "training time in round 344 cost 0.4078190326690674 sec\n",
      "loss 2.321458, train acc 0.099592\n",
      "round 345\n",
      "time to device 0.003995 sec\n",
      "time forward 4.559561 sec\n",
      "loss time 0.001536 sec\n",
      "backward time 0.012229 sec\n",
      "optimizer time 0.022739 sec\n",
      "training time in round 345 cost 0.3998689651489258 sec\n",
      "loss 2.321415, train acc 0.099463\n",
      "round 346\n",
      "time to device 0.004009 sec\n",
      "time forward 4.573878 sec\n",
      "loss time 0.002579 sec\n",
      "backward time 0.010397 sec\n",
      "optimizer time 0.023120 sec\n",
      "training time in round 346 cost 0.4004950523376465 sec\n",
      "loss 2.321354, train acc 0.099536\n",
      "round 347\n",
      "time to device 0.003806 sec\n",
      "time forward 4.587003 sec\n",
      "loss time 0.001352 sec\n",
      "backward time 0.012622 sec\n",
      "optimizer time 0.022404 sec\n",
      "training time in round 347 cost 0.3922159671783447 sec\n",
      "loss 2.321375, train acc 0.099587\n",
      "round 348\n",
      "time to device 0.005343 sec\n",
      "time forward 4.594665 sec\n",
      "loss time 0.000583 sec\n",
      "backward time 0.005114 sec\n",
      "optimizer time 0.013314 sec\n",
      "training time in round 348 cost 0.35106468200683594 sec\n",
      "loss 2.321327, train acc 0.099615\n",
      "round 349\n",
      "time to device 0.004076 sec\n",
      "time forward 4.608409 sec\n",
      "loss time 0.001379 sec\n",
      "backward time 0.012688 sec\n",
      "optimizer time 0.021022 sec\n",
      "training time in round 349 cost 0.3910050392150879 sec\n",
      "loss 2.321274, train acc 0.099598\n",
      "round 350\n",
      "time to device 0.004939 sec\n",
      "time forward 4.623558 sec\n",
      "loss time 0.001510 sec\n",
      "backward time 0.012405 sec\n",
      "optimizer time 0.024035 sec\n",
      "training time in round 350 cost 0.4033501148223877 sec\n",
      "loss 2.321211, train acc 0.099671\n",
      "round 351\n",
      "time to device 0.004887 sec\n",
      "time forward 4.640565 sec\n",
      "loss time 0.001501 sec\n",
      "backward time 0.012835 sec\n",
      "optimizer time 0.022840 sec\n",
      "training time in round 351 cost 0.410081148147583 sec\n",
      "loss 2.321163, train acc 0.099698\n",
      "round 352\n",
      "time to device 0.004756 sec\n",
      "time forward 4.655950 sec\n",
      "loss time 0.001242 sec\n",
      "backward time 0.013858 sec\n",
      "optimizer time 0.026320 sec\n",
      "training time in round 352 cost 0.40407395362854004 sec\n",
      "loss 2.321116, train acc 0.099814\n",
      "round 353\n",
      "time to device 0.004469 sec\n",
      "time forward 4.671548 sec\n",
      "loss time 0.001976 sec\n",
      "backward time 0.014565 sec\n",
      "optimizer time 0.022842 sec\n",
      "training time in round 353 cost 0.4009518623352051 sec\n",
      "loss 2.321067, train acc 0.099929\n",
      "round 354\n",
      "time to device 0.004298 sec\n",
      "time forward 4.683074 sec\n",
      "loss time 0.000568 sec\n",
      "backward time 0.005201 sec\n",
      "optimizer time 0.014428 sec\n",
      "training time in round 354 cost 0.3621551990509033 sec\n",
      "loss 2.321022, train acc 0.099890\n",
      "round 355\n",
      "time to device 0.003746 sec\n",
      "time forward 4.696963 sec\n",
      "loss time 0.002153 sec\n",
      "backward time 0.013900 sec\n",
      "optimizer time 0.023711 sec\n",
      "training time in round 355 cost 0.39955902099609375 sec\n",
      "loss 2.320969, train acc 0.099982\n",
      "round 356\n",
      "time to device 0.004308 sec\n",
      "time forward 4.710736 sec\n",
      "loss time 0.001554 sec\n",
      "backward time 0.012833 sec\n",
      "optimizer time 0.022287 sec\n",
      "training time in round 356 cost 0.3889331817626953 sec\n",
      "loss 2.320918, train acc 0.099987\n",
      "round 357\n",
      "time to device 0.003436 sec\n",
      "time forward 4.723604 sec\n",
      "loss time 0.001248 sec\n",
      "backward time 0.011618 sec\n",
      "optimizer time 0.023319 sec\n",
      "training time in round 357 cost 0.38246703147888184 sec\n",
      "loss 2.320867, train acc 0.100079\n",
      "round 358\n",
      "time to device 0.003755 sec\n",
      "time forward 4.738552 sec\n",
      "loss time 0.001402 sec\n",
      "backward time 0.015713 sec\n",
      "optimizer time 0.013596 sec\n",
      "training time in round 358 cost 0.3888270854949951 sec\n",
      "loss 2.320804, train acc 0.100126\n",
      "round 359\n",
      "time to device 0.004273 sec\n",
      "time forward 4.751071 sec\n",
      "loss time 0.001132 sec\n",
      "backward time 0.015732 sec\n",
      "optimizer time 0.026301 sec\n",
      "training time in round 359 cost 0.40421199798583984 sec\n",
      "loss 2.320741, train acc 0.100087\n",
      "round 360\n",
      "time to device 0.008686 sec\n",
      "time forward 4.764331 sec\n",
      "loss time 0.001604 sec\n",
      "backward time 0.015709 sec\n",
      "optimizer time 0.024186 sec\n",
      "training time in round 360 cost 0.41716980934143066 sec\n",
      "loss 2.320688, train acc 0.100004\n",
      "round 361\n",
      "time to device 0.010003 sec\n",
      "time forward 4.778564 sec\n",
      "loss time 0.001856 sec\n",
      "backward time 0.016515 sec\n",
      "optimizer time 0.026591 sec\n",
      "training time in round 361 cost 0.4166409969329834 sec\n",
      "loss 2.320687, train acc 0.100009\n",
      "round 362\n",
      "time to device 0.007075 sec\n",
      "time forward 4.798705 sec\n",
      "loss time 0.001437 sec\n",
      "backward time 0.013708 sec\n",
      "optimizer time 0.022134 sec\n",
      "training time in round 362 cost 0.4105982780456543 sec\n",
      "loss 2.320686, train acc 0.100056\n",
      "round 363\n",
      "time to device 0.009313 sec\n",
      "time forward 4.812069 sec\n",
      "loss time 0.001494 sec\n",
      "backward time 0.014783 sec\n",
      "optimizer time 0.022852 sec\n",
      "training time in round 363 cost 0.40216588973999023 sec\n",
      "loss 2.320633, train acc 0.100103\n",
      "round 364\n",
      "time to device 0.006119 sec\n",
      "time forward 4.826003 sec\n",
      "loss time 0.001570 sec\n",
      "backward time 0.012613 sec\n",
      "optimizer time 0.022373 sec\n",
      "training time in round 364 cost 0.3935239315032959 sec\n",
      "loss 2.320580, train acc 0.100086\n",
      "round 365\n",
      "time to device 0.004047 sec\n",
      "time forward 4.841555 sec\n",
      "loss time 0.001483 sec\n",
      "backward time 0.011526 sec\n",
      "optimizer time 0.020937 sec\n",
      "training time in round 365 cost 0.39780092239379883 sec\n",
      "loss 2.320513, train acc 0.100111\n",
      "round 366\n",
      "time to device 0.004289 sec\n",
      "time forward 4.855064 sec\n",
      "loss time 0.001414 sec\n",
      "backward time 0.011604 sec\n",
      "optimizer time 0.022361 sec\n",
      "training time in round 366 cost 0.3843982219696045 sec\n",
      "loss 2.321183, train acc 0.100115\n",
      "round 367\n",
      "time to device 0.003896 sec\n",
      "time forward 4.870016 sec\n",
      "loss time 0.002233 sec\n",
      "backward time 0.011512 sec\n",
      "optimizer time 0.023616 sec\n",
      "training time in round 367 cost 0.39834094047546387 sec\n",
      "loss 2.321123, train acc 0.100183\n",
      "round 368\n",
      "time to device 0.003378 sec\n",
      "time forward 4.876972 sec\n",
      "loss time 0.000562 sec\n",
      "backward time 0.005049 sec\n",
      "optimizer time 0.013435 sec\n",
      "training time in round 368 cost 0.342012882232666 sec\n",
      "loss 2.321062, train acc 0.100250\n",
      "round 369\n",
      "time to device 0.004228 sec\n",
      "time forward 4.892401 sec\n",
      "loss time 0.001582 sec\n",
      "backward time 0.011333 sec\n",
      "optimizer time 0.020723 sec\n",
      "training time in round 369 cost 0.39223408699035645 sec\n",
      "loss 2.321021, train acc 0.100127\n",
      "round 370\n",
      "time to device 0.004339 sec\n",
      "time forward 4.907428 sec\n",
      "loss time 0.001848 sec\n",
      "backward time 0.014258 sec\n",
      "optimizer time 0.024305 sec\n",
      "training time in round 370 cost 0.39638686180114746 sec\n",
      "loss 2.320988, train acc 0.100110\n",
      "round 371\n",
      "time to device 0.002298 sec\n",
      "time forward 4.918295 sec\n",
      "loss time 0.001074 sec\n",
      "backward time 0.009777 sec\n",
      "optimizer time 0.020700 sec\n",
      "training time in round 371 cost 0.3728978633880615 sec\n",
      "loss 2.320910, train acc 0.100113\n",
      "round 372\n",
      "time to device 0.004609 sec\n",
      "time forward 4.932924 sec\n",
      "loss time 0.001707 sec\n",
      "backward time 0.016331 sec\n",
      "optimizer time 0.020918 sec\n",
      "training time in round 372 cost 0.3954000473022461 sec\n",
      "loss 2.320872, train acc 0.100117\n",
      "round 373\n",
      "time to device 0.004791 sec\n",
      "time forward 4.948476 sec\n",
      "loss time 0.002092 sec\n",
      "backward time 0.014668 sec\n",
      "optimizer time 0.025708 sec\n",
      "training time in round 373 cost 0.41614699363708496 sec\n",
      "loss 2.320820, train acc 0.100100\n",
      "round 374\n",
      "time to device 0.003629 sec\n",
      "time forward 4.962209 sec\n",
      "loss time 0.001829 sec\n",
      "backward time 0.013950 sec\n",
      "optimizer time 0.025072 sec\n",
      "training time in round 374 cost 0.3990647792816162 sec\n",
      "loss 2.320764, train acc 0.100104\n",
      "round 375\n",
      "time to device 0.004358 sec\n",
      "time forward 4.976623 sec\n",
      "loss time 0.001844 sec\n",
      "backward time 0.015513 sec\n",
      "optimizer time 0.025218 sec\n",
      "training time in round 375 cost 0.40392494201660156 sec\n",
      "loss 2.320732, train acc 0.100046\n",
      "round 376\n",
      "time to device 0.003735 sec\n",
      "time forward 4.991738 sec\n",
      "loss time 0.001800 sec\n",
      "backward time 0.015781 sec\n",
      "optimizer time 0.024730 sec\n",
      "training time in round 376 cost 0.40044593811035156 sec\n",
      "loss 2.320666, train acc 0.100195\n",
      "round 377\n",
      "time to device 0.003975 sec\n",
      "time forward 5.009048 sec\n",
      "loss time 0.001386 sec\n",
      "backward time 0.013547 sec\n",
      "optimizer time 0.024047 sec\n",
      "training time in round 377 cost 0.4014139175415039 sec\n",
      "loss 2.320611, train acc 0.100260\n",
      "round 378\n",
      "time to device 0.003687 sec\n",
      "time forward 5.022571 sec\n",
      "loss time 0.001329 sec\n",
      "backward time 0.010537 sec\n",
      "optimizer time 0.021527 sec\n",
      "training time in round 378 cost 0.3838930130004883 sec\n",
      "loss 2.320817, train acc 0.100284\n",
      "round 379\n",
      "time to device 0.003643 sec\n",
      "time forward 5.038032 sec\n",
      "loss time 0.001247 sec\n",
      "backward time 0.011636 sec\n",
      "optimizer time 0.022019 sec\n",
      "training time in round 379 cost 0.3948249816894531 sec\n",
      "loss 2.320777, train acc 0.100308\n",
      "round 380\n",
      "time to device 0.005575 sec\n",
      "time forward 5.054186 sec\n",
      "loss time 0.001867 sec\n",
      "backward time 0.014809 sec\n",
      "optimizer time 0.023835 sec\n",
      "training time in round 380 cost 0.40242481231689453 sec\n",
      "loss 2.320723, train acc 0.100271\n",
      "round 381\n",
      "time to device 0.004084 sec\n",
      "time forward 5.062945 sec\n",
      "loss time 0.000634 sec\n",
      "backward time 0.005643 sec\n",
      "optimizer time 0.014577 sec\n",
      "training time in round 381 cost 0.36531805992126465 sec\n",
      "loss 2.320662, train acc 0.100335\n",
      "round 382\n",
      "time to device 0.004719 sec\n",
      "time forward 5.076715 sec\n",
      "loss time 0.001502 sec\n",
      "backward time 0.012165 sec\n",
      "optimizer time 0.021230 sec\n",
      "training time in round 382 cost 0.3921191692352295 sec\n",
      "loss 2.320611, train acc 0.100318\n",
      "round 383\n",
      "time to device 0.005050 sec\n",
      "time forward 5.095164 sec\n",
      "loss time 0.001672 sec\n",
      "backward time 0.011091 sec\n",
      "optimizer time 0.022226 sec\n",
      "training time in round 383 cost 0.42156291007995605 sec\n",
      "loss 2.320592, train acc 0.100342\n",
      "round 384\n",
      "time to device 0.008274 sec\n",
      "time forward 5.110425 sec\n",
      "loss time 0.002592 sec\n",
      "backward time 0.011403 sec\n",
      "optimizer time 0.023779 sec\n",
      "training time in round 384 cost 0.4008610248565674 sec\n",
      "loss 2.322073, train acc 0.100304\n",
      "round 385\n",
      "time to device 0.007244 sec\n",
      "time forward 5.125097 sec\n",
      "loss time 0.001246 sec\n",
      "backward time 0.011396 sec\n",
      "optimizer time 0.021260 sec\n",
      "training time in round 385 cost 0.39737987518310547 sec\n",
      "loss 2.322023, train acc 0.100429\n",
      "round 386\n",
      "time to device 0.009645 sec\n",
      "time forward 5.138968 sec\n",
      "loss time 0.002361 sec\n",
      "backward time 0.017212 sec\n",
      "optimizer time 0.026441 sec\n",
      "training time in round 386 cost 0.403822660446167 sec\n",
      "loss 2.321982, train acc 0.100371\n",
      "round 387\n",
      "time to device 0.006771 sec\n",
      "time forward 5.152573 sec\n",
      "loss time 0.001666 sec\n",
      "backward time 0.014826 sec\n",
      "optimizer time 0.023386 sec\n",
      "training time in round 387 cost 0.39438676834106445 sec\n",
      "loss 2.321936, train acc 0.100475\n",
      "round 388\n",
      "time to device 0.008415 sec\n",
      "time forward 5.168340 sec\n",
      "loss time 0.001542 sec\n",
      "backward time 0.013604 sec\n",
      "optimizer time 0.023170 sec\n",
      "training time in round 388 cost 0.4138150215148926 sec\n",
      "loss 2.321853, train acc 0.100478\n",
      "round 389\n",
      "time to device 0.007433 sec\n",
      "time forward 5.183013 sec\n",
      "loss time 0.002437 sec\n",
      "backward time 0.014766 sec\n",
      "optimizer time 0.023565 sec\n",
      "training time in round 389 cost 0.40662503242492676 sec\n",
      "loss 2.321826, train acc 0.100461\n",
      "round 390\n",
      "time to device 0.006857 sec\n",
      "time forward 5.196884 sec\n",
      "loss time 0.001976 sec\n",
      "backward time 0.016896 sec\n",
      "optimizer time 0.024321 sec\n",
      "training time in round 390 cost 0.40805506706237793 sec\n",
      "loss 2.321769, train acc 0.100404\n",
      "round 391\n",
      "time to device 0.008833 sec\n",
      "time forward 5.210395 sec\n",
      "loss time 0.001584 sec\n",
      "backward time 0.011271 sec\n",
      "optimizer time 0.021763 sec\n",
      "training time in round 391 cost 0.3928718566894531 sec\n",
      "loss 2.321742, train acc 0.100287\n",
      "round 392\n",
      "time to device 0.003893 sec\n",
      "time forward 5.217083 sec\n",
      "loss time 0.000373 sec\n",
      "backward time 0.003252 sec\n",
      "optimizer time 0.013092 sec\n",
      "training time in round 392 cost 0.3484327793121338 sec\n",
      "loss 2.322251, train acc 0.100231\n",
      "round 393\n",
      "time to device 0.003523 sec\n",
      "time forward 5.231498 sec\n",
      "loss time 0.002016 sec\n",
      "backward time 0.014762 sec\n",
      "optimizer time 0.022904 sec\n",
      "training time in round 393 cost 0.39231181144714355 sec\n",
      "loss 2.322622, train acc 0.100234\n",
      "round 394\n",
      "time to device 0.004300 sec\n",
      "time forward 5.248026 sec\n",
      "loss time 0.001537 sec\n",
      "backward time 0.013664 sec\n",
      "optimizer time 0.022659 sec\n",
      "training time in round 394 cost 0.40326881408691406 sec\n",
      "loss 2.322714, train acc 0.100158\n",
      "round 395\n",
      "time to device 0.003582 sec\n",
      "time forward 5.262398 sec\n",
      "loss time 0.001509 sec\n",
      "backward time 0.012672 sec\n",
      "optimizer time 0.023573 sec\n",
      "training time in round 395 cost 0.3923361301422119 sec\n",
      "loss 2.322665, train acc 0.100142\n",
      "round 396\n",
      "time to device 0.005213 sec\n",
      "time forward 5.278410 sec\n",
      "loss time 0.001974 sec\n",
      "backward time 0.014115 sec\n",
      "optimizer time 0.025628 sec\n",
      "training time in round 396 cost 0.40222907066345215 sec\n",
      "loss 2.322608, train acc 0.100165\n",
      "round 397\n",
      "time to device 0.006598 sec\n",
      "time forward 5.284572 sec\n",
      "loss time 0.000560 sec\n",
      "backward time 0.004903 sec\n",
      "optimizer time 0.014049 sec\n",
      "training time in round 397 cost 0.3464958667755127 sec\n",
      "loss 2.322577, train acc 0.100090\n",
      "round 398\n",
      "time to device 0.010055 sec\n",
      "time forward 5.299475 sec\n",
      "loss time 0.001436 sec\n",
      "backward time 0.022850 sec\n",
      "optimizer time 0.020090 sec\n",
      "training time in round 398 cost 0.4197518825531006 sec\n",
      "loss 2.322529, train acc 0.100133\n",
      "round 399\n",
      "time to device 0.007186 sec\n",
      "time forward 5.314766 sec\n",
      "loss time 0.001803 sec\n",
      "backward time 0.013432 sec\n",
      "optimizer time 0.025604 sec\n",
      "training time in round 399 cost 0.4156920909881592 sec\n",
      "loss 2.322594, train acc 0.100234\n",
      "round 400\n",
      "time to device 0.008606 sec\n",
      "time forward 5.330984 sec\n",
      "loss time 0.001549 sec\n",
      "backward time 0.013799 sec\n",
      "optimizer time 0.024806 sec\n",
      "training time in round 400 cost 0.40120768547058105 sec\n",
      "loss 2.322537, train acc 0.100316\n",
      "round 401\n",
      "time to device 0.004415 sec\n",
      "time forward 5.346199 sec\n",
      "loss time 0.001901 sec\n",
      "backward time 0.015735 sec\n",
      "optimizer time 0.024620 sec\n",
      "training time in round 401 cost 0.3999941349029541 sec\n",
      "loss 2.322484, train acc 0.100319\n",
      "round 402\n",
      "time to device 0.004350 sec\n",
      "time forward 5.361067 sec\n",
      "loss time 0.001480 sec\n",
      "backward time 0.012327 sec\n",
      "optimizer time 0.021782 sec\n",
      "training time in round 402 cost 0.3898789882659912 sec\n",
      "loss 2.322813, train acc 0.100225\n",
      "round 403\n",
      "time to device 0.003383 sec\n",
      "time forward 5.377010 sec\n",
      "loss time 0.001215 sec\n",
      "backward time 0.015183 sec\n",
      "optimizer time 0.024394 sec\n",
      "training time in round 403 cost 0.3985328674316406 sec\n",
      "loss 2.322762, train acc 0.100325\n",
      "round 404\n",
      "time to device 0.004785 sec\n",
      "time forward 5.391185 sec\n",
      "loss time 0.001572 sec\n",
      "backward time 0.014301 sec\n",
      "optimizer time 0.024224 sec\n",
      "training time in round 404 cost 0.3964221477508545 sec\n",
      "loss 2.322719, train acc 0.100289\n",
      "round 405\n",
      "time to device 0.004002 sec\n",
      "time forward 5.405695 sec\n",
      "loss time 0.001938 sec\n",
      "backward time 0.014800 sec\n",
      "optimizer time 0.022099 sec\n",
      "training time in round 405 cost 0.39566993713378906 sec\n",
      "loss 2.322777, train acc 0.100273\n",
      "round 406\n",
      "time to device 0.006129 sec\n",
      "time forward 5.420730 sec\n",
      "loss time 0.001461 sec\n",
      "backward time 0.012766 sec\n",
      "optimizer time 0.023715 sec\n",
      "training time in round 406 cost 0.40285778045654297 sec\n",
      "loss 2.322704, train acc 0.100180\n",
      "round 407\n",
      "time to device 0.004322 sec\n",
      "time forward 5.435257 sec\n",
      "loss time 0.002021 sec\n",
      "backward time 0.013814 sec\n",
      "optimizer time 0.024437 sec\n",
      "training time in round 407 cost 0.3981637954711914 sec\n",
      "loss 2.322657, train acc 0.100088\n",
      "round 408\n",
      "time to device 0.004434 sec\n",
      "time forward 5.449683 sec\n",
      "loss time 0.001478 sec\n",
      "backward time 0.014358 sec\n",
      "optimizer time 0.024756 sec\n",
      "training time in round 408 cost 0.40015077590942383 sec\n",
      "loss 2.322579, train acc 0.100073\n",
      "round 409\n",
      "time to device 0.004551 sec\n",
      "time forward 5.462982 sec\n",
      "loss time 0.001533 sec\n",
      "backward time 0.012259 sec\n",
      "optimizer time 0.022758 sec\n",
      "training time in round 409 cost 0.3897552490234375 sec\n",
      "loss 2.322534, train acc 0.100038\n",
      "round 410\n",
      "time to device 0.005717 sec\n",
      "time forward 5.477787 sec\n",
      "loss time 0.001432 sec\n",
      "backward time 0.012898 sec\n",
      "optimizer time 0.022418 sec\n",
      "training time in round 410 cost 0.3985002040863037 sec\n",
      "loss 2.322623, train acc 0.099928\n",
      "round 411\n",
      "time to device 0.004381 sec\n",
      "time forward 5.493468 sec\n",
      "loss time 0.001557 sec\n",
      "backward time 0.012914 sec\n",
      "optimizer time 0.022481 sec\n",
      "training time in round 411 cost 0.39639997482299805 sec\n",
      "loss 2.322593, train acc 0.100008\n",
      "round 412\n",
      "time to device 0.004104 sec\n",
      "time forward 5.506150 sec\n",
      "loss time 0.002004 sec\n",
      "backward time 0.013322 sec\n",
      "optimizer time 0.024498 sec\n",
      "training time in round 412 cost 0.3957827091217041 sec\n",
      "loss 2.322825, train acc 0.099974\n",
      "round 413\n",
      "time to device 0.003383 sec\n",
      "time forward 5.520764 sec\n",
      "loss time 0.001277 sec\n",
      "backward time 0.019075 sec\n",
      "optimizer time 0.022455 sec\n",
      "training time in round 413 cost 0.40042805671691895 sec\n",
      "loss 2.322801, train acc 0.099977\n",
      "round 414\n",
      "time to device 0.004515 sec\n",
      "time forward 5.536501 sec\n",
      "loss time 0.001564 sec\n",
      "backward time 0.013701 sec\n",
      "optimizer time 0.023980 sec\n",
      "training time in round 414 cost 0.42018604278564453 sec\n",
      "loss 2.322736, train acc 0.099981\n",
      "round 415\n",
      "time to device 0.004407 sec\n",
      "time forward 5.551066 sec\n",
      "loss time 0.001516 sec\n",
      "backward time 0.020468 sec\n",
      "optimizer time 0.022027 sec\n",
      "training time in round 415 cost 0.39847493171691895 sec\n",
      "loss 2.322685, train acc 0.100116\n",
      "round 416\n",
      "time to device 0.004170 sec\n",
      "time forward 5.563469 sec\n",
      "loss time 0.001066 sec\n",
      "backward time 0.012742 sec\n",
      "optimizer time 0.025347 sec\n",
      "training time in round 416 cost 0.396625280380249 sec\n",
      "loss 2.322665, train acc 0.099989\n",
      "round 417\n",
      "time to device 0.004059 sec\n",
      "time forward 5.570452 sec\n",
      "loss time 0.000554 sec\n",
      "backward time 0.005029 sec\n",
      "optimizer time 0.014040 sec\n",
      "training time in round 417 cost 0.3408670425415039 sec\n",
      "loss 2.322620, train acc 0.100030\n",
      "round 418\n",
      "time to device 0.004233 sec\n",
      "time forward 5.585618 sec\n",
      "loss time 0.001500 sec\n",
      "backward time 0.012833 sec\n",
      "optimizer time 0.024000 sec\n",
      "training time in round 418 cost 0.4000120162963867 sec\n",
      "loss 2.322572, train acc 0.100034\n",
      "round 419\n",
      "time to device 0.004312 sec\n",
      "time forward 5.600837 sec\n",
      "loss time 0.002175 sec\n",
      "backward time 0.015175 sec\n",
      "optimizer time 0.026244 sec\n",
      "training time in round 419 cost 0.3997330665588379 sec\n",
      "loss 2.322529, train acc 0.100112\n",
      "round 420\n",
      "time to device 0.003687 sec\n",
      "time forward 5.617253 sec\n",
      "loss time 0.001794 sec\n",
      "backward time 0.011730 sec\n",
      "optimizer time 0.023281 sec\n",
      "training time in round 420 cost 0.4032258987426758 sec\n",
      "loss 2.322484, train acc 0.099967\n",
      "round 421\n",
      "time to device 0.003499 sec\n",
      "time forward 5.632759 sec\n",
      "loss time 0.001483 sec\n",
      "backward time 0.012319 sec\n",
      "optimizer time 0.022720 sec\n",
      "training time in round 421 cost 0.39495301246643066 sec\n",
      "loss 2.322423, train acc 0.100137\n",
      "round 422\n",
      "time to device 0.004965 sec\n",
      "time forward 5.647727 sec\n",
      "loss time 0.001258 sec\n",
      "backward time 0.013343 sec\n",
      "optimizer time 0.021975 sec\n",
      "training time in round 422 cost 0.39527201652526855 sec\n",
      "loss 2.322376, train acc 0.100140\n",
      "round 423\n",
      "time to device 0.004080 sec\n",
      "time forward 5.661062 sec\n",
      "loss time 0.001367 sec\n",
      "backward time 0.013317 sec\n",
      "optimizer time 0.022932 sec\n",
      "training time in round 423 cost 0.39283013343811035 sec\n",
      "loss 2.322317, train acc 0.100144\n",
      "round 424\n",
      "time to device 0.003702 sec\n",
      "time forward 5.673790 sec\n",
      "loss time 0.001173 sec\n",
      "backward time 0.008790 sec\n",
      "optimizer time 0.018041 sec\n",
      "training time in round 424 cost 0.38086771965026855 sec\n",
      "loss 2.322264, train acc 0.100129\n",
      "round 425\n",
      "time to device 0.003512 sec\n",
      "time forward 5.689017 sec\n",
      "loss time 0.001923 sec\n",
      "backward time 0.015001 sec\n",
      "optimizer time 0.024532 sec\n",
      "training time in round 425 cost 0.4008488655090332 sec\n",
      "loss 2.322216, train acc 0.100114\n",
      "round 426\n",
      "time to device 0.003278 sec\n",
      "time forward 5.701740 sec\n",
      "loss time 0.001834 sec\n",
      "backward time 0.013525 sec\n",
      "optimizer time 0.012054 sec\n",
      "training time in round 426 cost 0.37825608253479004 sec\n",
      "loss 2.322679, train acc 0.100190\n",
      "round 427\n",
      "time to device 0.003345 sec\n",
      "time forward 5.717067 sec\n",
      "loss time 0.002043 sec\n",
      "backward time 0.015486 sec\n",
      "optimizer time 0.025341 sec\n",
      "training time in round 427 cost 0.4053518772125244 sec\n",
      "loss 2.322621, train acc 0.100267\n",
      "round 428\n",
      "time to device 0.003292 sec\n",
      "time forward 5.731348 sec\n",
      "loss time 0.001964 sec\n",
      "backward time 0.014194 sec\n",
      "optimizer time 0.022931 sec\n",
      "training time in round 428 cost 0.3926420211791992 sec\n",
      "loss 2.322587, train acc 0.100215\n",
      "round 429\n",
      "time to device 0.003371 sec\n",
      "time forward 5.745810 sec\n",
      "loss time 0.001410 sec\n",
      "backward time 0.012854 sec\n",
      "optimizer time 0.023565 sec\n",
      "training time in round 429 cost 0.3938918113708496 sec\n",
      "loss 2.322667, train acc 0.100254\n",
      "round 430\n",
      "time to device 0.004707 sec\n",
      "time forward 5.760689 sec\n",
      "loss time 0.001314 sec\n",
      "backward time 0.013244 sec\n",
      "optimizer time 0.021844 sec\n",
      "training time in round 430 cost 0.397219181060791 sec\n",
      "loss 2.322637, train acc 0.100149\n",
      "round 431\n",
      "time to device 0.003662 sec\n",
      "time forward 5.775615 sec\n",
      "loss time 0.002658 sec\n",
      "backward time 0.016048 sec\n",
      "optimizer time 0.024783 sec\n",
      "training time in round 431 cost 0.40204596519470215 sec\n",
      "loss 2.322606, train acc 0.100170\n",
      "round 432\n",
      "time to device 0.004336 sec\n",
      "time forward 5.788607 sec\n",
      "loss time 0.001947 sec\n",
      "backward time 0.013743 sec\n",
      "optimizer time 0.018537 sec\n",
      "training time in round 432 cost 0.386350154876709 sec\n",
      "loss 2.322565, train acc 0.100173\n",
      "round 433\n",
      "time to device 0.004073 sec\n",
      "time forward 5.802967 sec\n",
      "loss time 0.001255 sec\n",
      "backward time 0.011143 sec\n",
      "optimizer time 0.024823 sec\n",
      "training time in round 433 cost 0.3976578712463379 sec\n",
      "loss 2.322520, train acc 0.100158\n",
      "round 434\n",
      "time to device 0.004575 sec\n",
      "time forward 5.818305 sec\n",
      "loss time 0.001426 sec\n",
      "backward time 0.014719 sec\n",
      "optimizer time 0.022435 sec\n",
      "training time in round 434 cost 0.40116190910339355 sec\n",
      "loss 2.322471, train acc 0.100180\n",
      "round 435\n",
      "time to device 0.004183 sec\n",
      "time forward 5.832202 sec\n",
      "loss time 0.001619 sec\n",
      "backward time 0.012094 sec\n",
      "optimizer time 0.023197 sec\n",
      "training time in round 435 cost 0.388916015625 sec\n",
      "loss 2.322482, train acc 0.100201\n",
      "round 436\n",
      "time to device 0.004874 sec\n",
      "time forward 5.846703 sec\n",
      "loss time 0.001443 sec\n",
      "backward time 0.012590 sec\n",
      "optimizer time 0.022582 sec\n",
      "training time in round 436 cost 0.3947930335998535 sec\n",
      "loss 2.322438, train acc 0.100168\n",
      "round 437\n",
      "time to device 0.004673 sec\n",
      "time forward 5.853757 sec\n",
      "loss time 0.000630 sec\n",
      "backward time 0.005788 sec\n",
      "optimizer time 0.014653 sec\n",
      "training time in round 437 cost 0.3554880619049072 sec\n",
      "loss 2.322411, train acc 0.100100\n",
      "round 438\n",
      "time to device 0.004334 sec\n",
      "time forward 5.868894 sec\n",
      "loss time 0.001246 sec\n",
      "backward time 0.012479 sec\n",
      "optimizer time 0.023181 sec\n",
      "training time in round 438 cost 0.3949251174926758 sec\n",
      "loss 2.322344, train acc 0.100103\n",
      "round 439\n",
      "time to device 0.003925 sec\n",
      "time forward 5.882249 sec\n",
      "loss time 0.005044 sec\n",
      "backward time 0.012455 sec\n",
      "optimizer time 0.024459 sec\n",
      "training time in round 439 cost 0.3977508544921875 sec\n",
      "loss 2.322298, train acc 0.100124\n",
      "round 440\n",
      "time to device 0.004381 sec\n",
      "time forward 5.895627 sec\n",
      "loss time 0.001862 sec\n",
      "backward time 0.012700 sec\n",
      "optimizer time 0.017819 sec\n",
      "training time in round 440 cost 0.38776397705078125 sec\n",
      "loss 2.322256, train acc 0.100110\n",
      "round 441\n",
      "time to device 0.004339 sec\n",
      "time forward 5.909352 sec\n",
      "loss time 0.002081 sec\n",
      "backward time 0.014664 sec\n",
      "optimizer time 0.022614 sec\n",
      "training time in round 441 cost 0.40352487564086914 sec\n",
      "loss 2.322212, train acc 0.100095\n",
      "round 442\n",
      "time to device 0.006155 sec\n",
      "time forward 5.924237 sec\n",
      "loss time 0.001461 sec\n",
      "backward time 0.016421 sec\n",
      "optimizer time 0.020369 sec\n",
      "training time in round 442 cost 0.40353989601135254 sec\n",
      "loss 2.322594, train acc 0.100152\n",
      "round 443\n",
      "time to device 0.003926 sec\n",
      "time forward 5.938877 sec\n",
      "loss time 0.001977 sec\n",
      "backward time 0.014129 sec\n",
      "optimizer time 0.026203 sec\n",
      "training time in round 443 cost 0.4184739589691162 sec\n",
      "loss 2.322549, train acc 0.100172\n",
      "round 444\n",
      "time to device 0.004396 sec\n",
      "time forward 5.951705 sec\n",
      "loss time 0.001679 sec\n",
      "backward time 0.013952 sec\n",
      "optimizer time 0.024853 sec\n",
      "training time in round 444 cost 0.3930332660675049 sec\n",
      "loss 2.322515, train acc 0.100123\n",
      "round 445\n",
      "time to device 0.003898 sec\n",
      "time forward 5.966693 sec\n",
      "loss time 0.001485 sec\n",
      "backward time 0.012694 sec\n",
      "optimizer time 0.020622 sec\n",
      "training time in round 445 cost 0.39111804962158203 sec\n",
      "loss 2.322592, train acc 0.100056\n",
      "round 446\n",
      "time to device 0.003959 sec\n",
      "time forward 5.982376 sec\n",
      "loss time 0.001791 sec\n",
      "backward time 0.012125 sec\n",
      "optimizer time 0.021074 sec\n",
      "training time in round 446 cost 0.42167019844055176 sec\n",
      "loss 2.322705, train acc 0.100129\n",
      "round 447\n",
      "time to device 0.004709 sec\n",
      "time forward 5.998349 sec\n",
      "loss time 0.001305 sec\n",
      "backward time 0.015794 sec\n",
      "optimizer time 0.022561 sec\n",
      "training time in round 447 cost 0.40325212478637695 sec\n",
      "loss 2.322660, train acc 0.100098\n",
      "round 448\n",
      "time to device 0.009380 sec\n",
      "time forward 6.013704 sec\n",
      "loss time 0.001237 sec\n",
      "backward time 0.014418 sec\n",
      "optimizer time 0.025282 sec\n",
      "training time in round 448 cost 0.4055671691894531 sec\n",
      "loss 2.322828, train acc 0.100136\n",
      "round 449\n",
      "time to device 0.008460 sec\n",
      "time forward 6.031775 sec\n",
      "loss time 0.001764 sec\n",
      "backward time 0.014437 sec\n",
      "optimizer time 0.021290 sec\n",
      "training time in round 449 cost 0.4159841537475586 sec\n",
      "loss 2.322768, train acc 0.100156\n",
      "round 450\n",
      "time to device 0.009109 sec\n",
      "time forward 6.045134 sec\n",
      "loss time 0.001854 sec\n",
      "backward time 0.015752 sec\n",
      "optimizer time 0.025757 sec\n",
      "training time in round 450 cost 0.40370988845825195 sec\n",
      "loss 2.322731, train acc 0.100107\n",
      "round 451\n",
      "time to device 0.003980 sec\n",
      "time forward 6.060627 sec\n",
      "loss time 0.001611 sec\n",
      "backward time 0.012096 sec\n",
      "optimizer time 0.023990 sec\n",
      "training time in round 451 cost 0.40001821517944336 sec\n",
      "loss 2.322686, train acc 0.100128\n",
      "round 452\n",
      "time to device 0.005007 sec\n",
      "time forward 6.077970 sec\n",
      "loss time 0.001711 sec\n",
      "backward time 0.012536 sec\n",
      "optimizer time 0.023861 sec\n",
      "training time in round 452 cost 0.4059031009674072 sec\n",
      "loss 2.322639, train acc 0.100079\n",
      "round 453\n",
      "time to device 0.004288 sec\n",
      "time forward 6.092709 sec\n",
      "loss time 0.001905 sec\n",
      "backward time 0.015246 sec\n",
      "optimizer time 0.022773 sec\n",
      "training time in round 453 cost 0.3961217403411865 sec\n",
      "loss 2.322606, train acc 0.099997\n",
      "round 454\n",
      "time to device 0.004264 sec\n",
      "time forward 6.107887 sec\n",
      "loss time 0.001564 sec\n",
      "backward time 0.013408 sec\n",
      "optimizer time 0.022090 sec\n",
      "training time in round 454 cost 0.3951430320739746 sec\n",
      "loss 2.322571, train acc 0.099983\n",
      "round 455\n",
      "time to device 0.004155 sec\n",
      "time forward 6.122674 sec\n",
      "loss time 0.002232 sec\n",
      "backward time 0.013429 sec\n",
      "optimizer time 0.025428 sec\n",
      "training time in round 455 cost 0.402677059173584 sec\n",
      "loss 2.322529, train acc 0.099935\n",
      "round 456\n",
      "time to device 0.003619 sec\n",
      "time forward 6.130230 sec\n",
      "loss time 0.000629 sec\n",
      "backward time 0.005760 sec\n",
      "optimizer time 0.014485 sec\n",
      "training time in round 456 cost 0.3463470935821533 sec\n",
      "loss 2.322565, train acc 0.100007\n",
      "round 457\n",
      "time to device 0.004147 sec\n",
      "time forward 6.144466 sec\n",
      "loss time 0.001157 sec\n",
      "backward time 0.010330 sec\n",
      "optimizer time 0.018657 sec\n",
      "training time in round 457 cost 0.3820228576660156 sec\n",
      "loss 2.322517, train acc 0.099959\n",
      "round 458\n",
      "time to device 0.003700 sec\n",
      "time forward 6.160871 sec\n",
      "loss time 0.001274 sec\n",
      "backward time 0.014780 sec\n",
      "optimizer time 0.025041 sec\n",
      "training time in round 458 cost 0.3994009494781494 sec\n",
      "loss 2.322483, train acc 0.099877\n",
      "round 459\n",
      "time to device 0.003795 sec\n",
      "time forward 6.175466 sec\n",
      "loss time 0.002144 sec\n",
      "backward time 0.014694 sec\n",
      "optimizer time 0.024262 sec\n",
      "training time in round 459 cost 0.4016110897064209 sec\n",
      "loss 2.322440, train acc 0.099881\n",
      "round 460\n",
      "time to device 0.003819 sec\n",
      "time forward 6.189190 sec\n",
      "loss time 0.001993 sec\n",
      "backward time 0.013496 sec\n",
      "optimizer time 0.011912 sec\n",
      "training time in round 460 cost 0.3811049461364746 sec\n",
      "loss 2.322409, train acc 0.099817\n",
      "round 461\n",
      "time to device 0.003382 sec\n",
      "time forward 6.205554 sec\n",
      "loss time 0.001886 sec\n",
      "backward time 0.014663 sec\n",
      "optimizer time 0.026737 sec\n",
      "training time in round 461 cost 0.40538787841796875 sec\n",
      "loss 2.322375, train acc 0.099821\n",
      "round 462\n",
      "time to device 0.003878 sec\n",
      "time forward 6.220516 sec\n",
      "loss time 0.001030 sec\n",
      "backward time 0.010318 sec\n",
      "optimizer time 0.024621 sec\n",
      "training time in round 462 cost 0.4019646644592285 sec\n",
      "loss 2.322329, train acc 0.099791\n",
      "round 463\n",
      "time to device 0.003940 sec\n",
      "time forward 6.237899 sec\n",
      "loss time 0.001876 sec\n",
      "backward time 0.013710 sec\n",
      "optimizer time 0.023661 sec\n",
      "training time in round 463 cost 0.40506887435913086 sec\n",
      "loss 2.322607, train acc 0.099811\n",
      "round 464\n",
      "time to device 0.003161 sec\n",
      "time forward 6.246443 sec\n",
      "loss time 0.000615 sec\n",
      "backward time 0.005669 sec\n",
      "optimizer time 0.014436 sec\n",
      "training time in round 464 cost 0.36260485649108887 sec\n",
      "loss 2.322632, train acc 0.099748\n",
      "round 465\n",
      "time to device 0.004537 sec\n",
      "time forward 6.260197 sec\n",
      "loss time 0.000703 sec\n",
      "backward time 0.006421 sec\n",
      "optimizer time 0.017900 sec\n",
      "training time in round 465 cost 0.3714430332183838 sec\n",
      "loss 2.322602, train acc 0.099685\n",
      "round 466\n",
      "time to device 0.004505 sec\n",
      "time forward 6.277161 sec\n",
      "loss time 0.001979 sec\n",
      "backward time 0.015567 sec\n",
      "optimizer time 0.023795 sec\n",
      "training time in round 466 cost 0.40720701217651367 sec\n",
      "loss 2.322555, train acc 0.099689\n",
      "round 467\n",
      "time to device 0.003774 sec\n",
      "time forward 6.294025 sec\n",
      "loss time 0.001906 sec\n",
      "backward time 0.013587 sec\n",
      "optimizer time 0.025246 sec\n",
      "training time in round 467 cost 0.4059031009674072 sec\n",
      "loss 2.322504, train acc 0.099760\n",
      "round 468\n",
      "time to device 0.003382 sec\n",
      "time forward 6.315983 sec\n",
      "loss time 0.001883 sec\n",
      "backward time 0.016615 sec\n",
      "optimizer time 0.019301 sec\n",
      "training time in round 468 cost 0.3496279716491699 sec\n",
      "loss 2.322478, train acc 0.099800\n",
      "test acc is 0.100000\n",
      "epoch 8, time 3943.066888 sec\n",
      "epoch 10\n",
      "round 0\n",
      "time to device 0.034150 sec\n",
      "time forward 0.014251 sec\n",
      "loss time 0.000877 sec\n",
      "backward time 0.007024 sec\n",
      "optimizer time 0.015946 sec\n",
      "training time in round 0 cost 0.47176504135131836 sec\n",
      "loss 2.305977, train acc 0.054688\n",
      "round 1\n",
      "time to device 0.004833 sec\n",
      "time forward 0.020685 sec\n",
      "loss time 0.000496 sec\n",
      "backward time 0.004987 sec\n",
      "optimizer time 0.016342 sec\n",
      "training time in round 1 cost 0.41443705558776855 sec\n",
      "loss 2.308984, train acc 0.085938\n",
      "round 2\n",
      "time to device 0.010018 sec\n",
      "time forward 0.035315 sec\n",
      "loss time 0.001588 sec\n",
      "backward time 0.011856 sec\n",
      "optimizer time 0.022356 sec\n",
      "training time in round 2 cost 0.4042510986328125 sec\n",
      "loss 2.311728, train acc 0.098958\n",
      "round 3\n",
      "time to device 0.008389 sec\n",
      "time forward 0.047163 sec\n",
      "loss time 0.001663 sec\n",
      "backward time 0.013830 sec\n",
      "optimizer time 0.025746 sec\n",
      "training time in round 3 cost 0.407696008682251 sec\n",
      "loss 2.345679, train acc 0.097656\n",
      "round 4\n",
      "time to device 0.007459 sec\n",
      "time forward 0.063882 sec\n",
      "loss time 0.001430 sec\n",
      "backward time 0.018065 sec\n",
      "optimizer time 0.025327 sec\n",
      "training time in round 4 cost 0.415539026260376 sec\n",
      "loss 2.337669, train acc 0.095312\n",
      "round 5\n",
      "time to device 0.010378 sec\n",
      "time forward 0.079005 sec\n",
      "loss time 0.001917 sec\n",
      "backward time 0.013538 sec\n",
      "optimizer time 0.024805 sec\n",
      "training time in round 5 cost 0.4618360996246338 sec\n",
      "loss 2.331734, train acc 0.092448\n",
      "round 6\n",
      "time to device 0.008366 sec\n",
      "time forward 0.093226 sec\n",
      "loss time 0.001885 sec\n",
      "backward time 0.014546 sec\n",
      "optimizer time 0.025534 sec\n",
      "training time in round 6 cost 0.4034311771392822 sec\n",
      "loss 2.327727, train acc 0.094866\n",
      "round 7\n",
      "time to device 0.008285 sec\n",
      "time forward 0.106575 sec\n",
      "loss time 0.001896 sec\n",
      "backward time 0.013376 sec\n",
      "optimizer time 0.011296 sec\n",
      "training time in round 7 cost 0.40329599380493164 sec\n",
      "loss 2.324528, train acc 0.093750\n",
      "round 8\n",
      "time to device 0.010307 sec\n",
      "time forward 0.120872 sec\n",
      "loss time 0.001226 sec\n",
      "backward time 0.013427 sec\n",
      "optimizer time 0.023527 sec\n",
      "training time in round 8 cost 0.3966517448425293 sec\n",
      "loss 2.323008, train acc 0.094618\n",
      "round 9\n",
      "time to device 0.006592 sec\n",
      "time forward 0.137778 sec\n",
      "loss time 0.001426 sec\n",
      "backward time 0.013627 sec\n",
      "optimizer time 0.024775 sec\n",
      "training time in round 9 cost 0.4148111343383789 sec\n",
      "loss 2.321019, train acc 0.096094\n",
      "round 10\n",
      "time to device 0.011033 sec\n",
      "time forward 0.150768 sec\n",
      "loss time 0.002152 sec\n",
      "backward time 0.014546 sec\n",
      "optimizer time 0.025869 sec\n",
      "training time in round 10 cost 0.39934587478637695 sec\n",
      "loss 2.319237, train acc 0.097301\n",
      "round 11\n",
      "time to device 0.006615 sec\n",
      "time forward 0.167645 sec\n",
      "loss time 0.001265 sec\n",
      "backward time 0.012844 sec\n",
      "optimizer time 0.022081 sec\n",
      "training time in round 11 cost 0.4112262725830078 sec\n",
      "loss 2.319367, train acc 0.095703\n",
      "round 12\n",
      "time to device 0.008678 sec\n",
      "time forward 0.182485 sec\n",
      "loss time 0.002102 sec\n",
      "backward time 0.017840 sec\n",
      "optimizer time 0.022051 sec\n",
      "training time in round 12 cost 0.4054110050201416 sec\n",
      "loss 2.318156, train acc 0.093750\n",
      "round 13\n",
      "time to device 0.009534 sec\n",
      "time forward 0.201165 sec\n",
      "loss time 0.001410 sec\n",
      "backward time 0.014202 sec\n",
      "optimizer time 0.024326 sec\n",
      "training time in round 13 cost 0.41502881050109863 sec\n",
      "loss 2.317345, train acc 0.093192\n",
      "round 14\n",
      "time to device 0.004811 sec\n",
      "time forward 0.213435 sec\n",
      "loss time 0.001508 sec\n",
      "backward time 0.013377 sec\n",
      "optimizer time 0.026581 sec\n",
      "training time in round 14 cost 0.3890800476074219 sec\n",
      "loss 2.316349, train acc 0.095312\n",
      "round 15\n",
      "time to device 0.004142 sec\n",
      "time forward 0.229541 sec\n",
      "loss time 0.001512 sec\n",
      "backward time 0.014958 sec\n",
      "optimizer time 0.024723 sec\n",
      "training time in round 15 cost 0.39875125885009766 sec\n",
      "loss 2.315671, train acc 0.096191\n",
      "round 16\n",
      "time to device 0.004303 sec\n",
      "time forward 0.242129 sec\n",
      "loss time 0.001008 sec\n",
      "backward time 0.013164 sec\n",
      "optimizer time 0.021241 sec\n",
      "training time in round 16 cost 0.39977121353149414 sec\n",
      "loss 2.315083, train acc 0.097426\n",
      "round 17\n",
      "time to device 0.004690 sec\n",
      "time forward 0.257194 sec\n",
      "loss time 0.002225 sec\n",
      "backward time 0.015733 sec\n",
      "optimizer time 0.021324 sec\n",
      "training time in round 17 cost 0.40427184104919434 sec\n",
      "loss 2.314322, train acc 0.101128\n",
      "round 18\n",
      "time to device 0.004288 sec\n",
      "time forward 0.274677 sec\n",
      "loss time 0.002356 sec\n",
      "backward time 0.013889 sec\n",
      "optimizer time 0.025798 sec\n",
      "training time in round 18 cost 0.44266700744628906 sec\n",
      "loss 2.313577, train acc 0.103618\n",
      "round 19\n",
      "time to device 0.009125 sec\n",
      "time forward 0.289165 sec\n",
      "loss time 0.001654 sec\n",
      "backward time 0.012020 sec\n",
      "optimizer time 0.024443 sec\n",
      "training time in round 19 cost 0.3977060317993164 sec\n",
      "loss 2.312956, train acc 0.103516\n",
      "round 20\n",
      "time to device 0.007360 sec\n",
      "time forward 0.297318 sec\n",
      "loss time 0.000579 sec\n",
      "backward time 0.005069 sec\n",
      "optimizer time 0.014213 sec\n",
      "training time in round 20 cost 0.3523218631744385 sec\n",
      "loss 2.312332, train acc 0.105283\n",
      "round 21\n",
      "time to device 0.008938 sec\n",
      "time forward 0.311892 sec\n",
      "loss time 0.001644 sec\n",
      "backward time 0.013299 sec\n",
      "optimizer time 0.022990 sec\n",
      "training time in round 21 cost 0.41469573974609375 sec\n",
      "loss 2.318363, train acc 0.105824\n",
      "round 22\n",
      "time to device 0.009413 sec\n",
      "time forward 0.325442 sec\n",
      "loss time 0.002014 sec\n",
      "backward time 0.014777 sec\n",
      "optimizer time 0.026433 sec\n",
      "training time in round 22 cost 0.4025862216949463 sec\n",
      "loss 2.317756, train acc 0.103940\n",
      "round 23\n",
      "time to device 0.006690 sec\n",
      "time forward 0.339812 sec\n",
      "loss time 0.001355 sec\n",
      "backward time 0.011514 sec\n",
      "optimizer time 0.018638 sec\n",
      "training time in round 23 cost 0.3916199207305908 sec\n",
      "loss 2.317200, train acc 0.102539\n",
      "round 24\n",
      "time to device 0.008628 sec\n",
      "time forward 0.354327 sec\n",
      "loss time 0.001833 sec\n",
      "backward time 0.012724 sec\n",
      "optimizer time 0.024663 sec\n",
      "training time in round 24 cost 0.40435194969177246 sec\n",
      "loss 2.316608, train acc 0.102500\n",
      "round 25\n",
      "time to device 0.009133 sec\n",
      "time forward 0.368080 sec\n",
      "loss time 0.002459 sec\n",
      "backward time 0.015742 sec\n",
      "optimizer time 0.022816 sec\n",
      "training time in round 25 cost 0.4165842533111572 sec\n",
      "loss 2.316173, train acc 0.101562\n",
      "round 26\n",
      "time to device 0.008396 sec\n",
      "time forward 0.383061 sec\n",
      "loss time 0.001820 sec\n",
      "backward time 0.011938 sec\n",
      "optimizer time 0.025063 sec\n",
      "training time in round 26 cost 0.40224194526672363 sec\n",
      "loss 2.315783, train acc 0.101562\n",
      "round 27\n",
      "time to device 0.008106 sec\n",
      "time forward 0.398242 sec\n",
      "loss time 0.001215 sec\n",
      "backward time 0.011616 sec\n",
      "optimizer time 0.021330 sec\n",
      "training time in round 27 cost 0.3996708393096924 sec\n",
      "loss 2.315341, train acc 0.101283\n",
      "round 28\n",
      "time to device 0.009606 sec\n",
      "time forward 0.404504 sec\n",
      "loss time 0.000556 sec\n",
      "backward time 0.005251 sec\n",
      "optimizer time 0.015280 sec\n",
      "training time in round 28 cost 0.37012600898742676 sec\n",
      "loss 2.314605, train acc 0.102101\n",
      "round 29\n",
      "time to device 0.004135 sec\n",
      "time forward 0.419890 sec\n",
      "loss time 0.001576 sec\n",
      "backward time 0.016271 sec\n",
      "optimizer time 0.025588 sec\n",
      "training time in round 29 cost 0.40731287002563477 sec\n",
      "loss 2.314203, train acc 0.102604\n",
      "round 30\n",
      "time to device 0.006709 sec\n",
      "time forward 0.433891 sec\n",
      "loss time 0.001419 sec\n",
      "backward time 0.013133 sec\n",
      "optimizer time 0.022821 sec\n",
      "training time in round 30 cost 0.415330171585083 sec\n",
      "loss 2.313686, train acc 0.104335\n",
      "round 31\n",
      "time to device 0.005554 sec\n",
      "time forward 0.447534 sec\n",
      "loss time 0.001112 sec\n",
      "backward time 0.011166 sec\n",
      "optimizer time 0.024801 sec\n",
      "training time in round 31 cost 0.39104723930358887 sec\n",
      "loss 2.313449, train acc 0.104004\n",
      "round 32\n",
      "time to device 0.006822 sec\n",
      "time forward 0.461046 sec\n",
      "loss time 0.001720 sec\n",
      "backward time 0.015744 sec\n",
      "optimizer time 0.015023 sec\n",
      "training time in round 32 cost 0.3891739845275879 sec\n",
      "loss 2.313100, train acc 0.103693\n",
      "round 33\n",
      "time to device 0.006501 sec\n",
      "time forward 0.478871 sec\n",
      "loss time 0.002068 sec\n",
      "backward time 0.013120 sec\n",
      "optimizer time 0.024715 sec\n",
      "training time in round 33 cost 0.4201991558074951 sec\n",
      "loss 2.312814, train acc 0.103860\n",
      "round 34\n",
      "time to device 0.010057 sec\n",
      "time forward 0.491449 sec\n",
      "loss time 0.002243 sec\n",
      "backward time 0.015532 sec\n",
      "optimizer time 0.015001 sec\n",
      "training time in round 34 cost 0.39259910583496094 sec\n",
      "loss 2.312896, train acc 0.103125\n",
      "round 35\n",
      "time to device 0.008549 sec\n",
      "time forward 0.505264 sec\n",
      "loss time 0.001603 sec\n",
      "backward time 0.016350 sec\n",
      "optimizer time 0.024822 sec\n",
      "training time in round 35 cost 0.4035780429840088 sec\n",
      "loss 2.312649, train acc 0.102214\n",
      "round 36\n",
      "time to device 0.009015 sec\n",
      "time forward 0.519696 sec\n",
      "loss time 0.002445 sec\n",
      "backward time 0.020628 sec\n",
      "optimizer time 0.020489 sec\n",
      "training time in round 36 cost 0.40444493293762207 sec\n",
      "loss 2.312305, train acc 0.104096\n",
      "round 37\n",
      "time to device 0.008389 sec\n",
      "time forward 0.534065 sec\n",
      "loss time 0.002010 sec\n",
      "backward time 0.014797 sec\n",
      "optimizer time 0.024906 sec\n",
      "training time in round 37 cost 0.4035990238189697 sec\n",
      "loss 2.311925, train acc 0.104852\n",
      "round 38\n",
      "time to device 0.008188 sec\n",
      "time forward 0.549090 sec\n",
      "loss time 0.001608 sec\n",
      "backward time 0.011817 sec\n",
      "optimizer time 0.025091 sec\n",
      "training time in round 38 cost 0.42269420623779297 sec\n",
      "loss 2.311734, train acc 0.103766\n",
      "round 39\n",
      "time to device 0.005500 sec\n",
      "time forward 0.562860 sec\n",
      "loss time 0.002063 sec\n",
      "backward time 0.012391 sec\n",
      "optimizer time 0.024344 sec\n",
      "training time in round 39 cost 0.403170108795166 sec\n",
      "loss 2.311655, train acc 0.102734\n",
      "round 40\n",
      "time to device 0.004699 sec\n",
      "time forward 0.577575 sec\n",
      "loss time 0.001522 sec\n",
      "backward time 0.012394 sec\n",
      "optimizer time 0.024605 sec\n",
      "training time in round 40 cost 0.4024200439453125 sec\n",
      "loss 2.311393, train acc 0.102896\n",
      "round 41\n",
      "time to device 0.003785 sec\n",
      "time forward 0.591033 sec\n",
      "loss time 0.001918 sec\n",
      "backward time 0.012249 sec\n",
      "optimizer time 0.013079 sec\n",
      "training time in round 41 cost 0.3907942771911621 sec\n",
      "loss 2.311205, train acc 0.102121\n",
      "round 42\n",
      "time to device 0.004088 sec\n",
      "time forward 0.608424 sec\n",
      "loss time 0.001488 sec\n",
      "backward time 0.015239 sec\n",
      "optimizer time 0.021719 sec\n",
      "training time in round 42 cost 0.40706706047058105 sec\n",
      "loss 2.310944, train acc 0.102471\n",
      "round 43\n",
      "time to device 0.004899 sec\n",
      "time forward 0.623407 sec\n",
      "loss time 0.001489 sec\n",
      "backward time 0.013172 sec\n",
      "optimizer time 0.023139 sec\n",
      "training time in round 43 cost 0.4109671115875244 sec\n",
      "loss 2.310648, train acc 0.103871\n",
      "round 44\n",
      "time to device 0.004422 sec\n",
      "time forward 0.638027 sec\n",
      "loss time 0.001219 sec\n",
      "backward time 0.015180 sec\n",
      "optimizer time 0.020803 sec\n",
      "training time in round 44 cost 0.4203612804412842 sec\n",
      "loss 2.310438, train acc 0.104861\n",
      "round 45\n",
      "time to device 0.004154 sec\n",
      "time forward 0.652588 sec\n",
      "loss time 0.001538 sec\n",
      "backward time 0.019978 sec\n",
      "optimizer time 0.024441 sec\n",
      "training time in round 45 cost 0.4196431636810303 sec\n",
      "loss 2.310322, train acc 0.103940\n",
      "round 46\n",
      "time to device 0.003895 sec\n",
      "time forward 0.665800 sec\n",
      "loss time 0.002004 sec\n",
      "backward time 0.015534 sec\n",
      "optimizer time 0.025992 sec\n",
      "training time in round 46 cost 0.43834614753723145 sec\n",
      "loss 2.310200, train acc 0.103557\n",
      "round 47\n",
      "time to device 0.005167 sec\n",
      "time forward 0.671818 sec\n",
      "loss time 0.000830 sec\n",
      "backward time 0.006874 sec\n",
      "optimizer time 0.016340 sec\n",
      "training time in round 47 cost 0.36016011238098145 sec\n",
      "loss 2.310081, train acc 0.103027\n",
      "round 48\n",
      "time to device 0.004335 sec\n",
      "time forward 0.684813 sec\n",
      "loss time 0.001448 sec\n",
      "backward time 0.018056 sec\n",
      "optimizer time 0.021493 sec\n",
      "training time in round 48 cost 0.38912320137023926 sec\n",
      "loss 2.309970, train acc 0.102997\n",
      "round 49\n",
      "time to device 0.003785 sec\n",
      "time forward 0.698365 sec\n",
      "loss time 0.001219 sec\n",
      "backward time 0.012605 sec\n",
      "optimizer time 0.023449 sec\n",
      "training time in round 49 cost 0.39999890327453613 sec\n",
      "loss 2.309745, train acc 0.103281\n",
      "round 50\n",
      "time to device 0.003936 sec\n",
      "time forward 0.712673 sec\n",
      "loss time 0.001610 sec\n",
      "backward time 0.015242 sec\n",
      "optimizer time 0.024751 sec\n",
      "training time in round 50 cost 0.39627695083618164 sec\n",
      "loss 2.309592, train acc 0.103707\n",
      "round 51\n",
      "time to device 0.003798 sec\n",
      "time forward 0.729397 sec\n",
      "loss time 0.001980 sec\n",
      "backward time 0.014330 sec\n",
      "optimizer time 0.024659 sec\n",
      "training time in round 51 cost 0.40094900131225586 sec\n",
      "loss 2.309438, train acc 0.103816\n",
      "round 52\n",
      "time to device 0.003126 sec\n",
      "time forward 0.743664 sec\n",
      "loss time 0.001953 sec\n",
      "backward time 0.014554 sec\n",
      "optimizer time 0.024960 sec\n",
      "training time in round 52 cost 0.39676785469055176 sec\n",
      "loss 2.309365, train acc 0.103184\n",
      "round 53\n",
      "time to device 0.004722 sec\n",
      "time forward 0.757371 sec\n",
      "loss time 0.001905 sec\n",
      "backward time 0.016829 sec\n",
      "optimizer time 0.021066 sec\n",
      "training time in round 53 cost 0.3940432071685791 sec\n",
      "loss 2.309272, train acc 0.102865\n",
      "round 54\n",
      "time to device 0.004642 sec\n",
      "time forward 0.771508 sec\n",
      "loss time 0.001878 sec\n",
      "backward time 0.014167 sec\n",
      "optimizer time 0.024405 sec\n",
      "training time in round 54 cost 0.41264820098876953 sec\n",
      "loss 2.309242, train acc 0.103125\n",
      "round 55\n",
      "time to device 0.003568 sec\n",
      "time forward 0.786745 sec\n",
      "loss time 0.001518 sec\n",
      "backward time 0.014275 sec\n",
      "optimizer time 0.024669 sec\n",
      "training time in round 55 cost 0.39891600608825684 sec\n",
      "loss 2.309093, train acc 0.102539\n",
      "round 56\n",
      "time to device 0.006986 sec\n",
      "time forward 0.801844 sec\n",
      "loss time 0.001231 sec\n",
      "backward time 0.014445 sec\n",
      "optimizer time 0.025032 sec\n",
      "training time in round 56 cost 0.40113091468811035 sec\n",
      "loss 2.308994, train acc 0.102385\n",
      "round 57\n",
      "time to device 0.003530 sec\n",
      "time forward 0.816287 sec\n",
      "loss time 0.001904 sec\n",
      "backward time 0.012093 sec\n",
      "optimizer time 0.025331 sec\n",
      "training time in round 57 cost 0.43341708183288574 sec\n",
      "loss 2.311119, train acc 0.102371\n",
      "round 58\n",
      "time to device 0.004608 sec\n",
      "time forward 0.828723 sec\n",
      "loss time 0.001228 sec\n",
      "backward time 0.010446 sec\n",
      "optimizer time 0.025306 sec\n",
      "training time in round 58 cost 0.38045501708984375 sec\n",
      "loss 2.310953, train acc 0.101695\n",
      "round 59\n",
      "time to device 0.003880 sec\n",
      "time forward 0.843447 sec\n",
      "loss time 0.001471 sec\n",
      "backward time 0.014552 sec\n",
      "optimizer time 0.027926 sec\n",
      "training time in round 59 cost 0.4016849994659424 sec\n",
      "loss 2.310947, train acc 0.101172\n",
      "round 60\n",
      "time to device 0.008408 sec\n",
      "time forward 0.850238 sec\n",
      "loss time 0.000494 sec\n",
      "backward time 0.004521 sec\n",
      "optimizer time 0.013030 sec\n",
      "training time in round 60 cost 0.34595298767089844 sec\n",
      "loss 2.310762, train acc 0.101947\n",
      "round 61\n",
      "time to device 0.007943 sec\n",
      "time forward 0.863267 sec\n",
      "loss time 0.001882 sec\n",
      "backward time 0.015844 sec\n",
      "optimizer time 0.025458 sec\n",
      "training time in round 61 cost 0.4150049686431885 sec\n",
      "loss 2.310714, train acc 0.101562\n",
      "round 62\n",
      "time to device 0.003927 sec\n",
      "time forward 0.877717 sec\n",
      "loss time 0.001247 sec\n",
      "backward time 0.013423 sec\n",
      "optimizer time 0.024768 sec\n",
      "training time in round 62 cost 0.3957819938659668 sec\n",
      "loss 2.310590, train acc 0.101190\n",
      "round 63\n",
      "time to device 0.007358 sec\n",
      "time forward 0.890578 sec\n",
      "loss time 0.001652 sec\n",
      "backward time 0.014520 sec\n",
      "optimizer time 0.024658 sec\n",
      "training time in round 63 cost 0.41458988189697266 sec\n",
      "loss 2.310432, train acc 0.101929\n",
      "round 64\n",
      "time to device 0.007550 sec\n",
      "time forward 0.904721 sec\n",
      "loss time 0.001409 sec\n",
      "backward time 0.012938 sec\n",
      "optimizer time 0.024248 sec\n",
      "training time in round 64 cost 0.3982682228088379 sec\n",
      "loss 2.310382, train acc 0.101442\n",
      "round 65\n",
      "time to device 0.007258 sec\n",
      "time forward 0.918385 sec\n",
      "loss time 0.001919 sec\n",
      "backward time 0.014084 sec\n",
      "optimizer time 0.023598 sec\n",
      "training time in round 65 cost 0.4002969264984131 sec\n",
      "loss 2.310261, train acc 0.101326\n",
      "round 66\n",
      "time to device 0.008565 sec\n",
      "time forward 0.931213 sec\n",
      "loss time 0.001224 sec\n",
      "backward time 0.012962 sec\n",
      "optimizer time 0.025137 sec\n",
      "training time in round 66 cost 0.3910999298095703 sec\n",
      "loss 2.310161, train acc 0.101213\n",
      "round 67\n",
      "time to device 0.006477 sec\n",
      "time forward 0.946265 sec\n",
      "loss time 0.001842 sec\n",
      "backward time 0.014365 sec\n",
      "optimizer time 0.025284 sec\n",
      "training time in round 67 cost 0.4022979736328125 sec\n",
      "loss 2.310029, train acc 0.101103\n",
      "round 68\n",
      "time to device 0.005283 sec\n",
      "time forward 0.959902 sec\n",
      "loss time 0.001160 sec\n",
      "backward time 0.016399 sec\n",
      "optimizer time 0.025449 sec\n",
      "training time in round 68 cost 0.39940500259399414 sec\n",
      "loss 2.309963, train acc 0.101110\n",
      "round 69\n",
      "time to device 0.009492 sec\n",
      "time forward 0.972909 sec\n",
      "loss time 0.002139 sec\n",
      "backward time 0.013688 sec\n",
      "optimizer time 0.022717 sec\n",
      "training time in round 69 cost 0.41022324562072754 sec\n",
      "loss 2.309894, train acc 0.101339\n",
      "round 70\n",
      "time to device 0.006704 sec\n",
      "time forward 0.991041 sec\n",
      "loss time 0.001630 sec\n",
      "backward time 0.013341 sec\n",
      "optimizer time 0.022501 sec\n",
      "training time in round 70 cost 0.41140294075012207 sec\n",
      "loss 2.309824, train acc 0.101232\n",
      "round 71\n",
      "time to device 0.007820 sec\n",
      "time forward 0.997523 sec\n",
      "loss time 0.000551 sec\n",
      "backward time 0.005045 sec\n",
      "optimizer time 0.013828 sec\n",
      "training time in round 71 cost 0.36302709579467773 sec\n",
      "loss 2.309753, train acc 0.101020\n",
      "round 72\n",
      "time to device 0.008137 sec\n",
      "time forward 1.010708 sec\n",
      "loss time 0.001522 sec\n",
      "backward time 0.010816 sec\n",
      "optimizer time 0.021900 sec\n",
      "training time in round 72 cost 0.40616488456726074 sec\n",
      "loss 2.309717, train acc 0.101027\n",
      "round 73\n",
      "time to device 0.007109 sec\n",
      "time forward 1.024320 sec\n",
      "loss time 0.001596 sec\n",
      "backward time 0.018871 sec\n",
      "optimizer time 0.022116 sec\n",
      "training time in round 73 cost 0.40424609184265137 sec\n",
      "loss 2.309658, train acc 0.101668\n",
      "round 74\n",
      "time to device 0.008149 sec\n",
      "time forward 1.038820 sec\n",
      "loss time 0.001478 sec\n",
      "backward time 0.012883 sec\n",
      "optimizer time 0.021546 sec\n",
      "training time in round 74 cost 0.40911006927490234 sec\n",
      "loss 2.309602, train acc 0.101354\n",
      "round 75\n",
      "time to device 0.004515 sec\n",
      "time forward 1.050646 sec\n",
      "loss time 0.001014 sec\n",
      "backward time 0.012780 sec\n",
      "optimizer time 0.014352 sec\n",
      "training time in round 75 cost 0.3746018409729004 sec\n",
      "loss 2.309489, train acc 0.101151\n",
      "round 76\n",
      "time to device 0.003844 sec\n",
      "time forward 1.063080 sec\n",
      "loss time 0.001976 sec\n",
      "backward time 0.012040 sec\n",
      "optimizer time 0.026186 sec\n",
      "training time in round 76 cost 0.3888819217681885 sec\n",
      "loss 2.309366, train acc 0.101157\n",
      "round 77\n",
      "time to device 0.004773 sec\n",
      "time forward 1.077840 sec\n",
      "loss time 0.001742 sec\n",
      "backward time 0.016129 sec\n",
      "optimizer time 0.025811 sec\n",
      "training time in round 77 cost 0.4010019302368164 sec\n",
      "loss 2.309269, train acc 0.101262\n",
      "round 78\n",
      "time to device 0.009085 sec\n",
      "time forward 1.091895 sec\n",
      "loss time 0.001975 sec\n",
      "backward time 0.013094 sec\n",
      "optimizer time 0.023459 sec\n",
      "training time in round 78 cost 0.3965318202972412 sec\n",
      "loss 2.309200, train acc 0.101266\n",
      "round 79\n",
      "time to device 0.009280 sec\n",
      "time forward 1.097855 sec\n",
      "loss time 0.000567 sec\n",
      "backward time 0.005165 sec\n",
      "optimizer time 0.013760 sec\n",
      "training time in round 79 cost 0.36249303817749023 sec\n",
      "loss 2.309167, train acc 0.101562\n",
      "round 80\n",
      "time to device 0.008209 sec\n",
      "time forward 1.112545 sec\n",
      "loss time 0.001438 sec\n",
      "backward time 0.013254 sec\n",
      "optimizer time 0.024947 sec\n",
      "training time in round 80 cost 0.40007662773132324 sec\n",
      "loss 2.309095, train acc 0.101852\n",
      "round 81\n",
      "time to device 0.008571 sec\n",
      "time forward 1.126158 sec\n",
      "loss time 0.001435 sec\n",
      "backward time 0.011313 sec\n",
      "optimizer time 0.021059 sec\n",
      "training time in round 81 cost 0.39496397972106934 sec\n",
      "loss 2.309110, train acc 0.101658\n",
      "round 82\n",
      "time to device 0.006795 sec\n",
      "time forward 1.139723 sec\n",
      "loss time 0.002034 sec\n",
      "backward time 0.012603 sec\n",
      "optimizer time 0.026370 sec\n",
      "training time in round 82 cost 0.3973989486694336 sec\n",
      "loss 2.309086, train acc 0.101374\n",
      "round 83\n",
      "time to device 0.009923 sec\n",
      "time forward 1.155072 sec\n",
      "loss time 0.001447 sec\n",
      "backward time 0.012640 sec\n",
      "optimizer time 0.020494 sec\n",
      "training time in round 83 cost 0.4014773368835449 sec\n",
      "loss 2.308995, train acc 0.101004\n",
      "round 84\n",
      "time to device 0.008660 sec\n",
      "time forward 1.169061 sec\n",
      "loss time 0.001655 sec\n",
      "backward time 0.013818 sec\n",
      "optimizer time 0.024186 sec\n",
      "training time in round 84 cost 0.4016878604888916 sec\n",
      "loss 2.308871, train acc 0.101654\n",
      "round 85\n",
      "time to device 0.003174 sec\n",
      "time forward 1.183030 sec\n",
      "loss time 0.001927 sec\n",
      "backward time 0.013747 sec\n",
      "optimizer time 0.023182 sec\n",
      "training time in round 85 cost 0.3939969539642334 sec\n",
      "loss 2.308837, train acc 0.101653\n",
      "round 86\n",
      "time to device 0.004550 sec\n",
      "time forward 1.195104 sec\n",
      "loss time 0.002027 sec\n",
      "backward time 0.023173 sec\n",
      "optimizer time 0.020941 sec\n",
      "training time in round 86 cost 0.39423608779907227 sec\n",
      "loss 2.308739, train acc 0.101652\n",
      "round 87\n",
      "time to device 0.005160 sec\n",
      "time forward 1.207948 sec\n",
      "loss time 0.001081 sec\n",
      "backward time 0.015286 sec\n",
      "optimizer time 0.021982 sec\n",
      "training time in round 87 cost 0.38866281509399414 sec\n",
      "loss 2.308674, train acc 0.101918\n",
      "round 88\n",
      "time to device 0.003624 sec\n",
      "time forward 1.221550 sec\n",
      "loss time 0.001492 sec\n",
      "backward time 0.011827 sec\n",
      "optimizer time 0.022774 sec\n",
      "training time in round 88 cost 0.39145421981811523 sec\n",
      "loss 2.308573, train acc 0.102353\n",
      "round 89\n",
      "time to device 0.005052 sec\n",
      "time forward 1.234911 sec\n",
      "loss time 0.001954 sec\n",
      "backward time 0.013379 sec\n",
      "optimizer time 0.027425 sec\n",
      "training time in round 89 cost 0.39234304428100586 sec\n",
      "loss 2.308499, train acc 0.102344\n",
      "round 90\n",
      "time to device 0.003824 sec\n",
      "time forward 1.241504 sec\n",
      "loss time 0.000497 sec\n",
      "backward time 0.004552 sec\n",
      "optimizer time 0.012528 sec\n",
      "training time in round 90 cost 0.34862399101257324 sec\n",
      "loss 2.308485, train acc 0.102249\n",
      "round 91\n",
      "time to device 0.004930 sec\n",
      "time forward 1.256089 sec\n",
      "loss time 0.001975 sec\n",
      "backward time 0.015268 sec\n",
      "optimizer time 0.024346 sec\n",
      "training time in round 91 cost 0.39977097511291504 sec\n",
      "loss 2.308458, train acc 0.101987\n",
      "round 92\n",
      "time to device 0.003722 sec\n",
      "time forward 1.271535 sec\n",
      "loss time 0.001353 sec\n",
      "backward time 0.013046 sec\n",
      "optimizer time 0.024602 sec\n",
      "training time in round 92 cost 0.39942407608032227 sec\n",
      "loss 2.308402, train acc 0.101899\n",
      "round 93\n",
      "time to device 0.003623 sec\n",
      "time forward 1.289247 sec\n",
      "loss time 0.001576 sec\n",
      "backward time 0.013716 sec\n",
      "optimizer time 0.023720 sec\n",
      "training time in round 93 cost 0.4166991710662842 sec\n",
      "loss 2.308328, train acc 0.102311\n",
      "round 94\n",
      "time to device 0.004191 sec\n",
      "time forward 1.302886 sec\n",
      "loss time 0.001512 sec\n",
      "backward time 0.012301 sec\n",
      "optimizer time 0.023788 sec\n",
      "training time in round 94 cost 0.3880012035369873 sec\n",
      "loss 2.309682, train acc 0.101891\n",
      "round 95\n",
      "time to device 0.004621 sec\n",
      "time forward 1.315221 sec\n",
      "loss time 0.001491 sec\n",
      "backward time 0.013486 sec\n",
      "optimizer time 0.026701 sec\n",
      "training time in round 95 cost 0.3849790096282959 sec\n",
      "loss 2.309582, train acc 0.102295\n",
      "round 96\n",
      "time to device 0.004305 sec\n",
      "time forward 1.329601 sec\n",
      "loss time 0.001819 sec\n",
      "backward time 0.015439 sec\n",
      "optimizer time 0.024732 sec\n",
      "training time in round 96 cost 0.3976879119873047 sec\n",
      "loss 2.309483, train acc 0.102529\n",
      "round 97\n",
      "time to device 0.004829 sec\n",
      "time forward 1.343509 sec\n",
      "loss time 0.001212 sec\n",
      "backward time 0.014275 sec\n",
      "optimizer time 0.025999 sec\n",
      "training time in round 97 cost 0.3956911563873291 sec\n",
      "loss 2.309423, train acc 0.102758\n",
      "round 98\n",
      "time to device 0.004014 sec\n",
      "time forward 1.358372 sec\n",
      "loss time 0.001840 sec\n",
      "backward time 0.013870 sec\n",
      "optimizer time 0.024348 sec\n",
      "training time in round 98 cost 0.4065699577331543 sec\n",
      "loss 2.309396, train acc 0.102509\n",
      "round 99\n",
      "time to device 0.004326 sec\n",
      "time forward 1.371597 sec\n",
      "loss time 0.002006 sec\n",
      "backward time 0.014602 sec\n",
      "optimizer time 0.022300 sec\n",
      "training time in round 99 cost 0.3894510269165039 sec\n",
      "loss 2.309327, train acc 0.102422\n",
      "round 100\n",
      "time to device 0.004716 sec\n",
      "time forward 1.385125 sec\n",
      "loss time 0.001472 sec\n",
      "backward time 0.013276 sec\n",
      "optimizer time 0.025248 sec\n",
      "training time in round 100 cost 0.3879368305206299 sec\n",
      "loss 2.309355, train acc 0.102259\n",
      "round 101\n",
      "time to device 0.004014 sec\n",
      "time forward 1.399413 sec\n",
      "loss time 0.001987 sec\n",
      "backward time 0.013244 sec\n",
      "optimizer time 0.026001 sec\n",
      "training time in round 101 cost 0.3972458839416504 sec\n",
      "loss 2.309694, train acc 0.102022\n",
      "round 102\n",
      "time to device 0.003623 sec\n",
      "time forward 1.413487 sec\n",
      "loss time 0.001896 sec\n",
      "backward time 0.014722 sec\n",
      "optimizer time 0.024269 sec\n",
      "training time in round 102 cost 0.39144277572631836 sec\n",
      "loss 2.309693, train acc 0.102397\n",
      "round 103\n",
      "time to device 0.003688 sec\n",
      "time forward 1.425877 sec\n",
      "loss time 0.001311 sec\n",
      "backward time 0.013502 sec\n",
      "optimizer time 0.027654 sec\n",
      "training time in round 103 cost 0.38608884811401367 sec\n",
      "loss 2.309642, train acc 0.102239\n",
      "round 104\n",
      "time to device 0.004439 sec\n",
      "time forward 1.439866 sec\n",
      "loss time 0.002001 sec\n",
      "backward time 0.012651 sec\n",
      "optimizer time 0.023905 sec\n",
      "training time in round 104 cost 0.39192914962768555 sec\n",
      "loss 2.309549, train acc 0.102083\n",
      "round 105\n",
      "time to device 0.003666 sec\n",
      "time forward 1.454449 sec\n",
      "loss time 0.001563 sec\n",
      "backward time 0.013473 sec\n",
      "optimizer time 0.024635 sec\n",
      "training time in round 105 cost 0.3938279151916504 sec\n",
      "loss 2.309508, train acc 0.102005\n",
      "round 106\n",
      "time to device 0.003738 sec\n",
      "time forward 1.466362 sec\n",
      "loss time 0.001091 sec\n",
      "backward time 0.015928 sec\n",
      "optimizer time 0.026121 sec\n",
      "training time in round 106 cost 0.3812522888183594 sec\n",
      "loss 2.309464, train acc 0.102147\n",
      "round 107\n",
      "time to device 0.004256 sec\n",
      "time forward 1.479242 sec\n",
      "loss time 0.001297 sec\n",
      "backward time 0.015626 sec\n",
      "optimizer time 0.027017 sec\n",
      "training time in round 107 cost 0.3877570629119873 sec\n",
      "loss 2.309438, train acc 0.101924\n",
      "round 108\n",
      "time to device 0.003439 sec\n",
      "time forward 1.491571 sec\n",
      "loss time 0.001254 sec\n",
      "backward time 0.014908 sec\n",
      "optimizer time 0.028128 sec\n",
      "training time in round 108 cost 0.39281487464904785 sec\n",
      "loss 2.309354, train acc 0.101921\n",
      "round 109\n",
      "time to device 0.003475 sec\n",
      "time forward 1.497303 sec\n",
      "loss time 0.000366 sec\n",
      "backward time 0.003148 sec\n",
      "optimizer time 0.009802 sec\n",
      "training time in round 109 cost 0.3390209674835205 sec\n",
      "loss 2.309305, train acc 0.101918\n",
      "round 110\n",
      "time to device 0.004474 sec\n",
      "time forward 1.508713 sec\n",
      "loss time 0.001472 sec\n",
      "backward time 0.016810 sec\n",
      "optimizer time 0.026125 sec\n",
      "training time in round 110 cost 0.38495898246765137 sec\n",
      "loss 2.309073, train acc 0.102126\n",
      "round 111\n",
      "time to device 0.003227 sec\n",
      "time forward 1.523662 sec\n",
      "loss time 0.001502 sec\n",
      "backward time 0.012731 sec\n",
      "optimizer time 0.022633 sec\n",
      "training time in round 111 cost 0.4030752182006836 sec\n",
      "loss 2.309027, train acc 0.102190\n",
      "round 112\n",
      "time to device 0.004217 sec\n",
      "time forward 1.537199 sec\n",
      "loss time 0.001241 sec\n",
      "backward time 0.011771 sec\n",
      "optimizer time 0.026036 sec\n",
      "training time in round 112 cost 0.39322590827941895 sec\n",
      "loss 2.308997, train acc 0.102254\n",
      "round 113\n",
      "time to device 0.004390 sec\n",
      "time forward 1.549246 sec\n",
      "loss time 0.001247 sec\n",
      "backward time 0.011568 sec\n",
      "optimizer time 0.026539 sec\n",
      "training time in round 113 cost 0.3820507526397705 sec\n",
      "loss 2.308962, train acc 0.102111\n",
      "round 114\n",
      "time to device 0.004096 sec\n",
      "time forward 1.564195 sec\n",
      "loss time 0.001446 sec\n",
      "backward time 0.017913 sec\n",
      "optimizer time 0.022082 sec\n",
      "training time in round 114 cost 0.39580798149108887 sec\n",
      "loss 2.308920, train acc 0.102106\n",
      "round 115\n",
      "time to device 0.004124 sec\n",
      "time forward 1.577481 sec\n",
      "loss time 0.001240 sec\n",
      "backward time 0.015243 sec\n",
      "optimizer time 0.025763 sec\n",
      "training time in round 115 cost 0.38941502571105957 sec\n",
      "loss 2.308861, train acc 0.102303\n",
      "round 116\n",
      "time to device 0.006418 sec\n",
      "time forward 1.590968 sec\n",
      "loss time 0.001652 sec\n",
      "backward time 0.013786 sec\n",
      "optimizer time 0.025519 sec\n",
      "training time in round 116 cost 0.3961310386657715 sec\n",
      "loss 2.308867, train acc 0.102497\n",
      "round 117\n",
      "time to device 0.006831 sec\n",
      "time forward 1.604423 sec\n",
      "loss time 0.002095 sec\n",
      "backward time 0.015105 sec\n",
      "optimizer time 0.026223 sec\n",
      "training time in round 117 cost 0.3977339267730713 sec\n",
      "loss 2.308797, train acc 0.102688\n",
      "round 118\n",
      "time to device 0.009112 sec\n",
      "time forward 1.617100 sec\n",
      "loss time 0.001720 sec\n",
      "backward time 0.013983 sec\n",
      "optimizer time 0.024420 sec\n",
      "training time in round 118 cost 0.39528512954711914 sec\n",
      "loss 2.308762, train acc 0.102679\n",
      "round 119\n",
      "time to device 0.010777 sec\n",
      "time forward 1.632158 sec\n",
      "loss time 0.001468 sec\n",
      "backward time 0.014011 sec\n",
      "optimizer time 0.025022 sec\n",
      "training time in round 119 cost 0.40685105323791504 sec\n",
      "loss 2.310480, train acc 0.102669\n",
      "round 120\n",
      "time to device 0.004747 sec\n",
      "time forward 1.646276 sec\n",
      "loss time 0.001252 sec\n",
      "backward time 0.011935 sec\n",
      "optimizer time 0.028003 sec\n",
      "training time in round 120 cost 0.3935511112213135 sec\n",
      "loss 2.310443, train acc 0.102402\n",
      "round 121\n",
      "time to device 0.003636 sec\n",
      "time forward 1.658304 sec\n",
      "loss time 0.001877 sec\n",
      "backward time 0.013856 sec\n",
      "optimizer time 0.025971 sec\n",
      "training time in round 121 cost 0.3847169876098633 sec\n",
      "loss 2.310372, train acc 0.102459\n",
      "round 122\n",
      "time to device 0.003978 sec\n",
      "time forward 1.665434 sec\n",
      "loss time 0.000505 sec\n",
      "backward time 0.004533 sec\n",
      "optimizer time 0.013230 sec\n",
      "training time in round 122 cost 0.3484647274017334 sec\n",
      "loss 2.310324, train acc 0.102007\n",
      "round 123\n",
      "time to device 0.002923 sec\n",
      "time forward 1.679460 sec\n",
      "loss time 0.001570 sec\n",
      "backward time 0.012767 sec\n",
      "optimizer time 0.024908 sec\n",
      "training time in round 123 cost 0.3957858085632324 sec\n",
      "loss 2.310242, train acc 0.101752\n",
      "round 124\n",
      "time to device 0.004273 sec\n",
      "time forward 1.693378 sec\n",
      "loss time 0.001613 sec\n",
      "backward time 0.012864 sec\n",
      "optimizer time 0.024329 sec\n",
      "training time in round 124 cost 0.39154791831970215 sec\n",
      "loss 2.310283, train acc 0.101562\n",
      "round 125\n",
      "time to device 0.003389 sec\n",
      "time forward 1.710206 sec\n",
      "loss time 0.001207 sec\n",
      "backward time 0.012833 sec\n",
      "optimizer time 0.024634 sec\n",
      "training time in round 125 cost 0.3934030532836914 sec\n",
      "loss 2.310630, train acc 0.101314\n",
      "round 126\n",
      "time to device 0.005375 sec\n",
      "time forward 1.722066 sec\n",
      "loss time 0.002042 sec\n",
      "backward time 0.013588 sec\n",
      "optimizer time 0.025543 sec\n",
      "training time in round 126 cost 0.38391590118408203 sec\n",
      "loss 2.310782, train acc 0.101316\n",
      "round 127\n",
      "time to device 0.002863 sec\n",
      "time forward 1.736012 sec\n",
      "loss time 0.001057 sec\n",
      "backward time 0.013344 sec\n",
      "optimizer time 0.026547 sec\n",
      "training time in round 127 cost 0.3874690532684326 sec\n",
      "loss 2.310715, train acc 0.101074\n",
      "round 128\n",
      "time to device 0.003354 sec\n",
      "time forward 1.746743 sec\n",
      "loss time 0.001973 sec\n",
      "backward time 0.014099 sec\n",
      "optimizer time 0.026699 sec\n",
      "training time in round 128 cost 0.3820149898529053 sec\n",
      "loss 2.310641, train acc 0.101139\n",
      "round 129\n",
      "time to device 0.004116 sec\n",
      "time forward 1.753381 sec\n",
      "loss time 0.000568 sec\n",
      "backward time 0.005078 sec\n",
      "optimizer time 0.013942 sec\n",
      "training time in round 129 cost 0.3408782482147217 sec\n",
      "loss 2.310577, train acc 0.101262\n",
      "round 130\n",
      "time to device 0.003977 sec\n",
      "time forward 1.766673 sec\n",
      "loss time 0.001489 sec\n",
      "backward time 0.012426 sec\n",
      "optimizer time 0.023508 sec\n",
      "training time in round 130 cost 0.38679075241088867 sec\n",
      "loss 2.310514, train acc 0.101264\n",
      "round 131\n",
      "time to device 0.003774 sec\n",
      "time forward 1.782175 sec\n",
      "loss time 0.001961 sec\n",
      "backward time 0.016155 sec\n",
      "optimizer time 0.024930 sec\n",
      "training time in round 131 cost 0.40006589889526367 sec\n",
      "loss 2.310597, train acc 0.101444\n",
      "round 132\n",
      "time to device 0.003465 sec\n",
      "time forward 1.795968 sec\n",
      "loss time 0.001943 sec\n",
      "backward time 0.014126 sec\n",
      "optimizer time 0.024610 sec\n",
      "training time in round 132 cost 0.3906691074371338 sec\n",
      "loss 2.310526, train acc 0.101739\n",
      "round 133\n",
      "time to device 0.003161 sec\n",
      "time forward 1.809100 sec\n",
      "loss time 0.001482 sec\n",
      "backward time 0.014241 sec\n",
      "optimizer time 0.025946 sec\n",
      "training time in round 133 cost 0.39110565185546875 sec\n",
      "loss 2.310536, train acc 0.102029\n",
      "round 134\n",
      "time to device 0.008817 sec\n",
      "time forward 1.821803 sec\n",
      "loss time 0.002466 sec\n",
      "backward time 0.022474 sec\n",
      "optimizer time 0.021403 sec\n",
      "training time in round 134 cost 0.40166187286376953 sec\n",
      "loss 2.310565, train acc 0.101794\n",
      "round 135\n",
      "time to device 0.003678 sec\n",
      "time forward 1.835135 sec\n",
      "loss time 0.001315 sec\n",
      "backward time 0.011350 sec\n",
      "optimizer time 0.026119 sec\n",
      "training time in round 135 cost 0.40428900718688965 sec\n",
      "loss 2.310511, train acc 0.101735\n",
      "round 136\n",
      "time to device 0.003855 sec\n",
      "time forward 1.848281 sec\n",
      "loss time 0.001831 sec\n",
      "backward time 0.013277 sec\n",
      "optimizer time 0.025659 sec\n",
      "training time in round 136 cost 0.38817882537841797 sec\n",
      "loss 2.310471, train acc 0.101734\n",
      "round 137\n",
      "time to device 0.003655 sec\n",
      "time forward 1.860841 sec\n",
      "loss time 0.001965 sec\n",
      "backward time 0.013609 sec\n",
      "optimizer time 0.025375 sec\n",
      "training time in round 137 cost 0.3909142017364502 sec\n",
      "loss 2.312912, train acc 0.102015\n",
      "round 138\n",
      "time to device 0.004311 sec\n",
      "time forward 1.873843 sec\n",
      "loss time 0.001843 sec\n",
      "backward time 0.012350 sec\n",
      "optimizer time 0.026561 sec\n",
      "training time in round 138 cost 0.3905479907989502 sec\n",
      "loss 2.312842, train acc 0.101844\n",
      "round 139\n",
      "time to device 0.003937 sec\n",
      "time forward 1.887498 sec\n",
      "loss time 0.002572 sec\n",
      "backward time 0.014156 sec\n",
      "optimizer time 0.024502 sec\n",
      "training time in round 139 cost 0.39217519760131836 sec\n",
      "loss 2.312855, train acc 0.101507\n",
      "round 140\n",
      "time to device 0.003211 sec\n",
      "time forward 1.900059 sec\n",
      "loss time 0.001539 sec\n",
      "backward time 0.012963 sec\n",
      "optimizer time 0.023947 sec\n",
      "training time in round 140 cost 0.3843998908996582 sec\n",
      "loss 2.312772, train acc 0.101562\n",
      "round 141\n",
      "time to device 0.004166 sec\n",
      "time forward 1.911606 sec\n",
      "loss time 0.001064 sec\n",
      "backward time 0.011636 sec\n",
      "optimizer time 0.026335 sec\n",
      "training time in round 141 cost 0.3799750804901123 sec\n",
      "loss 2.312748, train acc 0.101838\n",
      "round 142\n",
      "time to device 0.003263 sec\n",
      "time forward 1.926196 sec\n",
      "loss time 0.001464 sec\n",
      "backward time 0.012849 sec\n",
      "optimizer time 0.024762 sec\n",
      "training time in round 142 cost 0.39046764373779297 sec\n",
      "loss 2.312682, train acc 0.101781\n",
      "round 143\n",
      "time to device 0.003477 sec\n",
      "time forward 1.939330 sec\n",
      "loss time 0.001951 sec\n",
      "backward time 0.014638 sec\n",
      "optimizer time 0.024073 sec\n",
      "training time in round 143 cost 0.39206671714782715 sec\n",
      "loss 2.312596, train acc 0.102105\n",
      "round 144\n",
      "time to device 0.003538 sec\n",
      "time forward 1.951853 sec\n",
      "loss time 0.001487 sec\n",
      "backward time 0.012909 sec\n",
      "optimizer time 0.014830 sec\n",
      "training time in round 144 cost 0.37648797035217285 sec\n",
      "loss 2.312550, train acc 0.101940\n",
      "round 145\n",
      "time to device 0.004079 sec\n",
      "time forward 1.964489 sec\n",
      "loss time 0.001885 sec\n",
      "backward time 0.016449 sec\n",
      "optimizer time 0.024819 sec\n",
      "training time in round 145 cost 0.39122819900512695 sec\n",
      "loss 2.312475, train acc 0.101562\n",
      "round 146\n",
      "time to device 0.004258 sec\n",
      "time forward 1.978580 sec\n",
      "loss time 0.001393 sec\n",
      "backward time 0.011970 sec\n",
      "optimizer time 0.023906 sec\n",
      "training time in round 146 cost 0.3904111385345459 sec\n",
      "loss 2.312421, train acc 0.101616\n",
      "round 147\n",
      "time to device 0.004132 sec\n",
      "time forward 1.991807 sec\n",
      "loss time 0.002072 sec\n",
      "backward time 0.014438 sec\n",
      "optimizer time 0.025184 sec\n",
      "training time in round 147 cost 0.3937568664550781 sec\n",
      "loss 2.312408, train acc 0.101510\n",
      "round 148\n",
      "time to device 0.004052 sec\n",
      "time forward 1.999281 sec\n",
      "loss time 0.000548 sec\n",
      "backward time 0.005011 sec\n",
      "optimizer time 0.013731 sec\n",
      "training time in round 148 cost 0.35362792015075684 sec\n",
      "loss 2.312331, train acc 0.101458\n",
      "round 149\n",
      "time to device 0.004141 sec\n",
      "time forward 2.013201 sec\n",
      "loss time 0.001703 sec\n",
      "backward time 0.014300 sec\n",
      "optimizer time 0.024665 sec\n",
      "training time in round 149 cost 0.39291810989379883 sec\n",
      "loss 2.312284, train acc 0.101510\n",
      "round 150\n",
      "time to device 0.003425 sec\n",
      "time forward 2.027853 sec\n",
      "loss time 0.001135 sec\n",
      "backward time 0.012851 sec\n",
      "optimizer time 0.025325 sec\n",
      "training time in round 150 cost 0.3951108455657959 sec\n",
      "loss 2.312224, train acc 0.101252\n",
      "round 151\n",
      "time to device 0.003566 sec\n",
      "time forward 2.040988 sec\n",
      "loss time 0.001564 sec\n",
      "backward time 0.015109 sec\n",
      "optimizer time 0.023876 sec\n",
      "training time in round 151 cost 0.385422945022583 sec\n",
      "loss 2.312189, train acc 0.101049\n",
      "round 152\n",
      "time to device 0.004510 sec\n",
      "time forward 2.054724 sec\n",
      "loss time 0.001627 sec\n",
      "backward time 0.011904 sec\n",
      "optimizer time 0.023139 sec\n",
      "training time in round 152 cost 0.384152889251709 sec\n",
      "loss 2.312146, train acc 0.101103\n",
      "round 153\n",
      "time to device 0.003559 sec\n",
      "time forward 2.067589 sec\n",
      "loss time 0.001119 sec\n",
      "backward time 0.012951 sec\n",
      "optimizer time 0.026513 sec\n",
      "training time in round 153 cost 0.3926122188568115 sec\n",
      "loss 2.312096, train acc 0.101055\n",
      "round 154\n",
      "time to device 0.003882 sec\n",
      "time forward 2.082115 sec\n",
      "loss time 0.001566 sec\n",
      "backward time 0.013262 sec\n",
      "optimizer time 0.024963 sec\n",
      "training time in round 154 cost 0.40050816535949707 sec\n",
      "loss 2.312063, train acc 0.100756\n",
      "round 155\n",
      "time to device 0.003613 sec\n",
      "time forward 2.094587 sec\n",
      "loss time 0.001865 sec\n",
      "backward time 0.014735 sec\n",
      "optimizer time 0.025338 sec\n",
      "training time in round 155 cost 0.3848409652709961 sec\n",
      "loss 2.312014, train acc 0.100811\n",
      "round 156\n",
      "time to device 0.003988 sec\n",
      "time forward 2.107906 sec\n",
      "loss time 0.001972 sec\n",
      "backward time 0.013913 sec\n",
      "optimizer time 0.025344 sec\n",
      "training time in round 156 cost 0.3928840160369873 sec\n",
      "loss 2.311943, train acc 0.100965\n",
      "round 157\n",
      "time to device 0.003699 sec\n",
      "time forward 2.120701 sec\n",
      "loss time 0.001591 sec\n",
      "backward time 0.014122 sec\n",
      "optimizer time 0.025770 sec\n",
      "training time in round 157 cost 0.38754701614379883 sec\n",
      "loss 2.311894, train acc 0.100672\n",
      "round 158\n",
      "time to device 0.003319 sec\n",
      "time forward 2.133993 sec\n",
      "loss time 0.001455 sec\n",
      "backward time 0.010796 sec\n",
      "optimizer time 0.021922 sec\n",
      "training time in round 158 cost 0.38199591636657715 sec\n",
      "loss 2.311829, train acc 0.100678\n",
      "round 159\n",
      "time to device 0.003401 sec\n",
      "time forward 2.146004 sec\n",
      "loss time 0.001076 sec\n",
      "backward time 0.011897 sec\n",
      "optimizer time 0.025562 sec\n",
      "training time in round 159 cost 0.38565993309020996 sec\n",
      "loss 2.311759, train acc 0.100488\n",
      "round 160\n",
      "time to device 0.003253 sec\n",
      "time forward 2.154753 sec\n",
      "loss time 0.000508 sec\n",
      "backward time 0.004199 sec\n",
      "optimizer time 0.011226 sec\n",
      "training time in round 160 cost 0.36474132537841797 sec\n",
      "loss 2.311710, train acc 0.100446\n",
      "round 161\n",
      "time to device 0.004825 sec\n",
      "time forward 2.172234 sec\n",
      "loss time 0.001779 sec\n",
      "backward time 0.013496 sec\n",
      "optimizer time 0.028721 sec\n",
      "training time in round 161 cost 0.4592609405517578 sec\n",
      "loss 2.311643, train acc 0.100550\n",
      "round 162\n",
      "time to device 0.009062 sec\n",
      "time forward 2.186882 sec\n",
      "loss time 0.001995 sec\n",
      "backward time 0.014060 sec\n",
      "optimizer time 0.024360 sec\n",
      "training time in round 162 cost 0.4000997543334961 sec\n",
      "loss 2.311575, train acc 0.100700\n",
      "round 163\n",
      "time to device 0.008263 sec\n",
      "time forward 2.196565 sec\n",
      "loss time 0.001565 sec\n",
      "backward time 0.013888 sec\n",
      "optimizer time 0.029200 sec\n",
      "training time in round 163 cost 0.38584208488464355 sec\n",
      "loss 2.311517, train acc 0.100800\n",
      "round 164\n",
      "time to device 0.009203 sec\n",
      "time forward 2.209488 sec\n",
      "loss time 0.001706 sec\n",
      "backward time 0.026318 sec\n",
      "optimizer time 0.022517 sec\n",
      "training time in round 164 cost 0.4082150459289551 sec\n",
      "loss 2.311614, train acc 0.100900\n",
      "round 165\n",
      "time to device 0.009522 sec\n",
      "time forward 2.223570 sec\n",
      "loss time 0.001983 sec\n",
      "backward time 0.015044 sec\n",
      "optimizer time 0.023453 sec\n",
      "training time in round 165 cost 0.4163990020751953 sec\n",
      "loss 2.311544, train acc 0.100857\n",
      "round 166\n",
      "time to device 0.009203 sec\n",
      "time forward 2.237709 sec\n",
      "loss time 0.001572 sec\n",
      "backward time 0.013374 sec\n",
      "optimizer time 0.025011 sec\n",
      "training time in round 166 cost 0.3996140956878662 sec\n",
      "loss 2.311671, train acc 0.100674\n",
      "round 167\n",
      "time to device 0.007127 sec\n",
      "time forward 2.250697 sec\n",
      "loss time 0.001577 sec\n",
      "backward time 0.013532 sec\n",
      "optimizer time 0.024145 sec\n",
      "training time in round 167 cost 0.3927760124206543 sec\n",
      "loss 2.311600, train acc 0.100911\n",
      "round 168\n",
      "time to device 0.008043 sec\n",
      "time forward 2.257894 sec\n",
      "loss time 0.000451 sec\n",
      "backward time 0.004109 sec\n",
      "optimizer time 0.011908 sec\n",
      "training time in round 168 cost 0.3480839729309082 sec\n",
      "loss 2.312036, train acc 0.100915\n",
      "round 169\n",
      "time to device 0.003721 sec\n",
      "time forward 2.270483 sec\n",
      "loss time 0.001529 sec\n",
      "backward time 0.013579 sec\n",
      "optimizer time 0.026842 sec\n",
      "training time in round 169 cost 0.39141416549682617 sec\n",
      "loss 2.311976, train acc 0.101057\n",
      "round 170\n",
      "time to device 0.005628 sec\n",
      "time forward 2.283029 sec\n",
      "loss time 0.001926 sec\n",
      "backward time 0.014196 sec\n",
      "optimizer time 0.024462 sec\n",
      "training time in round 170 cost 0.39359092712402344 sec\n",
      "loss 2.311931, train acc 0.101060\n",
      "round 171\n",
      "time to device 0.003553 sec\n",
      "time forward 2.296746 sec\n",
      "loss time 0.001101 sec\n",
      "backward time 0.020747 sec\n",
      "optimizer time 0.022247 sec\n",
      "training time in round 171 cost 0.3992609977722168 sec\n",
      "loss 2.311906, train acc 0.100745\n",
      "round 172\n",
      "time to device 0.004143 sec\n",
      "time forward 2.309964 sec\n",
      "loss time 0.001983 sec\n",
      "backward time 0.013737 sec\n",
      "optimizer time 0.029128 sec\n",
      "training time in round 172 cost 0.4138948917388916 sec\n",
      "loss 2.311851, train acc 0.100795\n",
      "round 173\n",
      "time to device 0.004238 sec\n",
      "time forward 2.326562 sec\n",
      "loss time 0.001211 sec\n",
      "backward time 0.012555 sec\n",
      "optimizer time 0.021042 sec\n",
      "training time in round 173 cost 0.4008200168609619 sec\n",
      "loss 2.311768, train acc 0.101158\n",
      "round 174\n",
      "time to device 0.004643 sec\n",
      "time forward 2.341804 sec\n",
      "loss time 0.001213 sec\n",
      "backward time 0.015907 sec\n",
      "optimizer time 0.026140 sec\n",
      "training time in round 174 cost 0.41804075241088867 sec\n",
      "loss 2.311735, train acc 0.101027\n",
      "round 175\n",
      "time to device 0.004704 sec\n",
      "time forward 2.355057 sec\n",
      "loss time 0.001530 sec\n",
      "backward time 0.012718 sec\n",
      "optimizer time 0.025428 sec\n",
      "training time in round 175 cost 0.3939330577850342 sec\n",
      "loss 2.311670, train acc 0.101074\n",
      "round 176\n",
      "time to device 0.008813 sec\n",
      "time forward 2.369564 sec\n",
      "loss time 0.000919 sec\n",
      "backward time 0.011564 sec\n",
      "optimizer time 0.023855 sec\n",
      "training time in round 176 cost 0.3975698947906494 sec\n",
      "loss 2.311651, train acc 0.101033\n",
      "round 177\n",
      "time to device 0.010303 sec\n",
      "time forward 2.383721 sec\n",
      "loss time 0.001193 sec\n",
      "backward time 0.013848 sec\n",
      "optimizer time 0.024322 sec\n",
      "training time in round 177 cost 0.4032008647918701 sec\n",
      "loss 2.311575, train acc 0.101299\n",
      "round 178\n",
      "time to device 0.008552 sec\n",
      "time forward 2.397186 sec\n",
      "loss time 0.001667 sec\n",
      "backward time 0.015029 sec\n",
      "optimizer time 0.014836 sec\n",
      "training time in round 178 cost 0.3879268169403076 sec\n",
      "loss 2.311496, train acc 0.101432\n",
      "round 179\n",
      "time to device 0.008622 sec\n",
      "time forward 2.410259 sec\n",
      "loss time 0.002107 sec\n",
      "backward time 0.012756 sec\n",
      "optimizer time 0.023822 sec\n",
      "training time in round 179 cost 0.39432287216186523 sec\n",
      "loss 2.311460, train acc 0.101432\n",
      "round 180\n",
      "time to device 0.006488 sec\n",
      "time forward 2.424412 sec\n",
      "loss time 0.001453 sec\n",
      "backward time 0.013814 sec\n",
      "optimizer time 0.025283 sec\n",
      "training time in round 180 cost 0.42136502265930176 sec\n",
      "loss 2.311406, train acc 0.101390\n",
      "round 181\n",
      "time to device 0.008899 sec\n",
      "time forward 2.436511 sec\n",
      "loss time 0.001268 sec\n",
      "backward time 0.013450 sec\n",
      "optimizer time 0.027173 sec\n",
      "training time in round 181 cost 0.387786865234375 sec\n",
      "loss 2.311361, train acc 0.101391\n",
      "round 182\n",
      "time to device 0.007060 sec\n",
      "time forward 2.449337 sec\n",
      "loss time 0.001845 sec\n",
      "backward time 0.014970 sec\n",
      "optimizer time 0.025240 sec\n",
      "training time in round 182 cost 0.3942248821258545 sec\n",
      "loss 2.311339, train acc 0.101349\n",
      "round 183\n",
      "time to device 0.009325 sec\n",
      "time forward 2.461598 sec\n",
      "loss time 0.001880 sec\n",
      "backward time 0.014432 sec\n",
      "optimizer time 0.027251 sec\n",
      "training time in round 183 cost 0.39927196502685547 sec\n",
      "loss 2.311342, train acc 0.101180\n",
      "round 184\n",
      "time to device 0.007518 sec\n",
      "time forward 2.473535 sec\n",
      "loss time 0.001676 sec\n",
      "backward time 0.013375 sec\n",
      "optimizer time 0.021274 sec\n",
      "training time in round 184 cost 0.38530492782592773 sec\n",
      "loss 2.311480, train acc 0.101309\n",
      "round 185\n",
      "time to device 0.011602 sec\n",
      "time forward 2.491542 sec\n",
      "loss time 0.002021 sec\n",
      "backward time 0.013253 sec\n",
      "optimizer time 0.024106 sec\n",
      "training time in round 185 cost 0.41822075843811035 sec\n",
      "loss 2.311447, train acc 0.101058\n",
      "round 186\n",
      "time to device 0.007417 sec\n",
      "time forward 2.506243 sec\n",
      "loss time 0.001934 sec\n",
      "backward time 0.013231 sec\n",
      "optimizer time 0.022525 sec\n",
      "training time in round 186 cost 0.39751482009887695 sec\n",
      "loss 2.311401, train acc 0.101145\n",
      "round 187\n",
      "time to device 0.008561 sec\n",
      "time forward 2.519711 sec\n",
      "loss time 0.002044 sec\n",
      "backward time 0.013553 sec\n",
      "optimizer time 0.024667 sec\n",
      "training time in round 187 cost 0.3925471305847168 sec\n",
      "loss 2.311347, train acc 0.101355\n",
      "round 188\n",
      "time to device 0.003210 sec\n",
      "time forward 2.533114 sec\n",
      "loss time 0.001180 sec\n",
      "backward time 0.011485 sec\n",
      "optimizer time 0.021014 sec\n",
      "training time in round 188 cost 0.37894201278686523 sec\n",
      "loss 2.311303, train acc 0.101562\n",
      "round 189\n",
      "time to device 0.003505 sec\n",
      "time forward 2.545696 sec\n",
      "loss time 0.001176 sec\n",
      "backward time 0.011539 sec\n",
      "optimizer time 0.020265 sec\n",
      "training time in round 189 cost 0.3886239528656006 sec\n",
      "loss 2.311267, train acc 0.101480\n",
      "round 190\n",
      "time to device 0.004022 sec\n",
      "time forward 2.556115 sec\n",
      "loss time 0.000592 sec\n",
      "backward time 0.005144 sec\n",
      "optimizer time 0.013838 sec\n",
      "training time in round 190 cost 0.3529810905456543 sec\n",
      "loss 2.311211, train acc 0.101440\n",
      "round 191\n",
      "time to device 0.003477 sec\n",
      "time forward 2.569073 sec\n",
      "loss time 0.001242 sec\n",
      "backward time 0.010957 sec\n",
      "optimizer time 0.024637 sec\n",
      "training time in round 191 cost 0.38417911529541016 sec\n",
      "loss 2.311168, train acc 0.101440\n",
      "round 192\n",
      "time to device 0.003555 sec\n",
      "time forward 2.581917 sec\n",
      "loss time 0.002050 sec\n",
      "backward time 0.013803 sec\n",
      "optimizer time 0.025704 sec\n",
      "training time in round 192 cost 0.3890969753265381 sec\n",
      "loss 2.311135, train acc 0.101360\n",
      "round 193\n",
      "time to device 0.003534 sec\n",
      "time forward 2.596629 sec\n",
      "loss time 0.001243 sec\n",
      "backward time 0.020184 sec\n",
      "optimizer time 0.024574 sec\n",
      "training time in round 193 cost 0.40009379386901855 sec\n",
      "loss 2.311070, train acc 0.101240\n",
      "round 194\n",
      "time to device 0.004043 sec\n",
      "time forward 2.603817 sec\n",
      "loss time 0.000636 sec\n",
      "backward time 0.005552 sec\n",
      "optimizer time 0.014132 sec\n",
      "training time in round 194 cost 0.35254907608032227 sec\n",
      "loss 2.311004, train acc 0.101362\n",
      "round 195\n",
      "time to device 0.002970 sec\n",
      "time forward 2.612181 sec\n",
      "loss time 0.001244 sec\n",
      "backward time 0.008725 sec\n",
      "optimizer time 0.019376 sec\n",
      "training time in round 195 cost 0.3487062454223633 sec\n",
      "loss 2.310954, train acc 0.101363\n",
      "round 196\n",
      "time to device 0.003805 sec\n",
      "time forward 2.625728 sec\n",
      "loss time 0.001180 sec\n",
      "backward time 0.012762 sec\n",
      "optimizer time 0.026207 sec\n",
      "training time in round 196 cost 0.3908119201660156 sec\n",
      "loss 2.310908, train acc 0.101444\n",
      "round 197\n",
      "time to device 0.004106 sec\n",
      "time forward 2.639916 sec\n",
      "loss time 0.002009 sec\n",
      "backward time 0.014311 sec\n",
      "optimizer time 0.026576 sec\n",
      "training time in round 197 cost 0.39708614349365234 sec\n",
      "loss 2.310879, train acc 0.101444\n",
      "round 198\n",
      "time to device 0.003729 sec\n",
      "time forward 2.651547 sec\n",
      "loss time 0.001792 sec\n",
      "backward time 0.013497 sec\n",
      "optimizer time 0.023821 sec\n",
      "training time in round 198 cost 0.3816540241241455 sec\n",
      "loss 2.310847, train acc 0.101484\n",
      "round 199\n",
      "time to device 0.003943 sec\n",
      "time forward 2.665539 sec\n",
      "loss time 0.001506 sec\n",
      "backward time 0.012281 sec\n",
      "optimizer time 0.021752 sec\n",
      "training time in round 199 cost 0.38661718368530273 sec\n",
      "loss 2.310810, train acc 0.101523\n",
      "round 200\n",
      "time to device 0.003632 sec\n",
      "time forward 2.679447 sec\n",
      "loss time 0.001583 sec\n",
      "backward time 0.010528 sec\n",
      "optimizer time 0.021317 sec\n",
      "training time in round 200 cost 0.385822057723999 sec\n",
      "loss 2.310742, train acc 0.101757\n",
      "round 201\n",
      "time to device 0.003296 sec\n",
      "time forward 2.691759 sec\n",
      "loss time 0.002028 sec\n",
      "backward time 0.015540 sec\n",
      "optimizer time 0.028646 sec\n",
      "training time in round 201 cost 0.39029693603515625 sec\n",
      "loss 2.310695, train acc 0.101756\n",
      "round 202\n",
      "time to device 0.003467 sec\n",
      "time forward 2.704731 sec\n",
      "loss time 0.001390 sec\n",
      "backward time 0.013028 sec\n",
      "optimizer time 0.024648 sec\n",
      "training time in round 202 cost 0.3854200839996338 sec\n",
      "loss 2.310647, train acc 0.101909\n",
      "round 203\n",
      "time to device 0.004738 sec\n",
      "time forward 2.717118 sec\n",
      "loss time 0.001862 sec\n",
      "backward time 0.012697 sec\n",
      "optimizer time 0.027669 sec\n",
      "training time in round 203 cost 0.3911421298980713 sec\n",
      "loss 2.310600, train acc 0.102022\n",
      "round 204\n",
      "time to device 0.003681 sec\n",
      "time forward 2.731954 sec\n",
      "loss time 0.001659 sec\n",
      "backward time 0.012200 sec\n",
      "optimizer time 0.023524 sec\n",
      "training time in round 204 cost 0.39176487922668457 sec\n",
      "loss 2.310558, train acc 0.102134\n",
      "round 205\n",
      "time to device 0.003789 sec\n",
      "time forward 2.747332 sec\n",
      "loss time 0.001197 sec\n",
      "backward time 0.011131 sec\n",
      "optimizer time 0.020993 sec\n",
      "training time in round 205 cost 0.38828301429748535 sec\n",
      "loss 2.310525, train acc 0.102169\n",
      "round 206\n",
      "time to device 0.004945 sec\n",
      "time forward 2.760301 sec\n",
      "loss time 0.001819 sec\n",
      "backward time 0.014726 sec\n",
      "optimizer time 0.025080 sec\n",
      "training time in round 206 cost 0.3913552761077881 sec\n",
      "loss 2.310511, train acc 0.101978\n",
      "round 207\n",
      "time to device 0.004715 sec\n",
      "time forward 2.772465 sec\n",
      "loss time 0.001910 sec\n",
      "backward time 0.013101 sec\n",
      "optimizer time 0.023920 sec\n",
      "training time in round 207 cost 0.3856210708618164 sec\n",
      "loss 2.310510, train acc 0.101825\n",
      "round 208\n",
      "time to device 0.004660 sec\n",
      "time forward 2.786464 sec\n",
      "loss time 0.001949 sec\n",
      "backward time 0.014575 sec\n",
      "optimizer time 0.025643 sec\n",
      "training time in round 208 cost 0.394909143447876 sec\n",
      "loss 2.310466, train acc 0.101824\n",
      "round 209\n",
      "time to device 0.003975 sec\n",
      "time forward 2.800858 sec\n",
      "loss time 0.001513 sec\n",
      "backward time 0.014946 sec\n",
      "optimizer time 0.024841 sec\n",
      "training time in round 209 cost 0.39565610885620117 sec\n",
      "loss 2.310395, train acc 0.102009\n",
      "round 210\n",
      "time to device 0.003063 sec\n",
      "time forward 2.814301 sec\n",
      "loss time 0.001788 sec\n",
      "backward time 0.017054 sec\n",
      "optimizer time 0.028152 sec\n",
      "training time in round 210 cost 0.3959810733795166 sec\n",
      "loss 2.310418, train acc 0.102118\n",
      "round 211\n",
      "time to device 0.005030 sec\n",
      "time forward 2.826968 sec\n",
      "loss time 0.001945 sec\n",
      "backward time 0.013545 sec\n",
      "optimizer time 0.026334 sec\n",
      "training time in round 211 cost 0.39008307456970215 sec\n",
      "loss 2.310371, train acc 0.102300\n",
      "round 212\n",
      "time to device 0.004257 sec\n",
      "time forward 2.840419 sec\n",
      "loss time 0.001449 sec\n",
      "backward time 0.014858 sec\n",
      "optimizer time 0.022946 sec\n",
      "training time in round 212 cost 0.4025998115539551 sec\n",
      "loss 2.310329, train acc 0.102443\n",
      "round 213\n",
      "time to device 0.003541 sec\n",
      "time forward 2.853494 sec\n",
      "loss time 0.001562 sec\n",
      "backward time 0.012217 sec\n",
      "optimizer time 0.027458 sec\n",
      "training time in round 213 cost 0.43759918212890625 sec\n",
      "loss 2.310291, train acc 0.102439\n",
      "round 214\n",
      "time to device 0.004643 sec\n",
      "time forward 2.865362 sec\n",
      "loss time 0.001751 sec\n",
      "backward time 0.013519 sec\n",
      "optimizer time 0.017247 sec\n",
      "training time in round 214 cost 0.3764822483062744 sec\n",
      "loss 2.310251, train acc 0.102544\n",
      "round 215\n",
      "time to device 0.006699 sec\n",
      "time forward 2.877972 sec\n",
      "loss time 0.001345 sec\n",
      "backward time 0.025431 sec\n",
      "optimizer time 0.021136 sec\n",
      "training time in round 215 cost 0.3967297077178955 sec\n",
      "loss 2.310208, train acc 0.102720\n",
      "round 216\n",
      "time to device 0.009217 sec\n",
      "time forward 2.891139 sec\n",
      "loss time 0.001480 sec\n",
      "backward time 0.011953 sec\n",
      "optimizer time 0.025490 sec\n",
      "training time in round 216 cost 0.40625715255737305 sec\n",
      "loss 2.310166, train acc 0.102751\n",
      "round 217\n",
      "time to device 0.006633 sec\n",
      "time forward 2.905287 sec\n",
      "loss time 0.002006 sec\n",
      "backward time 0.013682 sec\n",
      "optimizer time 0.024184 sec\n",
      "training time in round 217 cost 0.3968329429626465 sec\n",
      "loss 2.310127, train acc 0.102781\n",
      "round 218\n",
      "time to device 0.009182 sec\n",
      "time forward 2.918791 sec\n",
      "loss time 0.001799 sec\n",
      "backward time 0.014155 sec\n",
      "optimizer time 0.024182 sec\n",
      "training time in round 218 cost 0.3949449062347412 sec\n",
      "loss 2.310178, train acc 0.102918\n",
      "round 219\n",
      "time to device 0.003693 sec\n",
      "time forward 2.925468 sec\n",
      "loss time 0.000565 sec\n",
      "backward time 0.005125 sec\n",
      "optimizer time 0.014471 sec\n",
      "training time in round 219 cost 0.3435800075531006 sec\n",
      "loss 2.310144, train acc 0.102734\n",
      "round 220\n",
      "time to device 0.003120 sec\n",
      "time forward 2.938960 sec\n",
      "loss time 0.002422 sec\n",
      "backward time 0.012427 sec\n",
      "optimizer time 0.024508 sec\n",
      "training time in round 220 cost 0.38727498054504395 sec\n",
      "loss 2.310101, train acc 0.102977\n",
      "round 221\n",
      "time to device 0.003416 sec\n",
      "time forward 2.953551 sec\n",
      "loss time 0.001268 sec\n",
      "backward time 0.015415 sec\n",
      "optimizer time 0.024314 sec\n",
      "training time in round 221 cost 0.395413875579834 sec\n",
      "loss 2.310136, train acc 0.102829\n",
      "round 222\n",
      "time to device 0.003178 sec\n",
      "time forward 2.965122 sec\n",
      "loss time 0.001084 sec\n",
      "backward time 0.012136 sec\n",
      "optimizer time 0.027761 sec\n",
      "training time in round 222 cost 0.381087064743042 sec\n",
      "loss 2.310105, train acc 0.102754\n",
      "round 223\n",
      "time to device 0.003977 sec\n",
      "time forward 2.978293 sec\n",
      "loss time 0.001987 sec\n",
      "backward time 0.012866 sec\n",
      "optimizer time 0.023715 sec\n",
      "training time in round 223 cost 0.38953208923339844 sec\n",
      "loss 2.310063, train acc 0.102853\n",
      "round 224\n",
      "time to device 0.003932 sec\n",
      "time forward 2.985551 sec\n",
      "loss time 0.000494 sec\n",
      "backward time 0.004519 sec\n",
      "optimizer time 0.012908 sec\n",
      "training time in round 224 cost 0.35042881965637207 sec\n",
      "loss 2.310169, train acc 0.102743\n",
      "round 225\n",
      "time to device 0.004334 sec\n",
      "time forward 2.999876 sec\n",
      "loss time 0.001637 sec\n",
      "backward time 0.013613 sec\n",
      "optimizer time 0.024658 sec\n",
      "training time in round 225 cost 0.3945338726043701 sec\n",
      "loss 2.310120, train acc 0.102703\n",
      "round 226\n",
      "time to device 0.003958 sec\n",
      "time forward 3.013356 sec\n",
      "loss time 0.001774 sec\n",
      "backward time 0.012962 sec\n",
      "optimizer time 0.024930 sec\n",
      "training time in round 226 cost 0.3872852325439453 sec\n",
      "loss 2.310067, train acc 0.102836\n",
      "round 227\n",
      "time to device 0.003072 sec\n",
      "time forward 3.022640 sec\n",
      "loss time 0.001090 sec\n",
      "backward time 0.008708 sec\n",
      "optimizer time 0.019322 sec\n",
      "training time in round 227 cost 0.3626828193664551 sec\n",
      "loss 2.310052, train acc 0.102899\n",
      "round 228\n",
      "time to device 0.003382 sec\n",
      "time forward 3.036701 sec\n",
      "loss time 0.001226 sec\n",
      "backward time 0.014706 sec\n",
      "optimizer time 0.025662 sec\n",
      "training time in round 228 cost 0.39459896087646484 sec\n",
      "loss 2.310019, train acc 0.102893\n",
      "round 229\n",
      "time to device 0.003327 sec\n",
      "time forward 3.049883 sec\n",
      "loss time 0.001518 sec\n",
      "backward time 0.012518 sec\n",
      "optimizer time 0.024145 sec\n",
      "training time in round 229 cost 0.3836209774017334 sec\n",
      "loss 2.310026, train acc 0.102717\n",
      "round 230\n",
      "time to device 0.003543 sec\n",
      "time forward 3.064104 sec\n",
      "loss time 0.001558 sec\n",
      "backward time 0.013099 sec\n",
      "optimizer time 0.022794 sec\n",
      "training time in round 230 cost 0.38954758644104004 sec\n",
      "loss 2.309995, train acc 0.102645\n",
      "round 231\n",
      "time to device 0.004275 sec\n",
      "time forward 3.077167 sec\n",
      "loss time 0.001111 sec\n",
      "backward time 0.013092 sec\n",
      "optimizer time 0.026242 sec\n",
      "training time in round 231 cost 0.38842296600341797 sec\n",
      "loss 2.309973, train acc 0.102539\n",
      "round 232\n",
      "time to device 0.003554 sec\n",
      "time forward 3.091425 sec\n",
      "loss time 0.001990 sec\n",
      "backward time 0.015827 sec\n",
      "optimizer time 0.023627 sec\n",
      "training time in round 232 cost 0.398439884185791 sec\n",
      "loss 2.309942, train acc 0.102434\n",
      "round 233\n",
      "time to device 0.003667 sec\n",
      "time forward 3.104233 sec\n",
      "loss time 0.001245 sec\n",
      "backward time 0.014119 sec\n",
      "optimizer time 0.020545 sec\n",
      "training time in round 233 cost 0.3952817916870117 sec\n",
      "loss 2.309924, train acc 0.102397\n",
      "round 234\n",
      "time to device 0.004113 sec\n",
      "time forward 3.116814 sec\n",
      "loss time 0.001425 sec\n",
      "backward time 0.012562 sec\n",
      "optimizer time 0.023201 sec\n",
      "training time in round 234 cost 0.46166086196899414 sec\n",
      "loss 2.309908, train acc 0.102493\n",
      "round 235\n",
      "time to device 0.008651 sec\n",
      "time forward 3.132565 sec\n",
      "loss time 0.001366 sec\n",
      "backward time 0.013967 sec\n",
      "optimizer time 0.024506 sec\n",
      "training time in round 235 cost 0.4276399612426758 sec\n",
      "loss 2.309895, train acc 0.102456\n",
      "round 236\n",
      "time to device 0.009849 sec\n",
      "time forward 3.143807 sec\n",
      "loss time 0.002001 sec\n",
      "backward time 0.016125 sec\n",
      "optimizer time 0.025818 sec\n",
      "training time in round 236 cost 0.41915106773376465 sec\n",
      "loss 2.309879, train acc 0.102321\n",
      "round 237\n",
      "time to device 0.009046 sec\n",
      "time forward 3.156401 sec\n",
      "loss time 0.001196 sec\n",
      "backward time 0.012315 sec\n",
      "optimizer time 0.022627 sec\n",
      "training time in round 237 cost 0.4109959602355957 sec\n",
      "loss 2.310493, train acc 0.102186\n",
      "round 238\n",
      "time to device 0.009000 sec\n",
      "time forward 3.162517 sec\n",
      "loss time 0.000589 sec\n",
      "backward time 0.005240 sec\n",
      "optimizer time 0.014304 sec\n",
      "training time in round 238 cost 0.3663468360900879 sec\n",
      "loss 2.310410, train acc 0.102576\n",
      "round 239\n",
      "time to device 0.008978 sec\n",
      "time forward 3.178224 sec\n",
      "loss time 0.001109 sec\n",
      "backward time 0.012171 sec\n",
      "optimizer time 0.021403 sec\n",
      "training time in round 239 cost 0.40523624420166016 sec\n",
      "loss 2.310380, train acc 0.102474\n",
      "round 240\n",
      "time to device 0.010378 sec\n",
      "time forward 3.192314 sec\n",
      "loss time 0.001765 sec\n",
      "backward time 0.015706 sec\n",
      "optimizer time 0.025709 sec\n",
      "training time in round 240 cost 0.41106510162353516 sec\n",
      "loss 2.310322, train acc 0.102730\n",
      "round 241\n",
      "time to device 0.006626 sec\n",
      "time forward 3.206283 sec\n",
      "loss time 0.001507 sec\n",
      "backward time 0.013356 sec\n",
      "optimizer time 0.021835 sec\n",
      "training time in round 241 cost 0.40006494522094727 sec\n",
      "loss 2.310276, train acc 0.102789\n",
      "round 242\n",
      "time to device 0.004784 sec\n",
      "time forward 3.220520 sec\n",
      "loss time 0.001465 sec\n",
      "backward time 0.014492 sec\n",
      "optimizer time 0.025526 sec\n",
      "training time in round 242 cost 0.396848201751709 sec\n",
      "loss 2.310250, train acc 0.102913\n",
      "round 243\n",
      "time to device 0.008782 sec\n",
      "time forward 3.232293 sec\n",
      "loss time 0.001525 sec\n",
      "backward time 0.013004 sec\n",
      "optimizer time 0.020995 sec\n",
      "training time in round 243 cost 0.3884270191192627 sec\n",
      "loss 2.310237, train acc 0.102779\n",
      "round 244\n",
      "time to device 0.003344 sec\n",
      "time forward 3.239399 sec\n",
      "loss time 0.000543 sec\n",
      "backward time 0.004974 sec\n",
      "optimizer time 0.013985 sec\n",
      "training time in round 244 cost 0.35694098472595215 sec\n",
      "loss 2.310207, train acc 0.102902\n",
      "round 245\n",
      "time to device 0.004252 sec\n",
      "time forward 3.253690 sec\n",
      "loss time 0.001259 sec\n",
      "backward time 0.010919 sec\n",
      "optimizer time 0.020888 sec\n",
      "training time in round 245 cost 0.3894622325897217 sec\n",
      "loss 2.310207, train acc 0.102674\n",
      "round 246\n",
      "time to device 0.004365 sec\n",
      "time forward 3.267644 sec\n",
      "loss time 0.002070 sec\n",
      "backward time 0.013562 sec\n",
      "optimizer time 0.023954 sec\n",
      "training time in round 246 cost 0.39372992515563965 sec\n",
      "loss 2.310175, train acc 0.102733\n",
      "round 247\n",
      "time to device 0.003826 sec\n",
      "time forward 3.280434 sec\n",
      "loss time 0.000982 sec\n",
      "backward time 0.012225 sec\n",
      "optimizer time 0.020223 sec\n",
      "training time in round 247 cost 0.39420604705810547 sec\n",
      "loss 2.310148, train acc 0.102854\n",
      "round 248\n",
      "time to device 0.005198 sec\n",
      "time forward 3.295369 sec\n",
      "loss time 0.001155 sec\n",
      "backward time 0.012732 sec\n",
      "optimizer time 0.029559 sec\n",
      "training time in round 248 cost 0.41118407249450684 sec\n",
      "loss 2.310117, train acc 0.102974\n",
      "round 249\n",
      "time to device 0.004121 sec\n",
      "time forward 3.313578 sec\n",
      "loss time 0.001507 sec\n",
      "backward time 0.012664 sec\n",
      "optimizer time 0.023240 sec\n",
      "training time in round 249 cost 0.41528892517089844 sec\n",
      "loss 2.310082, train acc 0.103063\n",
      "round 250\n",
      "time to device 0.006280 sec\n",
      "time forward 3.328266 sec\n",
      "loss time 0.001039 sec\n",
      "backward time 0.014261 sec\n",
      "optimizer time 0.027500 sec\n",
      "training time in round 250 cost 0.3997318744659424 sec\n",
      "loss 2.310034, train acc 0.103088\n",
      "round 251\n",
      "time to device 0.003938 sec\n",
      "time forward 3.341727 sec\n",
      "loss time 0.002892 sec\n",
      "backward time 0.013341 sec\n",
      "optimizer time 0.024677 sec\n",
      "training time in round 251 cost 0.39657020568847656 sec\n",
      "loss 2.310033, train acc 0.102989\n",
      "round 252\n",
      "time to device 0.003734 sec\n",
      "time forward 3.356454 sec\n",
      "loss time 0.002096 sec\n",
      "backward time 0.020674 sec\n",
      "optimizer time 0.025984 sec\n",
      "training time in round 252 cost 0.40543389320373535 sec\n",
      "loss 2.310007, train acc 0.102983\n",
      "round 253\n",
      "time to device 0.003849 sec\n",
      "time forward 3.370341 sec\n",
      "loss time 0.001353 sec\n",
      "backward time 0.010764 sec\n",
      "optimizer time 0.020656 sec\n",
      "training time in round 253 cost 0.3855888843536377 sec\n",
      "loss 2.309976, train acc 0.103008\n",
      "round 254\n",
      "time to device 0.004788 sec\n",
      "time forward 3.384630 sec\n",
      "loss time 0.001523 sec\n",
      "backward time 0.012462 sec\n",
      "optimizer time 0.020101 sec\n",
      "training time in round 254 cost 0.4006471633911133 sec\n",
      "loss 2.309954, train acc 0.103033\n",
      "round 255\n",
      "time to device 0.005438 sec\n",
      "time forward 3.397147 sec\n",
      "loss time 0.001876 sec\n",
      "backward time 0.014512 sec\n",
      "optimizer time 0.024391 sec\n",
      "training time in round 255 cost 0.3914041519165039 sec\n",
      "loss 2.309930, train acc 0.103088\n",
      "round 256\n",
      "time to device 0.004205 sec\n",
      "time forward 3.412224 sec\n",
      "loss time 0.001467 sec\n",
      "backward time 0.016012 sec\n",
      "optimizer time 0.024003 sec\n",
      "training time in round 256 cost 0.39989304542541504 sec\n",
      "loss 2.309918, train acc 0.102991\n",
      "round 257\n",
      "time to device 0.003718 sec\n",
      "time forward 3.431223 sec\n",
      "loss time 0.001648 sec\n",
      "backward time 0.011317 sec\n",
      "optimizer time 0.023800 sec\n",
      "training time in round 257 cost 0.40809130668640137 sec\n",
      "loss 2.309897, train acc 0.102986\n",
      "round 258\n",
      "time to device 0.003779 sec\n",
      "time forward 3.447058 sec\n",
      "loss time 0.001413 sec\n",
      "backward time 0.014071 sec\n",
      "optimizer time 0.023527 sec\n",
      "training time in round 258 cost 0.4473741054534912 sec\n",
      "loss 2.309852, train acc 0.103041\n",
      "round 259\n",
      "time to device 0.008870 sec\n",
      "time forward 3.461508 sec\n",
      "loss time 0.001563 sec\n",
      "backward time 0.011745 sec\n",
      "optimizer time 0.024146 sec\n",
      "training time in round 259 cost 0.39594006538391113 sec\n",
      "loss 2.309840, train acc 0.102945\n",
      "round 260\n",
      "time to device 0.009710 sec\n",
      "time forward 3.476282 sec\n",
      "loss time 0.001850 sec\n",
      "backward time 0.012531 sec\n",
      "optimizer time 0.023526 sec\n",
      "training time in round 260 cost 0.4113030433654785 sec\n",
      "loss 2.309834, train acc 0.102820\n",
      "round 261\n",
      "time to device 0.006711 sec\n",
      "time forward 3.488998 sec\n",
      "loss time 0.001319 sec\n",
      "backward time 0.010448 sec\n",
      "optimizer time 0.021966 sec\n",
      "training time in round 261 cost 0.386368989944458 sec\n",
      "loss 2.309819, train acc 0.102785\n",
      "round 262\n",
      "time to device 0.008203 sec\n",
      "time forward 3.503791 sec\n",
      "loss time 0.001525 sec\n",
      "backward time 0.015205 sec\n",
      "optimizer time 0.024416 sec\n",
      "training time in round 262 cost 0.40499114990234375 sec\n",
      "loss 2.309797, train acc 0.102691\n",
      "round 263\n",
      "time to device 0.009110 sec\n",
      "time forward 3.517165 sec\n",
      "loss time 0.002261 sec\n",
      "backward time 0.015304 sec\n",
      "optimizer time 0.025956 sec\n",
      "training time in round 263 cost 0.4015491008758545 sec\n",
      "loss 2.309763, train acc 0.102805\n",
      "round 264\n",
      "time to device 0.010096 sec\n",
      "time forward 3.534000 sec\n",
      "loss time 0.001371 sec\n",
      "backward time 0.013467 sec\n",
      "optimizer time 0.022058 sec\n",
      "training time in round 264 cost 0.4078640937805176 sec\n",
      "loss 2.309867, train acc 0.102535\n",
      "round 265\n",
      "time to device 0.007065 sec\n",
      "time forward 3.548361 sec\n",
      "loss time 0.002224 sec\n",
      "backward time 0.013334 sec\n",
      "optimizer time 0.023915 sec\n",
      "training time in round 265 cost 0.4141981601715088 sec\n",
      "loss 2.309863, train acc 0.102326\n",
      "round 266\n",
      "time to device 0.003224 sec\n",
      "time forward 3.558532 sec\n",
      "loss time 0.001970 sec\n",
      "backward time 0.014867 sec\n",
      "optimizer time 0.025168 sec\n",
      "training time in round 266 cost 0.39992499351501465 sec\n",
      "loss 2.309822, train acc 0.102557\n",
      "round 267\n",
      "time to device 0.004989 sec\n",
      "time forward 3.572203 sec\n",
      "loss time 0.001861 sec\n",
      "backward time 0.010700 sec\n",
      "optimizer time 0.026267 sec\n",
      "training time in round 267 cost 0.3916511535644531 sec\n",
      "loss 2.309807, train acc 0.102466\n",
      "round 268\n",
      "time to device 0.003646 sec\n",
      "time forward 3.579842 sec\n",
      "loss time 0.000554 sec\n",
      "backward time 0.005005 sec\n",
      "optimizer time 0.013561 sec\n",
      "training time in round 268 cost 0.3535902500152588 sec\n",
      "loss 2.309781, train acc 0.102637\n",
      "round 269\n",
      "time to device 0.003405 sec\n",
      "time forward 3.593145 sec\n",
      "loss time 0.001357 sec\n",
      "backward time 0.010834 sec\n",
      "optimizer time 0.021149 sec\n",
      "training time in round 269 cost 0.3817868232727051 sec\n",
      "loss 2.309752, train acc 0.102778\n",
      "round 270\n",
      "time to device 0.003520 sec\n",
      "time forward 3.606008 sec\n",
      "loss time 0.001654 sec\n",
      "backward time 0.011946 sec\n",
      "optimizer time 0.026551 sec\n",
      "training time in round 270 cost 0.3900771141052246 sec\n",
      "loss 2.309725, train acc 0.102802\n",
      "round 271\n",
      "time to device 0.003629 sec\n",
      "time forward 3.617733 sec\n",
      "loss time 0.001874 sec\n",
      "backward time 0.013031 sec\n",
      "optimizer time 0.026824 sec\n",
      "training time in round 271 cost 0.38622379302978516 sec\n",
      "loss 2.309703, train acc 0.102769\n",
      "round 272\n",
      "time to device 0.004234 sec\n",
      "time forward 3.630321 sec\n",
      "loss time 0.001370 sec\n",
      "backward time 0.011539 sec\n",
      "optimizer time 0.023913 sec\n",
      "training time in round 272 cost 0.3818659782409668 sec\n",
      "loss 2.309674, train acc 0.102764\n",
      "round 273\n",
      "time to device 0.004257 sec\n",
      "time forward 3.642973 sec\n",
      "loss time 0.001525 sec\n",
      "backward time 0.014105 sec\n",
      "optimizer time 0.025487 sec\n",
      "training time in round 273 cost 0.3864140510559082 sec\n",
      "loss 2.309643, train acc 0.102789\n",
      "round 274\n",
      "time to device 0.003447 sec\n",
      "time forward 3.658240 sec\n",
      "loss time 0.001602 sec\n",
      "backward time 0.013794 sec\n",
      "optimizer time 0.023714 sec\n",
      "training time in round 274 cost 0.39393115043640137 sec\n",
      "loss 2.309615, train acc 0.102813\n",
      "round 275\n",
      "time to device 0.004024 sec\n",
      "time forward 3.670806 sec\n",
      "loss time 0.001871 sec\n",
      "backward time 0.015197 sec\n",
      "optimizer time 0.025258 sec\n",
      "training time in round 275 cost 0.39198803901672363 sec\n",
      "loss 2.309590, train acc 0.102695\n",
      "round 276\n",
      "time to device 0.005454 sec\n",
      "time forward 3.683493 sec\n",
      "loss time 0.001539 sec\n",
      "backward time 0.011051 sec\n",
      "optimizer time 0.025751 sec\n",
      "training time in round 276 cost 0.391124963760376 sec\n",
      "loss 2.309565, train acc 0.102747\n",
      "round 277\n",
      "time to device 0.003638 sec\n",
      "time forward 3.698436 sec\n",
      "loss time 0.001462 sec\n",
      "backward time 0.013050 sec\n",
      "optimizer time 0.023869 sec\n",
      "training time in round 277 cost 0.39496302604675293 sec\n",
      "loss 2.309540, train acc 0.102799\n",
      "round 278\n",
      "time to device 0.003012 sec\n",
      "time forward 3.705661 sec\n",
      "loss time 0.000547 sec\n",
      "backward time 0.004931 sec\n",
      "optimizer time 0.013020 sec\n",
      "training time in round 278 cost 0.3444092273712158 sec\n",
      "loss 2.309512, train acc 0.102823\n",
      "round 279\n",
      "time to device 0.004451 sec\n",
      "time forward 3.717550 sec\n",
      "loss time 0.001827 sec\n",
      "backward time 0.014960 sec\n",
      "optimizer time 0.025333 sec\n",
      "training time in round 279 cost 0.40061092376708984 sec\n",
      "loss 2.309483, train acc 0.102790\n",
      "round 280\n",
      "time to device 0.003669 sec\n",
      "time forward 3.732057 sec\n",
      "loss time 0.002069 sec\n",
      "backward time 0.015032 sec\n",
      "optimizer time 0.021544 sec\n",
      "training time in round 280 cost 0.4096348285675049 sec\n",
      "loss 2.309433, train acc 0.102786\n",
      "round 281\n",
      "time to device 0.004135 sec\n",
      "time forward 3.748402 sec\n",
      "loss time 0.001033 sec\n",
      "backward time 0.013058 sec\n",
      "optimizer time 0.014796 sec\n",
      "training time in round 281 cost 0.38501501083374023 sec\n",
      "loss 2.309394, train acc 0.102837\n",
      "round 282\n",
      "time to device 0.004678 sec\n",
      "time forward 3.762365 sec\n",
      "loss time 0.002038 sec\n",
      "backward time 0.014930 sec\n",
      "optimizer time 0.026150 sec\n",
      "training time in round 282 cost 0.41341090202331543 sec\n",
      "loss 2.309411, train acc 0.102832\n",
      "round 283\n",
      "time to device 0.003190 sec\n",
      "time forward 3.775763 sec\n",
      "loss time 0.001425 sec\n",
      "backward time 0.012487 sec\n",
      "optimizer time 0.020805 sec\n",
      "training time in round 283 cost 0.38312387466430664 sec\n",
      "loss 2.309592, train acc 0.102800\n",
      "round 284\n",
      "time to device 0.004015 sec\n",
      "time forward 3.788188 sec\n",
      "loss time 0.001618 sec\n",
      "backward time 0.014095 sec\n",
      "optimizer time 0.024756 sec\n",
      "training time in round 284 cost 0.3871150016784668 sec\n",
      "loss 2.309557, train acc 0.102906\n",
      "round 285\n",
      "time to device 0.003270 sec\n",
      "time forward 3.803546 sec\n",
      "loss time 0.001344 sec\n",
      "backward time 0.011850 sec\n",
      "optimizer time 0.023043 sec\n",
      "training time in round 285 cost 0.4441041946411133 sec\n",
      "loss 2.309543, train acc 0.102901\n",
      "round 286\n",
      "time to device 0.004697 sec\n",
      "time forward 3.816536 sec\n",
      "loss time 0.001254 sec\n",
      "backward time 0.016994 sec\n",
      "optimizer time 0.025136 sec\n",
      "training time in round 286 cost 0.3927769660949707 sec\n",
      "loss 2.309512, train acc 0.102978\n",
      "round 287\n",
      "time to device 0.004910 sec\n",
      "time forward 3.829918 sec\n",
      "loss time 0.001418 sec\n",
      "backward time 0.013787 sec\n",
      "optimizer time 0.024893 sec\n",
      "training time in round 287 cost 0.38622188568115234 sec\n",
      "loss 2.309504, train acc 0.102810\n",
      "round 288\n",
      "time to device 0.003912 sec\n",
      "time forward 3.842654 sec\n",
      "loss time 0.000627 sec\n",
      "backward time 0.005944 sec\n",
      "optimizer time 0.014966 sec\n",
      "training time in round 288 cost 0.3650240898132324 sec\n",
      "loss 2.309472, train acc 0.102941\n",
      "round 289\n",
      "time to device 0.008051 sec\n",
      "time forward 3.855976 sec\n",
      "loss time 0.001587 sec\n",
      "backward time 0.011857 sec\n",
      "optimizer time 0.023127 sec\n",
      "training time in round 289 cost 0.38556385040283203 sec\n",
      "loss 2.309452, train acc 0.102856\n",
      "round 290\n",
      "time to device 0.003512 sec\n",
      "time forward 3.868523 sec\n",
      "loss time 0.001915 sec\n",
      "backward time 0.015406 sec\n",
      "optimizer time 0.024840 sec\n",
      "training time in round 290 cost 0.38322997093200684 sec\n",
      "loss 2.309443, train acc 0.102851\n",
      "round 291\n",
      "time to device 0.003129 sec\n",
      "time forward 3.882105 sec\n",
      "loss time 0.001023 sec\n",
      "backward time 0.017857 sec\n",
      "optimizer time 0.024226 sec\n",
      "training time in round 291 cost 0.406951904296875 sec\n",
      "loss 2.309439, train acc 0.102900\n",
      "round 292\n",
      "time to device 0.008700 sec\n",
      "time forward 3.895516 sec\n",
      "loss time 0.001504 sec\n",
      "backward time 0.012334 sec\n",
      "optimizer time 0.037804 sec\n",
      "training time in round 292 cost 0.43896007537841797 sec\n",
      "loss 2.309397, train acc 0.102949\n",
      "round 293\n",
      "time to device 0.007708 sec\n",
      "time forward 3.901536 sec\n",
      "loss time 0.000563 sec\n",
      "backward time 0.005215 sec\n",
      "optimizer time 0.014960 sec\n",
      "training time in round 293 cost 0.361407995223999 sec\n",
      "loss 2.309403, train acc 0.102865\n",
      "round 294\n",
      "time to device 0.009703 sec\n",
      "time forward 3.917428 sec\n",
      "loss time 0.001599 sec\n",
      "backward time 0.015294 sec\n",
      "optimizer time 0.027724 sec\n",
      "training time in round 294 cost 0.40621399879455566 sec\n",
      "loss 2.309382, train acc 0.102807\n",
      "round 295\n",
      "time to device 0.009990 sec\n",
      "time forward 3.930865 sec\n",
      "loss time 0.001380 sec\n",
      "backward time 0.013895 sec\n",
      "optimizer time 0.024048 sec\n",
      "training time in round 295 cost 0.39582276344299316 sec\n",
      "loss 2.309376, train acc 0.102882\n",
      "round 296\n",
      "time to device 0.007060 sec\n",
      "time forward 3.944225 sec\n",
      "loss time 0.001002 sec\n",
      "backward time 0.009988 sec\n",
      "optimizer time 0.021938 sec\n",
      "training time in round 296 cost 0.38958072662353516 sec\n",
      "loss 2.309377, train acc 0.102667\n",
      "round 297\n",
      "time to device 0.009236 sec\n",
      "time forward 3.957752 sec\n",
      "loss time 0.002276 sec\n",
      "backward time 0.014941 sec\n",
      "optimizer time 0.024898 sec\n",
      "training time in round 297 cost 0.4395570755004883 sec\n",
      "loss 2.309354, train acc 0.102611\n",
      "round 298\n",
      "time to device 0.008932 sec\n",
      "time forward 3.970252 sec\n",
      "loss time 0.002020 sec\n",
      "backward time 0.013026 sec\n",
      "optimizer time 0.025160 sec\n",
      "training time in round 298 cost 0.389329195022583 sec\n",
      "loss 2.309343, train acc 0.102555\n",
      "round 299\n",
      "time to device 0.009505 sec\n",
      "time forward 3.983804 sec\n",
      "loss time 0.001918 sec\n",
      "backward time 0.014989 sec\n",
      "optimizer time 0.027505 sec\n",
      "training time in round 299 cost 0.402393102645874 sec\n",
      "loss 2.309326, train acc 0.102500\n",
      "round 300\n",
      "time to device 0.009297 sec\n",
      "time forward 3.998043 sec\n",
      "loss time 0.002011 sec\n",
      "backward time 0.016205 sec\n",
      "optimizer time 0.027325 sec\n",
      "training time in round 300 cost 0.40525293350219727 sec\n",
      "loss 2.309324, train acc 0.102419\n",
      "round 301\n",
      "time to device 0.008862 sec\n",
      "time forward 4.010523 sec\n",
      "loss time 0.001845 sec\n",
      "backward time 0.015626 sec\n",
      "optimizer time 0.027789 sec\n",
      "training time in round 301 cost 0.3954761028289795 sec\n",
      "loss 2.309325, train acc 0.102209\n",
      "round 302\n",
      "time to device 0.008744 sec\n",
      "time forward 4.021899 sec\n",
      "loss time 0.001945 sec\n",
      "backward time 0.013225 sec\n",
      "optimizer time 0.023218 sec\n",
      "training time in round 302 cost 0.40085697174072266 sec\n",
      "loss 2.309295, train acc 0.102284\n",
      "round 303\n",
      "time to device 0.007106 sec\n",
      "time forward 4.035900 sec\n",
      "loss time 0.002133 sec\n",
      "backward time 0.012257 sec\n",
      "optimizer time 0.025057 sec\n",
      "training time in round 303 cost 0.39387083053588867 sec\n",
      "loss 2.309298, train acc 0.101999\n",
      "round 304\n",
      "time to device 0.007458 sec\n",
      "time forward 4.043505 sec\n",
      "loss time 0.000565 sec\n",
      "backward time 0.005363 sec\n",
      "optimizer time 0.015868 sec\n",
      "training time in round 304 cost 0.3571920394897461 sec\n",
      "loss 2.309281, train acc 0.101998\n",
      "round 305\n",
      "time to device 0.010671 sec\n",
      "time forward 4.059040 sec\n",
      "loss time 0.001675 sec\n",
      "backward time 0.009841 sec\n",
      "optimizer time 0.021295 sec\n",
      "training time in round 305 cost 0.39317822456359863 sec\n",
      "loss 2.309252, train acc 0.102022\n",
      "round 306\n",
      "time to device 0.007266 sec\n",
      "time forward 4.072896 sec\n",
      "loss time 0.002122 sec\n",
      "backward time 0.014137 sec\n",
      "optimizer time 0.026556 sec\n",
      "training time in round 306 cost 0.4003129005432129 sec\n",
      "loss 2.309241, train acc 0.102046\n",
      "round 307\n",
      "time to device 0.007353 sec\n",
      "time forward 4.089991 sec\n",
      "loss time 0.001648 sec\n",
      "backward time 0.016636 sec\n",
      "optimizer time 0.024909 sec\n",
      "training time in round 307 cost 0.41351795196533203 sec\n",
      "loss 2.309214, train acc 0.101943\n",
      "round 308\n",
      "time to device 0.009113 sec\n",
      "time forward 4.108890 sec\n",
      "loss time 0.001572 sec\n",
      "backward time 0.013070 sec\n",
      "optimizer time 0.024612 sec\n",
      "training time in round 308 cost 0.4232611656188965 sec\n",
      "loss 2.309189, train acc 0.101916\n",
      "round 309\n",
      "time to device 0.009002 sec\n",
      "time forward 4.121748 sec\n",
      "loss time 0.001833 sec\n",
      "backward time 0.013403 sec\n",
      "optimizer time 0.026839 sec\n",
      "training time in round 309 cost 0.3962850570678711 sec\n",
      "loss 2.309183, train acc 0.101840\n",
      "round 310\n",
      "time to device 0.008076 sec\n",
      "time forward 4.135740 sec\n",
      "loss time 0.001876 sec\n",
      "backward time 0.015485 sec\n",
      "optimizer time 0.024302 sec\n",
      "training time in round 310 cost 0.39960384368896484 sec\n",
      "loss 2.309160, train acc 0.101889\n",
      "round 311\n",
      "time to device 0.008426 sec\n",
      "time forward 4.148802 sec\n",
      "loss time 0.001897 sec\n",
      "backward time 0.013661 sec\n",
      "optimizer time 0.024830 sec\n",
      "training time in round 311 cost 0.39645886421203613 sec\n",
      "loss 2.309147, train acc 0.101763\n",
      "round 312\n",
      "time to device 0.003586 sec\n",
      "time forward 4.162220 sec\n",
      "loss time 0.001881 sec\n",
      "backward time 0.014010 sec\n",
      "optimizer time 0.027077 sec\n",
      "training time in round 312 cost 0.39176487922668457 sec\n",
      "loss 2.309131, train acc 0.101712\n",
      "round 313\n",
      "time to device 0.003702 sec\n",
      "time forward 4.177017 sec\n",
      "loss time 0.002005 sec\n",
      "backward time 0.015587 sec\n",
      "optimizer time 0.024693 sec\n",
      "training time in round 313 cost 0.4000070095062256 sec\n",
      "loss 2.309132, train acc 0.101712\n",
      "round 314\n",
      "time to device 0.003817 sec\n",
      "time forward 4.190121 sec\n",
      "loss time 0.001159 sec\n",
      "backward time 0.014913 sec\n",
      "optimizer time 0.027155 sec\n",
      "training time in round 314 cost 0.3904452323913574 sec\n",
      "loss 2.309111, train acc 0.101637\n",
      "round 315\n",
      "time to device 0.004664 sec\n",
      "time forward 4.204203 sec\n",
      "loss time 0.001349 sec\n",
      "backward time 0.011974 sec\n",
      "optimizer time 0.014033 sec\n",
      "training time in round 315 cost 0.37914085388183594 sec\n",
      "loss 2.309088, train acc 0.101612\n",
      "round 316\n",
      "time to device 0.003906 sec\n",
      "time forward 4.217849 sec\n",
      "loss time 0.001842 sec\n",
      "backward time 0.018589 sec\n",
      "optimizer time 0.026034 sec\n",
      "training time in round 316 cost 0.3991861343383789 sec\n",
      "loss 2.309063, train acc 0.101562\n",
      "round 317\n",
      "time to device 0.003724 sec\n",
      "time forward 4.224615 sec\n",
      "loss time 0.000653 sec\n",
      "backward time 0.005510 sec\n",
      "optimizer time 0.014638 sec\n",
      "training time in round 317 cost 0.3625669479370117 sec\n",
      "loss 2.309038, train acc 0.101562\n",
      "round 318\n",
      "time to device 0.004621 sec\n",
      "time forward 4.235886 sec\n",
      "loss time 0.001872 sec\n",
      "backward time 0.014304 sec\n",
      "optimizer time 0.027346 sec\n",
      "training time in round 318 cost 0.38588595390319824 sec\n",
      "loss 2.309013, train acc 0.101709\n",
      "round 319\n",
      "time to device 0.004645 sec\n",
      "time forward 4.248146 sec\n",
      "loss time 0.001944 sec\n",
      "backward time 0.013812 sec\n",
      "optimizer time 0.026648 sec\n",
      "training time in round 319 cost 0.39085888862609863 sec\n",
      "loss 2.309000, train acc 0.101660\n",
      "round 320\n",
      "time to device 0.004740 sec\n",
      "time forward 4.260385 sec\n",
      "loss time 0.001088 sec\n",
      "backward time 0.009174 sec\n",
      "optimizer time 0.025115 sec\n",
      "training time in round 320 cost 0.3808290958404541 sec\n",
      "loss 2.308985, train acc 0.101562\n",
      "round 321\n",
      "time to device 0.003998 sec\n",
      "time forward 4.272795 sec\n",
      "loss time 0.001218 sec\n",
      "backward time 0.015685 sec\n",
      "optimizer time 0.024285 sec\n",
      "training time in round 321 cost 0.3877270221710205 sec\n",
      "loss 2.308965, train acc 0.101538\n",
      "round 322\n",
      "time to device 0.003628 sec\n",
      "time forward 4.285778 sec\n",
      "loss time 0.001607 sec\n",
      "backward time 0.013885 sec\n",
      "optimizer time 0.024905 sec\n",
      "training time in round 322 cost 0.43741703033447266 sec\n",
      "loss 2.308946, train acc 0.101514\n",
      "round 323\n",
      "time to device 0.004879 sec\n",
      "time forward 4.299042 sec\n",
      "loss time 0.001269 sec\n",
      "backward time 0.012415 sec\n",
      "optimizer time 0.025348 sec\n",
      "training time in round 323 cost 0.3883802890777588 sec\n",
      "loss 2.308925, train acc 0.101538\n",
      "round 324\n",
      "time to device 0.004790 sec\n",
      "time forward 4.312347 sec\n",
      "loss time 0.001614 sec\n",
      "backward time 0.016563 sec\n",
      "optimizer time 0.025528 sec\n",
      "training time in round 324 cost 0.3879120349884033 sec\n",
      "loss 2.308894, train acc 0.101394\n",
      "round 325\n",
      "time to device 0.003946 sec\n",
      "time forward 4.326475 sec\n",
      "loss time 0.001416 sec\n",
      "backward time 0.012192 sec\n",
      "optimizer time 0.024253 sec\n",
      "training time in round 325 cost 0.39099812507629395 sec\n",
      "loss 2.308876, train acc 0.101443\n",
      "round 326\n",
      "time to device 0.007975 sec\n",
      "time forward 4.334094 sec\n",
      "loss time 0.001071 sec\n",
      "backward time 0.010120 sec\n",
      "optimizer time 0.021029 sec\n",
      "training time in round 326 cost 0.354417085647583 sec\n",
      "loss 2.308848, train acc 0.101539\n",
      "round 327\n",
      "time to device 0.009264 sec\n",
      "time forward 4.346852 sec\n",
      "loss time 0.001486 sec\n",
      "backward time 0.022444 sec\n",
      "optimizer time 0.023610 sec\n",
      "training time in round 327 cost 0.3970060348510742 sec\n",
      "loss 2.308834, train acc 0.101539\n",
      "round 328\n",
      "time to device 0.009130 sec\n",
      "time forward 4.360603 sec\n",
      "loss time 0.001365 sec\n",
      "backward time 0.012076 sec\n",
      "optimizer time 0.023736 sec\n",
      "training time in round 328 cost 0.39251112937927246 sec\n",
      "loss 2.308815, train acc 0.101444\n",
      "round 329\n",
      "time to device 0.008073 sec\n",
      "time forward 4.375474 sec\n",
      "loss time 0.001205 sec\n",
      "backward time 0.019521 sec\n",
      "optimizer time 0.022877 sec\n",
      "training time in round 329 cost 0.4180920124053955 sec\n",
      "loss 2.308808, train acc 0.101373\n",
      "round 330\n",
      "time to device 0.008780 sec\n",
      "time forward 4.383114 sec\n",
      "loss time 0.000562 sec\n",
      "backward time 0.005034 sec\n",
      "optimizer time 0.013179 sec\n",
      "training time in round 330 cost 0.3551809787750244 sec\n",
      "loss 2.308784, train acc 0.101374\n",
      "round 331\n",
      "time to device 0.004225 sec\n",
      "time forward 4.397827 sec\n",
      "loss time 0.001907 sec\n",
      "backward time 0.012542 sec\n",
      "optimizer time 0.024940 sec\n",
      "training time in round 331 cost 0.39671778678894043 sec\n",
      "loss 2.308768, train acc 0.101398\n",
      "round 332\n",
      "time to device 0.005208 sec\n",
      "time forward 4.410185 sec\n",
      "loss time 0.001263 sec\n",
      "backward time 0.015801 sec\n",
      "optimizer time 0.025108 sec\n",
      "training time in round 332 cost 0.39611291885375977 sec\n",
      "loss 2.308748, train acc 0.101445\n",
      "round 333\n",
      "time to device 0.003701 sec\n",
      "time forward 4.424359 sec\n",
      "loss time 0.002750 sec\n",
      "backward time 0.012200 sec\n",
      "optimizer time 0.023457 sec\n",
      "training time in round 333 cost 0.3973870277404785 sec\n",
      "loss 2.308727, train acc 0.101492\n",
      "round 334\n",
      "time to device 0.003584 sec\n",
      "time forward 4.431330 sec\n",
      "loss time 0.000633 sec\n",
      "backward time 0.005692 sec\n",
      "optimizer time 0.015387 sec\n",
      "training time in round 334 cost 0.36371684074401855 sec\n",
      "loss 2.308727, train acc 0.101399\n",
      "round 335\n",
      "time to device 0.004394 sec\n",
      "time forward 4.443926 sec\n",
      "loss time 0.001234 sec\n",
      "backward time 0.011831 sec\n",
      "optimizer time 0.026678 sec\n",
      "training time in round 335 cost 0.38825511932373047 sec\n",
      "loss 2.308720, train acc 0.101376\n",
      "round 336\n",
      "time to device 0.003734 sec\n",
      "time forward 4.456836 sec\n",
      "loss time 0.001831 sec\n",
      "backward time 0.014049 sec\n",
      "optimizer time 0.024767 sec\n",
      "training time in round 336 cost 0.39556002616882324 sec\n",
      "loss 2.308710, train acc 0.101307\n",
      "round 337\n",
      "time to device 0.003910 sec\n",
      "time forward 4.471844 sec\n",
      "loss time 0.001574 sec\n",
      "backward time 0.010955 sec\n",
      "optimizer time 0.022379 sec\n",
      "training time in round 337 cost 0.39650487899780273 sec\n",
      "loss 2.308699, train acc 0.101308\n",
      "round 338\n",
      "time to device 0.004344 sec\n",
      "time forward 4.484722 sec\n",
      "loss time 0.001396 sec\n",
      "backward time 0.016381 sec\n",
      "optimizer time 0.024677 sec\n",
      "training time in round 338 cost 0.39124608039855957 sec\n",
      "loss 2.308801, train acc 0.101309\n",
      "round 339\n",
      "time to device 0.003880 sec\n",
      "time forward 4.497727 sec\n",
      "loss time 0.001916 sec\n",
      "backward time 0.016548 sec\n",
      "optimizer time 0.026166 sec\n",
      "training time in round 339 cost 0.40128087997436523 sec\n",
      "loss 2.308788, train acc 0.101333\n",
      "round 340\n",
      "time to device 0.003512 sec\n",
      "time forward 4.508983 sec\n",
      "loss time 0.001879 sec\n",
      "backward time 0.013213 sec\n",
      "optimizer time 0.025831 sec\n",
      "training time in round 340 cost 0.3842132091522217 sec\n",
      "loss 2.308771, train acc 0.101333\n",
      "round 341\n",
      "time to device 0.005285 sec\n",
      "time forward 4.522478 sec\n",
      "loss time 0.001561 sec\n",
      "backward time 0.012667 sec\n",
      "optimizer time 0.021768 sec\n",
      "training time in round 341 cost 0.39441823959350586 sec\n",
      "loss 2.308751, train acc 0.101380\n",
      "round 342\n",
      "time to device 0.003783 sec\n",
      "time forward 4.534727 sec\n",
      "loss time 0.001896 sec\n",
      "backward time 0.017521 sec\n",
      "optimizer time 0.022465 sec\n",
      "training time in round 342 cost 0.39551377296447754 sec\n",
      "loss 2.308730, train acc 0.101426\n",
      "round 343\n",
      "time to device 0.003767 sec\n",
      "time forward 4.546976 sec\n",
      "loss time 0.001767 sec\n",
      "backward time 0.012160 sec\n",
      "optimizer time 0.025216 sec\n",
      "training time in round 343 cost 0.40227198600769043 sec\n",
      "loss 2.308712, train acc 0.101426\n",
      "round 344\n",
      "time to device 0.004702 sec\n",
      "time forward 4.561265 sec\n",
      "loss time 0.002056 sec\n",
      "backward time 0.013752 sec\n",
      "optimizer time 0.024841 sec\n",
      "training time in round 344 cost 0.39201998710632324 sec\n",
      "loss 2.308695, train acc 0.101608\n",
      "round 345\n",
      "time to device 0.003410 sec\n",
      "time forward 4.576025 sec\n",
      "loss time 0.001603 sec\n",
      "backward time 0.012120 sec\n",
      "optimizer time 0.023657 sec\n",
      "training time in round 345 cost 0.39142298698425293 sec\n",
      "loss 2.308683, train acc 0.101540\n",
      "round 346\n",
      "time to device 0.004242 sec\n",
      "time forward 4.590474 sec\n",
      "loss time 0.001945 sec\n",
      "backward time 0.016122 sec\n",
      "optimizer time 0.027078 sec\n",
      "training time in round 346 cost 0.40007781982421875 sec\n",
      "loss 2.308668, train acc 0.101540\n",
      "round 347\n",
      "time to device 0.004147 sec\n",
      "time forward 4.602919 sec\n",
      "loss time 0.001832 sec\n",
      "backward time 0.018551 sec\n",
      "optimizer time 0.022809 sec\n",
      "training time in round 347 cost 0.3910098075866699 sec\n",
      "loss 2.308653, train acc 0.101585\n",
      "round 348\n",
      "time to device 0.003616 sec\n",
      "time forward 4.616088 sec\n",
      "loss time 0.001269 sec\n",
      "backward time 0.011458 sec\n",
      "optimizer time 0.022599 sec\n",
      "training time in round 348 cost 0.40188002586364746 sec\n",
      "loss 2.308642, train acc 0.101451\n",
      "round 349\n",
      "time to device 0.003705 sec\n",
      "time forward 4.630194 sec\n",
      "loss time 0.002219 sec\n",
      "backward time 0.013867 sec\n",
      "optimizer time 0.023610 sec\n",
      "training time in round 349 cost 0.3928649425506592 sec\n",
      "loss 2.308618, train acc 0.101496\n",
      "round 350\n",
      "time to device 0.003560 sec\n",
      "time forward 4.641640 sec\n",
      "loss time 0.000578 sec\n",
      "backward time 0.005640 sec\n",
      "optimizer time 0.024474 sec\n",
      "training time in round 350 cost 0.4165689945220947 sec\n",
      "loss 2.308605, train acc 0.101362\n",
      "round 351\n",
      "time to device 0.005236 sec\n",
      "time forward 4.653816 sec\n",
      "loss time 0.001573 sec\n",
      "backward time 0.015676 sec\n",
      "optimizer time 0.026999 sec\n",
      "training time in round 351 cost 0.38721680641174316 sec\n",
      "loss 2.308582, train acc 0.101452\n",
      "round 352\n",
      "time to device 0.004908 sec\n",
      "time forward 4.667533 sec\n",
      "loss time 0.001596 sec\n",
      "backward time 0.014853 sec\n",
      "optimizer time 0.024535 sec\n",
      "training time in round 352 cost 0.3929469585418701 sec\n",
      "loss 2.308551, train acc 0.101496\n",
      "round 353\n",
      "time to device 0.003995 sec\n",
      "time forward 4.681359 sec\n",
      "loss time 0.002012 sec\n",
      "backward time 0.013302 sec\n",
      "optimizer time 0.025906 sec\n",
      "training time in round 353 cost 0.39551711082458496 sec\n",
      "loss 2.308537, train acc 0.101342\n",
      "round 354\n",
      "time to device 0.011528 sec\n",
      "time forward 4.688193 sec\n",
      "loss time 0.000558 sec\n",
      "backward time 0.005234 sec\n",
      "optimizer time 0.014207 sec\n",
      "training time in round 354 cost 0.3491051197052002 sec\n",
      "loss 2.308932, train acc 0.101232\n",
      "round 355\n",
      "time to device 0.003496 sec\n",
      "time forward 4.706475 sec\n",
      "loss time 0.001421 sec\n",
      "backward time 0.013178 sec\n",
      "optimizer time 0.023374 sec\n",
      "training time in round 355 cost 0.4037020206451416 sec\n",
      "loss 2.308910, train acc 0.101211\n",
      "round 356\n",
      "time to device 0.003118 sec\n",
      "time forward 4.719034 sec\n",
      "loss time 0.001436 sec\n",
      "backward time 0.012370 sec\n",
      "optimizer time 0.023976 sec\n",
      "training time in round 356 cost 0.38324522972106934 sec\n",
      "loss 2.308890, train acc 0.101169\n",
      "round 357\n",
      "time to device 0.004282 sec\n",
      "time forward 4.730072 sec\n",
      "loss time 0.001107 sec\n",
      "backward time 0.012441 sec\n",
      "optimizer time 0.025874 sec\n",
      "training time in round 357 cost 0.3782501220703125 sec\n",
      "loss 2.308878, train acc 0.101322\n",
      "round 358\n",
      "time to device 0.003135 sec\n",
      "time forward 4.741806 sec\n",
      "loss time 0.001149 sec\n",
      "backward time 0.012983 sec\n",
      "optimizer time 0.024670 sec\n",
      "training time in round 358 cost 0.3778820037841797 sec\n",
      "loss 2.308860, train acc 0.101367\n",
      "round 359\n",
      "time to device 0.003549 sec\n",
      "time forward 4.755610 sec\n",
      "loss time 0.001974 sec\n",
      "backward time 0.016881 sec\n",
      "optimizer time 0.026493 sec\n",
      "training time in round 359 cost 0.39583516120910645 sec\n",
      "loss 2.308844, train acc 0.101389\n",
      "round 360\n",
      "time to device 0.004214 sec\n",
      "time forward 4.767846 sec\n",
      "loss time 0.001258 sec\n",
      "backward time 0.014007 sec\n",
      "optimizer time 0.024300 sec\n",
      "training time in round 360 cost 0.38343024253845215 sec\n",
      "loss 2.308817, train acc 0.101389\n",
      "round 361\n",
      "time to device 0.003367 sec\n",
      "time forward 4.781768 sec\n",
      "loss time 0.001951 sec\n",
      "backward time 0.014887 sec\n",
      "optimizer time 0.024742 sec\n",
      "training time in round 361 cost 0.39344072341918945 sec\n",
      "loss 2.308823, train acc 0.101390\n",
      "round 362\n",
      "time to device 0.003570 sec\n",
      "time forward 4.794825 sec\n",
      "loss time 0.001251 sec\n",
      "backward time 0.009815 sec\n",
      "optimizer time 0.020667 sec\n",
      "training time in round 362 cost 0.3811969757080078 sec\n",
      "loss 2.308811, train acc 0.101455\n",
      "round 363\n",
      "time to device 0.003460 sec\n",
      "time forward 4.807022 sec\n",
      "loss time 0.001490 sec\n",
      "backward time 0.012071 sec\n",
      "optimizer time 0.027780 sec\n",
      "training time in round 363 cost 0.38694024085998535 sec\n",
      "loss 2.308778, train acc 0.101434\n",
      "round 364\n",
      "time to device 0.003633 sec\n",
      "time forward 4.821108 sec\n",
      "loss time 0.001420 sec\n",
      "backward time 0.012638 sec\n",
      "optimizer time 0.023538 sec\n",
      "training time in round 364 cost 0.3862447738647461 sec\n",
      "loss 2.308774, train acc 0.101370\n",
      "round 365\n",
      "time to device 0.003866 sec\n",
      "time forward 4.835361 sec\n",
      "loss time 0.001932 sec\n",
      "backward time 0.015495 sec\n",
      "optimizer time 0.023893 sec\n",
      "training time in round 365 cost 0.39565324783325195 sec\n",
      "loss 2.308769, train acc 0.101392\n",
      "round 366\n",
      "time to device 0.004484 sec\n",
      "time forward 4.846993 sec\n",
      "loss time 0.001848 sec\n",
      "backward time 0.013665 sec\n",
      "optimizer time 0.022047 sec\n",
      "training time in round 366 cost 0.3820230960845947 sec\n",
      "loss 2.308787, train acc 0.101435\n",
      "round 367\n",
      "time to device 0.003943 sec\n",
      "time forward 4.861514 sec\n",
      "loss time 0.001821 sec\n",
      "backward time 0.012382 sec\n",
      "optimizer time 0.023554 sec\n",
      "training time in round 367 cost 0.3879508972167969 sec\n",
      "loss 2.308770, train acc 0.101435\n",
      "round 368\n",
      "time to device 0.003504 sec\n",
      "time forward 4.875083 sec\n",
      "loss time 0.001450 sec\n",
      "backward time 0.012795 sec\n",
      "optimizer time 0.023174 sec\n",
      "training time in round 368 cost 0.38577890396118164 sec\n",
      "loss 2.308746, train acc 0.101351\n",
      "round 369\n",
      "time to device 0.004045 sec\n",
      "time forward 4.888073 sec\n",
      "loss time 0.001953 sec\n",
      "backward time 0.013961 sec\n",
      "optimizer time 0.023059 sec\n",
      "training time in round 369 cost 0.3861677646636963 sec\n",
      "loss 2.308734, train acc 0.101457\n",
      "round 370\n",
      "time to device 0.004402 sec\n",
      "time forward 4.899378 sec\n",
      "loss time 0.001828 sec\n",
      "backward time 0.014013 sec\n",
      "optimizer time 0.020295 sec\n",
      "training time in round 370 cost 0.3821749687194824 sec\n",
      "loss 2.308731, train acc 0.101436\n",
      "round 371\n",
      "time to device 0.003840 sec\n",
      "time forward 4.913457 sec\n",
      "loss time 0.001509 sec\n",
      "backward time 0.012338 sec\n",
      "optimizer time 0.022010 sec\n",
      "training time in round 371 cost 0.3877558708190918 sec\n",
      "loss 2.308723, train acc 0.101415\n",
      "round 372\n",
      "time to device 0.003883 sec\n",
      "time forward 4.926611 sec\n",
      "loss time 0.000558 sec\n",
      "backward time 0.005532 sec\n",
      "optimizer time 0.013487 sec\n",
      "training time in round 372 cost 0.46391773223876953 sec\n",
      "loss 2.308709, train acc 0.101332\n",
      "round 373\n",
      "time to device 0.008267 sec\n",
      "time forward 4.941292 sec\n",
      "loss time 0.001230 sec\n",
      "backward time 0.012005 sec\n",
      "optimizer time 0.038720 sec\n",
      "training time in round 373 cost 0.44624996185302734 sec\n",
      "loss 2.308699, train acc 0.101291\n",
      "round 374\n",
      "time to device 0.006765 sec\n",
      "time forward 4.953691 sec\n",
      "loss time 0.001279 sec\n",
      "backward time 0.015214 sec\n",
      "optimizer time 0.026048 sec\n",
      "training time in round 374 cost 0.4094269275665283 sec\n",
      "loss 2.308686, train acc 0.101312\n",
      "round 375\n",
      "time to device 0.009760 sec\n",
      "time forward 4.965681 sec\n",
      "loss time 0.001373 sec\n",
      "backward time 0.015900 sec\n",
      "optimizer time 0.026291 sec\n",
      "training time in round 375 cost 0.4083240032196045 sec\n",
      "loss 2.308659, train acc 0.101355\n",
      "round 376\n",
      "time to device 0.007892 sec\n",
      "time forward 4.977961 sec\n",
      "loss time 0.001596 sec\n",
      "backward time 0.015437 sec\n",
      "optimizer time 0.025387 sec\n",
      "training time in round 376 cost 0.4195859432220459 sec\n",
      "loss 2.308643, train acc 0.101438\n",
      "round 377\n",
      "time to device 0.010056 sec\n",
      "time forward 4.987745 sec\n",
      "loss time 0.000496 sec\n",
      "backward time 0.004526 sec\n",
      "optimizer time 0.012909 sec\n",
      "training time in round 377 cost 0.37006211280822754 sec\n",
      "loss 2.309066, train acc 0.101397\n",
      "round 378\n",
      "time to device 0.006830 sec\n",
      "time forward 5.001436 sec\n",
      "loss time 0.001978 sec\n",
      "backward time 0.015701 sec\n",
      "optimizer time 0.026372 sec\n",
      "training time in round 378 cost 0.40335988998413086 sec\n",
      "loss 2.309047, train acc 0.101480\n",
      "round 379\n",
      "time to device 0.008634 sec\n",
      "time forward 5.015184 sec\n",
      "loss time 0.001149 sec\n",
      "backward time 0.011321 sec\n",
      "optimizer time 0.024741 sec\n",
      "training time in round 379 cost 0.3916480541229248 sec\n",
      "loss 2.309045, train acc 0.101336\n",
      "round 380\n",
      "time to device 0.009676 sec\n",
      "time forward 5.028039 sec\n",
      "loss time 0.000994 sec\n",
      "backward time 0.012515 sec\n",
      "optimizer time 0.027491 sec\n",
      "training time in round 380 cost 0.39346909523010254 sec\n",
      "loss 2.309028, train acc 0.101337\n",
      "round 381\n",
      "time to device 0.009222 sec\n",
      "time forward 5.043816 sec\n",
      "loss time 0.001493 sec\n",
      "backward time 0.013817 sec\n",
      "optimizer time 0.024626 sec\n",
      "training time in round 381 cost 0.4051549434661865 sec\n",
      "loss 2.309044, train acc 0.101174\n",
      "round 382\n",
      "time to device 0.007557 sec\n",
      "time forward 5.049420 sec\n",
      "loss time 0.000543 sec\n",
      "backward time 0.005154 sec\n",
      "optimizer time 0.014490 sec\n",
      "training time in round 382 cost 0.36093783378601074 sec\n",
      "loss 2.309031, train acc 0.101053\n",
      "round 383\n",
      "time to device 0.009299 sec\n",
      "time forward 5.062929 sec\n",
      "loss time 0.001244 sec\n",
      "backward time 0.014212 sec\n",
      "optimizer time 0.024636 sec\n",
      "training time in round 383 cost 0.3937058448791504 sec\n",
      "loss 2.309015, train acc 0.100952\n",
      "round 384\n",
      "time to device 0.007870 sec\n",
      "time forward 5.080490 sec\n",
      "loss time 0.001456 sec\n",
      "backward time 0.011112 sec\n",
      "optimizer time 0.010903 sec\n",
      "training time in round 384 cost 0.3870980739593506 sec\n",
      "loss 2.308997, train acc 0.101055\n",
      "round 385\n",
      "time to device 0.007573 sec\n",
      "time forward 5.094254 sec\n",
      "loss time 0.001917 sec\n",
      "backward time 0.014892 sec\n",
      "optimizer time 0.026257 sec\n",
      "training time in round 385 cost 0.3981771469116211 sec\n",
      "loss 2.308978, train acc 0.101036\n",
      "round 386\n",
      "time to device 0.010213 sec\n",
      "time forward 5.105528 sec\n",
      "loss time 0.001904 sec\n",
      "backward time 0.014634 sec\n",
      "optimizer time 0.025879 sec\n",
      "training time in round 386 cost 0.400285005569458 sec\n",
      "loss 2.308960, train acc 0.101078\n",
      "round 387\n",
      "time to device 0.008122 sec\n",
      "time forward 5.119674 sec\n",
      "loss time 0.001775 sec\n",
      "backward time 0.016002 sec\n",
      "optimizer time 0.025983 sec\n",
      "training time in round 387 cost 0.40105104446411133 sec\n",
      "loss 2.308942, train acc 0.101099\n",
      "round 388\n",
      "time to device 0.008854 sec\n",
      "time forward 5.131796 sec\n",
      "loss time 0.001189 sec\n",
      "backward time 0.014118 sec\n",
      "optimizer time 0.023713 sec\n",
      "training time in round 388 cost 0.4059610366821289 sec\n",
      "loss 2.308916, train acc 0.101161\n",
      "round 389\n",
      "time to device 0.009037 sec\n",
      "time forward 5.145111 sec\n",
      "loss time 0.001843 sec\n",
      "backward time 0.014894 sec\n",
      "optimizer time 0.025676 sec\n",
      "training time in round 389 cost 0.39761900901794434 sec\n",
      "loss 2.308903, train acc 0.101182\n",
      "round 390\n",
      "time to device 0.008272 sec\n",
      "time forward 5.157678 sec\n",
      "loss time 0.001724 sec\n",
      "backward time 0.013812 sec\n",
      "optimizer time 0.026672 sec\n",
      "training time in round 390 cost 0.39289116859436035 sec\n",
      "loss 2.309161, train acc 0.101203\n",
      "round 391\n",
      "time to device 0.010190 sec\n",
      "time forward 5.169847 sec\n",
      "loss time 0.001468 sec\n",
      "backward time 0.022032 sec\n",
      "optimizer time 0.022192 sec\n",
      "training time in round 391 cost 0.3930511474609375 sec\n",
      "loss 2.309130, train acc 0.101343\n",
      "round 392\n",
      "time to device 0.009084 sec\n",
      "time forward 5.182606 sec\n",
      "loss time 0.001692 sec\n",
      "backward time 0.010940 sec\n",
      "optimizer time 0.026188 sec\n",
      "training time in round 392 cost 0.40938305854797363 sec\n",
      "loss 2.309112, train acc 0.101503\n",
      "round 393\n",
      "time to device 0.009358 sec\n",
      "time forward 5.195947 sec\n",
      "loss time 0.001320 sec\n",
      "backward time 0.017278 sec\n",
      "optimizer time 0.025848 sec\n",
      "training time in round 393 cost 0.4037168025970459 sec\n",
      "loss 2.309099, train acc 0.101444\n",
      "round 394\n",
      "time to device 0.010092 sec\n",
      "time forward 5.211182 sec\n",
      "loss time 0.001122 sec\n",
      "backward time 0.016461 sec\n",
      "optimizer time 0.020113 sec\n",
      "training time in round 394 cost 0.40158820152282715 sec\n",
      "loss 2.309142, train acc 0.101365\n",
      "round 395\n",
      "time to device 0.010299 sec\n",
      "time forward 5.225626 sec\n",
      "loss time 0.001216 sec\n",
      "backward time 0.011231 sec\n",
      "optimizer time 0.021335 sec\n",
      "training time in round 395 cost 0.42236900329589844 sec\n",
      "loss 2.309115, train acc 0.101365\n",
      "round 396\n",
      "time to device 0.009925 sec\n",
      "time forward 5.239770 sec\n",
      "loss time 0.001473 sec\n",
      "backward time 0.018888 sec\n",
      "optimizer time 0.023538 sec\n",
      "training time in round 396 cost 0.40424084663391113 sec\n",
      "loss 2.309111, train acc 0.101287\n",
      "round 397\n",
      "time to device 0.008343 sec\n",
      "time forward 5.260824 sec\n",
      "loss time 0.001883 sec\n",
      "backward time 0.013494 sec\n",
      "optimizer time 0.023588 sec\n",
      "training time in round 397 cost 0.4016292095184326 sec\n",
      "loss 2.309078, train acc 0.101405\n",
      "round 398\n",
      "time to device 0.008957 sec\n",
      "time forward 5.274618 sec\n",
      "loss time 0.001254 sec\n",
      "backward time 0.014425 sec\n",
      "optimizer time 0.024996 sec\n",
      "training time in round 398 cost 0.39542388916015625 sec\n",
      "loss 2.309071, train acc 0.101386\n",
      "round 399\n",
      "time to device 0.009667 sec\n",
      "time forward 5.287694 sec\n",
      "loss time 0.001704 sec\n",
      "backward time 0.013690 sec\n",
      "optimizer time 0.023492 sec\n",
      "training time in round 399 cost 0.39167189598083496 sec\n",
      "loss 2.309248, train acc 0.101387\n",
      "round 400\n",
      "time to device 0.009341 sec\n",
      "time forward 5.299512 sec\n",
      "loss time 0.001066 sec\n",
      "backward time 0.011312 sec\n",
      "optimizer time 0.024064 sec\n",
      "training time in round 400 cost 0.40000486373901367 sec\n",
      "loss 2.309233, train acc 0.101348\n",
      "round 401\n",
      "time to device 0.003435 sec\n",
      "time forward 5.313544 sec\n",
      "loss time 0.001960 sec\n",
      "backward time 0.013069 sec\n",
      "optimizer time 0.023618 sec\n",
      "training time in round 401 cost 0.38893795013427734 sec\n",
      "loss 2.309208, train acc 0.101426\n",
      "round 402\n",
      "time to device 0.003833 sec\n",
      "time forward 5.320576 sec\n",
      "loss time 0.000552 sec\n",
      "backward time 0.005088 sec\n",
      "optimizer time 0.013782 sec\n",
      "training time in round 402 cost 0.350247859954834 sec\n",
      "loss 2.309198, train acc 0.101388\n",
      "round 403\n",
      "time to device 0.003721 sec\n",
      "time forward 5.335851 sec\n",
      "loss time 0.003778 sec\n",
      "backward time 0.014972 sec\n",
      "optimizer time 0.025593 sec\n",
      "training time in round 403 cost 0.4007999897003174 sec\n",
      "loss 2.309197, train acc 0.101485\n",
      "round 404\n",
      "time to device 0.004078 sec\n",
      "time forward 5.350591 sec\n",
      "loss time 0.001804 sec\n",
      "backward time 0.013505 sec\n",
      "optimizer time 0.022865 sec\n",
      "training time in round 404 cost 0.39641880989074707 sec\n",
      "loss 2.309173, train acc 0.101543\n",
      "round 405\n",
      "time to device 0.003864 sec\n",
      "time forward 5.374116 sec\n",
      "loss time 0.001638 sec\n",
      "backward time 0.011011 sec\n",
      "optimizer time 0.021794 sec\n",
      "training time in round 405 cost 0.41031384468078613 sec\n",
      "loss 2.309134, train acc 0.101639\n",
      "round 406\n",
      "time to device 0.003846 sec\n",
      "time forward 5.388177 sec\n",
      "loss time 0.001992 sec\n",
      "backward time 0.014729 sec\n",
      "optimizer time 0.023586 sec\n",
      "training time in round 406 cost 0.3932027816772461 sec\n",
      "loss 2.309112, train acc 0.101754\n",
      "round 407\n",
      "time to device 0.004692 sec\n",
      "time forward 5.402905 sec\n",
      "loss time 0.001188 sec\n",
      "backward time 0.015493 sec\n",
      "optimizer time 0.024997 sec\n",
      "training time in round 407 cost 0.40238380432128906 sec\n",
      "loss 2.309108, train acc 0.101754\n",
      "round 408\n",
      "time to device 0.003886 sec\n",
      "time forward 5.415184 sec\n",
      "loss time 0.002127 sec\n",
      "backward time 0.017326 sec\n",
      "optimizer time 0.024951 sec\n",
      "training time in round 408 cost 0.3930051326751709 sec\n",
      "loss 2.309135, train acc 0.101945\n",
      "round 409\n",
      "time to device 0.004519 sec\n",
      "time forward 5.432395 sec\n",
      "loss time 0.001042 sec\n",
      "backward time 0.012977 sec\n",
      "optimizer time 0.024124 sec\n",
      "training time in round 409 cost 0.40215420722961426 sec\n",
      "loss 2.309115, train acc 0.102001\n",
      "round 410\n",
      "time to device 0.003525 sec\n",
      "time forward 5.445626 sec\n",
      "loss time 0.001785 sec\n",
      "backward time 0.014459 sec\n",
      "optimizer time 0.022763 sec\n",
      "training time in round 410 cost 0.3878350257873535 sec\n",
      "loss 2.309091, train acc 0.102095\n",
      "round 411\n",
      "time to device 0.004109 sec\n",
      "time forward 5.459871 sec\n",
      "loss time 0.001402 sec\n",
      "backward time 0.012746 sec\n",
      "optimizer time 0.022127 sec\n",
      "training time in round 411 cost 0.39003419876098633 sec\n",
      "loss 2.309077, train acc 0.101980\n",
      "round 412\n",
      "time to device 0.004563 sec\n",
      "time forward 5.474628 sec\n",
      "loss time 0.001497 sec\n",
      "backward time 0.011264 sec\n",
      "optimizer time 0.022476 sec\n",
      "training time in round 412 cost 0.3921349048614502 sec\n",
      "loss 2.309065, train acc 0.101941\n",
      "round 413\n",
      "time to device 0.003405 sec\n",
      "time forward 5.490057 sec\n",
      "loss time 0.001991 sec\n",
      "backward time 0.014645 sec\n",
      "optimizer time 0.027218 sec\n",
      "training time in round 413 cost 0.4025239944458008 sec\n",
      "loss 2.309049, train acc 0.101921\n",
      "round 414\n",
      "time to device 0.003674 sec\n",
      "time forward 5.503463 sec\n",
      "loss time 0.001573 sec\n",
      "backward time 0.011695 sec\n",
      "optimizer time 0.023963 sec\n",
      "training time in round 414 cost 0.38304996490478516 sec\n",
      "loss 2.309013, train acc 0.101995\n",
      "round 415\n",
      "time to device 0.003676 sec\n",
      "time forward 5.516199 sec\n",
      "loss time 0.001827 sec\n",
      "backward time 0.013588 sec\n",
      "optimizer time 0.023667 sec\n",
      "training time in round 415 cost 0.3884460926055908 sec\n",
      "loss 2.309005, train acc 0.101976\n",
      "round 416\n",
      "time to device 0.003424 sec\n",
      "time forward 5.529747 sec\n",
      "loss time 0.001087 sec\n",
      "backward time 0.010432 sec\n",
      "optimizer time 0.021724 sec\n",
      "training time in round 416 cost 0.3833498954772949 sec\n",
      "loss 2.308998, train acc 0.101956\n",
      "round 417\n",
      "time to device 0.003058 sec\n",
      "time forward 5.542428 sec\n",
      "loss time 0.001403 sec\n",
      "backward time 0.012288 sec\n",
      "optimizer time 0.022007 sec\n",
      "training time in round 417 cost 0.380756139755249 sec\n",
      "loss 2.308982, train acc 0.101992\n",
      "round 418\n",
      "time to device 0.003832 sec\n",
      "time forward 5.554082 sec\n",
      "loss time 0.001677 sec\n",
      "backward time 0.014689 sec\n",
      "optimizer time 0.017125 sec\n",
      "training time in round 418 cost 0.37995195388793945 sec\n",
      "loss 2.308948, train acc 0.102159\n",
      "round 419\n",
      "time to device 0.004062 sec\n",
      "time forward 5.566341 sec\n",
      "loss time 0.001507 sec\n",
      "backward time 0.013074 sec\n",
      "optimizer time 0.024234 sec\n",
      "training time in round 419 cost 0.3817121982574463 sec\n",
      "loss 2.308929, train acc 0.102176\n",
      "round 420\n",
      "time to device 0.002806 sec\n",
      "time forward 5.574094 sec\n",
      "loss time 0.000876 sec\n",
      "backward time 0.007210 sec\n",
      "optimizer time 0.017578 sec\n",
      "training time in round 420 cost 0.3474161624908447 sec\n",
      "loss 2.308911, train acc 0.102212\n",
      "round 421\n",
      "time to device 0.004171 sec\n",
      "time forward 5.588475 sec\n",
      "loss time 0.001720 sec\n",
      "backward time 0.015765 sec\n",
      "optimizer time 0.025398 sec\n",
      "training time in round 421 cost 0.3970003128051758 sec\n",
      "loss 2.308891, train acc 0.102285\n",
      "round 422\n",
      "time to device 0.003063 sec\n",
      "time forward 5.598956 sec\n",
      "loss time 0.001076 sec\n",
      "backward time 0.008135 sec\n",
      "optimizer time 0.018915 sec\n",
      "training time in round 422 cost 0.3634810447692871 sec\n",
      "loss 2.308881, train acc 0.102246\n",
      "round 423\n",
      "time to device 0.003168 sec\n",
      "time forward 5.605644 sec\n",
      "loss time 0.000565 sec\n",
      "backward time 0.005135 sec\n",
      "optimizer time 0.013851 sec\n",
      "training time in round 423 cost 0.3407740592956543 sec\n",
      "loss 2.308863, train acc 0.102263\n",
      "round 424\n",
      "time to device 0.003913 sec\n",
      "time forward 5.618919 sec\n",
      "loss time 0.001050 sec\n",
      "backward time 0.013051 sec\n",
      "optimizer time 0.026345 sec\n",
      "training time in round 424 cost 0.39087796211242676 sec\n",
      "loss 2.308841, train acc 0.102298\n",
      "round 425\n",
      "time to device 0.004562 sec\n",
      "time forward 5.624835 sec\n",
      "loss time 0.000368 sec\n",
      "backward time 0.006548 sec\n",
      "optimizer time 0.010701 sec\n",
      "training time in round 425 cost 0.32816314697265625 sec\n",
      "loss 2.309192, train acc 0.102259\n",
      "round 426\n",
      "time to device 0.003421 sec\n",
      "time forward 5.640471 sec\n",
      "loss time 0.001240 sec\n",
      "backward time 0.010769 sec\n",
      "optimizer time 0.024238 sec\n",
      "training time in round 426 cost 0.4416239261627197 sec\n",
      "loss 2.309195, train acc 0.102221\n",
      "round 427\n",
      "time to device 0.004024 sec\n",
      "time forward 5.653257 sec\n",
      "loss time 0.001455 sec\n",
      "backward time 0.015516 sec\n",
      "optimizer time 0.026092 sec\n",
      "training time in round 427 cost 0.38730311393737793 sec\n",
      "loss 2.309191, train acc 0.102165\n",
      "round 428\n",
      "time to device 0.014035 sec\n",
      "time forward 5.660296 sec\n",
      "loss time 0.000566 sec\n",
      "backward time 0.005047 sec\n",
      "optimizer time 0.013096 sec\n",
      "training time in round 428 cost 0.3536410331726074 sec\n",
      "loss 2.309277, train acc 0.102145\n",
      "round 429\n",
      "time to device 0.003199 sec\n",
      "time forward 5.674448 sec\n",
      "loss time 0.001839 sec\n",
      "backward time 0.013684 sec\n",
      "optimizer time 0.023968 sec\n",
      "training time in round 429 cost 0.39112305641174316 sec\n",
      "loss 2.309276, train acc 0.102035\n",
      "round 430\n",
      "time to device 0.003558 sec\n",
      "time forward 5.687663 sec\n",
      "loss time 0.001486 sec\n",
      "backward time 0.014773 sec\n",
      "optimizer time 0.025182 sec\n",
      "training time in round 430 cost 0.39095497131347656 sec\n",
      "loss 2.309276, train acc 0.101961\n",
      "round 431\n",
      "time to device 0.004166 sec\n",
      "time forward 5.705563 sec\n",
      "loss time 0.001540 sec\n",
      "backward time 0.014736 sec\n",
      "optimizer time 0.023884 sec\n",
      "training time in round 431 cost 0.40807318687438965 sec\n",
      "loss 2.309277, train acc 0.101870\n",
      "round 432\n",
      "time to device 0.003626 sec\n",
      "time forward 5.720134 sec\n",
      "loss time 0.001635 sec\n",
      "backward time 0.015798 sec\n",
      "optimizer time 0.025859 sec\n",
      "training time in round 432 cost 0.4006342887878418 sec\n",
      "loss 2.309259, train acc 0.101887\n",
      "round 433\n",
      "time to device 0.003969 sec\n",
      "time forward 5.729330 sec\n",
      "loss time 0.000640 sec\n",
      "backward time 0.005786 sec\n",
      "optimizer time 0.015257 sec\n",
      "training time in round 433 cost 0.3466501235961914 sec\n",
      "loss 2.309232, train acc 0.102049\n",
      "round 434\n",
      "time to device 0.003795 sec\n",
      "time forward 5.741314 sec\n",
      "loss time 0.001547 sec\n",
      "backward time 0.014818 sec\n",
      "optimizer time 0.024266 sec\n",
      "training time in round 434 cost 0.38048887252807617 sec\n",
      "loss 2.309213, train acc 0.102083\n",
      "round 435\n",
      "time to device 0.003523 sec\n",
      "time forward 5.750677 sec\n",
      "loss time 0.001478 sec\n",
      "backward time 0.011212 sec\n",
      "optimizer time 0.023674 sec\n",
      "training time in round 435 cost 0.35909295082092285 sec\n",
      "loss 2.309196, train acc 0.102118\n",
      "round 436\n",
      "time to device 0.003659 sec\n",
      "time forward 5.763915 sec\n",
      "loss time 0.001393 sec\n",
      "backward time 0.011889 sec\n",
      "optimizer time 0.025390 sec\n",
      "training time in round 436 cost 0.3859741687774658 sec\n",
      "loss 2.309188, train acc 0.102063\n",
      "round 437\n",
      "time to device 0.004067 sec\n",
      "time forward 5.777002 sec\n",
      "loss time 0.001447 sec\n",
      "backward time 0.011889 sec\n",
      "optimizer time 0.023195 sec\n",
      "training time in round 437 cost 0.3791921138763428 sec\n",
      "loss 2.309146, train acc 0.102062\n",
      "round 438\n",
      "time to device 0.003881 sec\n",
      "time forward 5.791317 sec\n",
      "loss time 0.002166 sec\n",
      "backward time 0.013449 sec\n",
      "optimizer time 0.025283 sec\n",
      "training time in round 438 cost 0.39554810523986816 sec\n",
      "loss 2.309732, train acc 0.102025\n",
      "round 439\n",
      "time to device 0.002935 sec\n",
      "time forward 5.798898 sec\n",
      "loss time 0.000558 sec\n",
      "backward time 0.005086 sec\n",
      "optimizer time 0.013829 sec\n",
      "training time in round 439 cost 0.34998393058776855 sec\n",
      "loss 2.309719, train acc 0.102024\n",
      "round 440\n",
      "time to device 0.004934 sec\n",
      "time forward 5.811334 sec\n",
      "loss time 0.000834 sec\n",
      "backward time 0.006748 sec\n",
      "optimizer time 0.018031 sec\n",
      "training time in round 440 cost 0.3716301918029785 sec\n",
      "loss 2.309716, train acc 0.101899\n",
      "round 441\n",
      "time to device 0.004559 sec\n",
      "time forward 5.825813 sec\n",
      "loss time 0.001115 sec\n",
      "backward time 0.013339 sec\n",
      "optimizer time 0.029257 sec\n",
      "training time in round 441 cost 0.3971681594848633 sec\n",
      "loss 2.309695, train acc 0.101987\n",
      "round 442\n",
      "time to device 0.003256 sec\n",
      "time forward 5.840530 sec\n",
      "loss time 0.001027 sec\n",
      "backward time 0.011015 sec\n",
      "optimizer time 0.027828 sec\n",
      "training time in round 442 cost 0.3941221237182617 sec\n",
      "loss 2.309801, train acc 0.101898\n",
      "round 443\n",
      "time to device 0.004137 sec\n",
      "time forward 5.854551 sec\n",
      "loss time 0.001864 sec\n",
      "backward time 0.014947 sec\n",
      "optimizer time 0.025658 sec\n",
      "training time in round 443 cost 0.3944430351257324 sec\n",
      "loss 2.309789, train acc 0.101950\n",
      "round 444\n",
      "time to device 0.003138 sec\n",
      "time forward 5.867852 sec\n",
      "loss time 0.001898 sec\n",
      "backward time 0.017330 sec\n",
      "optimizer time 0.027093 sec\n",
      "training time in round 444 cost 0.3946800231933594 sec\n",
      "loss 2.309774, train acc 0.101914\n",
      "round 445\n",
      "time to device 0.004736 sec\n",
      "time forward 5.880032 sec\n",
      "loss time 0.001866 sec\n",
      "backward time 0.012997 sec\n",
      "optimizer time 0.025080 sec\n",
      "training time in round 445 cost 0.3874669075012207 sec\n",
      "loss 2.309758, train acc 0.101878\n",
      "round 446\n",
      "time to device 0.003889 sec\n",
      "time forward 5.893494 sec\n",
      "loss time 0.002031 sec\n",
      "backward time 0.012238 sec\n",
      "optimizer time 0.024304 sec\n",
      "training time in round 446 cost 0.3920891284942627 sec\n",
      "loss 2.309742, train acc 0.101877\n",
      "round 447\n",
      "time to device 0.003573 sec\n",
      "time forward 5.907510 sec\n",
      "loss time 0.002063 sec\n",
      "backward time 0.011806 sec\n",
      "optimizer time 0.024564 sec\n",
      "training time in round 447 cost 0.3888261318206787 sec\n",
      "loss 2.309712, train acc 0.101876\n",
      "round 448\n",
      "time to device 0.003494 sec\n",
      "time forward 5.912276 sec\n",
      "loss time 0.000551 sec\n",
      "backward time 0.006152 sec\n",
      "optimizer time 0.014863 sec\n",
      "training time in round 448 cost 0.32533812522888184 sec\n",
      "loss 2.309918, train acc 0.101771\n",
      "round 449\n",
      "time to device 0.004586 sec\n",
      "time forward 5.926044 sec\n",
      "loss time 0.001091 sec\n",
      "backward time 0.011562 sec\n",
      "optimizer time 0.028833 sec\n",
      "training time in round 449 cost 0.43033480644226074 sec\n",
      "loss 2.309991, train acc 0.101736\n",
      "round 450\n",
      "time to device 0.003773 sec\n",
      "time forward 5.942354 sec\n",
      "loss time 0.001745 sec\n",
      "backward time 0.011145 sec\n",
      "optimizer time 0.024540 sec\n",
      "training time in round 450 cost 0.47827887535095215 sec\n",
      "loss 2.309974, train acc 0.101666\n",
      "round 451\n",
      "time to device 0.003525 sec\n",
      "time forward 5.957171 sec\n",
      "loss time 0.001848 sec\n",
      "backward time 0.015942 sec\n",
      "optimizer time 0.027160 sec\n",
      "training time in round 451 cost 0.3991870880126953 sec\n",
      "loss 2.309964, train acc 0.101649\n",
      "round 452\n",
      "time to device 0.004665 sec\n",
      "time forward 5.964580 sec\n",
      "loss time 0.000586 sec\n",
      "backward time 0.005077 sec\n",
      "optimizer time 0.013069 sec\n",
      "training time in round 452 cost 0.34816789627075195 sec\n",
      "loss 2.309936, train acc 0.101597\n",
      "round 453\n",
      "time to device 0.004077 sec\n",
      "time forward 5.978142 sec\n",
      "loss time 0.001232 sec\n",
      "backward time 0.011821 sec\n",
      "optimizer time 0.024335 sec\n",
      "training time in round 453 cost 0.3862791061401367 sec\n",
      "loss 2.309933, train acc 0.101511\n",
      "round 454\n",
      "time to device 0.010078 sec\n",
      "time forward 5.990718 sec\n",
      "loss time 0.001595 sec\n",
      "backward time 0.013247 sec\n",
      "optimizer time 0.023775 sec\n",
      "training time in round 454 cost 0.3882579803466797 sec\n",
      "loss 2.309916, train acc 0.101545\n",
      "round 455\n",
      "time to device 0.008784 sec\n",
      "time forward 6.002995 sec\n",
      "loss time 0.001871 sec\n",
      "backward time 0.027056 sec\n",
      "optimizer time 0.020729 sec\n",
      "training time in round 455 cost 0.4048788547515869 sec\n",
      "loss 2.309906, train acc 0.101545\n",
      "round 456\n",
      "time to device 0.008068 sec\n",
      "time forward 6.016638 sec\n",
      "loss time 0.002032 sec\n",
      "backward time 0.013790 sec\n",
      "optimizer time 0.024851 sec\n",
      "training time in round 456 cost 0.4076070785522461 sec\n",
      "loss 2.309892, train acc 0.101562\n",
      "round 457\n",
      "time to device 0.007677 sec\n",
      "time forward 6.030514 sec\n",
      "loss time 0.001446 sec\n",
      "backward time 0.014318 sec\n",
      "optimizer time 0.024377 sec\n",
      "training time in round 457 cost 0.39545512199401855 sec\n",
      "loss 2.309887, train acc 0.101494\n",
      "round 458\n",
      "time to device 0.003313 sec\n",
      "time forward 6.043825 sec\n",
      "loss time 0.001331 sec\n",
      "backward time 0.010729 sec\n",
      "optimizer time 0.021609 sec\n",
      "training time in round 458 cost 0.38148021697998047 sec\n",
      "loss 2.309868, train acc 0.101477\n",
      "round 459\n",
      "time to device 0.003659 sec\n",
      "time forward 6.057285 sec\n",
      "loss time 0.001934 sec\n",
      "backward time 0.014752 sec\n",
      "optimizer time 0.024726 sec\n",
      "training time in round 459 cost 0.3908238410949707 sec\n",
      "loss 2.309837, train acc 0.101461\n",
      "round 460\n",
      "time to device 0.003599 sec\n",
      "time forward 6.070911 sec\n",
      "loss time 0.001842 sec\n",
      "backward time 0.015850 sec\n",
      "optimizer time 0.028429 sec\n",
      "training time in round 460 cost 0.396838903427124 sec\n",
      "loss 2.309808, train acc 0.101461\n",
      "round 461\n",
      "time to device 0.003618 sec\n",
      "time forward 6.086944 sec\n",
      "loss time 0.001785 sec\n",
      "backward time 0.012500 sec\n",
      "optimizer time 0.024038 sec\n",
      "training time in round 461 cost 0.3973240852355957 sec\n",
      "loss 2.309788, train acc 0.101529\n",
      "round 462\n",
      "time to device 0.004194 sec\n",
      "time forward 6.097029 sec\n",
      "loss time 0.000770 sec\n",
      "backward time 0.006865 sec\n",
      "optimizer time 0.017124 sec\n",
      "training time in round 462 cost 0.3616600036621094 sec\n",
      "loss 2.309768, train acc 0.101613\n",
      "round 463\n",
      "time to device 0.004643 sec\n",
      "time forward 6.114851 sec\n",
      "loss time 0.001194 sec\n",
      "backward time 0.013088 sec\n",
      "optimizer time 0.024732 sec\n",
      "training time in round 463 cost 0.399914026260376 sec\n",
      "loss 2.309755, train acc 0.101613\n",
      "round 464\n",
      "time to device 0.004040 sec\n",
      "time forward 6.131085 sec\n",
      "loss time 0.002226 sec\n",
      "backward time 0.015604 sec\n",
      "optimizer time 0.025632 sec\n",
      "training time in round 464 cost 0.40326881408691406 sec\n",
      "loss 2.309779, train acc 0.101596\n",
      "round 465\n",
      "time to device 0.003257 sec\n",
      "time forward 6.144760 sec\n",
      "loss time 0.001809 sec\n",
      "backward time 0.011733 sec\n",
      "optimizer time 0.026142 sec\n",
      "training time in round 465 cost 0.3859438896179199 sec\n",
      "loss 2.309764, train acc 0.101596\n",
      "round 466\n",
      "time to device 0.004781 sec\n",
      "time forward 6.156966 sec\n",
      "loss time 0.001930 sec\n",
      "backward time 0.013123 sec\n",
      "optimizer time 0.024071 sec\n",
      "training time in round 466 cost 0.3784489631652832 sec\n",
      "loss 2.309746, train acc 0.101546\n",
      "round 467\n",
      "time to device 0.004440 sec\n",
      "time forward 6.171203 sec\n",
      "loss time 0.001743 sec\n",
      "backward time 0.012775 sec\n",
      "optimizer time 0.024437 sec\n",
      "training time in round 467 cost 0.38601207733154297 sec\n",
      "loss 2.309736, train acc 0.101529\n",
      "round 468\n",
      "time to device 0.003036 sec\n",
      "time forward 6.191749 sec\n",
      "loss time 0.002855 sec\n",
      "backward time 0.019693 sec\n",
      "optimizer time 0.023241 sec\n",
      "training time in round 468 cost 0.3580498695373535 sec\n",
      "loss 2.309724, train acc 0.101600\n",
      "test acc is 0.100000\n",
      "epoch 9, time 4369.426770 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 10\n",
    "device = 'mps'\n",
    "timeenergy_data_forward, timeenergy_data_round, acc_data, train_l, train_acc, time_data_epoch, energy_data_epoch = train_ch6self(net, train_iter, test_iter, num_epochs, lr, device, energy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.25538373, 12.69162729],\n",
       "        [ 1.38759685, 14.02827006],\n",
       "        [ 0.80562568,  8.14468165],\n",
       "        [ 0.61864519,  6.25435395],\n",
       "        [ 1.0587554 , 10.70376219],\n",
       "        [ 0.02584505,  0.26128724]],\n",
       "\n",
       "       [[ 1.29033947, 12.95443744],\n",
       "        [ 1.46864891, 14.74458534],\n",
       "        [ 0.84415078,  8.4749004 ],\n",
       "        [ 0.62698841,  6.29468627],\n",
       "        [ 1.06303239, 10.6723749 ],\n",
       "        [ 0.02812743,  0.28238697]],\n",
       "\n",
       "       [[ 1.36043715, 13.56591736],\n",
       "        [ 1.50152183, 14.97277616],\n",
       "        [ 0.92076826,  9.18165612],\n",
       "        [ 0.64407825,  6.422577  ],\n",
       "        [ 1.1046927 , 11.01570167],\n",
       "        [ 0.02780581,  0.27727209]],\n",
       "\n",
       "       [[ 1.18078375, 12.19259926],\n",
       "        [ 1.29206491, 13.34167211],\n",
       "        [ 0.79197621,  8.17782986],\n",
       "        [ 0.56025434,  5.78510384],\n",
       "        [ 0.94263649,  9.73352571],\n",
       "        [ 0.02464485,  0.25447911]],\n",
       "\n",
       "       [[ 1.25701427, 12.51706299],\n",
       "        [ 1.34065223, 13.34991075],\n",
       "        [ 0.82181263,  8.18342374],\n",
       "        [ 0.58232856,  5.79869568],\n",
       "        [ 1.01897693, 10.14674108],\n",
       "        [ 0.02401948,  0.23918053]],\n",
       "\n",
       "       [[ 1.35518885, 13.74811302],\n",
       "        [ 1.69028687, 17.14761382],\n",
       "        [ 0.92385697,  9.3723396 ],\n",
       "        [ 0.7048471 ,  7.1505293 ],\n",
       "        [ 1.13859677, 11.55083084],\n",
       "        [ 0.03084898,  0.31295658]],\n",
       "\n",
       "       [[ 1.5242908 , 13.6479478 ],\n",
       "        [ 1.63860893, 14.67151096],\n",
       "        [ 0.9172852 ,  8.21303952],\n",
       "        [ 0.82856774,  7.41869551],\n",
       "        [ 1.48379517, 13.28536456],\n",
       "        [ 0.03428602,  0.30698463]],\n",
       "\n",
       "       [[ 1.40102696, 13.08426021],\n",
       "        [ 1.56787133, 14.64242803],\n",
       "        [ 0.80536437,  7.52133774],\n",
       "        [ 0.76767039,  7.16931182],\n",
       "        [ 1.3869555 , 12.9528461 ],\n",
       "        [ 0.03131032,  0.29240863]],\n",
       "\n",
       "       [[ 1.51341987, 13.45540885],\n",
       "        [ 1.60892868, 14.30455202],\n",
       "        [ 0.83663511,  7.43829769],\n",
       "        [ 0.8213284 ,  7.30220984],\n",
       "        [ 1.50162911, 13.35058044],\n",
       "        [ 0.0340414 ,  0.30265297]],\n",
       "\n",
       "       [[ 1.49977708, 13.43394356],\n",
       "        [ 1.57723689, 14.12777384],\n",
       "        [ 0.79265213,  7.10001782],\n",
       "        [ 0.81530213,  7.30290055],\n",
       "        [ 1.47456837, 13.20814173],\n",
       "        [ 0.0322125 ,  0.28853678]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeenergy_data_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  2.85010934,  28.81391928],\n",
       "        [  5.15185189,  52.08398237],\n",
       "        [  0.53453588,   5.40402911],\n",
       "        [  5.11875081,  51.7493384 ],\n",
       "        [ 10.50268769, 106.17964415],\n",
       "        [ 15.3544271 , 155.22956154]],\n",
       "\n",
       "       [[  2.95698452,  29.68681642],\n",
       "        [  5.32128739,  53.42337131],\n",
       "        [  0.51063848,   5.12658439],\n",
       "        [  5.17077327,  51.91227608],\n",
       "        [ 11.39377236, 114.38843397],\n",
       "        [ 15.69137979, 157.53451124]],\n",
       "\n",
       "       [[  3.31150079,  33.02140481],\n",
       "        [  5.559304  ,  55.4359004 ],\n",
       "        [  0.55992651,   5.58343819],\n",
       "        [  5.69200563,  56.7591658 ],\n",
       "        [ 11.18830156, 111.56676648],\n",
       "        [ 15.76284909, 157.18293736]],\n",
       "\n",
       "       [[  3.60720468,  37.24746477],\n",
       "        [  4.79236054,  49.4852099 ],\n",
       "        [  0.48504782,   5.0085324 ],\n",
       "        [  4.36983585,  45.12228211],\n",
       "        [  9.57307339,  98.85014734],\n",
       "        [ 15.01235604, 155.01537978]],\n",
       "\n",
       "       [[  3.22378922,  32.10176168],\n",
       "        [  5.0448041 ,  50.23501477],\n",
       "        [  0.50962138,   5.07469411],\n",
       "        [  4.66913867,  46.49422367],\n",
       "        [ 10.02818489,  99.85839023],\n",
       "        [ 15.05287099, 149.89307454]],\n",
       "\n",
       "       [[  3.75573087,  38.10111968],\n",
       "        [  5.84362555,  59.28238315],\n",
       "        [  0.58191514,   5.9034098 ],\n",
       "        [  5.55073142,  56.3110323 ],\n",
       "        [ 10.66592288, 108.20360098],\n",
       "        [ 14.85928822, 150.74443262]],\n",
       "\n",
       "       [[  3.09460258,  27.70795084],\n",
       "        [  6.42683387,  57.54354298],\n",
       "        [  0.72144723,   6.45957722],\n",
       "        [  6.02893019,  53.98085752],\n",
       "        [ 10.60655069,  94.96721375],\n",
       "        [ 14.70560217, 131.66863619]],\n",
       "\n",
       "       [[  3.00871754,  28.09856209],\n",
       "        [  5.96019888,  55.66259253],\n",
       "        [  0.69299412,   6.47190639],\n",
       "        [  5.90143919,  55.11383288],\n",
       "        [ 10.74143577, 100.31480063],\n",
       "        [ 14.46312785, 135.07186734]],\n",
       "\n",
       "       [[  2.55899262,  22.75131493],\n",
       "        [  6.31598258,  56.15370182],\n",
       "        [  0.74886179,   6.65792869],\n",
       "        [  6.17573571,  54.90680465],\n",
       "        [ 10.95040464,  97.35710151],\n",
       "        [ 14.5309689 , 129.19093501]],\n",
       "\n",
       "       [[  2.61112761,  23.38863656],\n",
       "        [  6.1917491 ,  55.46131428],\n",
       "        [  0.71691346,   6.42160433],\n",
       "        [  6.135957  ,  54.96156812],\n",
       "        [ 10.91762209,  97.79234599],\n",
       "        [ 14.47289395, 129.63795975]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeenergy_data_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.1, 0.2034, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.3047938346862793,\n",
       "  849926.1523969173,\n",
       "  566665.0814461708,\n",
       "  425108.57359683514,\n",
       "  340452.8078520775,\n",
       "  283726.4925612609,\n",
       "  243207.88886908122,\n",
       "  214436.84660810232,\n",
       "  190637.868663311,\n",
       "  171621.4032447338,\n",
       "  156071.39475107193,\n",
       "  143160.26591805616,\n",
       "  132227.30845110232,\n",
       "  122855.23429485729,\n",
       "  114719.03432868322,\n",
       "  107581.92286917567,\n",
       "  101269.00883615718,\n",
       "  95648.09487700462,\n",
       "  90615.27999514027,\n",
       "  86085.28040606975,\n",
       "  81987.57913487298,\n",
       "  78261.44556693597,\n",
       "  74859.17949450534,\n",
       "  71741.67976814508,\n",
       "  68872.65536405564,\n",
       "  66224.68273630508,\n",
       "  63772.48420226132,\n",
       "  61495.25602550166,\n",
       "  59375.02853766803,\n",
       "  57396.00114827156,\n",
       "  55546.365890549074,\n",
       "  53811.184836909175,\n",
       "  52181.156297784866,\n",
       "  50646.89417495447,\n",
       "  49200.31597991671,\n",
       "  47834.02865204546,\n",
       "  46541.61600286896,\n",
       "  45317.13912405466,\n",
       "  44155.456783918235,\n",
       "  43051.80567082167,\n",
       "  42001.9351425985,\n",
       "  41002.03731855892,\n",
       "  40048.61014874037,\n",
       "  39138.488757588646,\n",
       "  38268.826336876555,\n",
       "  37436.95349063044,\n",
       "  36640.47698717929,\n",
       "  35877.181571125984,\n",
       "  35145.39747487282,\n",
       "  34442.542587833406,\n",
       "  33767.268848306994,\n",
       "  33117.972271364466,\n",
       "  32493.178113294096,\n",
       "  31891.525351422806,\n",
       "  31311.75071775263,\n",
       "  30752.680104328054,\n",
       "  30213.220598195727,\n",
       "  29692.352624449235,\n",
       "  29189.149683483578,\n",
       "  28702.71036424637,\n",
       "  28232.22086437413,\n",
       "  27776.908794087747,\n",
       "  27336.050787778127,\n",
       "  26908.97328213975,\n",
       "  26495.025961696185,\n",
       "  26093.62704615521,\n",
       "  25704.20545806102,\n",
       "  25326.24290911941,\n",
       "  24959.231959778328,\n",
       "  24602.71409177099,\n",
       "  24256.24197241622,\n",
       "  23919.382096383306,\n",
       "  23591.761591336497,\n",
       "  23272.989387576643,\n",
       "  22962.718931789397,\n",
       "  22660.611874323142,\n",
       "  22366.349127044927,\n",
       "  22079.634353328973,\n",
       "  21800.178411414352,\n",
       "  21527.705245828627,\n",
       "  21261.96086144153,\n",
       "  21002.69623845961,\n",
       "  20749.684036151473,\n",
       "  20502.69448940527,\n",
       "  20261.51690142856,\n",
       "  20025.94502696603,\n",
       "  19795.7886131029,\n",
       "  19570.863002172926,\n",
       "  19350.99155490586,\n",
       "  19136.008768582346,\n",
       "  18925.749388351545,\n",
       "  18720.0620875851,\n",
       "  18518.79693558139,\n",
       "  18321.813042983096,\n",
       "  18128.977853094904,\n",
       "  17940.15971873949,\n",
       "  17755.233765909354,\n",
       "  17574.08081247612,\n",
       "  17396.587759095008,\n",
       "  17222.64587456703,\n",
       "  17052.14659158782,\n",
       "  16884.99452549336,\n",
       "  16721.087443273045,\n",
       "  16560.33045229545,\n",
       "  16402.63643652598,\n",
       "  16247.918099194203,\n",
       "  16096.090424865206,\n",
       "  15947.073538398301,\n",
       "  15800.791720541245,\n",
       "  15657.168731687285,\n",
       "  15516.133630428229,\n",
       "  15377.61780099358,\n",
       "  15241.55373538701,\n",
       "  15107.909327992222,\n",
       "  14976.560740358933,\n",
       "  14847.479767190998,\n",
       "  14720.602333333758,\n",
       "  14595.871986340668,\n",
       "  14473.238860731366,\n",
       "  14352.651698933045,\n",
       "  14234.060575818228,\n",
       "  14117.408624123354,\n",
       "  14002.656676949524,\n",
       "  13889.757109705479,\n",
       "  13778.670348234176,\n",
       "  13669.348779945147,\n",
       "  13561.740433923842,\n",
       "  13455.811216188595,\n",
       "  13351.526581309563,\n",
       "  13248.845456161866,\n",
       "  13147.75109564985,\n",
       "  13048.167013991962,\n",
       "  12950.093563556671,\n",
       "  12853.476778944927,\n",
       "  12758.290019897178,\n",
       "  12664.499966595104,\n",
       "  12572.077371017776,\n",
       "  12480.993644857752,\n",
       "  12391.226607084274,\n",
       "  12302.738101301875,\n",
       "  12215.513512770334,\n",
       "  12129.507156911031,\n",
       "  12044.70347417818,\n",
       "  11961.076881239811,\n",
       "  11878.60466492916,\n",
       "  11797.264778628742,\n",
       "  11717.02823263123,\n",
       "  11637.878265667607,\n",
       "  11559.788631648826,\n",
       "  11482.739503736497,\n",
       "  11406.712076471342,\n",
       "  11331.685029917642,\n",
       "  11257.638648668924,\n",
       "  11184.552186208886,\n",
       "  11112.40895945949,\n",
       "  11041.190885397104,\n",
       "  10970.879449174663,\n",
       "  10901.458428496047,\n",
       "  10832.910673970697,\n",
       "  10765.219846132397,\n",
       "  10698.369446082144,\n",
       "  10632.345733530727,\n",
       "  10567.132171531397,\n",
       "  10502.715148640842,\n",
       "  10439.075978920677,\n",
       "  10376.204281373197,\n",
       "  10314.085503329774,\n",
       "  10252.70698084434,\n",
       "  10192.053934019697,\n",
       "  10132.117265657818,\n",
       "  10072.879222645397,\n",
       "  10014.329604474611,\n",
       "  9956.457108474191,\n",
       "  9899.249201001792,\n",
       "  9842.695581509726,\n",
       "  9786.785123808817,\n",
       "  9731.506292405102,\n",
       "  9676.848185209747,\n",
       "  9622.80073383667,\n",
       "  9569.3537178927,\n",
       "  9516.497531993613,\n",
       "  9464.221767205458,\n",
       "  9412.518287051571,\n",
       "  9361.376124577679,\n",
       "  9310.786487982725,\n",
       "  9260.741862748258,\n",
       "  9211.231809484767,\n",
       "  9162.248447330709,\n",
       "  9113.78392965453,\n",
       "  9065.82937886966,\n",
       "  9018.3763971491,\n",
       "  8971.418522731712,\n",
       "  8924.94661588496,\n",
       "  8878.953792332373,\n",
       "  8833.434009787976,\n",
       "  8788.377543341141,\n",
       "  8743.778006099807,\n",
       "  8699.629372112679,\n",
       "  8655.92446091187,\n",
       "  8612.656894671916,\n",
       "  8569.82000103756,\n",
       "  8527.406732280655,\n",
       "  8485.411268027545,\n",
       "  8443.828613832886,\n",
       "  8402.650621083887,\n",
       "  8361.87230902968,\n",
       "  8321.489637948465,\n",
       "  8281.49348396636,\n",
       "  8241.880599251204,\n",
       "  8202.645224148886,\n",
       "  8163.781526158771,\n",
       "  8125.284204551634,\n",
       "  8087.148794311873,\n",
       "  8049.369210341267,\n",
       "  8011.943621650962,\n",
       "  7974.862230081249,\n",
       "  7938.122766428829,\n",
       "  7901.7205377696855,\n",
       "  7865.6518030721845,\n",
       "  7829.909601129185,\n",
       "  7794.491088628769,\n",
       "  7759.39120052097,\n",
       "  7724.606133818092,\n",
       "  7690.131571712239,\n",
       "  7655.963427137799,\n",
       "  7622.097914831828,\n",
       "  7588.531166446366,\n",
       "  7555.25862195199,\n",
       "  7522.276452314385,\n",
       "  7489.58143071299,\n",
       "  7457.169112385093,\n",
       "  7425.036276815266,\n",
       "  7393.179136647687,\n",
       "  7361.594334780661,\n",
       "  7330.278330343328,\n",
       "  7299.22754622516,\n",
       "  7268.4389962576615,\n",
       "  7237.909080908078,\n",
       "  7207.634505054442,\n",
       "  7177.6123038768765,\n",
       "  7147.83932781813,\n",
       "  7118.312331926724,\n",
       "  7089.028393190093,\n",
       "  7059.9846435570325,\n",
       "  7031.178342883441,\n",
       "  7002.605807533109,\n",
       "  6974.264387853715,\n",
       "  6946.152051559379,\n",
       "  6918.265300093884,\n",
       "  6890.60200480175,\n",
       "  6863.158642480098,\n",
       "  6835.933398513567,\n",
       "  6808.922995158335,\n",
       "  6782.125381608647,\n",
       "  6755.53841993201,\n",
       "  6729.158720847219,\n",
       "  6702.9845992359205,\n",
       "  6677.012941802195,\n",
       "  6651.241879859026,\n",
       "  6625.669152553265,\n",
       "  6600.292595956517,\n",
       "  6575.10958317855,\n",
       "  6550.118669093788,\n",
       "  6525.316348226685,\n",
       "  6500.701332620405,\n",
       "  6476.272203742114,\n",
       "  6452.025306584684,\n",
       "  6427.959300346339,\n",
       "  6404.072259819641,\n",
       "  6380.362642372979,\n",
       "  6356.827424761994,\n",
       "  6333.465208898572,\n",
       "  6310.274180099641,\n",
       "  6287.252360859056,\n",
       "  6264.397995548248,\n",
       "  6241.709287831749,\n",
       "  6219.184369039019,\n",
       "  6196.8214990560955,\n",
       "  6174.618946983823,\n",
       "  6152.575268720729,\n",
       "  6130.6881778316565,\n",
       "  6108.95652921149,\n",
       "  6087.378320431119,\n",
       "  6065.952040459908,\n",
       "  6044.676042274843,\n",
       "  6023.548854819544,\n",
       "  6002.568943626789,\n",
       "  5981.734822933872,\n",
       "  5961.044746973936,\n",
       "  5940.497654897591,\n",
       "  5920.0917163214735,\n",
       "  5899.825576516863,\n",
       "  5879.697699991916,\n",
       "  5859.706568614155,\n",
       "  5839.850966196545,\n",
       "  5820.129546689021,\n",
       "  5800.540864227597,\n",
       "  5781.083774273027,\n",
       "  5761.756741392174,\n",
       "  5742.5586992017425,\n",
       "  5723.48825369008,\n",
       "  5704.54394176701,\n",
       "  5685.724748448571,\n",
       "  5667.029772431442,\n",
       "  5648.457091774706,\n",
       "  5630.005517809998,\n",
       "  5611.674242296902,\n",
       "  5593.46240180576,\n",
       "  5575.368227234165,\n",
       "  5557.390720801969,\n",
       "  5539.5289775926585,\n",
       "  5521.781904296233,\n",
       "  5504.147838312978,\n",
       "  5486.626065295973,\n",
       "  5469.215571189306,\n",
       "  5451.915255004092,\n",
       "  5434.724047127583,\n",
       "  5417.64101056033,\n",
       "  5400.665087360573,\n",
       "  5383.7951983213425,\n",
       "  5367.030531652248,\n",
       "  5350.369920673577,\n",
       "  5333.8126640578175,\n",
       "  5317.357412592864,\n",
       "  5301.003928763316,\n",
       "  5284.750328259234,\n",
       "  5268.596030260809,\n",
       "  5252.54038296749,\n",
       "  5236.582290118226,\n",
       "  5220.721100221258,\n",
       "  5204.955777735148,\n",
       "  5189.285236814654,\n",
       "  5173.708867436772,\n",
       "  5158.226414219348,\n",
       "  5142.835629823315,\n",
       "  5127.536478240575,\n",
       "  5112.328107693075,\n",
       "  5097.209728995019,\n",
       "  5082.180749248263,\n",
       "  5067.240055183102,\n",
       "  5052.387476500178,\n",
       "  5037.621181316543,\n",
       "  5022.940953548726,\n",
       "  5008.346127347198,\n",
       "  4993.835867440874,\n",
       "  4979.409869512381,\n",
       "  4965.0666227512465,\n",
       "  4950.805823163055,\n",
       "  4936.626733114521,\n",
       "  4922.528724007607,\n",
       "  4908.5109834093655,\n",
       "  4894.572994713756,\n",
       "  4880.713960696212,\n",
       "  4866.933139248757,\n",
       "  4853.229958227319,\n",
       "  4839.603752854835,\n",
       "  4826.05396369659,\n",
       "  4812.580138674662,\n",
       "  4799.181026207703,\n",
       "  4785.856364834971,\n",
       "  4772.605563476145,\n",
       "  4759.428074585799,\n",
       "  4746.323148549424,\n",
       "  4733.290100315115,\n",
       "  4720.328538499466,\n",
       "  4707.438283943087,\n",
       "  4694.617742477386,\n",
       "  4681.866883534452,\n",
       "  4669.185112361985,\n",
       "  4656.571951362894,\n",
       "  4644.026730748842,\n",
       "  4631.548984681406,\n",
       "  4619.138530028729,\n",
       "  4606.794132029309,\n",
       "  4594.515507340113,\n",
       "  4582.302652014063,\n",
       "  4570.154127677492,\n",
       "  4558.069996766312,\n",
       "  4546.049634120081,\n",
       "  4534.092504381506,\n",
       "  4522.1980186528735,\n",
       "  4510.365837048485,\n",
       "  4498.596548948835,\n",
       "  4486.887481423095,\n",
       "  4475.239587834593,\n",
       "  4463.651642144653,\n",
       "  4452.123653090277,\n",
       "  4440.655041743185,\n",
       "  4429.245391019513,\n",
       "  4417.894290803029,\n",
       "  4406.601235605567,\n",
       "  4395.36578461467,\n",
       "  4384.187524060257,\n",
       "  4373.066042458346,\n",
       "  4362.000794875471,\n",
       "  4350.9916023606,\n",
       "  4340.037736988788,\n",
       "  4329.138910778203,\n",
       "  4318.294798514598,\n",
       "  4307.504857305885,\n",
       "  4296.768919246155,\n",
       "  4286.086163019067,\n",
       "  4275.456409168007,\n",
       "  4264.879388436232,\n",
       "  4254.354526402038,\n",
       "  4243.881539120463,\n",
       "  4233.460024256671,\n",
       "  4223.089744362761,\n",
       "  4212.7700971379545,\n",
       "  4202.500641615216,\n",
       "  4192.28129060251,\n",
       "  4182.111582306982,\n",
       "  4171.991392910913,\n",
       "  4161.919703117891,\n",
       "  4151.896550746136,\n",
       "  4141.921570484455,\n",
       "  4131.994432827266,\n",
       "  4122.114809919202,\n",
       "  4112.282310234334,\n",
       "  4102.496647113845,\n",
       "  4092.7575764848616,\n",
       "  4083.064561408843,\n",
       "  4073.417414850095,\n",
       "  4063.815808244471,\n",
       "  4054.2593437486535,\n",
       "  4044.7478318001745,\n",
       "  4035.2808026910106,\n",
       "  4025.857953785179,\n",
       "  4016.4790452827106,\n",
       "  4007.143815427048,\n",
       "  3997.8518407206525,\n",
       "  3988.602923271281,\n",
       "  3979.396679267597,\n",
       "  3970.2328764062872,\n",
       "  3961.111206806665,\n",
       "  3952.0313727713506,\n",
       "  3942.9930873735548,\n",
       "  3933.9961364541423,\n",
       "  3925.0402640297093,\n",
       "  3916.125534772873,\n",
       "  3907.2507059201093,\n",
       "  3898.4160226135773,\n",
       "  3889.621346102342,\n",
       "  3880.86639378146,\n",
       "  3872.1505390869097,\n",
       "  3863.4738457978037,\n",
       "  3854.8357772352447,\n",
       "  3846.236771303096,\n",
       "  3837.675773219701,\n",
       "  3829.152733657625,\n",
       "  3820.667527186104,\n",
       "  3812.2198202657487,\n",
       "  3803.8096048589837,\n",
       "  3795.4362145037376,\n",
       "  3787.0997238494538,\n",
       "  3778.799738663853,\n",
       "  3770.5361200667576,\n",
       "  3762.3085829966976,\n",
       "  3754.116854878033,\n",
       "  3745.961140563177,\n",
       "  3737.840404530151,\n",
       "  3729.7548318621402,\n",
       "  3721.7042373127865,\n",
       "  3713.6883920246155,\n",
       "  3705.7069190866205,\n",
       "  3697.7597405286306,\n",
       "  3689.8465605558113,\n",
       "  3681.9671669154086,\n",
       "  3676.0796733846028],\n",
       " [2.321483612060547,\n",
       "  2.3351982831954956,\n",
       "  2.3234591484069824,\n",
       "  2.3279424905776978,\n",
       "  2.3249026775360107,\n",
       "  2.319137136141459,\n",
       "  2.316863400595529,\n",
       "  2.315547466278076,\n",
       "  2.3137442800733776,\n",
       "  2.3198850393295287,\n",
       "  2.3193880861455742,\n",
       "  2.3177446921666465,\n",
       "  2.3170943076793966,\n",
       "  2.323743087904794,\n",
       "  2.32320237159729,\n",
       "  2.3220752477645874,\n",
       "  2.3207371375140022,\n",
       "  2.32032310962677,\n",
       "  2.321058285863776,\n",
       "  2.327632284164429,\n",
       "  2.3268029122125533,\n",
       "  2.326078176498413,\n",
       "  2.325286761574123,\n",
       "  2.3243964413801828,\n",
       "  2.3235823345184325,\n",
       "  2.3223422949130716,\n",
       "  2.3214856871852168,\n",
       "  2.320454486778804,\n",
       "  2.3193637173751305,\n",
       "  2.3187480847040813,\n",
       "  2.3186019082223215,\n",
       "  2.3180175125598907,\n",
       "  2.317448211438728,\n",
       "  2.317816537969253,\n",
       "  2.3178829193115233,\n",
       "  2.3207200368245444,\n",
       "  2.3213763301436967,\n",
       "  2.3213447457865666,\n",
       "  2.321156403957269,\n",
       "  2.321182280778885,\n",
       "  2.3210707176022414,\n",
       "  2.3213471117473783,\n",
       "  2.321610317673794,\n",
       "  2.3210413943637502,\n",
       "  2.320558187696669,\n",
       "  2.32008813775104,\n",
       "  2.319935093534754,\n",
       "  2.3195692052443824,\n",
       "  2.319942537619143,\n",
       "  2.320810284614563,\n",
       "  2.3204621847938087,\n",
       "  2.3200476307135363,\n",
       "  2.319737141987063,\n",
       "  2.319790760676066,\n",
       "  2.322160746834495,\n",
       "  2.3218038422720775,\n",
       "  2.3215976765281274,\n",
       "  2.3212657879138816,\n",
       "  2.321076502234249,\n",
       "  2.32187682390213,\n",
       "  2.321723578406162,\n",
       "  2.3220847883532123,\n",
       "  2.3227328800019764,\n",
       "  2.3225266821682453,\n",
       "  2.3222050116612363,\n",
       "  2.3220021291212602,\n",
       "  2.321728973246332,\n",
       "  2.3214111643679,\n",
       "  2.3211637199788853,\n",
       "  2.320925947598049,\n",
       "  2.3206586938508798,\n",
       "  2.3204702701833515,\n",
       "  2.320229807945147,\n",
       "  2.3204797860738395,\n",
       "  2.3200453440348308,\n",
       "  2.319612797937895,\n",
       "  2.319234073936165,\n",
       "  2.3190377247639193,\n",
       "  2.318846596947199,\n",
       "  2.3186513632535934,\n",
       "  2.3183281892611656,\n",
       "  2.318512483340938,\n",
       "  2.3183182722114655,\n",
       "  2.318094023636409,\n",
       "  2.3178986128638774,\n",
       "  2.3178854238155275,\n",
       "  2.3177190512076193,\n",
       "  2.3176803182471883,\n",
       "  2.317753486418992,\n",
       "  2.3174681663513184,\n",
       "  2.3171630770295533,\n",
       "  2.3174303070358606,\n",
       "  2.3173917621694584,\n",
       "  2.3185913055501084,\n",
       "  2.3181911016765393,\n",
       "  2.319596712787946,\n",
       "  2.319957595510581,\n",
       "  2.320364100592477,\n",
       "  2.320315806552617,\n",
       "  2.3206458401679995,\n",
       "  2.3236741759989523,\n",
       "  2.3236494672064687,\n",
       "  2.323458916932634,\n",
       "  2.32320996431204,\n",
       "  2.324743379865374,\n",
       "  2.324941527168706,\n",
       "  2.3251580835502836,\n",
       "  2.3249830780205905,\n",
       "  2.3248214349834195,\n",
       "  2.324627592346885,\n",
       "  2.3247480843518233,\n",
       "  2.3245704833950316,\n",
       "  2.3243832461601865,\n",
       "  2.3241525658389977,\n",
       "  2.3243331618930982,\n",
       "  2.324159807172315,\n",
       "  2.3239147540850515,\n",
       "  2.323807989136647,\n",
       "  2.3238158626716676,\n",
       "  2.3241860389709474,\n",
       "  2.324360447481644,\n",
       "  2.32420877355044,\n",
       "  2.324418759927517,\n",
       "  2.3242595253452176,\n",
       "  2.3242278232574463,\n",
       "  2.324093682425363,\n",
       "  2.3239294375021626,\n",
       "  2.3238284159451723,\n",
       "  2.323813240657481,\n",
       "  2.3236497457210836,\n",
       "  2.3234827391063892,\n",
       "  2.3233648014791086,\n",
       "  2.323312712791271,\n",
       "  2.3232931877250103,\n",
       "  2.323259291825471,\n",
       "  2.3233425564625683,\n",
       "  2.323536773667718,\n",
       "  2.3235760478005894,\n",
       "  2.3234764157439307,\n",
       "  2.3233667254447936,\n",
       "  2.323335733819515,\n",
       "  2.3232704115585543,\n",
       "  2.323024387959834,\n",
       "  2.323117893603113,\n",
       "  2.3235307874350712,\n",
       "  2.323375450421686,\n",
       "  2.3232937832267915,\n",
       "  2.323075998473812,\n",
       "  2.323486305723254,\n",
       "  2.324351838429769,\n",
       "  2.324101751213832,\n",
       "  2.3238977805564276,\n",
       "  2.3237695491391848,\n",
       "  2.3237144529045404,\n",
       "  2.3237604879563856,\n",
       "  2.3241599951034937,\n",
       "  2.3240687558605413,\n",
       "  2.3239527065542678,\n",
       "  2.32381775244227,\n",
       "  2.3238214209675787,\n",
       "  2.323848793965689,\n",
       "  2.323703771756019,\n",
       "  2.323575739480235,\n",
       "  2.323633308817701,\n",
       "  2.323633998813051,\n",
       "  2.323680504258857,\n",
       "  2.323503095946626,\n",
       "  2.3233632927849177,\n",
       "  2.3232540957321075,\n",
       "  2.3231627534417547,\n",
       "  2.323007858287521,\n",
       "  2.3229716558789097,\n",
       "  2.32288827923681,\n",
       "  2.3230125301185693,\n",
       "  2.3228991426740375,\n",
       "  2.3227909451181237,\n",
       "  2.322675364165656,\n",
       "  2.322559931305017,\n",
       "  2.3224335089742136,\n",
       "  2.3222933292388914,\n",
       "  2.3226434486347007,\n",
       "  2.322549670607179,\n",
       "  2.322548220066425,\n",
       "  2.322465826635775,\n",
       "  2.322373497163927,\n",
       "  2.3222801980151924,\n",
       "  2.3221970560716434,\n",
       "  2.3221454886679953,\n",
       "  2.322046538509389,\n",
       "  2.322024065569827,\n",
       "  2.321917365358762,\n",
       "  2.3222902677953243,\n",
       "  2.3221790247012914,\n",
       "  2.3219971324979642,\n",
       "  2.321857555095966,\n",
       "  2.321790889817841,\n",
       "  2.3223840742546895,\n",
       "  2.3223795902849447,\n",
       "  2.3223553602419904,\n",
       "  2.3222318255901335,\n",
       "  2.322164076477734,\n",
       "  2.3223036456816266,\n",
       "  2.322267780163018,\n",
       "  2.3221671908509496,\n",
       "  2.3220717918582077,\n",
       "  2.321996345103366,\n",
       "  2.3219388406633756,\n",
       "  2.3217492756935267,\n",
       "  2.3218471091329764,\n",
       "  2.321889551480611,\n",
       "  2.3217854872699033,\n",
       "  2.321697229484342,\n",
       "  2.3216999797194218,\n",
       "  2.3216152269149495,\n",
       "  2.3215191375377566,\n",
       "  2.321514915536951,\n",
       "  2.3214603206529048,\n",
       "  2.321412907827885,\n",
       "  2.3213523228963218,\n",
       "  2.3212646029212256,\n",
       "  2.3213248954099766,\n",
       "  2.3212678786870597,\n",
       "  2.3212668574978954,\n",
       "  2.3211343001042093,\n",
       "  2.3210638565487334,\n",
       "  2.32100976040933,\n",
       "  2.3209250498448175,\n",
       "  2.3208618571883752,\n",
       "  2.3207756348572444,\n",
       "  2.3206843811532725,\n",
       "  2.32062367753033,\n",
       "  2.320549392494662,\n",
       "  2.320495281096692,\n",
       "  2.3204167490331535,\n",
       "  2.3203549841617015,\n",
       "  2.3202844726837286,\n",
       "  2.320220495578106,\n",
       "  2.3201552328943205,\n",
       "  2.320084431181393,\n",
       "  2.320005668203036,\n",
       "  2.3199297451874035,\n",
       "  2.3199117065461214,\n",
       "  2.3198253470683783,\n",
       "  2.3197419135296933,\n",
       "  2.31971033057388,\n",
       "  2.3196449541464084,\n",
       "  2.319942283244268,\n",
       "  2.3198581626338344,\n",
       "  2.319784331034465,\n",
       "  2.319712766647339,\n",
       "  2.319614766603447,\n",
       "  2.3195406255267916,\n",
       "  2.3194776325828945,\n",
       "  2.3194407769075527,\n",
       "  2.319356148850684,\n",
       "  2.319320079870522,\n",
       "  2.319284521652103,\n",
       "  2.31926630633746,\n",
       "  2.3193118065940825,\n",
       "  2.3192637370182916,\n",
       "  2.3192149469222145,\n",
       "  2.319162963910867,\n",
       "  2.319847806778244,\n",
       "  2.3197576945478264,\n",
       "  2.319688570274497,\n",
       "  2.319699870912652,\n",
       "  2.319640893614694,\n",
       "  2.319591830025858,\n",
       "  2.3195414224078665,\n",
       "  2.319498407399213,\n",
       "  2.3194129009528353,\n",
       "  2.319684006712016,\n",
       "  2.319617753500467,\n",
       "  2.3197642408148216,\n",
       "  2.319690651460127,\n",
       "  2.319621987964796,\n",
       "  2.3196099484440222,\n",
       "  2.3195530647854152,\n",
       "  2.319502339995463,\n",
       "  2.319467648438045,\n",
       "  2.3194142490943555,\n",
       "  2.3195359656151306,\n",
       "  2.3194535680036243,\n",
       "  2.3194451147401836,\n",
       "  2.319434898778012,\n",
       "  2.3194807292698147,\n",
       "  2.3194388462691355,\n",
       "  2.3193924948573112,\n",
       "  2.3193401391118456,\n",
       "  2.3193307202437827,\n",
       "  2.319280236037736,\n",
       "  2.3192837826193196,\n",
       "  2.3193039161760245,\n",
       "  2.3193091437930153,\n",
       "  2.3193340560137217,\n",
       "  2.31928305690353,\n",
       "  2.3192270628932348,\n",
       "  2.319260821246461,\n",
       "  2.319196511271805,\n",
       "  2.3191839981079103,\n",
       "  2.319181177703249,\n",
       "  2.3191237315436863,\n",
       "  2.319250505749542,\n",
       "  2.3191869784342614,\n",
       "  2.3191540897869674,\n",
       "  2.319138627426297,\n",
       "  2.3191458045077247,\n",
       "  2.31909811419326,\n",
       "  2.3190474795677902,\n",
       "  2.3190310255173716,\n",
       "  2.3189866987455314,\n",
       "  2.3189338942368827,\n",
       "  2.3189513165349016,\n",
       "  2.3188957089831117,\n",
       "  2.3188488188244047,\n",
       "  2.3187974223607704,\n",
       "  2.3187895377727714,\n",
       "  2.318736064359077,\n",
       "  2.318715505091748,\n",
       "  2.31866322606802,\n",
       "  2.3186100502251836,\n",
       "  2.3186007264237967,\n",
       "  2.3185399427502515,\n",
       "  2.318476939642871,\n",
       "  2.318424792656532,\n",
       "  2.31839890714072,\n",
       "  2.318335890405404,\n",
       "  2.3183091442759443,\n",
       "  2.318264564119936,\n",
       "  2.318248747334336,\n",
       "  2.3182887908555228,\n",
       "  2.3182841575289346,\n",
       "  2.31824006117858,\n",
       "  2.3181945092663794,\n",
       "  2.3181862468150123,\n",
       "  2.3181328014248894,\n",
       "  2.3180671233451684,\n",
       "  2.318024648011789,\n",
       "  2.3180537716125666,\n",
       "  2.3179909993620478,\n",
       "  2.317963541428015,\n",
       "  2.317953917018154,\n",
       "  2.318273273223343,\n",
       "  2.3182552332101865,\n",
       "  2.3183233136716095,\n",
       "  2.318277396907696,\n",
       "  2.3182271337646574,\n",
       "  2.3181856439031403,\n",
       "  2.318130014277461,\n",
       "  2.318087295123509,\n",
       "  2.3181187916345407,\n",
       "  2.3180932795459572,\n",
       "  2.318047130411813,\n",
       "  2.3179900120880643,\n",
       "  2.317982337172602,\n",
       "  2.3179109833213722,\n",
       "  2.3178611469535935,\n",
       "  2.3178450714942462,\n",
       "  2.3178474139370295,\n",
       "  2.3177875412835016,\n",
       "  2.3177410691068445,\n",
       "  2.3176523644621203,\n",
       "  2.3176239049139102,\n",
       "  2.3175724856146087,\n",
       "  2.3175676424209386,\n",
       "  2.3181235217005827,\n",
       "  2.3181322348540094,\n",
       "  2.3180517651464627,\n",
       "  2.3180570893171355,\n",
       "  2.3181591130591728,\n",
       "  2.318124879723932,\n",
       "  2.318702415753436,\n",
       "  2.3187431963135667,\n",
       "  2.318738099088006,\n",
       "  2.318771098454793,\n",
       "  2.3186802160232625,\n",
       "  2.3188787271868962,\n",
       "  2.3189130289844737,\n",
       "  2.3191093064864265,\n",
       "  2.319662261009216,\n",
       "  2.3198834141408367,\n",
       "  2.319932734779038,\n",
       "  2.319878738791762,\n",
       "  2.3199427276849747,\n",
       "  2.319979557433686,\n",
       "  2.3199295466427974,\n",
       "  2.3199713538167397,\n",
       "  2.3200366073047993,\n",
       "  2.3200428210064805,\n",
       "  2.3201251353972996,\n",
       "  2.3200769357364197,\n",
       "  2.3200554683500405,\n",
       "  2.320143755458997,\n",
       "  2.320177831020452,\n",
       "  2.320151289203499,\n",
       "  2.3200794915960294,\n",
       "  2.3201443722626425,\n",
       "  2.320142001362901,\n",
       "  2.320252509941732,\n",
       "  2.320397874116898,\n",
       "  2.3203780098151685,\n",
       "  2.320591309770423,\n",
       "  2.3205505754456626,\n",
       "  2.3205034602986703,\n",
       "  2.320530784277268,\n",
       "  2.320469000069379,\n",
       "  2.320397627734435,\n",
       "  2.320362716328864,\n",
       "  2.3204877510630415,\n",
       "  2.320402087816378,\n",
       "  2.3204526872240425,\n",
       "  2.320430918225964,\n",
       "  2.3204229449533087,\n",
       "  2.3204639856366143,\n",
       "  2.320486728254571,\n",
       "  2.3204661229482064,\n",
       "  2.320408814816738,\n",
       "  2.3205004976126564,\n",
       "  2.3204340086916466,\n",
       "  2.3204423342432294,\n",
       "  2.3208293637300614,\n",
       "  2.3209007933241494,\n",
       "  2.3208487721481506,\n",
       "  2.3207996302055864,\n",
       "  2.3207654863245346,\n",
       "  2.3207235241160147,\n",
       "  2.320651605481007,\n",
       "  2.320610489800712,\n",
       "  2.3205662618428122,\n",
       "  2.320516284676485,\n",
       "  2.3204753365704742,\n",
       "  2.3204607273693436,\n",
       "  2.3203740466824856,\n",
       "  2.3203421413623793,\n",
       "  2.3203977820517,\n",
       "  2.320388931200045,\n",
       "  2.3204242975815483,\n",
       "  2.3204807952114437,\n",
       "  2.3204176963597605,\n",
       "  2.320532287792726,\n",
       "  2.321130509819844,\n",
       "  2.3211217239431665,\n",
       "  2.3210922955928486,\n",
       "  2.3210624950426118,\n",
       "  2.3210193334000833,\n",
       "  2.321020815939112,\n",
       "  2.320987211244485,\n",
       "  2.32094192770975,\n",
       "  2.3208943395678343,\n",
       "  2.3208594528834023,\n",
       "  2.3208067131676855,\n",
       "  2.3207790545657674,\n",
       "  2.3207344777273553,\n",
       "  2.320693603171126,\n",
       "  2.320678745521294,\n",
       "  2.320660583282772,\n",
       "  2.32061900769073,\n",
       "  2.3205859515344214,\n",
       "  2.3205472482835026,\n",
       "  2.3205141435498775,\n",
       "  2.3204741948597345,\n",
       "  2.3204355152138385,\n",
       "  2.3204045455347644,\n",
       "  2.32036390592312,\n",
       "  2.3203287709143856,\n",
       "  2.3202870188864515,\n",
       "  2.3202525880147866,\n",
       "  2.320213199680687,\n",
       "  2.320187646993001],\n",
       " [2.305935859680176,\n",
       "  2.301409959793091,\n",
       "  2.300382455190023,\n",
       "  2.3001675605773926,\n",
       "  2.299674701690674,\n",
       "  2.2999159495035806,\n",
       "  2.30085665839059,\n",
       "  2.3005619049072266,\n",
       "  2.3005572424994574,\n",
       "  2.304180550575256,\n",
       "  2.305408000946045,\n",
       "  2.3086844285329184,\n",
       "  2.3092630092914286,\n",
       "  2.307501826967512,\n",
       "  2.3074753125508627,\n",
       "  2.3078360557556152,\n",
       "  2.311501152375165,\n",
       "  2.3109757237964206,\n",
       "  2.3103502424139726,\n",
       "  2.30993766784668,\n",
       "  2.310215632120768,\n",
       "  2.3094721924174917,\n",
       "  2.309181918268618,\n",
       "  2.3087531129519143,\n",
       "  2.308550968170166,\n",
       "  2.308352965574998,\n",
       "  2.308194884547481,\n",
       "  2.3079840455736433,\n",
       "  2.3077672021142366,\n",
       "  2.307679231961568,\n",
       "  2.307551445499543,\n",
       "  2.3073680698871613,\n",
       "  2.30725731271686,\n",
       "  2.3071258418700276,\n",
       "  2.306910221917289,\n",
       "  2.307042075528039,\n",
       "  2.306935033282718,\n",
       "  2.3068830966949463,\n",
       "  2.3067703124804373,\n",
       "  2.3067058622837067,\n",
       "  2.3065208283866325,\n",
       "  2.306474589166187,\n",
       "  2.3062512098356733,\n",
       "  2.306148361076008,\n",
       "  2.3059223122066923,\n",
       "  2.305723304333894,\n",
       "  2.30544306369538,\n",
       "  2.3054661750793457,\n",
       "  2.305324281964983,\n",
       "  2.305444416999817,\n",
       "  2.30535636696161,\n",
       "  2.3053076588190518,\n",
       "  2.305977025122013,\n",
       "  2.306034454592952,\n",
       "  2.3059351964430377,\n",
       "  2.3059841181550707,\n",
       "  2.3058966335497404,\n",
       "  2.3061200339218666,\n",
       "  2.3060891749495167,\n",
       "  2.305748987197876,\n",
       "  2.305675561310815,\n",
       "  2.3057266127678657,\n",
       "  2.3055961775401284,\n",
       "  2.305594764649868,\n",
       "  2.305488755152776,\n",
       "  2.30536644747763,\n",
       "  2.3053182025453935,\n",
       "  2.305375775870155,\n",
       "  2.305331503135571,\n",
       "  2.305327033996582,\n",
       "  2.305363849854805,\n",
       "  2.3054012854894004,\n",
       "  2.3057651911696344,\n",
       "  2.3055474081554928,\n",
       "  2.305562810897827,\n",
       "  2.3059437745495845,\n",
       "  2.3063903412261566,\n",
       "  2.3066882628660936,\n",
       "  2.306847662865361,\n",
       "  2.3068041414022447,\n",
       "  2.3069308157320374,\n",
       "  2.306889574702193,\n",
       "  2.3070764541625977,\n",
       "  2.3070257050650462,\n",
       "  2.3069375290590175,\n",
       "  2.3069223997204804,\n",
       "  2.306864491824446,\n",
       "  2.3068911758336155,\n",
       "  2.306778334499745,\n",
       "  2.3067208607991536,\n",
       "  2.3066305773598805,\n",
       "  2.3065553670344143,\n",
       "  2.306519672434817,\n",
       "  2.306494690002279,\n",
       "  2.306423006559673,\n",
       "  2.3071489731470742,\n",
       "  2.307245969772339,\n",
       "  2.307187379622946,\n",
       "  2.3071865216650145,\n",
       "  2.3071231937408445,\n",
       "  2.307043410763882,\n",
       "  2.307018985935286,\n",
       "  2.3069689065507313,\n",
       "  2.306915356562688,\n",
       "  2.306973361968994,\n",
       "  2.3069116169551633,\n",
       "  2.3068900553979605,\n",
       "  2.306838353474935,\n",
       "  2.306848797229452,\n",
       "  2.306651375510476,\n",
       "  2.307024876276652,\n",
       "  2.306920051574707,\n",
       "  2.3068394724246675,\n",
       "  2.306799430596201,\n",
       "  2.306760951747065,\n",
       "  2.3067392789084336,\n",
       "  2.30778602249602,\n",
       "  2.3077791605965565,\n",
       "  2.307734956260489,\n",
       "  2.3078159511089327,\n",
       "  2.307798972799758,\n",
       "  2.308127315317998,\n",
       "  2.3081111966109855,\n",
       "  2.308064789541306,\n",
       "  2.308963205337524,\n",
       "  2.308970192122081,\n",
       "  2.3089360683921756,\n",
       "  2.30886753462255,\n",
       "  2.308868099552716,\n",
       "  2.3088020929923423,\n",
       "  2.30874308011004,\n",
       "  2.3087265906911907,\n",
       "  2.3086885348298494,\n",
       "  2.308642307324196,\n",
       "  2.3086118698120117,\n",
       "  2.3085197981666115,\n",
       "  2.308488062698476,\n",
       "  2.308397275814112,\n",
       "  2.3083565458119346,\n",
       "  2.3083336097853526,\n",
       "  2.308273301902392,\n",
       "  2.308259325967708,\n",
       "  2.3082233642364716,\n",
       "  2.3081781334347196,\n",
       "  2.3081443507095862,\n",
       "  2.308081966556915,\n",
       "  2.3080452867105703,\n",
       "  2.3080737236383797,\n",
       "  2.3080511205148375,\n",
       "  2.3080161078770955,\n",
       "  2.308014708638981,\n",
       "  2.3080141073779057,\n",
       "  2.3080054607266693,\n",
       "  2.307966837635288,\n",
       "  2.3079632866767144,\n",
       "  2.3079566023288627,\n",
       "  2.308009521217103,\n",
       "  2.308022984975501,\n",
       "  2.3079739096779495,\n",
       "  2.3079364195466043,\n",
       "  2.307885980013735,\n",
       "  2.3078670693032537,\n",
       "  2.3078317510569755,\n",
       "  2.3077912723145833,\n",
       "  2.307769922776656,\n",
       "  2.307728829154049,\n",
       "  2.3076504804417044,\n",
       "  2.3076481166340055,\n",
       "  2.307622247899072,\n",
       "  2.307607309958514,\n",
       "  2.3075320720672607,\n",
       "  2.3075334263402363,\n",
       "  2.3075137923907683,\n",
       "  2.3075592449341698,\n",
       "  2.3075202001844133,\n",
       "  2.307525562969121,\n",
       "  2.307485207325995,\n",
       "  2.307489683119099,\n",
       "  2.30746910825122,\n",
       "  2.307424236668481,\n",
       "  2.307385174609021,\n",
       "  2.307344126177358,\n",
       "  2.3073676088468624,\n",
       "  2.307309811529906,\n",
       "  2.3072470458778174,\n",
       "  2.307170678210515,\n",
       "  2.3071965533781817,\n",
       "  2.3071991940762135,\n",
       "  2.307145355870484,\n",
       "  2.3071157267219142,\n",
       "  2.306998539969559,\n",
       "  2.3070471795896688,\n",
       "  2.3069885542973334,\n",
       "  2.3069864388593695,\n",
       "  2.3069483280181884,\n",
       "  2.307172580641143,\n",
       "  2.307525414500745,\n",
       "  2.30749922569352,\n",
       "  2.307469113987295,\n",
       "  2.3074728190898894,\n",
       "  2.3074740165501684,\n",
       "  2.3076051296574054,\n",
       "  2.307571683611189,\n",
       "  2.307550616124097,\n",
       "  2.3075575956484164,\n",
       "  2.3075473146531187,\n",
       "  2.3075617315688572,\n",
       "  2.307549392947784,\n",
       "  2.307534336473383,\n",
       "  2.307505746114822,\n",
       "  2.3074728064062473,\n",
       "  2.3074829229768716,\n",
       "  2.3074410275114534,\n",
       "  2.3074315596963757,\n",
       "  2.307417348373768,\n",
       "  2.3073951458489455,\n",
       "  2.3073666260539114,\n",
       "  2.3073392854918033,\n",
       "  2.307349264893902,\n",
       "  2.3073004321618513,\n",
       "  2.307250569848453,\n",
       "  2.307251335264326,\n",
       "  2.3072213848610095,\n",
       "  2.3072209847824916,\n",
       "  2.307201526429918,\n",
       "  2.307165001345947,\n",
       "  2.3071505508758947,\n",
       "  2.3071464791632534,\n",
       "  2.3071341295950276,\n",
       "  2.307123989644258,\n",
       "  2.30711927042379,\n",
       "  2.307130764270651,\n",
       "  2.3070944102536965,\n",
       "  2.3070731427934437,\n",
       "  2.307042387698559,\n",
       "  2.306996400073423,\n",
       "  2.306973283300923,\n",
       "  2.3069503998556056,\n",
       "  2.3069386172992914,\n",
       "  2.3068988641103108,\n",
       "  2.3068783253554983,\n",
       "  2.3068580174249065,\n",
       "  2.3068333584585305,\n",
       "  2.3068393820621926,\n",
       "  2.3067998827720175,\n",
       "  2.306791896742534,\n",
       "  2.306835534601559,\n",
       "  2.3068045993005075,\n",
       "  2.3067845436463874,\n",
       "  2.306760199546814,\n",
       "  2.3067778866604507,\n",
       "  2.3067659016639466,\n",
       "  2.3067105363009004,\n",
       "  2.3067289985071016,\n",
       "  2.3067364982530183,\n",
       "  2.3067887565121055,\n",
       "  2.306837379700479,\n",
       "  2.306837981061418,\n",
       "  2.3068452175979908,\n",
       "  2.3068485525938183,\n",
       "  2.3068396643203792,\n",
       "  2.3068203971586154,\n",
       "  2.306795546310483,\n",
       "  2.3067751508770566,\n",
       "  2.306750824766339,\n",
       "  2.3067503979331567,\n",
       "  2.3067107102397677,\n",
       "  2.306703475873862,\n",
       "  2.306697146156907,\n",
       "  2.3067087553165577,\n",
       "  2.3067098482068613,\n",
       "  2.306693154222825,\n",
       "  2.3066717207213463,\n",
       "  2.306585987118909,\n",
       "  2.3065865230560303,\n",
       "  2.3065678580947546,\n",
       "  2.306561799686308,\n",
       "  2.306518126734727,\n",
       "  2.306497813980212,\n",
       "  2.306497005053929,\n",
       "  2.3064874788196064,\n",
       "  2.3064873649718916,\n",
       "  2.3064964592667434,\n",
       "  2.3064678403693186,\n",
       "  2.3065154209471586,\n",
       "  2.306486856687319,\n",
       "  2.306470154885216,\n",
       "  2.3064339831471443,\n",
       "  2.3064998078923735,\n",
       "  2.306494881366861,\n",
       "  2.306486243644531,\n",
       "  2.3064653726473248,\n",
       "  2.306479494726292,\n",
       "  2.3064735049293157,\n",
       "  2.306462414790008,\n",
       "  2.3064437758278205,\n",
       "  2.3064284509279913,\n",
       "  2.3064292445278807,\n",
       "  2.3064141823695254,\n",
       "  2.3064087557792665,\n",
       "  2.3063919346197896,\n",
       "  2.306371670685067,\n",
       "  2.3063695950083214,\n",
       "  2.306361172544329,\n",
       "  2.306359026080272,\n",
       "  2.3063402409647025,\n",
       "  2.306352587398566,\n",
       "  2.306337893783272,\n",
       "  2.306315215274354,\n",
       "  2.306306334464781,\n",
       "  2.306285997678996,\n",
       "  2.3062708316705165,\n",
       "  2.3062559987028566,\n",
       "  2.3062501249799303,\n",
       "  2.3062527596004427,\n",
       "  2.3062336686291274,\n",
       "  2.3062348200319693,\n",
       "  2.3062564337028646,\n",
       "  2.306236768590993,\n",
       "  2.306210269778967,\n",
       "  2.306208193859207,\n",
       "  2.306235551093676,\n",
       "  2.3062089567213975,\n",
       "  2.3061826913445085,\n",
       "  2.306176605958205,\n",
       "  2.306141026180946,\n",
       "  2.306137922706954,\n",
       "  2.3061411010056005,\n",
       "  2.306134278288728,\n",
       "  2.306111447016398,\n",
       "  2.3061319441953816,\n",
       "  2.3061129536973426,\n",
       "  2.3060932825277516,\n",
       "  2.3060707260748585,\n",
       "  2.306080220350579,\n",
       "  2.30605020125707,\n",
       "  2.306041962315138,\n",
       "  2.306021942189459,\n",
       "  2.305987966447453,\n",
       "  2.3059962826616625,\n",
       "  2.305971896543531,\n",
       "  2.305966858278241,\n",
       "  2.3059225673230674,\n",
       "  2.305929969216502,\n",
       "  2.3059845350790713,\n",
       "  2.3059498898555777,\n",
       "  2.305906385784534,\n",
       "  2.305897505118929,\n",
       "  2.305852021733806,\n",
       "  2.3058214575903757,\n",
       "  2.305836586531071,\n",
       "  2.3058082447810606,\n",
       "  2.305782565314101,\n",
       "  2.3057627341168074,\n",
       "  2.305750212870853,\n",
       "  2.305764480922999,\n",
       "  2.3056746330581794,\n",
       "  2.3055908013988473,\n",
       "  2.30555921809587,\n",
       "  2.3055197735627493,\n",
       "  2.3054150399078623,\n",
       "  2.3053486175958624,\n",
       "  2.305313761897652,\n",
       "  2.305271959566808,\n",
       "  2.30516953990884,\n",
       "  2.3051442012109393,\n",
       "  2.3050462952751554,\n",
       "  2.3050038380467375,\n",
       "  2.3049215889235497,\n",
       "  2.304926477896201,\n",
       "  2.3048363451687797,\n",
       "  2.3048169433429675,\n",
       "  2.304768656917296,\n",
       "  2.3046566318063175,\n",
       "  2.3044788767496747,\n",
       "  2.3043970985615507,\n",
       "  2.304256826243919,\n",
       "  2.3040974499687317,\n",
       "  2.303936709829245,\n",
       "  2.3038486091714154,\n",
       "  2.3036899297569056,\n",
       "  2.303390815620023,\n",
       "  2.3033141523366187,\n",
       "  2.3031630559513965,\n",
       "  2.3030842137027094,\n",
       "  2.303081120851744,\n",
       "  2.303087315818136,\n",
       "  2.302997092610782,\n",
       "  2.30290822933756,\n",
       "  2.302800858326447,\n",
       "  2.3026825424350434,\n",
       "  2.3026288011852576,\n",
       "  2.302464272229726,\n",
       "  2.302314079957565,\n",
       "  2.3022110776056217,\n",
       "  2.3022346863842973,\n",
       "  2.302135627876301,\n",
       "  2.3019371314264423,\n",
       "  2.3018362247256707,\n",
       "  2.3016726154088976,\n",
       "  2.301617719288776,\n",
       "  2.3013687501499307,\n",
       "  2.3012474849265505,\n",
       "  2.301102807026098,\n",
       "  2.3008677977102776,\n",
       "  2.3007249315383986,\n",
       "  2.3005596730281446,\n",
       "  2.3003208309996364,\n",
       "  2.300087427451733,\n",
       "  2.2998097105724056,\n",
       "  2.2996711574331687,\n",
       "  2.299379475487089,\n",
       "  2.2990699051078813,\n",
       "  2.298578057312159,\n",
       "  2.299355796446283,\n",
       "  2.299145412559693,\n",
       "  2.2987444743835668,\n",
       "  2.2988177195690467,\n",
       "  2.2987794989902253,\n",
       "  2.2984982819784254,\n",
       "  2.2984271145773048,\n",
       "  2.298204919738227,\n",
       "  2.298266871319313,\n",
       "  2.2980833615896836,\n",
       "  2.2979742470909565,\n",
       "  2.2977660564189786,\n",
       "  2.297572435763178,\n",
       "  2.297365835336881,\n",
       "  2.297196177613763,\n",
       "  2.297074717699095,\n",
       "  2.296976615547304,\n",
       "  2.296844098303053,\n",
       "  2.2966541478595337,\n",
       "  2.296536391231871,\n",
       "  2.2964013861513686,\n",
       "  2.296210851691185,\n",
       "  2.296055495329798,\n",
       "  2.2958867239625484,\n",
       "  2.295747185079275,\n",
       "  2.295635371316563,\n",
       "  2.295411474850713,\n",
       "  2.2952140105795538,\n",
       "  2.2951584007616237,\n",
       "  2.2951188296885103,\n",
       "  2.294828397772285,\n",
       "  2.2947511336194024,\n",
       "  2.2944863882640862,\n",
       "  2.2942141092249324,\n",
       "  2.2940305112995922,\n",
       "  2.2938541062672932,\n",
       "  2.293603757003987,\n",
       "  2.2934316760670823,\n",
       "  2.2931876014136847,\n",
       "  2.2929756273782202,\n",
       "  2.2927881293244416,\n",
       "  2.2925865210984884,\n",
       "  2.292379358404314,\n",
       "  2.292024723307014,\n",
       "  2.2918321956476615,\n",
       "  2.291591269036998,\n",
       "  2.2912639826859413,\n",
       "  2.29103515364907,\n",
       "  2.290882421621236,\n",
       "  2.2906604470877814,\n",
       "  2.290509282388995,\n",
       "  2.2901805439732104,\n",
       "  2.289923676586764,\n",
       "  2.294825061264201,\n",
       "  2.294672283935547],\n",
       " [2.2204387187957764,\n",
       "  2.273645043373108,\n",
       "  2.2845426400502524,\n",
       "  2.342933714389801,\n",
       "  2.329759407043457,\n",
       "  2.30804181098938,\n",
       "  2.3031833512442454,\n",
       "  2.2992112040519714,\n",
       "  2.3048333856794567,\n",
       "  2.301103138923645,\n",
       "  2.2938952445983887,\n",
       "  2.300957123438517,\n",
       "  2.2958743388836202,\n",
       "  2.2913742746625627,\n",
       "  2.290649731953939,\n",
       "  2.2938079982995987,\n",
       "  2.293985324747422,\n",
       "  2.290325893296136,\n",
       "  2.2881108208706507,\n",
       "  2.29140989780426,\n",
       "  2.2969560623168945,\n",
       "  2.3020049116828223,\n",
       "  2.301343596499899,\n",
       "  2.2985073626041412,\n",
       "  2.294539728164673,\n",
       "  2.2927798674656796,\n",
       "  2.291892228303132,\n",
       "  2.290249603135245,\n",
       "  2.2884385914638123,\n",
       "  2.2851857344309487,\n",
       "  2.2826942628429783,\n",
       "  2.2814031839370728,\n",
       "  2.2779584219961455,\n",
       "  2.2756447511560776,\n",
       "  2.273386655535017,\n",
       "  2.2707797288894653,\n",
       "  2.2703317049387337,\n",
       "  2.2691612745586194,\n",
       "  2.2674888402987747,\n",
       "  2.2655796349048614,\n",
       "  2.2647932738792607,\n",
       "  2.263495530400957,\n",
       "  2.2617914953897165,\n",
       "  2.260285832665183,\n",
       "  2.259539318084717,\n",
       "  2.257838995560356,\n",
       "  2.255749874926628,\n",
       "  2.254090537627538,\n",
       "  2.2533727178768235,\n",
       "  2.251998534202576,\n",
       "  2.2500131924947104,\n",
       "  2.2486004004111657,\n",
       "  2.2474934110101663,\n",
       "  2.2456768839447587,\n",
       "  2.2433485161174427,\n",
       "  2.2419500180653165,\n",
       "  2.239777447884543,\n",
       "  2.238593676994587,\n",
       "  2.2381782652968067,\n",
       "  2.237592351436615,\n",
       "  2.2370900677852945,\n",
       "  2.2365407982180194,\n",
       "  2.2344990571339927,\n",
       "  2.233635898679495,\n",
       "  2.2343075788938083,\n",
       "  2.2321905258930093,\n",
       "  2.2317349483717734,\n",
       "  2.230432191315819,\n",
       "  2.229058898013571,\n",
       "  2.2267363412039622,\n",
       "  2.2251296882898037,\n",
       "  2.2239182558324604,\n",
       "  2.222422420162044,\n",
       "  2.221666358612679,\n",
       "  2.2206372102101644,\n",
       "  2.219988487268749,\n",
       "  2.219362258911133,\n",
       "  2.218898730400281,\n",
       "  2.2179371556149254,\n",
       "  2.2172053277492525,\n",
       "  2.2168148829613203,\n",
       "  2.2166429002110553,\n",
       "  2.215587710759726,\n",
       "  2.2144769742375328,\n",
       "  2.2152573473313275,\n",
       "  2.2142373517502185,\n",
       "  2.213800507030268,\n",
       "  2.2129013267430393,\n",
       "  2.2111949358093606,\n",
       "  2.2105837530559964,\n",
       "  2.209557525404207,\n",
       "  2.2079975423605545,\n",
       "  2.20632609757044,\n",
       "  2.2063780997661833,\n",
       "  2.205492350929662,\n",
       "  2.2045626739660897,\n",
       "  2.2036994142630664,\n",
       "  2.2023999204440994,\n",
       "  2.2004221497160015,\n",
       "  2.199687511920929,\n",
       "  2.1989150967928444,\n",
       "  2.1976384952956556,\n",
       "  2.196288886579495,\n",
       "  2.1952646374702454,\n",
       "  2.1943663279215495,\n",
       "  2.193114127752916,\n",
       "  2.1918660012361046,\n",
       "  2.1922292135379933,\n",
       "  2.191782102672332,\n",
       "  2.1906762795014814,\n",
       "  2.190089865847751,\n",
       "  2.1893953404256274,\n",
       "  2.1898194688611325,\n",
       "  2.1889894803365073,\n",
       "  2.1877202573029892,\n",
       "  2.1865477973017198,\n",
       "  2.1852364010281033,\n",
       "  2.1843763327194474,\n",
       "  2.1835672434638527,\n",
       "  2.182793378829956,\n",
       "  2.1827234453406215,\n",
       "  2.181865750766191,\n",
       "  2.181187494014337,\n",
       "  2.1797888625052666,\n",
       "  2.178315266609192,\n",
       "  2.177141182952457,\n",
       "  2.176195558600538,\n",
       "  2.1759443851187825,\n",
       "  2.174661391465239,\n",
       "  2.1737275554583624,\n",
       "  2.1723323150445486,\n",
       "  2.172371341423555,\n",
       "  2.171530586436279,\n",
       "  2.1700991685710735,\n",
       "  2.169169290860494,\n",
       "  2.1680005604729935,\n",
       "  2.167253831007185,\n",
       "  2.165906931179157,\n",
       "  2.1643672083779206,\n",
       "  2.1630563965865544,\n",
       "  2.16206944834256,\n",
       "  2.1613399537516313,\n",
       "  2.1598188335245307,\n",
       "  2.158747342725595,\n",
       "  2.1581565043021893,\n",
       "  2.1570256548385096,\n",
       "  2.1559417272100645,\n",
       "  2.1549595811882534,\n",
       "  2.153780714777492,\n",
       "  2.152482089996338,\n",
       "  2.1512938619449438,\n",
       "  2.15210833674983,\n",
       "  2.150790753707387,\n",
       "  2.149293572871716,\n",
       "  2.1484463799384335,\n",
       "  2.1477320240094113,\n",
       "  2.1460787589382972,\n",
       "  2.146223680128025,\n",
       "  2.145636647752246,\n",
       "  2.1492368005216123,\n",
       "  2.1852605587207012,\n",
       "  2.186298609515767,\n",
       "  2.187973821821388,\n",
       "  2.1885096917792066,\n",
       "  2.192930152921966,\n",
       "  2.255877472550036,\n",
       "  2.2661864721846436,\n",
       "  2.2691888433127176,\n",
       "  2.2752076062930406,\n",
       "  2.2764921882573295,\n",
       "  2.278039192595677,\n",
       "  2.528437111959901,\n",
       "  2.5624198438115204,\n",
       "  2.6678035526440063,\n",
       "  2.760267766543797,\n",
       "  3.098960482938723,\n",
       "  3.317696260867146,\n",
       "  3.451293106159467,\n",
       "  3.5190524329020323,\n",
       "  3.6198467274506885,\n",
       "  3.6802297264172887,\n",
       "  3.7578385236499074,\n",
       "  3.899839695034131,\n",
       "  4.007892973397089,\n",
       "  4.240318331202945,\n",
       "  4.4030595921701,\n",
       "  4.877782231983654,\n",
       "  4.936865996173087,\n",
       "  4.952259242219269,\n",
       "  5.033561482554988,\n",
       "  5.132833307950285,\n",
       "  5.177218126133084,\n",
       "  5.174868368114215,\n",
       "  5.190535493118247,\n",
       "  5.274367921168988,\n",
       "  5.300270593287993,\n",
       "  5.321398475448492,\n",
       "  5.315384206747768,\n",
       "  5.3316537165761595,\n",
       "  5.351655756831169,\n",
       "  5.351502054959387,\n",
       "  5.345396945382109,\n",
       "  5.334936198929848,\n",
       "  5.325085458217883,\n",
       "  5.314502504976784,\n",
       "  5.304151836529519,\n",
       "  5.29249263903945,\n",
       "  5.285712326375338,\n",
       "  5.372012737835424,\n",
       "  5.360583872454507,\n",
       "  5.376178193996303,\n",
       "  5.377276492006374,\n",
       "  5.3886793784692255,\n",
       "  5.389478887910041,\n",
       "  5.398759085078572,\n",
       "  5.437487299243609,\n",
       "  5.6352394357804325,\n",
       "  5.6256575305527505,\n",
       "  5.629827288732137,\n",
       "  5.633249844746156,\n",
       "  5.624760224808395,\n",
       "  5.6354301797377095,\n",
       "  5.645917766831915,\n",
       "  5.652252900281122,\n",
       "  5.64723739888933,\n",
       "  5.65958700612583,\n",
       "  5.649954153577662,\n",
       "  5.6484224592384535,\n",
       "  5.649772979807125,\n",
       "  5.6713935256004335,\n",
       "  5.661966733086161,\n",
       "  5.651505054584865,\n",
       "  5.639424407430984,\n",
       "  5.703912765042395,\n",
       "  5.720243556956027,\n",
       "  5.7147829830646515,\n",
       "  5.715013571932346,\n",
       "  5.702969392307666,\n",
       "  5.691112477909072,\n",
       "  5.677785249054432,\n",
       "  5.671462446327526,\n",
       "  5.662249166610812,\n",
       "  5.652626291224005,\n",
       "  5.639710561662424,\n",
       "  5.627770104213637,\n",
       "  5.636202997793027,\n",
       "  5.625257653746045,\n",
       "  5.613826005208876,\n",
       "  5.639961203896855,\n",
       "  5.629109918117523,\n",
       "  5.629259863222738,\n",
       "  5.618576251798206,\n",
       "  5.611168872226369,\n",
       "  5.598181024780423,\n",
       "  5.594340233241811,\n",
       "  5.592265397775918,\n",
       "  5.58464604361048,\n",
       "  5.573594056820685,\n",
       "  5.566732491765704,\n",
       "  5.556992630316661,\n",
       "  5.54787362626686,\n",
       "  5.535513330506914,\n",
       "  5.524418530355388,\n",
       "  5.519095824071855,\n",
       "  5.508742885319692,\n",
       "  5.496692075317068,\n",
       "  5.500399009565289,\n",
       "  5.494502778818358,\n",
       "  5.4828241753312295,\n",
       "  5.471369792355431,\n",
       "  5.45989990366341,\n",
       "  5.448296671842828,\n",
       "  5.436902120873168,\n",
       "  5.425412845872614,\n",
       "  5.41405433698134,\n",
       "  5.402779559726301,\n",
       "  5.392633304268875,\n",
       "  5.385724843405991,\n",
       "  5.389820853014573,\n",
       "  5.384282373104777,\n",
       "  5.374334110059772,\n",
       "  5.3655437801746615,\n",
       "  5.354735170152078,\n",
       "  5.344430013021952,\n",
       "  5.3344437410956935,\n",
       "  5.3266394475956895,\n",
       "  5.3348875465293375,\n",
       "  5.324535521782106,\n",
       "  5.315134382990405,\n",
       "  5.304783899619662,\n",
       "  5.299168533885602,\n",
       "  5.291532921056225,\n",
       "  5.2814937553308114,\n",
       "  5.271376754556384,\n",
       "  5.261321738210775,\n",
       "  5.252440497279167,\n",
       "  5.249226910096628,\n",
       "  5.240621072733962,\n",
       "  5.230808481723568,\n",
       "  5.228873151540756,\n",
       "  5.219190482285332,\n",
       "  5.20958178603886,\n",
       "  5.200619472922272,\n",
       "  5.1910362820092,\n",
       "  5.18271068627717,\n",
       "  5.173503434346392,\n",
       "  5.171881490499267,\n",
       "  5.163967759191216,\n",
       "  5.154591916448476,\n",
       "  5.1461186658951545,\n",
       "  5.137293625874535,\n",
       "  5.131327005915153,\n",
       "  5.122397180944205,\n",
       "  5.114810751122274,\n",
       "  5.1058819305329095,\n",
       "  5.097013390894178,\n",
       "  5.092202249385581,\n",
       "  5.086160730640843,\n",
       "  5.0784054075288925,\n",
       "  5.075173811987042,\n",
       "  5.068031707285349,\n",
       "  5.059442951442292,\n",
       "  5.0509130390066845,\n",
       "  5.051773049581198,\n",
       "  5.047004447716933,\n",
       "  5.039459393433998,\n",
       "  5.031089213645422,\n",
       "  5.022775303663277,\n",
       "  5.014499577707795,\n",
       "  5.006887299003023,\n",
       "  5.0017292409505005,\n",
       "  4.993951750447951,\n",
       "  4.985982976876222,\n",
       "  4.978188616429974,\n",
       "  4.9706476827165975,\n",
       "  4.9627749518979165,\n",
       "  4.954880705573085,\n",
       "  4.946999380221734,\n",
       "  4.939215335522429,\n",
       "  4.931464720824185,\n",
       "  4.923758755331515,\n",
       "  4.916099501980676,\n",
       "  4.912922234646433,\n",
       "  4.905495842875436,\n",
       "  4.898711921512216,\n",
       "  4.891216328722893,\n",
       "  4.883757722137298,\n",
       "  4.876316514165922,\n",
       "  4.868941474097506,\n",
       "  4.861673273018428,\n",
       "  4.854412042517268,\n",
       "  4.847168920053677,\n",
       "  4.839913666417173,\n",
       "  4.838203622459692,\n",
       "  4.8311849389277715,\n",
       "  4.8281724757692785,\n",
       "  4.8252229406720115,\n",
       "  4.818984030012312,\n",
       "  4.812011153917127,\n",
       "  4.805040583014488,\n",
       "  4.798092016222735,\n",
       "  4.792310563569569,\n",
       "  4.7871154579577695,\n",
       "  4.780287771107076,\n",
       "  4.773579644830259,\n",
       "  4.7680082988869295,\n",
       "  4.761401213807046,\n",
       "  4.769212511246619,\n",
       "  4.76260753408034,\n",
       "  4.756425042732342,\n",
       "  4.750752002081138,\n",
       "  4.745772738931,\n",
       "  4.739651452759955,\n",
       "  4.733464752607804,\n",
       "  4.727028342882792,\n",
       "  4.720542287255856,\n",
       "  4.714145141507966,\n",
       "  4.7077703561101645,\n",
       "  4.701427899753198,\n",
       "  4.695111891156749,\n",
       "  4.688888847984354,\n",
       "  4.685101901361455,\n",
       "  4.67891151070906,\n",
       "  4.672722587051491,\n",
       "  4.666571418031469,\n",
       "  4.661882004280782,\n",
       "  4.655788313510806,\n",
       "  4.65034538108049,\n",
       "  4.644376095585468,\n",
       "  4.638375365734101,\n",
       "  4.632712835850923,\n",
       "  4.626803051148142,\n",
       "  4.620888079395731,\n",
       "  4.61500651309938,\n",
       "  4.6091563596001155,\n",
       "  4.603340131766869,\n",
       "  4.597533995618748,\n",
       "  4.59366282236636,\n",
       "  4.587919624526997,\n",
       "  4.582204614579678,\n",
       "  4.576483719069464,\n",
       "  4.570836771483445,\n",
       "  4.565285864598106,\n",
       "  4.559754631601938,\n",
       "  4.554721923816351,\n",
       "  4.551388602832268,\n",
       "  4.545813675008769,\n",
       "  4.540313194487609,\n",
       "  4.535932150038647,\n",
       "  4.531533882966856,\n",
       "  4.526349112645263,\n",
       "  4.520944780805736,\n",
       "  4.51695969289498,\n",
       "  4.5118731418669515,\n",
       "  4.507930665131075,\n",
       "  4.505507675787578,\n",
       "  4.501211720118992,\n",
       "  4.496054630245318,\n",
       "  4.490899279749194,\n",
       "  4.485995679526102,\n",
       "  4.481364449809113,\n",
       "  4.476624539960617,\n",
       "  4.471962261143587,\n",
       "  4.466843626128052,\n",
       "  4.46289809367236,\n",
       "  4.457865277086625,\n",
       "  4.452819061223461,\n",
       "  4.447805114717127,\n",
       "  4.443196685997756,\n",
       "  4.438344811561496,\n",
       "  4.433440173861599,\n",
       "  4.428543059638253,\n",
       "  4.42363471164439,\n",
       "  4.41875060555023,\n",
       "  4.414727414613482,\n",
       "  4.40996546947628,\n",
       "  4.405146909523883,\n",
       "  4.400355614755796,\n",
       "  4.395645725699927,\n",
       "  4.39088591418483,\n",
       "  4.386155477456765,\n",
       "  4.381483285944926,\n",
       "  4.37865981641257,\n",
       "  4.373987648669664,\n",
       "  4.3694165344988365,\n",
       "  4.364982010270448,\n",
       "  4.360367234921295,\n",
       "  4.356191753542849,\n",
       "  4.351618352870899,\n",
       "  4.347065550221338,\n",
       "  4.3425201256893695,\n",
       "  4.3380126681475515,\n",
       "  4.333528517887292,\n",
       "  4.329050068550698,\n",
       "  4.324963110881847,\n",
       "  4.320718531284416,\n",
       "  4.316297605992407,\n",
       "  4.31190610634708,\n",
       "  4.307524458515358,\n",
       "  4.303232810549114,\n",
       "  4.298888750293508,\n",
       "  4.29457698781769,\n",
       "  4.2905700075446145,\n",
       "  4.286287675386872,\n",
       "  4.282030207880082,\n",
       "  4.278111140359624,\n",
       "  4.273948020291788,\n",
       "  4.2697982627611895,\n",
       "  4.266649272410075],\n",
       " [2.3124918937683105,\n",
       "  2.3674296140670776,\n",
       "  2.3458988666534424,\n",
       "  2.340446710586548,\n",
       "  2.332810974121094,\n",
       "  2.3279546101888022,\n",
       "  2.324861322130476,\n",
       "  2.322252541780472,\n",
       "  2.3200445969899497,\n",
       "  2.318762683868408,\n",
       "  2.3314120552756568,\n",
       "  2.337904771169027,\n",
       "  2.335170158973107,\n",
       "  2.3330427748816356,\n",
       "  2.3310577074686685,\n",
       "  2.329707533121109,\n",
       "  2.328355733086081,\n",
       "  2.3272365199195013,\n",
       "  2.3257407640155994,\n",
       "  2.3244433641433715,\n",
       "  2.3420297531854537,\n",
       "  2.340243534608321,\n",
       "  2.3380381957344385,\n",
       "  2.338596353928248,\n",
       "  2.33730170249939,\n",
       "  2.354982513647813,\n",
       "  2.3530004730931036,\n",
       "  2.351258933544159,\n",
       "  2.350608866790245,\n",
       "  2.3490037043889362,\n",
       "  2.3474319827172065,\n",
       "  2.346040077507496,\n",
       "  2.344607721675526,\n",
       "  2.3435117847779217,\n",
       "  2.3422894750322616,\n",
       "  2.341235021750132,\n",
       "  2.3401476305884286,\n",
       "  2.339176159155996,\n",
       "  2.338248234528762,\n",
       "  2.33717594742775,\n",
       "  2.340485305320926,\n",
       "  2.3395074038278487,\n",
       "  2.338702074317045,\n",
       "  2.33787325295535,\n",
       "  2.337594011094835,\n",
       "  2.340354183445806,\n",
       "  2.3412926349234073,\n",
       "  2.340261568625768,\n",
       "  2.3394720019126427,\n",
       "  2.338698749542236,\n",
       "  2.3378405570983887,\n",
       "  2.3376580201662502,\n",
       "  2.338003540938755,\n",
       "  2.337371971872118,\n",
       "  2.336777331612327,\n",
       "  2.3375192880630493,\n",
       "  2.337364807463529,\n",
       "  2.336630891109335,\n",
       "  2.336384963181059,\n",
       "  2.3357431928316754,\n",
       "  2.3351404862325698,\n",
       "  2.3349497395177043,\n",
       "  2.3352344452388705,\n",
       "  2.3347518779337406,\n",
       "  2.334192316348736,\n",
       "  2.3337430628863247,\n",
       "  2.333219670537692,\n",
       "  2.3327645273769604,\n",
       "  2.3323894445446953,\n",
       "  2.3320420742034913,\n",
       "  2.3317103822466354,\n",
       "  2.3313449687427945,\n",
       "  2.3309486238923793,\n",
       "  2.330677657514005,\n",
       "  2.3303130944569905,\n",
       "  2.331739867988386,\n",
       "  2.3313788903224,\n",
       "  2.331039303388351,\n",
       "  2.3306724632842633,\n",
       "  2.3301247626543047,\n",
       "  2.3299820158216686,\n",
       "  2.329685594977402,\n",
       "  2.3294316257338927,\n",
       "  2.3291396413530623,\n",
       "  2.330376016392427,\n",
       "  2.330073647720869,\n",
       "  2.3297798359531097,\n",
       "  2.330639885230498,\n",
       "  2.3303281751911293,\n",
       "  2.3299547831217446,\n",
       "  2.3303504409370843,\n",
       "  2.333103843357252,\n",
       "  2.332800096081149,\n",
       "  2.3327149228846773,\n",
       "  2.332343866950587,\n",
       "  2.332030681272348,\n",
       "  2.3317781748230924,\n",
       "  2.3314936063727556,\n",
       "  2.331193447113037,\n",
       "  2.3310617876052855,\n",
       "  2.3307204175703595,\n",
       "  2.330433716960982,\n",
       "  2.3301609002270744,\n",
       "  2.3298911177195034,\n",
       "  2.329667822519938,\n",
       "  2.329452046808207,\n",
       "  2.3292075763238924,\n",
       "  2.3290682059747203,\n",
       "  2.328853060346131,\n",
       "  2.3356530883095483,\n",
       "  2.3353475085249893,\n",
       "  2.3353509413344518,\n",
       "  2.3352766902045867,\n",
       "  2.334981763572024,\n",
       "  2.335112356102985,\n",
       "  2.3348506689071655,\n",
       "  2.33461605789315,\n",
       "  2.334338208376351,\n",
       "  2.3347312542570737,\n",
       "  2.3344925959904987,\n",
       "  2.334231999294817,\n",
       "  2.33397946201387,\n",
       "  2.3371465903956716,\n",
       "  2.3368773460388184,\n",
       "  2.336623229980469,\n",
       "  2.3363574497283452,\n",
       "  2.336088477157232,\n",
       "  2.3358987104147673,\n",
       "  2.3356296720430834,\n",
       "  2.335381632584792,\n",
       "  2.3351383172828735,\n",
       "  2.3349131129004737,\n",
       "  2.3346780045588216,\n",
       "  2.334443690171882,\n",
       "  2.3341788397894967,\n",
       "  2.333958708188113,\n",
       "  2.333967003509076,\n",
       "  2.335222921509674,\n",
       "  2.3357921401373773,\n",
       "  2.335531336920602,\n",
       "  2.3397531137398793,\n",
       "  2.342819633618207,\n",
       "  2.3425396672495595,\n",
       "  2.342284989025858,\n",
       "  2.3419688635858997,\n",
       "  2.341680167472526,\n",
       "  2.342452808302276,\n",
       "  2.3426791945019283,\n",
       "  2.3442779387403654,\n",
       "  2.344009737968445,\n",
       "  2.3437671487694542,\n",
       "  2.343523466273358,\n",
       "  2.3449991886911827,\n",
       "  2.345016179146705,\n",
       "  2.3447816048899006,\n",
       "  2.3445211969889126,\n",
       "  2.3443868433593944,\n",
       "  2.345423304581944,\n",
       "  2.3451930606890024,\n",
       "  2.3449463441967966,\n",
       "  2.344723744422012,\n",
       "  2.3444822099473743,\n",
       "  2.3455543956873606,\n",
       "  2.345302363721336,\n",
       "  2.345051045851274,\n",
       "  2.3448803108858773,\n",
       "  2.344611185039589,\n",
       "  2.3443866939771745,\n",
       "  2.3441608304808126,\n",
       "  2.344045805931091,\n",
       "  2.343839471103155,\n",
       "  2.343619458897169,\n",
       "  2.343365973819887,\n",
       "  2.3435564876972945,\n",
       "  2.343320258004325,\n",
       "  2.3431899777867575,\n",
       "  2.342984180665959,\n",
       "  2.343428033121516,\n",
       "  2.343234347231561,\n",
       "  2.343002944522434,\n",
       "  2.3427836974022798,\n",
       "  2.3425474062070744,\n",
       "  2.3423835488616445,\n",
       "  2.342607803966688,\n",
       "  2.342387143985645,\n",
       "  2.3421779089076544,\n",
       "  2.341973037005746,\n",
       "  2.3417611756223313,\n",
       "  2.3415910024491566,\n",
       "  2.3413945198059083,\n",
       "  2.341199635211086,\n",
       "  2.340995574990908,\n",
       "  2.3417942536309595,\n",
       "  2.3415946640919163,\n",
       "  2.341384831452981,\n",
       "  2.3414232864671822,\n",
       "  2.3412254280245244,\n",
       "  2.3439914048320114,\n",
       "  2.3441110759524246,\n",
       "  2.3439037656784056,\n",
       "  2.343694192260059,\n",
       "  2.343501433287517,\n",
       "  2.343315108069058,\n",
       "  2.3431384119333005,\n",
       "  2.342978912446557,\n",
       "  2.342767716611473,\n",
       "  2.342561187375571,\n",
       "  2.3434725541334887,\n",
       "  2.3432779072574452,\n",
       "  2.343079956372579,\n",
       "  2.343942439951603,\n",
       "  2.3437301201640435,\n",
       "  2.3445407112999144,\n",
       "  2.344434171079475,\n",
       "  2.344359263708425,\n",
       "  2.3443519439962177,\n",
       "  2.3456037033538113,\n",
       "  2.3461267051346804,\n",
       "  2.3511359887580348,\n",
       "  2.3508997960524125,\n",
       "  2.3506202147557187,\n",
       "  2.3509296801713138,\n",
       "  2.3507417702354125,\n",
       "  2.3537428889955794,\n",
       "  2.353514870537652,\n",
       "  2.353287204176979,\n",
       "  2.3530521571373626,\n",
       "  2.3528700763719126,\n",
       "  2.352544088030486,\n",
       "  2.352344891299372,\n",
       "  2.3521552756751256,\n",
       "  2.352255526287802,\n",
       "  2.352151037797396,\n",
       "  2.3520629833906126,\n",
       "  2.3518682743640658,\n",
       "  2.351931137553716,\n",
       "  2.3517375495363386,\n",
       "  2.351528586459761,\n",
       "  2.3513354975808114,\n",
       "  2.3511475612719854,\n",
       "  2.350955924552506,\n",
       "  2.3509953012151166,\n",
       "  2.350897432845316,\n",
       "  2.3507284297317756,\n",
       "  2.3505220306162933,\n",
       "  2.3503260263582555,\n",
       "  2.3501391237081304,\n",
       "  2.349953355327729,\n",
       "  2.3497684901976683,\n",
       "  2.3497343072891237,\n",
       "  2.34974824764814,\n",
       "  2.3496783356817943,\n",
       "  2.3494935082823862,\n",
       "  2.3492958329793976,\n",
       "  2.349127701217053,\n",
       "  2.3490986535325646,\n",
       "  2.3491428677673936,\n",
       "  2.348970834598985,\n",
       "  2.3487939687309116,\n",
       "  2.3486317542883066,\n",
       "  2.3484578059550905,\n",
       "  2.348285149071963,\n",
       "  2.3481069517679543,\n",
       "  2.34792822599411,\n",
       "  2.3477795780829664,\n",
       "  2.3476055663331112,\n",
       "  2.3474417759684587,\n",
       "  2.3472944062147567,\n",
       "  2.347086943658311,\n",
       "  2.3470153243453415,\n",
       "  2.346848500170831,\n",
       "  2.346689110293108,\n",
       "  2.3465236988696425,\n",
       "  2.3463640334832405,\n",
       "  2.346213259263472,\n",
       "  2.3460547250250112,\n",
       "  2.345900392704492,\n",
       "  2.3457409117719252,\n",
       "  2.345645991704797,\n",
       "  2.345494420187814,\n",
       "  2.3453441073461785,\n",
       "  2.345193403832456,\n",
       "  2.345040323877503,\n",
       "  2.344906760773189,\n",
       "  2.3447988133681448,\n",
       "  2.344777251457001,\n",
       "  2.3446197783905456,\n",
       "  2.3445237088534565,\n",
       "  2.344366507546712,\n",
       "  2.344215184244616,\n",
       "  2.344910584774214,\n",
       "  2.3447622697647303,\n",
       "  2.3446252541330486,\n",
       "  2.3444888243058912,\n",
       "  2.3443466776508397,\n",
       "  2.3442022607133195,\n",
       "  2.344050575988461,\n",
       "  2.3439092700113386,\n",
       "  2.343781126781451,\n",
       "  2.343649606704712,\n",
       "  2.3435178547602553,\n",
       "  2.3433975415514006,\n",
       "  2.343280530211949,\n",
       "  2.34315629617164,\n",
       "  2.3430207565182544,\n",
       "  2.3428903903836518,\n",
       "  2.3427505920298324,\n",
       "  2.342641061002558,\n",
       "  2.342799677432162,\n",
       "  2.342667435061547,\n",
       "  2.3425444498706094,\n",
       "  2.3427364612237,\n",
       "  2.3426128271669624,\n",
       "  2.34247659877607,\n",
       "  2.3424056567842997,\n",
       "  2.342552744889561,\n",
       "  2.3424430442533284,\n",
       "  2.3423792918523154,\n",
       "  2.3423547475689257,\n",
       "  2.3421766445040704,\n",
       "  2.3420693436144298,\n",
       "  2.3419291773197815,\n",
       "  2.3418110612745258,\n",
       "  2.3420007523195245,\n",
       "  2.342318275158222,\n",
       "  2.3427032049448213,\n",
       "  2.3425786517082003,\n",
       "  2.342457247943413,\n",
       "  2.342350280031245,\n",
       "  2.3422420219941573,\n",
       "  2.3421709818422256,\n",
       "  2.3420613271644317,\n",
       "  2.3421331626158937,\n",
       "  2.3420930394155537,\n",
       "  2.341946253136023,\n",
       "  2.341878443246796,\n",
       "  2.341778515354462,\n",
       "  2.341671835741348,\n",
       "  2.3418605974641875,\n",
       "  2.3417608604711644,\n",
       "  2.341694888481297,\n",
       "  2.341639538257443,\n",
       "  2.3415223697184127,\n",
       "  2.3414065657660017,\n",
       "  2.3412874242533808,\n",
       "  2.3411747017347744,\n",
       "  2.341073651822225,\n",
       "  2.340968643796855,\n",
       "  2.3408702321585406,\n",
       "  2.3407907724380492,\n",
       "  2.34106522475892,\n",
       "  2.3409761610356243,\n",
       "  2.3408696847326693,\n",
       "  2.340769610162509,\n",
       "  2.3406671712096307,\n",
       "  2.3405606378330273,\n",
       "  2.3404579957326255,\n",
       "  2.3403515029885917,\n",
       "  2.3402523781927846,\n",
       "  2.340147067440881,\n",
       "  2.3400486143011796,\n",
       "  2.3399350623399515,\n",
       "  2.3398293535899852,\n",
       "  2.339721068576142,\n",
       "  2.339623186686268,\n",
       "  2.3395166827029867,\n",
       "  2.3394363472182356,\n",
       "  2.3393120396396387,\n",
       "  2.3392336601164283,\n",
       "  2.3391673345823545,\n",
       "  2.3390741586042543,\n",
       "  2.338971556514822,\n",
       "  2.3388736139353736,\n",
       "  2.3387800155476453,\n",
       "  2.338670496622721,\n",
       "  2.338571499002741,\n",
       "  2.338480702129536,\n",
       "  2.3383870478029603,\n",
       "  2.3384544333556083,\n",
       "  2.3383715623303463,\n",
       "  2.338271584097795,\n",
       "  2.338172801502088,\n",
       "  2.338076016299096,\n",
       "  2.3379411082714796,\n",
       "  2.3381943077236027,\n",
       "  2.3381652825854604,\n",
       "  2.338081021641576,\n",
       "  2.337988189200765,\n",
       "  2.3379027880249414,\n",
       "  2.337925585110982,\n",
       "  2.3378343258977243,\n",
       "  2.3377456233209495,\n",
       "  2.337676020978971,\n",
       "  2.3375878182764587,\n",
       "  2.33753747276113,\n",
       "  2.337441603342692,\n",
       "  2.3373872242886713,\n",
       "  2.337319462143596,\n",
       "  2.337439159402871,\n",
       "  2.3373631298542024,\n",
       "  2.337270648104889,\n",
       "  2.3371569226630293,\n",
       "  2.3370764308768526,\n",
       "  2.3370623553153314,\n",
       "  2.3371973820674565,\n",
       "  2.3373026513113766,\n",
       "  2.337218962957584,\n",
       "  2.3371558890623203,\n",
       "  2.3371319129589425,\n",
       "  2.3370485003401593,\n",
       "  2.336946403313147,\n",
       "  2.3368577407401743,\n",
       "  2.336831610658844,\n",
       "  2.336740101593128,\n",
       "  2.336666495541492,\n",
       "  2.3370186302524347,\n",
       "  2.3375557235104862,\n",
       "  2.3378559601934334,\n",
       "  2.3377739939314086,\n",
       "  2.3378598758152553,\n",
       "  2.3377844199998363,\n",
       "  2.337727694149831,\n",
       "  2.33763954430889,\n",
       "  2.337546748372744,\n",
       "  2.337739496792064,\n",
       "  2.337647636731466,\n",
       "  2.337574977785419,\n",
       "  2.337504156282015,\n",
       "  2.3374300019724386,\n",
       "  2.3373511746872304,\n",
       "  2.3372529852971122,\n",
       "  2.3371796078152127,\n",
       "  2.337098953079682,\n",
       "  2.3370263939079603,\n",
       "  2.336948570711859,\n",
       "  2.3369538696534042,\n",
       "  2.3368686183911986,\n",
       "  2.3370775860738537,\n",
       "  2.336998178095372,\n",
       "  2.336912177367644,\n",
       "  2.336847876745557,\n",
       "  2.336830391063949,\n",
       "  2.336758232009061,\n",
       "  2.3366847822258063,\n",
       "  2.3366143087322793,\n",
       "  2.3365341836561537,\n",
       "  2.336485507504252,\n",
       "  2.336478582982506,\n",
       "  2.3364055305387503,\n",
       "  2.33632041560279,\n",
       "  2.3363289526455153,\n",
       "  2.3362601135684327,\n",
       "  2.336179825380675,\n",
       "  2.3362631298897023,\n",
       "  2.3361938345563282,\n",
       "  2.336114072485974,\n",
       "  2.3360419435104602,\n",
       "  2.3359693569907973,\n",
       "  2.3358893908706366,\n",
       "  2.3358149544052456,\n",
       "  2.335739968397095,\n",
       "  2.3356598455668527,\n",
       "  2.3355948219546487,\n",
       "  2.3355210742046095,\n",
       "  2.335453746139362,\n",
       "  2.3353968771742135,\n",
       "  2.338729663375103,\n",
       "  2.33865908985464,\n",
       "  2.338598860168457],\n",
       " [2.3030929565429688,\n",
       "  2.3347880840301514,\n",
       "  2.3252347310384116,\n",
       "  2.320848762989044,\n",
       "  2.31734356880188,\n",
       "  2.3144161701202393,\n",
       "  2.312396390097482,\n",
       "  2.311067223548889,\n",
       "  2.31152704026964,\n",
       "  2.3103460311889648,\n",
       "  2.3093091357838023,\n",
       "  2.308817366758982,\n",
       "  2.3085062137016883,\n",
       "  2.3082770790372575,\n",
       "  2.3079474131266275,\n",
       "  2.3076732456684113,\n",
       "  2.3096923968371224,\n",
       "  2.3108935488594904,\n",
       "  2.311544142271343,\n",
       "  2.3110973834991455,\n",
       "  2.3107292311532155,\n",
       "  2.310433279384266,\n",
       "  2.310177284738292,\n",
       "  2.311000088850657,\n",
       "  2.310691270828247,\n",
       "  2.3103162050247192,\n",
       "  2.310140742195977,\n",
       "  2.3100310564041138,\n",
       "  2.310138159784777,\n",
       "  2.3110137303670246,\n",
       "  2.310663100211851,\n",
       "  2.310493029654026,\n",
       "  2.3102368874983354,\n",
       "  2.3105937663246605,\n",
       "  2.310306358337402,\n",
       "  2.310164862208896,\n",
       "  2.313400345879632,\n",
       "  2.313464967828048,\n",
       "  2.3132063486637215,\n",
       "  2.312917786836624,\n",
       "  2.3126907406783683,\n",
       "  2.3123714412961687,\n",
       "  2.312129475349604,\n",
       "  2.3119114420630713,\n",
       "  2.3113250626458064,\n",
       "  2.312166908512945,\n",
       "  2.312517927048054,\n",
       "  2.3124623696009317,\n",
       "  2.312267979797052,\n",
       "  2.313907279968262,\n",
       "  2.3135795266020533,\n",
       "  2.3136908274430494,\n",
       "  2.3135739227510848,\n",
       "  2.313371671570672,\n",
       "  2.313137483596802,\n",
       "  2.3149430794375285,\n",
       "  2.3147053258460866,\n",
       "  2.3145810242356926,\n",
       "  2.314403744067176,\n",
       "  2.314120133717855,\n",
       "  2.313888936746316,\n",
       "  2.313794555202607,\n",
       "  2.3135978494371687,\n",
       "  2.3134151808917522,\n",
       "  2.313255233031053,\n",
       "  2.313026178966869,\n",
       "  2.313632242715181,\n",
       "  2.3136706772972557,\n",
       "  2.313566539598548,\n",
       "  2.313488984107971,\n",
       "  2.3134030657754816,\n",
       "  2.313321202993393,\n",
       "  2.316671567420437,\n",
       "  2.3165134030419425,\n",
       "  2.3163681475321454,\n",
       "  2.3162015676498413,\n",
       "  2.316171831898875,\n",
       "  2.315997872597132,\n",
       "  2.3158722648137733,\n",
       "  2.3157185852527618,\n",
       "  2.315568373527056,\n",
       "  2.315565405822382,\n",
       "  2.315209833972425,\n",
       "  2.3150659004847207,\n",
       "  2.3148248756633087,\n",
       "  2.3146890263224758,\n",
       "  2.3145854171665237,\n",
       "  2.314635772596706,\n",
       "  2.314545543006297,\n",
       "  2.314758637216356,\n",
       "  2.3146385779747596,\n",
       "  2.3144701874774434,\n",
       "  2.314352532868744,\n",
       "  2.314811054696428,\n",
       "  2.3148838269083125,\n",
       "  2.3148520117004714,\n",
       "  2.314738959381261,\n",
       "  2.3146362620957044,\n",
       "  2.3150907983683577,\n",
       "  2.315140597820282,\n",
       "  2.315038093245856,\n",
       "  2.315727610214084,\n",
       "  2.3177923600650527,\n",
       "  2.3190430998802185,\n",
       "  2.3193019503638856,\n",
       "  2.319144896741183,\n",
       "  2.320684963297621,\n",
       "  2.320439652160362,\n",
       "  2.320863872493079,\n",
       "  2.3212419921701604,\n",
       "  2.321140312933707,\n",
       "  2.320992484688759,\n",
       "  2.3208376158655217,\n",
       "  2.320697303403888,\n",
       "  2.320515487505042,\n",
       "  2.3203423680930304,\n",
       "  2.3201877541012235,\n",
       "  2.3200514013484375,\n",
       "  2.3198950090328183,\n",
       "  2.3197432418664294,\n",
       "  2.3196204713553437,\n",
       "  2.319501646229478,\n",
       "  2.31926795137607,\n",
       "  2.3191550124076104,\n",
       "  2.3190348358154296,\n",
       "  2.3189196359543574,\n",
       "  2.319443856637309,\n",
       "  2.3194372039288282,\n",
       "  2.319652376248855,\n",
       "  2.320868389423077,\n",
       "  2.3208135393739657,\n",
       "  2.320733399102182,\n",
       "  2.3214344368841413,\n",
       "  2.321308121752383,\n",
       "  2.321254920959473,\n",
       "  2.3210909576977,\n",
       "  2.320975883163675,\n",
       "  2.3246923408646514,\n",
       "  2.324517299803041,\n",
       "  2.3243275472096037,\n",
       "  2.3243556479190257,\n",
       "  2.3243751274028295,\n",
       "  2.3242071891998077,\n",
       "  2.3240118987030454,\n",
       "  2.3240702448220087,\n",
       "  2.325153847263284,\n",
       "  2.3249642865187456,\n",
       "  2.324846905630988,\n",
       "  2.3246634886568827,\n",
       "  2.324789141019185,\n",
       "  2.3247672911511352,\n",
       "  2.3250350810979543,\n",
       "  2.3248972939509973,\n",
       "  2.325285080191377,\n",
       "  2.3255266189575194,\n",
       "  2.3253556795609303,\n",
       "  2.3252129949581852,\n",
       "  2.3250975125952613,\n",
       "  2.3249994403911085,\n",
       "  2.3248414188623427,\n",
       "  2.3247020052086493,\n",
       "  2.325888437989317,\n",
       "  2.325738184291161,\n",
       "  2.325590879451938,\n",
       "  2.325432949355154,\n",
       "  2.3254086554768576,\n",
       "  2.325270450043821,\n",
       "  2.3253049963996526,\n",
       "  2.3254091471609986,\n",
       "  2.325300704731661,\n",
       "  2.3252113939028733,\n",
       "  2.325093444003615,\n",
       "  2.3253814664190213,\n",
       "  2.325228332102984,\n",
       "  2.3251212324414934,\n",
       "  2.3250255584716797,\n",
       "  2.3249451534896246,\n",
       "  2.3248467150698886,\n",
       "  2.3253229343691353,\n",
       "  2.32515144083235,\n",
       "  2.327382572448056,\n",
       "  2.327648464140001,\n",
       "  2.3275340137585916,\n",
       "  2.3307823797930842,\n",
       "  2.330617024447467,\n",
       "  2.330466365301481,\n",
       "  2.330322788360922,\n",
       "  2.3301212229627244,\n",
       "  2.3300675979997747,\n",
       "  2.3298602217122126,\n",
       "  2.329725401563794,\n",
       "  2.3297901786863804,\n",
       "  2.3296404230779935,\n",
       "  2.3294857089052496,\n",
       "  2.329342423952543,\n",
       "  2.3292202925195498,\n",
       "  2.3291213802879835,\n",
       "  2.328958658256916,\n",
       "  2.328875292485683,\n",
       "  2.328751127719879,\n",
       "  2.3286074050030305,\n",
       "  2.3285950929811685,\n",
       "  2.3284703428522118,\n",
       "  2.3283338593501672,\n",
       "  2.328258118978361,\n",
       "  2.3283564859223596,\n",
       "  2.328241191624443,\n",
       "  2.328141907086739,\n",
       "  2.328027355613891,\n",
       "  2.327965985025678,\n",
       "  2.3278525531009477,\n",
       "  2.327727498873225,\n",
       "  2.3276148424461973,\n",
       "  2.327656901885416,\n",
       "  2.3275401403737623,\n",
       "  2.327428961241687,\n",
       "  2.327304140213997,\n",
       "  2.3271964285351814,\n",
       "  2.3270921826906945,\n",
       "  2.326994531804865,\n",
       "  2.3268947892598977,\n",
       "  2.3267625387724453,\n",
       "  2.326667731118309,\n",
       "  2.326567585979189,\n",
       "  2.3264694023132324,\n",
       "  2.326374820903339,\n",
       "  2.326398873644253,\n",
       "  2.326310144181837,\n",
       "  2.3262053577139907,\n",
       "  2.326179539639017,\n",
       "  2.326166393436911,\n",
       "  2.326115378018083,\n",
       "  2.326051500222202,\n",
       "  2.325971029762529,\n",
       "  2.3258645301169536,\n",
       "  2.325762736595283,\n",
       "  2.325681469108485,\n",
       "  2.3255838316027857,\n",
       "  2.32549014051589,\n",
       "  2.3253964970509213,\n",
       "  2.3253046298917397,\n",
       "  2.3252197366115475,\n",
       "  2.325138968204765,\n",
       "  2.3250390340070255,\n",
       "  2.324961303204906,\n",
       "  2.3248798430450566,\n",
       "  2.3249044080494867,\n",
       "  2.3248191312436135,\n",
       "  2.3247367493120064,\n",
       "  2.324690408706665,\n",
       "  2.324623892506755,\n",
       "  2.3245218604330034,\n",
       "  2.3244455360141196,\n",
       "  2.324354535951389,\n",
       "  2.3242790502660413,\n",
       "  2.324212586507201,\n",
       "  2.324139591320943,\n",
       "  2.3240768003833385,\n",
       "  2.3239844149144,\n",
       "  2.3238866796860327,\n",
       "  2.323788288452616,\n",
       "  2.3237039860878284,\n",
       "  2.323635373278716,\n",
       "  2.3236454056971,\n",
       "  2.3235571339445293,\n",
       "  2.323627647600676,\n",
       "  2.3235234089112016,\n",
       "  2.323932475118495,\n",
       "  2.323870868044715,\n",
       "  2.3238010106263336,\n",
       "  2.3237371603061354,\n",
       "  2.323667843552197,\n",
       "  2.3235678332192555,\n",
       "  2.323486932872856,\n",
       "  2.323402805328369,\n",
       "  2.3233121253442075,\n",
       "  2.3232441309987424,\n",
       "  2.323163819827622,\n",
       "  2.323080970394996,\n",
       "  2.322990070922034,\n",
       "  2.322895314769813,\n",
       "  2.322804833980317,\n",
       "  2.322758544038968,\n",
       "  2.3230386032185084,\n",
       "  2.322963995682566,\n",
       "  2.322918123298592,\n",
       "  2.3228443690708707,\n",
       "  2.322785659796662,\n",
       "  2.323401131844438,\n",
       "  2.3233538422091256,\n",
       "  2.323282306546608,\n",
       "  2.3231739263011986,\n",
       "  2.323151559959906,\n",
       "  2.323069657598223,\n",
       "  2.3230039103556486,\n",
       "  2.3229005948917285,\n",
       "  2.322951413164235,\n",
       "  2.3229557499789553,\n",
       "  2.32290253830594,\n",
       "  2.3228684306144713,\n",
       "  2.3236320549467475,\n",
       "  2.3235555800381085,\n",
       "  2.323500085585188,\n",
       "  2.3237592468136237,\n",
       "  2.3238046833726225,\n",
       "  2.323738900664585,\n",
       "  2.323672426640017,\n",
       "  2.3235895873664263,\n",
       "  2.3235187738844494,\n",
       "  2.3234610719065514,\n",
       "  2.3234055962209914,\n",
       "  2.3233513709826346,\n",
       "  2.3232985502614762,\n",
       "  2.323277690608031,\n",
       "  2.3232131958007813,\n",
       "  2.3231505381910105,\n",
       "  2.3230907202519075,\n",
       "  2.3230198089431666,\n",
       "  2.322947745786565,\n",
       "  2.3228842183947562,\n",
       "  2.3228685714745447,\n",
       "  2.322822566358199,\n",
       "  2.3227660412389795,\n",
       "  2.322726112824899,\n",
       "  2.3226847355182354,\n",
       "  2.3226098663236465,\n",
       "  2.322550182313365,\n",
       "  2.3224839371878927,\n",
       "  2.322414310507499,\n",
       "  2.3223438703652586,\n",
       "  2.322283800995242,\n",
       "  2.322226046797741,\n",
       "  2.322177695798444,\n",
       "  2.322116408519402,\n",
       "  2.32206005765431,\n",
       "  2.321985302226884,\n",
       "  2.3219341347408577,\n",
       "  2.321891447496132,\n",
       "  2.321829672056665,\n",
       "  2.321784165326287,\n",
       "  2.321729184595371,\n",
       "  2.321676548461468,\n",
       "  2.3216158509602005,\n",
       "  2.321564971707588,\n",
       "  2.321530930892281,\n",
       "  2.3214896276507075,\n",
       "  2.3214415061027243,\n",
       "  2.3213918661249093,\n",
       "  2.321330935360709,\n",
       "  2.3212745128359114,\n",
       "  2.321234910236804,\n",
       "  2.3211946561932564,\n",
       "  2.321136863643657,\n",
       "  2.321095098883419,\n",
       "  2.3210368048976844,\n",
       "  2.320984069550975,\n",
       "  2.3209451914501456,\n",
       "  2.3209008244828806,\n",
       "  2.3208707514579583,\n",
       "  2.3208167956935033,\n",
       "  2.3208736653473236,\n",
       "  2.3208338265919553,\n",
       "  2.320788128645295,\n",
       "  2.3207358174271637,\n",
       "  2.3206945785104414,\n",
       "  2.3206591117577475,\n",
       "  2.3206068105203905,\n",
       "  2.3205808796312497,\n",
       "  2.3205480872777096,\n",
       "  2.320502819886079,\n",
       "  2.320457025358298,\n",
       "  2.320412926776435,\n",
       "  2.320368312958418,\n",
       "  2.3203188212797605,\n",
       "  2.3202721983591714,\n",
       "  2.320346312954071,\n",
       "  2.320304204677713,\n",
       "  2.320279972263114,\n",
       "  2.320244337449288,\n",
       "  2.320203130496176,\n",
       "  2.320162958360407,\n",
       "  2.320152112326697,\n",
       "  2.320097344973691,\n",
       "  2.320049121355017,\n",
       "  2.3199914604038385,\n",
       "  2.3199515633014816,\n",
       "  2.319916672176785,\n",
       "  2.319880758364176,\n",
       "  2.319840315375046,\n",
       "  2.3197866421479447,\n",
       "  2.319748927870065,\n",
       "  2.319710845241741,\n",
       "  2.319663219476171,\n",
       "  2.3196270356928634,\n",
       "  2.31958009623274,\n",
       "  2.3195420359120225,\n",
       "  2.3194883800573853,\n",
       "  2.319448920350578,\n",
       "  2.3194092485241424,\n",
       "  2.319377920627594,\n",
       "  2.319347642009098,\n",
       "  2.31930575264034,\n",
       "  2.3194375481854004,\n",
       "  2.319394423820005,\n",
       "  2.31935569209817,\n",
       "  2.3193234763121957,\n",
       "  2.3192830437231415,\n",
       "  2.3192371071553697,\n",
       "  2.319169880416982,\n",
       "  2.3191605230657064,\n",
       "  2.3191135793996844,\n",
       "  2.31907103594067,\n",
       "  2.3190306543437966,\n",
       "  2.3190012824708135,\n",
       "  2.3189562998622297,\n",
       "  2.3189085882443647,\n",
       "  2.3188806249083376,\n",
       "  2.3188466250040887,\n",
       "  2.3188214097216475,\n",
       "  2.3187753722781226,\n",
       "  2.3187400756709082,\n",
       "  2.3187094344911983,\n",
       "  2.318666789548617,\n",
       "  2.3186383685975707,\n",
       "  2.3186095753838036,\n",
       "  2.31857082765427,\n",
       "  2.3185415234442894,\n",
       "  2.318511884903239,\n",
       "  2.318474836282797,\n",
       "  2.318487940278164,\n",
       "  2.318460989994129,\n",
       "  2.3184290627638497,\n",
       "  2.3183966563975837,\n",
       "  2.318379104961448,\n",
       "  2.318346076176084,\n",
       "  2.318307334676795,\n",
       "  2.3182779706042744,\n",
       "  2.318244132277084,\n",
       "  2.318196629608954,\n",
       "  2.3181671570647846,\n",
       "  2.318119674583141,\n",
       "  2.3180897818431596,\n",
       "  2.3180514522922766,\n",
       "  2.3179837341781133,\n",
       "  2.3179474546668235,\n",
       "  2.3179115495339637,\n",
       "  2.3178816721743387,\n",
       "  2.3178452210766927,\n",
       "  2.317814842895304,\n",
       "  2.3177704885270862,\n",
       "  2.3177345343545377,\n",
       "  2.3177074025162554,\n",
       "  2.317677832597139,\n",
       "  2.317754540674487,\n",
       "  2.317722032358358,\n",
       "  2.3176858744077515,\n",
       "  2.317661337570758,\n",
       "  2.317627272751654,\n",
       "  2.3175773672548514,\n",
       "  2.3175486098165097,\n",
       "  2.317514436105327,\n",
       "  2.3174898067078034,\n",
       "  2.3174474491671404,\n",
       "  2.317421001606974,\n",
       "  2.317394359137422,\n",
       "  2.3173611890604566,\n",
       "  2.3173928036169014,\n",
       "  2.317361599359757,\n",
       "  2.3173577707926434],\n",
       " [2.3081727027893066,\n",
       "  2.306193470954895,\n",
       "  2.3071308930714927,\n",
       "  2.306554853916168,\n",
       "  2.3065749645233153,\n",
       "  2.3052866458892822,\n",
       "  2.3051774161202565,\n",
       "  2.304817855358124,\n",
       "  2.3049870332082114,\n",
       "  2.3050150156021116,\n",
       "  2.3048874898390337,\n",
       "  2.304649809996287,\n",
       "  2.304567208656898,\n",
       "  2.304561802319118,\n",
       "  2.3042555967966716,\n",
       "  2.3039310425519943,\n",
       "  2.303807679344626,\n",
       "  2.3038153648376465,\n",
       "  2.3037186170879163,\n",
       "  2.3036062359809875,\n",
       "  2.3037915910993303,\n",
       "  2.303930000825362,\n",
       "  2.3039789303489355,\n",
       "  2.30395437280337,\n",
       "  2.3039715099334717,\n",
       "  2.304029813179603,\n",
       "  2.303887967710142,\n",
       "  2.303913346358708,\n",
       "  2.3040270065439157,\n",
       "  2.3038681745529175,\n",
       "  2.303800421376382,\n",
       "  2.3037167713046074,\n",
       "  2.3035071474133115,\n",
       "  2.3034471834407135,\n",
       "  2.303444242477417,\n",
       "  2.303379860189226,\n",
       "  2.3034224123568148,\n",
       "  2.3033215560411153,\n",
       "  2.3032302917578282,\n",
       "  2.303332710266113,\n",
       "  2.303312848253948,\n",
       "  2.3032283669426326,\n",
       "  2.303231494371281,\n",
       "  2.3032011443918403,\n",
       "  2.303350427415636,\n",
       "  2.303272273229516,\n",
       "  2.3033171866802458,\n",
       "  2.3032746762037277,\n",
       "  2.303243019142929,\n",
       "  2.303296217918396,\n",
       "  2.303349125619028,\n",
       "  2.303803631892571,\n",
       "  2.3038116491065836,\n",
       "  2.303843096450523,\n",
       "  2.3038108305497604,\n",
       "  2.3038700222969055,\n",
       "  2.303781358819259,\n",
       "  2.3037439790265313,\n",
       "  2.3038198907496565,\n",
       "  2.303828795750936,\n",
       "  2.303838526616331,\n",
       "  2.3038159185840237,\n",
       "  2.3038235164823986,\n",
       "  2.303828362375498,\n",
       "  2.3038305135873647,\n",
       "  2.3038127024968467,\n",
       "  2.3037739476161216,\n",
       "  2.3037868212251102,\n",
       "  2.3037242371103037,\n",
       "  2.303708386421204,\n",
       "  2.30371802289721,\n",
       "  2.303705973757638,\n",
       "  2.3037109375,\n",
       "  2.303721183055156,\n",
       "  2.303663657506307,\n",
       "  2.30367385399969,\n",
       "  2.3037187062300646,\n",
       "  2.3036929735770593,\n",
       "  2.303680157359642,\n",
       "  2.3038451820611954,\n",
       "  2.3038077177824796,\n",
       "  2.303806028714994,\n",
       "  2.303828334233847,\n",
       "  2.3038538637615384,\n",
       "  2.3038515876321233,\n",
       "  2.3038275186405626,\n",
       "  2.3037979904262498,\n",
       "  2.3037696562030097,\n",
       "  2.3037826773825656,\n",
       "  2.3037964661916095,\n",
       "  2.303815579676366,\n",
       "  2.3037752794182818,\n",
       "  2.3037811299806,\n",
       "  2.3037621898854033,\n",
       "  2.3037682457974085,\n",
       "  2.3037614350517592,\n",
       "  2.3037077544890727,\n",
       "  2.3036849304121367,\n",
       "  2.30366616056423,\n",
       "  2.303694803714752,\n",
       "  2.303681040754413,\n",
       "  2.3036742374008776,\n",
       "  2.3036904219284797,\n",
       "  2.3037434082764845,\n",
       "  2.303730587732224,\n",
       "  2.303721508889828,\n",
       "  2.3037141817752445,\n",
       "  2.3037356712200023,\n",
       "  2.3037038724356833,\n",
       "  2.303704938021573,\n",
       "  2.303689411094597,\n",
       "  2.303667519773756,\n",
       "  2.3036713178178907,\n",
       "  2.3036815576386034,\n",
       "  2.3037089472231655,\n",
       "  2.303743025352215,\n",
       "  2.3037490559439373,\n",
       "  2.30374189958734,\n",
       "  2.3037567739727116,\n",
       "  2.303768628835678,\n",
       "  2.3037644043441645,\n",
       "  2.3038282980684373,\n",
       "  2.3037486774165457,\n",
       "  2.3037429009714434,\n",
       "  2.304026107788086,\n",
       "  2.3040200452955943,\n",
       "  2.3040174574363887,\n",
       "  2.304011858999729,\n",
       "  2.3039933396864307,\n",
       "  2.3039749805743877,\n",
       "  2.303966061759541,\n",
       "  2.3039618170622624,\n",
       "  2.303976080471412,\n",
       "  2.303958188241987,\n",
       "  2.3039652206279615,\n",
       "  2.304015827529571,\n",
       "  2.3040195642596615,\n",
       "  2.304013440574425,\n",
       "  2.304004952204313,\n",
       "  2.3040282760347637,\n",
       "  2.3040045626620027,\n",
       "  2.303987269670191,\n",
       "  2.3039748401908606,\n",
       "  2.3039508793089123,\n",
       "  2.3039429105561355,\n",
       "  2.30425939331316,\n",
       "  2.304246625121759,\n",
       "  2.3042274536313236,\n",
       "  2.304243787023045,\n",
       "  2.304265430768331,\n",
       "  2.304259366547035,\n",
       "  2.304263119634829,\n",
       "  2.3042995524562264,\n",
       "  2.304292485311434,\n",
       "  2.304331224195419,\n",
       "  2.3043536375730467,\n",
       "  2.3043361256836326,\n",
       "  2.3043200275566003,\n",
       "  2.30431182129578,\n",
       "  2.30428633838892,\n",
       "  2.3042816123606995,\n",
       "  2.3044243373988587,\n",
       "  2.304416821778186,\n",
       "  2.3043894593308614,\n",
       "  2.3043717340989547,\n",
       "  2.3043683566242814,\n",
       "  2.304373010189947,\n",
       "  2.3043677040508816,\n",
       "  2.3043560671383108,\n",
       "  2.304336329067455,\n",
       "  2.304322358460454,\n",
       "  2.30429159624632,\n",
       "  2.304294449745575,\n",
       "  2.3042800988274057,\n",
       "  2.3042550768171037,\n",
       "  2.3042566004124554,\n",
       "  2.3042381133063365,\n",
       "  2.3042455241921243,\n",
       "  2.3042237652080684,\n",
       "  2.304235917992062,\n",
       "  2.30421636249479,\n",
       "  2.304740301855318,\n",
       "  2.3047124609921146,\n",
       "  2.304702421893244,\n",
       "  2.304718393892855,\n",
       "  2.304668071449444,\n",
       "  2.3051784625027905,\n",
       "  2.305164650399634,\n",
       "  2.3051652693874622,\n",
       "  2.305153893169604,\n",
       "  2.3051384731112976,\n",
       "  2.3051177337765694,\n",
       "  2.30521280160222,\n",
       "  2.305190385002451,\n",
       "  2.3051638370905168,\n",
       "  2.305159326718778,\n",
       "  2.3051342831045236,\n",
       "  2.305118032176085,\n",
       "  2.3052196957957207,\n",
       "  2.305296710729599,\n",
       "  2.305279320152245,\n",
       "  2.305298664782307,\n",
       "  2.3053069713667695,\n",
       "  2.3052817735017515,\n",
       "  2.3052448842583635,\n",
       "  2.305220757873313,\n",
       "  2.3052531935742513,\n",
       "  2.3054995112694225,\n",
       "  2.3054859980441735,\n",
       "  2.3054198003950575,\n",
       "  2.305400465337021,\n",
       "  2.3053947034871802,\n",
       "  2.305384718756161,\n",
       "  2.3053559789033695,\n",
       "  2.3053211500478343,\n",
       "  2.305335972044203,\n",
       "  2.3053271693568074,\n",
       "  2.3052819037656174,\n",
       "  2.305252739283592,\n",
       "  2.3052234454588456,\n",
       "  2.3052441286285537,\n",
       "  2.30526069800059,\n",
       "  2.3052775859832764,\n",
       "  2.30534487004791,\n",
       "  2.305349429448446,\n",
       "  2.30536636103571,\n",
       "  2.305365573992288,\n",
       "  2.3053776329023794,\n",
       "  2.305410266443111,\n",
       "  2.3053998428842295,\n",
       "  2.305377735203995,\n",
       "  2.3053785398088653,\n",
       "  2.3053770167633187,\n",
       "  2.3053753803937864,\n",
       "  2.3053677193661954,\n",
       "  2.305349252991757,\n",
       "  2.305339138216107,\n",
       "  2.305325598275962,\n",
       "  2.30532566772844,\n",
       "  2.3053090314070386,\n",
       "  2.305288433533981,\n",
       "  2.3052875246883424,\n",
       "  2.305272310358997,\n",
       "  2.3052289622728943,\n",
       "  2.3052162442888533,\n",
       "  2.305221402548193,\n",
       "  2.305204328737761,\n",
       "  2.3051950066320357,\n",
       "  2.3051790271896913,\n",
       "  2.305148545265198,\n",
       "  2.3051494630684415,\n",
       "  2.305173142561837,\n",
       "  2.305173131317018,\n",
       "  2.3051881076782705,\n",
       "  2.305144791509591,\n",
       "  2.307437880896032,\n",
       "  2.3074102206916662,\n",
       "  2.3074639407239217,\n",
       "  2.3074650479099463,\n",
       "  2.3074450135231017,\n",
       "  2.3074347178141275,\n",
       "  2.30742247232044,\n",
       "  2.3073802647028585,\n",
       "  2.3073674151391694,\n",
       "  2.3073813834280337,\n",
       "  2.307371393182224,\n",
       "  2.3074068451642096,\n",
       "  2.307374580582576,\n",
       "  2.3073567936411576,\n",
       "  2.3072971714867485,\n",
       "  2.307284359562441,\n",
       "  2.307261868434794,\n",
       "  2.30724228258098,\n",
       "  2.3072137858745827,\n",
       "  2.307205991744995,\n",
       "  2.3071858770605447,\n",
       "  2.307186903936338,\n",
       "  2.3071765891081997,\n",
       "  2.3071664875126228,\n",
       "  2.3071640031678338,\n",
       "  2.3071595112199885,\n",
       "  2.3071601196383753,\n",
       "  2.3071422324163753,\n",
       "  2.3071425943307475,\n",
       "  2.307134383184868,\n",
       "  2.3071208892168698,\n",
       "  2.307103529209044,\n",
       "  2.307047208150228,\n",
       "  2.307060668212732,\n",
       "  2.3070593184438244,\n",
       "  2.3070351520354806,\n",
       "  2.3070517557941073,\n",
       "  2.3071719900333028,\n",
       "  2.307152028797435,\n",
       "  2.307150025286917,\n",
       "  2.307143089739052,\n",
       "  2.30712947460136,\n",
       "  2.307219184485058,\n",
       "  2.3071962511260375,\n",
       "  2.3071760217348736,\n",
       "  2.3071369705010096,\n",
       "  2.3071404758668104,\n",
       "  2.307120131974173,\n",
       "  2.3071030864590094,\n",
       "  2.307087022750104,\n",
       "  2.307067652932959,\n",
       "  2.30705187297411,\n",
       "  2.307038157791286,\n",
       "  2.307133984797209,\n",
       "  2.3071245793373354,\n",
       "  2.307117961993938,\n",
       "  2.3071025625253334,\n",
       "  2.307085223853017,\n",
       "  2.307106286097484,\n",
       "  2.3071073463984897,\n",
       "  2.3071637055541894,\n",
       "  2.3071634047414977,\n",
       "  2.3071430299267077,\n",
       "  2.307137265100748,\n",
       "  2.307129882276058,\n",
       "  2.307116966009883,\n",
       "  2.3070911872460975,\n",
       "  2.3070889670782413,\n",
       "  2.307093255313826,\n",
       "  2.3070820925785944,\n",
       "  2.3070747610981477,\n",
       "  2.3070612500566954,\n",
       "  2.3070482248213233,\n",
       "  2.3070444712885245,\n",
       "  2.307043540838993,\n",
       "  2.307025619143806,\n",
       "  2.3070358712989165,\n",
       "  2.3070232452930988,\n",
       "  2.3070083171307685,\n",
       "  2.3069908690096725,\n",
       "  2.306979633512951,\n",
       "  2.3069668042553637,\n",
       "  2.3069592255812426,\n",
       "  2.306952717029943,\n",
       "  2.306947183609009,\n",
       "  2.3069187427196334,\n",
       "  2.3069054508766933,\n",
       "  2.306897547085153,\n",
       "  2.3068842659162923,\n",
       "  2.306870935274207,\n",
       "  2.3068554091315736,\n",
       "  2.3068519469983984,\n",
       "  2.306848567792739,\n",
       "  2.3068447256498144,\n",
       "  2.3068229457310268,\n",
       "  2.30680707988576,\n",
       "  2.3068211031231014,\n",
       "  2.306806601478425,\n",
       "  2.3068050651227012,\n",
       "  2.3067911443576006,\n",
       "  2.3068060566870012,\n",
       "  2.306785162757425,\n",
       "  2.3069706316100818,\n",
       "  2.3069528596979,\n",
       "  2.30693715678321,\n",
       "  2.306937290360723,\n",
       "  2.3069074127555553,\n",
       "  2.3068991186861822,\n",
       "  2.3068983535190206,\n",
       "  2.306915665326053,\n",
       "  2.306968331336975,\n",
       "  2.3069632118339434,\n",
       "  2.306981837619906,\n",
       "  2.306975698729518,\n",
       "  2.3070017891961174,\n",
       "  2.306992661278203,\n",
       "  2.3069834279757675,\n",
       "  2.306978786918497,\n",
       "  2.306967137969114,\n",
       "  2.3069627183278403,\n",
       "  2.3069504860867847,\n",
       "  2.306944695960938,\n",
       "  2.30692458152771,\n",
       "  2.3069195936097318,\n",
       "  2.3069040944701746,\n",
       "  2.306898886137434,\n",
       "  2.3068876010585204,\n",
       "  2.3068762329788806,\n",
       "  2.307008379449447,\n",
       "  2.307010381872004,\n",
       "  2.3069861250220187,\n",
       "  2.306973237399907,\n",
       "  2.306964042874956,\n",
       "  2.30695558942682,\n",
       "  2.30694272457025,\n",
       "  2.306935876226791,\n",
       "  2.3069345294212806,\n",
       "  2.3069139000113683,\n",
       "  2.3069153757869896,\n",
       "  2.306897658939603,\n",
       "  2.30688063424043,\n",
       "  2.306873753329068,\n",
       "  2.30686842616479,\n",
       "  2.3068390430364394,\n",
       "  2.306821001768112,\n",
       "  2.306811134119581,\n",
       "  2.306803320177752,\n",
       "  2.306800574877718,\n",
       "  2.306791385801712,\n",
       "  2.3067771752675372,\n",
       "  2.3068129752069857,\n",
       "  2.306809799091236,\n",
       "  2.3067949636309755,\n",
       "  2.3067852605525907,\n",
       "  2.3067919818366445,\n",
       "  2.306782842552575,\n",
       "  2.3068391240916206,\n",
       "  2.306840743626001,\n",
       "  2.3068210473959,\n",
       "  2.3068016425672786,\n",
       "  2.306793066744621,\n",
       "  2.3067961373775123,\n",
       "  2.3068036456997887,\n",
       "  2.3068131507154295,\n",
       "  2.3068183484531586,\n",
       "  2.30681277340778,\n",
       "  2.306860326025723,\n",
       "  2.3068461914152683,\n",
       "  2.30688801970122,\n",
       "  2.3068791798984303,\n",
       "  2.3068728911484913,\n",
       "  2.3068744979920934,\n",
       "  2.3068638722473214,\n",
       "  2.306855423467143,\n",
       "  2.306833017149637,\n",
       "  2.3068187922723333,\n",
       "  2.306814963618914,\n",
       "  2.306825848154328,\n",
       "  2.30681708441352,\n",
       "  2.306804944180894,\n",
       "  2.3068026107385617,\n",
       "  2.3067978617801272,\n",
       "  2.306785194296815,\n",
       "  2.3067752217920603,\n",
       "  2.306773162429983,\n",
       "  2.3067645421103826,\n",
       "  2.30679183847764,\n",
       "  2.3067856200930765,\n",
       "  2.3067764940562547,\n",
       "  2.3067675327986814,\n",
       "  2.3068129316039148,\n",
       "  2.3068292567660613,\n",
       "  2.3068264025662626,\n",
       "  2.3069391712579534,\n",
       "  2.306924302842882,\n",
       "  2.306918964153383,\n",
       "  2.30690771024839,\n",
       "  2.3068943839462652,\n",
       "  2.3070431065454358,\n",
       "  2.31009178842817,\n",
       "  2.310154707285396,\n",
       "  2.3102961108251527,\n",
       "  2.3106423986010154,\n",
       "  2.310677522667613,\n",
       "  2.3108602953993755,\n",
       "  2.3109022045342367,\n",
       "  2.3109465754909433,\n",
       "  2.311139386879445,\n",
       "  2.311120704330247,\n",
       "  2.3114613548401866,\n",
       "  2.31189175890239,\n",
       "  2.3118698821588555,\n",
       "  2.3121503056623998,\n",
       "  2.3121358510335286],\n",
       " [2.3203063011169434,\n",
       "  2.3196475505828857,\n",
       "  2.312949021657308,\n",
       "  2.3059409856796265,\n",
       "  2.2989431381225587,\n",
       "  2.330739895502726,\n",
       "  2.3408728327069963,\n",
       "  2.3354371190071106,\n",
       "  2.3316041628519693,\n",
       "  2.3288824558258057,\n",
       "  2.3268197666515005,\n",
       "  2.337194343407949,\n",
       "  2.3345244297614465,\n",
       "  2.332116825239999,\n",
       "  2.3302166938781737,\n",
       "  2.328850135207176,\n",
       "  2.327318486045389,\n",
       "  2.3258330954445734,\n",
       "  2.3244432399147437,\n",
       "  2.323297309875488,\n",
       "  2.322272913796561,\n",
       "  2.321887243877758,\n",
       "  2.329416223194288,\n",
       "  2.3283733626206717,\n",
       "  2.32969708442688,\n",
       "  2.328786299778865,\n",
       "  2.3350584153775817,\n",
       "  2.3351936084883556,\n",
       "  2.3390098522449363,\n",
       "  2.337714942296346,\n",
       "  2.3372377887848885,\n",
       "  2.336150214076042,\n",
       "  2.336190859476725,\n",
       "  2.3365061002619125,\n",
       "  2.338391351699829,\n",
       "  2.3375764555401273,\n",
       "  2.3409417513254525,\n",
       "  2.3399959551660636,\n",
       "  2.339079159956712,\n",
       "  2.3382605254650115,\n",
       "  2.337612896430783,\n",
       "  2.3369578350157965,\n",
       "  2.339147839435311,\n",
       "  2.3382597619836982,\n",
       "  2.3373395336998835,\n",
       "  2.3436983201814736,\n",
       "  2.3429031930071242,\n",
       "  2.3420900652805963,\n",
       "  2.341265498375406,\n",
       "  2.340483832359314,\n",
       "  2.339793406280817,\n",
       "  2.339213339182047,\n",
       "  2.3385048902259684,\n",
       "  2.3378150507255837,\n",
       "  2.3371444312008944,\n",
       "  2.336456767150334,\n",
       "  2.335897738473457,\n",
       "  2.33537128464929,\n",
       "  2.3348353555646995,\n",
       "  2.3345696449279787,\n",
       "  2.3340626700979765,\n",
       "  2.3335664964491323,\n",
       "  2.3330695439898776,\n",
       "  2.332599349319935,\n",
       "  2.332596133305476,\n",
       "  2.3332415783044063,\n",
       "  2.3331812353276495,\n",
       "  2.33275303069283,\n",
       "  2.332485831302145,\n",
       "  2.332072707584926,\n",
       "  2.3315623545310866,\n",
       "  2.331182291110357,\n",
       "  2.330764466769075,\n",
       "  2.330420941919894,\n",
       "  2.331779635747274,\n",
       "  2.3313833318258586,\n",
       "  2.330987698071963,\n",
       "  2.330641737351051,\n",
       "  2.3308404035206083,\n",
       "  2.330402675271034,\n",
       "  2.33007879021727,\n",
       "  2.329695562037026,\n",
       "  2.3297210974865648,\n",
       "  2.329504765215374,\n",
       "  2.329189224804149,\n",
       "  2.3288540729256564,\n",
       "  2.3285737202085297,\n",
       "  2.328243277289651,\n",
       "  2.3279503972342845,\n",
       "  2.3276051017973156,\n",
       "  2.327356917517526,\n",
       "  2.3271115007607834,\n",
       "  2.3268751303354898,\n",
       "  2.3266363930194935,\n",
       "  2.326462964007729,\n",
       "  2.3264228279391923,\n",
       "  2.326186566008735,\n",
       "  2.325925732145504,\n",
       "  2.3256126100366767,\n",
       "  2.325375208854675,\n",
       "  2.325183955749663,\n",
       "  2.3249909831028357,\n",
       "  2.3247907439481863,\n",
       "  2.324642451909872,\n",
       "  2.3244229225885302,\n",
       "  2.324179761814621,\n",
       "  2.3239573986730844,\n",
       "  2.323744884243718,\n",
       "  2.3235923215883587,\n",
       "  2.32347543889826,\n",
       "  2.3232984757638193,\n",
       "  2.3231525804315294,\n",
       "  2.3229970362334127,\n",
       "  2.3228925717504403,\n",
       "  2.3226934163466746,\n",
       "  2.3225241961150336,\n",
       "  2.322356209795699,\n",
       "  2.322176945411553,\n",
       "  2.3220076601044473,\n",
       "  2.3217889308929442,\n",
       "  2.3215615532614966,\n",
       "  2.321413817952891,\n",
       "  2.3211216965341954,\n",
       "  2.32085479651728,\n",
       "  2.320740940093994,\n",
       "  2.3205749420892623,\n",
       "  2.3203991060181868,\n",
       "  2.3203979711979628,\n",
       "  2.320268196653026,\n",
       "  2.3201457372078527,\n",
       "  2.319995583468721,\n",
       "  2.3198773662249246,\n",
       "  2.319761593539016,\n",
       "  2.319762555520926,\n",
       "  2.319661251703898,\n",
       "  2.319531393401763,\n",
       "  2.319425154776469,\n",
       "  2.320895951727162,\n",
       "  2.320753197018191,\n",
       "  2.320526610101972,\n",
       "  2.3210084793415477,\n",
       "  2.3208150091305586,\n",
       "  2.320733257106968,\n",
       "  2.3206105497148304,\n",
       "  2.3205333972799367,\n",
       "  2.320416964896738,\n",
       "  2.320302186369085,\n",
       "  2.320177092745497,\n",
       "  2.320071180394832,\n",
       "  2.3199769417444864,\n",
       "  2.3198684935538183,\n",
       "  2.3197517614615593,\n",
       "  2.3196473215140547,\n",
       "  2.3195639198476616,\n",
       "  2.319402345534294,\n",
       "  2.3193163795348926,\n",
       "  2.319205312971856,\n",
       "  2.3191538385198087,\n",
       "  2.3196247043849536,\n",
       "  2.319519054889679,\n",
       "  2.319386230492444,\n",
       "  2.3192793204460616,\n",
       "  2.319213460559494,\n",
       "  2.3191328383073575,\n",
       "  2.319054058826331,\n",
       "  2.3189591557146554,\n",
       "  2.318853541048701,\n",
       "  2.3187550689492906,\n",
       "  2.3186786767293714,\n",
       "  2.318579307724448,\n",
       "  2.3184859027639466,\n",
       "  2.318389559901038,\n",
       "  2.3183267778054826,\n",
       "  2.318232025223217,\n",
       "  2.3181662246159145,\n",
       "  2.3180651746012946,\n",
       "  2.3179862378007274,\n",
       "  2.3179139126552624,\n",
       "  2.317851787172882,\n",
       "  2.317775242858463,\n",
       "  2.317700986704115,\n",
       "  2.3176208839311703,\n",
       "  2.3181162440711685,\n",
       "  2.318029999732971,\n",
       "  2.3179574270506165,\n",
       "  2.317878550098788,\n",
       "  2.3177976710273622,\n",
       "  2.3177042235719396,\n",
       "  2.3176445368105774,\n",
       "  2.3175550925104242,\n",
       "  2.317477851637995,\n",
       "  2.317395493388176,\n",
       "  2.3175640723865882,\n",
       "  2.317479811992842,\n",
       "  2.3173860207582133,\n",
       "  2.3173354377551956,\n",
       "  2.3172590732574463,\n",
       "  2.3171776749870996,\n",
       "  2.317097981371472,\n",
       "  2.3170431554317474,\n",
       "  2.316985193176649,\n",
       "  2.3169088162998164,\n",
       "  2.3168256658638637,\n",
       "  2.316756047454535,\n",
       "  2.316681490874872,\n",
       "  2.3166165479178566,\n",
       "  2.3165914862628143,\n",
       "  2.316869930579112,\n",
       "  2.3168553382015684,\n",
       "  2.3167935905002413,\n",
       "  2.316819075724525,\n",
       "  2.3167518467273354,\n",
       "  2.3171370723437814,\n",
       "  2.3170423496549373,\n",
       "  2.316969100819078,\n",
       "  2.3169227915781514,\n",
       "  2.3168604901309386,\n",
       "  2.3167945923061546,\n",
       "  2.3167053531838335,\n",
       "  2.316631477529352,\n",
       "  2.3165853929735416,\n",
       "  2.3166738233050785,\n",
       "  2.3166039973631034,\n",
       "  2.316518599433558,\n",
       "  2.3164480686187745,\n",
       "  2.316369780396993,\n",
       "  2.3163174112462785,\n",
       "  2.316551827547843,\n",
       "  2.316497329020604,\n",
       "  2.316440284770468,\n",
       "  2.316390622745861,\n",
       "  2.3163330195278955,\n",
       "  2.3162857728966317,\n",
       "  2.316242396322071,\n",
       "  2.316202687202616,\n",
       "  2.3164694491079296,\n",
       "  2.31643085640694,\n",
       "  2.316403543247896,\n",
       "  2.3163474873020062,\n",
       "  2.3163063983122507,\n",
       "  2.316754882266413,\n",
       "  2.316752389442822,\n",
       "  2.3167082851315723,\n",
       "  2.316637939116994,\n",
       "  2.316574735057597,\n",
       "  2.3165294484394354,\n",
       "  2.316617970524529,\n",
       "  2.3165500846601303,\n",
       "  2.3165034424349007,\n",
       "  2.3164951877593993,\n",
       "  2.3164335959461106,\n",
       "  2.3163883846903603,\n",
       "  2.316344749314983,\n",
       "  2.3162964864039983,\n",
       "  2.3162627912035174,\n",
       "  2.3162191659212112,\n",
       "  2.3161802180546265,\n",
       "  2.3161577448364374,\n",
       "  2.316130370246858,\n",
       "  2.3160792405788717,\n",
       "  2.316033894074831,\n",
       "  2.316030048232042,\n",
       "  2.315976093023902,\n",
       "  2.3159243365128837,\n",
       "  2.3158775176642075,\n",
       "  2.3158389347836486,\n",
       "  2.3157829756147406,\n",
       "  2.31574397122682,\n",
       "  2.3157056450400653,\n",
       "  2.3158350105638856,\n",
       "  2.3157957532748963,\n",
       "  2.315741866827011,\n",
       "  2.3165739255073743,\n",
       "  2.316534694963998,\n",
       "  2.316478900909424,\n",
       "  2.3164721753286277,\n",
       "  2.316494541478071,\n",
       "  2.316455639523568,\n",
       "  2.3163995862434414,\n",
       "  2.316352701187134,\n",
       "  2.3163076940380383,\n",
       "  2.316265544147356,\n",
       "  2.3164691124703776,\n",
       "  2.3194082362551085,\n",
       "  2.319359706577502,\n",
       "  2.3193017277684245,\n",
       "  2.320114922440426,\n",
       "  2.3200684380200176,\n",
       "  2.3200073860920836,\n",
       "  2.31995192478443,\n",
       "  2.3199111776253614,\n",
       "  2.319860872340529,\n",
       "  2.319802571482219,\n",
       "  2.3197476823313705,\n",
       "  2.3196857816081935,\n",
       "  2.319626463426126,\n",
       "  2.319572591621065,\n",
       "  2.3195161467430574,\n",
       "  2.319463612642575,\n",
       "  2.3194159944852193,\n",
       "  2.31935715675354,\n",
       "  2.319315019032813,\n",
       "  2.3192590337381898,\n",
       "  2.3191999440130435,\n",
       "  2.319141574765815,\n",
       "  2.3190917509054048,\n",
       "  2.319039410022649,\n",
       "  2.3190876524169726,\n",
       "  2.319034739991222,\n",
       "  2.318986677354382,\n",
       "  2.318959218512777,\n",
       "  2.3188971976439157,\n",
       "  2.318850591921578,\n",
       "  2.3188073133966727,\n",
       "  2.318766690814306,\n",
       "  2.318725746643694,\n",
       "  2.3186801735911082,\n",
       "  2.318630594127583,\n",
       "  2.3185755234900687,\n",
       "  2.318521279096603,\n",
       "  2.3184659562749657,\n",
       "  2.31841510571308,\n",
       "  2.318371415507314,\n",
       "  2.3183159916489213,\n",
       "  2.318277147733248,\n",
       "  2.318185627094807,\n",
       "  2.318121413572119,\n",
       "  2.3180619020287585,\n",
       "  2.318010532384948,\n",
       "  2.3179635683695476,\n",
       "  2.3179042857939383,\n",
       "  2.3178554012114745,\n",
       "  2.317802383377029,\n",
       "  2.3178939291103156,\n",
       "  2.3179035307756113,\n",
       "  2.3181149753786268,\n",
       "  2.3181007495619776,\n",
       "  2.3180589626526693,\n",
       "  2.3181535325570795,\n",
       "  2.31809338611715,\n",
       "  2.318066779469465,\n",
       "  2.318050360121922,\n",
       "  2.3180025082635463,\n",
       "  2.3179710098477297,\n",
       "  2.3179247793943984,\n",
       "  2.3179057719390515,\n",
       "  2.317854407197804,\n",
       "  2.317825138568878,\n",
       "  2.3179141832969252,\n",
       "  2.3178547082628524,\n",
       "  2.317810135349589,\n",
       "  2.3177730569785293,\n",
       "  2.317730495004411,\n",
       "  2.317749540011088,\n",
       "  2.3176981704335815,\n",
       "  2.3176420277424072,\n",
       "  2.317589175467398,\n",
       "  2.317561881502247,\n",
       "  2.3175254565427563,\n",
       "  2.3175095670753056,\n",
       "  2.3174604425139704,\n",
       "  2.3174322020283062,\n",
       "  2.317379200097286,\n",
       "  2.3173616856009094,\n",
       "  2.317327027778103,\n",
       "  2.3172560598029466,\n",
       "  2.3172206365445005,\n",
       "  2.31718415086684,\n",
       "  2.3171548371715596,\n",
       "  2.317122953646892,\n",
       "  2.3170932097576378,\n",
       "  2.3170536192514564,\n",
       "  2.317023542547354,\n",
       "  2.316994327274873,\n",
       "  2.31694659614563,\n",
       "  2.3169135622521666,\n",
       "  2.316895679074194,\n",
       "  2.3168641738790683,\n",
       "  2.3168413720848062,\n",
       "  2.3168017261906675,\n",
       "  2.3167610093364566,\n",
       "  2.316727173890119,\n",
       "  2.3166920211234228,\n",
       "  2.3166540202995143,\n",
       "  2.316621613192868,\n",
       "  2.316577999703007,\n",
       "  2.3165378872430296,\n",
       "  2.3164964017179823,\n",
       "  2.31646783247705,\n",
       "  2.316433411378127,\n",
       "  2.3163932253942465,\n",
       "  2.316357302422426,\n",
       "  2.3163248794982754,\n",
       "  2.316601357484227,\n",
       "  2.316560146476649,\n",
       "  2.3165263852687796,\n",
       "  2.316497061654963,\n",
       "  2.3164618925832623,\n",
       "  2.3164289876034387,\n",
       "  2.3163924515247345,\n",
       "  2.316355233180553,\n",
       "  2.3163341770124672,\n",
       "  2.3163052936345707,\n",
       "  2.3162792803037284,\n",
       "  2.316250166480924,\n",
       "  2.3162180402596007,\n",
       "  2.316196459810037,\n",
       "  2.3161888835476896,\n",
       "  2.3161581623525085,\n",
       "  2.316119045746036,\n",
       "  2.3160815627615525,\n",
       "  2.3160557428609976,\n",
       "  2.3160188267363764,\n",
       "  2.315984152365422,\n",
       "  2.315907884505858,\n",
       "  2.3158738057200727,\n",
       "  2.31584872158883,\n",
       "  2.3158231391861106,\n",
       "  2.315906446133707,\n",
       "  2.3158696560632617,\n",
       "  2.316040876075944,\n",
       "  2.315998689823241,\n",
       "  2.315974131825404,\n",
       "  2.3159442060398607,\n",
       "  2.315924638860366,\n",
       "  2.3158744674333382,\n",
       "  2.315847295229552,\n",
       "  2.315831404423045,\n",
       "  2.3158038451677156,\n",
       "  2.3157773533532784,\n",
       "  2.3157412181597574,\n",
       "  2.3163571335651256,\n",
       "  2.3163262173430197,\n",
       "  2.3163075337212207,\n",
       "  2.3162887310159617,\n",
       "  2.316254539227267,\n",
       "  2.316228941867226,\n",
       "  2.316502861780663,\n",
       "  2.316468828631425,\n",
       "  2.3164432406425477,\n",
       "  2.3164127754246024,\n",
       "  2.3163868318316085,\n",
       "  2.316356599196354,\n",
       "  2.3163279386254043,\n",
       "  2.316362622614657,\n",
       "  2.316349181893695,\n",
       "  2.31663831235045,\n",
       "  2.316723348306758,\n",
       "  2.316774859991265,\n",
       "  2.3167639854219226,\n",
       "  2.316731162716174,\n",
       "  2.31719102004988,\n",
       "  2.3171582216721758,\n",
       "  2.3171278122763277,\n",
       "  2.317089992565113,\n",
       "  2.317073185715759,\n",
       "  2.317112522521739,\n",
       "  2.3170817455350052,\n",
       "  2.3170631897994896,\n",
       "  2.317000978925954,\n",
       "  2.3169715280388026,\n",
       "  2.31693016553854,\n",
       "  2.316911004274504,\n",
       "  2.3169914288767455,\n",
       "  2.31698365980579,\n",
       "  2.3172745095813734,\n",
       "  2.3172516746235097,\n",
       "  2.3172215829547653,\n",
       "  2.3174009768168133],\n",
       " [2.302137851715088,\n",
       "  2.3010811805725098,\n",
       "  2.3023703893025718,\n",
       "  2.3010536432266235,\n",
       "  2.3003664016723633,\n",
       "  2.314077933629354,\n",
       "  2.3150785309927806,\n",
       "  2.312889873981476,\n",
       "  2.3118578063117132,\n",
       "  2.311623525619507,\n",
       "  2.309551390734586,\n",
       "  2.3086820046106973,\n",
       "  2.3080983528724084,\n",
       "  2.333030411175319,\n",
       "  2.331261332829793,\n",
       "  2.330284908413887,\n",
       "  2.328533986035515,\n",
       "  2.3363720178604126,\n",
       "  2.3346743207228813,\n",
       "  2.3330416798591616,\n",
       "  2.331328040077573,\n",
       "  2.3299614407799463,\n",
       "  2.328831372053727,\n",
       "  2.329931765794754,\n",
       "  2.328780298233032,\n",
       "  2.328014768086947,\n",
       "  2.3268395088337086,\n",
       "  2.32580520425524,\n",
       "  2.3249959781252105,\n",
       "  2.3243008136749266,\n",
       "  2.3236267028316373,\n",
       "  2.3228311240673065,\n",
       "  2.3222932093071216,\n",
       "  2.3217177671544693,\n",
       "  2.3213546071733746,\n",
       "  2.32157031695048,\n",
       "  2.3209569260880754,\n",
       "  2.3202936900289437,\n",
       "  2.319888029343043,\n",
       "  2.3192567050457003,\n",
       "  2.3188220466055522,\n",
       "  2.3184900056748163,\n",
       "  2.3181877857030826,\n",
       "  2.317697974768552,\n",
       "  2.317583221859402,\n",
       "  2.3171524068583613,\n",
       "  2.3171746527895016,\n",
       "  2.319395969311396,\n",
       "  2.3190075913254096,\n",
       "  2.319402980804443,\n",
       "  2.3189359599468755,\n",
       "  2.318376683271848,\n",
       "  2.318090038479499,\n",
       "  2.3178115597477666,\n",
       "  2.317577747865157,\n",
       "  2.3174155056476593,\n",
       "  2.317242434150294,\n",
       "  2.321479077996879,\n",
       "  2.3211597628512624,\n",
       "  2.3207319537798563,\n",
       "  2.3212353166986683,\n",
       "  2.320951415646461,\n",
       "  2.3207767123267766,\n",
       "  2.3204038999974728,\n",
       "  2.3239358241741472,\n",
       "  2.3235207470980557,\n",
       "  2.3232386005458547,\n",
       "  2.3228466125095593,\n",
       "  2.322565818178481,\n",
       "  2.3271224975585936,\n",
       "  2.3267458156800607,\n",
       "  2.3261627422438726,\n",
       "  2.325962354059089,\n",
       "  2.3259542890497156,\n",
       "  2.3255289141337077,\n",
       "  2.325233600641552,\n",
       "  2.3250361201050995,\n",
       "  2.3248266990368185,\n",
       "  2.3244865996928157,\n",
       "  2.3242291659116745,\n",
       "  2.3239761870584372,\n",
       "  2.3237639781905384,\n",
       "  2.3235912064471878,\n",
       "  2.3233756650061834,\n",
       "  2.3231176011702592,\n",
       "  2.322989826978639,\n",
       "  2.3228959297311715,\n",
       "  2.322657742283561,\n",
       "  2.3224190835202676,\n",
       "  2.3222414678997465,\n",
       "  2.3221068460862715,\n",
       "  2.3218765906665637,\n",
       "  2.321615413952899,\n",
       "  2.3213940833477262,\n",
       "  2.330244526110197,\n",
       "  2.32997619609038,\n",
       "  2.329746482298546,\n",
       "  2.329450003954829,\n",
       "  2.329827833657313,\n",
       "  2.329556589126587,\n",
       "  2.329317867165745,\n",
       "  2.3290591356801054,\n",
       "  2.3288413482962302,\n",
       "  2.3285587452925167,\n",
       "  2.32835035551162,\n",
       "  2.3281314080616213,\n",
       "  2.3278997390069693,\n",
       "  2.3276845437509044,\n",
       "  2.327424311856611,\n",
       "  2.3272188316692004,\n",
       "  2.327000046635533,\n",
       "  2.3267977706023624,\n",
       "  2.32654268129737,\n",
       "  2.326445328561883,\n",
       "  2.3262164965919827,\n",
       "  2.3260214883705665,\n",
       "  2.3258263575725064,\n",
       "  2.325672018325935,\n",
       "  2.3254732504612257,\n",
       "  2.3252696812152864,\n",
       "  2.325062227643226,\n",
       "  2.3248716377821124,\n",
       "  2.32472463158088,\n",
       "  2.3245143601971288,\n",
       "  2.3243255710601805,\n",
       "  2.3241556542260304,\n",
       "  2.3239732351828746,\n",
       "  2.32382202334702,\n",
       "  2.3236273388529933,\n",
       "  2.323498089496906,\n",
       "  2.3233828471817133,\n",
       "  2.3232314279585173,\n",
       "  2.3230767716142466,\n",
       "  2.3229058198074797,\n",
       "  2.3235495373054786,\n",
       "  2.323404247269911,\n",
       "  2.3233194716655423,\n",
       "  2.3231876518415366,\n",
       "  2.323071502095504,\n",
       "  2.3228826812335424,\n",
       "  2.322764831231841,\n",
       "  2.322620860287841,\n",
       "  2.322496989390233,\n",
       "  2.3223498645755978,\n",
       "  2.3222369342014706,\n",
       "  2.322116296585292,\n",
       "  2.3220338918724837,\n",
       "  2.321914339387739,\n",
       "  2.321778860668208,\n",
       "  2.3216744073232016,\n",
       "  2.3215709332598755,\n",
       "  2.3214372647436043,\n",
       "  2.3212985743105023,\n",
       "  2.3211848472619985,\n",
       "  2.3217542263769335,\n",
       "  2.321622134783329,\n",
       "  2.321524093105535,\n",
       "  2.32141652439214,\n",
       "  2.321262298140136,\n",
       "  2.3211413621902466,\n",
       "  2.3220063277653287,\n",
       "  2.321885195779212,\n",
       "  2.3217825465407107,\n",
       "  2.321672144459515,\n",
       "  2.3215894236709134,\n",
       "  2.321487896413688,\n",
       "  2.3213621542125407,\n",
       "  2.3212887204828716,\n",
       "  2.321165668893848,\n",
       "  2.3210886618670297,\n",
       "  2.3209921435305945,\n",
       "  2.320882470108742,\n",
       "  2.320764173662042,\n",
       "  2.320677829884935,\n",
       "  2.3205619634900776,\n",
       "  2.3204730708490717,\n",
       "  2.3205784875794317,\n",
       "  2.3204838600051536,\n",
       "  2.3203873141517852,\n",
       "  2.32029158671697,\n",
       "  2.3201969473401487,\n",
       "  2.320106558747344,\n",
       "  2.320016578246987,\n",
       "  2.319912997276887,\n",
       "  2.319932293247532,\n",
       "  2.319839918485252,\n",
       "  2.3197405861023275,\n",
       "  2.3196581361141613,\n",
       "  2.3195680953838207,\n",
       "  2.3194804530394704,\n",
       "  2.319386092780148,\n",
       "  2.3194092561801276,\n",
       "  2.319313554566141,\n",
       "  2.319231392182026,\n",
       "  2.3194182408161654,\n",
       "  2.3193342843834235,\n",
       "  2.319228300588385,\n",
       "  2.3191407678103206,\n",
       "  2.3190694933560625,\n",
       "  2.31897940158844,\n",
       "  2.318897843953982,\n",
       "  2.3188130336232704,\n",
       "  2.3186503114371466,\n",
       "  2.324385264340569,\n",
       "  2.3243310858563677,\n",
       "  2.3242266432752885,\n",
       "  2.3241193018097808,\n",
       "  2.324021427677228,\n",
       "  2.3239098918494996,\n",
       "  2.3237906603586107,\n",
       "  2.3236963138761113,\n",
       "  2.323583702996092,\n",
       "  2.3234883798679835,\n",
       "  2.3233765441680623,\n",
       "  2.323307891224706,\n",
       "  2.323225993801046,\n",
       "  2.3230905379018476,\n",
       "  2.3231229607118378,\n",
       "  2.3230083130266026,\n",
       "  2.322929297793995,\n",
       "  2.322851953463317,\n",
       "  2.322880373344765,\n",
       "  2.3227781843176873,\n",
       "  2.3226675114461353,\n",
       "  2.322587252722846,\n",
       "  2.3225136098608505,\n",
       "  2.324077932845128,\n",
       "  2.3239944985038354,\n",
       "  2.323889839597144,\n",
       "  2.3238125655962074,\n",
       "  2.3237197409460557,\n",
       "  2.323640540756028,\n",
       "  2.323533491003667,\n",
       "  2.3234268355573344,\n",
       "  2.3233552131247013,\n",
       "  2.3232738517098506,\n",
       "  2.3231753327172515,\n",
       "  2.3230992475477588,\n",
       "  2.3231174167728823,\n",
       "  2.323031998674075,\n",
       "  2.322929306148988,\n",
       "  2.322908322673199,\n",
       "  2.322822201889729,\n",
       "  2.32275859352018,\n",
       "  2.3226840690690644,\n",
       "  2.322628167586598,\n",
       "  2.322547006220953,\n",
       "  2.3224726944200453,\n",
       "  2.3223935868366654,\n",
       "  2.32233189868927,\n",
       "  2.3222457897140685,\n",
       "  2.3221857396383134,\n",
       "  2.3221192114909175,\n",
       "  2.322053022272005,\n",
       "  2.3219873269399005,\n",
       "  2.3219117177650332,\n",
       "  2.321843904280013,\n",
       "  2.321775142536607,\n",
       "  2.3217105810246412,\n",
       "  2.321641567120185,\n",
       "  2.321648326413385,\n",
       "  2.3215768018751652,\n",
       "  2.321512271242903,\n",
       "  2.32144033908844,\n",
       "  2.3213849625497494,\n",
       "  2.3213153019883577,\n",
       "  2.3212430843253262,\n",
       "  2.32117137268408,\n",
       "  2.321106478184129,\n",
       "  2.3210506403887714,\n",
       "  2.3209867802933135,\n",
       "  2.323898172553848,\n",
       "  2.3238548673552906,\n",
       "  2.3238714855082714,\n",
       "  2.32379525011236,\n",
       "  2.323703329632248,\n",
       "  2.3238031003449366,\n",
       "  2.3239292292286167,\n",
       "  2.3238491148931577,\n",
       "  2.3237753706318993,\n",
       "  2.3236958641174423,\n",
       "  2.32361597795013,\n",
       "  2.3235716171062455,\n",
       "  2.323493436188765,\n",
       "  2.323422336578369,\n",
       "  2.323357271981406,\n",
       "  2.323287890763233,\n",
       "  2.3232263210746975,\n",
       "  2.3231502643506006,\n",
       "  2.3230810535365136,\n",
       "  2.3230118178010395,\n",
       "  2.323165535110317,\n",
       "  2.3231222710918646,\n",
       "  2.3230494885217574,\n",
       "  2.3229700258222676,\n",
       "  2.3229137570471377,\n",
       "  2.3228543992797133,\n",
       "  2.3227775984962515,\n",
       "  2.3227237140055883,\n",
       "  2.3226689783732097,\n",
       "  2.32260238926276,\n",
       "  2.322542606600073,\n",
       "  2.322490153139574,\n",
       "  2.322424369423013,\n",
       "  2.3232927087877617,\n",
       "  2.323233295110316,\n",
       "  2.323163303567843,\n",
       "  2.32318577905754,\n",
       "  2.3231228424121646,\n",
       "  2.3230626783063335,\n",
       "  2.3229944498975943,\n",
       "  2.322932657523033,\n",
       "  2.3228673584545003,\n",
       "  2.3227717868841378,\n",
       "  2.3227027976323686,\n",
       "  2.3226359788375563,\n",
       "  2.322568608383275,\n",
       "  2.3225087992050364,\n",
       "  2.3224502745840616,\n",
       "  2.322395871579647,\n",
       "  2.322332450533953,\n",
       "  2.322275026984837,\n",
       "  2.322206136242893,\n",
       "  2.3221508382279197,\n",
       "  2.322080541757437,\n",
       "  2.321952522898013,\n",
       "  2.3218951546088635,\n",
       "  2.3218393078664454,\n",
       "  2.3217759146878785,\n",
       "  2.3217048052585487,\n",
       "  2.3216478673352934,\n",
       "  2.3215999689446876,\n",
       "  2.3215452779878727,\n",
       "  2.3214909009590836,\n",
       "  2.321442752809667,\n",
       "  2.32138720367636,\n",
       "  2.32133798924681,\n",
       "  2.3212983544761614,\n",
       "  2.321226397798476,\n",
       "  2.3216994012103362,\n",
       "  2.321639804196847,\n",
       "  2.32163939908234,\n",
       "  2.3215854897791024,\n",
       "  2.32150263356608,\n",
       "  2.3214583500571875,\n",
       "  2.321414661545285,\n",
       "  2.3213537536368247,\n",
       "  2.3213750308957595,\n",
       "  2.3213274970778763,\n",
       "  2.3212744767325266,\n",
       "  2.3212114005346924,\n",
       "  2.321163285862316,\n",
       "  2.3211160867815317,\n",
       "  2.321066825403332,\n",
       "  2.321021629387224,\n",
       "  2.3209685495730197,\n",
       "  2.3209181533140293,\n",
       "  2.3208668092109637,\n",
       "  2.3208044989859493,\n",
       "  2.3207409686512417,\n",
       "  2.3206880297357024,\n",
       "  2.3206871510869234,\n",
       "  2.3206855869818654,\n",
       "  2.320632747896425,\n",
       "  2.3205801010131837,\n",
       "  2.3205134705767607,\n",
       "  2.3211831728184253,\n",
       "  2.3211234645998995,\n",
       "  2.3210618082423844,\n",
       "  2.321020871884114,\n",
       "  2.3209877573254936,\n",
       "  2.3209103012597687,\n",
       "  2.3208717251591007,\n",
       "  2.32081988214809,\n",
       "  2.3207638823191323,\n",
       "  2.320732367165545,\n",
       "  2.320666364396599,\n",
       "  2.320610764796141,\n",
       "  2.320816692387523,\n",
       "  2.320776685288078,\n",
       "  2.3207227432821678,\n",
       "  2.320661537934348,\n",
       "  2.3206112889023425,\n",
       "  2.3205918154368796,\n",
       "  2.3220732639362285,\n",
       "  2.3220228914152155,\n",
       "  2.321981792918163,\n",
       "  2.3219360580149386,\n",
       "  2.321853456276548,\n",
       "  2.321825943237696,\n",
       "  2.3217691984932745,\n",
       "  2.3217423886668924,\n",
       "  2.3222506119094732,\n",
       "  2.322621987555838,\n",
       "  2.3227140921580642,\n",
       "  2.3226650170605594,\n",
       "  2.3226075532754664,\n",
       "  2.3225773183544676,\n",
       "  2.322528846281812,\n",
       "  2.3225939643383025,\n",
       "  2.3225372331100806,\n",
       "  2.3224840893674252,\n",
       "  2.3228132275138837,\n",
       "  2.322762479876528,\n",
       "  2.3227190812428793,\n",
       "  2.3227769353706846,\n",
       "  2.3227044745217964,\n",
       "  2.32265708025764,\n",
       "  2.322579485862937,\n",
       "  2.322533891840679,\n",
       "  2.3226229831250045,\n",
       "  2.3225934383938616,\n",
       "  2.3228246288207197,\n",
       "  2.322801250766441,\n",
       "  2.3227362075483944,\n",
       "  2.3226848147236385,\n",
       "  2.32266501785754,\n",
       "  2.322619573921678,\n",
       "  2.3225724037052053,\n",
       "  2.3225292154720854,\n",
       "  2.3224842650307047,\n",
       "  2.322423359794074,\n",
       "  2.3223755461104374,\n",
       "  2.3223171880785025,\n",
       "  2.3222644441268026,\n",
       "  2.3222162393337125,\n",
       "  2.3226793705719135,\n",
       "  2.322621366688024,\n",
       "  2.3225871471814066,\n",
       "  2.3226674445839817,\n",
       "  2.32263660099003,\n",
       "  2.3226062379501484,\n",
       "  2.322565258237561,\n",
       "  2.322519733059791,\n",
       "  2.322470570706773,\n",
       "  2.3224821965628806,\n",
       "  2.322438147302623,\n",
       "  2.322411271535098,\n",
       "  2.3223442873813567,\n",
       "  2.322298441691832,\n",
       "  2.32225553573124,\n",
       "  2.322211699248439,\n",
       "  2.322594332102997,\n",
       "  2.322549448893951,\n",
       "  2.3225152931856305,\n",
       "  2.3225915469396274,\n",
       "  2.322704962702672,\n",
       "  2.322660030531032,\n",
       "  2.3228275122780575,\n",
       "  2.3227680089738634,\n",
       "  2.322730888548553,\n",
       "  2.3226855481620383,\n",
       "  2.3226390237576653,\n",
       "  2.3226064538115447,\n",
       "  2.3225712886223424,\n",
       "  2.3225291209262715,\n",
       "  2.3225654778386624,\n",
       "  2.3225168562351874,\n",
       "  2.322483037811479,\n",
       "  2.3224402883778446,\n",
       "  2.322408502376002,\n",
       "  2.322374849092393,\n",
       "  2.3223287606084835,\n",
       "  2.3226065954257704,\n",
       "  2.3226317897919686,\n",
       "  2.3226015700802782,\n",
       "  2.322555255073041,\n",
       "  2.322504358923333,\n",
       "  2.322478190612793],\n",
       " [2.3059773445129395,\n",
       "  2.3089842796325684,\n",
       "  2.31172776222229,\n",
       "  2.345678985118866,\n",
       "  2.337668514251709,\n",
       "  2.3317336241404214,\n",
       "  2.327726568494524,\n",
       "  2.3245281279087067,\n",
       "  2.323008033964369,\n",
       "  2.3210194587707518,\n",
       "  2.3192371238361704,\n",
       "  2.319366912047068,\n",
       "  2.3181559489323544,\n",
       "  2.317344972065517,\n",
       "  2.3163485368092855,\n",
       "  2.3156710416078568,\n",
       "  2.315083447624655,\n",
       "  2.3143220610088773,\n",
       "  2.31357657281976,\n",
       "  2.3129555225372314,\n",
       "  2.3123319376082647,\n",
       "  2.318362918767062,\n",
       "  2.3177562485570493,\n",
       "  2.3172000547250113,\n",
       "  2.3166082286834717,\n",
       "  2.3161728290411143,\n",
       "  2.3157827147731074,\n",
       "  2.3153414130210876,\n",
       "  2.3146050962908515,\n",
       "  2.314203476905823,\n",
       "  2.3136859632307485,\n",
       "  2.313449092209339,\n",
       "  2.3130995288039697,\n",
       "  2.3128142707488117,\n",
       "  2.3128963129861013,\n",
       "  2.3126486076249018,\n",
       "  2.312304889833605,\n",
       "  2.311924796355398,\n",
       "  2.3117339488787527,\n",
       "  2.3116552889347077,\n",
       "  2.3113929411260092,\n",
       "  2.3112054495584395,\n",
       "  2.310944496199142,\n",
       "  2.3106480565938083,\n",
       "  2.31043774816725,\n",
       "  2.310322175855222,\n",
       "  2.3101999759674072,\n",
       "  2.3100806524356208,\n",
       "  2.3099701647855797,\n",
       "  2.3097448253631594,\n",
       "  2.3095917935464896,\n",
       "  2.3094378205446096,\n",
       "  2.309365250029654,\n",
       "  2.309272152406198,\n",
       "  2.3092417153445157,\n",
       "  2.3090929431574687,\n",
       "  2.3089938958485923,\n",
       "  2.311119091921839,\n",
       "  2.3109528856762385,\n",
       "  2.3109472751617433,\n",
       "  2.3107618738393314,\n",
       "  2.31071400642395,\n",
       "  2.3105903542231,\n",
       "  2.3104317598044872,\n",
       "  2.310382259809054,\n",
       "  2.310260848565535,\n",
       "  2.3101613201312166,\n",
       "  2.3100292051539704,\n",
       "  2.309962701106417,\n",
       "  2.3098944527762275,\n",
       "  2.309823580191169,\n",
       "  2.3097525901264615,\n",
       "  2.309716626389386,\n",
       "  2.3096577573466943,\n",
       "  2.3096019204457603,\n",
       "  2.309488506693589,\n",
       "  2.3093656595651204,\n",
       "  2.3092692570808606,\n",
       "  2.309199963943868,\n",
       "  2.3091671049594877,\n",
       "  2.309095465106729,\n",
       "  2.3091100192651517,\n",
       "  2.3090855701860176,\n",
       "  2.308994520278204,\n",
       "  2.3088707110461066,\n",
       "  2.308836670809014,\n",
       "  2.308738755083632,\n",
       "  2.30867400765419,\n",
       "  2.308573280827383,\n",
       "  2.308499052789476,\n",
       "  2.3084848136692258,\n",
       "  2.308457594850789,\n",
       "  2.3084024972813104,\n",
       "  2.308328331784999,\n",
       "  2.3096823190387927,\n",
       "  2.3095820297797522,\n",
       "  2.309482500725186,\n",
       "  2.3094233688043087,\n",
       "  2.309396425882975,\n",
       "  2.3093274974823,\n",
       "  2.3093546924024526,\n",
       "  2.3096939488953234,\n",
       "  2.309692824928506,\n",
       "  2.3096416271649876,\n",
       "  2.3095491840725852,\n",
       "  2.309507538687508,\n",
       "  2.3094644234559247,\n",
       "  2.3094377870912903,\n",
       "  2.3093543861984114,\n",
       "  2.3093051585284146,\n",
       "  2.309073235537555,\n",
       "  2.3090271779469083,\n",
       "  2.3089967533550433,\n",
       "  2.308962207091482,\n",
       "  2.308919688929682,\n",
       "  2.308861177543114,\n",
       "  2.308867099957588,\n",
       "  2.3087972564212347,\n",
       "  2.308762047471119,\n",
       "  2.310479595263799,\n",
       "  2.3104427550449844,\n",
       "  2.310372018423237,\n",
       "  2.3103237345935854,\n",
       "  2.3102418126598483,\n",
       "  2.3102827167510984,\n",
       "  2.3106296365223233,\n",
       "  2.3107820045290968,\n",
       "  2.310715463012457,\n",
       "  2.3106412111326704,\n",
       "  2.3105774512657753,\n",
       "  2.3105143900136,\n",
       "  2.310596764087677,\n",
       "  2.3105259389805615,\n",
       "  2.3105361942035048,\n",
       "  2.3105650778169986,\n",
       "  2.310510716017555,\n",
       "  2.3104706019380665,\n",
       "  2.3129119233808657,\n",
       "  2.312841797904145,\n",
       "  2.3128545471600126,\n",
       "  2.3127723602538413,\n",
       "  2.312748499319587,\n",
       "  2.3126823652040707,\n",
       "  2.3125963111718497,\n",
       "  2.312550186288768,\n",
       "  2.3124747700887185,\n",
       "  2.312421115888219,\n",
       "  2.312407524199099,\n",
       "  2.3123312812523555,\n",
       "  2.3122835969924926,\n",
       "  2.3122235197105154,\n",
       "  2.3121888229721472,\n",
       "  2.3121459904839012,\n",
       "  2.312095583259285,\n",
       "  2.312063123333839,\n",
       "  2.312014032632877,\n",
       "  2.3119428871543546,\n",
       "  2.3118939218641836,\n",
       "  2.3118291381020217,\n",
       "  2.3117585241794587,\n",
       "  2.3117103073167504,\n",
       "  2.311642520221663,\n",
       "  2.3115748978831285,\n",
       "  2.311516863543813,\n",
       "  2.3116137287833474,\n",
       "  2.3115439888942673,\n",
       "  2.311671014317495,\n",
       "  2.311600148677826,\n",
       "  2.312035746828339,\n",
       "  2.311975664250991,\n",
       "  2.3119307261461404,\n",
       "  2.3119058262470156,\n",
       "  2.311850893704188,\n",
       "  2.3117678946462172,\n",
       "  2.3117348112378804,\n",
       "  2.3116697790947827,\n",
       "  2.311650988745824,\n",
       "  2.3115747550900063,\n",
       "  2.3114961072719296,\n",
       "  2.3114601095517475,\n",
       "  2.311405835230706,\n",
       "  2.3113605242509108,\n",
       "  2.311339048739991,\n",
       "  2.3113415435604425,\n",
       "  2.311479714110091,\n",
       "  2.3114473742823445,\n",
       "  2.311401251165625,\n",
       "  2.311347224610917,\n",
       "  2.3113031008886913,\n",
       "  2.311266666964481,\n",
       "  2.311211006803662,\n",
       "  2.311167895793915,\n",
       "  2.3111346669765336,\n",
       "  2.3110699432412374,\n",
       "  2.311004467499562,\n",
       "  2.3109543408666338,\n",
       "  2.310907892769363,\n",
       "  2.310878974018675,\n",
       "  2.3108471110837545,\n",
       "  2.3108096516132353,\n",
       "  2.310742219289144,\n",
       "  2.3106952716808506,\n",
       "  2.3106470119776983,\n",
       "  2.3106000668862285,\n",
       "  2.3105577457241897,\n",
       "  2.310525497186531,\n",
       "  2.3105110235260304,\n",
       "  2.3105103247440777,\n",
       "  2.3104663362913724,\n",
       "  2.310394580023629,\n",
       "  2.310418307498733,\n",
       "  2.310371312330354,\n",
       "  2.310329449568556,\n",
       "  2.3102912847126755,\n",
       "  2.3102505961129833,\n",
       "  2.310208182643961,\n",
       "  2.310166196339691,\n",
       "  2.3101265310147485,\n",
       "  2.3101779434778917,\n",
       "  2.3101438164710997,\n",
       "  2.310101035493531,\n",
       "  2.3101357780061327,\n",
       "  2.310105024431853,\n",
       "  2.310063217367445,\n",
       "  2.310169003804525,\n",
       "  2.3101196394557446,\n",
       "  2.3100673826780613,\n",
       "  2.310052254743743,\n",
       "  2.310018883001336,\n",
       "  2.310025926258253,\n",
       "  2.3099948172961478,\n",
       "  2.309973168989708,\n",
       "  2.309942475715932,\n",
       "  2.309923739514799,\n",
       "  2.309908251052207,\n",
       "  2.3098948840367592,\n",
       "  2.3098785414474423,\n",
       "  2.3104929633501197,\n",
       "  2.3104101374558326,\n",
       "  2.3103795995314917,\n",
       "  2.310322268869867,\n",
       "  2.3102760039085197,\n",
       "  2.310249976169916,\n",
       "  2.3102365165460306,\n",
       "  2.310207038996171,\n",
       "  2.31020710429525,\n",
       "  2.3101753754171765,\n",
       "  2.310147689234826,\n",
       "  2.310117032154497,\n",
       "  2.3100818519592283,\n",
       "  2.3100336006438114,\n",
       "  2.3100333119195606,\n",
       "  2.310006908748461,\n",
       "  2.30997588315348,\n",
       "  2.3099535783131917,\n",
       "  2.3099300619214773,\n",
       "  2.309917650334102,\n",
       "  2.309897489325945,\n",
       "  2.309851600396587,\n",
       "  2.3098401913276088,\n",
       "  2.309834200760414,\n",
       "  2.3098189029984804,\n",
       "  2.309797462855002,\n",
       "  2.3097628969134707,\n",
       "  2.3098668728234633,\n",
       "  2.3098625563141097,\n",
       "  2.309821641400512,\n",
       "  2.3098069856415933,\n",
       "  2.3097806287077725,\n",
       "  2.30975224353649,\n",
       "  2.309725187801347,\n",
       "  2.3097031870309044,\n",
       "  2.3096735093183134,\n",
       "  2.3096431485057747,\n",
       "  2.309615398753773,\n",
       "  2.3095904433208965,\n",
       "  2.309565456335295,\n",
       "  2.3095395307746722,\n",
       "  2.309512463094513,\n",
       "  2.309482503788812,\n",
       "  2.3094325532268374,\n",
       "  2.3093941355427954,\n",
       "  2.309411477705615,\n",
       "  2.3095924871068605,\n",
       "  2.309556792075174,\n",
       "  2.309543140284665,\n",
       "  2.309512032864401,\n",
       "  2.3095038168960147,\n",
       "  2.309472375262567,\n",
       "  2.309452225422037,\n",
       "  2.3094429543747523,\n",
       "  2.309438811589594,\n",
       "  2.3093974891376168,\n",
       "  2.309403499778436,\n",
       "  2.3093824588646323,\n",
       "  2.309376167284476,\n",
       "  2.30937659941137,\n",
       "  2.309354366072072,\n",
       "  2.3093433340257628,\n",
       "  2.30932596206665,\n",
       "  2.3093241425447686,\n",
       "  2.3093248826778487,\n",
       "  2.309294606986219,\n",
       "  2.3092981976898095,\n",
       "  2.3092813296396226,\n",
       "  2.3092524802762697,\n",
       "  2.309241489012777,\n",
       "  2.3092139030431773,\n",
       "  2.309188848946087,\n",
       "  2.309183253011396,\n",
       "  2.309160067720812,\n",
       "  2.3091472754111657,\n",
       "  2.309130760046621,\n",
       "  2.3091320528346264,\n",
       "  2.309111331001161,\n",
       "  2.309087850625002,\n",
       "  2.309063023197162,\n",
       "  2.3090381224950156,\n",
       "  2.309012646211726,\n",
       "  2.3090004950761793,\n",
       "  2.3089845321631506,\n",
       "  2.308965451228693,\n",
       "  2.3089460713944567,\n",
       "  2.3089248523300077,\n",
       "  2.308894315132728,\n",
       "  2.308876095373938,\n",
       "  2.3088482126183467,\n",
       "  2.3088342329350913,\n",
       "  2.3088151473767127,\n",
       "  2.308807690215833,\n",
       "  2.3087838315531566,\n",
       "  2.3087678393685676,\n",
       "  2.3087477218639387,\n",
       "  2.3087270516835288,\n",
       "  2.3087268238636987,\n",
       "  2.308719881943294,\n",
       "  2.308710311923607,\n",
       "  2.3086987994831696,\n",
       "  2.3088007451510357,\n",
       "  2.30878825748668,\n",
       "  2.3087714298729325,\n",
       "  2.3087510923196,\n",
       "  2.308729777183199,\n",
       "  2.3087123251238535,\n",
       "  2.3086948595185213,\n",
       "  2.308682827591207,\n",
       "  2.3086683427222523,\n",
       "  2.308652857939402,\n",
       "  2.3086419768183144,\n",
       "  2.3086181102480205,\n",
       "  2.308604556950409,\n",
       "  2.3085815865885126,\n",
       "  2.3085505982634027,\n",
       "  2.3085372522052396,\n",
       "  2.3089317926218813,\n",
       "  2.3089100892624157,\n",
       "  2.3088904876334992,\n",
       "  2.308877892334368,\n",
       "  2.3088597407912146,\n",
       "  2.3088441881868573,\n",
       "  2.308817481730453,\n",
       "  2.3088228702545166,\n",
       "  2.3088113256722442,\n",
       "  2.308778172010904,\n",
       "  2.3087736489021613,\n",
       "  2.308768990912724,\n",
       "  2.3087866293312094,\n",
       "  2.3087704116883487,\n",
       "  2.308746128547482,\n",
       "  2.3087341540568582,\n",
       "  2.3087307680649256,\n",
       "  2.308722604346532,\n",
       "  2.3087094021866212,\n",
       "  2.30869858787659,\n",
       "  2.308685986836751,\n",
       "  2.308658924508602,\n",
       "  2.3086434024082254,\n",
       "  2.3090664457391807,\n",
       "  2.309047020205093,\n",
       "  2.3090452853002046,\n",
       "  2.309028201215849,\n",
       "  2.3090436820584443,\n",
       "  2.30903129415786,\n",
       "  2.3090153224766254,\n",
       "  2.3089965232006917,\n",
       "  2.3089782919908433,\n",
       "  2.3089601894989804,\n",
       "  2.3089416389612807,\n",
       "  2.308915700275058,\n",
       "  2.3089029929576776,\n",
       "  2.3091605410856357,\n",
       "  2.3091301017878005,\n",
       "  2.309111942771737,\n",
       "  2.309099153818818,\n",
       "  2.3091415326806564,\n",
       "  2.3091149113394995,\n",
       "  2.3091106757108752,\n",
       "  2.3090775893561206,\n",
       "  2.3090712408672895,\n",
       "  2.309247577190399,\n",
       "  2.30923255958462,\n",
       "  2.3092078860126324,\n",
       "  2.309197756551927,\n",
       "  2.309197206898491,\n",
       "  2.309173443287979,\n",
       "  2.3091343324172673,\n",
       "  2.309112193250539,\n",
       "  2.3091083513755426,\n",
       "  2.309134806863836,\n",
       "  2.309115401128443,\n",
       "  2.309090755281657,\n",
       "  2.3090774943527665,\n",
       "  2.3090651606820685,\n",
       "  2.3090493189539885,\n",
       "  2.3090132891413675,\n",
       "  2.309004956139968,\n",
       "  2.3089982394120105,\n",
       "  2.3089822844455115,\n",
       "  2.308947894908932,\n",
       "  2.3089288399333046,\n",
       "  2.3089112940989875,\n",
       "  2.3088912720928825,\n",
       "  2.3088807783510106,\n",
       "  2.3088632765805945,\n",
       "  2.30884103270138,\n",
       "  2.30919232950524,\n",
       "  2.309194581570056,\n",
       "  2.3091914085584264,\n",
       "  2.3092774844669797,\n",
       "  2.3092763224313426,\n",
       "  2.309275872746089,\n",
       "  2.3092769097398826,\n",
       "  2.309259319415544,\n",
       "  2.3092320426817863,\n",
       "  2.309213331375999,\n",
       "  2.309196223359589,\n",
       "  2.3091881258809592,\n",
       "  2.3091460281311105,\n",
       "  2.3097321862240316,\n",
       "  2.309719040177085,\n",
       "  2.3097157489145155,\n",
       "  2.3096947270820585,\n",
       "  2.3098007088051964,\n",
       "  2.3097887264715657,\n",
       "  2.3097735538911284,\n",
       "  2.309758062854476,\n",
       "  2.3097423264377603,\n",
       "  2.309711746339287,\n",
       "  2.309918052635108,\n",
       "  2.3099913793139986,\n",
       "  2.3099744843273626,\n",
       "  2.3099639531785408,\n",
       "  2.3099360713369275,\n",
       "  2.3099328631346445,\n",
       "  2.309915887916481,\n",
       "  2.30990585527922,\n",
       "  2.3098922412296354,\n",
       "  2.3098866569943826,\n",
       "  2.3098682624841826,\n",
       "  2.309836683065995,\n",
       "  2.309808124947703,\n",
       "  2.3097875458853587,\n",
       "  2.309768280251752,\n",
       "  2.3097553124715544,\n",
       "  2.3097785657451997,\n",
       "  2.309763626479284,\n",
       "  2.309746067324849,\n",
       "  2.309735820843623,\n",
       "  2.309724133300781]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0625,\n",
       "  0.0703125,\n",
       "  0.06510416666666667,\n",
       "  0.078125,\n",
       "  0.075,\n",
       "  0.08072916666666667,\n",
       "  0.08370535714285714,\n",
       "  0.0869140625,\n",
       "  0.0920138888888889,\n",
       "  0.0921875,\n",
       "  0.09375,\n",
       "  0.09309895833333333,\n",
       "  0.09314903846153846,\n",
       "  0.09430803571428571,\n",
       "  0.09427083333333333,\n",
       "  0.095703125,\n",
       "  0.09466911764705882,\n",
       "  0.09505208333333333,\n",
       "  0.09498355263157894,\n",
       "  0.097265625,\n",
       "  0.0974702380952381,\n",
       "  0.09801136363636363,\n",
       "  0.09884510869565218,\n",
       "  0.0966796875,\n",
       "  0.0965625,\n",
       "  0.09885817307692307,\n",
       "  0.09895833333333333,\n",
       "  0.09877232142857142,\n",
       "  0.09886853448275862,\n",
       "  0.1015625,\n",
       "  0.10181451612903226,\n",
       "  0.102294921875,\n",
       "  0.10321969696969698,\n",
       "  0.10340073529411764,\n",
       "  0.10401785714285715,\n",
       "  0.10416666666666667,\n",
       "  0.10472972972972973,\n",
       "  0.10526315789473684,\n",
       "  0.1063701923076923,\n",
       "  0.10625,\n",
       "  0.10727896341463415,\n",
       "  0.10677083333333333,\n",
       "  0.10846656976744186,\n",
       "  0.10973011363636363,\n",
       "  0.10902777777777778,\n",
       "  0.10869565217391304,\n",
       "  0.10920877659574468,\n",
       "  0.11067708333333333,\n",
       "  0.11128826530612244,\n",
       "  0.11234375,\n",
       "  0.11228553921568628,\n",
       "  0.11328125,\n",
       "  0.11527122641509434,\n",
       "  0.11588541666666667,\n",
       "  0.11690340909090909,\n",
       "  0.11788504464285714,\n",
       "  0.11828399122807018,\n",
       "  0.11786099137931035,\n",
       "  0.11652542372881355,\n",
       "  0.116796875,\n",
       "  0.1173155737704918,\n",
       "  0.11743951612903226,\n",
       "  0.11793154761904762,\n",
       "  0.1180419921875,\n",
       "  0.11766826923076923,\n",
       "  0.11777935606060606,\n",
       "  0.11765391791044776,\n",
       "  0.1174172794117647,\n",
       "  0.11662137681159421,\n",
       "  0.11618303571428572,\n",
       "  0.11685739436619719,\n",
       "  0.11664496527777778,\n",
       "  0.11665239726027397,\n",
       "  0.11665962837837837,\n",
       "  0.11666666666666667,\n",
       "  0.11729029605263158,\n",
       "  0.11678165584415584,\n",
       "  0.11708733974358974,\n",
       "  0.11669303797468354,\n",
       "  0.1162109375,\n",
       "  0.11641589506172839,\n",
       "  0.11661585365853659,\n",
       "  0.1171875,\n",
       "  0.11662946428571429,\n",
       "  0.11636029411764706,\n",
       "  0.11609738372093023,\n",
       "  0.11619971264367816,\n",
       "  0.11629971590909091,\n",
       "  0.11630969101123595,\n",
       "  0.11605902777777778,\n",
       "  0.11624313186813187,\n",
       "  0.11608355978260869,\n",
       "  0.11575940860215053,\n",
       "  0.11602393617021277,\n",
       "  0.115625,\n",
       "  0.11539713541666667,\n",
       "  0.11533505154639176,\n",
       "  0.11495535714285714,\n",
       "  0.11521464646464646,\n",
       "  0.1159375,\n",
       "  0.11594987623762376,\n",
       "  0.11603860294117647,\n",
       "  0.11589805825242719,\n",
       "  0.1161358173076923,\n",
       "  0.11607142857142858,\n",
       "  0.11615566037735849,\n",
       "  0.11623831775700935,\n",
       "  0.11725983796296297,\n",
       "  0.1173308486238532,\n",
       "  0.11725852272727273,\n",
       "  0.11768018018018019,\n",
       "  0.11851283482142858,\n",
       "  0.11850110619469026,\n",
       "  0.11848958333333333,\n",
       "  0.11854619565217392,\n",
       "  0.11819773706896551,\n",
       "  0.11805555555555555,\n",
       "  0.11818061440677965,\n",
       "  0.11830357142857142,\n",
       "  0.11822916666666666,\n",
       "  0.11783316115702479,\n",
       "  0.1175717213114754,\n",
       "  0.1173780487804878,\n",
       "  0.11737651209677419,\n",
       "  0.1173125,\n",
       "  0.1171875,\n",
       "  0.11694143700787402,\n",
       "  0.11651611328125,\n",
       "  0.11652131782945736,\n",
       "  0.11622596153846154,\n",
       "  0.1160543893129771,\n",
       "  0.11600378787878787,\n",
       "  0.11548402255639098,\n",
       "  0.11578824626865672,\n",
       "  0.11556712962962963,\n",
       "  0.115234375,\n",
       "  0.11536268248175183,\n",
       "  0.11537590579710146,\n",
       "  0.1155013489208633,\n",
       "  0.11540178571428572,\n",
       "  0.11546985815602837,\n",
       "  0.11548195422535211,\n",
       "  0.11576704545454546,\n",
       "  0.11572265625,\n",
       "  0.11524784482758621,\n",
       "  0.11494006849315068,\n",
       "  0.11463647959183673,\n",
       "  0.11470650337837837,\n",
       "  0.11482802013422819,\n",
       "  0.1146875,\n",
       "  0.1146523178807947,\n",
       "  0.11456620065789473,\n",
       "  0.11443014705882353,\n",
       "  0.11419439935064934,\n",
       "  0.11401209677419355,\n",
       "  0.11378205128205128,\n",
       "  0.11365445859872611,\n",
       "  0.11377571202531646,\n",
       "  0.11394457547169812,\n",
       "  0.11376953125,\n",
       "  0.1139848602484472,\n",
       "  0.1136670524691358,\n",
       "  0.11349693251533742,\n",
       "  0.11323361280487805,\n",
       "  0.11358901515151515,\n",
       "  0.11342243975903614,\n",
       "  0.11311751497005988,\n",
       "  0.11300223214285714,\n",
       "  0.11302699704142012,\n",
       "  0.11291360294117647,\n",
       "  0.1126187865497076,\n",
       "  0.1125999273255814,\n",
       "  0.11271676300578035,\n",
       "  0.11314655172413793,\n",
       "  0.11299107142857143,\n",
       "  0.11265980113636363,\n",
       "  0.1127736581920904,\n",
       "  0.11306179775280899,\n",
       "  0.11321578212290503,\n",
       "  0.11319444444444444,\n",
       "  0.11321650552486189,\n",
       "  0.11293784340659341,\n",
       "  0.11266222677595629,\n",
       "  0.11260190217391304,\n",
       "  0.11254222972972973,\n",
       "  0.11256720430107527,\n",
       "  0.1126754679144385,\n",
       "  0.11278257978723404,\n",
       "  0.11259920634920635,\n",
       "  0.11245888157894737,\n",
       "  0.11223821989528796,\n",
       "  0.11214192708333333,\n",
       "  0.11192519430051813,\n",
       "  0.11175096649484537,\n",
       "  0.11149839743589744,\n",
       "  0.1112484056122449,\n",
       "  0.1112388959390863,\n",
       "  0.1111111111111111,\n",
       "  0.11118090452261306,\n",
       "  0.1109765625,\n",
       "  0.11077425373134328,\n",
       "  0.11072865099009901,\n",
       "  0.11079895320197045,\n",
       "  0.11060049019607843,\n",
       "  0.11040396341463414,\n",
       "  0.11024726941747573,\n",
       "  0.1101298309178744,\n",
       "  0.11008864182692307,\n",
       "  0.10997308612440192,\n",
       "  0.10993303571428571,\n",
       "  0.10978228672985782,\n",
       "  0.10966981132075472,\n",
       "  0.10970510563380281,\n",
       "  0.10977657710280374,\n",
       "  0.10973837209302326,\n",
       "  0.10955584490740741,\n",
       "  0.10955501152073732,\n",
       "  0.10941083715596331,\n",
       "  0.10930365296803653,\n",
       "  0.10941051136363636,\n",
       "  0.10941035067873303,\n",
       "  0.10933980855855856,\n",
       "  0.10941003363228699,\n",
       "  0.10934012276785714,\n",
       "  0.10927083333333333,\n",
       "  0.1093058628318584,\n",
       "  0.10934058370044053,\n",
       "  0.10923793859649122,\n",
       "  0.10906795851528384,\n",
       "  0.10903532608695653,\n",
       "  0.10896915584415584,\n",
       "  0.10886988146551724,\n",
       "  0.10883851931330472,\n",
       "  0.10884081196581197,\n",
       "  0.10874335106382979,\n",
       "  0.1086136122881356,\n",
       "  0.10848496835443038,\n",
       "  0.10858718487394958,\n",
       "  0.10855779288702928,\n",
       "  0.10830078125,\n",
       "  0.10840248962655602,\n",
       "  0.10814824380165289,\n",
       "  0.10818544238683128,\n",
       "  0.10812628073770492,\n",
       "  0.1079719387755102,\n",
       "  0.10794588414634146,\n",
       "  0.10795167004048584,\n",
       "  0.10776839717741936,\n",
       "  0.10777484939759036,\n",
       "  0.10759375,\n",
       "  0.10760084661354581,\n",
       "  0.10766989087301587,\n",
       "  0.10755311264822134,\n",
       "  0.10756028543307086,\n",
       "  0.10759803921568628,\n",
       "  0.10760498046875,\n",
       "  0.10764226653696499,\n",
       "  0.10770954457364341,\n",
       "  0.10765564671814672,\n",
       "  0.10763221153846154,\n",
       "  0.1077286877394636,\n",
       "  0.10776479007633588,\n",
       "  0.10762238593155894,\n",
       "  0.107421875,\n",
       "  0.10731132075471699,\n",
       "  0.10726033834586467,\n",
       "  0.10720973782771535,\n",
       "  0.10707206156716417,\n",
       "  0.10699349442379182,\n",
       "  0.10694444444444444,\n",
       "  0.10695341328413284,\n",
       "  0.10678998161764706,\n",
       "  0.10668498168498168,\n",
       "  0.10672331204379562,\n",
       "  0.10664772727272727,\n",
       "  0.10651607789855072,\n",
       "  0.10646999097472924,\n",
       "  0.10628372302158273,\n",
       "  0.1062948028673835,\n",
       "  0.10622209821428572,\n",
       "  0.10620551601423488,\n",
       "  0.10605053191489362,\n",
       "  0.10600706713780919,\n",
       "  0.10599141725352113,\n",
       "  0.1058936403508772,\n",
       "  0.1057965472027972,\n",
       "  0.10580901567944251,\n",
       "  0.10565863715277778,\n",
       "  0.1056985294117647,\n",
       "  0.1056842672413793,\n",
       "  0.1056164089347079,\n",
       "  0.1054419948630137,\n",
       "  0.10521544368600683,\n",
       "  0.1051498724489796,\n",
       "  0.1050052966101695,\n",
       "  0.10512563344594594,\n",
       "  0.10508733164983165,\n",
       "  0.10502307046979865,\n",
       "  0.10493311036789298,\n",
       "  0.10505208333333334,\n",
       "  0.10532599667774087,\n",
       "  0.10523592715231789,\n",
       "  0.10530115511551155,\n",
       "  0.10528885690789473,\n",
       "  0.10537909836065573,\n",
       "  0.10541768790849673,\n",
       "  0.10537968241042345,\n",
       "  0.1053419237012987,\n",
       "  0.10515271035598706,\n",
       "  0.10516633064516129,\n",
       "  0.10515474276527331,\n",
       "  0.10521834935897435,\n",
       "  0.1051317891373802,\n",
       "  0.10507066082802548,\n",
       "  0.10500992063492064,\n",
       "  0.10499901107594936,\n",
       "  0.10488958990536278,\n",
       "  0.10492826257861636,\n",
       "  0.10513812695924765,\n",
       "  0.10498046875,\n",
       "  0.10494548286604362,\n",
       "  0.10483792701863354,\n",
       "  0.10485197368421052,\n",
       "  0.10496238425925926,\n",
       "  0.10485576923076922,\n",
       "  0.10477377300613497,\n",
       "  0.10464449541284404,\n",
       "  0.10463509908536585,\n",
       "  0.10457826747720365,\n",
       "  0.10461647727272727,\n",
       "  0.10453644259818731,\n",
       "  0.1046922063253012,\n",
       "  0.10463588588588589,\n",
       "  0.10472024700598802,\n",
       "  0.10473414179104477,\n",
       "  0.10470145089285714,\n",
       "  0.10473850148367952,\n",
       "  0.10461353550295859,\n",
       "  0.10462758112094395,\n",
       "  0.10466452205882353,\n",
       "  0.1046783357771261,\n",
       "  0.10466922514619884,\n",
       "  0.10461461370262391,\n",
       "  0.10453760901162791,\n",
       "  0.10464221014492754,\n",
       "  0.10470104768786127,\n",
       "  0.10462445965417867,\n",
       "  0.10466056034482758,\n",
       "  0.10456214183381089,\n",
       "  0.10457589285714286,\n",
       "  0.1045673076923077,\n",
       "  0.10446999289772728,\n",
       "  0.10441749291784702,\n",
       "  0.1044094279661017,\n",
       "  0.10429137323943662,\n",
       "  0.10434954353932584,\n",
       "  0.10425420168067227,\n",
       "  0.10431215083798882,\n",
       "  0.1044350626740947,\n",
       "  0.10438368055555555,\n",
       "  0.10420273545706371,\n",
       "  0.10421702348066299,\n",
       "  0.10416666666666667,\n",
       "  0.10411658653846154,\n",
       "  0.10410958904109589,\n",
       "  0.10397455601092896,\n",
       "  0.1039466961852861,\n",
       "  0.10391898777173914,\n",
       "  0.10384908536585366,\n",
       "  0.10373733108108107,\n",
       "  0.1037525269541779,\n",
       "  0.10370463709677419,\n",
       "  0.10369889410187667,\n",
       "  0.10371407085561497,\n",
       "  0.10364583333333334,\n",
       "  0.10357795877659574,\n",
       "  0.10344827586206896,\n",
       "  0.10344328703703703,\n",
       "  0.10341771108179419,\n",
       "  0.10341282894736842,\n",
       "  0.10336696194225722,\n",
       "  0.10342359293193717,\n",
       "  0.10331674281984334,\n",
       "  0.10337320963541667,\n",
       "  0.10332792207792207,\n",
       "  0.10328286917098446,\n",
       "  0.1033187984496124,\n",
       "  0.10337467783505154,\n",
       "  0.10345035347043702,\n",
       "  0.10334535256410256,\n",
       "  0.10342071611253197,\n",
       "  0.10327646683673469,\n",
       "  0.10315283078880406,\n",
       "  0.1031289657360406,\n",
       "  0.10314477848101265,\n",
       "  0.10316051136363637,\n",
       "  0.10317616498740555,\n",
       "  0.10305433417085427,\n",
       "  0.10308975563909774,\n",
       "  0.1030859375,\n",
       "  0.10319903366583541,\n",
       "  0.10307835820895522,\n",
       "  0.10303582506203474,\n",
       "  0.10293548886138613,\n",
       "  0.10293209876543209,\n",
       "  0.10292872536945813,\n",
       "  0.10284858722358722,\n",
       "  0.10294117647058823,\n",
       "  0.10299511002444987,\n",
       "  0.10301067073170732,\n",
       "  0.10302615571776155,\n",
       "  0.10292779126213593,\n",
       "  0.10281098668280872,\n",
       "  0.10273248792270531,\n",
       "  0.10269201807228916,\n",
       "  0.1027080829326923,\n",
       "  0.10272407074340528,\n",
       "  0.10273998205741627,\n",
       "  0.10273717183770883,\n",
       "  0.10264136904761904,\n",
       "  0.10258313539192399,\n",
       "  0.10245112559241706,\n",
       "  0.10246749408983452,\n",
       "  0.10241008254716981,\n",
       "  0.1024264705882353,\n",
       "  0.10253447769953052,\n",
       "  0.10244072014051522,\n",
       "  0.10245692172897196,\n",
       "  0.10245483682983683,\n",
       "  0.10239825581395348,\n",
       "  0.10236006380510441,\n",
       "  0.10239438657407407,\n",
       "  0.10242855080831409,\n",
       "  0.10251656105990783,\n",
       "  0.10242456896551724,\n",
       "  0.10235091743119266,\n",
       "  0.1023491132723112,\n",
       "  0.1022759703196347,\n",
       "  0.10230993735763098,\n",
       "  0.1021484375,\n",
       "  0.10214710884353742,\n",
       "  0.10211043552036199,\n",
       "  0.10212683408577879,\n",
       "  0.10203758445945946,\n",
       "  0.10203651685393259,\n",
       "  0.10208800448430494,\n",
       "  0.10219169463087248,\n",
       "  0.10224260602678571,\n",
       "  0.10213669265033408,\n",
       "  0.10208333333333333,\n",
       "  0.10209950110864745,\n",
       "  0.10211559734513274,\n",
       "  0.10213162251655629,\n",
       "  0.10226803414096916,\n",
       "  0.10230082417582417,\n",
       "  0.10229920504385964,\n",
       "  0.1022804978118162,\n",
       "  0.10219364082969433,\n",
       "  0.10215822440087145,\n",
       "  0.10208899456521739,\n",
       "  0.10207090563991324,\n",
       "  0.10208671536796536,\n",
       "  0.10211933045356371,\n",
       "  0.10216864224137931,\n",
       "  0.10210013440860215,\n",
       "  0.10209898068669528,\n",
       "  0.10206437366167023,\n",
       "  0.10204660790598291,\n",
       "  0.10206666666666667],\n",
       " [0.1015625,\n",
       "  0.10546875,\n",
       "  0.1171875,\n",
       "  0.111328125,\n",
       "  0.109375,\n",
       "  0.10546875,\n",
       "  0.10714285714285714,\n",
       "  0.1025390625,\n",
       "  0.1032986111111111,\n",
       "  0.10703125,\n",
       "  0.10795454545454546,\n",
       "  0.10807291666666667,\n",
       "  0.10697115384615384,\n",
       "  0.10770089285714286,\n",
       "  0.109375,\n",
       "  0.10986328125,\n",
       "  0.11259191176470588,\n",
       "  0.11241319444444445,\n",
       "  0.11266447368421052,\n",
       "  0.1125,\n",
       "  0.11011904761904762,\n",
       "  0.10866477272727272,\n",
       "  0.109375,\n",
       "  0.10872395833333333,\n",
       "  0.10875,\n",
       "  0.10817307692307693,\n",
       "  0.10908564814814815,\n",
       "  0.10993303571428571,\n",
       "  0.10964439655172414,\n",
       "  0.10911458333333333,\n",
       "  0.11088709677419355,\n",
       "  0.112060546875,\n",
       "  0.11221590909090909,\n",
       "  0.11144301470588236,\n",
       "  0.11138392857142858,\n",
       "  0.11046006944444445,\n",
       "  0.11000844594594594,\n",
       "  0.109375,\n",
       "  0.10757211538461539,\n",
       "  0.1068359375,\n",
       "  0.10785060975609756,\n",
       "  0.10788690476190477,\n",
       "  0.10701308139534883,\n",
       "  0.10635653409090909,\n",
       "  0.10729166666666666,\n",
       "  0.10716711956521739,\n",
       "  0.10721409574468085,\n",
       "  0.10660807291666667,\n",
       "  0.10618622448979592,\n",
       "  0.1065625,\n",
       "  0.10692401960784313,\n",
       "  0.10727163461538461,\n",
       "  0.10731132075471699,\n",
       "  0.10677083333333333,\n",
       "  0.10639204545454546,\n",
       "  0.10616629464285714,\n",
       "  0.10581140350877193,\n",
       "  0.1058728448275862,\n",
       "  0.10527012711864407,\n",
       "  0.10559895833333334,\n",
       "  0.10489241803278689,\n",
       "  0.10395665322580645,\n",
       "  0.10416666666666667,\n",
       "  0.10400390625,\n",
       "  0.1045673076923077,\n",
       "  0.10392992424242424,\n",
       "  0.10412779850746269,\n",
       "  0.10477941176470588,\n",
       "  0.10484601449275362,\n",
       "  0.10446428571428572,\n",
       "  0.10431338028169014,\n",
       "  0.1042751736111111,\n",
       "  0.1035958904109589,\n",
       "  0.10388513513513513,\n",
       "  0.10385416666666666,\n",
       "  0.10361842105263158,\n",
       "  0.10409902597402597,\n",
       "  0.10406650641025642,\n",
       "  0.1038370253164557,\n",
       "  0.10419921875,\n",
       "  0.10474537037037036,\n",
       "  0.10470655487804878,\n",
       "  0.10448042168674698,\n",
       "  0.10453869047619048,\n",
       "  0.10413602941176471,\n",
       "  0.10437863372093023,\n",
       "  0.1044360632183908,\n",
       "  0.10413707386363637,\n",
       "  0.10410814606741572,\n",
       "  0.10416666666666667,\n",
       "  0.10362293956043957,\n",
       "  0.10309103260869565,\n",
       "  0.10315860215053764,\n",
       "  0.10272606382978723,\n",
       "  0.10279605263157894,\n",
       "  0.10294596354166667,\n",
       "  0.10325386597938144,\n",
       "  0.10371492346938775,\n",
       "  0.10369318181818182,\n",
       "  0.10359375,\n",
       "  0.10334158415841584,\n",
       "  0.10317095588235294,\n",
       "  0.10300364077669903,\n",
       "  0.10306490384615384,\n",
       "  0.10282738095238095,\n",
       "  0.10274174528301887,\n",
       "  0.10273072429906542,\n",
       "  0.10279224537037036,\n",
       "  0.10235091743119266,\n",
       "  0.10234375,\n",
       "  0.10254786036036036,\n",
       "  0.10239955357142858,\n",
       "  0.1025304203539823,\n",
       "  0.1025219298245614,\n",
       "  0.10278532608695652,\n",
       "  0.10243803879310345,\n",
       "  0.10269764957264957,\n",
       "  0.10255561440677965,\n",
       "  0.10254726890756302,\n",
       "  0.1021484375,\n",
       "  0.10227272727272728,\n",
       "  0.10233094262295082,\n",
       "  0.10200711382113821,\n",
       "  0.10219254032258064,\n",
       "  0.1019375,\n",
       "  0.10193452380952381,\n",
       "  0.10248523622047244,\n",
       "  0.102294921875,\n",
       "  0.10210755813953488,\n",
       "  0.1024639423076923,\n",
       "  0.10239742366412213,\n",
       "  0.10221354166666667,\n",
       "  0.10232612781954888,\n",
       "  0.10237873134328358,\n",
       "  0.10237268518518519,\n",
       "  0.10248161764705882,\n",
       "  0.10241788321167883,\n",
       "  0.10224184782608696,\n",
       "  0.10234937050359712,\n",
       "  0.10239955357142858,\n",
       "  0.10222739361702128,\n",
       "  0.10238776408450705,\n",
       "  0.10265515734265734,\n",
       "  0.1025390625,\n",
       "  0.1025323275862069,\n",
       "  0.10257919520547945,\n",
       "  0.10235969387755102,\n",
       "  0.10245988175675676,\n",
       "  0.10240142617449664,\n",
       "  0.10229166666666667,\n",
       "  0.10218336092715231,\n",
       "  0.10217927631578948,\n",
       "  0.10237949346405228,\n",
       "  0.10222199675324675,\n",
       "  0.10231854838709678,\n",
       "  0.10221354166666667,\n",
       "  0.10225915605095541,\n",
       "  0.10215585443037975,\n",
       "  0.10225039308176101,\n",
       "  0.10205078125,\n",
       "  0.10199922360248448,\n",
       "  0.1019483024691358,\n",
       "  0.10194593558282208,\n",
       "  0.1017530487804878,\n",
       "  0.10170454545454545,\n",
       "  0.1016566265060241,\n",
       "  0.1015625,\n",
       "  0.10193452380952381,\n",
       "  0.10183986686390532,\n",
       "  0.10183823529411765,\n",
       "  0.10165387426900585,\n",
       "  0.10124454941860465,\n",
       "  0.10097543352601156,\n",
       "  0.10066451149425287,\n",
       "  0.10084821428571429,\n",
       "  0.10063032670454546,\n",
       "  0.10067973163841808,\n",
       "  0.10064080056179775,\n",
       "  0.1007332402234637,\n",
       "  0.10065104166666666,\n",
       "  0.10074240331491713,\n",
       "  0.10061813186813187,\n",
       "  0.10053790983606557,\n",
       "  0.1005859375,\n",
       "  0.10059121621621622,\n",
       "  0.10055443548387097,\n",
       "  0.10060160427807487,\n",
       "  0.10048204787234043,\n",
       "  0.10052910052910052,\n",
       "  0.10037006578947369,\n",
       "  0.10045811518324607,\n",
       "  0.10054524739583333,\n",
       "  0.10051003886010362,\n",
       "  0.10063627577319588,\n",
       "  0.10080128205128205,\n",
       "  0.10080516581632654,\n",
       "  0.10080901015228426,\n",
       "  0.1006155303030303,\n",
       "  0.10062028894472362,\n",
       "  0.1005078125,\n",
       "  0.10055192786069651,\n",
       "  0.10051825495049505,\n",
       "  0.10052339901477833,\n",
       "  0.10064338235294118,\n",
       "  0.10064786585365854,\n",
       "  0.10057645631067962,\n",
       "  0.10054347826086957,\n",
       "  0.10039813701923077,\n",
       "  0.10059061004784689,\n",
       "  0.10044642857142858,\n",
       "  0.10034063981042654,\n",
       "  0.10045695754716981,\n",
       "  0.10020539906103286,\n",
       "  0.09999269859813084,\n",
       "  0.10010901162790697,\n",
       "  0.10007957175925926,\n",
       "  0.10001440092165899,\n",
       "  0.10002150229357798,\n",
       "  0.10017123287671233,\n",
       "  0.10003551136363636,\n",
       "  0.10036057692307693,\n",
       "  0.10019003378378379,\n",
       "  0.10037135650224215,\n",
       "  0.10048130580357142,\n",
       "  0.1004513888888889,\n",
       "  0.10038716814159292,\n",
       "  0.10046117841409692,\n",
       "  0.10046600877192982,\n",
       "  0.10050491266375546,\n",
       "  0.10037364130434782,\n",
       "  0.10027732683982683,\n",
       "  0.10021551724137931,\n",
       "  0.1002212982832618,\n",
       "  0.10019364316239317,\n",
       "  0.10009973404255319,\n",
       "  0.10023834745762712,\n",
       "  0.10011207805907173,\n",
       "  0.10018382352941177,\n",
       "  0.10032034518828452,\n",
       "  0.10032552083333333,\n",
       "  0.10033065352697096,\n",
       "  0.10004519628099173,\n",
       "  0.10011574074074074,\n",
       "  0.10015368852459017,\n",
       "  0.10012755102040816,\n",
       "  0.10016514227642276,\n",
       "  0.10010754048582995,\n",
       "  0.09998739919354839,\n",
       "  0.10018197791164658,\n",
       "  0.100375,\n",
       "  0.10031748007968128,\n",
       "  0.10026041666666667,\n",
       "  0.10035820158102766,\n",
       "  0.10039370078740158,\n",
       "  0.10033700980392157,\n",
       "  0.100189208984375,\n",
       "  0.10025535019455253,\n",
       "  0.10013929263565892,\n",
       "  0.10023527992277992,\n",
       "  0.10024038461538462,\n",
       "  0.10030531609195402,\n",
       "  0.10025047709923664,\n",
       "  0.1002851711026616,\n",
       "  0.10037878787878787,\n",
       "  0.10029481132075471,\n",
       "  0.10029957706766918,\n",
       "  0.1002750468164794,\n",
       "  0.10039645522388059,\n",
       "  0.10034270446096655,\n",
       "  0.10037615740740741,\n",
       "  0.10040936346863469,\n",
       "  0.10044232536764706,\n",
       "  0.10036057692307693,\n",
       "  0.10025091240875912,\n",
       "  0.10014204545454546,\n",
       "  0.10006227355072464,\n",
       "  0.09989846570397112,\n",
       "  0.09973583633093525,\n",
       "  0.0998263888888889,\n",
       "  0.0998046875,\n",
       "  0.09978314056939502,\n",
       "  0.09984485815602837,\n",
       "  0.09985092756183746,\n",
       "  0.09971941021126761,\n",
       "  0.0996984649122807,\n",
       "  0.09962303321678322,\n",
       "  0.09952090592334495,\n",
       "  0.0993923611111111,\n",
       "  0.09926470588235294,\n",
       "  0.09921875,\n",
       "  0.09906572164948453,\n",
       "  0.09907427226027397,\n",
       "  0.09908276450511945,\n",
       "  0.09909119897959184,\n",
       "  0.09902012711864407,\n",
       "  0.09897592905405406,\n",
       "  0.09895833333333333,\n",
       "  0.0988359899328859,\n",
       "  0.0989757525083612,\n",
       "  0.098984375,\n",
       "  0.0990967607973422,\n",
       "  0.09913079470198675,\n",
       "  0.09908725247524752,\n",
       "  0.0990953947368421,\n",
       "  0.0991547131147541,\n",
       "  0.09903492647058823,\n",
       "  0.09917039902280131,\n",
       "  0.0991020698051948,\n",
       "  0.09903418284789645,\n",
       "  0.09894153225806451,\n",
       "  0.09889971864951769,\n",
       "  0.09875801282051282,\n",
       "  0.09879193290734824,\n",
       "  0.09872611464968153,\n",
       "  0.09861111111111111,\n",
       "  0.09859572784810126,\n",
       "  0.09867902208201892,\n",
       "  0.09876179245283019,\n",
       "  0.09867260971786834,\n",
       "  0.09873046875,\n",
       "  0.0987636292834891,\n",
       "  0.09884510869565218,\n",
       "  0.09897445820433437,\n",
       "  0.09900655864197531,\n",
       "  0.0990625,\n",
       "  0.0991180981595092,\n",
       "  0.09914946483180428,\n",
       "  0.09918064024390244,\n",
       "  0.09923537234042554,\n",
       "  0.09917140151515151,\n",
       "  0.09929663897280967,\n",
       "  0.09911521084337349,\n",
       "  0.09905217717717718,\n",
       "  0.09898952095808383,\n",
       "  0.09888059701492537,\n",
       "  0.09891183035714286,\n",
       "  0.09891969584569733,\n",
       "  0.0989737426035503,\n",
       "  0.0989813790560472,\n",
       "  0.09896599264705883,\n",
       "  0.09904233870967742,\n",
       "  0.09907255116959064,\n",
       "  0.09892037172011661,\n",
       "  0.09885992005813954,\n",
       "  0.09889039855072464,\n",
       "  0.09889812138728324,\n",
       "  0.09899585734870317,\n",
       "  0.09893588362068965,\n",
       "  0.0990105659025788,\n",
       "  0.09890625,\n",
       "  0.09895833333333333,\n",
       "  0.09912109375,\n",
       "  0.09908374645892351,\n",
       "  0.09917902542372882,\n",
       "  0.09905369718309859,\n",
       "  0.09917047050561797,\n",
       "  0.09924282212885153,\n",
       "  0.0992929469273743,\n",
       "  0.09940807799442897,\n",
       "  0.09930555555555555,\n",
       "  0.09929016620498615,\n",
       "  0.09938276933701658,\n",
       "  0.09943181818181818,\n",
       "  0.09939474587912088,\n",
       "  0.09937928082191781,\n",
       "  0.09936390027322405,\n",
       "  0.09951890326975477,\n",
       "  0.09954568614130435,\n",
       "  0.09959349593495935,\n",
       "  0.09945101351351351,\n",
       "  0.0994777628032345,\n",
       "  0.09944136424731183,\n",
       "  0.09950988605898123,\n",
       "  0.09968248663101605,\n",
       "  0.09966666666666667,\n",
       "  0.09977559840425532,\n",
       "  0.09984250663129973,\n",
       "  0.09997106481481481,\n",
       "  0.09989281002638523,\n",
       "  0.0998766447368421,\n",
       "  0.09994258530183726,\n",
       "  0.10002863219895287,\n",
       "  0.10015502610966058,\n",
       "  0.10009765625,\n",
       "  0.10002029220779221,\n",
       "  0.10008500647668393,\n",
       "  0.10008882428940569,\n",
       "  0.10013289304123711,\n",
       "  0.10013656812339332,\n",
       "  0.10012019230769231,\n",
       "  0.10006393861892583,\n",
       "  0.10014748086734694,\n",
       "  0.10011132315521629,\n",
       "  0.10005552030456853,\n",
       "  0.1,\n",
       "  0.10020123106060606,\n",
       "  0.10026369647355164,\n",
       "  0.1001295540201005,\n",
       "  0.10015272556390978,\n",
       "  0.10021484375,\n",
       "  0.10021820448877805,\n",
       "  0.10018268034825871,\n",
       "  0.1002636476426799,\n",
       "  0.10024752475247525,\n",
       "  0.10040509259259259,\n",
       "  0.10033097290640394,\n",
       "  0.10031480343980344,\n",
       "  0.10031786151960784,\n",
       "  0.10028270171149144,\n",
       "  0.10032393292682927,\n",
       "  0.1001558698296837,\n",
       "  0.10015928398058252,\n",
       "  0.10012484866828088,\n",
       "  0.09999622584541062,\n",
       "  0.1,\n",
       "  0.10000375600961539,\n",
       "  0.09995128896882494,\n",
       "  0.09986169258373205,\n",
       "  0.09988439737470167,\n",
       "  0.09992559523809524,\n",
       "  0.09991092636579572,\n",
       "  0.09991484004739337,\n",
       "  0.09999261229314421,\n",
       "  0.09999631485849056,\n",
       "  0.09998161764705882,\n",
       "  0.09987529342723005,\n",
       "  0.09984265222482436,\n",
       "  0.09986492406542057,\n",
       "  0.09977782634032634,\n",
       "  0.09976380813953488,\n",
       "  0.0998042343387471,\n",
       "  0.0996997974537037,\n",
       "  0.09974018475750578,\n",
       "  0.0996903801843318,\n",
       "  0.09962284482758621,\n",
       "  0.09966313073394495,\n",
       "  0.0996674771167048,\n",
       "  0.09967180365296803,\n",
       "  0.09964051822323462,\n",
       "  0.09966264204545454,\n",
       "  0.09964923469387756,\n",
       "  0.09967123868778281,\n",
       "  0.0996755079006772,\n",
       "  0.09962697072072071,\n",
       "  0.09956109550561798,\n",
       "  0.09956558295964126,\n",
       "  0.09957005033557047,\n",
       "  0.09950474330357142,\n",
       "  0.09959632516703786,\n",
       "  0.09954861111111112,\n",
       "  0.09953575388026607,\n",
       "  0.099522953539823,\n",
       "  0.09954470198675497,\n",
       "  0.09960077092511013,\n",
       "  0.09965659340659341,\n",
       "  0.09969503837719298,\n",
       "  0.09971621991247265,\n",
       "  0.09960084606986899,\n",
       "  0.09963916122004357,\n",
       "  0.09967730978260869,\n",
       "  0.09968139913232105,\n",
       "  0.09968547077922078,\n",
       "  0.09963890388768898,\n",
       "  0.09967672413793104,\n",
       "  0.0996135752688172,\n",
       "  0.09946687231759657,\n",
       "  0.09943790149892934,\n",
       "  0.09947582799145299,\n",
       "  0.09946666666666666],\n",
       " [0.0703125,\n",
       "  0.07421875,\n",
       "  0.07291666666666667,\n",
       "  0.08203125,\n",
       "  0.090625,\n",
       "  0.08333333333333333,\n",
       "  0.0859375,\n",
       "  0.0888671875,\n",
       "  0.09461805555555555,\n",
       "  0.09609375,\n",
       "  0.09375,\n",
       "  0.095703125,\n",
       "  0.09435096153846154,\n",
       "  0.09430803571428571,\n",
       "  0.09114583333333333,\n",
       "  0.09228515625,\n",
       "  0.09053308823529412,\n",
       "  0.09114583333333333,\n",
       "  0.09169407894736842,\n",
       "  0.093359375,\n",
       "  0.09635416666666667,\n",
       "  0.09517045454545454,\n",
       "  0.09578804347826086,\n",
       "  0.09830729166666667,\n",
       "  0.0990625,\n",
       "  0.09795673076923077,\n",
       "  0.09693287037037036,\n",
       "  0.09654017857142858,\n",
       "  0.09698275862068965,\n",
       "  0.09713541666666667,\n",
       "  0.09727822580645161,\n",
       "  0.096923828125,\n",
       "  0.09730113636363637,\n",
       "  0.0978860294117647,\n",
       "  0.09821428571428571,\n",
       "  0.099609375,\n",
       "  0.09923986486486487,\n",
       "  0.09847861842105263,\n",
       "  0.09815705128205128,\n",
       "  0.09765625,\n",
       "  0.09698932926829268,\n",
       "  0.09728422619047619,\n",
       "  0.09756540697674419,\n",
       "  0.09765625,\n",
       "  0.09756944444444444,\n",
       "  0.09918478260869565,\n",
       "  0.09807180851063829,\n",
       "  0.09781901041666667,\n",
       "  0.0977359693877551,\n",
       "  0.09734375,\n",
       "  0.0977328431372549,\n",
       "  0.09825721153846154,\n",
       "  0.09861438679245282,\n",
       "  0.0982349537037037,\n",
       "  0.09872159090909091,\n",
       "  0.09849330357142858,\n",
       "  0.09882127192982457,\n",
       "  0.09873383620689655,\n",
       "  0.09878177966101695,\n",
       "  0.09934895833333333,\n",
       "  0.09938524590163934,\n",
       "  0.09942036290322581,\n",
       "  0.09908234126984126,\n",
       "  0.0986328125,\n",
       "  0.09891826923076923,\n",
       "  0.09872159090909091,\n",
       "  0.09853078358208955,\n",
       "  0.09834558823529412,\n",
       "  0.09861865942028986,\n",
       "  0.09866071428571428,\n",
       "  0.09870158450704225,\n",
       "  0.09874131944444445,\n",
       "  0.09877996575342465,\n",
       "  0.09892314189189189,\n",
       "  0.09958333333333333,\n",
       "  0.099609375,\n",
       "  0.09963474025974026,\n",
       "  0.0999599358974359,\n",
       "  0.09998022151898735,\n",
       "  0.10009765625,\n",
       "  0.09953703703703703,\n",
       "  0.09937118902439024,\n",
       "  0.09949171686746988,\n",
       "  0.0994233630952381,\n",
       "  0.09954044117647058,\n",
       "  0.09938226744186046,\n",
       "  0.09940732758620689,\n",
       "  0.09881036931818182,\n",
       "  0.09901685393258428,\n",
       "  0.09913194444444444,\n",
       "  0.09924450549450549,\n",
       "  0.09943953804347826,\n",
       "  0.09963037634408602,\n",
       "  0.09965093085106383,\n",
       "  0.09967105263157895,\n",
       "  0.09952799479166667,\n",
       "  0.09938788659793814,\n",
       "  0.09909119897959184,\n",
       "  0.09856376262626262,\n",
       "  0.09875,\n",
       "  0.09908725247524752,\n",
       "  0.09926470588235294,\n",
       "  0.09905946601941748,\n",
       "  0.09945913461538461,\n",
       "  0.09947916666666666,\n",
       "  0.09949882075471699,\n",
       "  0.09966413551401869,\n",
       "  0.09968171296296297,\n",
       "  0.10012901376146789,\n",
       "  0.10014204545454546,\n",
       "  0.10015484234234234,\n",
       "  0.10065569196428571,\n",
       "  0.10080199115044247,\n",
       "  0.1006030701754386,\n",
       "  0.10088315217391304,\n",
       "  0.10075431034482758,\n",
       "  0.10082799145299146,\n",
       "  0.10076800847457627,\n",
       "  0.10070903361344538,\n",
       "  0.10084635416666667,\n",
       "  0.10091683884297521,\n",
       "  0.1010502049180328,\n",
       "  0.10092733739837398,\n",
       "  0.10074344758064516,\n",
       "  0.1005,\n",
       "  0.10063244047619048,\n",
       "  0.10063976377952756,\n",
       "  0.100830078125,\n",
       "  0.10077519379844961,\n",
       "  0.10078125,\n",
       "  0.10114503816793893,\n",
       "  0.10085227272727272,\n",
       "  0.10103383458646617,\n",
       "  0.10086287313432836,\n",
       "  0.1009837962962963,\n",
       "  0.10110294117647059,\n",
       "  0.10099224452554745,\n",
       "  0.10093976449275362,\n",
       "  0.10111285971223022,\n",
       "  0.10111607142857143,\n",
       "  0.10145168439716312,\n",
       "  0.10128741197183098,\n",
       "  0.10145323426573427,\n",
       "  0.10167100694444445,\n",
       "  0.1017780172413793,\n",
       "  0.1017765410958904,\n",
       "  0.1017750850340136,\n",
       "  0.10161528716216216,\n",
       "  0.10177223154362416,\n",
       "  0.10182291666666667,\n",
       "  0.10166597682119205,\n",
       "  0.1015625,\n",
       "  0.10146037581699346,\n",
       "  0.10146103896103896,\n",
       "  0.10141129032258064,\n",
       "  0.10136217948717949,\n",
       "  0.10101512738853503,\n",
       "  0.10087025316455696,\n",
       "  0.10097287735849056,\n",
       "  0.10107421875,\n",
       "  0.10098020186335403,\n",
       "  0.10069444444444445,\n",
       "  0.10089148773006135,\n",
       "  0.10103849085365854,\n",
       "  0.10089962121212122,\n",
       "  0.10080948795180723,\n",
       "  0.10076721556886227,\n",
       "  0.10063244047619048,\n",
       "  0.10086908284023668,\n",
       "  0.10082720588235294,\n",
       "  0.10101425438596491,\n",
       "  0.10092659883720931,\n",
       "  0.10079479768786127,\n",
       "  0.10106860632183907,\n",
       "  0.10129464285714286,\n",
       "  0.10107421875,\n",
       "  0.10094456214689265,\n",
       "  0.10094803370786516,\n",
       "  0.10095146648044692,\n",
       "  0.10108506944444444,\n",
       "  0.10117403314917127,\n",
       "  0.10096153846153846,\n",
       "  0.10096482240437159,\n",
       "  0.10113790760869565,\n",
       "  0.10101351351351351,\n",
       "  0.10101646505376344,\n",
       "  0.10076871657754011,\n",
       "  0.1010222739361702,\n",
       "  0.10119047619047619,\n",
       "  0.10119243421052632,\n",
       "  0.10131708115183247,\n",
       "  0.101318359375,\n",
       "  0.1014410621761658,\n",
       "  0.1014416881443299,\n",
       "  0.1015224358974359,\n",
       "  0.10136320153061225,\n",
       "  0.10152284263959391,\n",
       "  0.10144412878787878,\n",
       "  0.10144472361809045,\n",
       "  0.1014453125,\n",
       "  0.10109608208955224,\n",
       "  0.10105971534653466,\n",
       "  0.1009082512315271,\n",
       "  0.10075827205882353,\n",
       "  0.10053353658536586,\n",
       "  0.10053853155339806,\n",
       "  0.1004302536231884,\n",
       "  0.10036057692307693,\n",
       "  0.10029156698564594,\n",
       "  0.10044642857142858,\n",
       "  0.10041469194312796,\n",
       "  0.10030955188679246,\n",
       "  0.100168720657277,\n",
       "  0.100321261682243,\n",
       "  0.10025436046511628,\n",
       "  0.1003689236111111,\n",
       "  0.10044642857142858,\n",
       "  0.10052322247706422,\n",
       "  0.10042094748858447,\n",
       "  0.10053267045454546,\n",
       "  0.10053733031674209,\n",
       "  0.10040118243243243,\n",
       "  0.10037135650224215,\n",
       "  0.100341796875,\n",
       "  0.10020833333333333,\n",
       "  0.10031803097345132,\n",
       "  0.10011701541850221,\n",
       "  0.10026041666666667,\n",
       "  0.10033433406113537,\n",
       "  0.10037364130434782,\n",
       "  0.1002435064935065,\n",
       "  0.10028286637931035,\n",
       "  0.10038894849785408,\n",
       "  0.10036057692307693,\n",
       "  0.1004654255319149,\n",
       "  0.10030455508474577,\n",
       "  0.10047468354430379,\n",
       "  0.10038077731092437,\n",
       "  0.10032034518828452,\n",
       "  0.10029296875,\n",
       "  0.10036307053941909,\n",
       "  0.10033574380165289,\n",
       "  0.10037294238683128,\n",
       "  0.10040983606557377,\n",
       "  0.10038265306122449,\n",
       "  0.10035569105691057,\n",
       "  0.1004870951417004,\n",
       "  0.1006804435483871,\n",
       "  0.10074673694779117,\n",
       "  0.10084375,\n",
       "  0.10093999003984064,\n",
       "  0.10084945436507936,\n",
       "  0.10128458498023715,\n",
       "  0.10134719488188976,\n",
       "  0.1012561274509804,\n",
       "  0.101226806640625,\n",
       "  0.10128891050583658,\n",
       "  0.10122940891472869,\n",
       "  0.10129102316602316,\n",
       "  0.10114182692307692,\n",
       "  0.10102370689655173,\n",
       "  0.10099594465648855,\n",
       "  0.10096839353612168,\n",
       "  0.10100023674242424,\n",
       "  0.1010318396226415,\n",
       "  0.10103383458646617,\n",
       "  0.10112359550561797,\n",
       "  0.10115438432835822,\n",
       "  0.10115590148698884,\n",
       "  0.10092592592592593,\n",
       "  0.10087061808118081,\n",
       "  0.10087316176470588,\n",
       "  0.10104739010989011,\n",
       "  0.10107778284671533,\n",
       "  0.10105113636363636,\n",
       "  0.10110960144927536,\n",
       "  0.1009702166064982,\n",
       "  0.1010847571942446,\n",
       "  0.10108646953405018,\n",
       "  0.10094866071428571,\n",
       "  0.10086743772241993,\n",
       "  0.10095301418439716,\n",
       "  0.10084474381625441,\n",
       "  0.10065470950704225,\n",
       "  0.10052083333333334,\n",
       "  0.10057910839160839,\n",
       "  0.10044642857142858,\n",
       "  0.1005859375,\n",
       "  0.10069744809688581,\n",
       "  0.10056573275862069,\n",
       "  0.10062285223367698,\n",
       "  0.10059931506849315,\n",
       "  0.10041595563139932,\n",
       "  0.10036670918367346,\n",
       "  0.10031779661016949,\n",
       "  0.10026921452702703,\n",
       "  0.1002209595959596,\n",
       "  0.10017302852348993,\n",
       "  0.10020380434782608,\n",
       "  0.1003125,\n",
       "  0.1004983388704319,\n",
       "  0.10052773178807947,\n",
       "  0.10045379537953796,\n",
       "  0.10045744243421052,\n",
       "  0.10053790983606557,\n",
       "  0.10051572712418301,\n",
       "  0.10049368892508144,\n",
       "  0.10044642857142858,\n",
       "  0.1005006067961165,\n",
       "  0.10047883064516129,\n",
       "  0.10050743569131833,\n",
       "  0.10053585737179487,\n",
       "  0.1005391373801917,\n",
       "  0.10046775477707007,\n",
       "  0.10027281746031746,\n",
       "  0.10020272943037975,\n",
       "  0.1001330835962145,\n",
       "  0.10003930817610063,\n",
       "  0.1000685736677116,\n",
       "  0.10009765625,\n",
       "  0.10007788161993769,\n",
       "  0.1000097049689441,\n",
       "  0.09999032507739938,\n",
       "  0.09997106481481481,\n",
       "  0.09997596153846154,\n",
       "  0.0999808282208589,\n",
       "  0.0998900993883792,\n",
       "  0.09984756097560976,\n",
       "  0.09992401215805471,\n",
       "  0.09978693181818182,\n",
       "  0.09976869335347432,\n",
       "  0.09993881777108433,\n",
       "  0.09987331081081081,\n",
       "  0.09978480538922156,\n",
       "  0.0997901119402985,\n",
       "  0.09988839285714286,\n",
       "  0.09987017804154302,\n",
       "  0.09985207100591716,\n",
       "  0.09988016224188791,\n",
       "  0.09972426470588236,\n",
       "  0.09963801319648094,\n",
       "  0.09962079678362573,\n",
       "  0.0996036807580175,\n",
       "  0.09956395348837209,\n",
       "  0.09959239130434783,\n",
       "  0.09957550578034682,\n",
       "  0.0994236311239193,\n",
       "  0.09958692528735633,\n",
       "  0.09961497134670487,\n",
       "  0.09962053571428571,\n",
       "  0.09960381054131054,\n",
       "  0.09969815340909091,\n",
       "  0.09974769830028328,\n",
       "  0.09984110169491525,\n",
       "  0.09986795774647887,\n",
       "  0.09980688202247191,\n",
       "  0.09985556722689076,\n",
       "  0.09983851256983241,\n",
       "  0.09986507660167131,\n",
       "  0.09976128472222222,\n",
       "  0.09993940443213296,\n",
       "  0.09992230662983426,\n",
       "  0.09988378099173553,\n",
       "  0.09988839285714286,\n",
       "  0.09991438356164384,\n",
       "  0.09981215846994536,\n",
       "  0.09990207765667575,\n",
       "  0.09988536005434782,\n",
       "  0.09993224932249323,\n",
       "  0.09995777027027027,\n",
       "  0.09991997978436658,\n",
       "  0.09994539650537634,\n",
       "  0.0999916219839142,\n",
       "  0.10007937834224599,\n",
       "  0.10016666666666667,\n",
       "  0.10019115691489362,\n",
       "  0.10025696286472148,\n",
       "  0.10034308862433862,\n",
       "  0.10036691952506596,\n",
       "  0.10043174342105263,\n",
       "  0.1005372375328084,\n",
       "  0.10056037303664922,\n",
       "  0.10062418407310705,\n",
       "  0.10066731770833333,\n",
       "  0.10073051948051948,\n",
       "  0.10083387305699482,\n",
       "  0.1007953811369509,\n",
       "  0.10085776417525773,\n",
       "  0.10093991002570694,\n",
       "  0.10106169871794872,\n",
       "  0.10118286445012788,\n",
       "  0.10116390306122448,\n",
       "  0.10120467557251908,\n",
       "  0.10124524111675128,\n",
       "  0.1013251582278481,\n",
       "  0.10148358585858586,\n",
       "  0.10142474811083123,\n",
       "  0.1014839824120603,\n",
       "  0.1015625,\n",
       "  0.10162109375,\n",
       "  0.1015430174563591,\n",
       "  0.10169853855721393,\n",
       "  0.10183390198511166,\n",
       "  0.10181389232673267,\n",
       "  0.10185185185185185,\n",
       "  0.10202432266009852,\n",
       "  0.10211916461916462,\n",
       "  0.10225183823529412,\n",
       "  0.10240296454767726,\n",
       "  0.10249618902439024,\n",
       "  0.10256995133819952,\n",
       "  0.1026243932038835,\n",
       "  0.10290556900726393,\n",
       "  0.10310990338164251,\n",
       "  0.10310617469879518,\n",
       "  0.10308368389423077,\n",
       "  0.1032486510791367,\n",
       "  0.10320723684210527,\n",
       "  0.10320331145584725,\n",
       "  0.10318080357142857,\n",
       "  0.10317695961995249,\n",
       "  0.10330272511848342,\n",
       "  0.103409426713948,\n",
       "  0.10349719929245282,\n",
       "  0.10358455882352942,\n",
       "  0.10370818661971831,\n",
       "  0.10394101288056207,\n",
       "  0.10413624415887851,\n",
       "  0.10425772144522144,\n",
       "  0.10416061046511628,\n",
       "  0.1042995939675174,\n",
       "  0.10431134259259259,\n",
       "  0.10435912240184758,\n",
       "  0.10437067972350231,\n",
       "  0.10450790229885057,\n",
       "  0.10455490252293578,\n",
       "  0.1046016876430206,\n",
       "  0.10471960616438356,\n",
       "  0.10474800683371298,\n",
       "  0.10470525568181818,\n",
       "  0.10492842970521542,\n",
       "  0.10486778846153846,\n",
       "  0.1049308690744921,\n",
       "  0.10508164414414414,\n",
       "  0.10514396067415731,\n",
       "  0.10531109865470852,\n",
       "  0.1053726230425056,\n",
       "  0.10536411830357142,\n",
       "  0.10539045100222717,\n",
       "  0.10546875,\n",
       "  0.10552937915742794,\n",
       "  0.10565887721238938,\n",
       "  0.10570157284768211,\n",
       "  0.10574408039647577,\n",
       "  0.10576923076923077,\n",
       "  0.10582853618421052,\n",
       "  0.10583629649890591,\n",
       "  0.10594637008733625,\n",
       "  0.10598788126361655,\n",
       "  0.10606317934782608,\n",
       "  0.10622288503253796,\n",
       "  0.1062804383116883,\n",
       "  0.1062365010799136,\n",
       "  0.10639480064655173,\n",
       "  0.10638440860215054,\n",
       "  0.10640759120171674,\n",
       "  0.10656450749464669,\n",
       "  0.10660389957264957,\n",
       "  0.10671666666666667],\n",
       " [0.140625,\n",
       "  0.140625,\n",
       "  0.15625,\n",
       "  0.16015625,\n",
       "  0.1484375,\n",
       "  0.15364583333333334,\n",
       "  0.14955357142857142,\n",
       "  0.14453125,\n",
       "  0.1388888888888889,\n",
       "  0.134375,\n",
       "  0.1328125,\n",
       "  0.1328125,\n",
       "  0.1310096153846154,\n",
       "  0.1328125,\n",
       "  0.13541666666666666,\n",
       "  0.1337890625,\n",
       "  0.13143382352941177,\n",
       "  0.13151041666666666,\n",
       "  0.13157894736842105,\n",
       "  0.128515625,\n",
       "  0.12797619047619047,\n",
       "  0.12535511363636365,\n",
       "  0.12432065217391304,\n",
       "  0.125,\n",
       "  0.1284375,\n",
       "  0.12980769230769232,\n",
       "  0.12905092592592593,\n",
       "  0.12918526785714285,\n",
       "  0.12984913793103448,\n",
       "  0.12864583333333332,\n",
       "  0.12827620967741934,\n",
       "  0.127685546875,\n",
       "  0.12807765151515152,\n",
       "  0.12821691176470587,\n",
       "  0.1279017857142857,\n",
       "  0.1286892361111111,\n",
       "  0.12837837837837837,\n",
       "  0.12746710526315788,\n",
       "  0.12780448717948717,\n",
       "  0.1291015625,\n",
       "  0.1286204268292683,\n",
       "  0.12816220238095238,\n",
       "  0.12917877906976744,\n",
       "  0.12943892045454544,\n",
       "  0.1284722222222222,\n",
       "  0.12839673913043478,\n",
       "  0.1276595744680851,\n",
       "  0.1279296875,\n",
       "  0.1286670918367347,\n",
       "  0.12859375,\n",
       "  0.13097426470588236,\n",
       "  0.1307091346153846,\n",
       "  0.1320754716981132,\n",
       "  0.13252314814814814,\n",
       "  0.1325284090909091,\n",
       "  0.13225446428571427,\n",
       "  0.13212719298245615,\n",
       "  0.13254310344827586,\n",
       "  0.13201800847457626,\n",
       "  0.13177083333333334,\n",
       "  0.13191598360655737,\n",
       "  0.1319304435483871,\n",
       "  0.13219246031746032,\n",
       "  0.1328125,\n",
       "  0.1326923076923077,\n",
       "  0.13245738636363635,\n",
       "  0.1328125,\n",
       "  0.13292738970588236,\n",
       "  0.13326539855072464,\n",
       "  0.13404017857142858,\n",
       "  0.1347931338028169,\n",
       "  0.13509114583333334,\n",
       "  0.1350599315068493,\n",
       "  0.13513513513513514,\n",
       "  0.13552083333333334,\n",
       "  0.13589638157894737,\n",
       "  0.13605925324675325,\n",
       "  0.13701923076923078,\n",
       "  0.1371637658227848,\n",
       "  0.13818359375,\n",
       "  0.13840663580246915,\n",
       "  0.13852896341463414,\n",
       "  0.1381777108433735,\n",
       "  0.138671875,\n",
       "  0.13897058823529412,\n",
       "  0.1392623546511628,\n",
       "  0.13891882183908047,\n",
       "  0.13893821022727273,\n",
       "  0.13930828651685392,\n",
       "  0.13967013888888888,\n",
       "  0.13976648351648352,\n",
       "  0.13994565217391305,\n",
       "  0.1405409946236559,\n",
       "  0.14037566489361702,\n",
       "  0.14004934210526315,\n",
       "  0.140380859375,\n",
       "  0.140222293814433,\n",
       "  0.1402264030612245,\n",
       "  0.14125631313131312,\n",
       "  0.141171875,\n",
       "  0.14124381188118812,\n",
       "  0.14208026960784315,\n",
       "  0.14229368932038836,\n",
       "  0.1424278846153846,\n",
       "  0.1425595238095238,\n",
       "  0.14283608490566038,\n",
       "  0.1431804906542056,\n",
       "  0.14359085648148148,\n",
       "  0.14363532110091742,\n",
       "  0.14417613636363635,\n",
       "  0.14414414414414414,\n",
       "  0.14460100446428573,\n",
       "  0.144358407079646,\n",
       "  0.1445997807017544,\n",
       "  0.14483695652173914,\n",
       "  0.14547413793103448,\n",
       "  0.14610042735042736,\n",
       "  0.1464512711864407,\n",
       "  0.14653361344537816,\n",
       "  0.14713541666666666,\n",
       "  0.14708161157024793,\n",
       "  0.1476690573770492,\n",
       "  0.14761178861788618,\n",
       "  0.14774445564516128,\n",
       "  0.14825,\n",
       "  0.14837549603174602,\n",
       "  0.14819143700787402,\n",
       "  0.14801025390625,\n",
       "  0.14807412790697674,\n",
       "  0.14819711538461539,\n",
       "  0.14849713740458015,\n",
       "  0.1484966856060606,\n",
       "  0.14896616541353383,\n",
       "  0.15001166044776118,\n",
       "  0.15,\n",
       "  0.15050551470588236,\n",
       "  0.15077554744525548,\n",
       "  0.15166440217391305,\n",
       "  0.1521470323741007,\n",
       "  0.152734375,\n",
       "  0.15287012411347517,\n",
       "  0.15300396126760563,\n",
       "  0.1535729895104895,\n",
       "  0.15380859375,\n",
       "  0.1540948275862069,\n",
       "  0.1542166095890411,\n",
       "  0.15460246598639457,\n",
       "  0.15493032094594594,\n",
       "  0.15488674496644295,\n",
       "  0.15536458333333333,\n",
       "  0.15573261589403972,\n",
       "  0.15568462171052633,\n",
       "  0.15614787581699346,\n",
       "  0.15645292207792208,\n",
       "  0.15650201612903225,\n",
       "  0.15665064102564102,\n",
       "  0.1572949840764331,\n",
       "  0.1573378164556962,\n",
       "  0.15777319182389937,\n",
       "  0.1583984375,\n",
       "  0.15823951863354038,\n",
       "  0.1584201388888889,\n",
       "  0.15816717791411042,\n",
       "  0.15834603658536586,\n",
       "  0.15828598484848486,\n",
       "  0.15799134036144577,\n",
       "  0.15774700598802396,\n",
       "  0.1575985863095238,\n",
       "  0.15722078402366865,\n",
       "  0.15707720588235294,\n",
       "  0.15675255847953215,\n",
       "  0.15647710755813954,\n",
       "  0.15620484104046242,\n",
       "  0.15557650862068967,\n",
       "  0.15544642857142857,\n",
       "  0.15531782670454544,\n",
       "  0.1554113700564972,\n",
       "  0.15506495786516855,\n",
       "  0.15480970670391062,\n",
       "  0.15425347222222222,\n",
       "  0.15400552486187846,\n",
       "  0.15384615384615385,\n",
       "  0.15364583333333334,\n",
       "  0.1533203125,\n",
       "  0.1529983108108108,\n",
       "  0.15272177419354838,\n",
       "  0.15236463903743316,\n",
       "  0.15217752659574468,\n",
       "  0.15186838624338625,\n",
       "  0.15172697368421054,\n",
       "  0.15130071989528796,\n",
       "  0.15108235677083334,\n",
       "  0.15074481865284975,\n",
       "  0.15053157216494845,\n",
       "  0.15036057692307692,\n",
       "  0.1503109056122449,\n",
       "  0.150182423857868,\n",
       "  0.15001578282828282,\n",
       "  0.14965452261306533,\n",
       "  0.1494140625,\n",
       "  0.1490593905472637,\n",
       "  0.14886293316831684,\n",
       "  0.1485914408866995,\n",
       "  0.1482843137254902,\n",
       "  0.14786585365853658,\n",
       "  0.14775485436893204,\n",
       "  0.147493961352657,\n",
       "  0.14727313701923078,\n",
       "  0.14724132775119617,\n",
       "  0.14713541666666666,\n",
       "  0.14691943127962084,\n",
       "  0.1467791863207547,\n",
       "  0.14638350938967137,\n",
       "  0.14621057242990654,\n",
       "  0.14578488372093024,\n",
       "  0.14565248842592593,\n",
       "  0.14566532258064516,\n",
       "  0.14539134174311927,\n",
       "  0.1451912100456621,\n",
       "  0.144921875,\n",
       "  0.14479638009049775,\n",
       "  0.14477759009009009,\n",
       "  0.14468890134529147,\n",
       "  0.14449637276785715,\n",
       "  0.14423611111111112,\n",
       "  0.14401272123893805,\n",
       "  0.14392896475770925,\n",
       "  0.14394873903508773,\n",
       "  0.14366129912663755,\n",
       "  0.1435461956521739,\n",
       "  0.1434659090909091,\n",
       "  0.14341998922413793,\n",
       "  0.1433074034334764,\n",
       "  0.14312900641025642,\n",
       "  0.14295212765957446,\n",
       "  0.14280985169491525,\n",
       "  0.14250395569620253,\n",
       "  0.14239758403361344,\n",
       "  0.1420959728033473,\n",
       "  0.14208984375,\n",
       "  0.14169476141078838,\n",
       "  0.1415934917355372,\n",
       "  0.14149305555555555,\n",
       "  0.14129738729508196,\n",
       "  0.14094387755102042,\n",
       "  0.1407202743902439,\n",
       "  0.14034033400809717,\n",
       "  0.14018397177419356,\n",
       "  0.14018574297188754,\n",
       "  0.139875,\n",
       "  0.13981573705179282,\n",
       "  0.13969494047619047,\n",
       "  0.1394824604743083,\n",
       "  0.13921013779527558,\n",
       "  0.13918504901960785,\n",
       "  0.139251708984375,\n",
       "  0.13910505836575876,\n",
       "  0.13883842054263565,\n",
       "  0.13869449806949807,\n",
       "  0.13858173076923078,\n",
       "  0.1383500957854406,\n",
       "  0.13820968511450382,\n",
       "  0.13795152091254753,\n",
       "  0.13784327651515152,\n",
       "  0.13776533018867926,\n",
       "  0.13765859962406016,\n",
       "  0.13755266853932585,\n",
       "  0.13727262126865672,\n",
       "  0.13719795539033458,\n",
       "  0.13700810185185186,\n",
       "  0.1370214483394834,\n",
       "  0.13683363970588236,\n",
       "  0.13664720695970695,\n",
       "  0.13671875,\n",
       "  0.13650568181818182,\n",
       "  0.13632246376811594,\n",
       "  0.13628158844765342,\n",
       "  0.1360161870503597,\n",
       "  0.1358646953405018,\n",
       "  0.13565848214285714,\n",
       "  0.13550934163701067,\n",
       "  0.13527814716312056,\n",
       "  0.13532464664310953,\n",
       "  0.13512323943661972,\n",
       "  0.1350328947368421,\n",
       "  0.13488854895104896,\n",
       "  0.13469076655052264,\n",
       "  0.1344943576388889,\n",
       "  0.1342993079584775,\n",
       "  0.13410560344827585,\n",
       "  0.13407431271477663,\n",
       "  0.13385595034246575,\n",
       "  0.1337190699658703,\n",
       "  0.13360969387755103,\n",
       "  0.13342161016949153,\n",
       "  0.13326119087837837,\n",
       "  0.13312815656565657,\n",
       "  0.13291736577181207,\n",
       "  0.13268185618729098,\n",
       "  0.13260416666666666,\n",
       "  0.13252699335548174,\n",
       "  0.13250206953642385,\n",
       "  0.13229682343234322,\n",
       "  0.13211862664473684,\n",
       "  0.13191598360655737,\n",
       "  0.1318423202614379,\n",
       "  0.1318709283387622,\n",
       "  0.1317978896103896,\n",
       "  0.13177588996763753,\n",
       "  0.13162802419354838,\n",
       "  0.13153135048231512,\n",
       "  0.1313601762820513,\n",
       "  0.13114017571884984,\n",
       "  0.13109574044585987,\n",
       "  0.1310515873015873,\n",
       "  0.13088409810126583,\n",
       "  0.13079160094637224,\n",
       "  0.13074882075471697,\n",
       "  0.13053487460815047,\n",
       "  0.1302978515625,\n",
       "  0.13020833333333334,\n",
       "  0.13009510869565216,\n",
       "  0.12988583591331268,\n",
       "  0.12972608024691357,\n",
       "  0.1297596153846154,\n",
       "  0.12969708588957055,\n",
       "  0.12956326452599387,\n",
       "  0.1295017149390244,\n",
       "  0.1294880319148936,\n",
       "  0.12937973484848486,\n",
       "  0.12920128398791542,\n",
       "  0.12916509789156627,\n",
       "  0.12901182432432431,\n",
       "  0.12885946856287425,\n",
       "  0.12880130597014924,\n",
       "  0.12862723214285715,\n",
       "  0.12847737388724034,\n",
       "  0.12846708579881658,\n",
       "  0.12836467551622419,\n",
       "  0.12823988970588235,\n",
       "  0.12813874633431085,\n",
       "  0.12796966374269006,\n",
       "  0.1278926749271137,\n",
       "  0.12783884447674418,\n",
       "  0.12785326086956522,\n",
       "  0.12768695809248554,\n",
       "  0.12767921469740634,\n",
       "  0.12764906609195403,\n",
       "  0.12764147564469913,\n",
       "  0.12752232142857142,\n",
       "  0.1274928774928775,\n",
       "  0.1273526278409091,\n",
       "  0.12730169971671387,\n",
       "  0.12714071327683615,\n",
       "  0.12691461267605633,\n",
       "  0.1267775632022472,\n",
       "  0.12675070028011204,\n",
       "  0.1267239874301676,\n",
       "  0.12678447075208912,\n",
       "  0.12664930555555556,\n",
       "  0.12668801939058172,\n",
       "  0.12670493784530387,\n",
       "  0.12674328512396693,\n",
       "  0.1267599587912088,\n",
       "  0.12669092465753426,\n",
       "  0.12651553961748635,\n",
       "  0.1264901226158038,\n",
       "  0.12642238451086957,\n",
       "  0.1263550135501355,\n",
       "  0.12622466216216216,\n",
       "  0.12611607142857142,\n",
       "  0.12605006720430106,\n",
       "  0.125921581769437,\n",
       "  0.1258355614973262,\n",
       "  0.12585416666666666,\n",
       "  0.12578956117021275,\n",
       "  0.12570457559681697,\n",
       "  0.12555803571428573,\n",
       "  0.12545349604221637,\n",
       "  0.1254934210526316,\n",
       "  0.12543061023622049,\n",
       "  0.12542948298429318,\n",
       "  0.1252651762402089,\n",
       "  0.12522379557291666,\n",
       "  0.12522321428571428,\n",
       "  0.12518215673575128,\n",
       "  0.12508074935400518,\n",
       "  0.125,\n",
       "  0.12495983290488431,\n",
       "  0.12489983974358974,\n",
       "  0.12492007672634271,\n",
       "  0.12484056122448979,\n",
       "  0.12476145038167939,\n",
       "  0.12472239847715735,\n",
       "  0.12468354430379747,\n",
       "  0.12448705808080808,\n",
       "  0.12454738664987405,\n",
       "  0.1245288944723618,\n",
       "  0.12451049498746868,\n",
       "  0.12451171875,\n",
       "  0.12459086658354114,\n",
       "  0.12443641169154229,\n",
       "  0.12430210918114144,\n",
       "  0.12422648514851485,\n",
       "  0.12417052469135803,\n",
       "  0.12407635467980295,\n",
       "  0.12425138206388206,\n",
       "  0.12415747549019608,\n",
       "  0.12414043398533008,\n",
       "  0.12414253048780488,\n",
       "  0.12399254866180048,\n",
       "  0.12407084344660194,\n",
       "  0.12405417675544794,\n",
       "  0.12388662439613526,\n",
       "  0.12390813253012048,\n",
       "  0.12383563701923077,\n",
       "  0.12365107913669064,\n",
       "  0.1235608552631579,\n",
       "  0.12335918854415275,\n",
       "  0.12340029761904762,\n",
       "  0.12332986935866984,\n",
       "  0.12331531398104266,\n",
       "  0.12324541962174941,\n",
       "  0.12323113207547169,\n",
       "  0.12316176470588236,\n",
       "  0.12314774061032864,\n",
       "  0.12307889344262295,\n",
       "  0.12293735397196262,\n",
       "  0.12286931818181818,\n",
       "  0.12283793604651162,\n",
       "  0.1228610788863109,\n",
       "  0.12281177662037036,\n",
       "  0.12274465935334873,\n",
       "  0.12276785714285714,\n",
       "  0.12268318965517241,\n",
       "  0.12265266628440367,\n",
       "  0.12258652745995423,\n",
       "  0.12243150684931507,\n",
       "  0.12233058086560364,\n",
       "  0.12231889204545454,\n",
       "  0.12220096371882086,\n",
       "  0.12211891968325791,\n",
       "  0.12207251693002258,\n",
       "  0.12206151463963964,\n",
       "  0.12196278089887641,\n",
       "  0.12196959080717489,\n",
       "  0.12194141498881432,\n",
       "  0.12191336495535714,\n",
       "  0.12183324053452116,\n",
       "  0.12182291666666667,\n",
       "  0.12179531596452328,\n",
       "  0.12175055309734513,\n",
       "  0.12161975717439294,\n",
       "  0.12142070484581498,\n",
       "  0.12134271978021978,\n",
       "  0.12133360745614036,\n",
       "  0.12127324945295405,\n",
       "  0.12123021288209607,\n",
       "  0.1211703431372549,\n",
       "  0.12109375,\n",
       "  0.12106832971800434,\n",
       "  0.12095846861471861,\n",
       "  0.12093345032397408,\n",
       "  0.12085802801724138,\n",
       "  0.12076612903225807,\n",
       "  0.12070815450643776,\n",
       "  0.12065042826552462,\n",
       "  0.12069310897435898,\n",
       "  0.12068333333333334],\n",
       " [0.109375,\n",
       "  0.08984375,\n",
       "  0.09635416666666667,\n",
       "  0.1015625,\n",
       "  0.0953125,\n",
       "  0.10286458333333333,\n",
       "  0.09709821428571429,\n",
       "  0.0927734375,\n",
       "  0.09722222222222222,\n",
       "  0.0953125,\n",
       "  0.09588068181818182,\n",
       "  0.09700520833333333,\n",
       "  0.10096153846153846,\n",
       "  0.09821428571428571,\n",
       "  0.0984375,\n",
       "  0.0986328125,\n",
       "  0.09558823529411764,\n",
       "  0.09505208333333333,\n",
       "  0.09375,\n",
       "  0.0953125,\n",
       "  0.09300595238095238,\n",
       "  0.09339488636363637,\n",
       "  0.09375,\n",
       "  0.09342447916666667,\n",
       "  0.093125,\n",
       "  0.09164663461538461,\n",
       "  0.09288194444444445,\n",
       "  0.09151785714285714,\n",
       "  0.0902478448275862,\n",
       "  0.09114583333333333,\n",
       "  0.09274193548387097,\n",
       "  0.0927734375,\n",
       "  0.09398674242424243,\n",
       "  0.09375,\n",
       "  0.09464285714285714,\n",
       "  0.09375,\n",
       "  0.0941722972972973,\n",
       "  0.09416118421052631,\n",
       "  0.09395032051282051,\n",
       "  0.094140625,\n",
       "  0.09432164634146341,\n",
       "  0.09449404761904762,\n",
       "  0.09429505813953488,\n",
       "  0.09392755681818182,\n",
       "  0.0953125,\n",
       "  0.09493885869565218,\n",
       "  0.0962433510638298,\n",
       "  0.09700520833333333,\n",
       "  0.09693877551020408,\n",
       "  0.0975,\n",
       "  0.09819240196078431,\n",
       "  0.09750600961538461,\n",
       "  0.0972877358490566,\n",
       "  0.0970775462962963,\n",
       "  0.0971590909090909,\n",
       "  0.09737723214285714,\n",
       "  0.09731359649122807,\n",
       "  0.09684806034482758,\n",
       "  0.09679555084745763,\n",
       "  0.09674479166666666,\n",
       "  0.09759221311475409,\n",
       "  0.09715221774193548,\n",
       "  0.09771825396825397,\n",
       "  0.0972900390625,\n",
       "  0.09795673076923077,\n",
       "  0.09824810606060606,\n",
       "  0.09899720149253731,\n",
       "  0.09903492647058823,\n",
       "  0.09884510869565218,\n",
       "  0.09799107142857143,\n",
       "  0.09859154929577464,\n",
       "  0.09809027777777778,\n",
       "  0.09813784246575342,\n",
       "  0.09797297297297297,\n",
       "  0.098125,\n",
       "  0.09806743421052631,\n",
       "  0.09801136363636363,\n",
       "  0.09765625,\n",
       "  0.09800237341772151,\n",
       "  0.0982421875,\n",
       "  0.09828317901234568,\n",
       "  0.09841844512195122,\n",
       "  0.09807981927710843,\n",
       "  0.09812127976190477,\n",
       "  0.0978860294117647,\n",
       "  0.09801962209302326,\n",
       "  0.09832974137931035,\n",
       "  0.09836647727272728,\n",
       "  0.09866573033707865,\n",
       "  0.09921875,\n",
       "  0.09924450549450549,\n",
       "  0.09952445652173914,\n",
       "  0.0992103494623656,\n",
       "  0.09898603723404255,\n",
       "  0.09884868421052631,\n",
       "  0.09871419270833333,\n",
       "  0.09826030927835051,\n",
       "  0.09821428571428571,\n",
       "  0.09864267676767677,\n",
       "  0.098671875,\n",
       "  0.09885519801980198,\n",
       "  0.09895833333333333,\n",
       "  0.09875606796116505,\n",
       "  0.09878305288461539,\n",
       "  0.09851190476190476,\n",
       "  0.0983932783018868,\n",
       "  0.09827686915887851,\n",
       "  0.09794560185185185,\n",
       "  0.09797878440366972,\n",
       "  0.09808238636363636,\n",
       "  0.09797297297297297,\n",
       "  0.09758649553571429,\n",
       "  0.09755254424778761,\n",
       "  0.09793037280701754,\n",
       "  0.09775815217391304,\n",
       "  0.09785829741379311,\n",
       "  0.09748931623931624,\n",
       "  0.09745762711864407,\n",
       "  0.09716386554621849,\n",
       "  0.09674479166666666,\n",
       "  0.09652634297520661,\n",
       "  0.09695184426229508,\n",
       "  0.09692581300813008,\n",
       "  0.0965851814516129,\n",
       "  0.0964375,\n",
       "  0.09635416666666667,\n",
       "  0.09627214566929133,\n",
       "  0.09674072265625,\n",
       "  0.09720203488372094,\n",
       "  0.09759615384615385,\n",
       "  0.09762643129770993,\n",
       "  0.09777462121212122,\n",
       "  0.09768562030075188,\n",
       "  0.09753964552238806,\n",
       "  0.09791666666666667,\n",
       "  0.09800091911764706,\n",
       "  0.0979698905109489,\n",
       "  0.09776947463768115,\n",
       "  0.09768435251798561,\n",
       "  0.09815848214285715,\n",
       "  0.09801640070921985,\n",
       "  0.09804137323943662,\n",
       "  0.0980659965034965,\n",
       "  0.09798177083333333,\n",
       "  0.09800646551724138,\n",
       "  0.09819135273972603,\n",
       "  0.09800170068027211,\n",
       "  0.09823690878378379,\n",
       "  0.09815436241610738,\n",
       "  0.09822916666666667,\n",
       "  0.0980442880794702,\n",
       "  0.09791324013157894,\n",
       "  0.09783496732026144,\n",
       "  0.0981635551948052,\n",
       "  0.0982358870967742,\n",
       "  0.09810697115384616,\n",
       "  0.0979796974522293,\n",
       "  0.09805181962025317,\n",
       "  0.09846698113207547,\n",
       "  0.0984375,\n",
       "  0.0984083850931677,\n",
       "  0.0982349537037037,\n",
       "  0.09839915644171779,\n",
       "  0.09846608231707317,\n",
       "  0.09824810606060606,\n",
       "  0.09826807228915663,\n",
       "  0.0985684880239521,\n",
       "  0.09853980654761904,\n",
       "  0.09837278106508876,\n",
       "  0.09811580882352941,\n",
       "  0.09786184210526316,\n",
       "  0.09779251453488372,\n",
       "  0.09758851156069365,\n",
       "  0.09747665229885058,\n",
       "  0.0975,\n",
       "  0.09761186079545454,\n",
       "  0.09754590395480225,\n",
       "  0.09752457865168539,\n",
       "  0.09741620111731844,\n",
       "  0.09752604166666666,\n",
       "  0.09746201657458564,\n",
       "  0.09718406593406594,\n",
       "  0.09716530054644809,\n",
       "  0.09718919836956522,\n",
       "  0.09708614864864865,\n",
       "  0.09690020161290322,\n",
       "  0.09684157754010696,\n",
       "  0.09694980053191489,\n",
       "  0.09693287037037036,\n",
       "  0.09691611842105263,\n",
       "  0.09681773560209424,\n",
       "  0.09688313802083333,\n",
       "  0.09674546632124352,\n",
       "  0.09648840206185567,\n",
       "  0.09639423076923077,\n",
       "  0.09650031887755102,\n",
       "  0.0965260152284264,\n",
       "  0.09659090909090909,\n",
       "  0.09689070351758794,\n",
       "  0.0969140625,\n",
       "  0.09689832089552239,\n",
       "  0.09672803217821782,\n",
       "  0.09663639162561577,\n",
       "  0.09673713235294118,\n",
       "  0.09649390243902439,\n",
       "  0.09682190533980582,\n",
       "  0.09703351449275362,\n",
       "  0.09705528846153846,\n",
       "  0.09703947368421052,\n",
       "  0.09698660714285715,\n",
       "  0.09693424170616113,\n",
       "  0.09702977594339622,\n",
       "  0.09697769953051644,\n",
       "  0.09714515186915888,\n",
       "  0.09698401162790697,\n",
       "  0.0970775462962963,\n",
       "  0.09691820276497695,\n",
       "  0.09683199541284404,\n",
       "  0.09692494292237443,\n",
       "  0.09701704545454545,\n",
       "  0.09714366515837104,\n",
       "  0.09719876126126126,\n",
       "  0.09721832959641255,\n",
       "  0.09720284598214286,\n",
       "  0.09715277777777778,\n",
       "  0.09717228982300885,\n",
       "  0.09715721365638766,\n",
       "  0.0971765350877193,\n",
       "  0.09712745633187773,\n",
       "  0.09704483695652173,\n",
       "  0.09706439393939394,\n",
       "  0.09694908405172414,\n",
       "  0.09693535407725322,\n",
       "  0.09695512820512821,\n",
       "  0.09694148936170213,\n",
       "  0.09669623940677965,\n",
       "  0.09655195147679325,\n",
       "  0.09647452731092437,\n",
       "  0.09646312761506276,\n",
       "  0.09635416666666667,\n",
       "  0.09634336099585063,\n",
       "  0.09636492768595041,\n",
       "  0.09635416666666667,\n",
       "  0.09624743852459017,\n",
       "  0.09646045918367346,\n",
       "  0.09648119918699187,\n",
       "  0.09640688259109312,\n",
       "  0.0963961693548387,\n",
       "  0.0963855421686747,\n",
       "  0.09653125,\n",
       "  0.09655129482071713,\n",
       "  0.09647817460317461,\n",
       "  0.09646739130434782,\n",
       "  0.09657972440944881,\n",
       "  0.09644607843137255,\n",
       "  0.096435546875,\n",
       "  0.0965466926070039,\n",
       "  0.09641472868217055,\n",
       "  0.09643460424710425,\n",
       "  0.09639423076923077,\n",
       "  0.0964140325670498,\n",
       "  0.0964038645038168,\n",
       "  0.09654230038022814,\n",
       "  0.09673887310606061,\n",
       "  0.09690448113207548,\n",
       "  0.09689262218045112,\n",
       "  0.09693937265917603,\n",
       "  0.09684001865671642,\n",
       "  0.09694470260223048,\n",
       "  0.096875,\n",
       "  0.09689229704797048,\n",
       "  0.09699563419117647,\n",
       "  0.09686927655677656,\n",
       "  0.09694343065693431,\n",
       "  0.09684659090909091,\n",
       "  0.09686367753623189,\n",
       "  0.09688064079422383,\n",
       "  0.09689748201438848,\n",
       "  0.0968301971326165,\n",
       "  0.09670758928571428,\n",
       "  0.09678047153024912,\n",
       "  0.09676972517730496,\n",
       "  0.09686947879858657,\n",
       "  0.09672095070422536,\n",
       "  0.09654605263157895,\n",
       "  0.09639969405594405,\n",
       "  0.09641768292682927,\n",
       "  0.09659830729166667,\n",
       "  0.09658845155709342,\n",
       "  0.09663254310344828,\n",
       "  0.09656894329896908,\n",
       "  0.09658604452054795,\n",
       "  0.0966296928327645,\n",
       "  0.09654017857142858,\n",
       "  0.09655720338983051,\n",
       "  0.09660050675675676,\n",
       "  0.09664351851851852,\n",
       "  0.09660759228187919,\n",
       "  0.09649352006688963,\n",
       "  0.09645833333333333,\n",
       "  0.09652720099667775,\n",
       "  0.09641452814569536,\n",
       "  0.09630259900990099,\n",
       "  0.09631990131578948,\n",
       "  0.0962858606557377,\n",
       "  0.09635416666666667,\n",
       "  0.09642202768729642,\n",
       "  0.09641335227272728,\n",
       "  0.09655643203883495,\n",
       "  0.09652217741935484,\n",
       "  0.09656350482315113,\n",
       "  0.09665464743589744,\n",
       "  0.09664536741214058,\n",
       "  0.09671078821656051,\n",
       "  0.09677579365079365,\n",
       "  0.09679094145569621,\n",
       "  0.09680599369085173,\n",
       "  0.09672268081761007,\n",
       "  0.0969092868338558,\n",
       "  0.0970947265625,\n",
       "  0.09698695482866043,\n",
       "  0.09726805124223603,\n",
       "  0.09720878482972137,\n",
       "  0.09719810956790123,\n",
       "  0.09713942307692308,\n",
       "  0.09708109662576687,\n",
       "  0.09707090978593272,\n",
       "  0.09703696646341463,\n",
       "  0.09697948328267478,\n",
       "  0.096875,\n",
       "  0.09695996978851963,\n",
       "  0.09676204819277108,\n",
       "  0.09682338588588589,\n",
       "  0.09681418413173652,\n",
       "  0.096875,\n",
       "  0.09695870535714286,\n",
       "  0.09681008902077151,\n",
       "  0.0968703772189349,\n",
       "  0.09695335545722714,\n",
       "  0.09694393382352941,\n",
       "  0.0968658357771261,\n",
       "  0.09683388157894737,\n",
       "  0.09687044460641399,\n",
       "  0.09695221656976744,\n",
       "  0.09703351449275362,\n",
       "  0.09706918352601156,\n",
       "  0.0970821325648415,\n",
       "  0.09709500718390805,\n",
       "  0.09713019340974212,\n",
       "  0.09709821428571429,\n",
       "  0.09717770655270655,\n",
       "  0.09712357954545454,\n",
       "  0.09706975920679886,\n",
       "  0.096972104519774,\n",
       "  0.09700704225352112,\n",
       "  0.09693205758426966,\n",
       "  0.09696691176470588,\n",
       "  0.09706703910614525,\n",
       "  0.09707956128133705,\n",
       "  0.09720052083333333,\n",
       "  0.09719096260387812,\n",
       "  0.09728936464088397,\n",
       "  0.09740874655647383,\n",
       "  0.09744162087912088,\n",
       "  0.09741010273972603,\n",
       "  0.0974001024590164,\n",
       "  0.097262431880109,\n",
       "  0.09729534646739131,\n",
       "  0.09715870596205962,\n",
       "  0.09710726351351351,\n",
       "  0.0970771563342318,\n",
       "  0.0969632056451613,\n",
       "  0.09695459115281502,\n",
       "  0.09688335561497326,\n",
       "  0.09697916666666667,\n",
       "  0.09690824468085106,\n",
       "  0.09692059018567639,\n",
       "  0.0968708664021164,\n",
       "  0.09696569920844327,\n",
       "  0.09706003289473684,\n",
       "  0.09701033464566929,\n",
       "  0.09712450916230367,\n",
       "  0.09711569843342037,\n",
       "  0.09712727864583333,\n",
       "  0.09717938311688312,\n",
       "  0.09725145725388601,\n",
       "  0.09722222222222222,\n",
       "  0.09709246134020619,\n",
       "  0.09704370179948586,\n",
       "  0.09703525641025641,\n",
       "  0.09700687340153452,\n",
       "  0.09691884566326531,\n",
       "  0.09681138676844783,\n",
       "  0.09680361675126904,\n",
       "  0.09679588607594937,\n",
       "  0.09682765151515152,\n",
       "  0.09680022040302266,\n",
       "  0.09689070351758794,\n",
       "  0.0968828320802005,\n",
       "  0.096875,\n",
       "  0.09686720698254364,\n",
       "  0.09691775497512438,\n",
       "  0.0968129652605459,\n",
       "  0.09670869430693069,\n",
       "  0.09672067901234568,\n",
       "  0.09673260467980295,\n",
       "  0.09664849508599509,\n",
       "  0.0966796875,\n",
       "  0.09657701711491443,\n",
       "  0.09662728658536586,\n",
       "  0.09673433698296836,\n",
       "  0.09672709344660194,\n",
       "  0.09662530266343826,\n",
       "  0.09671271135265701,\n",
       "  0.09664909638554217,\n",
       "  0.0966045673076923,\n",
       "  0.09671013189448441,\n",
       "  0.09668436004784689,\n",
       "  0.09671464797136038,\n",
       "  0.09678199404761904,\n",
       "  0.09673767814726841,\n",
       "  0.09671208530805687,\n",
       "  0.09672355200945626,\n",
       "  0.09682709316037735,\n",
       "  0.09683823529411764,\n",
       "  0.09690434272300469,\n",
       "  0.09691525175644028,\n",
       "  0.0969808703271028,\n",
       "  0.09704618298368298,\n",
       "  0.09700218023255813,\n",
       "  0.09723027842227379,\n",
       "  0.09722222222222222,\n",
       "  0.0972863741339492,\n",
       "  0.0973322292626728,\n",
       "  0.09734195402298851,\n",
       "  0.09742330848623854,\n",
       "  0.09748641304347826,\n",
       "  0.09747788242009132,\n",
       "  0.09745159453302961,\n",
       "  0.09754971590909091,\n",
       "  0.09750566893424037,\n",
       "  0.09753252262443439,\n",
       "  0.09757689051918736,\n",
       "  0.09758586711711711,\n",
       "  0.0976123595505618,\n",
       "  0.0976036995515695,\n",
       "  0.09757760067114093,\n",
       "  0.09751674107142858,\n",
       "  0.09756055122494432,\n",
       "  0.09765625,\n",
       "  0.09761294345898004,\n",
       "  0.097569828539823,\n",
       "  0.09763038079470199,\n",
       "  0.09767345814977973,\n",
       "  0.09764766483516484,\n",
       "  0.09772478070175439,\n",
       "  0.09769898796498906,\n",
       "  0.09772448144104803,\n",
       "  0.09783496732026144,\n",
       "  0.09784307065217392,\n",
       "  0.0979189262472885,\n",
       "  0.09796063311688312,\n",
       "  0.09793466522678186,\n",
       "  0.09804350754310345,\n",
       "  0.09806787634408602,\n",
       "  0.09800831545064377,\n",
       "  0.09796573875802998,\n",
       "  0.09792334401709402,\n",
       "  0.09795],\n",
       " [0.09375,\n",
       "  0.1015625,\n",
       "  0.08854166666666667,\n",
       "  0.078125,\n",
       "  0.0765625,\n",
       "  0.078125,\n",
       "  0.07924107142857142,\n",
       "  0.087890625,\n",
       "  0.09114583333333333,\n",
       "  0.0953125,\n",
       "  0.09872159090909091,\n",
       "  0.09830729166666667,\n",
       "  0.09795673076923077,\n",
       "  0.09821428571428571,\n",
       "  0.09583333333333334,\n",
       "  0.09912109375,\n",
       "  0.10064338235294118,\n",
       "  0.0993923611111111,\n",
       "  0.10032894736842106,\n",
       "  0.100390625,\n",
       "  0.10044642857142858,\n",
       "  0.10049715909090909,\n",
       "  0.09714673913043478,\n",
       "  0.09602864583333333,\n",
       "  0.09625,\n",
       "  0.09795673076923077,\n",
       "  0.09751157407407407,\n",
       "  0.09821428571428571,\n",
       "  0.09752155172413793,\n",
       "  0.09791666666666667,\n",
       "  0.09828629032258064,\n",
       "  0.099609375,\n",
       "  0.09919507575757576,\n",
       "  0.09995404411764706,\n",
       "  0.09955357142857142,\n",
       "  0.09830729166666667,\n",
       "  0.09881756756756757,\n",
       "  0.0990953947368421,\n",
       "  0.09935897435897435,\n",
       "  0.0990234375,\n",
       "  0.09851371951219512,\n",
       "  0.09895833333333333,\n",
       "  0.09865552325581395,\n",
       "  0.09872159090909091,\n",
       "  0.09895833333333333,\n",
       "  0.09969429347826086,\n",
       "  0.09956781914893617,\n",
       "  0.09977213541666667,\n",
       "  0.09996811224489796,\n",
       "  0.10046875,\n",
       "  0.10018382352941177,\n",
       "  0.1006610576923077,\n",
       "  0.09979363207547169,\n",
       "  0.09953703703703703,\n",
       "  0.10014204545454546,\n",
       "  0.10002790178571429,\n",
       "  0.10019188596491228,\n",
       "  0.09994612068965517,\n",
       "  0.1003707627118644,\n",
       "  0.10078125,\n",
       "  0.10040983606557377,\n",
       "  0.10017641129032258,\n",
       "  0.10081845238095238,\n",
       "  0.1011962890625,\n",
       "  0.10132211538461539,\n",
       "  0.10168087121212122,\n",
       "  0.10132929104477612,\n",
       "  0.1013327205882353,\n",
       "  0.10099637681159421,\n",
       "  0.10066964285714286,\n",
       "  0.10079225352112677,\n",
       "  0.10047743055555555,\n",
       "  0.10049229452054795,\n",
       "  0.10050675675675676,\n",
       "  0.10020833333333333,\n",
       "  0.1001233552631579,\n",
       "  0.10014204545454546,\n",
       "  0.09985977564102565,\n",
       "  0.09988132911392406,\n",
       "  0.09970703125,\n",
       "  0.0998263888888889,\n",
       "  0.09937118902439024,\n",
       "  0.0990210843373494,\n",
       "  0.09886532738095238,\n",
       "  0.0994485294117647,\n",
       "  0.0990188953488372,\n",
       "  0.09922772988505747,\n",
       "  0.09836647727272728,\n",
       "  0.09831460674157304,\n",
       "  0.09826388888888889,\n",
       "  0.09804258241758242,\n",
       "  0.09816576086956522,\n",
       "  0.09862231182795698,\n",
       "  0.0984873670212766,\n",
       "  0.09868421052631579,\n",
       "  0.098876953125,\n",
       "  0.09874355670103092,\n",
       "  0.09829400510204081,\n",
       "  0.09872159090909091,\n",
       "  0.098828125,\n",
       "  0.09900990099009901,\n",
       "  0.09903492647058823,\n",
       "  0.09913531553398058,\n",
       "  0.09938401442307693,\n",
       "  0.0994047619047619,\n",
       "  0.09942511792452831,\n",
       "  0.09944509345794393,\n",
       "  0.0993923611111111,\n",
       "  0.09934059633027523,\n",
       "  0.09971590909090909,\n",
       "  0.0995213963963964,\n",
       "  0.09940011160714286,\n",
       "  0.0996266592920354,\n",
       "  0.09978070175438597,\n",
       "  0.10027173913043479,\n",
       "  0.10048491379310345,\n",
       "  0.10056089743589744,\n",
       "  0.10030455508474577,\n",
       "  0.10018382352941177,\n",
       "  0.10052083333333334,\n",
       "  0.10046487603305786,\n",
       "  0.10015368852459017,\n",
       "  0.10048272357723577,\n",
       "  0.10036542338709678,\n",
       "  0.1003125,\n",
       "  0.0998263888888889,\n",
       "  0.09990157480314961,\n",
       "  0.099853515625,\n",
       "  0.09974563953488372,\n",
       "  0.09969951923076924,\n",
       "  0.0994155534351145,\n",
       "  0.099609375,\n",
       "  0.09933035714285714,\n",
       "  0.09917210820895522,\n",
       "  0.09924768518518519,\n",
       "  0.09955193014705882,\n",
       "  0.09928147810218978,\n",
       "  0.09946784420289854,\n",
       "  0.09931429856115108,\n",
       "  0.09905133928571429,\n",
       "  0.09945700354609929,\n",
       "  0.0995268485915493,\n",
       "  0.09943181818181818,\n",
       "  0.09955512152777778,\n",
       "  0.09962284482758621,\n",
       "  0.0996896404109589,\n",
       "  0.09964923469387756,\n",
       "  0.099609375,\n",
       "  0.09962248322147652,\n",
       "  0.09979166666666667,\n",
       "  0.0998033940397351,\n",
       "  0.09966077302631579,\n",
       "  0.0998263888888889,\n",
       "  0.09963474025974026,\n",
       "  0.09964717741935483,\n",
       "  0.09950921474358974,\n",
       "  0.09972133757961783,\n",
       "  0.09973299050632911,\n",
       "  0.09964622641509434,\n",
       "  0.099462890625,\n",
       "  0.09957298136645963,\n",
       "  0.09972993827160494,\n",
       "  0.0999808282208589,\n",
       "  0.0997046493902439,\n",
       "  0.09985795454545454,\n",
       "  0.09977409638554217,\n",
       "  0.09978480538922156,\n",
       "  0.10012090773809523,\n",
       "  0.09989829881656805,\n",
       "  0.09967830882352942,\n",
       "  0.09955226608187134,\n",
       "  0.09965479651162791,\n",
       "  0.09971098265895954,\n",
       "  0.09967672413793104,\n",
       "  0.099375,\n",
       "  0.09916548295454546,\n",
       "  0.0993555790960452,\n",
       "  0.09919241573033707,\n",
       "  0.09903107541899442,\n",
       "  0.09921875,\n",
       "  0.09936118784530387,\n",
       "  0.09915865384615384,\n",
       "  0.09912909836065574,\n",
       "  0.09926970108695653,\n",
       "  0.0991554054054054,\n",
       "  0.0991263440860215,\n",
       "  0.09918114973262032,\n",
       "  0.09915226063829788,\n",
       "  0.09904100529100529,\n",
       "  0.09917763157894736,\n",
       "  0.09923102094240838,\n",
       "  0.09916178385416667,\n",
       "  0.09913374352331607,\n",
       "  0.09930734536082474,\n",
       "  0.09915865384615384,\n",
       "  0.09893176020408163,\n",
       "  0.0988261421319797,\n",
       "  0.09891887626262626,\n",
       "  0.09865734924623115,\n",
       "  0.09859375,\n",
       "  0.09849191542288557,\n",
       "  0.09850711633663366,\n",
       "  0.09867610837438423,\n",
       "  0.09872855392156862,\n",
       "  0.09878048780487805,\n",
       "  0.0987181432038835,\n",
       "  0.09873188405797101,\n",
       "  0.09874549278846154,\n",
       "  0.09853468899521531,\n",
       "  0.09854910714285714,\n",
       "  0.09867446682464455,\n",
       "  0.09861438679245282,\n",
       "  0.09866490610328639,\n",
       "  0.09856892523364486,\n",
       "  0.09861918604651163,\n",
       "  0.09859664351851852,\n",
       "  0.09868231566820276,\n",
       "  0.09855217889908256,\n",
       "  0.09856592465753425,\n",
       "  0.09857954545454546,\n",
       "  0.09859304298642534,\n",
       "  0.0986768018018018,\n",
       "  0.09861967488789238,\n",
       "  0.09866768973214286,\n",
       "  0.0985763888888889,\n",
       "  0.09848589601769911,\n",
       "  0.09870594713656387,\n",
       "  0.09875274122807018,\n",
       "  0.09879912663755458,\n",
       "  0.09894701086956521,\n",
       "  0.09899215367965368,\n",
       "  0.09896955818965517,\n",
       "  0.09891362660944206,\n",
       "  0.09869123931623931,\n",
       "  0.09870345744680852,\n",
       "  0.09881488347457627,\n",
       "  0.09872758438818566,\n",
       "  0.09887079831932773,\n",
       "  0.09871861924686193,\n",
       "  0.09873046875,\n",
       "  0.09861255186721991,\n",
       "  0.09846332644628099,\n",
       "  0.09860468106995884,\n",
       "  0.09852074795081968,\n",
       "  0.09856505102040816,\n",
       "  0.09841844512195122,\n",
       "  0.0984628036437247,\n",
       "  0.09844380040322581,\n",
       "  0.09842494979919679,\n",
       "  0.0984375,\n",
       "  0.09838769920318725,\n",
       "  0.09849330357142858,\n",
       "  0.09841279644268774,\n",
       "  0.09827140748031496,\n",
       "  0.09834558823529412,\n",
       "  0.09832763671875,\n",
       "  0.09824902723735408,\n",
       "  0.09829215116279069,\n",
       "  0.09821428571428571,\n",
       "  0.09819711538461538,\n",
       "  0.09821000957854406,\n",
       "  0.09813334923664122,\n",
       "  0.09817609315589354,\n",
       "  0.09818892045454546,\n",
       "  0.09831957547169812,\n",
       "  0.09827302631578948,\n",
       "  0.09831460674157304,\n",
       "  0.09835587686567164,\n",
       "  0.09833875464684015,\n",
       "  0.0982349537037037,\n",
       "  0.09816074723247233,\n",
       "  0.09802964154411764,\n",
       "  0.0981856684981685,\n",
       "  0.09819799270072993,\n",
       "  0.0981534090909091,\n",
       "  0.09808084239130435,\n",
       "  0.09798059566787004,\n",
       "  0.09796537769784172,\n",
       "  0.09806227598566308,\n",
       "  0.09813058035714285,\n",
       "  0.09822620106761566,\n",
       "  0.09826573581560284,\n",
       "  0.09822217314487633,\n",
       "  0.09815140845070422,\n",
       "  0.0981359649122807,\n",
       "  0.09809331293706294,\n",
       "  0.09810540069686412,\n",
       "  0.0979275173611111,\n",
       "  0.09796712802768166,\n",
       "  0.09792564655172414,\n",
       "  0.09804553264604811,\n",
       "  0.09800406678082192,\n",
       "  0.09790955631399317,\n",
       "  0.09805484693877552,\n",
       "  0.09801377118644068,\n",
       "  0.09799936655405406,\n",
       "  0.0979587542087542,\n",
       "  0.09794463087248322,\n",
       "  0.09787834448160534,\n",
       "  0.09802083333333333,\n",
       "  0.09790282392026578,\n",
       "  0.09781146523178808,\n",
       "  0.09766914191419142,\n",
       "  0.0976819490131579,\n",
       "  0.09766905737704919,\n",
       "  0.09763071895424837,\n",
       "  0.09751628664495114,\n",
       "  0.0975294237012987,\n",
       "  0.09754247572815535,\n",
       "  0.09753024193548387,\n",
       "  0.09754320739549839,\n",
       "  0.09750600961538461,\n",
       "  0.09746904952076678,\n",
       "  0.09750696656050956,\n",
       "  0.09761904761904762,\n",
       "  0.09760680379746836,\n",
       "  0.09754534700315458,\n",
       "  0.09748427672955975,\n",
       "  0.09752155172413793,\n",
       "  0.09755859375,\n",
       "  0.09771709501557632,\n",
       "  0.09775329968944099,\n",
       "  0.09771671826625387,\n",
       "  0.09755979938271606,\n",
       "  0.09752403846153847,\n",
       "  0.09760832055214724,\n",
       "  0.09759652140672782,\n",
       "  0.09758479420731707,\n",
       "  0.09759688449848024,\n",
       "  0.09760890151515152,\n",
       "  0.09755003776435045,\n",
       "  0.0975621234939759,\n",
       "  0.09759759759759759,\n",
       "  0.09765625,\n",
       "  0.09755130597014926,\n",
       "  0.09767950148809523,\n",
       "  0.09778375370919881,\n",
       "  0.09779493343195267,\n",
       "  0.09778300147492626,\n",
       "  0.09774816176470588,\n",
       "  0.09771352639296188,\n",
       "  0.09772478070175439,\n",
       "  0.09778152332361516,\n",
       "  0.09776980377906977,\n",
       "  0.0978713768115942,\n",
       "  0.09788204479768786,\n",
       "  0.09784762247838617,\n",
       "  0.09794809626436782,\n",
       "  0.09798083810888251,\n",
       "  0.09805803571428572,\n",
       "  0.09817930911680911,\n",
       "  0.09823330965909091,\n",
       "  0.09824274079320114,\n",
       "  0.09818591101694915,\n",
       "  0.0982394366197183,\n",
       "  0.09831460674157304,\n",
       "  0.09823616946778711,\n",
       "  0.0982018156424581,\n",
       "  0.09808060584958217,\n",
       "  0.09806857638888888,\n",
       "  0.09807825484764543,\n",
       "  0.09800155386740332,\n",
       "  0.09803288567493113,\n",
       "  0.09799965659340659,\n",
       "  0.0980736301369863,\n",
       "  0.09806181693989072,\n",
       "  0.09802878065395096,\n",
       "  0.09799592391304347,\n",
       "  0.09800558943089431,\n",
       "  0.09814189189189189,\n",
       "  0.09813005390835579,\n",
       "  0.09820228494623656,\n",
       "  0.09819034852546916,\n",
       "  0.09815758689839572,\n",
       "  0.0983125,\n",
       "  0.09823803191489362,\n",
       "  0.09830901856763925,\n",
       "  0.09837962962962964,\n",
       "  0.09830557387862797,\n",
       "  0.09827302631578948,\n",
       "  0.09826115485564305,\n",
       "  0.09829024869109948,\n",
       "  0.09850277415143603,\n",
       "  0.09865315755208333,\n",
       "  0.09880275974025975,\n",
       "  0.09872895077720208,\n",
       "  0.09871608527131782,\n",
       "  0.09866301546391752,\n",
       "  0.09859013496143959,\n",
       "  0.09877804487179487,\n",
       "  0.09876518542199489,\n",
       "  0.09873246173469388,\n",
       "  0.09873966284987278,\n",
       "  0.09870717005076142,\n",
       "  0.09871439873417721,\n",
       "  0.09870186237373738,\n",
       "  0.09876810453400504,\n",
       "  0.09873586683417085,\n",
       "  0.09870379072681704,\n",
       "  0.09865234375,\n",
       "  0.09871804862842892,\n",
       "  0.09882229477611941,\n",
       "  0.09890663771712159,\n",
       "  0.09899056311881188,\n",
       "  0.0990162037037037,\n",
       "  0.09892626231527094,\n",
       "  0.09895193488943489,\n",
       "  0.09897748161764706,\n",
       "  0.09913661369193154,\n",
       "  0.09910442073170732,\n",
       "  0.09920544403892945,\n",
       "  0.09923012742718447,\n",
       "  0.09925469128329298,\n",
       "  0.09922252415458938,\n",
       "  0.09920933734939759,\n",
       "  0.09930889423076923,\n",
       "  0.09918315347721822,\n",
       "  0.09915146531100479,\n",
       "  0.0991385739856802,\n",
       "  0.09914434523809523,\n",
       "  0.09920576009501188,\n",
       "  0.0991928317535545,\n",
       "  0.09934618794326242,\n",
       "  0.09933298938679246,\n",
       "  0.09926470588235294,\n",
       "  0.09923342136150234,\n",
       "  0.09916569086651054,\n",
       "  0.09915303738317757,\n",
       "  0.09919507575757576,\n",
       "  0.09925508720930233,\n",
       "  0.09913355568445475,\n",
       "  0.09906684027777778,\n",
       "  0.09898239030023094,\n",
       "  0.09913234447004608,\n",
       "  0.09911997126436782,\n",
       "  0.09910765481651376,\n",
       "  0.09914902745995423,\n",
       "  0.09901184360730593,\n",
       "  0.09908883826879271,\n",
       "  0.09898792613636363,\n",
       "  0.09902919501133786,\n",
       "  0.09894654977375565,\n",
       "  0.0989877257336343,\n",
       "  0.09897592905405406,\n",
       "  0.09896418539325842,\n",
       "  0.09897001121076233,\n",
       "  0.09899328859060402,\n",
       "  0.09920828683035714,\n",
       "  0.09917873051224944,\n",
       "  0.09913194444444444,\n",
       "  0.09913733370288248,\n",
       "  0.09917726769911504,\n",
       "  0.09911354856512142,\n",
       "  0.09899848568281938,\n",
       "  0.09896978021978022,\n",
       "  0.09904399671052631,\n",
       "  0.09906660284463895,\n",
       "  0.09908911026200873,\n",
       "  0.09912854030501089,\n",
       "  0.0991508152173913,\n",
       "  0.09912215292841649,\n",
       "  0.09909361471861472,\n",
       "  0.09911582073434125,\n",
       "  0.09913793103448276,\n",
       "  0.09917674731182796,\n",
       "  0.09909804184549356,\n",
       "  0.09905313169164882,\n",
       "  0.09905849358974358,\n",
       "  0.09901666666666667],\n",
       " [0.109375,\n",
       "  0.09375,\n",
       "  0.08854166666666667,\n",
       "  0.076171875,\n",
       "  0.0765625,\n",
       "  0.09114583333333333,\n",
       "  0.08928571428571429,\n",
       "  0.0947265625,\n",
       "  0.09288194444444445,\n",
       "  0.09296875,\n",
       "  0.09232954545454546,\n",
       "  0.09049479166666667,\n",
       "  0.09314903846153846,\n",
       "  0.09095982142857142,\n",
       "  0.09322916666666667,\n",
       "  0.09716796875,\n",
       "  0.09696691176470588,\n",
       "  0.0959201388888889,\n",
       "  0.09703947368421052,\n",
       "  0.099609375,\n",
       "  0.09895833333333333,\n",
       "  0.09872159090909091,\n",
       "  0.09816576086956522,\n",
       "  0.0986328125,\n",
       "  0.0990625,\n",
       "  0.09945913461538461,\n",
       "  0.09924768518518519,\n",
       "  0.09877232142857142,\n",
       "  0.0972521551724138,\n",
       "  0.0984375,\n",
       "  0.09753024193548387,\n",
       "  0.097412109375,\n",
       "  0.09824810606060606,\n",
       "  0.09834558823529412,\n",
       "  0.09709821428571429,\n",
       "  0.0978732638888889,\n",
       "  0.09797297297297297,\n",
       "  0.09662828947368421,\n",
       "  0.09735576923076923,\n",
       "  0.09765625,\n",
       "  0.09832317073170732,\n",
       "  0.09951636904761904,\n",
       "  0.09974563953488372,\n",
       "  0.099609375,\n",
       "  0.09861111111111111,\n",
       "  0.09850543478260869,\n",
       "  0.09857047872340426,\n",
       "  0.09879557291666667,\n",
       "  0.09885204081632654,\n",
       "  0.098125,\n",
       "  0.09819240196078431,\n",
       "  0.09780649038461539,\n",
       "  0.09743514150943396,\n",
       "  0.09693287037037036,\n",
       "  0.09659090909090909,\n",
       "  0.0966796875,\n",
       "  0.09690241228070176,\n",
       "  0.09684806034482758,\n",
       "  0.0958686440677966,\n",
       "  0.096484375,\n",
       "  0.09605532786885246,\n",
       "  0.09551411290322581,\n",
       "  0.09561011904761904,\n",
       "  0.095947265625,\n",
       "  0.09567307692307692,\n",
       "  0.09588068181818182,\n",
       "  0.09573227611940298,\n",
       "  0.09616268382352941,\n",
       "  0.09612771739130435,\n",
       "  0.09575892857142858,\n",
       "  0.0958406690140845,\n",
       "  0.09635416666666667,\n",
       "  0.09621147260273973,\n",
       "  0.09596706081081081,\n",
       "  0.09572916666666667,\n",
       "  0.09560032894736842,\n",
       "  0.0950689935064935,\n",
       "  0.09525240384615384,\n",
       "  0.09562895569620253,\n",
       "  0.09609375,\n",
       "  0.09616126543209877,\n",
       "  0.09584603658536585,\n",
       "  0.09535015060240964,\n",
       "  0.09533110119047619,\n",
       "  0.09540441176470588,\n",
       "  0.09529433139534883,\n",
       "  0.09527658045977011,\n",
       "  0.09534801136363637,\n",
       "  0.09524227528089887,\n",
       "  0.09539930555555555,\n",
       "  0.09520947802197802,\n",
       "  0.09536345108695653,\n",
       "  0.09526209677419355,\n",
       "  0.0951628989361702,\n",
       "  0.09490131578947368,\n",
       "  0.094970703125,\n",
       "  0.09511920103092783,\n",
       "  0.09518494897959184,\n",
       "  0.09532828282828283,\n",
       "  0.095234375,\n",
       "  0.09491027227722772,\n",
       "  0.09474571078431372,\n",
       "  0.0948877427184466,\n",
       "  0.09510216346153846,\n",
       "  0.09523809523809523,\n",
       "  0.09537146226415094,\n",
       "  0.09557535046728972,\n",
       "  0.09555844907407407,\n",
       "  0.09590022935779817,\n",
       "  0.09609375,\n",
       "  0.09614301801801801,\n",
       "  0.09633091517857142,\n",
       "  0.09637721238938053,\n",
       "  0.09635416666666667,\n",
       "  0.09599184782608695,\n",
       "  0.09556842672413793,\n",
       "  0.09575320512820513,\n",
       "  0.0958686440677966,\n",
       "  0.09571953781512606,\n",
       "  0.09537760416666667,\n",
       "  0.09523502066115702,\n",
       "  0.09490266393442623,\n",
       "  0.09476626016260163,\n",
       "  0.09513608870967742,\n",
       "  0.0953125,\n",
       "  0.0953000992063492,\n",
       "  0.09504183070866142,\n",
       "  0.0950927734375,\n",
       "  0.09532461240310078,\n",
       "  0.09579326923076924,\n",
       "  0.0958969465648855,\n",
       "  0.09599905303030302,\n",
       "  0.0959234022556391,\n",
       "  0.09584888059701492,\n",
       "  0.09618055555555556,\n",
       "  0.09616268382352941,\n",
       "  0.09574589416058395,\n",
       "  0.09573143115942029,\n",
       "  0.09594199640287769,\n",
       "  0.09581473214285714,\n",
       "  0.09596631205673758,\n",
       "  0.09617077464788733,\n",
       "  0.09615384615384616,\n",
       "  0.09635416666666667,\n",
       "  0.09606681034482759,\n",
       "  0.09637200342465753,\n",
       "  0.09646045918367346,\n",
       "  0.09633657094594594,\n",
       "  0.09610947986577181,\n",
       "  0.09619791666666666,\n",
       "  0.0962851821192053,\n",
       "  0.09611430921052631,\n",
       "  0.09604779411764706,\n",
       "  0.09588068181818182,\n",
       "  0.09551411290322581,\n",
       "  0.09560296474358974,\n",
       "  0.09559116242038217,\n",
       "  0.09572784810126582,\n",
       "  0.09576454402515723,\n",
       "  0.095849609375,\n",
       "  0.09603066770186336,\n",
       "  0.09616126543209877,\n",
       "  0.09614647239263803,\n",
       "  0.09617949695121951,\n",
       "  0.09644886363636364,\n",
       "  0.0963855421686747,\n",
       "  0.09627619760479042,\n",
       "  0.09626116071428571,\n",
       "  0.0963387573964497,\n",
       "  0.09613970588235295,\n",
       "  0.09612573099415204,\n",
       "  0.09624818313953488,\n",
       "  0.09627890173410404,\n",
       "  0.09612966954022989,\n",
       "  0.09642857142857143,\n",
       "  0.09641335227272728,\n",
       "  0.09648658192090395,\n",
       "  0.09651509831460674,\n",
       "  0.09641236033519553,\n",
       "  0.09644097222222223,\n",
       "  0.09633977900552486,\n",
       "  0.09636847527472528,\n",
       "  0.09626878415300547,\n",
       "  0.09638247282608696,\n",
       "  0.09624155405405406,\n",
       "  0.0963961693548387,\n",
       "  0.09629846256684492,\n",
       "  0.09636801861702128,\n",
       "  0.09643683862433862,\n",
       "  0.09629934210526316,\n",
       "  0.0962859947643979,\n",
       "  0.09639485677083333,\n",
       "  0.09625971502590673,\n",
       "  0.09660921391752578,\n",
       "  0.096875,\n",
       "  0.09673947704081633,\n",
       "  0.09684327411167512,\n",
       "  0.09682765151515152,\n",
       "  0.096615891959799,\n",
       "  0.0966015625,\n",
       "  0.09674284825870647,\n",
       "  0.09665068069306931,\n",
       "  0.09675184729064039,\n",
       "  0.09677542892156862,\n",
       "  0.09695121951219512,\n",
       "  0.09693567961165049,\n",
       "  0.09707125603864734,\n",
       "  0.09713040865384616,\n",
       "  0.0970020933014354,\n",
       "  0.09732142857142857,\n",
       "  0.09737855450236967,\n",
       "  0.09732458726415094,\n",
       "  0.09738116197183098,\n",
       "  0.09740070093457943,\n",
       "  0.09752906976744186,\n",
       "  0.0974392361111111,\n",
       "  0.09742223502304148,\n",
       "  0.09769208715596331,\n",
       "  0.09785245433789955,\n",
       "  0.098046875,\n",
       "  0.0979920814479638,\n",
       "  0.09797297297297297,\n",
       "  0.09791900224215247,\n",
       "  0.09797014508928571,\n",
       "  0.09788194444444444,\n",
       "  0.09782909292035398,\n",
       "  0.09774229074889867,\n",
       "  0.0976905153508772,\n",
       "  0.09743449781659388,\n",
       "  0.09755434782608696,\n",
       "  0.09770698051948051,\n",
       "  0.09765625,\n",
       "  0.09760595493562232,\n",
       "  0.09765625,\n",
       "  0.0976063829787234,\n",
       "  0.09775556144067797,\n",
       "  0.09790348101265822,\n",
       "  0.09798450630252101,\n",
       "  0.09790141213389121,\n",
       "  0.09801432291666666,\n",
       "  0.09809387966804979,\n",
       "  0.09810821280991736,\n",
       "  0.0981224279835391,\n",
       "  0.09823258196721311,\n",
       "  0.09811862244897959,\n",
       "  0.09806910569105691,\n",
       "  0.09833628542510121,\n",
       "  0.09828629032258064,\n",
       "  0.09829944779116466,\n",
       "  0.09834375,\n",
       "  0.0982320717131474,\n",
       "  0.0982452876984127,\n",
       "  0.0981348814229249,\n",
       "  0.09805610236220473,\n",
       "  0.09822303921568627,\n",
       "  0.09820556640625,\n",
       "  0.09815783073929961,\n",
       "  0.09811046511627906,\n",
       "  0.09803330115830115,\n",
       "  0.09807692307692308,\n",
       "  0.0980603448275862,\n",
       "  0.09819298664122138,\n",
       "  0.09817609315589354,\n",
       "  0.09827769886363637,\n",
       "  0.09826061320754717,\n",
       "  0.09830239661654136,\n",
       "  0.09837312734082397,\n",
       "  0.0986182369402985,\n",
       "  0.09860013940520446,\n",
       "  0.09875578703703704,\n",
       "  0.09873731549815498,\n",
       "  0.0988625919117647,\n",
       "  0.09901556776556776,\n",
       "  0.09913891423357664,\n",
       "  0.09920454545454545,\n",
       "  0.0990715579710145,\n",
       "  0.09910875451263539,\n",
       "  0.09922999100719425,\n",
       "  0.09923835125448029,\n",
       "  0.09919084821428571,\n",
       "  0.09931049822064057,\n",
       "  0.09915226063829788,\n",
       "  0.09921598939929328,\n",
       "  0.09938930457746478,\n",
       "  0.09936951754385964,\n",
       "  0.09943181818181818,\n",
       "  0.09946646341463415,\n",
       "  0.09944661458333333,\n",
       "  0.09942690311418685,\n",
       "  0.09935344827586207,\n",
       "  0.09941473367697594,\n",
       "  0.09923480308219178,\n",
       "  0.09921608361774745,\n",
       "  0.09914434523809523,\n",
       "  0.09907309322033898,\n",
       "  0.09908150337837837,\n",
       "  0.09903724747474747,\n",
       "  0.09907193791946309,\n",
       "  0.09915865384615384,\n",
       "  0.09924479166666667,\n",
       "  0.0992265365448505,\n",
       "  0.09918253311258278,\n",
       "  0.09919038778877888,\n",
       "  0.09919819078947369,\n",
       "  0.09900102459016394,\n",
       "  0.0990859885620915,\n",
       "  0.09901771172638436,\n",
       "  0.09905133928571429,\n",
       "  0.09923644822006472,\n",
       "  0.09924395161290323,\n",
       "  0.09917604501607717,\n",
       "  0.09923377403846154,\n",
       "  0.0991663338658147,\n",
       "  0.09914908439490445,\n",
       "  0.09915674603174603,\n",
       "  0.09899129746835443,\n",
       "  0.09899940851735016,\n",
       "  0.09893376572327044,\n",
       "  0.09879506269592477,\n",
       "  0.0988525390625,\n",
       "  0.09898267133956386,\n",
       "  0.09906347049689442,\n",
       "  0.09902283281733747,\n",
       "  0.09883777006172839,\n",
       "  0.09872596153846154,\n",
       "  0.09878259202453987,\n",
       "  0.09883887614678899,\n",
       "  0.09877572408536585,\n",
       "  0.09880794072948328,\n",
       "  0.09869791666666666,\n",
       "  0.09868296827794562,\n",
       "  0.09864457831325302,\n",
       "  0.09865334084084085,\n",
       "  0.09877900449101797,\n",
       "  0.09871735074626865,\n",
       "  0.09872581845238096,\n",
       "  0.09878060089020771,\n",
       "  0.09876571745562131,\n",
       "  0.09872787610619468,\n",
       "  0.09869025735294118,\n",
       "  0.09869868035190615,\n",
       "  0.09877558479532164,\n",
       "  0.09878370991253645,\n",
       "  0.09870094476744186,\n",
       "  0.09868659420289855,\n",
       "  0.09860458815028902,\n",
       "  0.09859059798270893,\n",
       "  0.09855423850574713,\n",
       "  0.09856285816618911,\n",
       "  0.09857142857142857,\n",
       "  0.09862446581196581,\n",
       "  0.09861061789772728,\n",
       "  0.09861898016997167,\n",
       "  0.09860522598870057,\n",
       "  0.09863556338028169,\n",
       "  0.09853405898876405,\n",
       "  0.09849877450980392,\n",
       "  0.09850733240223464,\n",
       "  0.09853760445682451,\n",
       "  0.0986328125,\n",
       "  0.09855436288088643,\n",
       "  0.09873532458563536,\n",
       "  0.09880767906336088,\n",
       "  0.09875085851648352,\n",
       "  0.0988013698630137,\n",
       "  0.09889429644808743,\n",
       "  0.09881641689373297,\n",
       "  0.09878141983695653,\n",
       "  0.0987889566395664,\n",
       "  0.09871199324324324,\n",
       "  0.09869861859838275,\n",
       "  0.09862231182795698,\n",
       "  0.09867208445040214,\n",
       "  0.09870070187165775,\n",
       "  0.09858333333333333,\n",
       "  0.09859125664893617,\n",
       "  0.0985576923076923,\n",
       "  0.09860697751322751,\n",
       "  0.09853232189973615,\n",
       "  0.09858141447368421,\n",
       "  0.09858923884514435,\n",
       "  0.09863792539267016,\n",
       "  0.09862516318537859,\n",
       "  0.09869384765625,\n",
       "  0.09868100649350649,\n",
       "  0.09880990932642487,\n",
       "  0.0987766472868217,\n",
       "  0.09880396262886598,\n",
       "  0.098790970437018,\n",
       "  0.09883814102564102,\n",
       "  0.09878516624040921,\n",
       "  0.09867267219387756,\n",
       "  0.09875954198473283,\n",
       "  0.09870717005076142,\n",
       "  0.09877373417721519,\n",
       "  0.09882023358585859,\n",
       "  0.09884681989924433,\n",
       "  0.09873586683417085,\n",
       "  0.09866463032581453,\n",
       "  0.098671875,\n",
       "  0.09864011845386533,\n",
       "  0.09858908582089553,\n",
       "  0.0985383064516129,\n",
       "  0.09852645420792079,\n",
       "  0.09851466049382716,\n",
       "  0.09857989532019705,\n",
       "  0.09858722358722359,\n",
       "  0.09857536764705882,\n",
       "  0.09854446821515893,\n",
       "  0.0985327743902439,\n",
       "  0.09846411192214112,\n",
       "  0.09841474514563107,\n",
       "  0.09842236682808717,\n",
       "  0.09842995169082126,\n",
       "  0.0985316265060241,\n",
       "  0.09852013221153846,\n",
       "  0.09854616306954436,\n",
       "  0.09845992822966507,\n",
       "  0.09833681384248211,\n",
       "  0.09832589285714285,\n",
       "  0.09824079572446556,\n",
       "  0.09828569312796208,\n",
       "  0.09833037825059102,\n",
       "  0.09822744693396226,\n",
       "  0.09818014705882352,\n",
       "  0.09815140845070422,\n",
       "  0.09808621194379391,\n",
       "  0.09809433411214953,\n",
       "  0.09815705128205128,\n",
       "  0.09836482558139535,\n",
       "  0.09846287703016242,\n",
       "  0.0984157986111111,\n",
       "  0.0983689376443418,\n",
       "  0.09839429723502305,\n",
       "  0.0984375,\n",
       "  0.09837299311926606,\n",
       "  0.09829090389016018,\n",
       "  0.09835188356164383,\n",
       "  0.09837699316628702,\n",
       "  0.09836647727272728,\n",
       "  0.09830286281179139,\n",
       "  0.0983279128959276,\n",
       "  0.09833521444695259,\n",
       "  0.09841286599099099,\n",
       "  0.09838483146067416,\n",
       "  0.0984094730941704,\n",
       "  0.09832913870246085,\n",
       "  0.09828404017857142,\n",
       "  0.09825654231625836,\n",
       "  0.09828125,\n",
       "  0.0982365576496674,\n",
       "  0.09831305309734513,\n",
       "  0.09828573399558499,\n",
       "  0.09832736784140969,\n",
       "  0.09828296703296703,\n",
       "  0.09818736293859649,\n",
       "  0.09817765317286652,\n",
       "  0.09808269650655022,\n",
       "  0.09814133986928104,\n",
       "  0.09813179347826087,\n",
       "  0.09808839479392625,\n",
       "  0.09799445346320346,\n",
       "  0.09805278077753779,\n",
       "  0.09799299568965517,\n",
       "  0.09798387096774193,\n",
       "  0.09804184549356224,\n",
       "  0.09803265524625268,\n",
       "  0.09802350427350427,\n",
       "  0.09805],\n",
       " [0.09375,\n",
       "  0.1015625,\n",
       "  0.08854166666666667,\n",
       "  0.09375,\n",
       "  0.1015625,\n",
       "  0.09375,\n",
       "  0.09486607142857142,\n",
       "  0.0927734375,\n",
       "  0.0954861111111111,\n",
       "  0.09140625,\n",
       "  0.09303977272727272,\n",
       "  0.09505208333333333,\n",
       "  0.09495192307692307,\n",
       "  0.09821428571428571,\n",
       "  0.09947916666666666,\n",
       "  0.09716796875,\n",
       "  0.09466911764705882,\n",
       "  0.0959201388888889,\n",
       "  0.0962171052631579,\n",
       "  0.096484375,\n",
       "  0.0978422619047619,\n",
       "  0.09517045454545454,\n",
       "  0.09680706521739131,\n",
       "  0.09505208333333333,\n",
       "  0.0934375,\n",
       "  0.09254807692307693,\n",
       "  0.09056712962962964,\n",
       "  0.091796875,\n",
       "  0.09186422413793104,\n",
       "  0.09192708333333334,\n",
       "  0.0924899193548387,\n",
       "  0.093994140625,\n",
       "  0.09493371212121213,\n",
       "  0.09443933823529412,\n",
       "  0.09508928571428571,\n",
       "  0.09505208333333333,\n",
       "  0.09480574324324324,\n",
       "  0.09395559210526316,\n",
       "  0.09415064102564102,\n",
       "  0.0939453125,\n",
       "  0.09298780487804878,\n",
       "  0.09468005952380952,\n",
       "  0.09447674418604651,\n",
       "  0.09463778409090909,\n",
       "  0.09496527777777777,\n",
       "  0.09527853260869565,\n",
       "  0.09507978723404255,\n",
       "  0.09505208333333333,\n",
       "  0.09534438775510204,\n",
       "  0.0959375,\n",
       "  0.09558823529411764,\n",
       "  0.09540264423076923,\n",
       "  0.09537146226415094,\n",
       "  0.0954861111111111,\n",
       "  0.09602272727272727,\n",
       "  0.09584263392857142,\n",
       "  0.09594298245614036,\n",
       "  0.09577047413793104,\n",
       "  0.09626588983050847,\n",
       "  0.09635416666666667,\n",
       "  0.09695184426229508,\n",
       "  0.09715221774193548,\n",
       "  0.09722222222222222,\n",
       "  0.0970458984375,\n",
       "  0.09771634615384615,\n",
       "  0.09777462121212122,\n",
       "  0.09701492537313433,\n",
       "  0.09662224264705882,\n",
       "  0.09646739130434782,\n",
       "  0.09676339285714286,\n",
       "  0.0958406690140845,\n",
       "  0.09602864583333333,\n",
       "  0.09663955479452055,\n",
       "  0.09575591216216216,\n",
       "  0.09572916666666667,\n",
       "  0.09549753289473684,\n",
       "  0.09547483766233766,\n",
       "  0.09585336538461539,\n",
       "  0.09582674050632911,\n",
       "  0.09599609375,\n",
       "  0.09587191358024691,\n",
       "  0.09670350609756098,\n",
       "  0.09695030120481928,\n",
       "  0.09654017857142858,\n",
       "  0.09669117647058824,\n",
       "  0.09692950581395349,\n",
       "  0.09680316091954023,\n",
       "  0.09721235795454546,\n",
       "  0.09717345505617977,\n",
       "  0.09765625,\n",
       "  0.09778502747252747,\n",
       "  0.09816576086956522,\n",
       "  0.09820228494623656,\n",
       "  0.09815492021276596,\n",
       "  0.09777960526315789,\n",
       "  0.09773763020833333,\n",
       "  0.0979381443298969,\n",
       "  0.09805484693877552,\n",
       "  0.09832702020202021,\n",
       "  0.098671875,\n",
       "  0.0984684405940594,\n",
       "  0.09826899509803921,\n",
       "  0.09852851941747573,\n",
       "  0.0987079326923077,\n",
       "  0.09895833333333333,\n",
       "  0.09927771226415094,\n",
       "  0.09951810747663552,\n",
       "  0.099609375,\n",
       "  0.09941227064220183,\n",
       "  0.09936079545454546,\n",
       "  0.09945101351351351,\n",
       "  0.099609375,\n",
       "  0.09955752212389381,\n",
       "  0.09902686403508772,\n",
       "  0.09932065217391305,\n",
       "  0.09927262931034483,\n",
       "  0.09949252136752136,\n",
       "  0.09957627118644068,\n",
       "  0.09959296218487394,\n",
       "  0.0998046875,\n",
       "  0.09975464876033058,\n",
       "  0.09976946721311475,\n",
       "  0.10022865853658537,\n",
       "  0.10042842741935484,\n",
       "  0.1000625,\n",
       "  0.10026041666666667,\n",
       "  0.10070127952755906,\n",
       "  0.10052490234375,\n",
       "  0.10041182170542635,\n",
       "  0.10030048076923077,\n",
       "  0.10048902671755726,\n",
       "  0.10049715909090909,\n",
       "  0.10038768796992481,\n",
       "  0.09987173507462686,\n",
       "  0.09976851851851852,\n",
       "  0.09978170955882353,\n",
       "  0.09962363138686131,\n",
       "  0.09980751811594203,\n",
       "  0.09982014388489209,\n",
       "  0.09972098214285714,\n",
       "  0.09956781914893617,\n",
       "  0.09980193661971831,\n",
       "  0.09965034965034965,\n",
       "  0.09977213541666667,\n",
       "  0.09956896551724138,\n",
       "  0.0994755993150685,\n",
       "  0.09980867346938775,\n",
       "  0.09992609797297297,\n",
       "  0.09993708053691275,\n",
       "  0.1,\n",
       "  0.09995860927152318,\n",
       "  0.09976356907894737,\n",
       "  0.0999795751633987,\n",
       "  0.09988839285714286,\n",
       "  0.10005040322580645,\n",
       "  0.09980969551282051,\n",
       "  0.09987062101910828,\n",
       "  0.09973299050632911,\n",
       "  0.09969536163522012,\n",
       "  0.099658203125,\n",
       "  0.1000097049689441,\n",
       "  0.10016396604938271,\n",
       "  0.10012461656441718,\n",
       "  0.09994283536585366,\n",
       "  0.09981060606060606,\n",
       "  0.09958584337349398,\n",
       "  0.09945733532934131,\n",
       "  0.09937686011904762,\n",
       "  0.09911242603550297,\n",
       "  0.0994485294117647,\n",
       "  0.09946089181286549,\n",
       "  0.09933684593023256,\n",
       "  0.09934971098265896,\n",
       "  0.09931752873563218,\n",
       "  0.09955357142857142,\n",
       "  0.09965376420454546,\n",
       "  0.0994438559322034,\n",
       "  0.09919241573033707,\n",
       "  0.09911836592178772,\n",
       "  0.09904513888888888,\n",
       "  0.0991885359116022,\n",
       "  0.09911572802197802,\n",
       "  0.09900102459016394,\n",
       "  0.09901494565217392,\n",
       "  0.09894425675675676,\n",
       "  0.0989163306451613,\n",
       "  0.09926470588235294,\n",
       "  0.0993184840425532,\n",
       "  0.09916501322751323,\n",
       "  0.09921875,\n",
       "  0.09927192408376963,\n",
       "  0.09944661458333333,\n",
       "  0.09961949481865284,\n",
       "  0.09962951030927836,\n",
       "  0.09975961538461539,\n",
       "  0.09944993622448979,\n",
       "  0.09942100253807107,\n",
       "  0.09935290404040405,\n",
       "  0.09932474874371859,\n",
       "  0.099296875,\n",
       "  0.09911380597014925,\n",
       "  0.09908725247524752,\n",
       "  0.09917641625615764,\n",
       "  0.09918811274509803,\n",
       "  0.09919969512195122,\n",
       "  0.09943871359223301,\n",
       "  0.09918478260869565,\n",
       "  0.09915865384615384,\n",
       "  0.09928229665071771,\n",
       "  0.09918154761904761,\n",
       "  0.09922985781990522,\n",
       "  0.09916715801886793,\n",
       "  0.09921508215962441,\n",
       "  0.09929906542056074,\n",
       "  0.09920058139534883,\n",
       "  0.09917534722222222,\n",
       "  0.09907834101382489,\n",
       "  0.0990180619266055,\n",
       "  0.09931506849315068,\n",
       "  0.09932528409090909,\n",
       "  0.09919400452488687,\n",
       "  0.09899352477477477,\n",
       "  0.09911014573991031,\n",
       "  0.09933035714285714,\n",
       "  0.0992013888888889,\n",
       "  0.09924640486725664,\n",
       "  0.09908452643171806,\n",
       "  0.09906112938596491,\n",
       "  0.09907205240174673,\n",
       "  0.09908288043478261,\n",
       "  0.09909361471861472,\n",
       "  0.09913793103448276,\n",
       "  0.09904774678111589,\n",
       "  0.09899172008547008,\n",
       "  0.09886968085106383,\n",
       "  0.0990135063559322,\n",
       "  0.09885944092827004,\n",
       "  0.09864101890756302,\n",
       "  0.09858786610878661,\n",
       "  0.09840494791666667,\n",
       "  0.09828838174273859,\n",
       "  0.09833419421487603,\n",
       "  0.09809027777777778,\n",
       "  0.09807248975409837,\n",
       "  0.09799107142857143,\n",
       "  0.09803734756097561,\n",
       "  0.09808324898785425,\n",
       "  0.09809727822580645,\n",
       "  0.09779743975903614,\n",
       "  0.09784375,\n",
       "  0.09785856573705179,\n",
       "  0.09778025793650794,\n",
       "  0.09773344861660078,\n",
       "  0.0975947342519685,\n",
       "  0.09748774509803922,\n",
       "  0.09747314453125,\n",
       "  0.09748905642023346,\n",
       "  0.09735343992248062,\n",
       "  0.09727919884169885,\n",
       "  0.09729567307692308,\n",
       "  0.09719228927203065,\n",
       "  0.09717915076335878,\n",
       "  0.09710670152091255,\n",
       "  0.09718276515151515,\n",
       "  0.0970813679245283,\n",
       "  0.09703947368421052,\n",
       "  0.09705641385767791,\n",
       "  0.09686916977611941,\n",
       "  0.09679948884758365,\n",
       "  0.09664351851851852,\n",
       "  0.09660401291512916,\n",
       "  0.09670840992647059,\n",
       "  0.09684065934065934,\n",
       "  0.09680086678832117,\n",
       "  0.096875,\n",
       "  0.09703351449275362,\n",
       "  0.09704986462093863,\n",
       "  0.09689748201438848,\n",
       "  0.09680219534050179,\n",
       "  0.0966796875,\n",
       "  0.0966414590747331,\n",
       "  0.09652039007092199,\n",
       "  0.09653820671378092,\n",
       "  0.09655589788732394,\n",
       "  0.09640899122807017,\n",
       "  0.09639969405594405,\n",
       "  0.09652656794425087,\n",
       "  0.09654405381944445,\n",
       "  0.09645328719723184,\n",
       "  0.09644396551724138,\n",
       "  0.09621993127147767,\n",
       "  0.09621147260273973,\n",
       "  0.09625639931740615,\n",
       "  0.09619472789115646,\n",
       "  0.09629237288135593,\n",
       "  0.09631017736486487,\n",
       "  0.09619633838383838,\n",
       "  0.09618812919463088,\n",
       "  0.09620610367892976,\n",
       "  0.09611979166666666,\n",
       "  0.09611191860465117,\n",
       "  0.09597475165562915,\n",
       "  0.09614789603960396,\n",
       "  0.09608861019736842,\n",
       "  0.09613217213114754,\n",
       "  0.09609885620915033,\n",
       "  0.09611665309446255,\n",
       "  0.0963372564935065,\n",
       "  0.0963794498381877,\n",
       "  0.09637096774193549,\n",
       "  0.09643790192926045,\n",
       "  0.09637920673076923,\n",
       "  0.09624600638977636,\n",
       "  0.09618829617834394,\n",
       "  0.09615575396825397,\n",
       "  0.09612341772151899,\n",
       "  0.09604199526813881,\n",
       "  0.09598565251572327,\n",
       "  0.09605211598746081,\n",
       "  0.096142578125,\n",
       "  0.09611078660436137,\n",
       "  0.09620050465838509,\n",
       "  0.0962171052631579,\n",
       "  0.09623360339506173,\n",
       "  0.09627403846153847,\n",
       "  0.0963142254601227,\n",
       "  0.0963302752293578,\n",
       "  0.09637004573170732,\n",
       "  0.0963383358662614,\n",
       "  0.09635416666666667,\n",
       "  0.09648791540785498,\n",
       "  0.09662085843373494,\n",
       "  0.09661223723723723,\n",
       "  0.09662705838323353,\n",
       "  0.09668843283582089,\n",
       "  0.09670293898809523,\n",
       "  0.0967637240356083,\n",
       "  0.09666235207100592,\n",
       "  0.09672289823008849,\n",
       "  0.09685202205882353,\n",
       "  0.0969116568914956,\n",
       "  0.09685672514619884,\n",
       "  0.09693877551020408,\n",
       "  0.09686137354651163,\n",
       "  0.0969429347826087,\n",
       "  0.0968208092485549,\n",
       "  0.09690201729106629,\n",
       "  0.09680316091954023,\n",
       "  0.09681679799426934,\n",
       "  0.09689732142857142,\n",
       "  0.09699964387464387,\n",
       "  0.09699041193181818,\n",
       "  0.09709189093484419,\n",
       "  0.0970603813559322,\n",
       "  0.09711707746478873,\n",
       "  0.09715150983146068,\n",
       "  0.09714198179271709,\n",
       "  0.0970233938547486,\n",
       "  0.09705779944289694,\n",
       "  0.0970703125,\n",
       "  0.09712603878116344,\n",
       "  0.09707354972375691,\n",
       "  0.09710743801652892,\n",
       "  0.09696943681318682,\n",
       "  0.09693921232876712,\n",
       "  0.09697318989071038,\n",
       "  0.09685797002724796,\n",
       "  0.09684952445652174,\n",
       "  0.09677760840108401,\n",
       "  0.09672719594594595,\n",
       "  0.09674022911051212,\n",
       "  0.0967741935483871,\n",
       "  0.09682892091152814,\n",
       "  0.09690424465240642,\n",
       "  0.09695833333333333,\n",
       "  0.09694980053191489,\n",
       "  0.09700348143236075,\n",
       "  0.09697420634920635,\n",
       "  0.09690385883905013,\n",
       "  0.09695723684210526,\n",
       "  0.09698982939632546,\n",
       "  0.096940445026178,\n",
       "  0.09689131853785901,\n",
       "  0.096923828125,\n",
       "  0.09689529220779221,\n",
       "  0.09694786269430052,\n",
       "  0.09706072351421188,\n",
       "  0.09703205541237113,\n",
       "  0.09702361825192803,\n",
       "  0.09707532051282051,\n",
       "  0.09712675831202046,\n",
       "  0.09707828443877552,\n",
       "  0.0970698155216285,\n",
       "  0.09706138959390863,\n",
       "  0.09715189873417722,\n",
       "  0.09708412247474747,\n",
       "  0.09705604534005038,\n",
       "  0.09706736809045226,\n",
       "  0.09707863408521303,\n",
       "  0.097109375,\n",
       "  0.09706203241895262,\n",
       "  0.09693718905472637,\n",
       "  0.09692928039702234,\n",
       "  0.09694074876237624,\n",
       "  0.09693287037037036,\n",
       "  0.0970020012315271,\n",
       "  0.09691722972972973,\n",
       "  0.09694776348039216,\n",
       "  0.09690174205378974,\n",
       "  0.09695121951219512,\n",
       "  0.09700045620437957,\n",
       "  0.09695464199029126,\n",
       "  0.09704146489104117,\n",
       "  0.09709012681159421,\n",
       "  0.09710090361445783,\n",
       "  0.09713040865384616,\n",
       "  0.09712230215827339,\n",
       "  0.097188995215311,\n",
       "  0.09710620525059666,\n",
       "  0.09713541666666667,\n",
       "  0.09720160332541568,\n",
       "  0.09721193720379147,\n",
       "  0.09712987588652482,\n",
       "  0.09710347877358491,\n",
       "  0.09698529411764706,\n",
       "  0.09703271713615023,\n",
       "  0.09700673302107728,\n",
       "  0.0969991238317757,\n",
       "  0.09704618298368298,\n",
       "  0.0971656976744186,\n",
       "  0.09728465777262181,\n",
       "  0.09729456018518519,\n",
       "  0.09725028868360278,\n",
       "  0.09726022465437788,\n",
       "  0.09735991379310345,\n",
       "  0.09736955275229357,\n",
       "  0.09734339244851259,\n",
       "  0.09728167808219178,\n",
       "  0.09732702164009112,\n",
       "  0.09730113636363637,\n",
       "  0.09731079931972789,\n",
       "  0.09735576923076923,\n",
       "  0.09743580699774267,\n",
       "  0.09742750563063063,\n",
       "  0.09738412921348315,\n",
       "  0.09732343049327355,\n",
       "  0.09736786912751678,\n",
       "  0.09739467075892858,\n",
       "  0.09733435412026727,\n",
       "  0.09734375,\n",
       "  0.09740507206208426,\n",
       "  0.09734513274336283,\n",
       "  0.09735444260485651,\n",
       "  0.09727767070484582,\n",
       "  0.09742445054945055,\n",
       "  0.09738212719298246,\n",
       "  0.09735708424507658,\n",
       "  0.09740038209606987,\n",
       "  0.09732434640522876,\n",
       "  0.09738451086956522,\n",
       "  0.0973935737527115,\n",
       "  0.09745332792207792,\n",
       "  0.09741158207343413,\n",
       "  0.09745420258620689,\n",
       "  0.09747983870967741,\n",
       "  0.09742153969957082,\n",
       "  0.09744713597430407,\n",
       "  0.09733907585470085,\n",
       "  0.09728333333333333],\n",
       " [0.0859375,\n",
       "  0.078125,\n",
       "  0.08333333333333333,\n",
       "  0.08984375,\n",
       "  0.0890625,\n",
       "  0.08072916666666667,\n",
       "  0.08258928571428571,\n",
       "  0.0849609375,\n",
       "  0.08333333333333333,\n",
       "  0.0875,\n",
       "  0.09161931818181818,\n",
       "  0.09505208333333333,\n",
       "  0.0967548076923077,\n",
       "  0.09821428571428571,\n",
       "  0.096875,\n",
       "  0.09765625,\n",
       "  0.09834558823529412,\n",
       "  0.09635416666666667,\n",
       "  0.09539473684210527,\n",
       "  0.096484375,\n",
       "  0.09635416666666667,\n",
       "  0.09446022727272728,\n",
       "  0.09510869565217392,\n",
       "  0.095703125,\n",
       "  0.094375,\n",
       "  0.09435096153846154,\n",
       "  0.0943287037037037,\n",
       "  0.09542410714285714,\n",
       "  0.09590517241379311,\n",
       "  0.09791666666666667,\n",
       "  0.09803427419354839,\n",
       "  0.09912109375,\n",
       "  0.09943181818181818,\n",
       "  0.09880514705882353,\n",
       "  0.09776785714285714,\n",
       "  0.09678819444444445,\n",
       "  0.09607263513513513,\n",
       "  0.09662828947368421,\n",
       "  0.09695512820512821,\n",
       "  0.09609375,\n",
       "  0.09660823170731707,\n",
       "  0.0974702380952381,\n",
       "  0.09665697674418605,\n",
       "  0.09783380681818182,\n",
       "  0.09774305555555556,\n",
       "  0.09833559782608696,\n",
       "  0.09890292553191489,\n",
       "  0.09895833333333333,\n",
       "  0.09869260204081633,\n",
       "  0.0984375,\n",
       "  0.10003063725490197,\n",
       "  0.10021033653846154,\n",
       "  0.09994103773584906,\n",
       "  0.0993923611111111,\n",
       "  0.09914772727272728,\n",
       "  0.09849330357142858,\n",
       "  0.09799890350877193,\n",
       "  0.0972521551724138,\n",
       "  0.09745762711864407,\n",
       "  0.09817708333333333,\n",
       "  0.09772028688524591,\n",
       "  0.09778225806451613,\n",
       "  0.0978422619047619,\n",
       "  0.0975341796875,\n",
       "  0.09867788461538461,\n",
       "  0.0986032196969697,\n",
       "  0.09841417910447761,\n",
       "  0.09857536764705882,\n",
       "  0.09839221014492754,\n",
       "  0.09821428571428571,\n",
       "  0.09815140845070422,\n",
       "  0.09906684027777778,\n",
       "  0.09920804794520548,\n",
       "  0.09902871621621621,\n",
       "  0.09989583333333334,\n",
       "  0.1001233552631579,\n",
       "  0.10004058441558442,\n",
       "  0.09985977564102565,\n",
       "  0.10017800632911393,\n",
       "  0.100390625,\n",
       "  0.10069444444444445,\n",
       "  0.10003810975609756,\n",
       "  0.09958584337349398,\n",
       "  0.09970238095238096,\n",
       "  0.0994485294117647,\n",
       "  0.09929142441860465,\n",
       "  0.09913793103448276,\n",
       "  0.09916548295454546,\n",
       "  0.09892907303370786,\n",
       "  0.09904513888888888,\n",
       "  0.0989010989010989,\n",
       "  0.09909986413043478,\n",
       "  0.09988239247311828,\n",
       "  0.10023271276595745,\n",
       "  0.10032894736842106,\n",
       "  0.10001627604166667,\n",
       "  0.09962951030927836,\n",
       "  0.10004783163265306,\n",
       "  0.10029987373737374,\n",
       "  0.100234375,\n",
       "  0.10017017326732673,\n",
       "  0.10010723039215687,\n",
       "  0.09981796116504854,\n",
       "  0.09983473557692307,\n",
       "  0.09955357142857142,\n",
       "  0.09957252358490566,\n",
       "  0.0995911214953271,\n",
       "  0.09975405092592593,\n",
       "  0.09984231651376146,\n",
       "  0.09992897727272727,\n",
       "  0.10036599099099099,\n",
       "  0.10044642857142858,\n",
       "  0.10011061946902655,\n",
       "  0.09998629385964912,\n",
       "  0.10027173913043479,\n",
       "  0.10041756465517242,\n",
       "  0.10029380341880342,\n",
       "  0.10010593220338983,\n",
       "  0.10038077731092437,\n",
       "  0.100390625,\n",
       "  0.10052944214876033,\n",
       "  0.10066598360655737,\n",
       "  0.10073678861788618,\n",
       "  0.10112147177419355,\n",
       "  0.101125,\n",
       "  0.10106646825396826,\n",
       "  0.10119340551181102,\n",
       "  0.10101318359375,\n",
       "  0.10150193798449612,\n",
       "  0.10114182692307692,\n",
       "  0.10090648854961833,\n",
       "  0.10085227272727272,\n",
       "  0.10103383458646617,\n",
       "  0.10115438432835822,\n",
       "  0.1011574074074074,\n",
       "  0.10104549632352941,\n",
       "  0.10087819343065693,\n",
       "  0.10093976449275362,\n",
       "  0.1008318345323741,\n",
       "  0.10128348214285714,\n",
       "  0.10106382978723404,\n",
       "  0.10106734154929578,\n",
       "  0.10101617132867133,\n",
       "  0.10118272569444445,\n",
       "  0.10102370689655173,\n",
       "  0.10081335616438356,\n",
       "  0.10065901360544217,\n",
       "  0.10055954391891891,\n",
       "  0.10061870805369127,\n",
       "  0.10026041666666667,\n",
       "  0.10006208609271523,\n",
       "  0.10043174342105263,\n",
       "  0.10049019607843138,\n",
       "  0.10054788961038962,\n",
       "  0.10055443548387097,\n",
       "  0.1005108173076923,\n",
       "  0.10051751592356688,\n",
       "  0.10047468354430379,\n",
       "  0.10107114779874214,\n",
       "  0.101171875,\n",
       "  0.10141692546583851,\n",
       "  0.10141782407407407,\n",
       "  0.10108320552147239,\n",
       "  0.10099085365853659,\n",
       "  0.10075757575757575,\n",
       "  0.10057417168674698,\n",
       "  0.10048652694610778,\n",
       "  0.10021391369047619,\n",
       "  0.10026812130177515,\n",
       "  0.10013786764705883,\n",
       "  0.10023757309941521,\n",
       "  0.10015443313953488,\n",
       "  0.10047868497109827,\n",
       "  0.10039511494252873,\n",
       "  0.10071428571428571,\n",
       "  0.10067471590909091,\n",
       "  0.10067973163841808,\n",
       "  0.10050912921348315,\n",
       "  0.1003840782122905,\n",
       "  0.10034722222222223,\n",
       "  0.10031077348066299,\n",
       "  0.10023179945054946,\n",
       "  0.10032445355191257,\n",
       "  0.10028872282608696,\n",
       "  0.10059121621621622,\n",
       "  0.10047043010752688,\n",
       "  0.10064338235294118,\n",
       "  0.10056515957446809,\n",
       "  0.10048776455026455,\n",
       "  0.10045230263157895,\n",
       "  0.10066263089005235,\n",
       "  0.10062662760416667,\n",
       "  0.10071243523316062,\n",
       "  0.10055573453608248,\n",
       "  0.10028044871794872,\n",
       "  0.10032684948979592,\n",
       "  0.10025380710659898,\n",
       "  0.10041824494949494,\n",
       "  0.10030621859296482,\n",
       "  0.1002734375,\n",
       "  0.1002021144278607,\n",
       "  0.10032487623762376,\n",
       "  0.10048491379310345,\n",
       "  0.10029871323529412,\n",
       "  0.10022865853658537,\n",
       "  0.10019720873786407,\n",
       "  0.10009057971014493,\n",
       "  0.10013521634615384,\n",
       "  0.10010466507177034,\n",
       "  0.10011160714285715,\n",
       "  0.10015550947867298,\n",
       "  0.10016214622641509,\n",
       "  0.09994865023474178,\n",
       "  0.09988317757009346,\n",
       "  0.09992732558139535,\n",
       "  0.09989872685185185,\n",
       "  0.10008640552995392,\n",
       "  0.09984231651376146,\n",
       "  0.09988584474885845,\n",
       "  0.09985795454545454,\n",
       "  0.09961821266968326,\n",
       "  0.09962697072072071,\n",
       "  0.09967068385650224,\n",
       "  0.09971400669642858,\n",
       "  0.0996875,\n",
       "  0.099522953539823,\n",
       "  0.0996351872246696,\n",
       "  0.09954084429824561,\n",
       "  0.09951555676855896,\n",
       "  0.09952445652173914,\n",
       "  0.0997362012987013,\n",
       "  0.09964304956896551,\n",
       "  0.09978540772532189,\n",
       "  0.09975961538461539,\n",
       "  0.09973404255319149,\n",
       "  0.09980799788135593,\n",
       "  0.09984836497890295,\n",
       "  0.09998686974789917,\n",
       "  0.09992808577405858,\n",
       "  0.09983723958333333,\n",
       "  0.0997795643153527,\n",
       "  0.09956095041322315,\n",
       "  0.09953703703703703,\n",
       "  0.09932120901639344,\n",
       "  0.09917091836734694,\n",
       "  0.09911712398373984,\n",
       "  0.0990005060728745,\n",
       "  0.09897933467741936,\n",
       "  0.09908383534136546,\n",
       "  0.09896875,\n",
       "  0.09901020916334662,\n",
       "  0.09880332341269842,\n",
       "  0.09878334980237154,\n",
       "  0.09876353346456693,\n",
       "  0.09868259803921568,\n",
       "  0.09881591796875,\n",
       "  0.09879620622568093,\n",
       "  0.09883720930232558,\n",
       "  0.09875723938223938,\n",
       "  0.09858774038461539,\n",
       "  0.09850933908045977,\n",
       "  0.09852099236641221,\n",
       "  0.09856226235741444,\n",
       "  0.0986624053030303,\n",
       "  0.09855542452830189,\n",
       "  0.09868421052631579,\n",
       "  0.09872425093632958,\n",
       "  0.09882229477611941,\n",
       "  0.09883248141263941,\n",
       "  0.0986400462962963,\n",
       "  0.09870848708487084,\n",
       "  0.09871897977941177,\n",
       "  0.0987293956043956,\n",
       "  0.09865419708029197,\n",
       "  0.09875,\n",
       "  0.09876019021739131,\n",
       "  0.09874210288808664,\n",
       "  0.09858363309352518,\n",
       "  0.0985663082437276,\n",
       "  0.0984375,\n",
       "  0.09847642348754448,\n",
       "  0.09857047872340426,\n",
       "  0.09860865724381626,\n",
       "  0.09870158450704225,\n",
       "  0.09871162280701755,\n",
       "  0.09880354020979021,\n",
       "  0.09875871080139373,\n",
       "  0.09876844618055555,\n",
       "  0.09877811418685122,\n",
       "  0.09878771551724137,\n",
       "  0.09879725085910653,\n",
       "  0.09886023116438356,\n",
       "  0.09876279863481228,\n",
       "  0.09882546768707483,\n",
       "  0.09883474576271187,\n",
       "  0.0987647804054054,\n",
       "  0.09872159090909091,\n",
       "  0.09867869127516779,\n",
       "  0.09866220735785954,\n",
       "  0.09861979166666666,\n",
       "  0.09870743355481727,\n",
       "  0.09871688741721854,\n",
       "  0.09867471122112212,\n",
       "  0.09881270559210527,\n",
       "  0.09871926229508196,\n",
       "  0.09862642973856209,\n",
       "  0.09863599348534202,\n",
       "  0.09864549512987013,\n",
       "  0.09862965210355987,\n",
       "  0.09851310483870968,\n",
       "  0.0985480305466238,\n",
       "  0.09868289262820513,\n",
       "  0.09864217252396167,\n",
       "  0.09870123407643312,\n",
       "  0.0988095238095238,\n",
       "  0.09891712816455696,\n",
       "  0.09902405362776025,\n",
       "  0.0990811713836478,\n",
       "  0.09906445924764891,\n",
       "  0.0989501953125,\n",
       "  0.09903134735202493,\n",
       "  0.09899068322981366,\n",
       "  0.09904702012383901,\n",
       "  0.09898244598765432,\n",
       "  0.09911057692307693,\n",
       "  0.09926188650306748,\n",
       "  0.09924503058103976,\n",
       "  0.09918064024390244,\n",
       "  0.09925911854103343,\n",
       "  0.09940814393939394,\n",
       "  0.09946185800604229,\n",
       "  0.09944465361445783,\n",
       "  0.0994040915915916,\n",
       "  0.09948072604790419,\n",
       "  0.0994169776119403,\n",
       "  0.09946986607142858,\n",
       "  0.09947607566765579,\n",
       "  0.09941290680473373,\n",
       "  0.09948838495575221,\n",
       "  0.09963235294117648,\n",
       "  0.09963801319648094,\n",
       "  0.09966648391812866,\n",
       "  0.09955812682215744,\n",
       "  0.09958666424418605,\n",
       "  0.09959239130434783,\n",
       "  0.09946260838150289,\n",
       "  0.09953620317002881,\n",
       "  0.09958692528735633,\n",
       "  0.09961497134670487,\n",
       "  0.09959821428571429,\n",
       "  0.09967058404558404,\n",
       "  0.09969815340909091,\n",
       "  0.09981409348441926,\n",
       "  0.09992937853107345,\n",
       "  0.0998899647887324,\n",
       "  0.09998244382022473,\n",
       "  0.09998686974789917,\n",
       "  0.10007856145251397,\n",
       "  0.10012621866295264,\n",
       "  0.10008680555555556,\n",
       "  0.10000432825484765,\n",
       "  0.10000863259668508,\n",
       "  0.10005595730027549,\n",
       "  0.10010302197802198,\n",
       "  0.10008561643835616,\n",
       "  0.10011099726775956,\n",
       "  0.1001149523160763,\n",
       "  0.10018257472826086,\n",
       "  0.10024983062330624,\n",
       "  0.10012668918918918,\n",
       "  0.10010950134770889,\n",
       "  0.10011340725806452,\n",
       "  0.10011729222520108,\n",
       "  0.10010026737967914,\n",
       "  0.10010416666666666,\n",
       "  0.1000457114361702,\n",
       "  0.10019479442970822,\n",
       "  0.10026041666666667,\n",
       "  0.10028446569920844,\n",
       "  0.10030838815789474,\n",
       "  0.10027066929133858,\n",
       "  0.1003354057591623,\n",
       "  0.10031821148825065,\n",
       "  0.100341796875,\n",
       "  0.10030438311688311,\n",
       "  0.10042908031088082,\n",
       "  0.10037144702842377,\n",
       "  0.10047519329896908,\n",
       "  0.10047798843187661,\n",
       "  0.10046073717948718,\n",
       "  0.1004036125319693,\n",
       "  0.10028698979591837,\n",
       "  0.1002305979643766,\n",
       "  0.10023397842639593,\n",
       "  0.10015822784810127,\n",
       "  0.10014204545454546,\n",
       "  0.10016530226700252,\n",
       "  0.10009029522613065,\n",
       "  0.10013314536340852,\n",
       "  0.100234375,\n",
       "  0.10031561720698254,\n",
       "  0.10031871890547264,\n",
       "  0.1002248759305211,\n",
       "  0.10032487623762376,\n",
       "  0.10028935185185185,\n",
       "  0.10027324507389163,\n",
       "  0.10018043611793612,\n",
       "  0.10008808210784313,\n",
       "  0.10007258557457213,\n",
       "  0.10003810975609756,\n",
       "  0.09992776763990267,\n",
       "  0.10000758495145631,\n",
       "  0.09997351694915255,\n",
       "  0.09997735507246377,\n",
       "  0.09998117469879518,\n",
       "  0.10011643629807693,\n",
       "  0.09998875899280575,\n",
       "  0.1000299043062201,\n",
       "  0.10003356205250596,\n",
       "  0.10011160714285715,\n",
       "  0.0999665973871734,\n",
       "  0.10013699644549763,\n",
       "  0.10014036643026004,\n",
       "  0.10014372051886793,\n",
       "  0.10012867647058823,\n",
       "  0.10011370305164319,\n",
       "  0.10019028103044496,\n",
       "  0.1002665011682243,\n",
       "  0.10021488927738928,\n",
       "  0.10025436046511628,\n",
       "  0.10014863689095127,\n",
       "  0.10016999421296297,\n",
       "  0.10017321016166282,\n",
       "  0.10015841013824885,\n",
       "  0.10017959770114943,\n",
       "  0.1002006880733945,\n",
       "  0.10016804919908467,\n",
       "  0.10009988584474885,\n",
       "  0.10010321753986333,\n",
       "  0.10012428977272728,\n",
       "  0.10010983560090703,\n",
       "  0.10009544683257919,\n",
       "  0.10015166478555304,\n",
       "  0.10017243806306306,\n",
       "  0.10012289325842696,\n",
       "  0.10005605381165919,\n",
       "  0.10012933445190157,\n",
       "  0.10009765625,\n",
       "  0.10013571826280623,\n",
       "  0.10015625,\n",
       "  0.1001074002217295,\n",
       "  0.10012790376106195,\n",
       "  0.10007933222958057,\n",
       "  0.09999655837004405,\n",
       "  0.09998282967032968,\n",
       "  0.09993489583333333,\n",
       "  0.10000683807439825,\n",
       "  0.09995906113537117,\n",
       "  0.09987745098039216,\n",
       "  0.09988111413043478,\n",
       "  0.09981697396963124,\n",
       "  0.09982075216450216,\n",
       "  0.09979076673866091,\n",
       "  0.09981142241379311,\n",
       "  0.09974798387096774,\n",
       "  0.09968481759656653,\n",
       "  0.09968883832976445,\n",
       "  0.09975961538461539,\n",
       "  0.0998],\n",
       " [0.0546875,\n",
       "  0.0859375,\n",
       "  0.09895833333333333,\n",
       "  0.09765625,\n",
       "  0.0953125,\n",
       "  0.09244791666666667,\n",
       "  0.09486607142857142,\n",
       "  0.09375,\n",
       "  0.09461805555555555,\n",
       "  0.09609375,\n",
       "  0.09730113636363637,\n",
       "  0.095703125,\n",
       "  0.09375,\n",
       "  0.09319196428571429,\n",
       "  0.0953125,\n",
       "  0.09619140625,\n",
       "  0.0974264705882353,\n",
       "  0.10112847222222222,\n",
       "  0.10361842105263158,\n",
       "  0.103515625,\n",
       "  0.1052827380952381,\n",
       "  0.10582386363636363,\n",
       "  0.10394021739130435,\n",
       "  0.1025390625,\n",
       "  0.1025,\n",
       "  0.1015625,\n",
       "  0.1015625,\n",
       "  0.10128348214285714,\n",
       "  0.10210129310344827,\n",
       "  0.10260416666666666,\n",
       "  0.10433467741935484,\n",
       "  0.10400390625,\n",
       "  0.10369318181818182,\n",
       "  0.10386029411764706,\n",
       "  0.103125,\n",
       "  0.10221354166666667,\n",
       "  0.10409628378378379,\n",
       "  0.10485197368421052,\n",
       "  0.10376602564102565,\n",
       "  0.102734375,\n",
       "  0.10289634146341463,\n",
       "  0.10212053571428571,\n",
       "  0.10247093023255814,\n",
       "  0.10387073863636363,\n",
       "  0.10486111111111111,\n",
       "  0.10394021739130435,\n",
       "  0.10355718085106383,\n",
       "  0.10302734375,\n",
       "  0.10299744897959184,\n",
       "  0.10328125,\n",
       "  0.10370710784313726,\n",
       "  0.10381610576923077,\n",
       "  0.10318396226415094,\n",
       "  0.10286458333333333,\n",
       "  0.103125,\n",
       "  0.1025390625,\n",
       "  0.10238486842105263,\n",
       "  0.10237068965517242,\n",
       "  0.1016949152542373,\n",
       "  0.101171875,\n",
       "  0.1019467213114754,\n",
       "  0.1015625,\n",
       "  0.10119047619047619,\n",
       "  0.1019287109375,\n",
       "  0.10144230769230769,\n",
       "  0.10132575757575757,\n",
       "  0.10121268656716417,\n",
       "  0.10110294117647059,\n",
       "  0.10110960144927536,\n",
       "  0.10133928571428572,\n",
       "  0.10123239436619719,\n",
       "  0.10101996527777778,\n",
       "  0.10102739726027397,\n",
       "  0.10166807432432433,\n",
       "  0.10135416666666666,\n",
       "  0.10115131578947369,\n",
       "  0.10115665584415584,\n",
       "  0.10126201923076923,\n",
       "  0.10126582278481013,\n",
       "  0.1015625,\n",
       "  0.10185185185185185,\n",
       "  0.1016577743902439,\n",
       "  0.1013742469879518,\n",
       "  0.10100446428571429,\n",
       "  0.10165441176470588,\n",
       "  0.10165334302325581,\n",
       "  0.10165229885057471,\n",
       "  0.10191761363636363,\n",
       "  0.10235252808988764,\n",
       "  0.10234375,\n",
       "  0.10224931318681318,\n",
       "  0.10198709239130435,\n",
       "  0.10189852150537634,\n",
       "  0.10231050531914894,\n",
       "  0.10189144736842105,\n",
       "  0.102294921875,\n",
       "  0.10252899484536082,\n",
       "  0.10275829081632654,\n",
       "  0.1025094696969697,\n",
       "  0.102421875,\n",
       "  0.10225866336633663,\n",
       "  0.10202205882352941,\n",
       "  0.10239684466019418,\n",
       "  0.10223858173076923,\n",
       "  0.10208333333333333,\n",
       "  0.10200471698113207,\n",
       "  0.1021466121495327,\n",
       "  0.10192418981481481,\n",
       "  0.10192087155963303,\n",
       "  0.10191761363636363,\n",
       "  0.10212556306306306,\n",
       "  0.10219029017857142,\n",
       "  0.10225387168141593,\n",
       "  0.10211074561403509,\n",
       "  0.10210597826086956,\n",
       "  0.10230334051724138,\n",
       "  0.10249732905982906,\n",
       "  0.10268802966101695,\n",
       "  0.10267857142857142,\n",
       "  0.10266927083333334,\n",
       "  0.10240185950413223,\n",
       "  0.10245901639344263,\n",
       "  0.10200711382113821,\n",
       "  0.10175151209677419,\n",
       "  0.1015625,\n",
       "  0.10131448412698413,\n",
       "  0.10131643700787402,\n",
       "  0.10107421875,\n",
       "  0.10113856589147287,\n",
       "  0.10126201923076923,\n",
       "  0.10126431297709923,\n",
       "  0.10144412878787878,\n",
       "  0.10173872180451128,\n",
       "  0.10202891791044776,\n",
       "  0.10179398148148149,\n",
       "  0.10173483455882353,\n",
       "  0.10173357664233576,\n",
       "  0.10201539855072464,\n",
       "  0.10184352517985612,\n",
       "  0.10150669642857142,\n",
       "  0.1015625,\n",
       "  0.10183758802816902,\n",
       "  0.10178103146853147,\n",
       "  0.10210503472222222,\n",
       "  0.1019396551724138,\n",
       "  0.1015625,\n",
       "  0.1016156462585034,\n",
       "  0.10150971283783784,\n",
       "  0.10145763422818792,\n",
       "  0.10151041666666667,\n",
       "  0.10125206953642384,\n",
       "  0.1010485197368421,\n",
       "  0.10110294117647059,\n",
       "  0.1010551948051948,\n",
       "  0.10075604838709677,\n",
       "  0.10081129807692307,\n",
       "  0.10096536624203821,\n",
       "  0.10067246835443038,\n",
       "  0.10067806603773585,\n",
       "  0.10048828125,\n",
       "  0.10044642857142858,\n",
       "  0.10054976851851852,\n",
       "  0.1006997699386503,\n",
       "  0.10080030487804878,\n",
       "  0.10089962121212122,\n",
       "  0.10085655120481928,\n",
       "  0.10067365269461077,\n",
       "  0.10091145833333333,\n",
       "  0.10091531065088757,\n",
       "  0.10105698529411765,\n",
       "  0.10105994152046784,\n",
       "  0.10074491279069768,\n",
       "  0.10079479768786127,\n",
       "  0.1011584051724138,\n",
       "  0.10102678571428571,\n",
       "  0.10107421875,\n",
       "  0.10103283898305085,\n",
       "  0.10129915730337079,\n",
       "  0.10143156424581005,\n",
       "  0.10143229166666666,\n",
       "  0.10138984806629835,\n",
       "  0.1013907967032967,\n",
       "  0.10134904371584699,\n",
       "  0.10118036684782608,\n",
       "  0.10130912162162162,\n",
       "  0.10105846774193548,\n",
       "  0.1011447192513369,\n",
       "  0.10135472074468085,\n",
       "  0.1015625,\n",
       "  0.10148026315789474,\n",
       "  0.10143979057591623,\n",
       "  0.1014404296875,\n",
       "  0.101360103626943,\n",
       "  0.10124033505154639,\n",
       "  0.10136217948717949,\n",
       "  0.10136320153061225,\n",
       "  0.10144352791878172,\n",
       "  0.10144412878787878,\n",
       "  0.1014839824120603,\n",
       "  0.1015234375,\n",
       "  0.1017568407960199,\n",
       "  0.10175587871287128,\n",
       "  0.10190886699507389,\n",
       "  0.10202205882352941,\n",
       "  0.10213414634146341,\n",
       "  0.10216929611650485,\n",
       "  0.10197765700483091,\n",
       "  0.10182542067307693,\n",
       "  0.10182416267942583,\n",
       "  0.10200892857142857,\n",
       "  0.10211789099526067,\n",
       "  0.1022995283018868,\n",
       "  0.10244278169014084,\n",
       "  0.10243866822429906,\n",
       "  0.10254360465116279,\n",
       "  0.10271990740740741,\n",
       "  0.10275057603686635,\n",
       "  0.1027809633027523,\n",
       "  0.10291809360730593,\n",
       "  0.102734375,\n",
       "  0.10297652714932126,\n",
       "  0.10282939189189189,\n",
       "  0.10275364349775785,\n",
       "  0.10285295758928571,\n",
       "  0.10274305555555556,\n",
       "  0.10270326327433628,\n",
       "  0.10283590308370044,\n",
       "  0.10289884868421052,\n",
       "  0.10289301310043668,\n",
       "  0.10271739130434783,\n",
       "  0.10264475108225109,\n",
       "  0.1025390625,\n",
       "  0.10243428111587982,\n",
       "  0.1023971688034188,\n",
       "  0.10249335106382979,\n",
       "  0.1024563029661017,\n",
       "  0.10232067510548523,\n",
       "  0.10218618697478991,\n",
       "  0.10257583682008369,\n",
       "  0.10247395833333334,\n",
       "  0.10272951244813278,\n",
       "  0.10278925619834711,\n",
       "  0.10291280864197531,\n",
       "  0.10277920081967214,\n",
       "  0.10290178571428571,\n",
       "  0.10267403455284553,\n",
       "  0.1027327935222672,\n",
       "  0.10285408266129033,\n",
       "  0.10297439759036145,\n",
       "  0.1030625,\n",
       "  0.10308764940239044,\n",
       "  0.10298859126984126,\n",
       "  0.10298295454545454,\n",
       "  0.10300812007874016,\n",
       "  0.10303308823529411,\n",
       "  0.10308837890625,\n",
       "  0.10299124513618677,\n",
       "  0.10298570736434108,\n",
       "  0.10304054054054054,\n",
       "  0.10294471153846153,\n",
       "  0.10281968390804598,\n",
       "  0.10278506679389313,\n",
       "  0.10269130228136882,\n",
       "  0.10280539772727272,\n",
       "  0.10253537735849057,\n",
       "  0.10232612781954888,\n",
       "  0.10255735018726592,\n",
       "  0.10246618470149253,\n",
       "  0.10263708178438662,\n",
       "  0.10277777777777777,\n",
       "  0.10280212177121771,\n",
       "  0.1027688419117647,\n",
       "  0.10276442307692307,\n",
       "  0.102788549270073,\n",
       "  0.1028125,\n",
       "  0.1026947463768116,\n",
       "  0.10274706678700361,\n",
       "  0.10279901079136691,\n",
       "  0.1028225806451613,\n",
       "  0.10279017857142857,\n",
       "  0.10278580960854093,\n",
       "  0.10283687943262411,\n",
       "  0.10283237632508833,\n",
       "  0.10280039612676056,\n",
       "  0.10290570175438596,\n",
       "  0.10290100524475525,\n",
       "  0.10297800522648083,\n",
       "  0.1028103298611111,\n",
       "  0.10294117647058823,\n",
       "  0.10285560344827586,\n",
       "  0.10285115979381443,\n",
       "  0.10290025684931507,\n",
       "  0.10294901877133106,\n",
       "  0.10286458333333333,\n",
       "  0.10280720338983051,\n",
       "  0.10288217905405406,\n",
       "  0.10266729797979798,\n",
       "  0.10261115771812081,\n",
       "  0.10255539297658862,\n",
       "  0.1025,\n",
       "  0.10241901993355482,\n",
       "  0.10220923013245033,\n",
       "  0.10228444719471948,\n",
       "  0.10199938322368421,\n",
       "  0.10199795081967213,\n",
       "  0.10202205882352941,\n",
       "  0.10204600977198697,\n",
       "  0.1019429788961039,\n",
       "  0.1019164644012945,\n",
       "  0.10183971774193548,\n",
       "  0.10188906752411575,\n",
       "  0.10176282051282051,\n",
       "  0.10171226038338659,\n",
       "  0.10171178343949044,\n",
       "  0.10163690476190476,\n",
       "  0.10161194620253164,\n",
       "  0.1015625,\n",
       "  0.1015625,\n",
       "  0.10170944357366771,\n",
       "  0.10166015625,\n",
       "  0.1015625,\n",
       "  0.10153823757763975,\n",
       "  0.1015141253869969,\n",
       "  0.10153838734567901,\n",
       "  0.10139423076923076,\n",
       "  0.1014426763803681,\n",
       "  0.10153860856269113,\n",
       "  0.10153868140243902,\n",
       "  0.10144376899696049,\n",
       "  0.10137310606060607,\n",
       "  0.10137367824773413,\n",
       "  0.10139777861445783,\n",
       "  0.1014451951951952,\n",
       "  0.10149232784431138,\n",
       "  0.10139925373134329,\n",
       "  0.1013764880952381,\n",
       "  0.10130749258160238,\n",
       "  0.10130824704142012,\n",
       "  0.1013089970501475,\n",
       "  0.1013327205882353,\n",
       "  0.10133339442815249,\n",
       "  0.1013797514619883,\n",
       "  0.10142583819241982,\n",
       "  0.10142623546511628,\n",
       "  0.10160778985507246,\n",
       "  0.10153992052023121,\n",
       "  0.10153998559077809,\n",
       "  0.10158494971264367,\n",
       "  0.10145057306590258,\n",
       "  0.10149553571428571,\n",
       "  0.10136217948717949,\n",
       "  0.10145152698863637,\n",
       "  0.10149610481586402,\n",
       "  0.10134180790960452,\n",
       "  0.10123239436619719,\n",
       "  0.10121137640449439,\n",
       "  0.10116859243697479,\n",
       "  0.10132245111731844,\n",
       "  0.101366643454039,\n",
       "  0.10138888888888889,\n",
       "  0.10138936980609418,\n",
       "  0.10138984806629835,\n",
       "  0.10145488980716254,\n",
       "  0.10143372252747253,\n",
       "  0.10136986301369863,\n",
       "  0.1013917349726776,\n",
       "  0.10143477520435967,\n",
       "  0.10143512228260869,\n",
       "  0.10135077913279132,\n",
       "  0.10145692567567567,\n",
       "  0.10143615229110513,\n",
       "  0.10141549059139784,\n",
       "  0.10133210455764075,\n",
       "  0.10129094251336898,\n",
       "  0.1013125,\n",
       "  0.10135472074468085,\n",
       "  0.10143816312997347,\n",
       "  0.10139715608465609,\n",
       "  0.10148004617414248,\n",
       "  0.10133634868421053,\n",
       "  0.10133694225721784,\n",
       "  0.10117392015706807,\n",
       "  0.101052545691906,\n",
       "  0.1009521484375,\n",
       "  0.1010551948051948,\n",
       "  0.10103626943005181,\n",
       "  0.10107800387596899,\n",
       "  0.10109938788659793,\n",
       "  0.10116082904884319,\n",
       "  0.10118189102564103,\n",
       "  0.1012028452685422,\n",
       "  0.10134327168367346,\n",
       "  0.10150286259541985,\n",
       "  0.10144352791878172,\n",
       "  0.10136471518987342,\n",
       "  0.10136521464646464,\n",
       "  0.10128699622166247,\n",
       "  0.1014054648241206,\n",
       "  0.10138627819548872,\n",
       "  0.10138671875,\n",
       "  0.10134819201995013,\n",
       "  0.10142646144278607,\n",
       "  0.10138802729528536,\n",
       "  0.10148514851485149,\n",
       "  0.10154320987654321,\n",
       "  0.10163947044334976,\n",
       "  0.10175445331695332,\n",
       "  0.10175398284313726,\n",
       "  0.1019445293398533,\n",
       "  0.10200076219512196,\n",
       "  0.10209473844282238,\n",
       "  0.10197967233009708,\n",
       "  0.10194082929782082,\n",
       "  0.10192104468599034,\n",
       "  0.10199548192771084,\n",
       "  0.1019756610576923,\n",
       "  0.10195593525179857,\n",
       "  0.10199237440191387,\n",
       "  0.10215915871121718,\n",
       "  0.10217633928571429,\n",
       "  0.10221199524940618,\n",
       "  0.10228450829383887,\n",
       "  0.10224586288416075,\n",
       "  0.10226267688679246,\n",
       "  0.10229779411764706,\n",
       "  0.1022593896713615,\n",
       "  0.10222116510538641,\n",
       "  0.10216486565420561,\n",
       "  0.10214525058275058,\n",
       "  0.10203488372093024,\n",
       "  0.1019612819025522,\n",
       "  0.10186993634259259,\n",
       "  0.10188726905311778,\n",
       "  0.10204853110599078,\n",
       "  0.10208333333333333,\n",
       "  0.10211797591743119,\n",
       "  0.10206307208237986,\n",
       "  0.1020619292237443,\n",
       "  0.1020251993166287,\n",
       "  0.10202414772727272,\n",
       "  0.10189909297052155,\n",
       "  0.10198670814479638,\n",
       "  0.10189757336343115,\n",
       "  0.10194960585585586,\n",
       "  0.10191362359550561,\n",
       "  0.10187780269058296,\n",
       "  0.10187709731543625,\n",
       "  0.10187639508928571,\n",
       "  0.1017712973273942,\n",
       "  0.10173611111111111,\n",
       "  0.1016664356984479,\n",
       "  0.101648921460177,\n",
       "  0.10159699227373069,\n",
       "  0.1015108755506608,\n",
       "  0.10154532967032967,\n",
       "  0.1015453673245614,\n",
       "  0.1015625,\n",
       "  0.10149426855895197,\n",
       "  0.10147739651416122,\n",
       "  0.10146059782608696,\n",
       "  0.10146081887201736,\n",
       "  0.10152867965367965,\n",
       "  0.10161312095032397,\n",
       "  0.10161301185344827,\n",
       "  0.10159610215053763,\n",
       "  0.10159603004291845,\n",
       "  0.10154577087794432,\n",
       "  0.10152911324786325,\n",
       "  0.1016]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 4.39207272e+02],\n",
       "       [2.00000000e+00, 8.80324958e+02],\n",
       "       [3.00000000e+00, 1.32315002e+03],\n",
       "       [4.00000000e+00, 1.76440199e+03],\n",
       "       [5.00000000e+00, 2.20326648e+03],\n",
       "       [6.00000000e+00, 2.64974354e+03],\n",
       "       [7.00000000e+00, 3.08497752e+03],\n",
       "       [8.00000000e+00, 3.51581531e+03],\n",
       "       [9.00000000e+00, 3.94306689e+03],\n",
       "       [1.00000000e+01, 4.36942677e+03]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list([5590, 9104, 8740, 9042, 8802, 8662, 8192, 8596, 8659, 8236, 8771, 8769, 8827, 8407, 8691, 8217, 8606, 8782, 9558, 10957, 8597, 8693, 8173, 8506, 9523, 9838, 8867, 8334, 8821, 8488, 8380, 8703, 9188, 9406, 8254, 8742, 8323, 8468, 8860, 9106, 9354, 8418, 8821, 8601, 8294, 8494, 9050, 9482, 10595, 9048, 9410, 8454, 8743, 9319, 9254, 8937, 8159, 8793, 9521, 10970, 9924, 9282, 10516, 10859, 9482, 9265, 9102, 8459, 8287, 8811, 9678, 9324, 9478, 8852, 9720, 9660, 9588, 9389, 11379, 10255, 8762, 8175, 8574, 9722, 8368, 8737, 9657, 8648, 8851, 8227, 8685, 8375, 9534, 9872, 9586, 9258, 9918, 9070, 10339, 8577, 8927, 8848, 9243, 9210, 8799, 8549, 8469, 9809, 10314, 9301, 8703, 8196, 9190, 8273, 8497, 8658, 9132, 8950, 10091, 8994, 8912, 8400, 8618, 8847, 8867, 8917, 9053, 8863, 8063, 8378, 10080, 9289, 9638, 9506, 9001, 8399, 8983, 13151, 10179, 10149, 9955, 9179, 8605, 8242, 8826, 8350, 8272, 8700, 9197, 8980, 9139, 8754, 10399, 9567, 9117, 10588, 10552, 10518, 9651, 9765, 11639, 10864, 9333, 10783, 11171, 11614, 8523, 14423, 10084, 11508, 10214, 10920, 11079, 12616, 15394, 14211, 12103, 11716, 10956, 10718, 11215, 10192, 13063, 11031, 13819, 16009, 15766, 13855, 13505, 10736, 10819, 9873, 11780, 15464, 15972, 15627, 15259, 13323, 11715, 12051, 14717, 16062, 14935, 12787, 14501, 10839, 10104, 10027, 9641, 9901, 11957, 13655, 11459, 10897, 9754, 12253, 10184, 11148, 10758, 10174, 10517, 9710, 10703, 10831, 10892, 11323, 10947, 9476, 9853, 14633, 13329, 12584, 12136, 10487, 10813, 8799, 11074, 10834, 9833, 11174, 13653, 11491, 12774, 9974, 9562, 10240, 9406, 10963, 12265, 15632, 15797, 9486, 9172, 11984, 11352, 10655, 14497, 9760, 11770, 9670, 8685, 8634, 10260, 10207, 10389, 8806, 10312, 10978, 10442, 10376, 14757, 13776, 10766, 12599, 10124, 9598, 9076, 9093, 8856, 8700, 9048, 9183, 9272, 9511, 8566, 9134, 10805, 9562, 9210, 8984, 9565, 9065, 8551, 8988, 10003, 10267, 13335, 9999, 9839, 13280, 9413, 10151, 12515, 11883, 11374, 12512, 9130, 10907, 8772, 9087, 9862, 10157, 9356, 8970, 12723, 16536, 13248, 12923, 9772, 8846, 10453, 9121, 12648, 13019, 9375, 9319, 9936, 9414, 9348, 9561, 9725, 9929, 9718, 9740, 11873, 9948, 9894, 9681, 9819, 10260, 9154, 9364, 9190, 9065, 9879, 12204, 10004, 9498, 9486, 9627, 8912, 9927, 9931, 9607, 9536, 10050, 9905, 9138, 9651, 9603, 9584, 8960, 9346, 8938, 10517, 10175, 9612, 9548, 9590, 10519, 9860, 8930, 9244, 9704, 9942, 11361, 9772, 8922, 10461, 9018, 9517, 9413, 9883, 9379, 9097, 9064, 9120, 8982, 9846, 9970, 9657, 9286, 9648, 9110, 8987, 9574, 10400, 9761, 9055, 9635, 10586, 9433, 9206, 9738, 10857, 10264, 9808, 9301, 9512, 9644, 9646, 9502, 9086, 9229, 8955, 9025, 9847, 8822, 12678, 10970, 11771, 11398, 11356, 11237, 11905, 11260, 11438, 11568, 11892, 11420, 11361, 13075])],\n",
       "       [list([11406, 11021, 9363, 8786, 9319, 9782, 9894, 9852, 10045, 9406, 8920, 9340, 9218, 10756, 9796, 9743, 9673, 9911, 8967, 9259, 9260, 9045, 9161, 10377, 10178, 10708, 12714, 11420, 10420, 12140, 11281, 9547, 9089, 9362, 10086, 9835, 10042, 10691, 9185, 9898, 9441, 11773, 11177, 10895, 9267, 11916, 12495, 12319, 10123, 9555, 12299, 15382, 13903, 14482, 10808, 11007, 10317, 8886, 9144, 13394, 13095, 12351, 9681, 9209, 8930, 10540, 12187, 9734, 9547, 9720, 9541, 9798, 9972, 10222, 9638, 9469, 10330, 9751, 9668, 9955, 10402, 9790, 9817, 9353, 10000, 10130, 9275, 9758, 11571, 12384, 10173, 9651, 10298, 9233, 10012, 9509, 9678, 9710, 9949, 9020, 9420, 8946, 9042, 9715, 9909, 9425, 8801, 9306, 9617, 9683, 9661, 9988, 9302, 9804, 9974, 10600, 8852, 9364, 10384, 10988, 9403, 9310, 8819, 8965, 9576, 9792, 9643, 8947, 9360, 8888, 9247, 9581, 9474, 9642, 9365, 9204, 10053, 9037, 8843, 9309, 9722, 9552, 9090, 9325, 12999, 10151, 11229, 10758, 12681, 11659, 12303, 11809, 12428, 10989, 11054, 9401, 9561, 9708, 9495, 8868, 9282, 9447, 9550, 9750, 8819, 8526, 8839, 9836, 9405, 8466, 8914, 10150, 12398, 9215, 9088, 10237, 11656, 12059, 11856, 11537, 9208, 10227, 9999, 8546, 9075, 9629, 15162, 17925, 12537, 9369, 9308, 9333, 9256, 9022, 9256, 8526, 8530, 9884, 9547, 11193, 13576, 11926, 9357, 9430, 8734, 9444, 8825, 10238, 10628, 10180, 9459, 9230, 8624, 9252, 8786, 9211, 9553, 9466, 9735, 9422, 9321, 9059, 8790, 9385, 9754, 9287, 9428, 9433, 9121, 9030, 9879, 9675, 9907, 9313, 9314, 9014, 9056, 11706, 9989, 9984, 9048, 9240, 9636, 10600, 9218, 10074, 9739, 9663, 9590, 9466, 8994, 9686, 9481, 9118, 9542, 11486, 9537, 9831, 9098, 9620, 9111, 9239, 9682, 9430, 9011, 9453, 9099, 11547, 10784, 9549, 9605, 9170, 9357, 9786, 8900, 9465, 9786, 9529, 9654, 8924, 10805, 10170, 8637, 9367, 9407, 10695, 10718, 8839, 10051, 8889, 8940, 9413, 9689, 9972, 9088, 9342, 9911, 10322, 9968, 9363, 9478, 9520, 9007, 9627, 8939, 9328, 10547, 9872, 9486, 9153, 9268, 9298, 10056, 9157, 9324, 9556, 8816, 9988, 9443, 11815, 9953, 9214, 9447, 9755, 9118, 8912, 11159, 9476, 10427, 9254, 9282, 9783, 9781, 9385, 9186, 9371, 9725, 9059, 10187, 9763, 9945, 9730, 9975, 9492, 9272, 9092, 9426, 8927, 9425, 9395, 9551, 9255, 9618, 9250, 9563, 9819, 11668, 10573, 9733, 9601, 9887, 9231, 9517, 9451, 9446, 9642, 9877, 9402, 9404, 9687, 9685, 9321, 9231, 9481, 9618, 9325, 9032, 9170, 9050, 10568, 10088, 10533, 9402, 9674, 9731, 11195, 11727, 12610, 10096, 12185, 11005, 9799, 9611, 9796, 10053, 9670, 9513, 9883, 14154, 9183, 9420, 14535, 9982, 13328, 11910, 11756, 13356, 9637, 9407, 9093, 9725, 8202, 9055, 9797, 9740, 12109, 15312, 16874, 9500, 11043, 11143, 11490, 13255, 13665, 13415, 11348, 11320, 11707, 11541, 11559, 11704, 11694, 11442, 10978])],\n",
       "       [list([9391, 9552, 9571, 9732, 9041, 8963, 9608, 9788, 11512, 11377, 10504, 9336, 9525, 9565, 9987, 9284, 9469, 9578, 9450, 8581, 9166, 9121, 9627, 8740, 9703, 9449, 9508, 9195, 8855, 9514, 8932, 8775, 9415, 10059, 9811, 9334, 8816, 9276, 11418, 9765, 10281, 9852, 9660, 8894, 9198, 8905, 9184, 9387, 9648, 9510, 8832, 9517, 9254, 9638, 9697, 10078, 9327, 8847, 9299, 9067, 9133, 9938, 9722, 10263, 8745, 9151, 9431, 9495, 11489, 10123, 9005, 9734, 8735, 9397, 9035, 9449, 9322, 9901, 9567, 9180, 8803, 11142, 9904, 9337, 9518, 9242, 9454, 8948, 8840, 9945, 9036, 9306, 10103, 9950, 9506, 9323, 9197, 11371, 9641, 10556, 9669, 9759, 9019, 9539, 9486, 8840, 9316, 9375, 9634, 9743, 10217, 9097, 9575, 9062, 9081, 9353, 9450, 9376, 9502, 9024, 9846, 9044, 9733, 11507, 11873, 12004, 9613, 11025, 9517, 9348, 9330, 9526, 9817, 9396, 9186, 10528, 9233, 9368, 9116, 9800, 9656, 11358, 9884, 9307, 9005, 9143, 8871, 9533, 10412, 9517, 9154, 9302, 9209, 9004, 10329, 9552, 10033, 10774, 9631, 9133, 8902, 9021, 9359, 9478, 9425, 8974, 9318, 9277, 9052, 9487, 9389, 10863, 12650, 11332, 11289, 9642, 9834, 9636, 12102, 11963, 10202, 10517, 11199, 11692, 12447, 11144, 13004, 10331, 10071, 8874, 9942, 10115, 9894, 12013, 9586, 9271, 11534, 8730, 10160, 8532, 9043, 9809, 8627, 9349, 8848, 8915, 9103, 8100, 8774, 8511, 8761, 9189, 9128, 8556, 8956, 8376, 11486, 9889, 8810, 9073, 8462, 8679, 8480, 9270, 9857, 9890, 8788, 8852, 10055, 11219, 9067, 8565, 9792, 9790, 9438, 10425, 8336, 8620, 9104, 9089, 9586, 9413, 9245, 8747, 8715, 9389, 11213, 10783, 9787, 8510, 10733, 9257, 9426, 9659, 8648, 9575, 9305, 9223, 9590, 9348, 10833, 9546, 8589, 9756, 9111, 8542, 8786, 9262, 10208, 9207, 9008, 9870, 8684, 8847, 9685, 11293, 8757, 10449, 9563, 8807, 9072, 9028, 9309, 9753, 9099, 9039, 9125, 8740, 8535, 8976, 10726, 9256, 8393, 9071, 8734, 8588, 8994, 9481, 9936, 8579, 9846, 8569, 9031, 9862, 8888, 11606, 9412, 9340, 8984, 9509, 9604, 9550, 9808, 8690, 8840, 8866, 8636, 10065, 9633, 11171, 12783, 12471, 12293, 11898, 13570, 14784, 12565, 15971, 13306, 12391, 9081, 11471, 12738, 10177, 10235, 11095, 10527, 11527, 10976, 10528, 11344, 9781, 9993, 9903, 10276, 15398, 16194, 13395, 13238, 12367, 11486, 12199, 10115, 10447, 13395, 13152, 13354, 12553, 13004, 12361, 15443, 13627, 10232, 14327, 15569, 11797, 12823, 10850, 10738, 10127, 10752, 9752, 10379, 11483, 10110, 11092, 9035, 9633, 10124, 9310, 9252, 9192, 8792, 8832, 8576, 8966, 9326, 9600, 9097, 9073, 9072, 8883, 9885, 9200, 11448, 9587, 8562, 8754, 8820, 9110, 9075, 9252, 9306, 8456, 8916, 9263, 8428, 9259, 12233, 9295, 8976, 9227, 8938, 10698, 9299, 8831, 10027, 9816, 8671, 9373, 10169, 12586, 11576, 12455, 12587, 12600, 13350, 12897, 12199, 13914, 13377, 14393, 14758, 13196, 12513, 9525])],\n",
       "       [list([11305, 12777, 11558, 10954, 14632, 11982, 11680, 9602, 10558, 13031, 12976, 11575, 11861, 14324, 12158, 11082, 15975, 13418, 15153, 14215, 10903, 12981, 13784, 13130, 14356, 15251, 12829, 12640, 9430, 13402, 12968, 13813, 12077, 10369, 9837, 12030, 10995, 11807, 12756, 13059, 13035, 12733, 9248, 11928, 10987, 14734, 15336, 11439, 14009, 11598, 12338, 10255, 9548, 10113, 8535, 8811, 9378, 9520, 8855, 8733, 8835, 8817, 8977, 8744, 9272, 9115, 8813, 8903, 8370, 8791, 9007, 9415, 8796, 9102, 8867, 11298, 9624, 10073, 9544, 9276, 8949, 9067, 8264, 9172, 9045, 8865, 8430, 8674, 9468, 9017, 9077, 8673, 9070, 8920, 8346, 8933, 8575, 9566, 9396, 8608, 8997, 8590, 8848, 9237, 10075, 14438, 10898, 11466, 11078, 13272, 14077, 10355, 13675, 11375, 12243, 11939, 11883, 12265, 11786, 11515, 10606, 10668, 10683, 10724, 8547, 10162, 11448, 9336, 9465, 11776, 10821, 10222, 13111, 12600, 14214, 15140, 14307, 12400, 12308, 11737, 12115, 10588, 12249, 10096, 11844, 11589, 12151, 11391, 12103, 11631, 12609, 10958, 11695, 11619, 12129, 12960, 11638, 11031, 9177, 9554, 9061, 8819, 8599, 9324, 10041, 11243, 10101, 8689, 8970, 8868, 8907, 9295, 9214, 8416, 10569, 10553, 12879, 10644, 11015, 10131, 11960, 14251, 10090, 9455, 11057, 9008, 9258, 9635, 9000, 9325, 9405, 9588, 10126, 9150, 10792, 9885, 9260, 8475, 11223, 10399, 9653, 9148, 9184, 9957, 13662, 11221, 9641, 9792, 8523, 10031, 9875, 9385, 10614, 10126, 11483, 11587, 9850, 9160, 10309, 9657, 10148, 10126, 9663, 12000, 14286, 11036, 9244, 9140, 9625, 9101, 8800, 9123, 9151, 9601, 9134, 9163, 8525, 8960, 8813, 9509, 9356, 9523, 9997, 9104, 9214, 8997, 12090, 11187, 10106, 10724, 10626, 9242, 12645, 12525, 12134, 10479, 9310, 10575, 9780, 10177, 10934, 10251, 9079, 8668, 9592, 9616, 11495, 14603, 11197, 16117, 12174, 10375, 9444, 11079, 14535, 13774, 12843, 11307, 12539, 10950, 10219, 9310, 8785, 11145, 9635, 9792, 8377, 9654, 9495, 9661, 9191, 9207, 8236, 9478, 9239, 8973, 9521, 9062, 8898, 9129, 8355, 9123, 8966, 11717, 11645, 12688, 9558, 11265, 12352, 9356, 8684, 9102, 8967, 10967, 10153, 9021, 8724, 8562, 9081, 8397, 9089, 9403, 8769, 9377, 9059, 8976, 8404, 8701, 9006, 8669, 8722, 8829, 8369, 8512, 8625, 8419, 9327, 8752, 8830, 9255, 9009, 8827, 9790, 10151, 9603, 9178, 8042, 8709, 8995, 8208, 8955, 9261, 8623, 8661, 8946, 9207, 9169, 8514, 12810, 9054, 8585, 8602, 8823, 8425, 8673, 8407, 8342, 8838, 9572, 10095, 10620, 9926, 10934, 9149, 11003, 10052, 10280, 9905, 8851, 9024, 9312, 10016, 9333, 9217, 9461, 9535, 9630, 10404, 9869, 10774, 9589, 11003, 9502, 9583, 9140, 8903, 9855, 10210, 9012, 8919, 9181, 9196, 11107, 9835, 9332, 9365, 9582, 9145, 10007, 11439, 9984, 9268, 9091, 9295, 9062, 8978, 8224, 9374, 8740, 9112, 9500, 13126, 12337, 10900, 10964, 10865, 10957, 11747, 11271, 11895, 11889, 12030, 12628, 12813, 11056])],\n",
       "       [list([11126, 9387, 9789, 8987, 9616, 9583, 9546, 9064, 9511, 10525, 9724, 9290, 9693, 8595, 9120, 9711, 9170, 9038, 9070, 9862, 10712, 8951, 9618, 9128, 11141, 10572, 11305, 10532, 9811, 8986, 10198, 9376, 8929, 8883, 9345, 9432, 9073, 9306, 8584, 8954, 9301, 9287, 10841, 9474, 9242, 10080, 10093, 9370, 9208, 10180, 11456, 9512, 8777, 9920, 11629, 9417, 9312, 10471, 8945, 8979, 8306, 9146, 9087, 12265, 12798, 12510, 10273, 10819, 12212, 10864, 13866, 9514, 13248, 16363, 9446, 10454, 9310, 9489, 9133, 9530, 9113, 9609, 9817, 10371, 11738, 11198, 8516, 8976, 9392, 8683, 8910, 9527, 9429, 9461, 12795, 10490, 12418, 11038, 10232, 9828, 8948, 8804, 9382, 9150, 10764, 8515, 8769, 8522, 8917, 9111, 8989, 8378, 8757, 10883, 9201, 9580, 8498, 9010, 8650, 9128, 8994, 8994, 8387, 8967, 8561, 10388, 9298, 8594, 8848, 8873, 9134, 8948, 8656, 8754, 8751, 8993, 9494, 8493, 8676, 8378, 9063, 9914, 9342, 11247, 9742, 9164, 9523, 9731, 9194, 8832, 9351, 8758, 11132, 9248, 8956, 8547, 9011, 9720, 9463, 9080, 8854, 11662, 11459, 10840, 9514, 11227, 10701, 9584, 10419, 10153, 10410, 11168, 10015, 12448, 9846, 9117, 9281, 9429, 9071, 9432, 9120, 9414, 9374, 9219, 9029, 9509, 9723, 9204, 9843, 8893, 9684, 9049, 9011, 9344, 9487, 11137, 9553, 9166, 9419, 9208, 9173, 9540, 12049, 9773, 9184, 9676, 10083, 9836, 9316, 9473, 9591, 10893, 10234, 9910, 9343, 9935, 9459, 9752, 11049, 14368, 13903, 16523, 11157, 10158, 9193, 10026, 9410, 8717, 9203, 8644, 9172, 9278, 12086, 10194, 9278, 9494, 10111, 9641, 10602, 10122, 10282, 9032, 9082, 9038, 9028, 9201, 9688, 12514, 11326, 10719, 13033, 10037, 9384, 9083, 8993, 9336, 9841, 9521, 8528, 10059, 10587, 11074, 11535, 10058, 10007, 11100, 10850, 11569, 9497, 11256, 9427, 9100, 10933, 14085, 10716, 12266, 12289, 10845, 10732, 9230, 9706, 10334, 9613, 11433, 11100, 9816, 9288, 9585, 9860, 9517, 9799, 11526, 10173, 11323, 11150, 10305, 9387, 9822, 10057, 11113, 9809, 8419, 8712, 9209, 9293, 10776, 9048, 8760, 8943, 8990, 9013, 9225, 8984, 9087, 8979, 8838, 9320, 9328, 8812, 8832, 8671, 11313, 9887, 8705, 9099, 8749, 9003, 9073, 9346, 8384, 9103, 8586, 9112, 9164, 8609, 8786, 8644, 9434, 9176, 8779, 8760, 10659, 10299, 10605, 9719, 10353, 10485, 10623, 10169, 10124, 10442, 11498, 10474, 9013, 9471, 9721, 9624, 9847, 10094, 10510, 12375, 16836, 12630, 9031, 9242, 9294, 13581, 16635, 17160, 14266, 10608, 10645, 10625, 11368, 10129, 10267, 10213, 9577, 9671, 10124, 11653, 11046, 11202, 9954, 10106, 9372, 10886, 9414, 8804, 9335, 9548, 9536, 9706, 8811, 9368, 9014, 8979, 9855, 9527, 9703, 8900, 9130, 9113, 9868, 9419, 9486, 8883, 8846, 9410, 8976, 11173, 10202, 9624, 9444, 8729, 9000, 8839, 10187, 13402, 11709, 11532, 11877, 11563, 11722, 11564, 11766, 11901, 11938, 11814, 11856, 11570, 11310])],\n",
       "       [list([11483, 10483, 9580, 9512, 9510, 11097, 10726, 9934, 8745, 8907, 8975, 8353, 8747, 9154, 9266, 9539, 8539, 8999, 8217, 9109, 9453, 9403, 8706, 8887, 9312, 8770, 9208, 9327, 9099, 8630, 8970, 8332, 9396, 9493, 10786, 11820, 12124, 11655, 10470, 11168, 11129, 11553, 10882, 16364, 14495, 10816, 10119, 10664, 14500, 15350, 9177, 9196, 8591, 9143, 8436, 9372, 9915, 12239, 11226, 10276, 9859, 9568, 8422, 11156, 8636, 10800, 9933, 9225, 8987, 9555, 9826, 9030, 9200, 13736, 16703, 16594, 15096, 13298, 11333, 10795, 10312, 10433, 12328, 10186, 8752, 11782, 11671, 11066, 10249, 9892, 9449, 8734, 9425, 9148, 11147, 11687, 10124, 8709, 9575, 10063, 10397, 9669, 9016, 9361, 8981, 8650, 8928, 9886, 10356, 8996, 10025, 9166, 9355, 9250, 8738, 8734, 8865, 9748, 9989, 9631, 9050, 9652, 9536, 9128, 12287, 10283, 10616, 8822, 9546, 11803, 12077, 9770, 10184, 10853, 10306, 11228, 10037, 12136, 9874, 9161, 9248, 8430, 9633, 9520, 10404, 10566, 11054, 12973, 10415, 10982, 10259, 11677, 10600, 10708, 12065, 10730, 12025, 13206, 12776, 14509, 9645, 10009, 9698, 10052, 8805, 10117, 10377, 9154, 8926, 10032, 11430, 8856, 9040, 8884, 8910, 9026, 8894, 8905, 9248, 10277, 9224, 8459, 8561, 9592, 10925, 9726, 9473, 8884, 9089, 9067, 10041, 9711, 9458, 9749, 9462, 9820, 8847, 8576, 9043, 10329, 10031, 8885, 8907, 9498, 9128, 9604, 9107, 10536, 8920, 9109, 8712, 8750, 9074, 10561, 9705, 9735, 9082, 8781, 8491, 9143, 8455, 8928, 8643, 9357, 9277, 8880, 9737, 8826, 8755, 8856, 9774, 9174, 8657, 9465, 11825, 9653, 9645, 9422, 10330, 11218, 10534, 10388, 11815, 16422, 11513, 11670, 13339, 12245, 11856, 12045, 11750, 9211, 10276, 9552, 9670, 11517, 9856, 9628, 9611, 13134, 12072, 15062, 10273, 12426, 11314, 12471, 11074, 11941, 11544, 12338, 10644, 12485, 12369, 14862, 11720, 9395, 9985, 10848, 10971, 11403, 11015, 10938, 10536, 10640, 10485, 9059, 10176, 9555, 8335, 8745, 9440, 8911, 8802, 9175, 11380, 11312, 9235, 9044, 10444, 9255, 10608, 10832, 11473, 11159, 10610, 9158, 9329, 10408, 9644, 9237, 9473, 8942, 8391, 8529, 9047, 9188, 8815, 8291, 10292, 9545, 8440, 8563, 9222, 8833, 8787, 8444, 10143, 9157, 9334, 9551, 9220, 9138, 12133, 9526, 9594, 8731, 8672, 10412, 9275, 10233, 9343, 8794, 8755, 9464, 9367, 8453, 9029, 9751, 10697, 10913, 10451, 10994, 9863, 11500, 11222, 12009, 9896, 11247, 11409, 9427, 8558, 11250, 10774, 9353, 9294, 10012, 9487, 8696, 9029, 9480, 8688, 9375, 9398, 10137, 9433, 11430, 11467, 9498, 8981, 10538, 11799, 10880, 12526, 12753, 10868, 12758, 11358, 11788, 9478, 13252, 11073, 13738, 12522, 12519, 10639, 8947, 9237, 9277, 9148, 8807, 8436, 9137, 9156, 8995, 8527, 12803, 10331, 8823, 11914, 10951, 9319, 8687, 9178, 9085, 9449, 9776, 8696, 8427, 8554, 8623, 8767, 11185, 9447, 8742, 7093, 12045, 12243, 11215, 11048, 11788, 10803, 11123, 11206, 11036, 10961, 11035, 11531, 11011, 10862])],\n",
       "       [list([11582, 8435, 8748, 9175, 8296, 8235, 8302, 8810, 8870, 11780, 8786, 8991, 8095, 8590, 8886, 8884, 8830, 8074, 9074, 9104, 8761, 10344, 9859, 9350, 9487, 14022, 11839, 9588, 8867, 8910, 8626, 9234, 8484, 8395, 9192, 9152, 8771, 8505, 8854, 10597, 8998, 8766, 9148, 8843, 8466, 8672, 8478, 8144, 8693, 9423, 9421, 8317, 8880, 8707, 8552, 8497, 9177, 9056, 9135, 9969, 9056, 8480, 9245, 11206, 11788, 9380, 11388, 12097, 12959, 14076, 12206, 11607, 9464, 9428, 9528, 9491, 9091, 9191, 8895, 9166, 9448, 9155, 8654, 9107, 8945, 9154, 10937, 9419, 8927, 8899, 9058, 8683, 9296, 9223, 8862, 9463, 8551, 8773, 12377, 10785, 8858, 8720, 8396, 8175, 8584, 8171, 8968, 8584, 8636, 8707, 8126, 8216, 8659, 8072, 8395, 9017, 8860, 8933, 9088, 8515, 8486, 7976, 8879, 8513, 8916, 8587, 8472, 9525, 10400, 8584, 8859, 8720, 8958, 8650, 8317, 8636, 8584, 9010, 10119, 11373, 13138, 11253, 8857, 8623, 8752, 8334, 8119, 8790, 8939, 9458, 8538, 9597, 8244, 8050, 8632, 9110, 8857, 10752, 8105, 9102, 9237, 8499, 8198, 8601, 8881, 8824, 8473, 8753, 9005, 8403, 8711, 8772, 8679, 8227, 9252, 8654, 7928, 8882, 9314, 8783, 8536, 8152, 8823, 8143, 8152, 8791, 8691, 11049, 8794, 8594, 8287, 8760, 8798, 8783, 8322, 8622, 8441, 8254, 8824, 8752, 8560, 8427, 8428, 7954, 9420, 8865, 8690, 8128, 8678, 8385, 8653, 9982, 8741, 8238, 8443, 8371, 9099, 9572, 9522, 8742, 8111, 8362, 8685, 8530, 7938, 8656, 8627, 8755, 8342, 8409, 8578, 8086, 9200, 8859, 8730, 8486, 8735, 8295, 7961, 8631, 9072, 8668, 8295, 8575, 8450, 7940, 10946, 9320, 9150, 8020, 8345, 8902, 8140, 8709, 8696, 8712, 8078, 8608, 8467, 8009, 8751, 8696, 8840, 8134, 8600, 8587, 8068, 8549, 8736, 8781, 8009, 8499, 8078, 8168, 10260, 9002, 10818, 8627, 9214, 8448, 8016, 8686, 8809, 8542, 9014, 8593, 8228, 8037, 9448, 8693, 8531, 8209, 8581, 8487, 8780, 8797, 8841, 8382, 8912, 8223, 8139, 8671, 8809, 8715, 8872, 10044, 8762, 8746, 8693, 8924, 8626, 8103, 10205, 9716, 8586, 8599, 8746, 8528, 8044, 8607, 8220, 8008, 9044, 8890, 8768, 8165, 8230, 8458, 7886, 9168, 8874, 8747, 7974, 8649, 8113, 10413, 9318, 9054, 8918, 8099, 8528, 7969, 8258, 8690, 8929, 8840, 8012, 8515, 8189, 7887, 8548, 8732, 8883, 8402, 8657, 8280, 8278, 8677, 8729, 8730, 8038, 8744, 8104, 8295, 10064, 9851, 9397, 7943, 8602, 8131, 8480, 9658, 8468, 8561, 8392, 8660, 8487, 8603, 8271, 8657, 8669, 8748, 8740, 8137, 8023, 8661, 8785, 9194, 8218, 8559, 8177, 8172, 8854, 9206, 11562, 9193, 8944, 8108, 8731, 8810, 8758, 9167, 8101, 8545, 8108, 8186, 8443, 8697, 8670, 7881, 8729, 8241, 7869, 9478, 13215, 10643, 10792, 10800, 10865, 10715, 10800, 10896, 11006, 10925, 13030, 11491, 10696, 9677])],\n",
       "       [list([8736, 8193, 8080, 8715, 8300, 8511, 8718, 8628, 8818, 8371, 8642, 8423, 8556, 9111, 8916, 8872, 9065, 8726, 8642, 8256, 8903, 8871, 8903, 8811, 10551, 9704, 8285, 8800, 8881, 8876, 8529, 8404, 8899, 8117, 8695, 8900, 8715, 8631, 8267, 9159, 8192, 9396, 10791, 10778, 9412, 10865, 9794, 9123, 9893, 8849, 9222, 8882, 8561, 10848, 11817, 10482, 9157, 9781, 9101, 8537, 9226, 9541, 8871, 11599, 10989, 9384, 11769, 10486, 11397, 9110, 9512, 8762, 9198, 12074, 11313, 10035, 10696, 9979, 8802, 9011, 8672, 9088, 9548, 12186, 9886, 9353, 8438, 8155, 8851, 8974, 8682, 8550, 9879, 9012, 10454, 8762, 8927, 8998, 9454, 8198, 8655, 8734, 8038, 9343, 8847, 9871, 10101, 9216, 8542, 8851, 9023, 8522, 9160, 11363, 9945, 8438, 8741, 8175, 9001, 10095, 14125, 13119, 11880, 11831, 11520, 10499, 10200, 9249, 8563, 8868, 9221, 8982, 8515, 9386, 10019, 11107, 10790, 9374, 8789, 8512, 8763, 8726, 11676, 12219, 12776, 10713, 8294, 8750, 8040, 9331, 9374, 8961, 9657, 8616, 8141, 8266, 9008, 9325, 8699, 8312, 8589, 8474, 8491, 8911, 8759, 8710, 8133, 9022, 7999, 8899, 8820, 8987, 10626, 9795, 8775, 8463, 8895, 9429, 9237, 8071, 8546, 8116, 8541, 8817, 8810, 8646, 8363, 8444, 8089, 8863, 9488, 10949, 12067, 7537, 8144, 9666, 11358, 7979, 8734, 9405, 8887, 8228, 10815, 9083, 8865, 10156, 8762, 8810, 8694, 8667, 8320, 8229, 8931, 16737, 14747, 14535, 14537, 14685, 15024, 15209, 14988, 14226, 14785, 13880, 14355, 14512, 14937, 13982, 10772, 9969, 8200, 10355, 9927, 9486, 8689, 8759, 8290, 8515, 8443, 9339, 8886, 8248, 8725, 8485, 8725, 9014, 8739, 8675, 8720, 8761, 8448, 8723, 9587, 8687, 8451, 8683, 8586, 9006, 9045, 8631, 8624, 11194, 8773, 9124, 8842, 9097, 8716, 8368, 8627, 9340, 8995, 8053, 8620, 8430, 8493, 9020, 8881, 8665, 8925, 8604, 8265, 9229, 8819, 8859, 8782, 8338, 8393, 9307, 9043, 8568, 9448, 10064, 8671, 8816, 8941, 9136, 8257, 8671, 8176, 8817, 9100, 8766, 8186, 8834, 8467, 8382, 8931, 8665, 8897, 8559, 8524, 8119, 8688, 9330, 8805, 8239, 8725, 8686, 8335, 9160, 11068, 9003, 9054, 8697, 8442, 8815, 9668, 8929, 8174, 8729, 8261, 8823, 8920, 8871, 8420, 8707, 8288, 8449, 9444, 9100, 8493, 9031, 8238, 8134, 8800, 8932, 8776, 8317, 8624, 8106, 10475, 9594, 8952, 8776, 8365, 8578, 8646, 8936, 8902, 8837, 8549, 8430, 8267, 8906, 9040, 8636, 8456, 8587, 8344, 9389, 8885, 8502, 8653, 8355, 8376, 9207, 8824, 8597, 8134, 10691, 8655, 9214, 8829, 9280, 8207, 8654, 8143, 8795, 9381, 8807, 8291, 8626, 8129, 9131, 8981, 9406, 8205, 8965, 8286, 9000, 8734, 8619, 8232, 8886, 8164, 9254, 8874, 9076, 8231, 9711, 13528, 11975, 10993, 11031, 11189, 10974, 11076, 10936, 10959, 10997, 11018, 11020, 10909, 10654])],\n",
       "       [list([10089, 8661, 8606, 8754, 8154, 8655, 9283, 8717, 8188, 8313, 8600, 8514, 8788, 11127, 9611, 9317, 8491, 8464, 8262, 8997, 9062, 8662, 8473, 9086, 8760, 8444, 8960, 9009, 8926, 8399, 9203, 8398, 8815, 8712, 8983, 8849, 8695, 8854, 8144, 8596, 8800, 9404, 8375, 11266, 9136, 8696, 8995, 8868, 8593, 9032, 8539, 8964, 8960, 9000, 8198, 8996, 8147, 8616, 9007, 8895, 8390, 8807, 8457, 8307, 8877, 8711, 8869, 8848, 8420, 8247, 8875, 9487, 10050, 9520, 8759, 8513, 9144, 8924, 8588, 8785, 8308, 8946, 8886, 8533, 8508, 8700, 8533, 8417, 8942, 8945, 8533, 8765, 8651, 8716, 9093, 8796, 8584, 8123, 8875, 8060, 8807, 9024, 11602, 8879, 8609, 8193, 8678, 9007, 8959, 8472, 8508, 8462, 8293, 8836, 8912, 8865, 8569, 8485, 8272, 8840, 8905, 9103, 8806, 8451, 8342, 9200, 8723, 8611, 8760, 8682, 8585, 9978, 10131, 8724, 9166, 8228, 8496, 8909, 9099, 8446, 8698, 8227, 8554, 9059, 8882, 8244, 8293, 8569, 8182, 8946, 9124, 9147, 8189, 8568, 8109, 8536, 8780, 9538, 8831, 9062, 8250, 11049, 9083, 9532, 8118, 8762, 8224, 8844, 8552, 8922, 8881, 8366, 8545, 8477, 8610, 8752, 9185, 8937, 8838, 8777, 8297, 8861, 9025, 9009, 8649, 8948, 8185, 8718, 8999, 9039, 8705, 10848, 8651, 8862, 8841, 8988, 8235, 8907, 8069, 8893, 8968, 8831, 8811, 8516, 8245, 8902, 9111, 8624, 8576, 9728, 8277, 9525, 8903, 8480, 8831, 8283, 8581, 8867, 9146, 8351, 10026, 9025, 9307, 8944, 8764, 8625, 9582, 9658, 8825, 8600, 8813, 8922, 8050, 8670, 8391, 8061, 9027, 8995, 8698, 8468, 8539, 8079, 9432, 10678, 9473, 8025, 8599, 8301, 8453, 8444, 11859, 10085, 8373, 8382, 8427, 8084, 9128, 8655, 9303, 9998, 8451, 8523, 8260, 8348, 9190, 8733, 8672, 8539, 8485, 8163, 9471, 8859, 8566, 8590, 8703, 7759, 8730, 9237, 8962, 9373, 9991, 9566, 8693, 8709, 9148, 8666, 8105, 8862, 8171, 8420, 8830, 8921, 8575, 8409, 8662, 8090, 8924, 8805, 8895, 8193, 8623, 8480, 8663, 8980, 8873, 8495, 9138, 8314, 8455, 11190, 9165, 9303, 8175, 8723, 8291, 8354, 9044, 8825, 9115, 8761, 9170, 8503, 8837, 8861, 9063, 8230, 8673, 8306, 8762, 9506, 8937, 9226, 8386, 8571, 8453, 8719, 8924, 8813, 8701, 11516, 8983, 8487, 9064, 9573, 8423, 8291, 8776, 8103, 8862, 9205, 8902, 8349, 8785, 8349, 8252, 8906, 9226, 8808, 8205, 8613, 8696, 8881, 9207, 8893, 8290, 8759, 8303, 8460, 11646, 8778, 9264, 8629, 8787, 8452, 8934, 8900, 9139, 8265, 9169, 8147, 8920, 9093, 8820, 8413, 8634, 8376, 8066, 9211, 8902, 8735, 8536, 8526, 8572, 8135, 9488, 9024, 8710, 8238, 10858, 8728, 8643, 9368, 8994, 8205, 8314, 7976, 13728, 11330, 11075, 11027, 10870, 11061, 11211, 11117, 11042, 11070, 11132, 10997, 11019, 10297])],\n",
       "       [list([9804, 9305, 8354, 8836, 8507, 9019, 10982, 8897, 8794, 8241, 8725, 8818, 9270, 8567, 9667, 8527, 8322, 9108, 8918, 8887, 8506, 8330, 8729, 8125, 9260, 9053, 8841, 8571, 10814, 9076, 8882, 8904, 8887, 8668, 8652, 9480, 10135, 8798, 8636, 8774, 8715, 9603, 8261, 8895, 8125, 8928, 8998, 8984, 8511, 8363, 8664, 8380, 9627, 8917, 9034, 8336, 8798, 8523, 8849, 9158, 8919, 9507, 8677, 8839, 8076, 11334, 9275, 9391, 8402, 9219, 8283, 8616, 8938, 9081, 8685, 8738, 8678, 8455, 9563, 8987, 8733, 8260, 8728, 8430, 9306, 8958, 8930, 8182, 8691, 8143, 9032, 8974, 8993, 8269, 8824, 11061, 9482, 8909, 8698, 8441, 8604, 8545, 8815, 8830, 8772, 8276, 9048, 8169, 8848, 9025, 8721, 8577, 8870, 8504, 9101, 8792, 8594, 8489, 8491, 8216, 8967, 8852, 8624, 8933, 10080, 8952, 9412, 8794, 8949, 8726, 8188, 8602, 8972, 9010, 8463, 8746, 8251, 8572, 12065, 8518, 8677, 8545, 8439, 8217, 8774, 9525, 8868, 8274, 8853, 8131, 8541, 9257, 8818, 8536, 10731, 10529, 8251, 8898, 8902, 9255, 8066, 8631, 8236, 9098, 9480, 8920, 8286, 8793, 9080, 8892, 8889, 8731, 8629, 8790, 8327, 8998, 8846, 8692, 8526, 8493, 8423, 9011, 9015, 10283, 8989, 9239, 8170, 8516, 8936, 9391, 8357, 8628, 8160, 9221, 8988, 8903, 9250, 8566, 8256, 8915, 9268, 9080, 8027, 8454, 8720, 8617, 8744, 8820, 8873, 8674, 8705, 8923, 8327, 11362, 9490, 8963, 8342, 8770, 8218, 9328, 9162, 8979, 8334, 7994, 8563, 8247, 8499, 9073, 8636, 8392, 8561, 8587, 8796, 8939, 8924, 8761, 8794, 8236, 8338, 8851, 9469, 8298, 9048, 10120, 8711, 9161, 8801, 8962, 8324, 8967, 8247, 11835, 13200, 10480, 8425, 8659, 8322, 8127, 9216, 8879, 8904, 8349, 8832, 8540, 8778, 9742, 8568, 8806, 8473, 8481, 8109, 8946, 11187, 8770, 9419, 8547, 8341, 9048, 8751, 8904, 8252, 8774, 8445, 8807, 8755, 9262, 8119, 8765, 8391, 8910, 9005, 8949, 8172, 8613, 8127, 9306, 8789, 8900, 8287, 8882, 8156, 8442, 11070, 9441, 8527, 8505, 8913, 8410, 9168, 8919, 8415, 8713, 8415, 8657, 9031, 8869, 8503, 8666, 8182, 8925, 8969, 11618, 10981, 10061, 8413, 8530, 8737, 9027, 9096, 8787, 8781, 9900, 9276, 9699, 8920, 8817, 8492, 8775, 8434, 8634, 8875, 9081, 9001, 8269, 8860, 8391, 8648, 9544, 8875, 8547, 8728, 8609, 8617, 8930, 9353, 8774, 8661, 8668, 8297, 9071, 9306, 11147, 8920, 8840, 8500, 9543, 9175, 8749, 8617, 8496, 8780, 9009, 8739, 8393, 9111, 8487, 8862, 9044, 8705, 8837, 9783, 8289, 8840, 9145, 8700, 8392, 8774, 8307, 8000, 8874, 10097, 9961, 9338, 8171, 8248, 9160, 8912, 8479, 8356, 8706, 8144, 8910, 9061, 8560, 7338, 13620, 11604, 10991, 11209, 11060, 11048, 10961, 10972, 12153, 12089, 10984, 11055, 10940, 10666])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_data_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dtjgp/Learning/d2l-zh/pytorch/chapter_convolutional-modern'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "working_dir = os.getcwd()\n",
    "working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dtjgp/Learning/d2l-zh/pytorch/chapter_convolutional-modern/second_part'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the second_part folder\n",
    "second_part_dir = os.path.join(working_dir, 'second_part')\n",
    "second_part_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data as .npy file\n",
    "np.save(os.path.join(second_part_dir, 'timeenergy_data_forward.npy'), timeenergy_data_forward)\n",
    "np.save(os.path.join(second_part_dir, 'timeenergy_data_round.npy'), timeenergy_data_round)\n",
    "np.save(os.path.join(second_part_dir, 'acc_data.npy'), acc_data)\n",
    "np.save(os.path.join(second_part_dir, 'train_acc.npy'), train_acc)\n",
    "np.save(os.path.join(second_part_dir, 'train_l.npy'), train_l)\n",
    "np.save(os.path.join(second_part_dir, 'time_data_epoch.npy'), time_data_epoch)\n",
    "np.save(os.path.join(second_part_dir, 'energy_data_epoch.npy'), energy_data_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
